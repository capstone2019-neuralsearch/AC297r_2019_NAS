2019-11-04 20:49:32,089 gpu device = 2
2019-11-04 20:49:32,090 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=64, cutout=False, cutout_length=16, data='../data', dataset='GalaxyZoo', drop_path_prob=0.5, epochs=2000, fc1_size=2048, fc2_size=2048, gpu=2, grad_clip=5, init_channels=32, layers=8, learning_rate=0.0005, model_path='saved_models', momentum=0.9, optimizer='Adam', random=False, report_freq=50, save='eval-GalaxyZoo-Run07-C32_L08_FC2048_DROP50_BS64-20191104-204932', seed=0, val_portion=0.1, weight_decay=1e-06)
2019-11-04 20:49:35,508 param size = 6.055045MB
2019-11-04 20:49:35,512 epoch 0 lr 5.000000e-04
2019-11-04 20:49:38,087 train 000 4.057807e-02 -1.530696
2019-11-04 20:49:48,127 train 050 4.181714e-02 -1401.302083
2019-11-04 20:49:58,576 train 100 3.672868e-02 -708.136212
2019-11-04 20:50:08,900 train 150 3.455834e-02 -474.113549
2019-11-04 20:50:19,270 train 200 3.317430e-02 -356.355984
2019-11-04 20:50:29,457 train 250 3.218594e-02 -285.542614
2019-11-04 20:50:39,575 train 300 3.161910e-02 -238.186181
2019-11-04 20:50:49,841 train 350 3.109855e-02 -204.350170
2019-11-04 20:51:00,137 train 400 3.059692e-02 -178.931727
2019-11-04 20:51:10,304 train 450 3.024650e-02 -159.154661
2019-11-04 20:51:20,486 train 500 3.000505e-02 -143.325758
2019-11-04 20:51:30,772 train 550 2.978777e-02 -130.428435
2019-11-04 20:51:41,023 train 600 2.958525e-02 -119.692622
2019-11-04 20:51:51,311 train 650 2.940851e-02 -110.535521
2019-11-04 20:52:01,545 train 700 2.922791e-02 -102.682491
2019-11-04 20:52:11,792 train 750 2.905489e-02 -95.879544
2019-11-04 20:52:22,019 train 800 2.890021e-02 -89.940735
2019-11-04 20:52:32,213 train 850 2.876898e-02 -84.676628
2019-11-04 20:52:35,980 training loss; R2: 2.873195e-02 -83.223606
2019-11-04 20:52:36,544 valid 000 2.643159e-02 -0.117742
2019-11-04 20:52:47,006 valid 050 2.557312e-02 -0.385858
2019-11-04 20:52:56,281 validation loss; R2: 2.572847e-02 -0.378362
2019-11-04 20:52:56,323 epoch 1 lr 5.000000e-04
2019-11-04 20:52:57,073 train 000 2.468536e-02 -0.416861
2019-11-04 20:53:07,442 train 050 2.651622e-02 -0.422247
2019-11-04 20:53:17,875 train 100 2.647979e-02 -0.553682
2019-11-04 20:53:28,143 train 150 2.646275e-02 -0.503460
2019-11-04 20:53:38,452 train 200 2.643875e-02 -13.383835
2019-11-04 20:53:48,800 train 250 2.643375e-02 -10.799196
2019-11-04 20:53:59,135 train 300 2.629025e-02 -9.100649
2019-11-04 20:54:09,475 train 350 2.623868e-02 -7.931583
2019-11-04 20:54:19,798 train 400 2.614567e-02 -7.009275
2019-11-04 20:54:30,131 train 450 2.603977e-02 -6.292032
2019-11-04 20:54:40,453 train 500 2.598294e-02 -5.703136
2019-11-04 20:54:50,779 train 550 2.595855e-02 -5.225513
2019-11-04 20:55:01,078 train 600 2.598647e-02 -4.845056
2019-11-04 20:55:11,370 train 650 2.597866e-02 -4.543300
2019-11-04 20:55:21,667 train 700 2.595811e-02 -4.256243
2019-11-04 20:55:31,972 train 750 2.594475e-02 -4.005342
2019-11-04 20:55:42,289 train 800 2.595412e-02 -3.780549
2019-11-04 20:55:52,611 train 850 2.592811e-02 -3.593461
2019-11-04 20:55:55,616 training loss; R2: 2.592969e-02 -3.542099
2019-11-04 20:55:56,236 valid 000 2.251353e-02 -1.858165
2019-11-04 20:56:06,295 valid 050 2.416184e-02 -0.736746
2019-11-04 20:56:15,429 validation loss; R2: 2.452395e-02 -0.856249
2019-11-04 20:56:15,499 epoch 2 lr 5.000000e-04
2019-11-04 20:56:16,192 train 000 3.012436e-02 -0.093482
2019-11-04 20:56:26,545 train 050 2.581590e-02 -0.536764
2019-11-04 20:56:36,892 train 100 2.542375e-02 -0.519892
2019-11-04 20:56:47,288 train 150 2.565657e-02 -0.491037
2019-11-04 20:56:57,665 train 200 2.555090e-02 -0.500987
2019-11-04 20:57:07,985 train 250 2.563536e-02 -0.554466
2019-11-04 20:57:18,241 train 300 2.563484e-02 -0.542965
2019-11-04 20:57:28,514 train 350 2.565967e-02 -0.523327
2019-11-04 20:57:38,802 train 400 2.561233e-02 -0.590463
2019-11-04 20:57:49,103 train 450 2.564676e-02 -0.593696
2019-11-04 20:57:59,432 train 500 2.560301e-02 -0.590802
2019-11-04 20:58:09,725 train 550 2.554976e-02 -0.900653
2019-11-04 20:58:20,050 train 600 2.552893e-02 -0.869623
2019-11-04 20:58:30,354 train 650 2.547986e-02 -0.836626
2019-11-04 20:58:40,700 train 700 2.547711e-02 -0.809375
2019-11-04 20:58:51,058 train 750 2.545778e-02 -0.786468
2019-11-04 20:59:01,391 train 800 2.545275e-02 -0.766370
2019-11-04 20:59:11,682 train 850 2.541770e-02 -0.750297
2019-11-04 20:59:14,779 training loss; R2: 2.542246e-02 -0.742603
2019-11-04 20:59:15,400 valid 000 2.616451e-02 -0.097793
2019-11-04 20:59:25,503 valid 050 2.592996e-02 -0.230893
2019-11-04 20:59:34,581 validation loss; R2: 2.606961e-02 -0.258381
2019-11-04 20:59:34,651 epoch 3 lr 5.000000e-04
2019-11-04 20:59:35,377 train 000 3.004565e-02 -0.525574
2019-11-04 20:59:45,493 train 050 2.553990e-02 -0.488294
2019-11-04 20:59:55,719 train 100 2.559085e-02 -0.422518
2019-11-04 21:00:05,901 train 150 2.555148e-02 -0.511568
2019-11-04 21:00:16,110 train 200 2.554653e-02 -0.499802
2019-11-04 21:00:26,226 train 250 2.552562e-02 -0.507971
2019-11-04 21:00:36,336 train 300 2.547930e-02 -0.508760
2019-11-04 21:00:46,565 train 350 2.536150e-02 -0.517963
2019-11-04 21:00:56,733 train 400 2.525456e-02 -0.523977
2019-11-04 21:01:06,982 train 450 2.523200e-02 -0.540709
2019-11-04 21:01:17,086 train 500 2.517823e-02 -0.548167
2019-11-04 21:01:27,301 train 550 2.512309e-02 -0.561149
2019-11-04 21:01:37,479 train 600 2.511487e-02 -0.561569
2019-11-04 21:01:47,613 train 650 2.514550e-02 -0.551364
2019-11-04 21:01:57,839 train 700 2.512422e-02 -0.561164
2019-11-04 21:02:07,961 train 750 2.509214e-02 -0.562346
2019-11-04 21:02:18,179 train 800 2.508494e-02 -0.551947
2019-11-04 21:02:28,404 train 850 2.506363e-02 -0.551516
2019-11-04 21:02:31,384 training loss; R2: 2.506268e-02 -0.547848
2019-11-04 21:02:31,920 valid 000 2.333625e-02 -0.773740
2019-11-04 21:02:42,307 valid 050 2.349325e-02 -0.386718
2019-11-04 21:02:51,456 validation loss; R2: 2.364061e-02 -0.346606
2019-11-04 21:02:51,518 epoch 4 lr 5.000000e-04
2019-11-04 21:02:52,211 train 000 2.298155e-02 -0.158695
2019-11-04 21:03:02,628 train 050 2.487548e-02 -0.456624
2019-11-04 21:03:12,976 train 100 2.518055e-02 -0.430008
2019-11-04 21:03:23,310 train 150 2.511945e-02 -0.467467
2019-11-04 21:03:33,608 train 200 2.489042e-02 -0.561679
2019-11-04 21:03:43,956 train 250 2.498160e-02 -0.557977
2019-11-04 21:03:54,300 train 300 2.485928e-02 -0.544275
2019-11-04 21:04:04,631 train 350 2.479786e-02 -0.548948
2019-11-04 21:04:14,915 train 400 2.471461e-02 -0.579960
2019-11-04 21:04:25,199 train 450 2.471699e-02 -0.556717
2019-11-04 21:04:35,515 train 500 2.476766e-02 -0.559539
2019-11-04 21:04:45,833 train 550 2.484016e-02 -0.549098
2019-11-04 21:04:56,157 train 600 2.486585e-02 -0.547380
2019-11-04 21:05:06,470 train 650 2.483003e-02 -0.548007
2019-11-04 21:05:16,780 train 700 2.484281e-02 -0.553358
2019-11-04 21:05:26,999 train 750 2.487201e-02 -0.561058
2019-11-04 21:05:37,268 train 800 2.486825e-02 -0.558865
2019-11-04 21:05:47,520 train 850 2.484655e-02 -0.560663
2019-11-04 21:05:50,565 training loss; R2: 2.483314e-02 -0.558694
2019-11-04 21:05:51,116 valid 000 2.743122e-02 -0.892752
2019-11-04 21:06:01,396 valid 050 2.314055e-02 -0.466863
2019-11-04 21:06:10,512 validation loss; R2: 2.331639e-02 -0.544527
2019-11-04 21:06:10,583 epoch 5 lr 5.000000e-04
2019-11-04 21:06:11,347 train 000 2.529401e-02 -2.181412
2019-11-04 21:06:21,507 train 050 2.507519e-02 -0.679783
2019-11-04 21:06:31,735 train 100 2.490853e-02 -0.631587
2019-11-04 21:06:42,017 train 150 2.491372e-02 -0.588176
2019-11-04 21:06:52,314 train 200 2.492507e-02 -0.551937
2019-11-04 21:07:02,597 train 250 2.489625e-02 -0.761285
2019-11-04 21:07:12,901 train 300 2.488272e-02 -0.752957
2019-11-04 21:07:23,197 train 350 2.477183e-02 -0.722862
2019-11-04 21:07:33,517 train 400 2.476993e-02 -0.705891
2019-11-04 21:07:43,841 train 450 2.473073e-02 -0.676972
2019-11-04 21:07:54,135 train 500 2.469810e-02 -0.669356
2019-11-04 21:08:04,427 train 550 2.469580e-02 -0.647851
2019-11-04 21:08:14,810 train 600 2.470343e-02 -0.633602
2019-11-04 21:08:25,178 train 650 2.469979e-02 -0.623555
2019-11-04 21:08:35,524 train 700 2.471648e-02 -0.616840
2019-11-04 21:08:45,851 train 750 2.475663e-02 -0.613863
2019-11-04 21:08:56,234 train 800 2.478254e-02 -0.608192
2019-11-04 21:09:06,534 train 850 2.480657e-02 -0.599771
2019-11-04 21:09:09,550 training loss; R2: 2.479058e-02 -0.600195
2019-11-04 21:09:10,120 valid 000 2.262078e-02 -0.238352
2019-11-04 21:09:20,147 valid 050 2.482813e-02 -0.253377
2019-11-04 21:09:29,319 validation loss; R2: 2.465480e-02 -0.310262
2019-11-04 21:09:29,381 epoch 6 lr 5.000000e-04
2019-11-04 21:09:30,101 train 000 2.322756e-02 -0.306970
2019-11-04 21:09:40,343 train 050 2.447149e-02 -0.426270
2019-11-04 21:09:50,619 train 100 2.461713e-02 -0.474338
2019-11-04 21:10:00,936 train 150 2.466038e-02 -0.521340
2019-11-04 21:10:11,102 train 200 2.468214e-02 -0.506199
2019-11-04 21:10:21,274 train 250 2.471188e-02 -0.525557
2019-11-04 21:10:31,551 train 300 2.467109e-02 -0.555244
2019-11-04 21:10:41,788 train 350 2.458986e-02 -0.573156
2019-11-04 21:10:52,014 train 400 2.457633e-02 -0.554500
2019-11-04 21:11:02,254 train 450 2.453942e-02 -0.544846
2019-11-04 21:11:12,460 train 500 2.450049e-02 -0.554306
2019-11-04 21:11:22,659 train 550 2.448880e-02 -0.549187
2019-11-04 21:11:32,899 train 600 2.450905e-02 -0.544688
2019-11-04 21:11:43,163 train 650 2.453578e-02 -0.546622
2019-11-04 21:11:53,435 train 700 2.455504e-02 -0.546761
2019-11-04 21:12:03,680 train 750 2.458091e-02 -0.557218
2019-11-04 21:12:13,988 train 800 2.458595e-02 -0.559280
2019-11-04 21:12:24,233 train 850 2.457451e-02 -0.569172
2019-11-04 21:12:27,287 training loss; R2: 2.458150e-02 -0.566436
2019-11-04 21:12:27,871 valid 000 2.644760e-02 -0.184876
2019-11-04 21:12:38,239 valid 050 2.735566e-02 -0.188232
2019-11-04 21:12:47,460 validation loss; R2: 2.739472e-02 -0.191448
2019-11-04 21:12:47,537 epoch 7 lr 5.000000e-04
2019-11-04 21:12:48,200 train 000 2.055134e-02 -0.408785
2019-11-04 21:12:58,634 train 050 2.419275e-02 -0.437316
2019-11-04 21:13:08,972 train 100 2.447522e-02 -0.547282
2019-11-04 21:13:19,367 train 150 2.472234e-02 -0.544949
2019-11-04 21:13:29,831 train 200 2.466912e-02 -0.562273
2019-11-04 21:13:40,218 train 250 2.469810e-02 -0.536616
2019-11-04 21:13:50,564 train 300 2.467806e-02 -0.546781
2019-11-04 21:14:00,943 train 350 2.471128e-02 -0.533625
2019-11-04 21:14:11,312 train 400 2.469688e-02 -0.537433
2019-11-04 21:14:21,718 train 450 2.465002e-02 -0.526421
2019-11-04 21:14:32,147 train 500 2.461027e-02 -0.541731
2019-11-04 21:14:42,662 train 550 2.466248e-02 -0.576274
2019-11-04 21:14:53,013 train 600 2.470662e-02 -0.568548
2019-11-04 21:15:03,394 train 650 2.471135e-02 -0.575793
2019-11-04 21:15:13,734 train 700 2.470533e-02 -0.571652
2019-11-04 21:15:24,374 train 750 2.467700e-02 -0.576968
2019-11-04 21:15:35,308 train 800 2.466991e-02 -0.567227
2019-11-04 21:15:46,245 train 850 2.465992e-02 -0.560653
2019-11-04 21:15:49,545 training loss; R2: 2.466524e-02 -0.557428
2019-11-04 21:15:50,182 valid 000 2.785287e-02 -0.229791
2019-11-04 21:16:00,937 valid 050 2.473652e-02 -0.788425
2019-11-04 21:16:10,551 validation loss; R2: 2.468316e-02 -0.806914
2019-11-04 21:16:10,621 epoch 8 lr 5.000000e-04
2019-11-04 21:16:11,335 train 000 2.357469e-02 -0.488789
2019-11-04 21:16:22,084 train 050 2.461620e-02 -0.430422
2019-11-04 21:16:32,946 train 100 2.478438e-02 -0.487082
2019-11-04 21:16:43,711 train 150 2.463295e-02 -0.456880
2019-11-04 21:16:54,328 train 200 2.464930e-02 -0.521262
2019-11-04 21:17:05,076 train 250 2.458570e-02 -0.511270
2019-11-04 21:17:15,812 train 300 2.460910e-02 -0.501716
2019-11-04 21:17:26,595 train 350 2.457014e-02 -0.514048
2019-11-04 21:17:37,257 train 400 2.450209e-02 -0.526374
2019-11-04 21:17:48,004 train 450 2.451568e-02 -0.534045
2019-11-04 21:17:58,819 train 500 2.446502e-02 -0.578290
2019-11-04 21:18:09,529 train 550 2.445073e-02 -0.564070
2019-11-04 21:18:20,247 train 600 2.439887e-02 -0.552595
2019-11-04 21:18:31,094 train 650 2.441122e-02 -0.561027
2019-11-04 21:18:41,673 train 700 2.438473e-02 -0.560548
2019-11-04 21:18:52,344 train 750 2.435367e-02 -0.553920
2019-11-04 21:19:03,116 train 800 2.435981e-02 -0.560546
2019-11-04 21:19:13,841 train 850 2.435352e-02 -0.785118
2019-11-04 21:19:17,019 training loss; R2: 2.434281e-02 -0.783045
2019-11-04 21:19:17,589 valid 000 3.096958e-02 -4.691983
2019-11-04 21:19:28,399 valid 050 2.904347e-02 -1.102501
2019-11-04 21:19:38,016 validation loss; R2: 2.869205e-02 -1.390235
2019-11-04 21:19:38,095 epoch 9 lr 5.000000e-04
2019-11-04 21:19:38,834 train 000 2.139137e-02 -0.497929
2019-11-04 21:19:49,697 train 050 2.387245e-02 -0.718634
2019-11-04 21:20:00,566 train 100 2.412401e-02 -0.603945
2019-11-04 21:20:11,499 train 150 2.401325e-02 -0.561604
2019-11-04 21:20:22,251 train 200 2.411838e-02 -0.516698
2019-11-04 21:20:33,107 train 250 2.413700e-02 -0.556887
2019-11-04 21:20:44,063 train 300 2.411823e-02 -0.552246
2019-11-04 21:20:54,919 train 350 2.414797e-02 -0.659026
2019-11-04 21:21:05,717 train 400 2.412118e-02 -0.646908
2019-11-04 21:21:16,636 train 450 2.406134e-02 -0.635363
2019-11-04 21:21:27,588 train 500 2.411637e-02 -0.627628
2019-11-04 21:21:38,416 train 550 2.410509e-02 -0.608651
2019-11-04 21:21:49,406 train 600 2.412091e-02 -0.599543
2019-11-04 21:22:00,433 train 650 2.411419e-02 -0.598791
2019-11-04 21:22:11,449 train 700 2.411181e-02 -0.605756
2019-11-04 21:22:22,478 train 750 2.409323e-02 -0.604148
2019-11-04 21:22:33,480 train 800 2.406843e-02 -0.599172
2019-11-04 21:22:44,397 train 850 2.407099e-02 -0.598408
2019-11-04 21:22:47,610 training loss; R2: 2.406478e-02 -0.601658
2019-11-04 21:22:48,171 valid 000 2.180800e-02 -0.118060
2019-11-04 21:22:59,021 valid 050 2.721652e-02 -0.197260
2019-11-04 21:23:08,632 validation loss; R2: 2.733779e-02 -0.258659
2019-11-04 21:23:08,703 epoch 10 lr 5.000000e-04
2019-11-04 21:23:09,425 train 000 2.430824e-02 -0.272268
2019-11-04 21:23:20,415 train 050 2.474052e-02 -0.474578
2019-11-04 21:23:31,303 train 100 2.486746e-02 -1.732762
2019-11-04 21:23:42,092 train 150 2.481944e-02 -1.403339
2019-11-04 21:23:52,703 train 200 2.485958e-02 -1.182844
2019-11-04 21:24:03,419 train 250 2.488622e-02 -1.044567
2019-11-04 21:24:14,123 train 300 2.488698e-02 -0.949882
2019-11-04 21:24:24,893 train 350 2.486944e-02 -0.903226
2019-11-04 21:24:35,637 train 400 2.500395e-02 -0.836466
2019-11-04 21:24:46,407 train 450 2.497286e-02 -0.793173
2019-11-04 21:24:57,118 train 500 2.498674e-02 -0.766205
2019-11-04 21:25:07,894 train 550 2.496082e-02 -0.748807
2019-11-04 21:25:18,574 train 600 2.490215e-02 -0.715998
2019-11-04 21:25:29,291 train 650 2.483536e-02 -0.695064
2019-11-04 21:25:39,984 train 700 2.477748e-02 -0.682733
2019-11-04 21:25:50,722 train 750 2.472293e-02 -0.667332
2019-11-04 21:26:01,456 train 800 2.463309e-02 -0.654375
2019-11-04 21:26:12,199 train 850 2.459055e-02 -0.639677
2019-11-04 21:26:15,462 training loss; R2: 2.458064e-02 -0.634378
2019-11-04 21:26:16,071 valid 000 2.373998e-02 0.018009
2019-11-04 21:26:26,749 valid 050 2.290444e-02 -0.274573
2019-11-04 21:26:36,503 validation loss; R2: 2.317322e-02 -0.238957
2019-11-04 21:26:36,575 epoch 11 lr 5.000000e-04
2019-11-04 21:26:37,333 train 000 2.432446e-02 -0.147821
2019-11-04 21:26:48,251 train 050 2.375086e-02 -0.758604
2019-11-04 21:26:59,151 train 100 2.385540e-02 -0.757175
2019-11-04 21:27:10,101 train 150 2.387670e-02 -0.711510
2019-11-04 21:27:20,819 train 200 2.380042e-02 -0.720040
2019-11-04 21:27:31,519 train 250 2.376835e-02 -0.656882
2019-11-04 21:27:42,209 train 300 2.392468e-02 -2.092218
2019-11-04 21:27:52,938 train 350 2.400556e-02 -1.858337
2019-11-04 21:28:03,637 train 400 2.402701e-02 -1.683821
2019-11-04 21:28:14,309 train 450 2.402290e-02 -1.552236
2019-11-04 21:28:24,987 train 500 2.401713e-02 -1.447219
2019-11-04 21:28:35,797 train 550 2.400757e-02 -1.357647
2019-11-04 21:28:46,515 train 600 2.399550e-02 -1.276459
2019-11-04 21:28:57,274 train 650 2.399347e-02 -1.210099
2019-11-04 21:29:08,006 train 700 2.398362e-02 -1.166014
2019-11-04 21:29:18,651 train 750 2.396527e-02 -1.119088
2019-11-04 21:29:29,571 train 800 2.395413e-02 -1.083309
2019-11-04 21:29:40,436 train 850 2.395292e-02 -1.054158
2019-11-04 21:29:43,652 training loss; R2: 2.394269e-02 -1.046462
2019-11-04 21:29:44,249 valid 000 2.219915e-02 0.003337
2019-11-04 21:29:54,860 valid 050 2.138643e-02 -0.256749
2019-11-04 21:30:04,537 validation loss; R2: 2.111447e-02 -0.299751
2019-11-04 21:30:04,609 epoch 12 lr 5.000000e-04
2019-11-04 21:30:05,347 train 000 2.239290e-02 -0.392571
2019-11-04 21:30:16,101 train 050 2.382025e-02 -0.477680
2019-11-04 21:30:26,971 train 100 2.396820e-02 -0.508075
2019-11-04 21:30:37,837 train 150 2.409332e-02 -0.523523
2019-11-04 21:30:48,557 train 200 2.380473e-02 -0.522504
2019-11-04 21:30:59,377 train 250 2.374929e-02 -0.537973
2019-11-04 21:31:10,170 train 300 2.366349e-02 -0.540543
2019-11-04 21:31:21,022 train 350 2.361908e-02 -0.545460
2019-11-04 21:31:31,909 train 400 2.364710e-02 -0.547646
2019-11-04 21:31:42,647 train 450 2.366930e-02 -0.523361
2019-11-04 21:31:53,396 train 500 2.364745e-02 -0.513836
2019-11-04 21:32:04,190 train 550 2.371471e-02 -0.522209
2019-11-04 21:32:15,010 train 600 2.384002e-02 -0.525022
2019-11-04 21:32:25,750 train 650 2.403720e-02 -0.526414
2019-11-04 21:32:36,573 train 700 2.425643e-02 -0.518633
2019-11-04 21:32:47,250 train 750 2.432729e-02 -0.525834
2019-11-04 21:32:58,020 train 800 2.436093e-02 -0.519958
2019-11-04 21:33:08,799 train 850 2.438051e-02 -0.517845
2019-11-04 21:33:12,065 training loss; R2: 2.439744e-02 -0.516362
2019-11-04 21:33:12,659 valid 000 2.680578e-02 -0.111023
2019-11-04 21:33:23,388 valid 050 2.451953e-02 -0.369111
2019-11-04 21:33:33,181 validation loss; R2: 2.462194e-02 -0.364824
2019-11-04 21:33:33,242 epoch 13 lr 5.000000e-04
2019-11-04 21:33:34,050 train 000 2.334364e-02 -0.125305
2019-11-04 21:33:44,978 train 050 2.548744e-02 -0.313396
2019-11-04 21:33:55,797 train 100 2.501505e-02 -0.383529
2019-11-04 21:34:06,575 train 150 2.493968e-02 -0.450395
2019-11-04 21:34:17,259 train 200 2.474235e-02 -0.453772
2019-11-04 21:34:27,971 train 250 2.463602e-02 -0.471824
2019-11-04 21:34:38,700 train 300 2.452486e-02 -0.469904
2019-11-04 21:34:49,391 train 350 2.447565e-02 -0.480863
2019-11-04 21:35:00,056 train 400 2.444712e-02 -0.505614
2019-11-04 21:35:10,785 train 450 2.436723e-02 -0.496446
2019-11-04 21:35:21,518 train 500 2.426482e-02 -0.509143
2019-11-04 21:35:32,250 train 550 2.424103e-02 -0.495866
2019-11-04 21:35:43,006 train 600 2.420055e-02 -0.507063
2019-11-04 21:35:53,711 train 650 2.418830e-02 -0.499712
2019-11-04 21:36:04,265 train 700 2.416505e-02 -0.572083
2019-11-04 21:36:14,945 train 750 2.414129e-02 -0.567435
2019-11-04 21:36:25,720 train 800 2.414326e-02 -0.565863
2019-11-04 21:36:36,507 train 850 2.412491e-02 -0.556219
2019-11-04 21:36:39,678 training loss; R2: 2.412300e-02 -0.552386
2019-11-04 21:36:40,296 valid 000 2.407984e-02 -0.021701
2019-11-04 21:36:51,083 valid 050 2.544483e-02 -0.227954
2019-11-04 21:37:00,668 validation loss; R2: 2.539656e-02 -0.203778
2019-11-04 21:37:00,740 epoch 14 lr 5.000000e-04
2019-11-04 21:37:01,487 train 000 2.464965e-02 -0.593268
2019-11-04 21:37:12,358 train 050 2.364476e-02 -0.460404
2019-11-04 21:37:23,204 train 100 2.358424e-02 -0.576581
2019-11-04 21:37:34,132 train 150 2.371406e-02 -0.531406
2019-11-04 21:37:45,042 train 200 2.372615e-02 -0.520470
2019-11-04 21:37:55,888 train 250 2.371501e-02 -0.705273
2019-11-04 21:38:06,743 train 300 2.363791e-02 -0.675776
2019-11-04 21:38:17,592 train 350 2.358100e-02 -0.648342
2019-11-04 21:38:28,485 train 400 2.363701e-02 -0.633051
2019-11-04 21:38:39,271 train 450 2.362140e-02 -0.617830
2019-11-04 21:38:50,111 train 500 2.365023e-02 -0.592506
2019-11-04 21:39:00,968 train 550 2.361664e-02 -0.584254
2019-11-04 21:39:11,808 train 600 2.354839e-02 -0.570869
2019-11-04 21:39:22,634 train 650 2.353836e-02 -0.556767
2019-11-04 21:39:33,249 train 700 2.357071e-02 -0.554273
2019-11-04 21:39:44,088 train 750 2.360386e-02 -0.552111
2019-11-04 21:39:54,856 train 800 2.355489e-02 -0.557909
2019-11-04 21:40:05,630 train 850 2.356323e-02 -0.553680
2019-11-04 21:40:08,817 training loss; R2: 2.356142e-02 -0.549585
2019-11-04 21:40:09,424 valid 000 2.456139e-02 -0.124707
2019-11-04 21:40:20,139 valid 050 2.250426e-02 -0.250052
2019-11-04 21:40:29,648 validation loss; R2: 2.250849e-02 -0.232957
2019-11-04 21:40:29,713 epoch 15 lr 5.000000e-04
2019-11-04 21:40:30,483 train 000 2.515865e-02 -1.002180
2019-11-04 21:40:41,326 train 050 2.387933e-02 -0.781689
2019-11-04 21:40:52,243 train 100 2.386143e-02 -0.771688
2019-11-04 21:41:02,985 train 150 2.383750e-02 -0.676795
2019-11-04 21:41:13,840 train 200 2.372935e-02 -0.646956
2019-11-04 21:41:24,570 train 250 2.365683e-02 -0.618310
2019-11-04 21:41:35,400 train 300 2.362927e-02 -0.612893
2019-11-04 21:41:46,074 train 350 2.352314e-02 -0.586538
2019-11-04 21:41:56,888 train 400 2.350604e-02 -0.604230
2019-11-04 21:42:07,521 train 450 2.349365e-02 -0.597524
2019-11-04 21:42:18,177 train 500 2.347423e-02 -0.584457
2019-11-04 21:42:28,794 train 550 2.342189e-02 -0.591047
2019-11-04 21:42:39,395 train 600 2.337845e-02 -0.572328
2019-11-04 21:42:49,888 train 650 2.344141e-02 -0.566475
2019-11-04 21:43:00,273 train 700 2.369506e-02 -0.559894
2019-11-04 21:43:10,713 train 750 2.386135e-02 -0.559660
2019-11-04 21:43:21,358 train 800 2.395299e-02 -0.561653
2019-11-04 21:43:32,079 train 850 2.399146e-02 -0.556230
2019-11-04 21:43:35,231 training loss; R2: 2.399855e-02 -0.555922
2019-11-04 21:43:35,809 valid 000 2.575317e-02 -0.118729
2019-11-04 21:43:46,352 valid 050 2.447422e-02 -0.169542
2019-11-04 21:43:55,696 validation loss; R2: 2.466054e-02 -0.168043
2019-11-04 21:43:55,777 epoch 16 lr 5.000000e-04
2019-11-04 21:43:56,482 train 000 2.682751e-02 -0.064167
2019-11-04 21:44:07,301 train 050 2.422185e-02 -0.395598
2019-11-04 21:44:18,069 train 100 2.394794e-02 -0.443199
2019-11-04 21:44:28,807 train 150 2.376186e-02 -0.530388
2019-11-04 21:44:39,432 train 200 2.380648e-02 -0.509331
2019-11-04 21:44:50,144 train 250 2.379888e-02 -0.530477
2019-11-04 21:45:00,920 train 300 2.375693e-02 -0.532991
2019-11-04 21:45:11,671 train 350 2.381884e-02 -0.512364
2019-11-04 21:45:22,451 train 400 2.375263e-02 -0.511389
2019-11-04 21:45:33,202 train 450 2.373018e-02 -0.503329
2019-11-04 21:45:43,945 train 500 2.369182e-02 -0.506397
2019-11-04 21:45:54,722 train 550 2.365294e-02 -0.518292
2019-11-04 21:46:05,461 train 600 2.362395e-02 -0.507573
2019-11-04 21:46:16,191 train 650 2.361660e-02 -0.505813
2019-11-04 21:46:26,799 train 700 2.356142e-02 -0.496267
2019-11-04 21:46:37,393 train 750 2.350990e-02 -0.496502
2019-11-04 21:46:48,217 train 800 2.344949e-02 -0.506104
2019-11-04 21:46:59,084 train 850 2.342596e-02 -0.505805
2019-11-04 21:47:02,361 training loss; R2: 2.343001e-02 -0.502884
2019-11-04 21:47:02,910 valid 000 3.779048e-02 -0.283927
2019-11-04 21:47:13,694 valid 050 3.827992e-02 -0.537401
2019-11-04 21:47:23,537 validation loss; R2: 3.824620e-02 -0.620922
2019-11-04 21:47:23,603 epoch 17 lr 5.000000e-04
2019-11-04 21:47:24,307 train 000 2.018599e-02 -0.258732
2019-11-04 21:47:35,250 train 050 2.288645e-02 -0.435749
2019-11-04 21:47:46,163 train 100 2.284850e-02 -0.441045
2019-11-04 21:47:57,104 train 150 2.303797e-02 -0.460358
2019-11-04 21:48:07,978 train 200 2.310710e-02 -0.517370
2019-11-04 21:48:18,900 train 250 2.330963e-02 -0.519914
2019-11-04 21:48:29,744 train 300 2.337205e-02 -0.517998
2019-11-04 21:48:40,609 train 350 2.331464e-02 -0.520744
2019-11-04 21:48:51,461 train 400 2.326345e-02 -0.504004
2019-11-04 21:49:02,218 train 450 2.320730e-02 -0.515737
2019-11-04 21:49:12,819 train 500 2.321072e-02 -0.512367
2019-11-04 21:49:23,465 train 550 2.322831e-02 -0.510915
2019-11-04 21:49:34,103 train 600 2.322721e-02 -0.523352
2019-11-04 21:49:44,678 train 650 2.323859e-02 -0.535967
2019-11-04 21:49:55,112 train 700 2.326594e-02 -0.522747
2019-11-04 21:50:05,507 train 750 2.325376e-02 -0.569270
2019-11-04 21:50:16,031 train 800 2.322248e-02 -0.564956
2019-11-04 21:50:26,752 train 850 2.316730e-02 -0.557138
2019-11-04 21:50:30,042 training loss; R2: 2.317379e-02 -0.555504
2019-11-04 21:50:30,611 valid 000 2.418070e-02 -0.334656
2019-11-04 21:50:41,407 valid 050 2.363511e-02 -0.204597
2019-11-04 21:50:51,254 validation loss; R2: 2.347735e-02 -0.200982
2019-11-04 21:50:51,317 epoch 18 lr 5.000000e-04
2019-11-04 21:50:52,033 train 000 2.515003e-02 -0.014272
2019-11-04 21:51:03,071 train 050 2.260588e-02 -0.531067
2019-11-04 21:51:14,188 train 100 2.265741e-02 -0.491796
2019-11-04 21:51:25,161 train 150 2.272434e-02 -0.497180
2019-11-04 21:51:36,008 train 200 2.294621e-02 -0.494168
2019-11-04 21:51:46,775 train 250 2.303813e-02 -0.504349
2019-11-04 21:51:57,474 train 300 2.304863e-02 -0.471451
2019-11-04 21:52:08,099 train 350 2.315365e-02 -0.466911
2019-11-04 21:52:18,640 train 400 2.316535e-02 -0.479317
2019-11-04 21:52:29,174 train 450 2.312178e-02 -1.999191
2019-11-04 21:52:39,730 train 500 2.319152e-02 -1.860345
2019-11-04 21:52:50,490 train 550 2.325814e-02 -1.733095
2019-11-04 21:53:01,100 train 600 2.321672e-02 -1.626093
2019-11-04 21:53:11,789 train 650 2.323778e-02 -1.576728
2019-11-04 21:53:22,384 train 700 2.324510e-02 -1.498948
2019-11-04 21:53:32,934 train 750 2.325907e-02 -1.463252
2019-11-04 21:53:43,638 train 800 2.321777e-02 -1.411517
2019-11-04 21:53:54,430 train 850 2.317142e-02 -1.355710
2019-11-04 21:53:57,703 training loss; R2: 2.316290e-02 -1.343797
2019-11-04 21:53:58,324 valid 000 1.872462e-02 -0.029939
2019-11-04 21:54:09,013 valid 050 2.060752e-02 -0.289732
2019-11-04 21:54:18,648 validation loss; R2: 2.031401e-02 -0.287997
2019-11-04 21:54:18,711 epoch 19 lr 5.000000e-04
2019-11-04 21:54:19,461 train 000 2.338532e-02 -0.835464
2019-11-04 21:54:30,313 train 050 2.255384e-02 -0.593913
2019-11-04 21:54:41,106 train 100 2.270338e-02 -0.602902
2019-11-04 21:54:51,821 train 150 2.264829e-02 -0.579902
2019-11-04 21:55:02,549 train 200 2.270975e-02 -0.587840
2019-11-04 21:55:13,302 train 250 2.273761e-02 -0.565838
2019-11-04 21:55:24,080 train 300 2.272864e-02 -0.587843
2019-11-04 21:55:34,830 train 350 2.269776e-02 -0.591210
2019-11-04 21:55:45,605 train 400 2.269299e-02 -0.596467
2019-11-04 21:55:56,410 train 450 2.272671e-02 -0.582448
2019-11-04 21:56:07,264 train 500 2.283166e-02 -0.582925
2019-11-04 21:56:18,045 train 550 2.292951e-02 -0.587382
2019-11-04 21:56:28,742 train 600 2.296734e-02 -0.569751
2019-11-04 21:56:39,485 train 650 2.292553e-02 -0.569476
2019-11-04 21:56:50,175 train 700 2.291130e-02 -0.556485
2019-11-04 21:57:00,779 train 750 2.293430e-02 -0.591359
2019-11-04 21:57:11,492 train 800 2.294885e-02 -0.590042
2019-11-04 21:57:22,273 train 850 2.301359e-02 -0.589220
2019-11-04 21:57:25,559 training loss; R2: 2.301445e-02 -0.585596
2019-11-04 21:57:26,166 valid 000 2.166258e-02 0.003377
2019-11-04 21:57:36,736 valid 050 2.264811e-02 -0.279499
2019-11-04 21:57:46,143 validation loss; R2: 2.279146e-02 -0.386014
2019-11-04 21:57:46,223 epoch 20 lr 5.000000e-04
2019-11-04 21:57:46,914 train 000 2.477886e-02 -0.029212
2019-11-04 21:57:57,646 train 050 2.329006e-02 -0.411866
2019-11-04 21:58:08,368 train 100 2.331591e-02 -0.519318
2019-11-04 21:58:19,157 train 150 2.385489e-02 -0.548762
2019-11-04 21:58:29,918 train 200 2.439784e-02 -0.542344
2019-11-04 21:58:40,676 train 250 2.484894e-02 -0.537978
2019-11-04 21:58:51,407 train 300 2.490483e-02 -0.520798
2019-11-04 21:59:02,151 train 350 2.484084e-02 -0.487570
2019-11-04 21:59:12,907 train 400 2.482278e-02 -0.485362
2019-11-04 21:59:23,673 train 450 2.473643e-02 -0.473776
2019-11-04 21:59:34,404 train 500 2.471817e-02 -0.502865
2019-11-04 21:59:45,156 train 550 2.460882e-02 -0.523757
2019-11-04 21:59:55,903 train 600 2.451360e-02 -0.524667
2019-11-04 22:00:06,648 train 650 2.440675e-02 -0.513614
2019-11-04 22:00:17,326 train 700 2.432132e-02 -0.513571
2019-11-04 22:00:28,022 train 750 2.423750e-02 -0.512584
2019-11-04 22:00:38,848 train 800 2.416715e-02 -0.509071
2019-11-04 22:00:49,790 train 850 2.408950e-02 -0.513385
2019-11-04 22:00:53,092 training loss; R2: 2.407697e-02 -0.512867
2019-11-04 22:00:53,705 valid 000 1.963656e-02 0.019288
2019-11-04 22:01:04,392 valid 050 2.057228e-02 -0.152106
2019-11-04 22:01:14,074 validation loss; R2: 2.067332e-02 -0.179316
2019-11-04 22:01:14,145 epoch 21 lr 5.000000e-04
2019-11-04 22:01:14,896 train 000 2.002398e-02 -0.346739
2019-11-04 22:01:25,905 train 050 2.275310e-02 -0.507213
2019-11-04 22:01:36,681 train 100 2.310302e-02 -0.456164
2019-11-04 22:01:47,508 train 150 2.332414e-02 -0.487945
2019-11-04 22:01:58,381 train 200 2.337751e-02 -0.553086
2019-11-04 22:02:09,335 train 250 2.321495e-02 -0.537505
2019-11-04 22:02:20,148 train 300 2.313174e-02 -0.524676
2019-11-04 22:02:30,925 train 350 2.310766e-02 -0.521866
2019-11-04 22:02:41,723 train 400 2.312777e-02 -0.538977
2019-11-04 22:02:52,512 train 450 2.317646e-02 -0.547761
2019-11-04 22:03:03,302 train 500 2.316483e-02 -0.523740
2019-11-04 22:03:14,090 train 550 2.318321e-02 -0.520411
2019-11-04 22:03:24,856 train 600 2.320339e-02 -0.510792
2019-11-04 22:03:35,628 train 650 2.316390e-02 -0.509040
2019-11-04 22:03:46,232 train 700 2.317623e-02 -4.840761
2019-11-04 22:03:56,810 train 750 2.314138e-02 -4.545987
2019-11-04 22:04:07,576 train 800 2.310104e-02 -4.293058
2019-11-04 22:04:18,288 train 850 2.305602e-02 -4.074808
2019-11-04 22:04:21,552 training loss; R2: 2.305038e-02 -4.016991
2019-11-04 22:04:22,171 valid 000 2.021176e-02 -0.535849
2019-11-04 22:04:32,796 valid 050 2.123822e-02 -0.294910
2019-11-04 22:04:42,511 validation loss; R2: 2.118944e-02 -0.293524
2019-11-04 22:04:42,577 epoch 22 lr 5.000000e-04
2019-11-04 22:04:43,320 train 000 2.195343e-02 -0.413010
2019-11-04 22:04:54,251 train 050 2.299554e-02 -0.324002
2019-11-04 22:05:05,127 train 100 2.300242e-02 -0.382234
2019-11-04 22:05:16,029 train 150 2.282182e-02 -0.469724
2019-11-04 22:05:26,861 train 200 2.274231e-02 -0.530375
2019-11-04 22:05:37,827 train 250 2.284785e-02 -0.527891
2019-11-04 22:05:48,802 train 300 2.286982e-02 -0.545271
2019-11-04 22:05:59,768 train 350 2.289872e-02 -0.564438
2019-11-04 22:06:10,659 train 400 2.287841e-02 -0.566836
2019-11-04 22:06:21,587 train 450 2.282460e-02 -0.558370
2019-11-04 22:06:32,477 train 500 2.276788e-02 -0.566812
2019-11-04 22:06:43,319 train 550 2.275612e-02 -0.556325
2019-11-04 22:06:54,190 train 600 2.279626e-02 -0.548062
2019-11-04 22:07:05,060 train 650 2.281459e-02 -0.541000
2019-11-04 22:07:15,624 train 700 2.279874e-02 -0.548269
2019-11-04 22:07:26,253 train 750 2.279317e-02 -0.545023
2019-11-04 22:07:37,159 train 800 2.280493e-02 -0.554605
2019-11-04 22:07:48,041 train 850 2.280890e-02 -0.549276
2019-11-04 22:07:51,241 training loss; R2: 2.280767e-02 -0.548328
2019-11-04 22:07:51,819 valid 000 1.948958e-02 -1.073184
2019-11-04 22:08:02,507 valid 050 2.025299e-02 -0.221763
2019-11-04 22:08:12,211 validation loss; R2: 2.025445e-02 -0.215099
2019-11-04 22:08:12,279 epoch 23 lr 5.000000e-04
2019-11-04 22:08:13,035 train 000 2.495768e-02 -0.348165
2019-11-04 22:08:23,763 train 050 2.201984e-02 -0.475489
2019-11-04 22:08:34,577 train 100 2.228385e-02 -0.596017
2019-11-04 22:08:45,406 train 150 2.255722e-02 -0.560842
2019-11-04 22:08:55,993 train 200 2.256178e-02 -0.564549
2019-11-04 22:09:06,777 train 250 2.268625e-02 -0.543388
2019-11-04 22:09:17,475 train 300 2.272324e-02 -0.555350
2019-11-04 22:09:28,220 train 350 2.268884e-02 -0.559729
2019-11-04 22:09:38,952 train 400 2.270531e-02 -0.559047
2019-11-04 22:09:49,629 train 450 2.270309e-02 -0.541297
2019-11-04 22:10:00,528 train 500 2.275753e-02 -0.529035
2019-11-04 22:10:11,349 train 550 2.277405e-02 -0.521724
2019-11-04 22:10:22,241 train 600 2.279999e-02 -0.516668
2019-11-04 22:10:32,908 train 650 2.284285e-02 -0.508267
2019-11-04 22:10:43,627 train 700 2.282073e-02 -0.515731
2019-11-04 22:10:54,242 train 750 2.283995e-02 -0.517001
2019-11-04 22:11:04,970 train 800 2.282201e-02 -0.506804
2019-11-04 22:11:15,784 train 850 2.282366e-02 -0.506887
2019-11-04 22:11:19,044 training loss; R2: 2.282871e-02 -0.513528
2019-11-04 22:11:19,661 valid 000 2.003160e-02 0.098364
2019-11-04 22:11:30,332 valid 050 1.996597e-02 -1.210997
2019-11-04 22:11:40,054 validation loss; R2: 1.991291e-02 -0.840966
2019-11-04 22:11:40,131 epoch 24 lr 5.000000e-04
2019-11-04 22:11:40,891 train 000 2.226246e-02 -0.789928
2019-11-04 22:11:52,012 train 050 2.276298e-02 -0.584139
2019-11-04 22:12:03,063 train 100 2.296929e-02 -0.544403
2019-11-04 22:12:14,091 train 150 2.302847e-02 -0.515984
2019-11-04 22:12:24,960 train 200 2.293288e-02 -0.500564
2019-11-04 22:12:35,790 train 250 2.289250e-02 -0.470359
2019-11-04 22:12:46,638 train 300 2.368440e-02 -0.486480
2019-11-04 22:12:57,475 train 350 2.425157e-02 -0.484806
2019-11-04 22:13:08,318 train 400 2.455158e-02 -0.477067
2019-11-04 22:13:19,134 train 450 2.467264e-02 -0.465857
2019-11-04 22:13:29,998 train 500 2.475790e-02 -0.485398
2019-11-04 22:13:40,850 train 550 2.476772e-02 -0.497623
2019-11-04 22:13:51,743 train 600 2.473462e-02 -0.500342
2019-11-04 22:14:02,524 train 650 2.466734e-02 -0.505299
2019-11-04 22:14:13,129 train 700 2.457854e-02 -0.506865
2019-11-04 22:14:23,772 train 750 2.452627e-02 -0.610235
2019-11-04 22:14:34,616 train 800 2.447924e-02 -0.599386
2019-11-04 22:14:45,445 train 850 2.443515e-02 -0.600420
2019-11-04 22:14:48,691 training loss; R2: 2.442224e-02 -0.597795
2019-11-04 22:14:49,286 valid 000 2.411426e-02 0.018051
2019-11-04 22:14:59,925 valid 050 2.342509e-02 -3.002643
2019-11-04 22:15:09,651 validation loss; R2: 2.364477e-02 -1.675733
2019-11-04 22:15:09,719 epoch 25 lr 5.000000e-04
2019-11-04 22:15:10,429 train 000 2.143116e-02 -0.671007
2019-11-04 22:15:21,450 train 050 2.347244e-02 -0.443212
2019-11-04 22:15:32,356 train 100 2.350119e-02 -0.410876
2019-11-04 22:15:43,205 train 150 2.363490e-02 -0.414032
2019-11-04 22:15:54,141 train 200 2.365902e-02 -0.453149
2019-11-04 22:16:04,924 train 250 2.351703e-02 -0.440345
2019-11-04 22:16:15,894 train 300 2.351261e-02 -0.435722
2019-11-04 22:16:26,744 train 350 2.348106e-02 -0.444243
2019-11-04 22:16:37,619 train 400 2.342683e-02 -0.476653
2019-11-04 22:16:48,386 train 450 2.338280e-02 -0.474091
2019-11-04 22:16:59,179 train 500 2.338705e-02 -0.479384
2019-11-04 22:17:09,987 train 550 2.336523e-02 -0.479989
2019-11-04 22:17:20,759 train 600 2.334687e-02 -0.479366
2019-11-04 22:17:31,510 train 650 2.336197e-02 -0.469852
2019-11-04 22:17:42,258 train 700 2.333483e-02 -0.470068
2019-11-04 22:17:53,054 train 750 2.329957e-02 -0.464178
2019-11-04 22:18:03,897 train 800 2.333301e-02 -0.460940
2019-11-04 22:18:14,705 train 850 2.331131e-02 -0.458218
2019-11-04 22:18:17,976 training loss; R2: 2.330972e-02 -0.456290
2019-11-04 22:18:18,598 valid 000 2.367559e-02 -0.416192
2019-11-04 22:18:29,438 valid 050 2.283855e-02 -0.824292
2019-11-04 22:18:39,178 validation loss; R2: 2.242323e-02 -0.871895
2019-11-04 22:18:39,246 epoch 26 lr 5.000000e-04
2019-11-04 22:18:39,996 train 000 2.668217e-02 -0.568064
2019-11-04 22:18:50,718 train 050 2.339169e-02 -0.449964
2019-11-04 22:19:01,476 train 100 2.308648e-02 -0.507864
2019-11-04 22:19:12,269 train 150 2.303059e-02 -0.511122
2019-11-04 22:19:22,898 train 200 2.300495e-02 -0.479909
2019-11-04 22:19:33,595 train 250 2.304053e-02 -0.473202
2019-11-04 22:19:44,454 train 300 2.299814e-02 -0.505073
2019-11-04 22:19:55,320 train 350 2.298818e-02 -0.495038
2019-11-04 22:20:06,125 train 400 2.306449e-02 -0.489917
2019-11-04 22:20:16,860 train 450 2.310740e-02 -0.487743
2019-11-04 22:20:27,583 train 500 2.312613e-02 -0.499995
2019-11-04 22:20:38,372 train 550 2.312630e-02 -0.501957
2019-11-04 22:20:49,171 train 600 2.313552e-02 -0.513256
2019-11-04 22:20:59,873 train 650 2.313395e-02 -0.515231
2019-11-04 22:21:10,431 train 700 2.310176e-02 -0.523289
2019-11-04 22:21:21,120 train 750 2.309568e-02 -0.540863
2019-11-04 22:21:31,850 train 800 2.311544e-02 -0.539193
2019-11-04 22:21:42,590 train 850 2.313090e-02 -0.529381
2019-11-04 22:21:45,841 training loss; R2: 2.311883e-02 -0.528356
2019-11-04 22:21:46,421 valid 000 1.856915e-02 -0.098213
2019-11-04 22:21:57,144 valid 050 1.939368e-02 -1.069501
2019-11-04 22:22:06,845 validation loss; R2: 1.947145e-02 -0.723533
2019-11-04 22:22:06,911 epoch 27 lr 5.000000e-04
2019-11-04 22:22:07,616 train 000 2.004017e-02 -0.116440
2019-11-04 22:22:18,425 train 050 2.299526e-02 -0.571484
2019-11-04 22:22:29,244 train 100 2.311247e-02 -0.485445
2019-11-04 22:22:40,055 train 150 2.330138e-02 -0.471341
2019-11-04 22:22:50,786 train 200 2.320718e-02 -0.494372
2019-11-04 22:23:01,496 train 250 2.301813e-02 -0.541573
2019-11-04 22:23:12,341 train 300 2.300925e-02 -0.546218
2019-11-04 22:23:23,176 train 350 2.297623e-02 -0.578105
2019-11-04 22:23:33,902 train 400 2.300313e-02 -0.573432
2019-11-04 22:23:44,597 train 450 2.300667e-02 -0.550837
2019-11-04 22:23:55,384 train 500 2.295680e-02 -0.548265
2019-11-04 22:24:06,193 train 550 2.295549e-02 -0.557115
2019-11-04 22:24:16,965 train 600 2.296853e-02 -0.542844
2019-11-04 22:24:27,653 train 650 2.295999e-02 -0.629516
2019-11-04 22:24:38,240 train 700 2.295133e-02 -0.638384
2019-11-04 22:24:48,993 train 750 2.294014e-02 -0.634407
2019-11-04 22:24:59,830 train 800 2.294566e-02 -0.615446
2019-11-04 22:25:10,534 train 850 2.293277e-02 -0.603620
2019-11-04 22:25:13,699 training loss; R2: 2.293795e-02 -0.600441
2019-11-04 22:25:14,317 valid 000 2.501077e-02 -0.495230
2019-11-04 22:25:25,027 valid 050 2.499394e-02 -0.404217
2019-11-04 22:25:34,556 validation loss; R2: 2.531551e-02 -0.366347
2019-11-04 22:25:34,623 epoch 28 lr 5.000000e-04
2019-11-04 22:25:35,359 train 000 2.391201e-02 -0.198348
2019-11-04 22:25:46,173 train 050 2.319032e-02 -0.595177
2019-11-04 22:25:57,046 train 100 2.288622e-02 -1.056691
2019-11-04 22:26:07,877 train 150 2.286901e-02 -0.948379
2019-11-04 22:26:18,535 train 200 2.290118e-02 -0.807274
2019-11-04 22:26:29,327 train 250 2.288117e-02 -0.731708
2019-11-04 22:26:40,117 train 300 2.282251e-02 -0.709395
2019-11-04 22:26:50,985 train 350 2.280780e-02 -0.877074
2019-11-04 22:27:01,846 train 400 2.279841e-02 -0.812804
2019-11-04 22:27:12,660 train 450 2.278363e-02 -0.788437
2019-11-04 22:27:23,460 train 500 2.280729e-02 -0.749871
2019-11-04 22:27:34,273 train 550 2.286649e-02 -0.739627
2019-11-04 22:27:45,117 train 600 2.288832e-02 -0.726450
2019-11-04 22:27:55,621 train 650 2.286855e-02 -0.732070
2019-11-04 22:28:06,090 train 700 2.289504e-02 -0.714808
2019-11-04 22:28:16,855 train 750 2.289024e-02 -0.703618
2019-11-04 22:28:27,833 train 800 2.290618e-02 -0.689766
2019-11-04 22:28:38,608 train 850 2.291929e-02 -0.686158
2019-11-04 22:28:41,775 training loss; R2: 2.292491e-02 -0.680822
2019-11-04 22:28:42,366 valid 000 2.461059e-02 -0.100425
2019-11-04 22:28:53,068 valid 050 2.168080e-02 -0.247430
2019-11-04 22:29:02,505 validation loss; R2: 2.147851e-02 -0.228546
2019-11-04 22:29:02,572 epoch 29 lr 5.000000e-04
2019-11-04 22:29:03,316 train 000 1.968280e-02 -0.312376
2019-11-04 22:29:14,229 train 050 2.317309e-02 -0.511174
2019-11-04 22:29:25,130 train 100 2.311540e-02 -0.756184
2019-11-04 22:29:35,957 train 150 2.305398e-02 -0.700864
2019-11-04 22:29:46,866 train 200 2.284719e-02 -0.633442
2019-11-04 22:29:57,784 train 250 2.283885e-02 -0.594478
2019-11-04 22:30:08,726 train 300 2.281536e-02 -0.580047
2019-11-04 22:30:19,690 train 350 2.281247e-02 -0.555656
2019-11-04 22:30:30,576 train 400 2.284417e-02 -0.569435
2019-11-04 22:30:41,473 train 450 2.282220e-02 -0.562867
2019-11-04 22:30:52,318 train 500 2.280690e-02 -0.550850
2019-11-04 22:31:03,214 train 550 2.284793e-02 -0.543343
2019-11-04 22:31:14,097 train 600 2.282025e-02 -0.529495
2019-11-04 22:31:24,716 train 650 2.281706e-02 -0.521365
2019-11-04 22:31:35,123 train 700 2.286813e-02 -0.515545
2019-11-04 22:31:45,870 train 750 2.289987e-02 -0.511734
2019-11-04 22:31:56,750 train 800 2.291326e-02 -0.510666
2019-11-04 22:32:07,605 train 850 2.288740e-02 -0.502003
2019-11-04 22:32:10,795 training loss; R2: 2.289773e-02 -0.501163
2019-11-04 22:32:11,414 valid 000 2.510489e-02 -0.037462
2019-11-04 22:32:22,159 valid 050 2.398606e-02 -0.146944
2019-11-04 22:32:31,851 validation loss; R2: 2.394338e-02 -0.227638
2019-11-04 22:32:31,918 epoch 30 lr 5.000000e-04
2019-11-04 22:32:32,662 train 000 2.255637e-02 -0.495693
2019-11-04 22:32:43,546 train 050 2.270275e-02 -0.498086
2019-11-04 22:32:54,442 train 100 2.268482e-02 -0.588101
2019-11-04 22:33:05,330 train 150 2.270429e-02 -0.540242
2019-11-04 22:33:16,117 train 200 2.278727e-02 -0.536268
2019-11-04 22:33:26,905 train 250 2.284444e-02 -0.535485
2019-11-04 22:33:37,631 train 300 2.280727e-02 -0.529060
2019-11-04 22:33:48,303 train 350 2.283688e-02 -0.592734
2019-11-04 22:33:59,095 train 400 2.285110e-02 -0.578878
2019-11-04 22:34:09,853 train 450 2.285231e-02 -0.567350
2019-11-04 22:34:20,699 train 500 2.282696e-02 -0.552402
2019-11-04 22:34:31,510 train 550 2.283601e-02 -0.547885
2019-11-04 22:34:42,206 train 600 2.278673e-02 -0.546993
2019-11-04 22:34:52,888 train 650 2.277971e-02 -0.554459
2019-11-04 22:35:03,531 train 700 2.277206e-02 -0.554201
2019-11-04 22:35:14,251 train 750 2.278033e-02 -0.552800
2019-11-04 22:35:24,983 train 800 2.279225e-02 -0.549498
2019-11-04 22:35:35,722 train 850 2.280458e-02 -0.547105
2019-11-04 22:35:38,959 training loss; R2: 2.280781e-02 -0.550569
2019-11-04 22:35:39,564 valid 000 2.370970e-02 -0.083749
2019-11-04 22:35:50,213 valid 050 2.379801e-02 -0.229102
2019-11-04 22:35:59,878 validation loss; R2: 2.373778e-02 -0.240725
2019-11-04 22:35:59,945 epoch 31 lr 5.000000e-04
2019-11-04 22:36:00,660 train 000 2.248953e-02 -0.103209
2019-11-04 22:36:11,665 train 050 2.316398e-02 -0.613727
2019-11-04 22:36:22,411 train 100 2.297562e-02 -0.627580
2019-11-04 22:36:33,138 train 150 2.304310e-02 -0.575825
2019-11-04 22:36:43,815 train 200 2.298572e-02 -0.589635
2019-11-04 22:36:54,562 train 250 2.296838e-02 -0.572227
2019-11-04 22:37:05,255 train 300 2.293780e-02 -0.594952
2019-11-04 22:37:15,989 train 350 2.290441e-02 -0.586721
2019-11-04 22:37:26,803 train 400 2.284199e-02 -0.565694
2019-11-04 22:37:37,628 train 450 2.277064e-02 -0.568221
2019-11-04 22:37:48,376 train 500 2.275095e-02 -0.568637
2019-11-04 22:37:59,107 train 550 2.275444e-02 -0.582589
2019-11-04 22:38:09,824 train 600 2.273268e-02 -0.565264
2019-11-04 22:38:20,549 train 650 2.281357e-02 -0.576508
2019-11-04 22:38:31,173 train 700 2.293182e-02 -0.578080
2019-11-04 22:38:41,963 train 750 2.297319e-02 -0.568890
2019-11-04 22:38:52,599 train 800 2.300869e-02 -0.552589
2019-11-04 22:39:03,293 train 850 2.306818e-02 -0.544393
2019-11-04 22:39:06,528 training loss; R2: 2.307694e-02 -0.542252
2019-11-04 22:39:07,135 valid 000 2.024876e-02 0.041651
2019-11-04 22:39:17,839 valid 050 2.119168e-02 -0.488306
2019-11-04 22:39:27,282 validation loss; R2: 2.127636e-02 -0.461151
2019-11-04 22:39:27,342 epoch 32 lr 5.000000e-04
2019-11-04 22:39:28,076 train 000 2.729597e-02 -0.231393
2019-11-04 22:39:39,044 train 050 2.359080e-02 -0.463127
2019-11-04 22:39:49,939 train 100 2.329452e-02 -0.476534
2019-11-04 22:40:00,792 train 150 2.322895e-02 -0.445074
2019-11-04 22:40:11,546 train 200 2.310156e-02 -0.444213
2019-11-04 22:40:22,319 train 250 2.307176e-02 -0.433332
2019-11-04 22:40:33,154 train 300 2.314965e-02 -0.462559
2019-11-04 22:40:43,949 train 350 2.327873e-02 -0.466008
2019-11-04 22:40:54,808 train 400 2.324734e-02 -0.478124
2019-11-04 22:41:05,673 train 450 2.322302e-02 -0.494916
2019-11-04 22:41:16,540 train 500 2.319066e-02 -0.513141
2019-11-04 22:41:27,290 train 550 2.318945e-02 -0.514501
2019-11-04 22:41:38,042 train 600 2.320140e-02 -0.556204
2019-11-04 22:41:48,770 train 650 2.316260e-02 -0.552680
2019-11-04 22:41:59,541 train 700 2.313734e-02 -0.540516
2019-11-04 22:42:10,286 train 750 2.313955e-02 -0.600670
2019-11-04 22:42:20,958 train 800 2.312513e-02 -0.600580
2019-11-04 22:42:31,746 train 850 2.311548e-02 -0.591326
2019-11-04 22:42:35,003 training loss; R2: 2.309885e-02 -0.588099
2019-11-04 22:42:35,573 valid 000 2.312312e-02 -0.287965
2019-11-04 22:42:46,289 valid 050 2.281403e-02 -0.153152
2019-11-04 22:42:55,821 validation loss; R2: 2.279548e-02 -0.202726
2019-11-04 22:42:55,890 epoch 33 lr 5.000000e-04
2019-11-04 22:42:56,640 train 000 2.402424e-02 -0.036989
2019-11-04 22:43:07,592 train 050 2.323162e-02 -0.444057
2019-11-04 22:43:18,393 train 100 2.283279e-02 -0.517973
2019-11-04 22:43:29,089 train 150 2.284236e-02 -0.493167
2019-11-04 22:43:39,769 train 200 2.281770e-02 -0.550507
2019-11-04 22:43:50,433 train 250 2.279584e-02 -0.550599
2019-11-04 22:44:01,063 train 300 2.284819e-02 -0.558876
2019-11-04 22:44:11,718 train 350 2.284426e-02 -0.568863
2019-11-04 22:44:22,357 train 400 2.284588e-02 -0.727857
2019-11-04 22:44:33,023 train 450 2.281143e-02 -0.715393
2019-11-04 22:44:43,720 train 500 2.274120e-02 -0.697718
2019-11-04 22:44:54,427 train 550 2.271223e-02 -0.706270
2019-11-04 22:45:05,088 train 600 2.271347e-02 -0.705160
2019-11-04 22:45:15,486 train 650 2.269653e-02 -0.674173
2019-11-04 22:45:25,889 train 700 2.272016e-02 -0.705850
2019-11-04 22:45:36,366 train 750 2.275899e-02 -0.684440
2019-11-04 22:45:46,824 train 800 2.276850e-02 -0.668011
2019-11-04 22:45:57,367 train 850 2.275392e-02 -0.651262
2019-11-04 22:46:00,457 training loss; R2: 2.275175e-02 -0.648631
2019-11-04 22:46:01,040 valid 000 1.708711e-02 -2.355312
2019-11-04 22:46:11,615 valid 050 1.851377e-02 -0.463913
2019-11-04 22:46:20,931 validation loss; R2: 1.852982e-02 -0.393608
2019-11-04 22:46:20,998 epoch 34 lr 5.000000e-04
2019-11-04 22:46:21,672 train 000 2.211616e-02 -2.254395
2019-11-04 22:46:32,296 train 050 2.245919e-02 -0.595375
2019-11-04 22:46:42,900 train 100 2.262764e-02 -0.523865
2019-11-04 22:46:53,566 train 150 2.250884e-02 -0.497355
2019-11-04 22:47:04,271 train 200 2.253992e-02 -0.530308
2019-11-04 22:47:14,951 train 250 2.257608e-02 -0.564318
2019-11-04 22:47:25,647 train 300 2.262738e-02 -0.523435
2019-11-04 22:47:36,396 train 350 2.264653e-02 -0.532381
2019-11-04 22:47:47,142 train 400 2.269947e-02 -0.531147
2019-11-04 22:47:57,895 train 450 2.279620e-02 -0.531754
2019-11-04 22:48:08,646 train 500 2.280327e-02 -0.537547
2019-11-04 22:48:19,382 train 550 2.277228e-02 -0.530145
2019-11-04 22:48:30,117 train 600 2.280943e-02 -0.526465
2019-11-04 22:48:40,764 train 650 2.281181e-02 -0.544031
2019-11-04 22:48:51,484 train 700 2.289485e-02 -0.550077
2019-11-04 22:49:02,328 train 750 2.287523e-02 -0.536065
2019-11-04 22:49:13,263 train 800 2.287367e-02 -0.570052
2019-11-04 22:49:24,197 train 850 2.297521e-02 -0.566117
2019-11-04 22:49:27,410 training loss; R2: 2.298953e-02 -0.565561
2019-11-04 22:49:27,997 valid 000 1.870436e-02 -0.230067
2019-11-04 22:49:38,644 valid 050 2.128801e-02 -1.965441
2019-11-04 22:49:48,324 validation loss; R2: 2.153203e-02 -1.222789
2019-11-04 22:49:48,388 epoch 35 lr 5.000000e-04
2019-11-04 22:49:49,105 train 000 2.826802e-02 -0.067982
2019-11-04 22:49:59,817 train 050 2.337406e-02 -0.530657
2019-11-04 22:50:10,608 train 100 2.293364e-02 -0.518540
2019-11-04 22:50:21,410 train 150 2.322490e-02 -0.533512
2019-11-04 22:50:32,134 train 200 2.337636e-02 -0.534172
2019-11-04 22:50:42,865 train 250 2.350304e-02 -0.504944
2019-11-04 22:50:53,665 train 300 2.344940e-02 -0.508658
2019-11-04 22:51:04,526 train 350 2.335258e-02 -0.517285
2019-11-04 22:51:15,414 train 400 2.332156e-02 -0.506918
2019-11-04 22:51:26,070 train 450 2.320483e-02 -0.513846
2019-11-04 22:51:36,927 train 500 2.322513e-02 -0.503451
2019-11-04 22:51:47,690 train 550 2.318194e-02 -0.517010
2019-11-04 22:51:58,564 train 600 2.313696e-02 -0.509957
2019-11-04 22:52:09,244 train 650 2.314918e-02 -0.519073
2019-11-04 22:52:19,929 train 700 2.310385e-02 -0.548414
2019-11-04 22:52:30,722 train 750 2.309055e-02 -0.543381
2019-11-04 22:52:41,434 train 800 2.308253e-02 -0.532551
2019-11-04 22:52:52,135 train 850 2.304779e-02 -0.525285
2019-11-04 22:52:55,404 training loss; R2: 2.303510e-02 -0.526949
2019-11-04 22:52:55,977 valid 000 3.952471e-02 -1.129055
2019-11-04 22:53:06,923 valid 050 3.600691e-02 -1.605909
2019-11-04 22:53:16,567 validation loss; R2: 3.539161e-02 -1.476605
2019-11-04 22:53:16,638 epoch 36 lr 5.000000e-04
2019-11-04 22:53:17,332 train 000 2.572464e-02 -0.098401
2019-11-04 22:53:28,456 train 050 2.306256e-02 -0.380795
2019-11-04 22:53:39,438 train 100 2.297459e-02 -0.424903
2019-11-04 22:53:50,357 train 150 2.267894e-02 -0.584141
2019-11-04 22:54:00,933 train 200 2.265627e-02 -0.558912
2019-11-04 22:54:11,499 train 250 2.268926e-02 -0.563229
2019-11-04 22:54:22,286 train 300 2.279359e-02 -0.551682
2019-11-04 22:54:32,910 train 350 2.299021e-02 -0.532347
2019-11-04 22:54:43,697 train 400 2.300937e-02 -0.537080
2019-11-04 22:54:54,525 train 450 2.296335e-02 -0.531231
2019-11-04 22:55:05,349 train 500 2.299936e-02 -0.538086
2019-11-04 22:55:16,161 train 550 2.299506e-02 -0.551390
2019-11-04 22:55:27,012 train 600 2.305314e-02 -0.541617
2019-11-04 22:55:37,642 train 650 2.302314e-02 -0.529715
2019-11-04 22:55:48,324 train 700 2.301213e-02 -0.533509
2019-11-04 22:55:59,235 train 750 2.300012e-02 -0.557273
2019-11-04 22:56:10,374 train 800 2.299341e-02 -0.553244
2019-11-04 22:56:21,367 train 850 2.296754e-02 -0.557205
2019-11-04 22:56:24,672 training loss; R2: 2.294916e-02 -0.567003
2019-11-04 22:56:25,276 valid 000 2.478001e-02 -0.436408
2019-11-04 22:56:35,979 valid 050 2.400936e-02 -0.251095
2019-11-04 22:56:45,481 validation loss; R2: 2.383081e-02 -0.233461
2019-11-04 22:56:45,544 epoch 37 lr 5.000000e-04
2019-11-04 22:56:46,282 train 000 2.160739e-02 -1.049364
2019-11-04 22:56:57,270 train 050 2.254431e-02 -0.435762
2019-11-04 22:57:08,361 train 100 2.267533e-02 -0.485417
2019-11-04 22:57:19,182 train 150 2.280617e-02 -0.476283
2019-11-04 22:57:29,932 train 200 2.278955e-02 -0.480233
2019-11-04 22:57:40,673 train 250 2.275518e-02 -0.482049
2019-11-04 22:57:51,331 train 300 2.273397e-02 -0.469716
2019-11-04 22:58:01,971 train 350 2.273503e-02 -0.453687
2019-11-04 22:58:12,721 train 400 2.265755e-02 -0.456725
2019-11-04 22:58:23,458 train 450 2.263514e-02 -0.464352
2019-11-04 22:58:34,192 train 500 2.267776e-02 -0.496598
2019-11-04 22:58:44,845 train 550 2.266538e-02 -0.508579
2019-11-04 22:58:55,458 train 600 2.268172e-02 -0.506251
2019-11-04 22:59:06,170 train 650 2.270393e-02 -0.510707
2019-11-04 22:59:16,846 train 700 2.270827e-02 -0.503611
2019-11-04 22:59:27,693 train 750 2.271260e-02 -0.515103
2019-11-04 22:59:38,533 train 800 2.272343e-02 -0.522457
2019-11-04 22:59:49,411 train 850 2.269735e-02 -0.523724
2019-11-04 22:59:52,680 training loss; R2: 2.269192e-02 -0.528280
2019-11-04 22:59:53,299 valid 000 2.096164e-02 -1.365394
2019-11-04 23:00:03,923 valid 050 2.073619e-02 -0.471696
2019-11-04 23:00:13,633 validation loss; R2: 2.070381e-02 -0.513892
2019-11-04 23:00:13,698 epoch 38 lr 5.000000e-04
2019-11-04 23:00:14,402 train 000 2.224274e-02 -0.118483
2019-11-04 23:00:25,204 train 050 2.292878e-02 -0.610053
2019-11-04 23:00:35,936 train 100 2.286425e-02 -0.529941
2019-11-04 23:00:46,621 train 150 2.275894e-02 -0.501241
2019-11-04 23:00:57,338 train 200 2.281537e-02 -0.500840
2019-11-04 23:01:08,039 train 250 2.273100e-02 -0.476608
2019-11-04 23:01:18,765 train 300 2.266753e-02 -0.494432
2019-11-04 23:01:29,489 train 350 2.265904e-02 -0.526575
2019-11-04 23:01:40,250 train 400 2.268667e-02 -0.560212
2019-11-04 23:01:51,029 train 450 2.285574e-02 -0.575691
2019-11-04 23:02:01,790 train 500 2.299978e-02 -0.595356
2019-11-04 23:02:12,552 train 550 2.307163e-02 -0.581100
2019-11-04 23:02:23,322 train 600 2.311303e-02 -0.567858
2019-11-04 23:02:33,974 train 650 2.313476e-02 -0.565556
2019-11-04 23:02:44,645 train 700 2.314773e-02 -0.560132
2019-11-04 23:02:55,508 train 750 2.315901e-02 -0.555967
2019-11-04 23:03:06,373 train 800 2.315070e-02 -0.549530
2019-11-04 23:03:17,114 train 850 2.311944e-02 -0.543329
2019-11-04 23:03:20,278 training loss; R2: 2.311131e-02 -0.538656
2019-11-04 23:03:20,899 valid 000 2.167794e-02 0.016775
2019-11-04 23:03:31,524 valid 050 2.221154e-02 -0.170437
2019-11-04 23:03:41,182 validation loss; R2: 2.212820e-02 -0.173450
2019-11-04 23:03:41,256 epoch 39 lr 5.000000e-04
2019-11-04 23:03:41,958 train 000 2.460313e-02 -0.172026
2019-11-04 23:03:52,971 train 050 2.269536e-02 -0.475312
2019-11-04 23:04:03,878 train 100 2.305590e-02 -0.400219
2019-11-04 23:04:14,750 train 150 2.306465e-02 -0.434865
2019-11-04 23:04:25,575 train 200 2.285018e-02 -0.480020
2019-11-04 23:04:36,430 train 250 2.275856e-02 -0.487574
2019-11-04 23:04:47,250 train 300 2.283160e-02 -0.475995
2019-11-04 23:04:58,009 train 350 2.281548e-02 -0.486107
2019-11-04 23:05:08,784 train 400 2.277744e-02 -0.485109
2019-11-04 23:05:19,580 train 450 2.267115e-02 -0.511077
2019-11-04 23:05:30,393 train 500 2.268647e-02 -0.511334
2019-11-04 23:05:41,236 train 550 2.265996e-02 -0.512203
2019-11-04 23:05:52,045 train 600 2.264970e-02 -0.506175
2019-11-04 23:06:02,587 train 650 2.267401e-02 -0.503588
2019-11-04 23:06:13,130 train 700 2.268927e-02 -0.505060
2019-11-04 23:06:23,879 train 750 2.266094e-02 -0.507812
2019-11-04 23:06:34,638 train 800 2.267783e-02 -0.510426
2019-11-04 23:06:45,384 train 850 2.266909e-02 -0.602629
2019-11-04 23:06:48,554 training loss; R2: 2.267451e-02 -0.598245
2019-11-04 23:06:49,194 valid 000 3.080650e-02 -7.982486
2019-11-04 23:06:59,903 valid 050 3.065180e-02 -2.244423
2019-11-04 23:07:09,756 validation loss; R2: 3.102847e-02 -2.242503
2019-11-04 23:07:09,819 epoch 40 lr 5.000000e-04
2019-11-04 23:07:10,532 train 000 2.400982e-02 -0.817098
2019-11-04 23:07:21,334 train 050 2.267921e-02 -0.721664
2019-11-04 23:07:32,241 train 100 2.246011e-02 -0.589592
2019-11-04 23:07:43,204 train 150 2.265223e-02 -0.611431
2019-11-04 23:07:53,929 train 200 2.252058e-02 -0.597047
2019-11-04 23:08:04,763 train 250 2.247229e-02 -0.572063
2019-11-04 23:08:15,624 train 300 2.241377e-02 -0.551817
2019-11-04 23:08:26,427 train 350 2.241142e-02 -0.544322
2019-11-04 23:08:37,254 train 400 2.246366e-02 -0.607470
2019-11-04 23:08:48,066 train 450 2.248185e-02 -0.626413
2019-11-04 23:08:58,807 train 500 2.259900e-02 -0.617702
2019-11-04 23:09:09,543 train 550 2.279421e-02 -2.240925
2019-11-04 23:09:20,243 train 600 2.291337e-02 -2.081922
2019-11-04 23:09:30,878 train 650 2.300738e-02 -1.964980
2019-11-04 23:09:41,629 train 700 2.304486e-02 -1.856792
2019-11-04 23:09:52,410 train 750 2.309268e-02 -1.765121
2019-11-04 23:10:03,114 train 800 2.312337e-02 -1.687911
2019-11-04 23:10:13,803 train 850 2.315695e-02 -1.614656
2019-11-04 23:10:17,032 training loss; R2: 2.319477e-02 -1.592328
2019-11-04 23:10:17,651 valid 000 2.487032e-02 -0.339396
2019-11-04 23:10:28,184 valid 050 2.526479e-02 -0.515271
2019-11-04 23:10:37,857 validation loss; R2: 2.524184e-02 -0.409142
2019-11-04 23:10:37,929 epoch 41 lr 5.000000e-04
2019-11-04 23:10:38,710 train 000 2.909775e-02 -0.143646
2019-11-04 23:10:49,458 train 050 2.499667e-02 -0.449602
2019-11-04 23:11:00,179 train 100 2.447044e-02 -0.983048
2019-11-04 23:11:10,915 train 150 2.423934e-02 -0.821598
2019-11-04 23:11:21,666 train 200 2.425631e-02 -0.703133
2019-11-04 23:11:32,361 train 250 2.405250e-02 -0.655926
2019-11-04 23:11:43,136 train 300 2.385934e-02 -0.642362
2019-11-04 23:11:53,867 train 350 2.376764e-02 -0.620042
2019-11-04 23:12:04,600 train 400 2.361151e-02 -0.590045
2019-11-04 23:12:15,327 train 450 2.352887e-02 -0.609620
2019-11-04 23:12:26,044 train 500 2.345338e-02 -0.605352
2019-11-04 23:12:36,751 train 550 2.341563e-02 -0.608142
2019-11-04 23:12:47,514 train 600 2.333791e-02 -0.628644
2019-11-04 23:12:58,194 train 650 2.326576e-02 -0.615235
2019-11-04 23:13:08,887 train 700 2.326415e-02 -0.607700
2019-11-04 23:13:19,720 train 750 2.323854e-02 -0.610161
2019-11-04 23:13:30,552 train 800 2.322165e-02 -0.592102
2019-11-04 23:13:41,383 train 850 2.321944e-02 -0.579475
2019-11-04 23:13:44,590 training loss; R2: 2.323133e-02 -0.573839
2019-11-04 23:13:45,164 valid 000 2.495786e-02 -2.814667
2019-11-04 23:13:55,723 valid 050 2.460550e-02 -0.397766
2019-11-04 23:14:05,387 validation loss; R2: 2.442403e-02 -0.431924
2019-11-04 23:14:05,453 epoch 42 lr 5.000000e-04
2019-11-04 23:14:06,159 train 000 2.277897e-02 -0.076126
2019-11-04 23:14:16,976 train 050 2.295313e-02 -0.401030
2019-11-04 23:14:27,752 train 100 2.292974e-02 -0.451374
2019-11-04 23:14:38,603 train 150 2.275646e-02 -0.457269
2019-11-04 23:14:49,350 train 200 2.274655e-02 -0.469211
2019-11-04 23:15:00,008 train 250 2.279789e-02 -0.466360
2019-11-04 23:15:10,745 train 300 2.275527e-02 -0.469737
2019-11-04 23:15:21,477 train 350 2.277093e-02 -0.457969
2019-11-04 23:15:32,249 train 400 2.278308e-02 -0.456536
2019-11-04 23:15:42,976 train 450 2.274464e-02 -0.475154
2019-11-04 23:15:53,740 train 500 2.272271e-02 -0.463749
2019-11-04 23:16:04,551 train 550 2.271662e-02 -0.461491
2019-11-04 23:16:15,245 train 600 2.267982e-02 -0.476044
2019-11-04 23:16:25,830 train 650 2.267517e-02 -0.490554
2019-11-04 23:16:36,432 train 700 2.269091e-02 -0.487995
2019-11-04 23:16:47,245 train 750 2.270015e-02 -0.490895
2019-11-04 23:16:57,861 train 800 2.269548e-02 -0.492692
2019-11-04 23:17:08,529 train 850 2.267727e-02 -0.489289
2019-11-04 23:17:11,788 training loss; R2: 2.267198e-02 -0.486457
2019-11-04 23:17:12,362 valid 000 2.402561e-02 -0.167729
2019-11-04 23:17:22,957 valid 050 2.476797e-02 -0.468211
2019-11-04 23:17:32,608 validation loss; R2: 2.474134e-02 -0.477753
2019-11-04 23:17:32,677 epoch 43 lr 5.000000e-04
2019-11-04 23:17:33,442 train 000 1.963159e-02 -0.076202
2019-11-04 23:17:44,264 train 050 2.221972e-02 -0.577176
2019-11-04 23:17:55,100 train 100 2.265234e-02 -0.506655
2019-11-04 23:18:05,880 train 150 2.273336e-02 -0.495994
2019-11-04 23:18:16,633 train 200 2.254761e-02 -0.523992
2019-11-04 23:18:27,543 train 250 2.257604e-02 -0.531399
2019-11-04 23:18:38,266 train 300 2.253923e-02 -0.547047
2019-11-04 23:18:48,938 train 350 2.251240e-02 -0.552212
2019-11-04 23:18:59,808 train 400 2.250097e-02 -0.573568
2019-11-04 23:19:10,568 train 450 2.248855e-02 -0.563208
2019-11-04 23:19:21,256 train 500 2.244162e-02 -0.876492
2019-11-04 23:19:31,954 train 550 2.245994e-02 -0.840373
2019-11-04 23:19:42,595 train 600 2.249912e-02 -0.833415
2019-11-04 23:19:53,135 train 650 2.251667e-02 -0.804272
2019-11-04 23:20:03,740 train 700 2.253001e-02 -0.781109
2019-11-04 23:20:14,295 train 750 2.254820e-02 -0.775661
2019-11-04 23:20:24,941 train 800 2.254452e-02 -0.751325
2019-11-04 23:20:35,626 train 850 2.254877e-02 -0.734460
2019-11-04 23:20:38,775 training loss; R2: 2.253891e-02 -0.725888
2019-11-04 23:20:39,399 valid 000 3.012209e-02 -0.251223
2019-11-04 23:20:50,020 valid 050 2.992343e-02 -0.253464
2019-11-04 23:20:59,414 validation loss; R2: 2.944114e-02 -0.246069
2019-11-04 23:20:59,492 epoch 44 lr 5.000000e-04
2019-11-04 23:21:00,222 train 000 2.456369e-02 -0.122623
2019-11-04 23:21:10,987 train 050 2.293409e-02 -3.258605
2019-11-04 23:21:21,727 train 100 2.284583e-02 -1.928332
2019-11-04 23:21:32,479 train 150 2.265494e-02 -1.472260
2019-11-04 23:21:43,224 train 200 2.296747e-02 -1.224022
2019-11-04 23:21:53,910 train 250 2.305627e-02 -1.113598
2019-11-04 23:22:04,615 train 300 2.303326e-02 -1.009854
2019-11-04 23:22:15,358 train 350 2.300313e-02 -0.930492
2019-11-04 23:22:26,062 train 400 2.297974e-02 -0.876408
2019-11-04 23:22:36,789 train 450 2.295535e-02 -0.844729
2019-11-04 23:22:47,544 train 500 2.294907e-02 -0.803234
2019-11-04 23:22:58,298 train 550 2.293878e-02 -0.791724
2019-11-04 23:23:09,030 train 600 2.290135e-02 -0.797711
2019-11-04 23:23:19,568 train 650 2.297369e-02 -0.777834
2019-11-04 23:23:30,078 train 700 2.297786e-02 -0.746113
2019-11-04 23:23:40,799 train 750 2.297249e-02 -0.736985
2019-11-04 23:23:51,533 train 800 2.293773e-02 -0.733866
2019-11-04 23:24:02,259 train 850 2.292214e-02 -0.715175
2019-11-04 23:24:05,420 training loss; R2: 2.291466e-02 -0.716308
2019-11-04 23:24:06,061 valid 000 2.617398e-02 -0.078692
2019-11-04 23:24:16,547 valid 050 2.402421e-02 -0.374922
2019-11-04 23:24:26,218 validation loss; R2: 2.409409e-02 -0.297490
2019-11-04 23:24:26,285 epoch 45 lr 5.000000e-04
2019-11-04 23:24:26,981 train 000 2.258876e-02 -0.295584
2019-11-04 23:24:37,736 train 050 2.293126e-02 -0.574001
2019-11-04 23:24:48,379 train 100 2.261981e-02 -0.556192
2019-11-04 23:24:59,088 train 150 2.242148e-02 -0.562047
2019-11-04 23:25:09,786 train 200 2.231600e-02 -3.179565
2019-11-04 23:25:20,465 train 250 2.234457e-02 -2.628951
2019-11-04 23:25:31,215 train 300 2.242481e-02 -2.266068
2019-11-04 23:25:41,919 train 350 2.240246e-02 -2.024554
2019-11-04 23:25:52,564 train 400 2.247623e-02 -1.865209
2019-11-04 23:26:03,173 train 450 2.248182e-02 -1.713180
2019-11-04 23:26:13,876 train 500 2.245629e-02 -1.596689
2019-11-04 23:26:24,555 train 550 2.249301e-02 -1.500083
2019-11-04 23:26:35,213 train 600 2.256571e-02 -1.430451
2019-11-04 23:26:46,120 train 650 2.264835e-02 -1.361332
2019-11-04 23:26:56,897 train 700 2.267178e-02 -1.303651
2019-11-04 23:27:07,619 train 750 2.268472e-02 -1.243535
2019-11-04 23:27:18,298 train 800 2.265971e-02 -1.189873
2019-11-04 23:27:29,098 train 850 2.266867e-02 -1.145482
2019-11-04 23:27:32,313 training loss; R2: 2.269091e-02 -1.133580
2019-11-04 23:27:32,922 valid 000 2.172091e-02 -0.150400
2019-11-04 23:27:43,586 valid 050 2.349676e-02 -0.146098
2019-11-04 23:27:53,011 validation loss; R2: 2.349074e-02 -0.142072
2019-11-04 23:27:53,080 epoch 46 lr 5.000000e-04
2019-11-04 23:27:53,812 train 000 2.097067e-02 -0.991186
2019-11-04 23:28:04,732 train 050 2.197103e-02 -0.619921
2019-11-04 23:28:15,628 train 100 2.244849e-02 -0.524593
2019-11-04 23:28:26,490 train 150 2.254771e-02 -0.504962
2019-11-04 23:28:37,420 train 200 2.257357e-02 -0.487115
2019-11-04 23:28:48,131 train 250 2.253074e-02 -0.503432
2019-11-04 23:28:58,766 train 300 2.249585e-02 -0.526249
2019-11-04 23:29:09,411 train 350 2.247909e-02 -0.528905
2019-11-04 23:29:20,032 train 400 2.253474e-02 -0.538632
2019-11-04 23:29:30,618 train 450 2.261817e-02 -0.527885
2019-11-04 23:29:41,257 train 500 2.260018e-02 -0.522634
2019-11-04 23:29:51,857 train 550 2.256503e-02 -0.511986
2019-11-04 23:30:02,430 train 600 2.255939e-02 -0.514430
2019-11-04 23:30:12,951 train 650 2.253658e-02 -0.522766
2019-11-04 23:30:23,408 train 700 2.255949e-02 -0.530495
2019-11-04 23:30:33,829 train 750 2.254232e-02 -0.523820
2019-11-04 23:30:44,360 train 800 2.268392e-02 -0.519742
2019-11-04 23:30:54,942 train 850 2.279563e-02 -0.524112
2019-11-04 23:30:58,064 training loss; R2: 2.281480e-02 -0.521739
2019-11-04 23:30:58,668 valid 000 2.300935e-02 -0.751525
2019-11-04 23:31:09,200 valid 050 2.539342e-02 -0.561790
2019-11-04 23:31:18,525 validation loss; R2: 2.562614e-02 -0.575882
2019-11-04 23:31:18,594 epoch 47 lr 5.000000e-04
2019-11-04 23:31:19,305 train 000 2.351702e-02 -0.260960
2019-11-04 23:31:30,047 train 050 2.345820e-02 -0.459111
2019-11-04 23:31:40,810 train 100 2.343670e-02 -0.445566
2019-11-04 23:31:51,513 train 150 2.319065e-02 -0.471382
2019-11-04 23:32:02,222 train 200 2.304619e-02 -0.481249
2019-11-04 23:32:12,964 train 250 2.302571e-02 -0.492088
2019-11-04 23:32:23,738 train 300 2.300024e-02 -0.514938
2019-11-04 23:32:34,467 train 350 2.284464e-02 -0.516664
2019-11-04 23:32:45,177 train 400 2.286666e-02 -0.531736
2019-11-04 23:32:55,885 train 450 2.280224e-02 -0.539225
2019-11-04 23:33:06,605 train 500 2.276472e-02 -0.551233
2019-11-04 23:33:17,325 train 550 2.271156e-02 -0.547529
2019-11-04 23:33:28,036 train 600 2.272246e-02 -0.534300
2019-11-04 23:33:38,706 train 650 2.272422e-02 -0.527564
2019-11-04 23:33:49,235 train 700 2.273333e-02 -0.528747
2019-11-04 23:33:59,927 train 750 2.276730e-02 -0.818041
2019-11-04 23:34:10,592 train 800 2.270860e-02 -0.817707
2019-11-04 23:34:21,348 train 850 2.272509e-02 -0.803659
2019-11-04 23:34:24,561 training loss; R2: 2.273172e-02 -0.798142
2019-11-04 23:34:25,181 valid 000 1.977523e-02 -0.201113
2019-11-04 23:34:36,078 valid 050 1.958149e-02 -0.179465
2019-11-04 23:34:45,808 validation loss; R2: 1.942920e-02 -0.230222
2019-11-04 23:34:45,877 epoch 48 lr 5.000000e-04
2019-11-04 23:34:46,622 train 000 2.348354e-02 -0.173312
2019-11-04 23:34:57,623 train 050 2.261741e-02 -0.527856
2019-11-04 23:35:08,450 train 100 2.269830e-02 -0.445268
2019-11-04 23:35:19,309 train 150 2.274611e-02 -1.128925
2019-11-04 23:35:30,205 train 200 2.261453e-02 -0.945658
2019-11-04 23:35:40,964 train 250 2.264194e-02 -0.854722
2019-11-04 23:35:51,720 train 300 2.251838e-02 -0.818086
2019-11-04 23:36:02,473 train 350 2.257109e-02 -0.775035
2019-11-04 23:36:13,227 train 400 2.261206e-02 -0.755854
2019-11-04 23:36:24,053 train 450 2.260886e-02 -0.718241
2019-11-04 23:36:34,910 train 500 2.262369e-02 -0.712878
2019-11-04 23:36:45,717 train 550 2.261421e-02 -0.749058
2019-11-04 23:36:56,569 train 600 2.260864e-02 -0.732867
2019-11-04 23:37:07,298 train 650 2.260006e-02 -0.721348
2019-11-04 23:37:17,913 train 700 2.259347e-02 -0.713196
2019-11-04 23:37:28,695 train 750 2.259962e-02 -0.692680
2019-11-04 23:37:39,480 train 800 2.258110e-02 -0.688192
2019-11-04 23:37:50,286 train 850 2.257194e-02 -0.699578
2019-11-04 23:37:53,556 training loss; R2: 2.256604e-02 -0.692869
2019-11-04 23:37:54,202 valid 000 2.519912e-02 -0.268198
2019-11-04 23:38:04,928 valid 050 2.404956e-02 -0.241679
2019-11-04 23:38:14,523 validation loss; R2: 2.399723e-02 -0.245916
2019-11-04 23:38:14,589 epoch 49 lr 5.000000e-04
2019-11-04 23:38:15,353 train 000 2.283187e-02 -0.254005
2019-11-04 23:38:26,273 train 050 2.195168e-02 -0.440199
2019-11-04 23:38:37,072 train 100 2.237240e-02 -0.487934
2019-11-04 23:38:48,029 train 150 2.252235e-02 -0.521617
2019-11-04 23:38:58,832 train 200 2.246815e-02 -0.543320
2019-11-04 23:39:09,701 train 250 2.251870e-02 -0.541130
2019-11-04 23:39:20,596 train 300 2.248912e-02 -0.549699
2019-11-04 23:39:31,388 train 350 2.245031e-02 -0.539871
2019-11-04 23:39:42,184 train 400 2.240658e-02 -0.536796
2019-11-04 23:39:53,091 train 450 2.241097e-02 -0.527307
2019-11-04 23:40:03,875 train 500 2.247584e-02 -0.531780
2019-11-04 23:40:14,827 train 550 2.250216e-02 -0.526502
2019-11-04 23:40:25,743 train 600 2.250106e-02 -0.520232
2019-11-04 23:40:36,356 train 650 2.250249e-02 -0.514065
2019-11-04 23:40:46,824 train 700 2.251388e-02 -0.516618
2019-11-04 23:40:57,317 train 750 2.251943e-02 -0.516500
2019-11-04 23:41:07,935 train 800 2.250440e-02 -0.525491
2019-11-04 23:41:18,688 train 850 2.249541e-02 -0.538070
2019-11-04 23:41:21,929 training loss; R2: 2.251718e-02 -0.538295
2019-11-04 23:41:22,541 valid 000 2.175427e-02 -0.009589
2019-11-04 23:41:33,133 valid 050 2.196126e-02 -0.146535
2019-11-04 23:41:42,579 validation loss; R2: 2.217391e-02 -0.140104
2019-11-04 23:41:42,647 epoch 50 lr 5.000000e-04
2019-11-04 23:41:43,347 train 000 2.513011e-02 -0.115603
2019-11-04 23:41:54,218 train 050 2.245147e-02 -0.417625
2019-11-04 23:42:04,977 train 100 2.231622e-02 -0.462258
2019-11-04 23:42:15,747 train 150 2.227639e-02 -0.450955
2019-11-04 23:42:26,549 train 200 2.245284e-02 -0.439520
2019-11-04 23:42:37,327 train 250 2.240937e-02 -0.443478
2019-11-04 23:42:48,069 train 300 2.242252e-02 -0.463533
2019-11-04 23:42:58,826 train 350 2.239880e-02 -0.479049
2019-11-04 23:43:09,602 train 400 2.240538e-02 -0.481729
2019-11-04 23:43:20,375 train 450 2.240215e-02 -0.476648
2019-11-04 23:43:31,143 train 500 2.239629e-02 -0.486719
2019-11-04 23:43:41,901 train 550 2.238979e-02 -0.497041
2019-11-04 23:43:52,668 train 600 2.236942e-02 -0.495422
2019-11-04 23:44:03,376 train 650 2.235229e-02 -0.504783
2019-11-04 23:44:13,918 train 700 2.236891e-02 -0.509264
2019-11-04 23:44:24,611 train 750 2.238237e-02 -0.522642
2019-11-04 23:44:35,408 train 800 2.236172e-02 -0.535959
2019-11-04 23:44:46,242 train 850 2.237267e-02 -0.529531
2019-11-04 23:44:49,428 training loss; R2: 2.237564e-02 -0.526816
2019-11-04 23:44:50,052 valid 000 2.829179e-02 -0.222093
2019-11-04 23:45:00,714 valid 050 2.856397e-02 -0.239734
2019-11-04 23:45:10,239 validation loss; R2: 2.854682e-02 -0.267030
2019-11-04 23:45:10,314 epoch 51 lr 5.000000e-04
2019-11-04 23:45:11,085 train 000 2.123144e-02 -1.482411
2019-11-04 23:45:21,911 train 050 2.243718e-02 -0.397242
2019-11-04 23:45:32,717 train 100 2.243002e-02 -0.415829
2019-11-04 23:45:43,467 train 150 2.229797e-02 -0.441413
2019-11-04 23:45:54,240 train 200 2.242236e-02 -0.512942
2019-11-04 23:46:05,026 train 250 2.250137e-02 -0.545514
2019-11-04 23:46:15,826 train 300 2.254418e-02 -0.592997
2019-11-04 23:46:26,648 train 350 2.258212e-02 -0.574688
2019-11-04 23:46:37,475 train 400 2.256979e-02 -0.604012
2019-11-04 23:46:48,310 train 450 2.253687e-02 -0.597829
2019-11-04 23:46:59,145 train 500 2.259695e-02 -0.591846
2019-11-04 23:47:10,026 train 550 2.266772e-02 -0.580107
2019-11-04 23:47:20,845 train 600 2.266571e-02 -0.574640
2019-11-04 23:47:31,628 train 650 2.263729e-02 -0.566472
2019-11-04 23:47:42,188 train 700 2.269231e-02 -0.563241
2019-11-04 23:47:52,815 train 750 2.267153e-02 -0.551161
2019-11-04 23:48:03,652 train 800 2.267241e-02 -0.575999
2019-11-04 23:48:14,499 train 850 2.271890e-02 -0.567488
2019-11-04 23:48:17,703 training loss; R2: 2.272450e-02 -0.563543
2019-11-04 23:48:18,300 valid 000 2.516965e-02 -0.271428
2019-11-04 23:48:28,937 valid 050 2.555531e-02 -0.263374
2019-11-04 23:48:38,611 validation loss; R2: 2.548461e-02 -0.235305
2019-11-04 23:48:38,679 epoch 52 lr 5.000000e-04
2019-11-04 23:48:39,457 train 000 2.506233e-02 -0.116998
2019-11-04 23:48:50,169 train 050 2.379883e-02 -0.339578
2019-11-04 23:49:01,053 train 100 2.327696e-02 -0.403259
2019-11-04 23:49:11,758 train 150 2.291945e-02 -0.391909
2019-11-04 23:49:22,476 train 200 2.293502e-02 -0.418352
2019-11-04 23:49:33,347 train 250 2.292501e-02 -0.420625
2019-11-04 23:49:43,994 train 300 2.288936e-02 -0.433525
2019-11-04 23:49:54,856 train 350 2.280662e-02 -0.435417
2019-11-04 23:50:05,638 train 400 2.276368e-02 -0.441962
2019-11-04 23:50:16,457 train 450 2.278197e-02 -0.449212
2019-11-04 23:50:27,185 train 500 2.275764e-02 -0.468215
2019-11-04 23:50:38,104 train 550 2.277011e-02 -2.601500
2019-11-04 23:50:48,896 train 600 2.271351e-02 -2.428868
2019-11-04 23:50:59,650 train 650 2.277095e-02 -2.282347
2019-11-04 23:51:10,159 train 700 2.275059e-02 -2.159311
2019-11-04 23:51:20,899 train 750 2.275656e-02 -2.101876
2019-11-04 23:51:31,666 train 800 2.282468e-02 -2.007729
2019-11-04 23:51:42,440 train 850 2.290184e-02 -1.925249
2019-11-04 23:51:45,622 training loss; R2: 2.291691e-02 -1.901495
2019-11-04 23:51:46,220 valid 000 2.788237e-02 -0.016009
2019-11-04 23:51:56,968 valid 050 2.538492e-02 -0.248432
2019-11-04 23:52:06,444 validation loss; R2: 2.546409e-02 -0.235812
2019-11-04 23:52:06,511 epoch 53 lr 5.000000e-04
2019-11-04 23:52:07,239 train 000 2.418138e-02 -0.043696
2019-11-04 23:52:18,084 train 050 2.327139e-02 -0.459269
2019-11-04 23:52:28,952 train 100 2.320029e-02 -0.569528
2019-11-04 23:52:39,756 train 150 2.308020e-02 -0.527507
2019-11-04 23:52:50,565 train 200 2.294406e-02 -0.494217
2019-11-04 23:53:01,056 train 250 2.297736e-02 -0.559712
2019-11-04 23:53:11,585 train 300 2.286391e-02 -0.554889
2019-11-04 23:53:22,135 train 350 2.280445e-02 -0.538719
2019-11-04 23:53:32,695 train 400 2.281558e-02 -0.552424
2019-11-04 23:53:43,252 train 450 2.283966e-02 -0.543396
2019-11-04 23:53:53,950 train 500 2.281341e-02 -0.557953
2019-11-04 23:54:04,650 train 550 2.277283e-02 -0.549037
2019-11-04 23:54:15,355 train 600 2.277860e-02 -0.538047
2019-11-04 23:54:26,082 train 650 2.279321e-02 -0.532894
2019-11-04 23:54:36,616 train 700 2.281456e-02 -0.532726
2019-11-04 23:54:47,150 train 750 2.279401e-02 -0.534348
2019-11-04 23:54:58,084 train 800 2.275696e-02 -0.538639
2019-11-04 23:55:08,858 train 850 2.277740e-02 -0.534210
2019-11-04 23:55:12,107 training loss; R2: 2.277689e-02 -0.531804
2019-11-04 23:55:12,708 valid 000 2.078919e-02 -1.670743
2019-11-04 23:55:23,390 valid 050 2.133284e-02 -0.595938
2019-11-04 23:55:32,820 validation loss; R2: 2.124864e-02 -0.726699
2019-11-04 23:55:32,887 epoch 54 lr 5.000000e-04
2019-11-04 23:55:33,589 train 000 2.326510e-02 -0.093651
2019-11-04 23:55:44,389 train 050 2.273598e-02 -0.471114
2019-11-04 23:55:55,286 train 100 2.284739e-02 -0.552948
2019-11-04 23:56:06,132 train 150 2.262426e-02 -0.528852
2019-11-04 23:56:16,987 train 200 2.258854e-02 -0.494428
2019-11-04 23:56:27,604 train 250 2.260385e-02 -0.509024
2019-11-04 23:56:38,001 train 300 2.277068e-02 -0.520875
2019-11-04 23:56:48,463 train 350 2.280536e-02 -0.517885
2019-11-04 23:56:59,085 train 400 2.279555e-02 -3.797781
2019-11-04 23:57:09,771 train 450 2.278461e-02 -3.439867
2019-11-04 23:57:20,441 train 500 2.277885e-02 -3.149333
2019-11-04 23:57:31,111 train 550 2.273132e-02 -2.906297
2019-11-04 23:57:41,793 train 600 2.270908e-02 -2.703111
2019-11-04 23:57:52,532 train 650 2.270649e-02 -2.544270
2019-11-04 23:58:03,198 train 700 2.272668e-02 -2.392705
2019-11-04 23:58:13,825 train 750 2.272252e-02 -2.270733
2019-11-04 23:58:24,681 train 800 2.274568e-02 -2.162228
2019-11-04 23:58:35,511 train 850 2.277707e-02 -2.070965
2019-11-04 23:58:38,717 training loss; R2: 2.276993e-02 -2.044194
2019-11-04 23:58:39,315 valid 000 2.426287e-02 -0.036918
2019-11-04 23:58:49,913 valid 050 2.350214e-02 -0.375582
2019-11-04 23:58:59,645 validation loss; R2: 2.323851e-02 -0.304376
2019-11-04 23:58:59,701 epoch 55 lr 5.000000e-04
2019-11-04 23:59:00,465 train 000 2.157123e-02 -0.543423
2019-11-04 23:59:11,240 train 050 2.275708e-02 -0.485524
2019-11-04 23:59:22,068 train 100 2.255725e-02 -1.608676
2019-11-04 23:59:32,764 train 150 2.260336e-02 -1.205646
2019-11-04 23:59:43,622 train 200 2.288588e-02 -1.036988
2019-11-04 23:59:54,332 train 250 2.283991e-02 -0.953238
2019-11-05 00:00:05,085 train 300 2.277358e-02 -0.896627
2019-11-05 00:00:15,753 train 350 2.283122e-02 -0.853372
2019-11-05 00:00:26,534 train 400 2.280612e-02 -0.788308
2019-11-05 00:00:37,347 train 450 2.273597e-02 -0.750224
2019-11-05 00:00:48,173 train 500 2.266841e-02 -0.722300
2019-11-05 00:00:58,973 train 550 2.268331e-02 -0.714758
2019-11-05 00:01:09,836 train 600 2.269835e-02 -0.733997
2019-11-05 00:01:20,553 train 650 2.269394e-02 -0.728039
2019-11-05 00:01:31,386 train 700 2.264514e-02 -0.748977
2019-11-05 00:01:42,021 train 750 2.262318e-02 -0.737662
2019-11-05 00:01:52,810 train 800 2.263209e-02 -0.719820
2019-11-05 00:02:03,674 train 850 2.265511e-02 -0.696727
2019-11-05 00:02:06,878 training loss; R2: 2.265061e-02 -0.695496
2019-11-05 00:02:07,499 valid 000 2.779524e-02 -0.121034
2019-11-05 00:02:18,543 valid 050 2.422989e-02 -0.231023
2019-11-05 00:02:28,211 validation loss; R2: 2.419427e-02 -0.340051
2019-11-05 00:02:28,282 epoch 56 lr 5.000000e-04
2019-11-05 00:02:29,004 train 000 1.878502e-02 -2.193863
2019-11-05 00:02:39,820 train 050 2.266336e-02 -0.887728
2019-11-05 00:02:50,601 train 100 2.267532e-02 -0.782432
2019-11-05 00:03:01,316 train 150 2.258754e-02 -0.693973
2019-11-05 00:03:12,111 train 200 2.279277e-02 -0.656540
2019-11-05 00:03:22,892 train 250 2.274181e-02 -1.750105
2019-11-05 00:03:33,623 train 300 2.262408e-02 -1.575684
2019-11-05 00:03:44,350 train 350 2.263164e-02 -1.416414
2019-11-05 00:03:54,909 train 400 2.267804e-02 -1.309476
2019-11-05 00:04:05,686 train 450 2.267790e-02 -1.225832
2019-11-05 00:04:16,351 train 500 2.264234e-02 -1.148966
2019-11-05 00:04:27,112 train 550 2.258970e-02 -1.087675
2019-11-05 00:04:37,865 train 600 2.263660e-02 -1.024801
2019-11-05 00:04:48,529 train 650 2.265588e-02 -1.030215
2019-11-05 00:04:59,076 train 700 2.261946e-02 -0.982632
2019-11-05 00:05:09,663 train 750 2.262125e-02 -0.959407
2019-11-05 00:05:20,416 train 800 2.262173e-02 -0.949332
2019-11-05 00:05:31,083 train 850 2.259984e-02 -0.933045
2019-11-05 00:05:34,232 training loss; R2: 2.260796e-02 -0.921552
2019-11-05 00:05:34,824 valid 000 2.311809e-02 -0.198367
2019-11-05 00:05:45,659 valid 050 2.074506e-02 -0.263673
2019-11-05 00:05:55,239 validation loss; R2: 2.079365e-02 -2.106358
2019-11-05 00:05:55,306 epoch 57 lr 5.000000e-04
2019-11-05 00:05:56,081 train 000 2.051945e-02 -3.494174
2019-11-05 00:06:07,009 train 050 2.267305e-02 -0.480435
2019-11-05 00:06:17,816 train 100 2.253505e-02 -0.570621
2019-11-05 00:06:28,654 train 150 2.252694e-02 -0.550963
2019-11-05 00:06:39,484 train 200 2.264567e-02 -0.509488
2019-11-05 00:06:50,453 train 250 2.261696e-02 -0.491773
2019-11-05 00:07:01,332 train 300 2.263063e-02 -0.486040
2019-11-05 00:07:12,194 train 350 2.264805e-02 -0.492278
2019-11-05 00:07:22,926 train 400 2.265099e-02 -0.485054
2019-11-05 00:07:33,718 train 450 2.263825e-02 -0.503663
2019-11-05 00:07:44,481 train 500 2.265126e-02 -0.491036
2019-11-05 00:07:55,097 train 550 2.261578e-02 -0.478444
2019-11-05 00:08:05,912 train 600 2.259247e-02 -0.566939
2019-11-05 00:08:16,647 train 650 2.257363e-02 -0.556726
2019-11-05 00:08:27,324 train 700 2.257854e-02 -0.545179
2019-11-05 00:08:38,020 train 750 2.257358e-02 -0.538952
2019-11-05 00:08:48,797 train 800 2.259489e-02 -0.532025
2019-11-05 00:08:59,594 train 850 2.261130e-02 -0.543830
2019-11-05 00:09:03,050 training loss; R2: 2.260000e-02 -0.542656
2019-11-05 00:09:03,609 valid 000 2.383179e-02 0.031215
2019-11-05 00:09:14,422 valid 050 2.539505e-02 -0.177339
2019-11-05 00:09:23,822 validation loss; R2: 2.543547e-02 -0.223077
2019-11-05 00:09:23,888 epoch 58 lr 5.000000e-04
2019-11-05 00:09:24,590 train 000 2.237234e-02 -0.716908
2019-11-05 00:09:35,473 train 050 2.239750e-02 -0.509728
2019-11-05 00:09:46,351 train 100 2.267406e-02 -0.501663
2019-11-05 00:09:57,152 train 150 2.274293e-02 -0.455341
2019-11-05 00:10:07,929 train 200 2.270873e-02 -0.435738
2019-11-05 00:10:18,707 train 250 2.270473e-02 -0.439739
2019-11-05 00:10:29,479 train 300 2.262830e-02 -0.436543
2019-11-05 00:10:40,244 train 350 2.257777e-02 -0.459186
2019-11-05 00:10:50,901 train 400 2.255676e-02 -0.453786
2019-11-05 00:11:01,732 train 450 2.260473e-02 -0.466790
2019-11-05 00:11:12,416 train 500 2.255580e-02 -0.467713
2019-11-05 00:11:23,228 train 550 2.254215e-02 -0.475606
2019-11-05 00:11:33,970 train 600 2.251228e-02 -0.501297
2019-11-05 00:11:44,727 train 650 2.251637e-02 -0.512258
2019-11-05 00:11:55,345 train 700 2.252145e-02 -0.509435
2019-11-05 00:12:06,007 train 750 2.255046e-02 -0.513118
2019-11-05 00:12:16,916 train 800 2.256313e-02 -0.516199
2019-11-05 00:12:27,747 train 850 2.258753e-02 -0.520059
2019-11-05 00:12:30,968 training loss; R2: 2.259655e-02 -0.515999
2019-11-05 00:12:31,527 valid 000 2.549720e-02 -0.381853
2019-11-05 00:12:42,174 valid 050 2.827588e-02 -1.145788
2019-11-05 00:12:51,688 validation loss; R2: 2.839891e-02 -1.117914
2019-11-05 00:12:51,756 epoch 59 lr 5.000000e-04
2019-11-05 00:12:52,456 train 000 2.427718e-02 -0.578564
2019-11-05 00:13:03,283 train 050 2.255979e-02 -0.348531
2019-11-05 00:13:14,109 train 100 2.264047e-02 -0.451588
2019-11-05 00:13:24,957 train 150 2.260618e-02 -0.434255
2019-11-05 00:13:35,815 train 200 2.268722e-02 -0.439597
2019-11-05 00:13:46,620 train 250 2.269729e-02 -0.471556
2019-11-05 00:13:57,367 train 300 2.264733e-02 -0.455256
2019-11-05 00:14:08,226 train 350 2.262194e-02 -0.457463
2019-11-05 00:14:19,158 train 400 2.255484e-02 -0.468764
2019-11-05 00:14:29,985 train 450 2.251077e-02 -0.493038
2019-11-05 00:14:40,739 train 500 2.251345e-02 -0.502885
2019-11-05 00:14:51,537 train 550 2.251615e-02 -0.500081
2019-11-05 00:15:02,393 train 600 2.250441e-02 -0.496205
2019-11-05 00:15:13,262 train 650 2.252184e-02 -0.585501
2019-11-05 00:15:24,135 train 700 2.254928e-02 -0.580030
2019-11-05 00:15:34,961 train 750 2.251802e-02 -0.623522
2019-11-05 00:15:45,849 train 800 2.250137e-02 -0.628508
2019-11-05 00:15:56,912 train 850 2.248082e-02 -0.627511
2019-11-05 00:16:00,119 training loss; R2: 2.248769e-02 -7.328972
2019-11-05 00:16:00,676 valid 000 1.738493e-02 0.033753
2019-11-05 00:16:11,490 valid 050 1.814106e-02 -0.149423
2019-11-05 00:16:20,990 validation loss; R2: 1.820452e-02 -0.163697
2019-11-05 00:16:21,062 epoch 60 lr 5.000000e-04
2019-11-05 00:16:21,801 train 000 2.273782e-02 -0.240896
2019-11-05 00:16:32,707 train 050 2.264093e-02 -0.529481
2019-11-05 00:16:43,619 train 100 2.250573e-02 -0.496393
2019-11-05 00:16:54,521 train 150 2.247142e-02 -0.530381
2019-11-05 00:17:05,383 train 200 2.243399e-02 -0.545010
2019-11-05 00:17:16,206 train 250 2.243436e-02 -0.527647
2019-11-05 00:17:26,998 train 300 2.248684e-02 -0.493936
2019-11-05 00:17:37,787 train 350 2.252494e-02 -0.546575
2019-11-05 00:17:48,599 train 400 2.254600e-02 -0.552535
2019-11-05 00:17:59,396 train 450 2.252531e-02 -0.527737
2019-11-05 00:18:10,219 train 500 2.250429e-02 -0.544295
2019-11-05 00:18:21,069 train 550 2.250547e-02 -0.550904
2019-11-05 00:18:31,933 train 600 2.251326e-02 -0.548032
2019-11-05 00:18:42,625 train 650 2.251185e-02 -0.567432
2019-11-05 00:18:53,038 train 700 2.253067e-02 -0.568164
2019-11-05 00:19:03,564 train 750 2.249656e-02 -0.562879
2019-11-05 00:19:14,173 train 800 2.248951e-02 -0.565155
2019-11-05 00:19:24,882 train 850 2.248486e-02 -0.561217
2019-11-05 00:19:28,095 training loss; R2: 2.249534e-02 -0.559004
2019-11-05 00:19:28,685 valid 000 5.839173e-02 -8.084291
2019-11-05 00:19:39,196 valid 050 5.867215e-02 -12.385428
2019-11-05 00:19:48,513 validation loss; R2: 5.888383e-02 -12.472473
2019-11-05 00:19:48,588 epoch 61 lr 5.000000e-04
2019-11-05 00:19:49,274 train 000 2.333979e-02 -0.003746
2019-11-05 00:20:00,092 train 050 2.381778e-02 -0.527846
2019-11-05 00:20:10,853 train 100 2.352876e-02 -0.480639
2019-11-05 00:20:21,623 train 150 2.317167e-02 -0.486079
2019-11-05 00:20:32,359 train 200 2.297717e-02 -0.510061
2019-11-05 00:20:43,071 train 250 2.286939e-02 -0.542426
2019-11-05 00:20:53,784 train 300 2.283136e-02 -0.516794
2019-11-05 00:21:04,537 train 350 2.277833e-02 -0.556076
2019-11-05 00:21:15,246 train 400 2.272908e-02 -0.556279
2019-11-05 00:21:25,989 train 450 2.264516e-02 -0.538293
2019-11-05 00:21:36,696 train 500 2.257361e-02 -0.542431
2019-11-05 00:21:47,500 train 550 2.255903e-02 -0.541375
2019-11-05 00:21:58,216 train 600 2.253302e-02 -0.535154
2019-11-05 00:22:08,949 train 650 2.259619e-02 -0.538078
2019-11-05 00:22:19,658 train 700 2.263911e-02 -0.525963
2019-11-05 00:22:30,364 train 750 2.265231e-02 -0.533599
2019-11-05 00:22:41,242 train 800 2.266059e-02 -0.539655
2019-11-05 00:22:52,019 train 850 2.266026e-02 -0.546775
2019-11-05 00:22:55,301 training loss; R2: 2.265302e-02 -0.546905
2019-11-05 00:22:55,926 valid 000 3.106993e-02 -0.787667
2019-11-05 00:23:06,631 valid 050 2.516912e-02 -1.153732
2019-11-05 00:23:16,319 validation loss; R2: 2.555699e-02 -1.080019
2019-11-05 00:23:16,391 epoch 62 lr 5.000000e-04
2019-11-05 00:23:17,161 train 000 2.501876e-02 -0.105113
2019-11-05 00:23:27,912 train 050 2.253746e-02 -0.464006
2019-11-05 00:23:38,602 train 100 2.257238e-02 -0.476585
2019-11-05 00:23:49,377 train 150 2.274428e-02 -0.475836
2019-11-05 00:24:00,134 train 200 2.265929e-02 -0.523768
2019-11-05 00:24:10,898 train 250 2.250119e-02 -0.535954
2019-11-05 00:24:21,648 train 300 2.253977e-02 -0.545209
2019-11-05 00:24:32,385 train 350 2.262395e-02 -0.532125
2019-11-05 00:24:43,140 train 400 2.260300e-02 -0.529082
2019-11-05 00:24:53,876 train 450 2.257639e-02 -0.513643
2019-11-05 00:25:04,634 train 500 2.259928e-02 -0.502931
2019-11-05 00:25:15,332 train 550 2.259393e-02 -0.527997
2019-11-05 00:25:26,135 train 600 2.256483e-02 -0.530047
2019-11-05 00:25:36,829 train 650 2.253918e-02 -0.522985
2019-11-05 00:25:47,611 train 700 2.249129e-02 -0.522830
2019-11-05 00:25:58,196 train 750 2.248091e-02 -0.523542
2019-11-05 00:26:08,991 train 800 2.249087e-02 -0.522906
2019-11-05 00:26:19,743 train 850 2.252746e-02 -0.518609
2019-11-05 00:26:23,001 training loss; R2: 2.252670e-02 -0.518816
2019-11-05 00:26:23,581 valid 000 2.014287e-02 -0.212685
2019-11-05 00:26:34,328 valid 050 1.995976e-02 -1.106692
2019-11-05 00:26:44,155 validation loss; R2: 1.967387e-02 -0.691825
2019-11-05 00:26:44,234 epoch 63 lr 5.000000e-04
2019-11-05 00:26:44,933 train 000 2.397455e-02 -0.808264
2019-11-05 00:26:55,890 train 050 2.289376e-02 -0.466511
2019-11-05 00:27:06,829 train 100 2.238751e-02 -0.404772
2019-11-05 00:27:17,728 train 150 2.232606e-02 -0.518137
2019-11-05 00:27:28,650 train 200 2.231756e-02 -0.509478
2019-11-05 00:27:39,562 train 250 2.244457e-02 -0.483174
2019-11-05 00:27:50,433 train 300 2.250952e-02 -0.477447
2019-11-05 00:28:01,355 train 350 2.254453e-02 -0.473471
2019-11-05 00:28:12,262 train 400 2.264167e-02 -0.465283
2019-11-05 00:28:23,147 train 450 2.266027e-02 -0.495961
2019-11-05 00:28:34,023 train 500 2.270980e-02 -0.502064
2019-11-05 00:28:44,931 train 550 2.266942e-02 -0.497739
2019-11-05 00:28:55,843 train 600 2.266837e-02 -0.564115
2019-11-05 00:29:06,513 train 650 2.259785e-02 -0.561849
2019-11-05 00:29:17,015 train 700 2.260148e-02 -0.560434
2019-11-05 00:29:27,451 train 750 2.257990e-02 -0.559184
2019-11-05 00:29:37,991 train 800 2.257210e-02 -0.555157
2019-11-05 00:29:48,733 train 850 2.256234e-02 -0.556352
2019-11-05 00:29:51,917 training loss; R2: 2.254109e-02 -0.553233
2019-11-05 00:29:52,516 valid 000 1.910249e-02 0.024948
2019-11-05 00:30:03,112 valid 050 1.916669e-02 -0.338374
2019-11-05 00:30:12,451 validation loss; R2: 1.903564e-02 -0.500195
2019-11-05 00:30:12,517 epoch 64 lr 5.000000e-04
2019-11-05 00:30:13,207 train 000 2.220251e-02 -0.636088
2019-11-05 00:30:24,005 train 050 2.278424e-02 -0.443425
2019-11-05 00:30:34,783 train 100 2.250867e-02 -0.904356
2019-11-05 00:30:45,548 train 150 2.244575e-02 -0.821561
2019-11-05 00:30:56,311 train 200 2.243688e-02 -0.732562
2019-11-05 00:31:07,005 train 250 2.246144e-02 -0.702507
2019-11-05 00:31:17,674 train 300 2.239557e-02 -0.689464
2019-11-05 00:31:28,427 train 350 2.244541e-02 -0.676068
2019-11-05 00:31:39,158 train 400 2.247175e-02 -0.685898
2019-11-05 00:31:49,909 train 450 2.251149e-02 -0.665096
2019-11-05 00:32:00,642 train 500 2.251956e-02 -0.650735
2019-11-05 00:32:11,399 train 550 2.251261e-02 -0.645675
2019-11-05 00:32:22,118 train 600 2.249686e-02 -0.640414
2019-11-05 00:32:32,814 train 650 2.250444e-02 -0.629109
2019-11-05 00:32:43,354 train 700 2.248803e-02 -0.622015
2019-11-05 00:32:53,904 train 750 2.246589e-02 -0.609816
2019-11-05 00:33:04,615 train 800 2.244595e-02 -0.617044
2019-11-05 00:33:15,392 train 850 2.244249e-02 -0.609606
2019-11-05 00:33:18,579 training loss; R2: 2.243909e-02 -0.605771
2019-11-05 00:33:19,232 valid 000 1.941410e-02 -0.756451
2019-11-05 00:33:29,756 valid 050 2.170227e-02 -0.381741
2019-11-05 00:33:39,375 validation loss; R2: 2.172256e-02 -0.456983
2019-11-05 00:33:39,449 epoch 65 lr 5.000000e-04
2019-11-05 00:33:40,193 train 000 2.164066e-02 -0.151561
2019-11-05 00:33:51,123 train 050 2.247397e-02 -0.490653
2019-11-05 00:34:01,994 train 100 2.244002e-02 -0.509015
2019-11-05 00:34:12,760 train 150 2.264504e-02 -0.481222
2019-11-05 00:34:23,585 train 200 2.255483e-02 -0.505909
2019-11-05 00:34:34,519 train 250 2.244943e-02 -0.507180
2019-11-05 00:34:45,330 train 300 2.248605e-02 -0.505087
2019-11-05 00:34:56,078 train 350 2.248355e-02 -0.550306
2019-11-05 00:35:06,901 train 400 2.241272e-02 -0.609922
2019-11-05 00:35:17,700 train 450 2.245820e-02 -0.604109
2019-11-05 00:35:28,516 train 500 2.246319e-02 -0.594995
2019-11-05 00:35:39,341 train 550 2.243973e-02 -0.578925
2019-11-05 00:35:50,100 train 600 2.249145e-02 -0.571249
2019-11-05 00:36:00,905 train 650 2.249147e-02 -0.577837
2019-11-05 00:36:11,721 train 700 2.256225e-02 -0.563010
2019-11-05 00:36:22,458 train 750 2.255232e-02 -0.553758
2019-11-05 00:36:33,144 train 800 2.259439e-02 -0.562148
2019-11-05 00:36:43,840 train 850 2.260802e-02 -0.554544
2019-11-05 00:36:46,982 training loss; R2: 2.258951e-02 -0.552545
2019-11-05 00:36:47,612 valid 000 2.883564e-02 -0.549515
2019-11-05 00:36:58,411 valid 050 3.323982e-02 -0.958884
2019-11-05 00:37:07,865 validation loss; R2: 3.324602e-02 -1.098170
2019-11-05 00:37:07,926 epoch 66 lr 5.000000e-04
2019-11-05 00:37:08,680 train 000 2.616479e-02 -0.188728
2019-11-05 00:37:19,400 train 050 2.227234e-02 -0.499376
2019-11-05 00:37:30,195 train 100 2.235073e-02 -0.426960
2019-11-05 00:37:40,935 train 150 2.222221e-02 -0.496145
2019-11-05 00:37:51,703 train 200 2.225928e-02 -0.518766
2019-11-05 00:38:02,388 train 250 2.243454e-02 -0.499830
2019-11-05 00:38:13,111 train 300 2.256390e-02 -0.492364
2019-11-05 00:38:23,794 train 350 2.260254e-02 -0.490213
2019-11-05 00:38:34,532 train 400 2.260988e-02 -0.484912
2019-11-05 00:38:45,307 train 450 2.264558e-02 -0.474464
2019-11-05 00:38:56,116 train 500 2.270841e-02 -0.489607
2019-11-05 00:39:06,910 train 550 2.275783e-02 -0.503599
2019-11-05 00:39:17,717 train 600 2.277912e-02 -0.494846
2019-11-05 00:39:28,541 train 650 2.281323e-02 -0.485674
2019-11-05 00:39:39,305 train 700 2.282428e-02 -0.483088
2019-11-05 00:39:50,081 train 750 2.280898e-02 -0.519349
2019-11-05 00:40:00,888 train 800 2.276564e-02 -0.580716
2019-11-05 00:40:11,671 train 850 2.276598e-02 -0.576477
2019-11-05 00:40:14,863 training loss; R2: 2.276464e-02 -0.577771
2019-11-05 00:40:15,440 valid 000 2.695142e-02 -1.515926
2019-11-05 00:40:26,322 valid 050 2.621940e-02 -0.361941
2019-11-05 00:40:35,795 validation loss; R2: 2.612707e-02 -0.336431
2019-11-05 00:40:35,862 epoch 67 lr 5.000000e-04
2019-11-05 00:40:36,593 train 000 2.599873e-02 -0.290088
2019-11-05 00:40:47,405 train 050 2.324600e-02 -0.564619
2019-11-05 00:40:58,170 train 100 2.307650e-02 -0.535850
2019-11-05 00:41:08,924 train 150 2.283883e-02 -0.474626
2019-11-05 00:41:19,703 train 200 2.302469e-02 -0.496613
2019-11-05 00:41:30,391 train 250 2.300958e-02 -0.518451
2019-11-05 00:41:41,115 train 300 2.306402e-02 -0.523324
2019-11-05 00:41:51,830 train 350 2.309259e-02 -0.512740
2019-11-05 00:42:02,509 train 400 2.313242e-02 -0.519190
2019-11-05 00:42:13,208 train 450 2.321666e-02 -0.520512
2019-11-05 00:42:23,927 train 500 2.318523e-02 -0.532890
2019-11-05 00:42:34,592 train 550 2.315563e-02 -0.530295
2019-11-05 00:42:45,326 train 600 2.314838e-02 -0.559358
2019-11-05 00:42:56,082 train 650 2.313101e-02 -0.542450
2019-11-05 00:43:06,708 train 700 2.311562e-02 -0.535913
2019-11-05 00:43:17,354 train 750 2.315689e-02 -0.543777
2019-11-05 00:43:28,062 train 800 2.315788e-02 -0.531097
2019-11-05 00:43:38,865 train 850 2.326798e-02 -0.611162
2019-11-05 00:43:42,055 training loss; R2: 2.327193e-02 -0.608337
2019-11-05 00:43:42,660 valid 000 2.582769e-02 -0.241294
2019-11-05 00:43:53,498 valid 050 2.384831e-02 -0.463412
2019-11-05 00:44:03,052 validation loss; R2: 2.351249e-02 -0.590859
2019-11-05 00:44:03,120 epoch 68 lr 5.000000e-04
2019-11-05 00:44:03,886 train 000 2.417289e-02 -0.294936
2019-11-05 00:44:14,698 train 050 2.348273e-02 -0.459542
2019-11-05 00:44:25,464 train 100 2.366382e-02 -0.460376
2019-11-05 00:44:36,265 train 150 2.387900e-02 -0.480767
2019-11-05 00:44:47,092 train 200 2.360737e-02 -0.452820
2019-11-05 00:44:57,899 train 250 2.352227e-02 -0.476592
2019-11-05 00:45:08,654 train 300 2.345686e-02 -0.484899
2019-11-05 00:45:19,352 train 350 2.346211e-02 -0.498925
2019-11-05 00:45:30,022 train 400 2.348542e-02 -0.496602
2019-11-05 00:45:40,739 train 450 2.350010e-02 -0.496984
2019-11-05 00:45:51,715 train 500 2.342092e-02 -0.499938
2019-11-05 00:46:02,612 train 550 2.338563e-02 -0.497200
2019-11-05 00:46:13,481 train 600 2.357250e-02 -0.496330
2019-11-05 00:46:24,356 train 650 2.389918e-02 -0.497021
2019-11-05 00:46:34,985 train 700 2.412699e-02 -0.490472
2019-11-05 00:46:45,764 train 750 2.421577e-02 -0.485651
2019-11-05 00:46:56,619 train 800 2.419989e-02 -0.490875
2019-11-05 00:47:07,624 train 850 2.417185e-02 -0.495649
2019-11-05 00:47:10,798 training loss; R2: 2.413342e-02 -0.497687
2019-11-05 00:47:11,413 valid 000 2.373119e-02 -9.015648
2019-11-05 00:47:22,289 valid 050 2.600093e-02 -1.426975
2019-11-05 00:47:31,851 validation loss; R2: 2.643217e-02 -1.270599
2019-11-05 00:47:31,934 epoch 69 lr 5.000000e-04
2019-11-05 00:47:32,648 train 000 2.731088e-02 -0.112945
2019-11-05 00:47:43,514 train 050 2.365231e-02 -0.372574
2019-11-05 00:47:54,425 train 100 2.352640e-02 -0.433961
2019-11-05 00:48:05,394 train 150 2.344926e-02 -0.795691
2019-11-05 00:48:16,325 train 200 2.345631e-02 -0.906699
2019-11-05 00:48:27,194 train 250 2.349535e-02 -0.818538
2019-11-05 00:48:37,968 train 300 2.351065e-02 -0.780426
2019-11-05 00:48:48,802 train 350 2.342897e-02 -0.856613
2019-11-05 00:48:59,614 train 400 2.337840e-02 -0.806271
2019-11-05 00:49:10,429 train 450 2.342883e-02 -0.857255
2019-11-05 00:49:21,279 train 500 2.349854e-02 -0.821190
2019-11-05 00:49:32,115 train 550 2.346597e-02 -0.791677
2019-11-05 00:49:42,970 train 600 2.339926e-02 -0.770210
2019-11-05 00:49:53,863 train 650 2.336295e-02 -0.747142
2019-11-05 00:50:04,553 train 700 2.335603e-02 -0.726096
2019-11-05 00:50:15,443 train 750 2.337429e-02 -0.708415
2019-11-05 00:50:26,211 train 800 2.337447e-02 -0.702229
2019-11-05 00:50:37,147 train 850 2.339480e-02 -0.693155
2019-11-05 00:50:40,412 training loss; R2: 2.338725e-02 -0.687396
2019-11-05 00:50:41,044 valid 000 2.331887e-02 -1.050558
2019-11-05 00:50:51,931 valid 050 2.631317e-02 -0.275830
2019-11-05 00:51:01,593 validation loss; R2: 2.647683e-02 -0.275938
2019-11-05 00:51:01,661 epoch 70 lr 5.000000e-04
2019-11-05 00:51:02,430 train 000 2.608860e-02 -0.295638
2019-11-05 00:51:13,273 train 050 2.338110e-02 -0.472228
2019-11-05 00:51:24,078 train 100 2.336803e-02 -0.479426
2019-11-05 00:51:34,890 train 150 2.356252e-02 -0.481619
2019-11-05 00:51:45,690 train 200 2.353283e-02 -0.486351
2019-11-05 00:51:56,510 train 250 2.341120e-02 -0.476579
2019-11-05 00:52:07,119 train 300 2.335552e-02 -0.469531
2019-11-05 00:52:17,980 train 350 2.326877e-02 -0.454208
2019-11-05 00:52:28,847 train 400 2.336007e-02 -0.487458
2019-11-05 00:52:39,604 train 450 2.334514e-02 -0.494923
2019-11-05 00:52:50,332 train 500 2.334047e-02 -0.495279
2019-11-05 00:53:01,072 train 550 2.329718e-02 -0.497298
2019-11-05 00:53:11,779 train 600 2.329999e-02 -0.489932
2019-11-05 00:53:22,452 train 650 2.324394e-02 -0.484722
2019-11-05 00:53:33,150 train 700 2.324955e-02 -0.488953
2019-11-05 00:53:43,871 train 750 2.329578e-02 -0.494769
2019-11-05 00:53:54,625 train 800 2.350607e-02 -0.488069
2019-11-05 00:54:05,345 train 850 2.366578e-02 -0.490958
2019-11-05 00:54:08,524 training loss; R2: 2.370983e-02 -0.494827
2019-11-05 00:54:09,094 valid 000 2.700857e-02 -1.299064
2019-11-05 00:54:19,759 valid 050 2.865446e-02 -0.748323
2019-11-05 00:54:29,361 validation loss; R2: 2.821475e-02 -0.827798
2019-11-05 00:54:29,430 epoch 71 lr 5.000000e-04
2019-11-05 00:54:30,204 train 000 2.505337e-02 -0.255300
2019-11-05 00:54:41,002 train 050 2.542475e-02 -0.473669
2019-11-05 00:54:51,869 train 100 2.522929e-02 -0.445421
2019-11-05 00:55:02,605 train 150 2.494419e-02 -0.493264
2019-11-05 00:55:13,334 train 200 2.479766e-02 -0.494233
2019-11-05 00:55:24,166 train 250 2.471143e-02 -0.500524
2019-11-05 00:55:34,852 train 300 2.463783e-02 -0.490618
2019-11-05 00:55:45,655 train 350 2.463243e-02 -0.479328
2019-11-05 00:55:56,387 train 400 2.459660e-02 -0.469846
2019-11-05 00:56:07,216 train 450 2.455328e-02 -0.472783
2019-11-05 00:56:17,960 train 500 2.468742e-02 -0.488202
2019-11-05 00:56:28,724 train 550 2.472805e-02 -0.499133
2019-11-05 00:56:39,651 train 600 2.470044e-02 -0.506384
2019-11-05 00:56:50,421 train 650 2.462190e-02 -0.532037
2019-11-05 00:57:01,243 train 700 2.455225e-02 -0.528118
2019-11-05 00:57:11,857 train 750 2.448155e-02 -0.526763
2019-11-05 00:57:22,654 train 800 2.440052e-02 -0.524344
2019-11-05 00:57:33,515 train 850 2.437598e-02 -0.518747
2019-11-05 00:57:36,737 training loss; R2: 2.436029e-02 -0.520652
2019-11-05 00:57:37,349 valid 000 2.011134e-02 -0.085954
2019-11-05 00:57:48,163 valid 050 2.124888e-02 -0.243308
2019-11-05 00:57:57,662 validation loss; R2: 2.143920e-02 -0.246962
2019-11-05 00:57:57,729 epoch 72 lr 5.000000e-04
2019-11-05 00:57:58,428 train 000 2.325477e-02 -0.214228
2019-11-05 00:58:09,362 train 050 2.342407e-02 -0.547042
2019-11-05 00:58:20,065 train 100 2.321982e-02 -0.648053
2019-11-05 00:58:30,841 train 150 2.325418e-02 -0.642190
2019-11-05 00:58:41,532 train 200 2.334324e-02 -0.563243
2019-11-05 00:58:52,442 train 250 2.351586e-02 -1.590916
2019-11-05 00:59:03,068 train 300 2.366216e-02 -1.382691
2019-11-05 00:59:13,769 train 350 2.379635e-02 -1.240742
2019-11-05 00:59:24,532 train 400 2.380126e-02 -1.196649
2019-11-05 00:59:35,168 train 450 2.384130e-02 -1.129769
2019-11-05 00:59:45,927 train 500 2.382671e-02 -1.076157
2019-11-05 00:59:56,759 train 550 2.378987e-02 -1.021603
2019-11-05 01:00:07,392 train 600 2.378227e-02 -0.985473
2019-11-05 01:00:18,158 train 650 2.380647e-02 -2.790669
2019-11-05 01:00:29,013 train 700 2.384817e-02 -2.623708
2019-11-05 01:00:39,664 train 750 2.387975e-02 -2.481448
2019-11-05 01:00:50,343 train 800 2.391493e-02 -2.356594
2019-11-05 01:01:01,103 train 850 2.392153e-02 -2.249320
2019-11-05 01:01:04,312 training loss; R2: 2.392677e-02 -2.218535
2019-11-05 01:01:04,914 valid 000 2.597401e-02 -1.815647
2019-11-05 01:01:15,633 valid 050 2.517294e-02 -1.191903
2019-11-05 01:01:25,099 validation loss; R2: 2.523641e-02 -1.440561
2019-11-05 01:01:25,171 epoch 73 lr 5.000000e-04
2019-11-05 01:01:25,903 train 000 2.403245e-02 -0.312778
2019-11-05 01:01:36,769 train 050 2.380004e-02 -0.429097
2019-11-05 01:01:47,735 train 100 2.366917e-02 -0.483206
2019-11-05 01:01:58,677 train 150 2.367813e-02 -0.484436
2019-11-05 01:02:09,597 train 200 2.359208e-02 -0.472759
2019-11-05 01:02:20,087 train 250 2.350917e-02 -0.444569
2019-11-05 01:02:30,530 train 300 2.357084e-02 -0.495643
2019-11-05 01:02:41,135 train 350 2.356146e-02 -0.525523
2019-11-05 01:02:52,090 train 400 2.359896e-02 -0.528439
2019-11-05 01:03:03,016 train 450 2.360389e-02 -0.519021
2019-11-05 01:03:13,976 train 500 2.356774e-02 -0.524283
2019-11-05 01:03:24,793 train 550 2.357517e-02 -0.541316
2019-11-05 01:03:35,630 train 600 2.366694e-02 -0.528880
2019-11-05 01:03:46,468 train 650 2.371436e-02 -0.580537
2019-11-05 01:03:57,177 train 700 2.372089e-02 -0.576302
2019-11-05 01:04:07,781 train 750 2.375287e-02 -0.572812
2019-11-05 01:04:18,344 train 800 2.371827e-02 -0.560590
2019-11-05 01:04:28,952 train 850 2.370208e-02 -0.548751
2019-11-05 01:04:32,052 training loss; R2: 2.370561e-02 -0.545961
2019-11-05 01:04:32,629 valid 000 2.518650e-02 -0.324508
2019-11-05 01:04:43,236 valid 050 2.313885e-02 -0.177927
2019-11-05 01:04:52,875 validation loss; R2: 2.280598e-02 -0.147107
2019-11-05 01:04:52,943 epoch 74 lr 5.000000e-04
2019-11-05 01:04:53,718 train 000 2.210330e-02 -0.856722
2019-11-05 01:05:04,635 train 050 2.357269e-02 -0.511253
2019-11-05 01:05:15,492 train 100 2.553591e-02 -0.441595
2019-11-05 01:05:26,255 train 150 2.621462e-02 -0.465258
2019-11-05 01:05:37,056 train 200 2.651911e-02 -0.445725
2019-11-05 01:05:47,763 train 250 2.669545e-02 -0.422270
2019-11-05 01:05:58,482 train 300 2.668409e-02 -0.437265
2019-11-05 01:06:09,325 train 350 2.669015e-02 -0.429285
2019-11-05 01:06:20,060 train 400 2.672601e-02 -0.437090
2019-11-05 01:06:30,783 train 450 2.669242e-02 -0.442421
2019-11-05 01:06:41,541 train 500 2.678139e-02 -0.428266
2019-11-05 01:06:52,259 train 550 2.683406e-02 -0.421917
2019-11-05 01:07:03,029 train 600 2.685536e-02 -0.412030
2019-11-05 01:07:13,840 train 650 2.689400e-02 -0.417190
2019-11-05 01:07:24,503 train 700 2.689020e-02 -0.413445
2019-11-05 01:07:35,180 train 750 2.690455e-02 -0.407698
2019-11-05 01:07:45,836 train 800 2.692558e-02 -0.403245
2019-11-05 01:07:56,642 train 850 2.694096e-02 -0.416741
2019-11-05 01:07:59,905 training loss; R2: 2.694418e-02 -0.417054
2019-11-05 01:08:00,486 valid 000 2.708114e-02 -0.141106
2019-11-05 01:08:11,417 valid 050 2.716012e-02 -0.522923
2019-11-05 01:08:21,026 validation loss; R2: 2.700310e-02 -0.488545
2019-11-05 01:08:21,095 epoch 75 lr 5.000000e-04
2019-11-05 01:08:21,859 train 000 2.357805e-02 -0.184909
2019-11-05 01:08:32,684 train 050 2.693248e-02 -0.341758
2019-11-05 01:08:43,392 train 100 2.683634e-02 -0.362050
2019-11-05 01:08:54,140 train 150 2.685172e-02 -0.357538
2019-11-05 01:09:04,872 train 200 2.690293e-02 -0.360404
2019-11-05 01:09:15,624 train 250 2.691976e-02 -0.437235
2019-11-05 01:09:26,314 train 300 2.689648e-02 -0.417784
2019-11-05 01:09:37,187 train 350 2.684200e-02 -0.438736
2019-11-05 01:09:47,938 train 400 2.683579e-02 -0.423949
2019-11-05 01:09:58,771 train 450 2.687441e-02 -0.421322
2019-11-05 01:10:09,446 train 500 2.690366e-02 -0.423504
2019-11-05 01:10:20,256 train 550 2.689543e-02 -0.421158
2019-11-05 01:10:31,110 train 600 2.693858e-02 -0.420219
2019-11-05 01:10:41,812 train 650 2.688729e-02 -0.415753
2019-11-05 01:10:52,600 train 700 2.687287e-02 -0.409564
2019-11-05 01:11:03,154 train 750 2.689919e-02 -0.408445
2019-11-05 01:11:13,859 train 800 2.688616e-02 -0.408417
2019-11-05 01:11:24,608 train 850 2.686945e-02 -0.405298
2019-11-05 01:11:27,833 training loss; R2: 2.686745e-02 -0.405045
2019-11-05 01:11:28,444 valid 000 2.630014e-02 -0.471710
2019-11-05 01:11:39,133 valid 050 2.558498e-02 -0.319785
2019-11-05 01:11:48,735 validation loss; R2: 2.544676e-02 -0.349447
2019-11-05 01:11:48,802 epoch 76 lr 5.000000e-04
2019-11-05 01:11:49,570 train 000 2.280290e-02 -0.269278
2019-11-05 01:12:00,449 train 050 2.614213e-02 -0.440121
2019-11-05 01:12:11,245 train 100 2.657939e-02 -0.430749
2019-11-05 01:12:22,030 train 150 2.670066e-02 -0.412084
2019-11-05 01:12:32,789 train 200 2.669342e-02 -0.421237
2019-11-05 01:12:43,632 train 250 2.666537e-02 -0.432093
2019-11-05 01:12:54,322 train 300 2.670519e-02 -0.424010
2019-11-05 01:13:05,031 train 350 2.671025e-02 -0.444035
2019-11-05 01:13:15,786 train 400 2.666800e-02 -0.447760
2019-11-05 01:13:26,460 train 450 2.669560e-02 -0.448299
2019-11-05 01:13:37,220 train 500 2.668192e-02 -0.446853
2019-11-05 01:13:47,994 train 550 2.667981e-02 -0.449609
2019-11-05 01:13:58,773 train 600 2.669789e-02 -0.479037
2019-11-05 01:14:09,554 train 650 2.670394e-02 -0.474517
2019-11-05 01:14:20,052 train 700 2.667833e-02 -0.482603
2019-11-05 01:14:30,593 train 750 2.667926e-02 -0.477760
2019-11-05 01:14:41,183 train 800 2.667134e-02 -0.475108
2019-11-05 01:14:51,791 train 850 2.667691e-02 -0.470594
2019-11-05 01:14:54,931 training loss; R2: 2.668591e-02 -0.468077
2019-11-05 01:14:55,596 valid 000 2.525320e-02 -0.088816
2019-11-05 01:15:06,202 valid 050 2.655119e-02 -0.388197
2019-11-05 01:15:15,627 validation loss; R2: 2.653085e-02 -0.493618
2019-11-05 01:15:15,691 epoch 77 lr 5.000000e-04
2019-11-05 01:15:16,452 train 000 2.323307e-02 -0.224976
2019-11-05 01:15:27,034 train 050 2.665536e-02 -0.373420
2019-11-05 01:15:37,670 train 100 2.658417e-02 -0.421789
2019-11-05 01:15:48,301 train 150 2.677637e-02 -0.390601
2019-11-05 01:15:59,059 train 200 2.671139e-02 -0.391601
2019-11-05 01:16:09,711 train 250 2.678627e-02 -0.369137
2019-11-05 01:16:20,594 train 300 2.672934e-02 -0.398979
2019-11-05 01:16:31,532 train 350 2.668179e-02 -0.480811
2019-11-05 01:16:42,365 train 400 2.672553e-02 -0.477578
2019-11-05 01:16:53,189 train 450 2.669773e-02 -0.462712
2019-11-05 01:17:04,231 train 500 2.664367e-02 -0.460066
2019-11-05 01:17:15,016 train 550 2.663356e-02 -0.455137
2019-11-05 01:17:25,782 train 600 2.666088e-02 -0.440711
2019-11-05 01:17:36,527 train 650 2.665340e-02 -0.440125
2019-11-05 01:17:47,232 train 700 2.665498e-02 -0.433370
2019-11-05 01:17:57,879 train 750 2.668377e-02 -0.439956
2019-11-05 01:18:08,628 train 800 2.666860e-02 -0.435314
2019-11-05 01:18:19,333 train 850 2.664283e-02 -0.431415
2019-11-05 01:18:22,627 training loss; R2: 2.663470e-02 -0.428129
2019-11-05 01:18:23,216 valid 000 2.297491e-02 -0.132871
2019-11-05 01:18:33,957 valid 050 2.557536e-02 -0.317442
2019-11-05 01:18:43,437 validation loss; R2: 2.541324e-02 -0.370901
2019-11-05 01:18:43,515 epoch 78 lr 5.000000e-04
2019-11-05 01:18:44,269 train 000 2.474835e-02 -0.108418
2019-11-05 01:18:55,189 train 050 2.657167e-02 -0.433865
2019-11-05 01:19:06,107 train 100 2.672993e-02 -0.428184
2019-11-05 01:19:17,043 train 150 2.658618e-02 -0.407365
2019-11-05 01:19:28,021 train 200 2.653607e-02 -0.394814
2019-11-05 01:19:38,960 train 250 2.653006e-02 -0.409912
2019-11-05 01:19:49,492 train 300 2.652103e-02 -0.424282
2019-11-05 01:20:00,159 train 350 2.647939e-02 -0.430348
2019-11-05 01:20:10,946 train 400 2.650546e-02 -0.423602
2019-11-05 01:20:21,749 train 450 2.654883e-02 -0.433739
2019-11-05 01:20:32,500 train 500 2.653355e-02 -0.430423
2019-11-05 01:20:43,312 train 550 2.655581e-02 -0.442234
2019-11-05 01:20:54,102 train 600 2.653687e-02 -0.440934
2019-11-05 01:21:04,975 train 650 2.652390e-02 -0.452064
2019-11-05 01:21:15,690 train 700 2.657124e-02 -0.453687
2019-11-05 01:21:26,449 train 750 2.655234e-02 -0.449678
2019-11-05 01:21:37,402 train 800 2.653658e-02 -0.446015
2019-11-05 01:21:48,393 train 850 2.654612e-02 -0.444651
2019-11-05 01:21:51,722 training loss; R2: 2.654125e-02 -0.443305
2019-11-05 01:21:52,378 valid 000 2.920024e-02 -0.695681
2019-11-05 01:22:03,316 valid 050 2.679161e-02 -0.461150
2019-11-05 01:22:13,057 validation loss; R2: 2.699762e-02 -0.541028
2019-11-05 01:22:13,127 epoch 79 lr 5.000000e-04
2019-11-05 01:22:13,928 train 000 2.593686e-02 -0.091992
2019-11-05 01:22:24,737 train 050 2.658836e-02 -0.320047
2019-11-05 01:22:35,519 train 100 2.660935e-02 -0.432821
2019-11-05 01:22:46,234 train 150 2.659941e-02 -0.592799
2019-11-05 01:22:56,993 train 200 2.640754e-02 -0.541902
2019-11-05 01:23:07,699 train 250 2.644244e-02 -0.519506
2019-11-05 01:23:18,273 train 300 2.647087e-02 -0.491391
2019-11-05 01:23:29,012 train 350 2.644678e-02 -0.478936
2019-11-05 01:23:39,808 train 400 2.643595e-02 -0.468415
2019-11-05 01:23:50,567 train 450 2.645005e-02 -0.467883
2019-11-05 01:24:01,312 train 500 2.645759e-02 -0.462407
2019-11-05 01:24:12,068 train 550 2.653368e-02 -0.455930
2019-11-05 01:24:22,752 train 600 2.653995e-02 -0.450398
2019-11-05 01:24:33,564 train 650 2.653065e-02 -0.450379
2019-11-05 01:24:44,251 train 700 2.653915e-02 -0.445217
2019-11-05 01:24:54,925 train 750 2.654821e-02 -0.446781
2019-11-05 01:25:05,631 train 800 2.654764e-02 -0.441820
2019-11-05 01:25:16,279 train 850 2.652677e-02 -0.441779
2019-11-05 01:25:19,481 training loss; R2: 2.652857e-02 -0.441247
2019-11-05 01:25:20,056 valid 000 2.549036e-02 -0.076421
2019-11-05 01:25:30,899 valid 050 2.707473e-02 -0.435665
2019-11-05 01:25:40,421 validation loss; R2: 2.700022e-02 -0.480431
2019-11-05 01:25:40,487 epoch 80 lr 5.000000e-04
2019-11-05 01:25:41,186 train 000 2.475327e-02 -0.095387
2019-11-05 01:25:52,048 train 050 2.660313e-02 -0.949869
2019-11-05 01:26:02,783 train 100 2.647765e-02 -0.712558
2019-11-05 01:26:13,431 train 150 2.636650e-02 -0.599347
2019-11-05 01:26:24,087 train 200 2.632322e-02 -0.535015
2019-11-05 01:26:34,695 train 250 2.638544e-02 -0.498780
2019-11-05 01:26:45,283 train 300 2.640836e-02 -0.494802
2019-11-05 01:26:55,906 train 350 2.648010e-02 -0.485519
2019-11-05 01:27:06,592 train 400 2.646930e-02 -0.475522
2019-11-05 01:27:17,288 train 450 2.655317e-02 -0.463424
2019-11-05 01:27:27,995 train 500 2.656608e-02 -0.455557
2019-11-05 01:27:38,662 train 550 2.661514e-02 -0.461236
2019-11-05 01:27:49,349 train 600 2.657337e-02 -0.449875
2019-11-05 01:28:00,028 train 650 2.660235e-02 -0.445770
2019-11-05 01:28:10,687 train 700 2.660990e-02 -0.446776
2019-11-05 01:28:21,292 train 750 2.659066e-02 -0.450083
2019-11-05 01:28:31,967 train 800 2.656030e-02 -0.487184
2019-11-05 01:28:42,699 train 850 2.656800e-02 -0.480022
2019-11-05 01:28:45,856 training loss; R2: 2.657113e-02 -0.477328
2019-11-05 01:28:46,440 valid 000 2.780968e-02 -0.078978
2019-11-05 01:28:57,096 valid 050 2.769224e-02 -0.461332
2019-11-05 01:29:06,804 validation loss; R2: 2.770183e-02 -0.415194
2019-11-05 01:29:06,885 epoch 81 lr 5.000000e-04
2019-11-05 01:29:07,635 train 000 2.796999e-02 -0.064569
2019-11-05 01:29:18,367 train 050 2.605907e-02 -0.334128
2019-11-05 01:29:29,222 train 100 2.614078e-02 -0.399810
2019-11-05 01:29:39,900 train 150 2.615684e-02 -0.379619
2019-11-05 01:29:50,691 train 200 2.618468e-02 -0.369906
2019-11-05 01:30:01,497 train 250 2.619636e-02 -0.379593
2019-11-05 01:30:12,171 train 300 2.631728e-02 -0.378883
2019-11-05 01:30:22,834 train 350 2.638950e-02 -0.375054
2019-11-05 01:30:33,580 train 400 2.637252e-02 -0.417645
2019-11-05 01:30:44,383 train 450 2.644636e-02 -0.417065
2019-11-05 01:30:55,088 train 500 2.644076e-02 -0.435593
2019-11-05 01:31:05,730 train 550 2.652484e-02 -0.431526
2019-11-05 01:31:16,513 train 600 2.653157e-02 -0.438779
2019-11-05 01:31:27,229 train 650 2.658156e-02 -0.434893
2019-11-05 01:31:38,041 train 700 2.653913e-02 -0.443504
2019-11-05 01:31:48,635 train 750 2.653300e-02 -0.441110
2019-11-05 01:31:59,256 train 800 2.648706e-02 -0.443877
2019-11-05 01:32:10,017 train 850 2.647630e-02 -0.438783
2019-11-05 01:32:13,249 training loss; R2: 2.646555e-02 -0.439622
2019-11-05 01:32:13,884 valid 000 2.735806e-02 -0.515548
2019-11-05 01:32:24,538 valid 050 2.594760e-02 -0.653669
2019-11-05 01:32:34,236 validation loss; R2: 2.567690e-02 -0.579371
2019-11-05 01:32:34,305 epoch 82 lr 5.000000e-04
2019-11-05 01:32:35,050 train 000 3.046302e-02 -0.588999
2019-11-05 01:32:46,023 train 050 2.670922e-02 -0.470082
2019-11-05 01:32:56,962 train 100 2.635186e-02 -0.406904
2019-11-05 01:33:07,856 train 150 2.638052e-02 -0.445948
2019-11-05 01:33:18,667 train 200 2.645234e-02 -0.422331
2019-11-05 01:33:29,289 train 250 2.644676e-02 -0.436290
2019-11-05 01:33:39,679 train 300 2.645323e-02 -0.431591
2019-11-05 01:33:50,207 train 350 2.646406e-02 -0.455027
2019-11-05 01:34:00,806 train 400 2.647493e-02 -0.452792
2019-11-05 01:34:11,361 train 450 2.642788e-02 -0.450787
2019-11-05 01:34:21,946 train 500 2.645866e-02 -0.444602
2019-11-05 01:34:32,467 train 550 2.644563e-02 -0.436787
2019-11-05 01:34:42,998 train 600 2.645840e-02 -0.469372
2019-11-05 01:34:53,546 train 650 2.646984e-02 -0.467704
2019-11-05 01:35:04,155 train 700 2.647378e-02 -0.459905
2019-11-05 01:35:14,742 train 750 2.649200e-02 -0.458718
2019-11-05 01:35:25,438 train 800 2.650070e-02 -0.452142
2019-11-05 01:35:36,071 train 850 2.653086e-02 -0.451401
2019-11-05 01:35:39,273 training loss; R2: 2.653427e-02 -0.450688
2019-11-05 01:35:39,882 valid 000 2.723548e-02 -0.222456
2019-11-05 01:35:50,556 valid 050 2.675869e-02 -0.415789
2019-11-05 01:35:59,947 validation loss; R2: 2.698230e-02 -0.532979
2019-11-05 01:36:00,018 epoch 83 lr 5.000000e-04
2019-11-05 01:36:00,717 train 000 2.288245e-02 -0.031229
2019-11-05 01:36:11,690 train 050 2.693141e-02 -0.378156
2019-11-05 01:36:22,554 train 100 2.685739e-02 -0.396968
2019-11-05 01:36:33,421 train 150 2.672662e-02 -0.420596
2019-11-05 01:36:44,256 train 200 2.667397e-02 -0.421644
2019-11-05 01:36:55,083 train 250 2.655352e-02 -0.419324
2019-11-05 01:37:05,852 train 300 2.651300e-02 -0.424141
2019-11-05 01:37:16,540 train 350 2.652676e-02 -0.428833
2019-11-05 01:37:27,394 train 400 2.650674e-02 -0.439570
2019-11-05 01:37:38,237 train 450 2.651292e-02 -0.447285
2019-11-05 01:37:49,095 train 500 2.654222e-02 -0.442721
2019-11-05 01:37:59,920 train 550 2.657260e-02 -0.433703
2019-11-05 01:38:10,748 train 600 2.655191e-02 -0.434097
2019-11-05 01:38:21,512 train 650 2.657257e-02 -0.431079
2019-11-05 01:38:32,300 train 700 2.657893e-02 -0.440606
2019-11-05 01:38:42,942 train 750 2.655168e-02 -0.443643
2019-11-05 01:38:53,556 train 800 2.652665e-02 -0.443475
2019-11-05 01:39:04,305 train 850 2.649175e-02 -0.548308
2019-11-05 01:39:07,518 training loss; R2: 2.649484e-02 -0.545090
2019-11-05 01:39:08,108 valid 000 2.766169e-02 -0.702103
2019-11-05 01:39:19,055 valid 050 2.632713e-02 -0.328812
2019-11-05 01:39:28,724 validation loss; R2: 2.638122e-02 -0.419845
2019-11-05 01:39:28,793 epoch 84 lr 5.000000e-04
2019-11-05 01:39:29,499 train 000 2.615971e-02 -0.286821
2019-11-05 01:39:40,564 train 050 2.631343e-02 -0.340870
2019-11-05 01:39:51,531 train 100 2.655286e-02 -0.367338
2019-11-05 01:40:02,344 train 150 2.651401e-02 -0.361480
2019-11-05 01:40:13,286 train 200 2.642449e-02 -0.386380
2019-11-05 01:40:23,992 train 250 2.637344e-02 -0.383236
2019-11-05 01:40:34,789 train 300 2.641183e-02 -0.380537
2019-11-05 01:40:45,414 train 350 2.646238e-02 -0.382915
2019-11-05 01:40:55,955 train 400 2.652069e-02 -0.379405
2019-11-05 01:41:06,629 train 450 2.651592e-02 -0.376692
2019-11-05 01:41:17,189 train 500 2.653341e-02 -0.388766
2019-11-05 01:41:27,730 train 550 2.653152e-02 -0.389074
2019-11-05 01:41:38,341 train 600 2.654245e-02 -0.392256
2019-11-05 01:41:48,854 train 650 2.650634e-02 -0.397235
2019-11-05 01:41:59,461 train 700 2.649311e-02 -0.397577
2019-11-05 01:42:10,150 train 750 2.648262e-02 -0.402022
2019-11-05 01:42:20,804 train 800 2.645400e-02 -0.405873
2019-11-05 01:42:31,620 train 850 2.645175e-02 -0.406059
2019-11-05 01:42:34,887 training loss; R2: 2.645214e-02 -0.404530
2019-11-05 01:42:35,502 valid 000 2.513144e-02 -0.303636
2019-11-05 01:42:46,127 valid 050 2.577953e-02 -0.442716
2019-11-05 01:42:55,856 validation loss; R2: 2.592828e-02 -0.670883
2019-11-05 01:42:55,925 epoch 85 lr 5.000000e-04
2019-11-05 01:42:56,720 train 000 2.477548e-02 -0.282211
2019-11-05 01:43:07,427 train 050 2.621023e-02 -0.500643
2019-11-05 01:43:18,159 train 100 2.625506e-02 -0.483038
2019-11-05 01:43:28,909 train 150 2.630916e-02 -0.451078
2019-11-05 01:43:39,734 train 200 2.628351e-02 -0.447282
2019-11-05 01:43:50,454 train 250 2.634659e-02 -0.439929
2019-11-05 01:44:01,173 train 300 2.635515e-02 -0.440897
2019-11-05 01:44:11,848 train 350 2.634060e-02 -0.506349
2019-11-05 01:44:22,655 train 400 2.633868e-02 -0.487697
2019-11-05 01:44:33,428 train 450 2.638701e-02 -0.480949
2019-11-05 01:44:44,132 train 500 2.639441e-02 -0.473153
2019-11-05 01:44:54,837 train 550 2.640839e-02 -0.463565
2019-11-05 01:45:05,541 train 600 2.641880e-02 -0.476501
2019-11-05 01:45:16,257 train 650 2.640617e-02 -0.473454
2019-11-05 01:45:26,956 train 700 2.640337e-02 -0.472145
2019-11-05 01:45:37,493 train 750 2.639254e-02 -0.512073
2019-11-05 01:45:48,074 train 800 2.640836e-02 -0.508650
2019-11-05 01:45:58,799 train 850 2.638602e-02 -0.498905
2019-11-05 01:46:01,974 training loss; R2: 2.639004e-02 -0.495076
2019-11-05 01:46:02,594 valid 000 2.519439e-02 -1.238378
2019-11-05 01:46:13,357 valid 050 2.720099e-02 -0.476437
2019-11-05 01:46:22,795 validation loss; R2: 2.694102e-02 -0.472069
2019-11-05 01:46:22,861 epoch 86 lr 5.000000e-04
2019-11-05 01:46:23,561 train 000 2.875227e-02 -0.195495
2019-11-05 01:46:34,343 train 050 2.674692e-02 -0.371830
2019-11-05 01:46:45,127 train 100 2.663637e-02 -0.434318
2019-11-05 01:46:55,977 train 150 2.654368e-02 -0.406198
2019-11-05 01:47:06,788 train 200 2.662637e-02 -0.411272
2019-11-05 01:47:17,663 train 250 2.653856e-02 -0.392623
2019-11-05 01:47:28,290 train 300 2.653923e-02 -0.392542
2019-11-05 01:47:39,111 train 350 2.652889e-02 -0.416289
2019-11-05 01:47:49,758 train 400 2.653205e-02 -0.415797
2019-11-05 01:48:00,339 train 450 2.653476e-02 -0.410516
2019-11-05 01:48:11,132 train 500 2.653392e-02 -0.411792
2019-11-05 01:48:22,015 train 550 2.648081e-02 -0.409142
2019-11-05 01:48:32,933 train 600 2.648961e-02 -0.403258
2019-11-05 01:48:43,781 train 650 2.647305e-02 -0.405754
2019-11-05 01:48:54,579 train 700 2.643773e-02 -0.413687
2019-11-05 01:49:05,131 train 750 2.639570e-02 -0.425718
2019-11-05 01:49:15,585 train 800 2.640581e-02 -0.427067
2019-11-05 01:49:26,249 train 850 2.638754e-02 -0.463206
2019-11-05 01:49:29,467 training loss; R2: 2.640679e-02 -0.462054
2019-11-05 01:49:30,080 valid 000 3.693739e-02 -0.612967
2019-11-05 01:49:40,771 valid 050 3.661049e-02 -0.511149
2019-11-05 01:49:50,322 validation loss; R2: 3.624502e-02 -0.445381
2019-11-05 01:49:50,388 epoch 87 lr 5.000000e-04
2019-11-05 01:49:51,129 train 000 2.678829e-02 -0.145553
2019-11-05 01:50:02,006 train 050 2.607559e-02 -0.448991
2019-11-05 01:50:12,876 train 100 2.594816e-02 -0.474789
2019-11-05 01:50:23,742 train 150 2.604036e-02 -0.451603
2019-11-05 01:50:34,601 train 200 2.633771e-02 -0.440073
2019-11-05 01:50:45,447 train 250 2.631182e-02 -0.450349
2019-11-05 01:50:56,269 train 300 2.631218e-02 -0.441986
2019-11-05 01:51:07,107 train 350 2.627231e-02 -0.435513
2019-11-05 01:51:17,862 train 400 2.628970e-02 -0.447775
2019-11-05 01:51:28,645 train 450 2.630997e-02 -0.442670
2019-11-05 01:51:39,482 train 500 2.631875e-02 -0.449147
2019-11-05 01:51:50,270 train 550 2.636384e-02 -0.441970
2019-11-05 01:52:01,020 train 600 2.636099e-02 -0.429047
2019-11-05 01:52:11,785 train 650 2.636278e-02 -0.425755
2019-11-05 01:52:22,660 train 700 2.634106e-02 -0.427585
2019-11-05 01:52:33,439 train 750 2.633179e-02 -0.437847
2019-11-05 01:52:43,898 train 800 2.634046e-02 -0.435132
2019-11-05 01:52:54,452 train 850 2.635612e-02 -0.431000
2019-11-05 01:52:57,586 training loss; R2: 2.636799e-02 -0.434009
2019-11-05 01:52:58,139 valid 000 2.747989e-02 -1.090642
2019-11-05 01:53:08,721 valid 050 2.734176e-02 -0.423956
2019-11-05 01:53:18,114 validation loss; R2: 2.707789e-02 -0.447225
2019-11-05 01:53:18,187 epoch 88 lr 5.000000e-04
2019-11-05 01:53:18,872 train 000 2.708052e-02 -0.161644
2019-11-05 01:53:29,735 train 050 2.625631e-02 -0.900009
2019-11-05 01:53:40,521 train 100 2.637574e-02 -0.612724
2019-11-05 01:53:51,219 train 150 2.643536e-02 -0.505168
2019-11-05 01:54:01,911 train 200 2.652464e-02 -0.671392
2019-11-05 01:54:12,583 train 250 2.647064e-02 -0.619750
2019-11-05 01:54:23,293 train 300 2.651598e-02 -0.593677
2019-11-05 01:54:33,996 train 350 2.646514e-02 -0.559916
2019-11-05 01:54:44,705 train 400 2.645337e-02 -0.547856
2019-11-05 01:54:55,420 train 450 2.641688e-02 -0.547689
2019-11-05 01:55:06,128 train 500 2.641628e-02 -0.537553
2019-11-05 01:55:16,793 train 550 2.644794e-02 -0.520712
2019-11-05 01:55:27,510 train 600 2.646248e-02 -0.505823
2019-11-05 01:55:38,241 train 650 2.645892e-02 -0.495684
2019-11-05 01:55:48,965 train 700 2.646092e-02 -0.492686
2019-11-05 01:55:59,665 train 750 2.646659e-02 -0.489565
2019-11-05 01:56:10,190 train 800 2.643705e-02 -0.480255
2019-11-05 01:56:20,859 train 850 2.644223e-02 -0.474872
2019-11-05 01:56:24,067 training loss; R2: 2.644511e-02 -0.485456
2019-11-05 01:56:24,688 valid 000 2.730868e-02 -2.990586
2019-11-05 01:56:35,455 valid 050 2.715321e-02 -0.421989
2019-11-05 01:56:45,298 validation loss; R2: 2.700318e-02 -0.572459
2019-11-05 01:56:45,367 epoch 89 lr 5.000000e-04
2019-11-05 01:56:46,079 train 000 2.762506e-02 -0.131943
2019-11-05 01:56:57,140 train 050 2.678408e-02 -0.410348
2019-11-05 01:57:08,292 train 100 2.630071e-02 -0.395299
2019-11-05 01:57:19,299 train 150 2.608893e-02 -0.424164
2019-11-05 01:57:30,432 train 200 2.605128e-02 -0.407173
2019-11-05 01:57:41,584 train 250 2.606638e-02 -0.414348
2019-11-05 01:57:52,612 train 300 2.600553e-02 -0.451935
2019-11-05 01:58:03,776 train 350 2.612935e-02 -0.432926
2019-11-05 01:58:14,797 train 400 2.622230e-02 -0.434625
2019-11-05 01:58:25,716 train 450 2.628511e-02 -0.434480
2019-11-05 01:58:36,792 train 500 2.632112e-02 -0.438781
2019-11-05 01:58:47,749 train 550 2.636906e-02 -0.440785
2019-11-05 01:58:58,719 train 600 2.641088e-02 -0.431979
2019-11-05 01:59:09,566 train 650 2.640774e-02 -0.438238
2019-11-05 01:59:20,404 train 700 2.641718e-02 -0.435763
2019-11-05 01:59:31,123 train 750 2.641004e-02 -0.428720
2019-11-05 01:59:41,608 train 800 2.640895e-02 -0.423792
2019-11-05 01:59:52,164 train 850 2.638760e-02 -0.424824
2019-11-05 01:59:55,335 training loss; R2: 2.639700e-02 -0.424112
2019-11-05 01:59:55,928 valid 000 2.737871e-02 -0.110053
2019-11-05 02:00:06,536 valid 050 2.724411e-02 -0.393943
2019-11-05 02:00:15,944 validation loss; R2: 2.701493e-02 -0.491106
2019-11-05 02:00:16,014 epoch 90 lr 5.000000e-04
2019-11-05 02:00:16,712 train 000 2.811089e-02 -0.318478
2019-11-05 02:00:27,466 train 050 2.703673e-02 -0.384605
2019-11-05 02:00:38,201 train 100 2.662606e-02 -0.405064
2019-11-05 02:00:48,938 train 150 2.637183e-02 -0.431803
2019-11-05 02:00:59,684 train 200 2.649939e-02 -0.417691
2019-11-05 02:01:10,412 train 250 2.642094e-02 -0.407235
2019-11-05 02:01:21,130 train 300 2.643782e-02 -0.403795
2019-11-05 02:01:31,877 train 350 2.637221e-02 -0.411979
2019-11-05 02:01:42,596 train 400 2.634023e-02 -0.409054
2019-11-05 02:01:53,283 train 450 2.628982e-02 -0.397625
2019-11-05 02:02:04,010 train 500 2.630697e-02 -0.390263
2019-11-05 02:02:14,716 train 550 2.633023e-02 -0.381321
2019-11-05 02:02:25,421 train 600 2.636068e-02 -0.378154
2019-11-05 02:02:36,088 train 650 2.636024e-02 -0.393998
2019-11-05 02:02:46,782 train 700 2.634926e-02 -0.395227
2019-11-05 02:02:57,478 train 750 2.637172e-02 -0.407188
2019-11-05 02:03:08,004 train 800 2.639257e-02 -0.408825
2019-11-05 02:03:18,571 train 850 2.638782e-02 -0.473863
2019-11-05 02:03:21,768 training loss; R2: 2.640492e-02 -0.474513
2019-11-05 02:03:22,390 valid 000 2.323730e-02 -0.517239
2019-11-05 02:03:33,217 valid 050 2.674344e-02 -0.518779
2019-11-05 02:03:42,655 validation loss; R2: 2.701315e-02 -0.474522
2019-11-05 02:03:42,737 epoch 91 lr 5.000000e-04
2019-11-05 02:03:43,469 train 000 2.727806e-02 -0.249994
2019-11-05 02:03:54,394 train 050 2.633739e-02 -0.363848
2019-11-05 02:04:05,271 train 100 2.622256e-02 -0.356916
2019-11-05 02:04:16,102 train 150 2.622272e-02 -0.398114
2019-11-05 02:04:26,931 train 200 2.634731e-02 -0.364000
2019-11-05 02:04:37,826 train 250 2.626639e-02 -0.382082
2019-11-05 02:04:48,762 train 300 2.628894e-02 -0.391717
2019-11-05 02:04:59,648 train 350 2.626461e-02 -0.408933
2019-11-05 02:05:10,469 train 400 2.631010e-02 -0.404643
2019-11-05 02:05:21,306 train 450 2.630135e-02 -0.456448
2019-11-05 02:05:32,100 train 500 2.631922e-02 -0.445902
2019-11-05 02:05:42,885 train 550 2.629396e-02 -0.434062
2019-11-05 02:05:53,693 train 600 2.631797e-02 -0.423255
2019-11-05 02:06:04,510 train 650 2.629491e-02 -0.412570
2019-11-05 02:06:15,312 train 700 2.633457e-02 -0.413381
2019-11-05 02:06:25,966 train 750 2.628873e-02 -0.444182
2019-11-05 02:06:36,387 train 800 2.626425e-02 -0.437074
2019-11-05 02:06:46,840 train 850 2.628357e-02 -0.442079
2019-11-05 02:06:50,080 training loss; R2: 2.627160e-02 -0.449216
2019-11-05 02:06:50,631 valid 000 2.752797e-02 -0.161954
2019-11-05 02:07:01,262 valid 050 2.699712e-02 -0.605098
2019-11-05 02:07:10,672 validation loss; R2: 2.716432e-02 -0.524363
2019-11-05 02:07:10,731 epoch 92 lr 5.000000e-04
2019-11-05 02:07:11,406 train 000 2.778810e-02 -0.048146
2019-11-05 02:07:22,290 train 050 2.599768e-02 -0.433515
2019-11-05 02:07:33,114 train 100 2.613123e-02 -0.517955
2019-11-05 02:07:43,902 train 150 2.629606e-02 -0.488543
2019-11-05 02:07:54,738 train 200 2.630831e-02 -0.476914
2019-11-05 02:08:05,515 train 250 2.638653e-02 -0.441509
2019-11-05 02:08:16,362 train 300 2.636825e-02 -0.433476
2019-11-05 02:08:27,193 train 350 2.644326e-02 -0.430895
2019-11-05 02:08:37,995 train 400 2.639867e-02 -0.421366
2019-11-05 02:08:48,742 train 450 2.635296e-02 -0.422107
2019-11-05 02:08:59,475 train 500 2.629043e-02 -0.423803
2019-11-05 02:09:10,211 train 550 2.626088e-02 -0.421509
2019-11-05 02:09:21,013 train 600 2.629782e-02 -0.422263
2019-11-05 02:09:31,784 train 650 2.627330e-02 -0.427558
2019-11-05 02:09:42,536 train 700 2.629603e-02 -0.430625
2019-11-05 02:09:53,303 train 750 2.633824e-02 -0.427116
2019-11-05 02:10:03,740 train 800 2.634101e-02 -0.421587
2019-11-05 02:10:14,130 train 850 2.632934e-02 -0.424674
2019-11-05 02:10:17,183 training loss; R2: 2.630985e-02 -0.424471
2019-11-05 02:10:17,772 valid 000 2.428635e-02 -0.109486
2019-11-05 02:10:28,265 valid 050 2.787595e-02 -0.391452
2019-11-05 02:10:37,607 validation loss; R2: 2.792641e-02 -0.314766
2019-11-05 02:10:37,682 epoch 93 lr 5.000000e-04
2019-11-05 02:10:38,414 train 000 2.894279e-02 -0.393441
2019-11-05 02:10:49,107 train 050 2.634806e-02 -0.438084
2019-11-05 02:10:59,806 train 100 2.628278e-02 -0.450929
2019-11-05 02:11:10,502 train 150 2.635355e-02 -0.471391
2019-11-05 02:11:21,209 train 200 2.625060e-02 -0.449985
2019-11-05 02:11:31,906 train 250 2.635541e-02 -0.441470
2019-11-05 02:11:42,604 train 300 2.631742e-02 -0.428112
2019-11-05 02:11:53,290 train 350 2.636732e-02 -0.423262
2019-11-05 02:12:03,994 train 400 2.631728e-02 -0.437289
2019-11-05 02:12:14,734 train 450 2.630598e-02 -0.420330
2019-11-05 02:12:25,468 train 500 2.629042e-02 -0.414172
2019-11-05 02:12:36,216 train 550 2.625227e-02 -0.402882
2019-11-05 02:12:46,907 train 600 2.622267e-02 -0.398667
2019-11-05 02:12:57,574 train 650 2.619437e-02 -0.425830
2019-11-05 02:13:08,258 train 700 2.620409e-02 -0.422270
2019-11-05 02:13:19,027 train 750 2.623441e-02 -0.423106
2019-11-05 02:13:29,625 train 800 2.621386e-02 -0.415978
2019-11-05 02:13:40,138 train 850 2.625150e-02 -0.412396
2019-11-05 02:13:43,366 training loss; R2: 2.623887e-02 -0.415867
2019-11-05 02:13:43,935 valid 000 2.755091e-02 -0.292507
2019-11-05 02:13:54,687 valid 050 3.072782e-02 -0.229831
2019-11-05 02:14:04,492 validation loss; R2: 3.079553e-02 -0.254640
2019-11-05 02:14:04,560 epoch 94 lr 5.000000e-04
2019-11-05 02:14:05,262 train 000 2.581205e-02 -0.379957
2019-11-05 02:14:16,118 train 050 2.577142e-02 -0.418636
2019-11-05 02:14:26,968 train 100 2.609621e-02 -0.382414
2019-11-05 02:14:37,815 train 150 2.607734e-02 -0.386475
2019-11-05 02:14:48,607 train 200 2.615861e-02 -0.399320
2019-11-05 02:14:59,456 train 250 2.621471e-02 -0.392731
2019-11-05 02:15:10,302 train 300 2.620642e-02 -0.380475
2019-11-05 02:15:21,046 train 350 2.618460e-02 -0.388047
2019-11-05 02:15:31,847 train 400 2.620240e-02 -0.400253
2019-11-05 02:15:42,696 train 450 2.615257e-02 -0.385001
2019-11-05 02:15:53,557 train 500 2.616072e-02 -0.391156
2019-11-05 02:16:04,395 train 550 2.620657e-02 -0.402811
2019-11-05 02:16:15,252 train 600 2.618813e-02 -0.396888
2019-11-05 02:16:26,060 train 650 2.621520e-02 -0.394908
2019-11-05 02:16:36,886 train 700 2.621485e-02 -0.395631
2019-11-05 02:16:47,674 train 750 2.620117e-02 -0.391176
2019-11-05 02:16:58,186 train 800 2.619476e-02 -0.396196
2019-11-05 02:17:08,637 train 850 2.618495e-02 -0.404123
2019-11-05 02:17:11,705 training loss; R2: 2.619249e-02 -0.405561
2019-11-05 02:17:12,313 valid 000 2.594383e-02 -0.648296
2019-11-05 02:17:22,994 valid 050 2.735524e-02 -5.213481
2019-11-05 02:17:32,454 validation loss; R2: 2.713291e-02 -2.982169
2019-11-05 02:17:32,535 epoch 95 lr 5.000000e-04
2019-11-05 02:17:33,276 train 000 2.835541e-02 -0.184783
2019-11-05 02:17:44,184 train 050 2.631031e-02 -0.481646
2019-11-05 02:17:55,101 train 100 2.643668e-02 -0.372493
2019-11-05 02:18:06,008 train 150 2.658524e-02 -0.388671
2019-11-05 02:18:16,879 train 200 2.648253e-02 -0.465115
2019-11-05 02:18:27,794 train 250 2.649393e-02 -0.451069
2019-11-05 02:18:38,610 train 300 2.643277e-02 -0.452154
2019-11-05 02:18:49,515 train 350 2.640903e-02 -0.455040
2019-11-05 02:19:00,345 train 400 2.636414e-02 -0.456996
2019-11-05 02:19:11,191 train 450 2.631235e-02 -0.443246
2019-11-05 02:19:22,034 train 500 2.626447e-02 -0.444731
2019-11-05 02:19:32,908 train 550 2.631620e-02 -0.439173
2019-11-05 02:19:43,779 train 600 2.629693e-02 -0.430319
2019-11-05 02:19:54,629 train 650 2.627399e-02 -0.425491
2019-11-05 02:20:05,496 train 700 2.627152e-02 -0.420778
2019-11-05 02:20:16,345 train 750 2.626425e-02 -0.417851
2019-11-05 02:20:26,899 train 800 2.625996e-02 -0.414219
2019-11-05 02:20:37,373 train 850 2.623380e-02 -0.410563
2019-11-05 02:20:40,456 training loss; R2: 2.623490e-02 -0.409716
2019-11-05 02:20:41,061 valid 000 2.285724e-02 -0.164921
2019-11-05 02:20:51,574 valid 050 2.551482e-02 -0.410258
2019-11-05 02:21:00,848 validation loss; R2: 2.564659e-02 -0.450460
2019-11-05 02:21:00,913 epoch 96 lr 5.000000e-04
2019-11-05 02:21:01,612 train 000 2.565431e-02 -0.160997
2019-11-05 02:21:12,285 train 050 2.607939e-02 -0.456179
2019-11-05 02:21:22,954 train 100 2.599825e-02 -0.423165
2019-11-05 02:21:33,577 train 150 2.619503e-02 -0.442696
2019-11-05 02:21:44,234 train 200 2.619995e-02 -0.435207
2019-11-05 02:21:54,887 train 250 2.619542e-02 -0.416626
2019-11-05 02:22:05,540 train 300 2.619003e-02 -0.469872
2019-11-05 02:22:16,162 train 350 2.618698e-02 -0.461925
2019-11-05 02:22:26,809 train 400 2.616688e-02 -0.457245
2019-11-05 02:22:37,435 train 450 2.616582e-02 -0.448263
2019-11-05 02:22:48,093 train 500 2.618854e-02 -0.439374
2019-11-05 02:22:58,723 train 550 2.615506e-02 -0.433936
2019-11-05 02:23:09,358 train 600 2.616276e-02 -0.437138
2019-11-05 02:23:19,974 train 650 2.619088e-02 -0.428197
2019-11-05 02:23:30,652 train 700 2.620248e-02 -0.418115
2019-11-05 02:23:41,319 train 750 2.618780e-02 -0.413390
2019-11-05 02:23:51,965 train 800 2.618100e-02 -0.431858
2019-11-05 02:24:02,427 train 850 2.617447e-02 -0.436942
2019-11-05 02:24:05,577 training loss; R2: 2.616404e-02 -0.437470
2019-11-05 02:24:06,176 valid 000 2.528274e-02 -0.698106
2019-11-05 02:24:16,784 valid 050 2.693029e-02 -0.505239
2019-11-05 02:24:26,223 validation loss; R2: 2.661164e-02 -0.559269
2019-11-05 02:24:26,303 epoch 97 lr 5.000000e-04
2019-11-05 02:24:27,036 train 000 2.472762e-02 -0.458906
2019-11-05 02:24:37,839 train 050 2.561765e-02 -0.512829
2019-11-05 02:24:48,646 train 100 2.605600e-02 -0.485094
2019-11-05 02:24:59,448 train 150 2.598893e-02 -0.447269
2019-11-05 02:25:10,265 train 200 2.601373e-02 -0.452529
2019-11-05 02:25:21,058 train 250 2.606486e-02 -0.442521
2019-11-05 02:25:31,850 train 300 2.616394e-02 -0.453735
2019-11-05 02:25:42,678 train 350 2.617365e-02 -0.443519
2019-11-05 02:25:53,513 train 400 2.615298e-02 -0.449571
2019-11-05 02:26:04,380 train 450 2.620356e-02 -0.439383
2019-11-05 02:26:15,212 train 500 2.621767e-02 -0.432917
2019-11-05 02:26:26,065 train 550 2.622042e-02 -0.444858
2019-11-05 02:26:36,908 train 600 2.618200e-02 -0.459427
2019-11-05 02:26:47,728 train 650 2.621235e-02 -0.450717
2019-11-05 02:26:58,555 train 700 2.617108e-02 -0.442379
2019-11-05 02:27:09,380 train 750 2.616771e-02 -0.440683
2019-11-05 02:27:20,011 train 800 2.618191e-02 -0.444039
2019-11-05 02:27:30,486 train 850 2.618416e-02 -0.438075
2019-11-05 02:27:33,643 training loss; R2: 2.617900e-02 -0.434382
2019-11-05 02:27:34,232 valid 000 2.487239e-02 -0.023787
2019-11-05 02:27:44,719 valid 050 2.440615e-02 -0.386232
2019-11-05 02:27:53,978 validation loss; R2: 2.445670e-02 -0.420999
2019-11-05 02:27:54,060 epoch 98 lr 5.000000e-04
2019-11-05 02:27:54,752 train 000 2.609791e-02 -0.803466
2019-11-05 02:28:05,493 train 050 2.652605e-02 -0.398124
2019-11-05 02:28:16,152 train 100 2.626339e-02 -0.332622
2019-11-05 02:28:26,811 train 150 2.625684e-02 -0.372556
2019-11-05 02:28:37,483 train 200 2.624368e-02 -0.378164
2019-11-05 02:28:48,246 train 250 2.614739e-02 -0.386053
2019-11-05 02:28:59,046 train 300 2.620042e-02 -0.395359
2019-11-05 02:29:09,832 train 350 2.616688e-02 -0.393845
2019-11-05 02:29:20,627 train 400 2.620756e-02 -0.403877
2019-11-05 02:29:31,435 train 450 2.622136e-02 -0.396130
2019-11-05 02:29:42,218 train 500 2.623363e-02 -0.386492
2019-11-05 02:29:53,003 train 550 2.628347e-02 -0.375570
2019-11-05 02:30:03,862 train 600 2.628658e-02 -0.374719
2019-11-05 02:30:14,615 train 650 2.624031e-02 -0.380362
2019-11-05 02:30:25,441 train 700 2.625633e-02 -0.396477
2019-11-05 02:30:36,279 train 750 2.625419e-02 -0.395492
2019-11-05 02:30:47,017 train 800 2.626873e-02 -3.423926
2019-11-05 02:30:57,610 train 850 2.623728e-02 -3.248190
2019-11-05 02:31:00,722 training loss; R2: 2.624642e-02 -3.197530
2019-11-05 02:31:01,390 valid 000 2.692386e-02 -0.249962
2019-11-05 02:31:11,929 valid 050 2.426817e-02 -0.483261
2019-11-05 02:31:21,763 validation loss; R2: 2.415446e-02 -0.459004
2019-11-05 02:31:21,832 epoch 99 lr 5.000000e-04
2019-11-05 02:31:22,573 train 000 2.751103e-02 -0.464026
2019-11-05 02:31:33,396 train 050 2.621642e-02 -0.437833
2019-11-05 02:31:44,225 train 100 2.613625e-02 -0.378881
2019-11-05 02:31:55,134 train 150 2.617118e-02 -0.347521
2019-11-05 02:32:06,024 train 200 2.616177e-02 -0.362116
2019-11-05 02:32:16,767 train 250 2.612801e-02 -0.367128
2019-11-05 02:32:27,603 train 300 2.605291e-02 -0.368006
2019-11-05 02:32:38,408 train 350 2.606498e-02 -0.380205
2019-11-05 02:32:49,345 train 400 2.606580e-02 -0.372321
2019-11-05 02:33:00,066 train 450 2.607430e-02 -0.376178
2019-11-05 02:33:10,898 train 500 2.613818e-02 -0.386939
2019-11-05 02:33:21,703 train 550 2.613908e-02 -0.387839
2019-11-05 02:33:32,587 train 600 2.619206e-02 -0.397547
2019-11-05 02:33:43,323 train 650 2.618037e-02 -0.398661
2019-11-05 02:33:54,038 train 700 2.616701e-02 -0.432407
2019-11-05 02:34:04,728 train 750 2.613441e-02 -0.432490
2019-11-05 02:34:15,509 train 800 2.612724e-02 -0.436365
2019-11-05 02:34:26,089 train 850 2.609253e-02 -0.437140
2019-11-05 02:34:29,315 training loss; R2: 2.608543e-02 -0.434857
2019-11-05 02:34:29,903 valid 000 2.478640e-02 -0.084006
2019-11-05 02:34:40,598 valid 050 2.674792e-02 -0.393874
2019-11-05 02:34:50,170 validation loss; R2: 2.693080e-02 -0.431599
2019-11-05 02:34:50,244 epoch 100 lr 5.000000e-04
2019-11-05 02:34:50,978 train 000 2.895897e-02 -0.138112
2019-11-05 02:35:01,797 train 050 2.616984e-02 -0.364395
2019-11-05 02:35:12,657 train 100 2.622702e-02 -0.445081
2019-11-05 02:35:23,478 train 150 2.593891e-02 -0.474187
2019-11-05 02:35:34,308 train 200 2.601933e-02 -0.451698
2019-11-05 02:35:45,077 train 250 2.600398e-02 -0.443561
2019-11-05 02:35:55,913 train 300 2.598045e-02 -0.429824
2019-11-05 02:36:06,585 train 350 2.603390e-02 -0.424391
2019-11-05 02:36:17,341 train 400 2.601363e-02 -0.418998
2019-11-05 02:36:28,158 train 450 2.604061e-02 -0.409663
2019-11-05 02:36:38,978 train 500 2.597697e-02 -0.407854
2019-11-05 02:36:49,756 train 550 2.593241e-02 -0.406159
2019-11-05 02:37:00,499 train 600 2.593763e-02 -0.414091
2019-11-05 02:37:11,229 train 650 2.595439e-02 -0.413648
2019-11-05 02:37:21,991 train 700 2.598973e-02 -0.404824
2019-11-05 02:37:32,821 train 750 2.599725e-02 -0.401186
2019-11-05 02:37:43,673 train 800 2.598627e-02 -0.396637
2019-11-05 02:37:54,122 train 850 2.595468e-02 -0.402706
2019-11-05 02:37:57,168 training loss; R2: 2.595590e-02 -0.403267
2019-11-05 02:37:57,751 valid 000 2.702518e-02 -0.217116
2019-11-05 02:38:08,261 valid 050 2.753958e-02 -0.346784
2019-11-05 02:38:17,639 validation loss; R2: 2.766777e-02 -0.328170
2019-11-05 02:38:17,705 epoch 101 lr 5.000000e-04
2019-11-05 02:38:18,439 train 000 2.872578e-02 -0.066628
2019-11-05 02:38:29,187 train 050 2.553536e-02 -0.517969
2019-11-05 02:38:39,939 train 100 2.554503e-02 -0.447713
2019-11-05 02:38:50,670 train 150 2.573883e-02 -0.426720
2019-11-05 02:39:01,454 train 200 2.581322e-02 -0.420293
2019-11-05 02:39:12,227 train 250 2.570413e-02 -0.457424
2019-11-05 02:39:22,950 train 300 2.566865e-02 -0.446952
2019-11-05 02:39:33,694 train 350 2.564684e-02 -0.448958
2019-11-05 02:39:44,468 train 400 2.564538e-02 -0.467114
2019-11-05 02:39:55,176 train 450 2.571005e-02 -0.459783
2019-11-05 02:40:05,932 train 500 2.573686e-02 -0.450710
2019-11-05 02:40:16,637 train 550 2.576142e-02 -0.446183
2019-11-05 02:40:27,371 train 600 2.579746e-02 -0.498074
2019-11-05 02:40:38,136 train 650 2.584408e-02 -0.483577
2019-11-05 02:40:48,885 train 700 2.586493e-02 -0.477495
2019-11-05 02:40:59,587 train 750 2.584334e-02 -0.471264
2019-11-05 02:41:10,311 train 800 2.584775e-02 -0.464192
2019-11-05 02:41:20,950 train 850 2.583690e-02 -0.464395
2019-11-05 02:41:24,031 training loss; R2: 2.582401e-02 -0.471477
2019-11-05 02:41:24,634 valid 000 2.760571e-02 -0.279567
2019-11-05 02:41:35,164 valid 050 2.625777e-02 -0.248458
2019-11-05 02:41:44,777 validation loss; R2: 2.650934e-02 -0.299236
2019-11-05 02:41:44,846 epoch 102 lr 5.000000e-04
2019-11-05 02:41:45,597 train 000 2.463444e-02 -0.220106
2019-11-05 02:41:56,434 train 050 2.601180e-02 -0.367589
2019-11-05 02:42:07,344 train 100 2.572491e-02 -0.388460
2019-11-05 02:42:18,208 train 150 2.592732e-02 -0.411654
2019-11-05 02:42:29,017 train 200 2.573509e-02 -0.458525
2019-11-05 02:42:39,700 train 250 2.574550e-02 -0.444740
2019-11-05 02:42:50,462 train 300 2.576919e-02 -0.441664
2019-11-05 02:43:01,207 train 350 2.582680e-02 -0.448732
2019-11-05 02:43:11,995 train 400 2.585209e-02 -0.448582
2019-11-05 02:43:22,824 train 450 2.582502e-02 -0.442576
2019-11-05 02:43:33,622 train 500 2.589197e-02 -0.430117
2019-11-05 02:43:44,474 train 550 2.591895e-02 -0.500607
2019-11-05 02:43:55,265 train 600 2.590317e-02 -0.488202
2019-11-05 02:44:06,047 train 650 2.585856e-02 -0.480476
2019-11-05 02:44:16,887 train 700 2.584476e-02 -0.485555
2019-11-05 02:44:27,701 train 750 2.582540e-02 -0.489432
2019-11-05 02:44:38,549 train 800 2.583041e-02 -0.483083
2019-11-05 02:44:49,176 train 850 2.582010e-02 -0.477831
2019-11-05 02:44:52,284 training loss; R2: 2.580506e-02 -0.477319
2019-11-05 02:44:52,900 valid 000 2.444958e-02 -1.035693
2019-11-05 02:45:03,394 valid 050 2.434350e-02 -0.393219
2019-11-05 02:45:13,137 validation loss; R2: 2.414631e-02 -0.388443
2019-11-05 02:45:13,209 epoch 103 lr 5.000000e-04
2019-11-05 02:45:13,992 train 000 2.697589e-02 -0.636775
2019-11-05 02:45:24,850 train 050 2.571685e-02 -0.392686
2019-11-05 02:45:35,635 train 100 2.578108e-02 -0.419962
2019-11-05 02:45:46,358 train 150 2.565514e-02 -0.421629
2019-11-05 02:45:57,051 train 200 2.565871e-02 -0.422631
2019-11-05 02:46:07,767 train 250 2.570768e-02 -0.451053
2019-11-05 02:46:18,535 train 300 2.556100e-02 -0.536471
2019-11-05 02:46:29,264 train 350 2.560298e-02 -0.506269
2019-11-05 02:46:39,989 train 400 2.563670e-02 -0.499101
2019-11-05 02:46:50,713 train 450 2.562423e-02 -0.517816
2019-11-05 02:47:01,436 train 500 2.562221e-02 -0.518020
2019-11-05 02:47:12,135 train 550 2.571463e-02 -0.518483
2019-11-05 02:47:22,871 train 600 2.576184e-02 -0.505262
2019-11-05 02:47:33,577 train 650 2.577137e-02 -0.502739
2019-11-05 02:47:44,290 train 700 2.577025e-02 -0.491555
2019-11-05 02:47:55,039 train 750 2.577647e-02 -0.486486
2019-11-05 02:48:05,775 train 800 2.575211e-02 -0.481010
2019-11-05 02:48:16,373 train 850 2.575531e-02 -0.473093
2019-11-05 02:48:19,543 training loss; R2: 2.575174e-02 -0.479826
2019-11-05 02:48:20,160 valid 000 2.488964e-02 -0.190571
2019-11-05 02:48:30,664 valid 050 2.544795e-02 -0.361172
2019-11-05 02:48:40,359 validation loss; R2: 2.566768e-02 -0.410836
2019-11-05 02:48:40,428 epoch 104 lr 5.000000e-04
2019-11-05 02:48:41,172 train 000 2.598838e-02 -0.386483
2019-11-05 02:48:52,139 train 050 2.566258e-02 -0.439656
2019-11-05 02:49:03,047 train 100 2.581544e-02 -0.397400
2019-11-05 02:49:13,895 train 150 2.589458e-02 -0.418839
2019-11-05 02:49:24,718 train 200 2.579412e-02 -0.417936
2019-11-05 02:49:35,562 train 250 2.586943e-02 -0.420266
2019-11-05 02:49:46,383 train 300 2.583636e-02 -0.424376
2019-11-05 02:49:57,230 train 350 2.581061e-02 -0.429179
2019-11-05 02:50:08,051 train 400 2.575823e-02 -0.430209
2019-11-05 02:50:18,961 train 450 2.573070e-02 -0.447266
2019-11-05 02:50:29,838 train 500 2.577789e-02 -0.445964
2019-11-05 02:50:40,722 train 550 2.578022e-02 -0.441882
2019-11-05 02:50:51,495 train 600 2.583618e-02 -0.434229
2019-11-05 02:51:02,291 train 650 2.585451e-02 -0.427921
2019-11-05 02:51:13,165 train 700 2.582789e-02 -0.420276
2019-11-05 02:51:24,052 train 750 2.579916e-02 -0.416438
2019-11-05 02:51:34,882 train 800 2.574770e-02 -0.422054
2019-11-05 02:51:45,548 train 850 2.574647e-02 -0.425880
2019-11-05 02:51:48,781 training loss; R2: 2.574062e-02 -0.422924
2019-11-05 02:51:49,362 valid 000 2.775788e-02 -0.058881
2019-11-05 02:51:59,851 valid 050 2.635924e-02 -0.494263
2019-11-05 02:52:09,509 validation loss; R2: 2.645274e-02 -0.466726
2019-11-05 02:52:09,590 epoch 105 lr 5.000000e-04
2019-11-05 02:52:10,312 train 000 2.438987e-02 -0.911565
2019-11-05 02:52:21,031 train 050 2.594755e-02 -0.606781
2019-11-05 02:52:31,857 train 100 2.566307e-02 -0.489593
2019-11-05 02:52:42,712 train 150 2.570342e-02 -0.468289
2019-11-05 02:52:53,469 train 200 2.566936e-02 -0.490153
2019-11-05 02:53:04,224 train 250 2.565979e-02 -0.447461
2019-11-05 02:53:14,931 train 300 2.559882e-02 -0.415984
2019-11-05 02:53:25,732 train 350 2.564637e-02 -0.411380
2019-11-05 02:53:36,547 train 400 2.561554e-02 -0.409939
2019-11-05 02:53:47,338 train 450 2.564063e-02 -0.406847
2019-11-05 02:53:58,124 train 500 2.564179e-02 -0.408799
2019-11-05 02:54:08,901 train 550 2.568166e-02 -0.403056
2019-11-05 02:54:19,709 train 600 2.566974e-02 -0.395037
2019-11-05 02:54:30,494 train 650 2.567914e-02 -0.393836
2019-11-05 02:54:41,319 train 700 2.571608e-02 -0.395628
2019-11-05 02:54:52,116 train 750 2.574814e-02 -0.393762
2019-11-05 02:55:02,860 train 800 2.576683e-02 -0.394994
2019-11-05 02:55:13,412 train 850 2.575505e-02 -0.393345
2019-11-05 02:55:16,584 training loss; R2: 2.574382e-02 -0.397132
2019-11-05 02:55:17,189 valid 000 2.581708e-02 -0.225155
2019-11-05 02:55:27,944 valid 050 2.667998e-02 -0.481075
2019-11-05 02:55:37,374 validation loss; R2: 2.658813e-02 -0.463928
2019-11-05 02:55:37,444 epoch 106 lr 5.000000e-04
2019-11-05 02:55:38,134 train 000 2.526277e-02 -0.998807
2019-11-05 02:55:48,867 train 050 2.631627e-02 -0.452711
2019-11-05 02:55:59,580 train 100 2.575973e-02 -0.405440
2019-11-05 02:56:10,298 train 150 2.579549e-02 -0.425299
2019-11-05 02:56:20,962 train 200 2.585669e-02 -0.452601
2019-11-05 02:56:31,646 train 250 2.577249e-02 -0.431275
2019-11-05 02:56:42,308 train 300 2.575246e-02 -0.437477
2019-11-05 02:56:52,967 train 350 2.572147e-02 -0.452987
2019-11-05 02:57:03,647 train 400 2.572548e-02 -0.455873
2019-11-05 02:57:14,287 train 450 2.573393e-02 -0.460958
2019-11-05 02:57:24,952 train 500 2.568651e-02 -0.452820
2019-11-05 02:57:35,659 train 550 2.564831e-02 -0.461990
2019-11-05 02:57:46,376 train 600 2.567462e-02 -0.447706
2019-11-05 02:57:57,080 train 650 2.568216e-02 -0.446923
2019-11-05 02:58:07,747 train 700 2.568179e-02 -0.449346
2019-11-05 02:58:18,441 train 750 2.572401e-02 -0.444117
2019-11-05 02:58:29,152 train 800 2.573319e-02 -0.445405
2019-11-05 02:58:39,788 train 850 2.570789e-02 -0.444003
2019-11-05 02:58:42,902 training loss; R2: 2.569271e-02 -0.442947
2019-11-05 02:58:43,505 valid 000 2.140562e-02 -2.520474
2019-11-05 02:58:54,058 valid 050 2.365281e-02 -0.486201
2019-11-05 02:59:03,722 validation loss; R2: 2.359308e-02 -0.753290
2019-11-05 02:59:03,791 epoch 107 lr 5.000000e-04
2019-11-05 02:59:04,524 train 000 2.810429e-02 -0.330493
2019-11-05 02:59:15,327 train 050 2.574436e-02 -0.408348
2019-11-05 02:59:26,059 train 100 2.585497e-02 -0.410159
2019-11-05 02:59:36,758 train 150 2.599409e-02 -0.403154
2019-11-05 02:59:47,525 train 200 2.594519e-02 -0.432587
2019-11-05 02:59:58,357 train 250 2.577120e-02 -0.429303
2019-11-05 03:00:09,058 train 300 2.576588e-02 -0.422596
2019-11-05 03:00:19,719 train 350 2.575340e-02 -0.440673
2019-11-05 03:00:30,427 train 400 2.574283e-02 -0.438637
2019-11-05 03:00:41,204 train 450 2.576112e-02 -0.422923
2019-11-05 03:00:51,971 train 500 2.571828e-02 -0.426926
2019-11-05 03:01:02,682 train 550 2.569507e-02 -0.421157
2019-11-05 03:01:13,349 train 600 2.569795e-02 -0.417983
2019-11-05 03:01:24,104 train 650 2.568877e-02 -0.415234
2019-11-05 03:01:34,895 train 700 2.567757e-02 -0.417641
2019-11-05 03:01:45,644 train 750 2.567139e-02 -0.413772
2019-11-05 03:01:56,485 train 800 2.563407e-02 -0.416027
2019-11-05 03:02:07,081 train 850 2.564085e-02 -0.427519
2019-11-05 03:02:10,353 training loss; R2: 2.564549e-02 -0.426770
2019-11-05 03:02:10,954 valid 000 2.668499e-02 -0.165557
2019-11-05 03:02:21,666 valid 050 2.576476e-02 -0.455141
2019-11-05 03:02:31,434 validation loss; R2: 2.578484e-02 -0.782960
2019-11-05 03:02:31,504 epoch 108 lr 5.000000e-04
2019-11-05 03:02:32,237 train 000 2.459517e-02 -0.164797
2019-11-05 03:02:42,998 train 050 2.551547e-02 -0.333027
2019-11-05 03:02:53,749 train 100 2.589004e-02 -0.316140
2019-11-05 03:03:04,504 train 150 2.567113e-02 -0.327066
2019-11-05 03:03:15,305 train 200 2.559161e-02 -0.366513
2019-11-05 03:03:26,045 train 250 2.550458e-02 -0.360116
2019-11-05 03:03:36,770 train 300 2.547609e-02 -0.434858
2019-11-05 03:03:47,470 train 350 2.552060e-02 -0.435219
2019-11-05 03:03:58,210 train 400 2.545671e-02 -0.425253
2019-11-05 03:04:08,965 train 450 2.548051e-02 -0.470544
2019-11-05 03:04:19,700 train 500 2.552553e-02 -0.465026
2019-11-05 03:04:30,397 train 550 2.553189e-02 -0.461765
2019-11-05 03:04:41,149 train 600 2.556637e-02 -0.476424
2019-11-05 03:04:51,866 train 650 2.558589e-02 -0.469321
2019-11-05 03:05:02,593 train 700 2.557124e-02 -0.466665
2019-11-05 03:05:13,370 train 750 2.554252e-02 -0.478457
2019-11-05 03:05:24,080 train 800 2.555015e-02 -0.480420
2019-11-05 03:05:34,629 train 850 2.556851e-02 -0.497119
2019-11-05 03:05:37,714 training loss; R2: 2.555583e-02 -0.495283
2019-11-05 03:05:38,338 valid 000 2.354379e-02 -0.300514
2019-11-05 03:05:49,061 valid 050 2.322820e-02 -0.820123
2019-11-05 03:05:58,596 validation loss; R2: 2.319821e-02 -0.661082
2019-11-05 03:05:58,666 epoch 109 lr 5.000000e-04
2019-11-05 03:05:59,402 train 000 3.040957e-02 -0.300045
2019-11-05 03:06:10,301 train 050 2.609640e-02 -0.465314
2019-11-05 03:06:21,217 train 100 2.566251e-02 -0.467214
2019-11-05 03:06:32,161 train 150 2.550430e-02 -0.480660
2019-11-05 03:06:43,074 train 200 2.528636e-02 -0.530410
2019-11-05 03:06:53,980 train 250 2.537583e-02 -0.511737
2019-11-05 03:07:04,890 train 300 2.551589e-02 -0.511133
2019-11-05 03:07:15,765 train 350 2.547962e-02 -0.514810
2019-11-05 03:07:26,539 train 400 2.545487e-02 -0.494215
2019-11-05 03:07:37,379 train 450 2.543761e-02 -0.501837
2019-11-05 03:07:48,189 train 500 2.546968e-02 -0.487248
2019-11-05 03:07:58,986 train 550 2.543952e-02 -0.499132
2019-11-05 03:08:09,827 train 600 2.543870e-02 -0.491507
2019-11-05 03:08:20,638 train 650 2.545360e-02 -0.480466
2019-11-05 03:08:31,480 train 700 2.548021e-02 -0.466607
2019-11-05 03:08:42,264 train 750 2.547490e-02 -0.477583
2019-11-05 03:08:52,890 train 800 2.547436e-02 -0.479116
2019-11-05 03:09:03,427 train 850 2.547028e-02 -0.632622
2019-11-05 03:09:06,551 training loss; R2: 2.547219e-02 -0.627558
2019-11-05 03:09:07,106 valid 000 2.235869e-02 -0.547524
2019-11-05 03:09:17,609 valid 050 2.709406e-02 -0.556943
2019-11-05 03:09:27,068 validation loss; R2: 2.701378e-02 -0.471070
2019-11-05 03:09:27,135 epoch 110 lr 5.000000e-04
2019-11-05 03:09:27,827 train 000 2.795609e-02 -0.028969
2019-11-05 03:09:38,771 train 050 2.564216e-02 -0.458677
2019-11-05 03:09:49,653 train 100 2.530193e-02 -0.456657
2019-11-05 03:10:00,488 train 150 2.530613e-02 -0.460879
2019-11-05 03:10:11,324 train 200 2.534040e-02 -0.441388
2019-11-05 03:10:22,161 train 250 2.536116e-02 -0.418689
2019-11-05 03:10:33,063 train 300 2.548877e-02 -0.397735
2019-11-05 03:10:44,110 train 350 2.555102e-02 -0.406035
2019-11-05 03:10:55,030 train 400 2.551104e-02 -0.431277
2019-11-05 03:11:06,058 train 450 2.561391e-02 -0.548696
2019-11-05 03:11:16,845 train 500 2.565236e-02 -0.534690
2019-11-05 03:11:27,639 train 550 2.565963e-02 -0.521932
2019-11-05 03:11:38,485 train 600 2.568561e-02 -0.515074
2019-11-05 03:11:49,278 train 650 2.567712e-02 -0.500083
2019-11-05 03:11:59,955 train 700 2.567618e-02 -0.497786
2019-11-05 03:12:10,687 train 750 2.566257e-02 -0.489949
2019-11-05 03:12:21,521 train 800 2.567165e-02 -0.491539
2019-11-05 03:12:32,042 train 850 2.567921e-02 -0.491380
2019-11-05 03:12:35,230 training loss; R2: 2.565547e-02 -0.491006
2019-11-05 03:12:35,794 valid 000 2.755019e-02 -0.177798
2019-11-05 03:12:46,293 valid 050 2.483116e-02 -0.470125
2019-11-05 03:12:55,692 validation loss; R2: 2.441274e-02 -0.481939
2019-11-05 03:12:55,772 epoch 111 lr 5.000000e-04
2019-11-05 03:12:56,507 train 000 2.698360e-02 -0.593038
2019-11-05 03:13:07,288 train 050 2.567725e-02 -0.618970
2019-11-05 03:13:18,044 train 100 2.547369e-02 -0.513305
2019-11-05 03:13:28,654 train 150 2.540116e-02 -0.461155
2019-11-05 03:13:39,257 train 200 2.544433e-02 -0.440578
2019-11-05 03:13:49,851 train 250 2.538771e-02 -0.490825
2019-11-05 03:14:00,424 train 300 2.537062e-02 -0.487358
2019-11-05 03:14:10,963 train 350 2.537322e-02 -0.471454
2019-11-05 03:14:21,784 train 400 2.543336e-02 -0.485329
2019-11-05 03:14:32,358 train 450 2.545233e-02 -0.476708
2019-11-05 03:14:43,015 train 500 2.544950e-02 -0.477773
2019-11-05 03:14:53,642 train 550 2.541807e-02 -0.483327
2019-11-05 03:15:04,247 train 600 2.541210e-02 -0.475833
2019-11-05 03:15:14,800 train 650 2.544190e-02 -0.486402
2019-11-05 03:15:25,371 train 700 2.545902e-02 -0.479407
2019-11-05 03:15:35,945 train 750 2.544849e-02 -0.468650
2019-11-05 03:15:46,506 train 800 2.542943e-02 -0.471967
2019-11-05 03:15:57,060 train 850 2.546503e-02 -0.464123
2019-11-05 03:16:00,229 training loss; R2: 2.546544e-02 -0.467973
2019-11-05 03:16:00,791 valid 000 2.677784e-02 -0.320962
2019-11-05 03:16:11,163 valid 050 2.587916e-02 -0.587066
2019-11-05 03:16:20,519 validation loss; R2: 2.604212e-02 -0.525520
2019-11-05 03:16:20,586 epoch 112 lr 5.000000e-04
2019-11-05 03:16:21,316 train 000 2.517228e-02 -0.428411
2019-11-05 03:16:32,269 train 050 2.535566e-02 -0.341106
2019-11-05 03:16:43,254 train 100 2.494074e-02 -0.362011
2019-11-05 03:16:54,184 train 150 2.508096e-02 -0.358346
2019-11-05 03:17:05,049 train 200 2.512558e-02 -0.366864
2019-11-05 03:17:15,920 train 250 2.523311e-02 -0.371965
2019-11-05 03:17:26,741 train 300 2.528478e-02 -0.408369
2019-11-05 03:17:37,578 train 350 2.530797e-02 -0.411569
2019-11-05 03:17:48,376 train 400 2.530850e-02 -0.408353
2019-11-05 03:17:59,140 train 450 2.534316e-02 -0.412061
2019-11-05 03:18:09,804 train 500 2.535384e-02 -0.407678
2019-11-05 03:18:20,428 train 550 2.540513e-02 -0.413753
2019-11-05 03:18:31,086 train 600 2.544355e-02 -0.419717
2019-11-05 03:18:41,720 train 650 2.549266e-02 -0.419685
2019-11-05 03:18:52,377 train 700 2.549322e-02 -0.424079
2019-11-05 03:19:02,965 train 750 2.552358e-02 -0.434732
2019-11-05 03:19:13,646 train 800 2.552672e-02 -0.429837
2019-11-05 03:19:24,283 train 850 2.549973e-02 -0.433509
2019-11-05 03:19:27,364 training loss; R2: 2.550586e-02 -0.430030
2019-11-05 03:19:28,000 valid 000 2.326313e-02 -0.281321
2019-11-05 03:19:38,339 valid 050 2.299537e-02 -0.343655
2019-11-05 03:19:48,088 validation loss; R2: 2.298808e-02 -0.354271
2019-11-05 03:19:48,165 epoch 113 lr 5.000000e-04
2019-11-05 03:19:48,872 train 000 2.495602e-02 -0.999091
2019-11-05 03:19:59,825 train 050 2.534783e-02 -0.595579
2019-11-05 03:20:10,608 train 100 2.550561e-02 -0.470811
2019-11-05 03:20:21,422 train 150 2.561372e-02 -0.567626
2019-11-05 03:20:32,237 train 200 2.563602e-02 -0.531998
2019-11-05 03:20:42,997 train 250 2.558302e-02 -0.530312
2019-11-05 03:20:53,760 train 300 2.551900e-02 -0.522028
2019-11-05 03:21:04,549 train 350 2.556640e-02 -0.565027
2019-11-05 03:21:15,302 train 400 2.555645e-02 -0.538938
2019-11-05 03:21:26,054 train 450 2.554271e-02 -0.517308
2019-11-05 03:21:36,839 train 500 2.553310e-02 -0.496698
2019-11-05 03:21:47,582 train 550 2.548454e-02 -0.499387
2019-11-05 03:21:58,435 train 600 2.548916e-02 -0.494798
2019-11-05 03:22:09,198 train 650 2.545815e-02 -0.492606
2019-11-05 03:22:19,981 train 700 2.545297e-02 -0.549104
2019-11-05 03:22:30,762 train 750 2.545858e-02 -0.535100
2019-11-05 03:22:41,527 train 800 2.544497e-02 -0.523645
2019-11-05 03:22:52,295 train 850 2.545289e-02 -0.515721
2019-11-05 03:22:55,386 training loss; R2: 2.544664e-02 -0.512236
2019-11-05 03:22:55,955 valid 000 2.432819e-02 -0.285511
2019-11-05 03:23:06,698 valid 050 2.487138e-02 -0.416794
2019-11-05 03:23:16,061 validation loss; R2: 2.476050e-02 -0.425538
2019-11-05 03:23:16,126 epoch 114 lr 5.000000e-04
2019-11-05 03:23:16,845 train 000 2.595393e-02 -1.322579
2019-11-05 03:23:27,584 train 050 2.559872e-02 -0.422242
2019-11-05 03:23:38,380 train 100 2.576307e-02 -0.391981
2019-11-05 03:23:49,162 train 150 2.549880e-02 -2.928256
2019-11-05 03:23:59,936 train 200 2.540443e-02 -2.287641
2019-11-05 03:24:10,676 train 250 2.548411e-02 -2.109326
2019-11-05 03:24:21,416 train 300 2.548328e-02 -1.834219
2019-11-05 03:24:32,104 train 350 2.547069e-02 -1.633851
2019-11-05 03:24:42,763 train 400 2.536539e-02 -1.549748
2019-11-05 03:24:53,483 train 450 2.537402e-02 -1.435356
2019-11-05 03:25:04,186 train 500 2.536573e-02 -1.329877
2019-11-05 03:25:14,898 train 550 2.535730e-02 -1.247388
2019-11-05 03:25:25,650 train 600 2.535501e-02 -1.182940
2019-11-05 03:25:36,419 train 650 2.530733e-02 -1.132959
2019-11-05 03:25:47,185 train 700 2.529927e-02 -1.081395
2019-11-05 03:25:57,958 train 750 2.527273e-02 -1.055148
2019-11-05 03:26:08,676 train 800 2.525330e-02 -1.065491
2019-11-05 03:26:19,429 train 850 2.528753e-02 -1.019036
2019-11-05 03:26:22,576 training loss; R2: 2.528080e-02 -1.018950
2019-11-05 03:26:23,195 valid 000 2.002378e-02 -1.661430
2019-11-05 03:26:33,719 valid 050 2.389970e-02 -0.549343
2019-11-05 03:26:43,428 validation loss; R2: 2.364869e-02 -0.997659
2019-11-05 03:26:43,497 epoch 115 lr 5.000000e-04
2019-11-05 03:26:44,301 train 000 2.201478e-02 0.019322
2019-11-05 03:26:55,081 train 050 2.543563e-02 -0.464579
2019-11-05 03:27:05,876 train 100 2.547256e-02 -0.480918
2019-11-05 03:27:16,637 train 150 2.558006e-02 -1.279500
2019-11-05 03:27:27,361 train 200 2.553641e-02 -1.051844
2019-11-05 03:27:38,166 train 250 2.545048e-02 -0.916504
2019-11-05 03:27:48,922 train 300 2.550730e-02 -0.839721
2019-11-05 03:27:59,658 train 350 2.557785e-02 -0.795479
2019-11-05 03:28:10,371 train 400 2.558573e-02 -0.771726
2019-11-05 03:28:21,064 train 450 2.554816e-02 -0.733201
2019-11-05 03:28:31,833 train 500 2.547666e-02 -0.703401
2019-11-05 03:28:42,687 train 550 2.547384e-02 -0.674598
2019-11-05 03:28:53,380 train 600 2.543338e-02 -0.653427
2019-11-05 03:29:04,119 train 650 2.542137e-02 -0.646513
2019-11-05 03:29:14,978 train 700 2.541185e-02 -0.638865
2019-11-05 03:29:25,837 train 750 2.538640e-02 -0.621136
2019-11-05 03:29:36,621 train 800 2.541584e-02 -0.613455
2019-11-05 03:29:47,238 train 850 2.541653e-02 -0.603654
2019-11-05 03:29:50,515 training loss; R2: 2.539498e-02 -0.598649
2019-11-05 03:29:51,116 valid 000 2.853293e-02 -0.921985
2019-11-05 03:30:01,846 valid 050 2.543757e-02 -0.844061
2019-11-05 03:30:11,270 validation loss; R2: 2.566373e-02 -0.776947
2019-11-05 03:30:11,338 epoch 116 lr 5.000000e-04
2019-11-05 03:30:12,086 train 000 2.377731e-02 -0.031997
2019-11-05 03:30:22,829 train 050 2.549350e-02 -0.323524
2019-11-05 03:30:33,632 train 100 2.550699e-02 -0.317458
2019-11-05 03:30:44,494 train 150 2.543793e-02 -0.319924
2019-11-05 03:30:55,368 train 200 2.525668e-02 -0.342410
2019-11-05 03:31:06,068 train 250 2.535239e-02 -0.390013
2019-11-05 03:31:16,898 train 300 2.527962e-02 -0.507429
2019-11-05 03:31:27,557 train 350 2.523523e-02 -0.482098
2019-11-05 03:31:38,331 train 400 2.530209e-02 -0.469993
2019-11-05 03:31:49,018 train 450 2.524421e-02 -0.483068
2019-11-05 03:31:59,852 train 500 2.521449e-02 -0.478819
2019-11-05 03:32:10,643 train 550 2.519619e-02 -0.486080
2019-11-05 03:32:21,453 train 600 2.519676e-02 -0.505327
2019-11-05 03:32:32,310 train 650 2.520678e-02 -0.495660
2019-11-05 03:32:43,032 train 700 2.521252e-02 -0.488428
2019-11-05 03:32:53,798 train 750 2.524767e-02 -0.475235
2019-11-05 03:33:04,532 train 800 2.522759e-02 -0.469550
2019-11-05 03:33:15,331 train 850 2.519769e-02 -0.467181
2019-11-05 03:33:18,496 training loss; R2: 2.520664e-02 -0.483747
2019-11-05 03:33:19,092 valid 000 2.571762e-02 -0.350400
2019-11-05 03:33:29,806 valid 050 2.564714e-02 -0.512789
2019-11-05 03:33:39,088 validation loss; R2: 2.619091e-02 -0.580685
2019-11-05 03:33:39,151 epoch 117 lr 5.000000e-04
2019-11-05 03:33:39,830 train 000 2.343295e-02 -0.170001
2019-11-05 03:33:50,497 train 050 2.501677e-02 -0.593074
2019-11-05 03:34:01,000 train 100 2.493779e-02 -0.532100
2019-11-05 03:34:11,578 train 150 2.503919e-02 -0.492843
2019-11-05 03:34:22,217 train 200 2.509757e-02 -0.479060
2019-11-05 03:34:32,805 train 250 2.520791e-02 -0.501796
2019-11-05 03:34:43,350 train 300 2.518709e-02 -0.584870
2019-11-05 03:34:54,038 train 350 2.512634e-02 -0.539354
2019-11-05 03:35:04,754 train 400 2.508011e-02 -0.530008
2019-11-05 03:35:15,668 train 450 2.510021e-02 -0.534356
2019-11-05 03:35:26,493 train 500 2.506113e-02 -0.516669
2019-11-05 03:35:37,276 train 550 2.502701e-02 -0.514559
2019-11-05 03:35:48,084 train 600 2.500507e-02 -1.359239
2019-11-05 03:35:58,878 train 650 2.496223e-02 -1.296582
2019-11-05 03:36:09,681 train 700 2.502043e-02 -1.249052
2019-11-05 03:36:20,465 train 750 2.505080e-02 -1.196776
2019-11-05 03:36:31,191 train 800 2.509188e-02 -1.154504
2019-11-05 03:36:41,838 train 850 2.509359e-02 -1.118477
2019-11-05 03:36:45,029 training loss; R2: 2.510679e-02 -1.105338
2019-11-05 03:36:45,602 valid 000 2.408485e-02 0.052462
2019-11-05 03:36:56,021 valid 050 2.369180e-02 -0.215138
2019-11-05 03:37:05,366 validation loss; R2: 2.358744e-02 -0.236949
2019-11-05 03:37:05,439 epoch 118 lr 5.000000e-04
2019-11-05 03:37:06,143 train 000 2.701083e-02 -0.236710
2019-11-05 03:37:17,137 train 050 2.572119e-02 -0.408380
2019-11-05 03:37:28,009 train 100 2.551806e-02 -0.415448
2019-11-05 03:37:38,880 train 150 2.533952e-02 -0.458661
2019-11-05 03:37:49,758 train 200 2.529243e-02 -0.454371
2019-11-05 03:38:00,606 train 250 2.532209e-02 -0.472760
2019-11-05 03:38:11,437 train 300 2.530671e-02 -0.459297
2019-11-05 03:38:21,997 train 350 2.527124e-02 -0.466062
2019-11-05 03:38:32,493 train 400 2.523731e-02 -0.454168
2019-11-05 03:38:43,087 train 450 2.519011e-02 -0.449718
2019-11-05 03:38:53,800 train 500 2.513847e-02 -0.451579
2019-11-05 03:39:04,539 train 550 2.508345e-02 -0.468183
2019-11-05 03:39:15,270 train 600 2.509052e-02 -0.462545
2019-11-05 03:39:25,995 train 650 2.510078e-02 -0.466402
2019-11-05 03:39:36,617 train 700 2.513045e-02 -0.515594
2019-11-05 03:39:47,278 train 750 2.513283e-02 -0.514206
2019-11-05 03:39:57,869 train 800 2.511557e-02 -0.502385
2019-11-05 03:40:08,445 train 850 2.514852e-02 -0.503544
2019-11-05 03:40:11,616 training loss; R2: 2.515856e-02 -0.501418
2019-11-05 03:40:12,208 valid 000 2.610180e-02 -0.511502
2019-11-05 03:40:22,655 valid 050 2.677582e-02 -0.579424
2019-11-05 03:40:32,017 validation loss; R2: 2.666628e-02 -0.642191
2019-11-05 03:40:32,094 epoch 119 lr 5.000000e-04
2019-11-05 03:40:32,836 train 000 2.859720e-02 -0.140537
2019-11-05 03:40:43,469 train 050 2.464715e-02 -0.392114
2019-11-05 03:40:54,108 train 100 2.477758e-02 -0.422592
2019-11-05 03:41:04,715 train 150 2.484983e-02 -0.432978
2019-11-05 03:41:15,324 train 200 2.493134e-02 -0.418389
2019-11-05 03:41:25,947 train 250 2.494713e-02 -0.427462
2019-11-05 03:41:36,564 train 300 2.500929e-02 -0.438671
2019-11-05 03:41:47,286 train 350 2.498013e-02 -0.432893
2019-11-05 03:41:58,015 train 400 2.498272e-02 -0.456341
2019-11-05 03:42:08,929 train 450 2.506890e-02 -0.482275
2019-11-05 03:42:19,864 train 500 2.509648e-02 -0.485231
2019-11-05 03:42:30,768 train 550 2.504779e-02 -0.472769
2019-11-05 03:42:41,566 train 600 2.508632e-02 -0.456688
2019-11-05 03:42:52,425 train 650 2.509944e-02 -0.459330
2019-11-05 03:43:03,274 train 700 2.510070e-02 -0.456464
2019-11-05 03:43:14,065 train 750 2.509942e-02 -0.458768
2019-11-05 03:43:24,663 train 800 2.511799e-02 -0.459182
2019-11-05 03:43:35,523 train 850 2.511661e-02 -0.461558
2019-11-05 03:43:38,609 training loss; R2: 2.512498e-02 -0.461662
2019-11-05 03:43:39,222 valid 000 2.688987e-02 -0.611376
2019-11-05 03:43:49,909 valid 050 2.521016e-02 -0.530058
2019-11-05 03:43:59,615 validation loss; R2: 2.512573e-02 -0.400714
2019-11-05 03:43:59,682 epoch 120 lr 5.000000e-04
2019-11-05 03:44:00,407 train 000 2.849728e-02 -1.067081
2019-11-05 03:44:11,364 train 050 2.477285e-02 -0.466522
2019-11-05 03:44:22,277 train 100 2.510933e-02 -0.423597
2019-11-05 03:44:33,123 train 150 2.492783e-02 -0.452167
2019-11-05 03:44:43,988 train 200 2.490884e-02 -0.425168
2019-11-05 03:44:54,803 train 250 2.498773e-02 -0.454837
2019-11-05 03:45:05,597 train 300 2.497245e-02 -0.461213
2019-11-05 03:45:16,323 train 350 2.499399e-02 -0.467358
2019-11-05 03:45:26,766 train 400 2.498080e-02 -0.460593
2019-11-05 03:45:37,129 train 450 2.499408e-02 -0.466846
2019-11-05 03:45:47,566 train 500 2.495804e-02 -0.458640
2019-11-05 03:45:58,006 train 550 2.496391e-02 -0.455786
2019-11-05 03:46:08,655 train 600 2.493257e-02 -0.469771
2019-11-05 03:46:19,304 train 650 2.496680e-02 -0.469299
2019-11-05 03:46:30,059 train 700 2.499754e-02 -0.462178
2019-11-05 03:46:40,807 train 750 2.501352e-02 -0.467773
2019-11-05 03:46:51,609 train 800 2.504138e-02 -0.462405
2019-11-05 03:47:02,301 train 850 2.503107e-02 -0.467216
2019-11-05 03:47:05,524 training loss; R2: 2.503989e-02 -0.466214
2019-11-05 03:47:06,122 valid 000 3.158077e-02 -0.719475
2019-11-05 03:47:16,889 valid 050 2.744717e-02 -0.995916
2019-11-05 03:47:26,395 validation loss; R2: 2.759891e-02 -0.989214
2019-11-05 03:47:26,465 epoch 121 lr 5.000000e-04
2019-11-05 03:47:27,178 train 000 2.459561e-02 -0.323734
2019-11-05 03:47:38,060 train 050 2.494207e-02 -0.394294
2019-11-05 03:47:48,904 train 100 2.491334e-02 -0.406784
2019-11-05 03:47:59,753 train 150 2.482799e-02 -0.433051
2019-11-05 03:48:10,628 train 200 2.485591e-02 -0.429622
2019-11-05 03:48:21,500 train 250 2.488773e-02 -0.458509
2019-11-05 03:48:32,335 train 300 2.506128e-02 -0.449732
2019-11-05 03:48:43,147 train 350 2.513091e-02 -0.449507
2019-11-05 03:48:53,632 train 400 2.512658e-02 -0.433025
2019-11-05 03:49:04,263 train 450 2.511506e-02 -0.421117
2019-11-05 03:49:15,190 train 500 2.515384e-02 -0.420872
2019-11-05 03:49:25,977 train 550 2.522415e-02 -0.419465
2019-11-05 03:49:36,784 train 600 2.522975e-02 -0.427131
2019-11-05 03:49:47,580 train 650 2.521009e-02 -0.450539
2019-11-05 03:49:58,441 train 700 2.517935e-02 -0.456541
2019-11-05 03:50:09,315 train 750 2.516621e-02 -0.462351
2019-11-05 03:50:20,149 train 800 2.515046e-02 -0.462994
2019-11-05 03:50:30,916 train 850 2.513756e-02 -0.458502
2019-11-05 03:50:34,120 training loss; R2: 2.514176e-02 -0.457651
2019-11-05 03:50:34,687 valid 000 2.146845e-02 -0.494353
2019-11-05 03:50:45,393 valid 050 2.589377e-02 -0.467602
2019-11-05 03:50:54,777 validation loss; R2: 2.625708e-02 -0.905691
2019-11-05 03:50:54,845 epoch 122 lr 5.000000e-04
2019-11-05 03:50:55,534 train 000 2.538524e-02 -0.630249
2019-11-05 03:51:06,328 train 050 2.502825e-02 -0.533132
2019-11-05 03:51:17,039 train 100 2.534147e-02 -0.431898
2019-11-05 03:51:27,705 train 150 2.530664e-02 -0.414612
2019-11-05 03:51:38,366 train 200 2.511936e-02 -0.471704
2019-11-05 03:51:49,062 train 250 2.506365e-02 -0.494374
2019-11-05 03:51:59,735 train 300 2.503953e-02 -0.485193
2019-11-05 03:52:10,410 train 350 2.508347e-02 -0.475299
2019-11-05 03:52:21,076 train 400 2.500606e-02 -0.475182
2019-11-05 03:52:31,783 train 450 2.496558e-02 -0.476234
2019-11-05 03:52:42,475 train 500 2.502890e-02 -0.483341
2019-11-05 03:52:53,141 train 550 2.505024e-02 -0.469580
2019-11-05 03:53:03,866 train 600 2.508280e-02 -0.457643
2019-11-05 03:53:14,546 train 650 2.503526e-02 -0.461440
2019-11-05 03:53:25,282 train 700 2.508036e-02 -0.450560
2019-11-05 03:53:36,012 train 750 2.507519e-02 -0.445473
2019-11-05 03:53:46,748 train 800 2.507510e-02 -0.445537
2019-11-05 03:53:57,489 train 850 2.507445e-02 -0.447202
2019-11-05 03:54:00,648 training loss; R2: 2.508081e-02 -0.452897
2019-11-05 03:54:01,242 valid 000 2.785133e-02 -0.739276
2019-11-05 03:54:11,906 valid 050 2.661560e-02 -0.765107
2019-11-05 03:54:21,332 validation loss; R2: 2.652458e-02 -0.717683
2019-11-05 03:54:21,399 epoch 123 lr 5.000000e-04
2019-11-05 03:54:22,113 train 000 2.556011e-02 -0.226755
2019-11-05 03:54:32,854 train 050 2.548407e-02 -127.849758
2019-11-05 03:54:43,562 train 100 2.528603e-02 -64.746044
2019-11-05 03:54:54,260 train 150 2.521758e-02 -43.446700
2019-11-05 03:55:04,959 train 200 2.516929e-02 -32.747420
2019-11-05 03:55:15,688 train 250 2.515744e-02 -26.308719
2019-11-05 03:55:26,447 train 300 2.517591e-02 -21.999637
2019-11-05 03:55:37,178 train 350 2.514159e-02 -18.917360
2019-11-05 03:55:47,794 train 400 2.520603e-02 -16.598002
2019-11-05 03:55:58,488 train 450 2.516748e-02 -14.819455
2019-11-05 03:56:09,161 train 500 2.519478e-02 -13.399523
2019-11-05 03:56:19,860 train 550 2.516355e-02 -12.229208
2019-11-05 03:56:30,574 train 600 2.518618e-02 -11.253552
2019-11-05 03:56:41,280 train 650 2.518859e-02 -10.423245
2019-11-05 03:56:52,025 train 700 2.512341e-02 -9.713615
2019-11-05 03:57:02,759 train 750 2.513027e-02 -9.093820
2019-11-05 03:57:13,525 train 800 2.514249e-02 -8.544695
2019-11-05 03:57:24,267 train 850 2.513004e-02 -8.073094
2019-11-05 03:57:27,444 training loss; R2: 2.512961e-02 -7.945933
2019-11-05 03:57:28,056 valid 000 2.810612e-02 -0.107632
2019-11-05 03:57:38,822 valid 050 2.327484e-02 -0.472193
2019-11-05 03:57:48,326 validation loss; R2: 2.310064e-02 -0.464190
2019-11-05 03:57:48,394 epoch 124 lr 5.000000e-04
2019-11-05 03:57:49,092 train 000 2.449933e-02 -0.716981
2019-11-05 03:57:59,809 train 050 2.512479e-02 -0.604825
2019-11-05 03:58:10,486 train 100 2.498550e-02 -0.516608
2019-11-05 03:58:21,106 train 150 2.506693e-02 -0.721633
2019-11-05 03:58:31,749 train 200 2.530213e-02 -0.643460
2019-11-05 03:58:42,404 train 250 2.526418e-02 -0.588112
2019-11-05 03:58:53,099 train 300 2.527036e-02 -0.547922
2019-11-05 03:59:03,819 train 350 2.522696e-02 -0.553191
2019-11-05 03:59:14,568 train 400 2.520264e-02 -0.537552
2019-11-05 03:59:25,252 train 450 2.519943e-02 -0.536831
2019-11-05 03:59:35,954 train 500 2.514232e-02 -0.529463
2019-11-05 03:59:46,649 train 550 2.518705e-02 -0.511250
2019-11-05 03:59:57,351 train 600 2.515196e-02 -0.505341
2019-11-05 04:00:08,080 train 650 2.513449e-02 -1.932644
2019-11-05 04:00:18,783 train 700 2.513525e-02 -1.828300
2019-11-05 04:00:29,512 train 750 2.511728e-02 -1.738894
2019-11-05 04:00:40,222 train 800 2.510673e-02 -1.658531
2019-11-05 04:00:50,949 train 850 2.509591e-02 -1.591896
2019-11-05 04:00:54,087 training loss; R2: 2.509631e-02 -1.569449
2019-11-05 04:00:54,692 valid 000 2.387269e-02 -0.382654
2019-11-05 04:01:05,123 valid 050 2.387501e-02 -0.517877
2019-11-05 04:01:14,304 validation loss; R2: 2.417231e-02 -0.546595
2019-11-05 04:01:14,371 epoch 125 lr 5.000000e-04
2019-11-05 04:01:15,068 train 000 2.285451e-02 -0.251268
2019-11-05 04:01:26,025 train 050 2.588192e-02 -0.459423
2019-11-05 04:01:36,847 train 100 2.549229e-02 -0.457011
2019-11-05 04:01:47,557 train 150 2.521064e-02 -0.449903
2019-11-05 04:01:58,181 train 200 2.514830e-02 -0.449489
2019-11-05 04:02:08,806 train 250 2.513537e-02 -2.021371
2019-11-05 04:02:19,383 train 300 2.501981e-02 -1.779231
2019-11-05 04:02:30,056 train 350 2.500388e-02 -1.601439
2019-11-05 04:02:40,784 train 400 2.495366e-02 -1.472037
2019-11-05 04:02:51,530 train 450 2.491919e-02 -1.351688
2019-11-05 04:03:02,250 train 500 2.488709e-02 -1.258281
2019-11-05 04:03:13,026 train 550 2.488187e-02 -1.184331
2019-11-05 04:03:23,768 train 600 2.491737e-02 -1.114661
2019-11-05 04:03:34,511 train 650 2.497013e-02 -1.059007
2019-11-05 04:03:45,335 train 700 2.501005e-02 -1.020054
2019-11-05 04:03:56,120 train 750 2.503040e-02 -0.976300
2019-11-05 04:04:07,032 train 800 2.502881e-02 -0.952622
2019-11-05 04:04:17,788 train 850 2.502495e-02 -0.925710
2019-11-05 04:04:20,960 training loss; R2: 2.503572e-02 -0.915228
2019-11-05 04:04:21,567 valid 000 2.167195e-02 -0.448087
2019-11-05 04:04:32,122 valid 050 2.276784e-02 -1.140314
2019-11-05 04:04:41,682 validation loss; R2: 2.299365e-02 -0.889014
2019-11-05 04:04:41,754 epoch 126 lr 5.000000e-04
2019-11-05 04:04:42,452 train 000 3.594534e-02 -1.607628
2019-11-05 04:04:53,360 train 050 2.510828e-02 -0.545005
2019-11-05 04:05:04,181 train 100 2.502075e-02 -0.458148
2019-11-05 04:05:15,092 train 150 2.502933e-02 -0.426284
2019-11-05 04:05:25,773 train 200 2.494467e-02 -0.461779
2019-11-05 04:05:36,577 train 250 2.496718e-02 -0.474115
2019-11-05 04:05:47,454 train 300 2.501401e-02 -0.456811
2019-11-05 04:05:58,225 train 350 2.498104e-02 -0.455961
2019-11-05 04:06:08,956 train 400 2.496022e-02 -0.440680
2019-11-05 04:06:19,769 train 450 2.499340e-02 -0.813372
2019-11-05 04:06:30,475 train 500 2.496462e-02 -0.790582
2019-11-05 04:06:41,370 train 550 2.494235e-02 -0.749138
2019-11-05 04:06:52,036 train 600 2.491257e-02 -0.713757
2019-11-05 04:07:02,868 train 650 2.489395e-02 -0.686476
2019-11-05 04:07:13,657 train 700 2.492646e-02 -0.676072
2019-11-05 04:07:24,432 train 750 2.495068e-02 -0.649612
2019-11-05 04:07:35,229 train 800 2.498366e-02 -0.634478
2019-11-05 04:07:46,010 train 850 2.493668e-02 -0.625181
2019-11-05 04:07:49,257 training loss; R2: 2.493272e-02 -0.621380
2019-11-05 04:07:49,888 valid 000 2.470132e-02 -0.666239
2019-11-05 04:08:00,519 valid 050 2.286140e-02 -0.479237
2019-11-05 04:08:10,304 validation loss; R2: 2.273790e-02 -0.464879
2019-11-05 04:08:10,379 epoch 127 lr 5.000000e-04
2019-11-05 04:08:11,138 train 000 2.223980e-02 -2.359087
2019-11-05 04:08:22,016 train 050 2.534981e-02 -0.534663
2019-11-05 04:08:33,042 train 100 2.490850e-02 -0.469038
2019-11-05 04:08:43,909 train 150 2.505708e-02 -0.473703
2019-11-05 04:08:54,623 train 200 2.503522e-02 -0.475760
2019-11-05 04:09:05,397 train 250 2.507088e-02 -0.500018
2019-11-05 04:09:16,226 train 300 2.510436e-02 -0.545062
2019-11-05 04:09:27,020 train 350 2.511214e-02 -0.552291
2019-11-05 04:09:37,629 train 400 2.504061e-02 -0.540863
2019-11-05 04:09:48,347 train 450 2.500653e-02 -0.542089
2019-11-05 04:09:58,989 train 500 2.498373e-02 -0.528518
2019-11-05 04:10:09,785 train 550 2.503731e-02 -0.532869
2019-11-05 04:10:20,428 train 600 2.506692e-02 -0.528708
2019-11-05 04:10:31,139 train 650 2.502817e-02 -0.516405
2019-11-05 04:10:41,832 train 700 2.500806e-02 -0.509870
2019-11-05 04:10:52,554 train 750 2.496240e-02 -0.499831
2019-11-05 04:11:03,167 train 800 2.498005e-02 -0.498226
2019-11-05 04:11:13,977 train 850 2.495600e-02 -0.492387
2019-11-05 04:11:17,188 training loss; R2: 2.497007e-02 -0.490413
2019-11-05 04:11:17,797 valid 000 2.096665e-02 -0.303214
2019-11-05 04:11:28,323 valid 050 2.262994e-02 -0.456192
2019-11-05 04:11:38,094 validation loss; R2: 2.252362e-02 -0.353692
2019-11-05 04:11:38,159 epoch 128 lr 5.000000e-04
2019-11-05 04:11:38,922 train 000 2.198670e-02 -0.266404
2019-11-05 04:11:49,794 train 050 2.504987e-02 -0.487217
2019-11-05 04:12:00,651 train 100 2.500060e-02 -0.526718
2019-11-05 04:12:11,530 train 150 2.514119e-02 -0.524061
2019-11-05 04:12:22,375 train 200 2.508275e-02 -0.490928
2019-11-05 04:12:33,110 train 250 2.510244e-02 -0.531322
2019-11-05 04:12:43,866 train 300 2.501803e-02 -0.509497
2019-11-05 04:12:54,673 train 350 2.502549e-02 -0.496291
2019-11-05 04:13:05,450 train 400 2.505173e-02 -0.485036
2019-11-05 04:13:16,276 train 450 2.506409e-02 -0.972236
2019-11-05 04:13:27,066 train 500 2.509198e-02 -0.917779
2019-11-05 04:13:37,877 train 550 2.509599e-02 -0.881881
2019-11-05 04:13:48,646 train 600 2.506713e-02 -0.836772
2019-11-05 04:13:59,501 train 650 2.508416e-02 -0.799473
2019-11-05 04:14:10,347 train 700 2.503428e-02 -0.772461
2019-11-05 04:14:21,158 train 750 2.505164e-02 -0.751918
2019-11-05 04:14:32,012 train 800 2.501058e-02 -0.733813
2019-11-05 04:14:42,893 train 850 2.503137e-02 -0.714983
2019-11-05 04:14:46,109 training loss; R2: 2.503723e-02 -0.708143
2019-11-05 04:14:46,752 valid 000 2.260105e-02 -1.271021
2019-11-05 04:14:57,429 valid 050 2.509567e-02 -0.669841
2019-11-05 04:15:07,045 validation loss; R2: 2.516816e-02 -0.701298
2019-11-05 04:15:07,113 epoch 129 lr 5.000000e-04
2019-11-05 04:15:07,819 train 000 2.393259e-02 -0.102464
2019-11-05 04:15:18,927 train 050 2.525309e-02 -0.429916
2019-11-05 04:15:29,845 train 100 2.509530e-02 -0.414213
2019-11-05 04:15:40,837 train 150 2.497914e-02 -0.406775
2019-11-05 04:15:51,831 train 200 2.498321e-02 -0.414542
2019-11-05 04:16:02,845 train 250 2.494403e-02 -0.430737
2019-11-05 04:16:13,823 train 300 2.496334e-02 -0.419236
2019-11-05 04:16:24,804 train 350 2.493443e-02 -0.434426
2019-11-05 04:16:35,649 train 400 2.496074e-02 -0.444809
2019-11-05 04:16:46,443 train 450 2.496338e-02 -0.431680
2019-11-05 04:16:57,216 train 500 2.501128e-02 -0.455307
2019-11-05 04:17:07,933 train 550 2.500664e-02 -0.454433
2019-11-05 04:17:18,697 train 600 2.497890e-02 -0.470234
2019-11-05 04:17:29,435 train 650 2.498425e-02 -0.461450
2019-11-05 04:17:40,122 train 700 2.497445e-02 -0.473865
2019-11-05 04:17:50,813 train 750 2.498535e-02 -0.467935
2019-11-05 04:18:01,507 train 800 2.500780e-02 -0.477702
2019-11-05 04:18:12,207 train 850 2.499151e-02 -0.468171
2019-11-05 04:18:15,378 training loss; R2: 2.499087e-02 -0.469456
2019-11-05 04:18:15,973 valid 000 2.247726e-02 -0.972218
2019-11-05 04:18:26,445 valid 050 2.655411e-02 -0.944875
2019-11-05 04:18:36,109 validation loss; R2: 2.634582e-02 -0.826566
2019-11-05 04:18:36,179 epoch 130 lr 5.000000e-04
2019-11-05 04:18:36,928 train 000 2.401374e-02 -0.823529
2019-11-05 04:18:47,879 train 050 2.437113e-02 -0.445755
2019-11-05 04:18:58,720 train 100 2.471919e-02 -0.484923
2019-11-05 04:19:09,534 train 150 2.499858e-02 -0.444495
2019-11-05 04:19:20,292 train 200 2.510065e-02 -0.407308
2019-11-05 04:19:31,074 train 250 2.509553e-02 -0.417612
2019-11-05 04:19:41,805 train 300 2.500176e-02 -0.428652
2019-11-05 04:19:52,565 train 350 2.502741e-02 -0.439332
2019-11-05 04:20:03,340 train 400 2.503211e-02 -0.458618
2019-11-05 04:20:14,131 train 450 2.495235e-02 -0.454654
2019-11-05 04:20:24,942 train 500 2.496889e-02 -0.457001
2019-11-05 04:20:35,638 train 550 2.494765e-02 -0.452071
2019-11-05 04:20:46,423 train 600 2.492202e-02 -0.441328
2019-11-05 04:20:57,243 train 650 2.487564e-02 -0.650736
2019-11-05 04:21:08,023 train 700 2.483488e-02 -0.640408
2019-11-05 04:21:18,803 train 750 2.483157e-02 -0.630709
2019-11-05 04:21:29,647 train 800 2.486249e-02 -0.617372
2019-11-05 04:21:40,498 train 850 2.486657e-02 -0.612411
2019-11-05 04:21:43,765 training loss; R2: 2.485769e-02 -0.608620
2019-11-05 04:21:44,335 valid 000 2.270071e-02 -0.095935
2019-11-05 04:21:54,831 valid 050 2.539256e-02 -0.683934
2019-11-05 04:22:04,431 validation loss; R2: 2.573956e-02 -0.568784
2019-11-05 04:22:04,501 epoch 131 lr 5.000000e-04
2019-11-05 04:22:05,204 train 000 2.710775e-02 -0.303533
2019-11-05 04:22:16,013 train 050 2.492957e-02 -0.483850
2019-11-05 04:22:26,789 train 100 2.485655e-02 -0.412707
2019-11-05 04:22:37,611 train 150 2.481889e-02 -0.440476
2019-11-05 04:22:48,344 train 200 2.483635e-02 -0.425515
2019-11-05 04:22:59,125 train 250 2.484852e-02 -0.408616
2019-11-05 04:23:09,769 train 300 2.481911e-02 -0.418805
2019-11-05 04:23:20,532 train 350 2.478279e-02 -0.432245
2019-11-05 04:23:31,299 train 400 2.482218e-02 -0.455774
2019-11-05 04:23:42,045 train 450 2.486284e-02 -0.453124
2019-11-05 04:23:52,736 train 500 2.483236e-02 -0.455247
2019-11-05 04:24:03,482 train 550 2.486129e-02 -0.443695
2019-11-05 04:24:14,151 train 600 2.485337e-02 -0.456541
2019-11-05 04:24:24,916 train 650 2.481267e-02 -0.457019
2019-11-05 04:24:35,670 train 700 2.482926e-02 -0.456105
2019-11-05 04:24:46,508 train 750 2.480829e-02 -0.467111
2019-11-05 04:24:57,133 train 800 2.481921e-02 -0.519437
2019-11-05 04:25:07,883 train 850 2.480894e-02 -0.527291
2019-11-05 04:25:11,091 training loss; R2: 2.480832e-02 -0.523307
2019-11-05 04:25:11,669 valid 000 2.433447e-02 -0.065901
2019-11-05 04:25:22,299 valid 050 2.287690e-02 -0.332352
2019-11-05 04:25:31,531 validation loss; R2: 2.286517e-02 -0.455159
2019-11-05 04:25:31,596 epoch 132 lr 5.000000e-04
2019-11-05 04:25:32,277 train 000 2.443943e-02 0.004736
2019-11-05 04:25:42,989 train 050 2.507105e-02 -0.444109
2019-11-05 04:25:53,769 train 100 2.495562e-02 -0.459850
2019-11-05 04:26:04,635 train 150 2.489560e-02 -0.482798
2019-11-05 04:26:15,551 train 200 2.494970e-02 -0.481161
2019-11-05 04:26:26,463 train 250 2.498708e-02 -0.476201
2019-11-05 04:26:37,368 train 300 2.493453e-02 -0.524017
2019-11-05 04:26:48,266 train 350 2.490621e-02 -0.577824
2019-11-05 04:26:59,300 train 400 2.481375e-02 -0.556777
2019-11-05 04:27:10,205 train 450 2.483257e-02 -0.536061
2019-11-05 04:27:21,077 train 500 2.484857e-02 -0.529850
2019-11-05 04:27:32,017 train 550 2.479413e-02 -0.519906
2019-11-05 04:27:43,059 train 600 2.475178e-02 -4.532606
2019-11-05 04:27:53,989 train 650 2.479346e-02 -4.223845
2019-11-05 04:28:04,880 train 700 2.473665e-02 -3.946717
2019-11-05 04:28:15,762 train 750 2.474721e-02 -3.707719
2019-11-05 04:28:26,609 train 800 2.476338e-02 -3.506240
2019-11-05 04:28:37,481 train 850 2.476608e-02 -3.323195
2019-11-05 04:28:40,675 training loss; R2: 2.476514e-02 -3.271991
2019-11-05 04:28:41,226 valid 000 2.536630e-02 -0.170953
2019-11-05 04:28:51,833 valid 050 2.575457e-02 -0.691680
2019-11-05 04:29:01,311 validation loss; R2: 2.546970e-02 -0.655737
2019-11-05 04:29:01,376 epoch 133 lr 5.000000e-04
2019-11-05 04:29:02,064 train 000 2.492366e-02 -0.244198
2019-11-05 04:29:12,845 train 050 2.477085e-02 -163.100300
2019-11-05 04:29:23,483 train 100 2.472279e-02 -82.855809
2019-11-05 04:29:34,156 train 150 2.482382e-02 -56.615750
2019-11-05 04:29:44,872 train 200 2.481337e-02 -42.649796
2019-11-05 04:29:55,575 train 250 2.472171e-02 -34.230777
2019-11-05 04:30:06,260 train 300 2.479112e-02 -28.648352
2019-11-05 04:30:16,998 train 350 2.477615e-02 -24.629873
2019-11-05 04:30:28,039 train 400 2.482213e-02 -21.634619
2019-11-05 04:30:39,084 train 450 2.480877e-02 -19.292198
2019-11-05 04:30:49,987 train 500 2.477108e-02 -17.419196
2019-11-05 04:31:00,849 train 550 2.478112e-02 -15.874517
2019-11-05 04:31:11,761 train 600 2.483861e-02 -14.587943
2019-11-05 04:31:22,658 train 650 2.481858e-02 -13.504016
2019-11-05 04:31:33,606 train 700 2.478558e-02 -12.572764
2019-11-05 04:31:44,510 train 750 2.482305e-02 -11.763092
2019-11-05 04:31:55,449 train 800 2.480376e-02 -11.062722
2019-11-05 04:32:06,259 train 850 2.474958e-02 -10.435125
2019-11-05 04:32:09,519 training loss; R2: 2.475178e-02 -10.269407
2019-11-05 04:32:10,100 valid 000 2.137242e-02 -0.102392
2019-11-05 04:32:20,674 valid 050 2.258095e-02 -0.633074
2019-11-05 04:32:30,161 validation loss; R2: 2.256368e-02 -0.687509
2019-11-05 04:32:30,224 epoch 134 lr 5.000000e-04
2019-11-05 04:32:30,920 train 000 2.214762e-02 -0.176308
2019-11-05 04:32:41,735 train 050 2.454583e-02 -0.386986
2019-11-05 04:32:52,681 train 100 2.457839e-02 -0.374128
2019-11-05 04:33:03,638 train 150 2.441467e-02 -0.389111
2019-11-05 04:33:14,540 train 200 2.436267e-02 -0.407745
2019-11-05 04:33:25,419 train 250 2.440481e-02 -0.396065
2019-11-05 04:33:36,315 train 300 2.452384e-02 -0.704179
2019-11-05 04:33:47,179 train 350 2.456746e-02 -0.655658
2019-11-05 04:33:58,097 train 400 2.463707e-02 -0.613967
2019-11-05 04:34:08,940 train 450 2.462829e-02 -0.608897
2019-11-05 04:34:19,856 train 500 2.464963e-02 -0.588103
2019-11-05 04:34:30,734 train 550 2.459632e-02 -0.584366
2019-11-05 04:34:41,599 train 600 2.456978e-02 -0.574665
2019-11-05 04:34:52,618 train 650 2.456705e-02 -0.565832
2019-11-05 04:35:03,567 train 700 2.455779e-02 -0.568493
2019-11-05 04:35:14,485 train 750 2.456798e-02 -0.606967
2019-11-05 04:35:25,405 train 800 2.456790e-02 -0.595023
2019-11-05 04:35:36,289 train 850 2.462563e-02 -0.584092
2019-11-05 04:35:39,435 training loss; R2: 2.463901e-02 -0.583966
2019-11-05 04:35:40,043 valid 000 2.046750e-02 -0.103240
2019-11-05 04:35:50,513 valid 050 2.229340e-02 -0.367862
2019-11-05 04:35:59,832 validation loss; R2: 2.227101e-02 -0.374004
2019-11-05 04:35:59,905 epoch 135 lr 5.000000e-04
2019-11-05 04:36:00,636 train 000 2.465066e-02 -1.273782
2019-11-05 04:36:11,365 train 050 2.448358e-02 -0.533057
2019-11-05 04:36:22,188 train 100 2.465501e-02 -0.502886
2019-11-05 04:36:32,964 train 150 2.441664e-02 -0.472788
2019-11-05 04:36:43,794 train 200 2.440968e-02 -0.439763
2019-11-05 04:36:54,630 train 250 2.442000e-02 -0.455956
2019-11-05 04:37:05,519 train 300 2.440753e-02 -0.438202
2019-11-05 04:37:16,360 train 350 2.441742e-02 -0.428545
2019-11-05 04:37:27,126 train 400 2.443185e-02 -0.452323
2019-11-05 04:37:37,886 train 450 2.446190e-02 -0.455239
2019-11-05 04:37:48,690 train 500 2.449759e-02 -0.449057
2019-11-05 04:37:59,485 train 550 2.452923e-02 -0.450467
2019-11-05 04:38:10,282 train 600 2.455533e-02 -0.455467
2019-11-05 04:38:21,062 train 650 2.456237e-02 -0.466917
2019-11-05 04:38:31,873 train 700 2.458516e-02 -0.466561
2019-11-05 04:38:42,602 train 750 2.460368e-02 -0.462067
2019-11-05 04:38:53,394 train 800 2.458377e-02 -0.459373
2019-11-05 04:39:04,303 train 850 2.459374e-02 -0.455395
2019-11-05 04:39:07,570 training loss; R2: 2.461627e-02 -0.459151
2019-11-05 04:39:08,138 valid 000 2.236982e-02 -0.471413
2019-11-05 04:39:18,693 valid 050 2.311716e-02 -0.579211
2019-11-05 04:39:28,096 validation loss; R2: 2.282467e-02 -0.547475
2019-11-05 04:39:28,157 epoch 136 lr 5.000000e-04
2019-11-05 04:39:28,898 train 000 2.397293e-02 -0.156574
2019-11-05 04:39:39,853 train 050 2.496388e-02 -0.304472
2019-11-05 04:39:50,751 train 100 2.474944e-02 -0.320091
2019-11-05 04:40:01,617 train 150 2.456635e-02 -0.398648
2019-11-05 04:40:12,536 train 200 2.461979e-02 -0.390236
2019-11-05 04:40:23,430 train 250 2.464963e-02 -0.441329
2019-11-05 04:40:34,382 train 300 2.465126e-02 -0.427418
2019-11-05 04:40:45,419 train 350 2.470968e-02 -0.455361
2019-11-05 04:40:56,425 train 400 2.473443e-02 -0.456928
2019-11-05 04:41:07,439 train 450 2.468953e-02 -0.450809
2019-11-05 04:41:18,340 train 500 2.467054e-02 -0.458192
2019-11-05 04:41:29,282 train 550 2.468781e-02 -0.468805
2019-11-05 04:41:40,207 train 600 2.468404e-02 -0.474858
2019-11-05 04:41:51,095 train 650 2.467665e-02 -0.465112
2019-11-05 04:42:02,047 train 700 2.467310e-02 -0.460492
2019-11-05 04:42:12,985 train 750 2.467089e-02 -0.454240
2019-11-05 04:42:23,881 train 800 2.465616e-02 -0.455460
2019-11-05 04:42:34,794 train 850 2.464769e-02 -0.453153
2019-11-05 04:42:38,084 training loss; R2: 2.465356e-02 -0.449209
2019-11-05 04:42:38,676 valid 000 2.195615e-02 0.000653
2019-11-05 04:42:49,468 valid 050 2.164915e-02 -0.393292
2019-11-05 04:42:59,008 validation loss; R2: 2.193137e-02 -0.663284
2019-11-05 04:42:59,073 epoch 137 lr 5.000000e-04
2019-11-05 04:42:59,766 train 000 2.381470e-02 -0.194732
2019-11-05 04:43:10,598 train 050 2.480363e-02 -0.445636
2019-11-05 04:43:21,418 train 100 2.478785e-02 -0.462905
2019-11-05 04:43:32,263 train 150 2.486100e-02 -0.450115
2019-11-05 04:43:43,177 train 200 2.481172e-02 -0.443670
2019-11-05 04:43:53,978 train 250 2.473520e-02 -0.443869
2019-11-05 04:44:04,771 train 300 2.472358e-02 -0.456409
2019-11-05 04:44:15,644 train 350 2.478459e-02 -0.457596
2019-11-05 04:44:26,576 train 400 2.473485e-02 -0.460183
2019-11-05 04:44:37,490 train 450 2.478081e-02 -0.481482
2019-11-05 04:44:48,360 train 500 2.471277e-02 -0.485677
2019-11-05 04:44:59,198 train 550 2.469879e-02 -0.485617
2019-11-05 04:45:10,033 train 600 2.468269e-02 -0.478908
2019-11-05 04:45:20,900 train 650 2.463918e-02 -0.475905
2019-11-05 04:45:31,736 train 700 2.462741e-02 -0.473337
2019-11-05 04:45:42,572 train 750 2.461466e-02 -0.478604
2019-11-05 04:45:53,411 train 800 2.463881e-02 -0.488170
2019-11-05 04:46:04,255 train 850 2.461813e-02 -0.487176
2019-11-05 04:46:07,514 training loss; R2: 2.461888e-02 -0.484653
2019-11-05 04:46:08,121 valid 000 2.384878e-02 -0.103671
2019-11-05 04:46:18,650 valid 050 2.290289e-02 -0.446814
2019-11-05 04:46:28,135 validation loss; R2: 2.298749e-02 -0.426203
2019-11-05 04:46:28,209 epoch 138 lr 5.000000e-04
2019-11-05 04:46:28,937 train 000 2.393922e-02 -0.162103
2019-11-05 04:46:39,649 train 050 2.443022e-02 -1.752109
2019-11-05 04:46:50,356 train 100 2.442250e-02 -1.154183
2019-11-05 04:47:01,050 train 150 2.459990e-02 -0.898620
2019-11-05 04:47:11,731 train 200 2.461084e-02 -0.783299
2019-11-05 04:47:22,428 train 250 2.464657e-02 -0.716364
2019-11-05 04:47:32,973 train 300 2.459778e-02 -0.798198
2019-11-05 04:47:43,533 train 350 2.464022e-02 -0.763609
2019-11-05 04:47:54,181 train 400 2.474108e-02 -0.721847
2019-11-05 04:48:04,870 train 450 2.471817e-02 -0.694504
2019-11-05 04:48:15,557 train 500 2.467314e-02 -0.664378
2019-11-05 04:48:26,261 train 550 2.462802e-02 -0.757986
2019-11-05 04:48:36,979 train 600 2.462070e-02 -0.721289
2019-11-05 04:48:47,663 train 650 2.464023e-02 -0.705554
2019-11-05 04:48:58,356 train 700 2.469341e-02 -0.686680
2019-11-05 04:49:09,034 train 750 2.469310e-02 -0.674118
2019-11-05 04:49:19,728 train 800 2.471366e-02 -0.661183
2019-11-05 04:49:30,426 train 850 2.470882e-02 -0.642910
2019-11-05 04:49:33,544 training loss; R2: 2.468445e-02 -0.638071
2019-11-05 04:49:34,144 valid 000 2.370632e-02 -0.660315
2019-11-05 04:49:44,640 valid 050 2.300038e-02 -1.177961
2019-11-05 04:49:54,230 validation loss; R2: 2.323196e-02 -0.957624
2019-11-05 04:49:54,301 epoch 139 lr 5.000000e-04
2019-11-05 04:49:55,082 train 000 2.228931e-02 -0.136677
2019-11-05 04:50:05,794 train 050 2.461339e-02 -0.366835
2019-11-05 04:50:16,531 train 100 2.491156e-02 -0.432679
2019-11-05 04:50:27,287 train 150 2.488888e-02 -0.422785
2019-11-05 04:50:37,987 train 200 2.472096e-02 -0.450071
2019-11-05 04:50:48,666 train 250 2.477897e-02 -0.465391
2019-11-05 04:50:59,277 train 300 2.468590e-02 -0.472810
2019-11-05 04:51:09,867 train 350 2.469265e-02 -0.472070
2019-11-05 04:51:20,447 train 400 2.469564e-02 -0.477223
2019-11-05 04:51:31,089 train 450 2.463973e-02 -0.462466
2019-11-05 04:51:41,809 train 500 2.464531e-02 -0.469278
2019-11-05 04:51:52,541 train 550 2.465489e-02 -0.460186
2019-11-05 04:52:03,343 train 600 2.460854e-02 -0.454299
2019-11-05 04:52:14,113 train 650 2.461703e-02 -0.453665
2019-11-05 04:52:25,013 train 700 2.460430e-02 -0.464046
2019-11-05 04:52:35,817 train 750 2.464663e-02 -0.462259
2019-11-05 04:52:46,507 train 800 2.464789e-02 -0.466566
2019-11-05 04:52:57,342 train 850 2.463483e-02 -0.463365
2019-11-05 04:53:00,577 training loss; R2: 2.462765e-02 -0.464464
2019-11-05 04:53:01,143 valid 000 2.279286e-02 -2.184321
2019-11-05 04:53:11,827 valid 050 2.293578e-02 -0.399298
2019-11-05 04:53:21,500 validation loss; R2: 2.292363e-02 -0.564569
2019-11-05 04:53:21,562 epoch 140 lr 5.000000e-04
2019-11-05 04:53:22,318 train 000 2.566841e-02 -0.499172
2019-11-05 04:53:33,000 train 050 2.498663e-02 -0.496961
2019-11-05 04:53:43,726 train 100 2.480913e-02 -0.458724
2019-11-05 04:53:54,547 train 150 2.487547e-02 -0.423076
2019-11-05 04:54:05,294 train 200 2.496443e-02 -0.459750
2019-11-05 04:54:16,168 train 250 2.488693e-02 -0.504468
2019-11-05 04:54:26,794 train 300 2.478373e-02 -0.484249
2019-11-05 04:54:37,562 train 350 2.470818e-02 -0.506399
2019-11-05 04:54:48,474 train 400 2.472303e-02 -0.484224
2019-11-05 04:54:59,339 train 450 2.472666e-02 -0.485503
2019-11-05 04:55:09,995 train 500 2.469106e-02 -0.479595
2019-11-05 04:55:20,734 train 550 2.468097e-02 -0.508232
2019-11-05 04:55:31,389 train 600 2.465025e-02 -0.504586
2019-11-05 04:55:42,146 train 650 2.465585e-02 -0.502802
2019-11-05 04:55:52,969 train 700 2.464650e-02 -0.486868
2019-11-05 04:56:03,656 train 750 2.462235e-02 -0.486139
2019-11-05 04:56:14,388 train 800 2.462307e-02 -0.484148
2019-11-05 04:56:25,213 train 850 2.460337e-02 -0.500466
2019-11-05 04:56:28,343 training loss; R2: 2.461907e-02 -0.503286
2019-11-05 04:56:28,929 valid 000 2.125188e-02 -0.092816
2019-11-05 04:56:39,658 valid 050 2.190341e-02 -0.580369
2019-11-05 04:56:49,116 validation loss; R2: 2.197335e-02 -0.451145
2019-11-05 04:56:49,177 epoch 141 lr 5.000000e-04
2019-11-05 04:56:49,866 train 000 2.431246e-02 -1.158681
2019-11-05 04:57:00,611 train 050 2.499245e-02 -0.470621
2019-11-05 04:57:11,402 train 100 2.486910e-02 -0.492658
2019-11-05 04:57:22,150 train 150 2.459212e-02 -0.492665
2019-11-05 04:57:32,877 train 200 2.472851e-02 -0.493619
2019-11-05 04:57:43,662 train 250 2.478473e-02 -0.477488
2019-11-05 04:57:54,423 train 300 2.474843e-02 -0.486701
2019-11-05 04:58:05,267 train 350 2.476939e-02 -0.500675
2019-11-05 04:58:16,087 train 400 2.481240e-02 -0.500708
2019-11-05 04:58:26,858 train 450 2.482304e-02 -0.483218
2019-11-05 04:58:37,580 train 500 2.477769e-02 -0.493338
2019-11-05 04:58:48,399 train 550 2.473660e-02 -0.480361
2019-11-05 04:58:59,221 train 600 2.474059e-02 -0.482757
2019-11-05 04:59:10,023 train 650 2.469580e-02 -0.484586
2019-11-05 04:59:20,781 train 700 2.466547e-02 -0.476969
2019-11-05 04:59:31,534 train 750 2.463962e-02 -0.476311
2019-11-05 04:59:42,345 train 800 2.463474e-02 -0.471710
2019-11-05 04:59:53,168 train 850 2.463188e-02 -0.473488
2019-11-05 04:59:56,412 training loss; R2: 2.462795e-02 -0.473102
2019-11-05 04:59:56,965 valid 000 2.768782e-02 -0.600087
2019-11-05 05:00:07,770 valid 050 2.563695e-02 -0.892673
2019-11-05 05:00:17,298 validation loss; R2: 2.528748e-02 -0.739156
2019-11-05 05:00:17,358 epoch 142 lr 5.000000e-04
2019-11-05 05:00:18,072 train 000 2.382509e-02 -0.449456
2019-11-05 05:00:29,162 train 050 2.463964e-02 -0.386660
2019-11-05 05:00:40,036 train 100 2.462419e-02 -0.637211
2019-11-05 05:00:51,025 train 150 2.461350e-02 -0.609789
2019-11-05 05:01:02,237 train 200 2.462414e-02 -0.604822
2019-11-05 05:01:13,322 train 250 2.458556e-02 -0.546421
2019-11-05 05:01:24,310 train 300 2.458908e-02 -0.522323
2019-11-05 05:01:35,131 train 350 2.453399e-02 -0.517673
2019-11-05 05:01:46,007 train 400 2.456729e-02 -0.500056
2019-11-05 05:01:56,970 train 450 2.464539e-02 -0.473250
2019-11-05 05:02:07,906 train 500 2.459377e-02 -0.548512
2019-11-05 05:02:18,833 train 550 2.456100e-02 -0.532672
2019-11-05 05:02:29,734 train 600 2.459259e-02 -0.524508
2019-11-05 05:02:40,669 train 650 2.457254e-02 -0.884619
2019-11-05 05:02:51,513 train 700 2.457413e-02 -0.851285
2019-11-05 05:03:02,367 train 750 2.452706e-02 -0.831746
2019-11-05 05:03:13,294 train 800 2.453531e-02 -0.810483
2019-11-05 05:03:24,246 train 850 2.452320e-02 -0.784076
2019-11-05 05:03:27,422 training loss; R2: 2.451970e-02 -0.779841
2019-11-05 05:03:28,028 valid 000 2.277812e-02 -0.408562
2019-11-05 05:03:38,514 valid 050 2.332492e-02 -0.673931
2019-11-05 05:03:48,139 validation loss; R2: 2.352149e-02 -0.615048
2019-11-05 05:03:48,213 epoch 143 lr 5.000000e-04
2019-11-05 05:03:48,924 train 000 2.331529e-02 -0.381607
2019-11-05 05:03:59,886 train 050 2.396860e-02 -23.709510
2019-11-05 05:04:10,747 train 100 2.410918e-02 -12.191237
2019-11-05 05:04:21,494 train 150 2.404385e-02 -8.329218
2019-11-05 05:04:32,264 train 200 2.416690e-02 -6.338105
2019-11-05 05:04:42,769 train 250 2.420219e-02 -5.202525
2019-11-05 05:04:53,284 train 300 2.434727e-02 -4.487524
2019-11-05 05:05:03,982 train 350 2.442834e-02 -3.907226
2019-11-05 05:05:14,581 train 400 2.448672e-02 -3.463739
2019-11-05 05:05:25,302 train 450 2.447379e-02 -3.131110
2019-11-05 05:05:36,018 train 500 2.450397e-02 -2.863037
2019-11-05 05:05:46,646 train 550 2.449124e-02 -2.691504
2019-11-05 05:05:57,246 train 600 2.451862e-02 -2.502565
2019-11-05 05:06:07,923 train 650 2.451528e-02 -2.671318
2019-11-05 05:06:18,616 train 700 2.452911e-02 -2.517197
2019-11-05 05:06:29,318 train 750 2.448042e-02 -2.379058
2019-11-05 05:06:39,977 train 800 2.448303e-02 -2.258973
2019-11-05 05:06:50,603 train 850 2.448078e-02 -2.148593
2019-11-05 05:06:53,788 training loss; R2: 2.449108e-02 -2.117874
2019-11-05 05:06:54,401 valid 000 2.348388e-02 -2.823143
2019-11-05 05:07:04,890 valid 050 2.334799e-02 -1.109855
2019-11-05 05:07:14,420 validation loss; R2: 2.313867e-02 -1.142468
2019-11-05 05:07:14,488 epoch 144 lr 5.000000e-04
2019-11-05 05:07:15,214 train 000 2.597294e-02 -0.577954
2019-11-05 05:07:26,269 train 050 2.421406e-02 -0.527747
2019-11-05 05:07:37,258 train 100 2.408257e-02 -0.501720
2019-11-05 05:07:48,199 train 150 2.412364e-02 -0.490976
2019-11-05 05:07:59,082 train 200 2.434522e-02 -0.463473
2019-11-05 05:08:09,754 train 250 2.433169e-02 -0.486045
2019-11-05 05:08:20,464 train 300 2.436567e-02 -0.472575
2019-11-05 05:08:31,176 train 350 2.440339e-02 -0.468496
2019-11-05 05:08:41,890 train 400 2.444125e-02 -3.632800
2019-11-05 05:08:52,537 train 450 2.450419e-02 -3.267894
2019-11-05 05:09:03,185 train 500 2.450412e-02 -2.999458
2019-11-05 05:09:13,902 train 550 2.447845e-02 -2.776432
2019-11-05 05:09:24,666 train 600 2.452721e-02 -2.581598
2019-11-05 05:09:35,383 train 650 2.450087e-02 -2.416539
2019-11-05 05:09:46,073 train 700 2.448190e-02 -2.273757
2019-11-05 05:09:56,800 train 750 2.447933e-02 -2.145911
2019-11-05 05:10:07,516 train 800 2.445674e-02 -2.040485
2019-11-05 05:10:18,248 train 850 2.442730e-02 -1.948175
2019-11-05 05:10:21,392 training loss; R2: 2.441708e-02 -1.920344
2019-11-05 05:10:21,981 valid 000 2.086582e-02 -0.005725
2019-11-05 05:10:32,691 valid 050 2.244951e-02 -0.483389
2019-11-05 05:10:42,424 validation loss; R2: 2.219976e-02 -0.457476
2019-11-05 05:10:42,495 epoch 145 lr 5.000000e-04
2019-11-05 05:10:43,320 train 000 2.774890e-02 -0.336248
2019-11-05 05:10:54,082 train 050 2.435516e-02 -0.517559
2019-11-05 05:11:04,822 train 100 2.444324e-02 -0.546558
2019-11-05 05:11:15,512 train 150 2.444503e-02 -0.493939
2019-11-05 05:11:26,224 train 200 2.439020e-02 -0.521585
2019-11-05 05:11:36,912 train 250 2.430696e-02 -0.518456
2019-11-05 05:11:47,587 train 300 2.433107e-02 -0.562715
2019-11-05 05:11:58,311 train 350 2.433003e-02 -0.548049
2019-11-05 05:12:09,066 train 400 2.437434e-02 -0.533104
2019-11-05 05:12:19,753 train 450 2.439437e-02 -0.529822
2019-11-05 05:12:30,480 train 500 2.436954e-02 -0.521406
2019-11-05 05:12:41,204 train 550 2.436730e-02 -0.505058
2019-11-05 05:12:51,894 train 600 2.435318e-02 -0.501096
2019-11-05 05:13:02,626 train 650 2.438432e-02 -0.497434
2019-11-05 05:13:13,363 train 700 2.439246e-02 -0.489695
2019-11-05 05:13:24,036 train 750 2.443026e-02 -0.485114
2019-11-05 05:13:34,681 train 800 2.444668e-02 -0.484760
2019-11-05 05:13:45,346 train 850 2.441837e-02 -0.536751
2019-11-05 05:13:48,590 training loss; R2: 2.440549e-02 -0.533178
2019-11-05 05:13:49,176 valid 000 2.246712e-02 -1.163634
2019-11-05 05:13:59,921 valid 050 2.279691e-02 -0.385638
2019-11-05 05:14:09,416 validation loss; R2: 2.258744e-02 -0.386447
2019-11-05 05:14:09,483 epoch 146 lr 5.000000e-04
2019-11-05 05:14:10,188 train 000 2.873921e-02 -1.090897
2019-11-05 05:14:21,116 train 050 2.414300e-02 -0.421029
2019-11-05 05:14:31,963 train 100 2.441055e-02 -0.419877
2019-11-05 05:14:42,783 train 150 2.444890e-02 -0.480016
2019-11-05 05:14:53,612 train 200 2.445058e-02 -0.469613
2019-11-05 05:15:04,132 train 250 2.447407e-02 -0.466830
2019-11-05 05:15:14,799 train 300 2.444478e-02 -0.499692
2019-11-05 05:15:25,368 train 350 2.447589e-02 -0.474047
2019-11-05 05:15:35,891 train 400 2.445913e-02 -0.452677
2019-11-05 05:15:46,477 train 450 2.443048e-02 -0.459269
2019-11-05 05:15:57,102 train 500 2.443588e-02 -0.445964
2019-11-05 05:16:07,691 train 550 2.445360e-02 -0.444030
2019-11-05 05:16:18,308 train 600 2.447234e-02 -0.450034
2019-11-05 05:16:28,919 train 650 2.448674e-02 -0.454614
2019-11-05 05:16:39,479 train 700 2.451741e-02 -0.457970
2019-11-05 05:16:50,060 train 750 2.450927e-02 -0.470478
2019-11-05 05:17:00,620 train 800 2.448895e-02 -0.464647
2019-11-05 05:17:11,181 train 850 2.451413e-02 -0.456523
2019-11-05 05:17:14,290 training loss; R2: 2.452571e-02 -0.453728
2019-11-05 05:17:14,848 valid 000 2.117056e-02 -0.348054
2019-11-05 05:17:25,419 valid 050 2.117249e-02 -0.459001
2019-11-05 05:17:34,753 validation loss; R2: 2.140201e-02 -0.411512
2019-11-05 05:17:34,823 epoch 147 lr 5.000000e-04
2019-11-05 05:17:35,512 train 000 2.485273e-02 -0.409191
2019-11-05 05:17:46,168 train 050 2.410156e-02 -0.392150
2019-11-05 05:17:56,790 train 100 2.444065e-02 -0.430776
2019-11-05 05:18:07,331 train 150 2.434993e-02 -0.614581
2019-11-05 05:18:17,928 train 200 2.425026e-02 -0.555389
2019-11-05 05:18:28,522 train 250 2.428889e-02 -0.545951
2019-11-05 05:18:39,023 train 300 2.433189e-02 -0.519403
2019-11-05 05:18:49,641 train 350 2.436493e-02 -0.521881
2019-11-05 05:19:00,327 train 400 2.435785e-02 -0.542582
2019-11-05 05:19:11,016 train 450 2.433018e-02 -0.522074
2019-11-05 05:19:21,735 train 500 2.431560e-02 -0.512818
2019-11-05 05:19:32,435 train 550 2.434414e-02 -0.499455
2019-11-05 05:19:43,076 train 600 2.433864e-02 -0.503780
2019-11-05 05:19:53,731 train 650 2.434322e-02 -0.494824
2019-11-05 05:20:04,358 train 700 2.436013e-02 -0.499685
2019-11-05 05:20:14,994 train 750 2.437344e-02 -0.488938
2019-11-05 05:20:25,687 train 800 2.437287e-02 -0.485125
2019-11-05 05:20:36,367 train 850 2.436421e-02 -0.483294
2019-11-05 05:20:39,515 training loss; R2: 2.436770e-02 -0.485521
2019-11-05 05:20:40,129 valid 000 2.164593e-02 -0.162435
2019-11-05 05:20:50,886 valid 050 2.223467e-02 -0.432768
2019-11-05 05:21:00,427 validation loss; R2: 2.245916e-02 -0.417112
2019-11-05 05:21:00,492 epoch 148 lr 5.000000e-04
2019-11-05 05:21:01,227 train 000 2.422099e-02 -0.362536
2019-11-05 05:21:11,958 train 050 2.446565e-02 -0.409379
2019-11-05 05:21:22,742 train 100 2.471808e-02 -0.493013
2019-11-05 05:21:33,471 train 150 2.461423e-02 -0.463868
2019-11-05 05:21:44,221 train 200 2.457781e-02 -0.483036
2019-11-05 05:21:54,967 train 250 2.450992e-02 -0.519894
2019-11-05 05:22:05,699 train 300 2.447221e-02 -0.509516
2019-11-05 05:22:16,444 train 350 2.444075e-02 -0.512274
2019-11-05 05:22:27,117 train 400 2.438894e-02 -0.501799
2019-11-05 05:22:37,889 train 450 2.449136e-02 -0.491553
2019-11-05 05:22:48,608 train 500 2.446796e-02 -0.520033
2019-11-05 05:22:59,244 train 550 2.444411e-02 -0.513510
2019-11-05 05:23:09,988 train 600 2.442067e-02 -0.499206
2019-11-05 05:23:20,680 train 650 2.438994e-02 -0.506035
2019-11-05 05:23:31,378 train 700 2.439399e-02 -0.520925
2019-11-05 05:23:42,144 train 750 2.441413e-02 -0.517888
2019-11-05 05:23:52,902 train 800 2.441472e-02 -0.514807
2019-11-05 05:24:03,664 train 850 2.443880e-02 -0.506654
2019-11-05 05:24:06,795 training loss; R2: 2.444864e-02 -0.502002
2019-11-05 05:24:07,361 valid 000 2.835477e-02 -0.247438
2019-11-05 05:24:18,173 valid 050 2.437108e-02 -0.422574
2019-11-05 05:24:27,654 validation loss; R2: 2.457540e-02 -0.496311
2019-11-05 05:24:27,721 epoch 149 lr 5.000000e-04
2019-11-05 05:24:28,466 train 000 2.581545e-02 -0.245564
2019-11-05 05:24:39,482 train 050 2.447287e-02 -0.446249
2019-11-05 05:24:50,586 train 100 2.431893e-02 -0.381984
2019-11-05 05:25:01,373 train 150 2.420743e-02 -0.394521
2019-11-05 05:25:12,184 train 200 2.423573e-02 -0.375623
2019-11-05 05:25:23,233 train 250 2.434664e-02 -0.417911
2019-11-05 05:25:34,273 train 300 2.437777e-02 -0.410501
2019-11-05 05:25:45,263 train 350 2.435568e-02 -0.420369
2019-11-05 05:25:56,222 train 400 2.442274e-02 -0.462015
2019-11-05 05:26:07,165 train 450 2.438018e-02 -0.461200
2019-11-05 05:26:17,961 train 500 2.438025e-02 -0.463522
2019-11-05 05:26:28,915 train 550 2.437710e-02 -0.465921
2019-11-05 05:26:39,907 train 600 2.438427e-02 -0.467813
2019-11-05 05:26:50,740 train 650 2.439020e-02 -0.461762
2019-11-05 05:27:01,694 train 700 2.443287e-02 -0.463100
2019-11-05 05:27:12,618 train 750 2.444307e-02 -0.462226
2019-11-05 05:27:23,513 train 800 2.443416e-02 -0.476423
2019-11-05 05:27:34,507 train 850 2.444553e-02 -0.473584
2019-11-05 05:27:37,721 training loss; R2: 2.443868e-02 -0.472067
2019-11-05 05:27:38,371 valid 000 2.053151e-02 -0.362801
2019-11-05 05:27:48,856 valid 050 2.055605e-02 -0.372303
2019-11-05 05:27:58,415 validation loss; R2: 2.061745e-02 -0.343452
2019-11-05 05:27:58,489 epoch 150 lr 5.000000e-04
2019-11-05 05:27:59,245 train 000 2.481899e-02 -0.117499
2019-11-05 05:28:10,026 train 050 2.399753e-02 -0.569896
2019-11-05 05:28:20,732 train 100 2.435351e-02 -0.491917
2019-11-05 05:28:31,390 train 150 2.427974e-02 -0.521736
2019-11-05 05:28:41,997 train 200 2.418985e-02 -0.468961
2019-11-05 05:28:52,534 train 250 2.419183e-02 -0.452363
2019-11-05 05:29:03,067 train 300 2.425662e-02 -0.436418
2019-11-05 05:29:13,743 train 350 2.428255e-02 -0.442034
2019-11-05 05:29:24,388 train 400 2.430712e-02 -0.458431
2019-11-05 05:29:35,083 train 450 2.438991e-02 -12.850584
2019-11-05 05:29:45,758 train 500 2.436078e-02 -11.607964
2019-11-05 05:29:56,459 train 550 2.435933e-02 -10.615390
2019-11-05 05:30:07,122 train 600 2.437827e-02 -9.767350
2019-11-05 05:30:17,803 train 650 2.439630e-02 -9.077522
2019-11-05 05:30:28,441 train 700 2.441910e-02 -8.468111
2019-11-05 05:30:39,113 train 750 2.438822e-02 -7.927711
2019-11-05 05:30:49,771 train 800 2.438338e-02 -7.455303
2019-11-05 05:31:00,474 train 850 2.438038e-02 -7.042552
2019-11-05 05:31:03,705 training loss; R2: 2.437577e-02 -6.925831
2019-11-05 05:31:04,367 valid 000 2.158610e-02 -1.074018
2019-11-05 05:31:14,951 valid 050 2.215349e-02 -0.330311
2019-11-05 05:31:24,586 validation loss; R2: 2.188007e-02 -0.366220
2019-11-05 05:31:24,658 epoch 151 lr 5.000000e-04
2019-11-05 05:31:25,367 train 000 2.254400e-02 -0.486217
2019-11-05 05:31:36,091 train 050 2.411052e-02 -0.590281
2019-11-05 05:31:46,933 train 100 2.427716e-02 -0.431178
2019-11-05 05:31:57,813 train 150 2.445967e-02 -0.439596
2019-11-05 05:32:08,595 train 200 2.444944e-02 -0.454638
2019-11-05 05:32:19,311 train 250 2.437414e-02 -1.441257
2019-11-05 05:32:30,179 train 300 2.444365e-02 -1.297652
2019-11-05 05:32:40,878 train 350 2.446178e-02 -1.187927
2019-11-05 05:32:51,595 train 400 2.438749e-02 -1.094983
2019-11-05 05:33:02,378 train 450 2.428500e-02 -1.014229
2019-11-05 05:33:13,236 train 500 2.424946e-02 -0.952317
2019-11-05 05:33:24,051 train 550 2.423378e-02 -0.906567
2019-11-05 05:33:34,782 train 600 2.424957e-02 -0.865413
2019-11-05 05:33:45,520 train 650 2.428610e-02 -0.845162
2019-11-05 05:33:56,372 train 700 2.430255e-02 -0.822512
2019-11-05 05:34:07,084 train 750 2.432155e-02 -0.793859
2019-11-05 05:34:17,888 train 800 2.433830e-02 -0.763852
2019-11-05 05:34:28,711 train 850 2.434348e-02 -0.749401
2019-11-05 05:34:31,875 training loss; R2: 2.435291e-02 -0.744590
2019-11-05 05:34:32,478 valid 000 2.344920e-02 -0.590279
2019-11-05 05:34:43,237 valid 050 2.461307e-02 -1.017531
2019-11-05 05:34:52,816 validation loss; R2: 2.457492e-02 -0.835985
2019-11-05 05:34:52,882 epoch 152 lr 5.000000e-04
2019-11-05 05:34:53,579 train 000 2.451312e-02 -0.537062
2019-11-05 05:35:04,448 train 050 2.466007e-02 -0.653619
2019-11-05 05:35:15,198 train 100 2.435710e-02 -0.626850
2019-11-05 05:35:25,948 train 150 2.449428e-02 -0.568028
2019-11-05 05:35:36,693 train 200 2.455717e-02 -0.531868
2019-11-05 05:35:47,444 train 250 2.450423e-02 -0.536846
2019-11-05 05:35:58,201 train 300 2.452511e-02 -0.529216
2019-11-05 05:36:08,960 train 350 2.453449e-02 -0.545376
2019-11-05 05:36:19,799 train 400 2.450563e-02 -0.548906
2019-11-05 05:36:30,817 train 450 2.448037e-02 -0.542451
2019-11-05 05:36:41,573 train 500 2.439235e-02 -0.522998
2019-11-05 05:36:52,275 train 550 2.437241e-02 -0.573926
2019-11-05 05:37:02,998 train 600 2.441702e-02 -0.576718
2019-11-05 05:37:13,759 train 650 2.442092e-02 -0.566955
2019-11-05 05:37:24,535 train 700 2.444312e-02 -0.555248
2019-11-05 05:37:35,486 train 750 2.441767e-02 -0.557478
2019-11-05 05:37:46,345 train 800 2.441294e-02 -0.552990
2019-11-05 05:37:57,326 train 850 2.438302e-02 -0.544940
2019-11-05 05:38:00,440 training loss; R2: 2.438549e-02 -0.539207
2019-11-05 05:38:01,042 valid 000 2.257530e-02 -0.432861
2019-11-05 05:38:11,704 valid 050 2.133706e-02 -0.457821
2019-11-05 05:38:21,135 validation loss; R2: 2.136628e-02 -0.411526
2019-11-05 05:38:21,201 epoch 153 lr 5.000000e-04
2019-11-05 05:38:21,894 train 000 2.477195e-02 -0.324210
2019-11-05 05:38:32,614 train 050 2.453725e-02 -0.454923
2019-11-05 05:38:43,524 train 100 2.454405e-02 -0.489834
2019-11-05 05:38:54,336 train 150 2.456334e-02 -0.452083
2019-11-05 05:39:05,087 train 200 2.460479e-02 -0.454721
2019-11-05 05:39:15,749 train 250 2.448444e-02 -0.437120
2019-11-05 05:39:26,448 train 300 2.434476e-02 -0.468205
2019-11-05 05:39:37,113 train 350 2.435117e-02 -0.466677
2019-11-05 05:39:47,788 train 400 2.432194e-02 -0.454799
2019-11-05 05:39:58,501 train 450 2.430466e-02 -7.901968
2019-11-05 05:40:09,223 train 500 2.428354e-02 -7.167117
2019-11-05 05:40:19,934 train 550 2.425781e-02 -6.556738
2019-11-05 05:40:30,642 train 600 2.425166e-02 -6.043612
2019-11-05 05:40:41,341 train 650 2.426046e-02 -5.784544
2019-11-05 05:40:52,041 train 700 2.428141e-02 -5.400752
2019-11-05 05:41:02,755 train 750 2.428118e-02 -5.064334
2019-11-05 05:41:13,500 train 800 2.429007e-02 -4.787988
2019-11-05 05:41:24,167 train 850 2.431270e-02 -4.528585
2019-11-05 05:41:27,378 training loss; R2: 2.431264e-02 -4.455690
2019-11-05 05:41:27,948 valid 000 1.874271e-02 -0.395503
2019-11-05 05:41:38,509 valid 050 2.244003e-02 -0.468067
2019-11-05 05:41:47,729 validation loss; R2: 2.238496e-02 -0.382456
2019-11-05 05:41:47,794 epoch 154 lr 5.000000e-04
2019-11-05 05:41:48,525 train 000 2.293244e-02 -0.582109
2019-11-05 05:41:59,272 train 050 2.434250e-02 -0.618046
2019-11-05 05:42:10,202 train 100 2.446601e-02 -0.814225
2019-11-05 05:42:21,179 train 150 2.458827e-02 -0.713123
2019-11-05 05:42:31,933 train 200 2.438048e-02 -0.646675
2019-11-05 05:42:42,465 train 250 2.439500e-02 -0.605446
2019-11-05 05:42:52,985 train 300 2.434676e-02 -0.770402
2019-11-05 05:43:03,525 train 350 2.433692e-02 -0.733348
2019-11-05 05:43:14,091 train 400 2.428933e-02 -0.683416
2019-11-05 05:43:24,768 train 450 2.429515e-02 -0.653523
2019-11-05 05:43:35,427 train 500 2.429922e-02 -0.652495
2019-11-05 05:43:46,084 train 550 2.435186e-02 -0.637187
2019-11-05 05:43:56,822 train 600 2.441015e-02 -0.635371
2019-11-05 05:44:07,559 train 650 2.439411e-02 -0.623071
2019-11-05 05:44:18,288 train 700 2.438446e-02 -0.605171
2019-11-05 05:44:28,973 train 750 2.437769e-02 -0.595982
2019-11-05 05:44:39,694 train 800 2.436874e-02 -0.590795
2019-11-05 05:44:50,389 train 850 2.436729e-02 -0.589305
2019-11-05 05:44:53,669 training loss; R2: 2.436895e-02 -0.584998
2019-11-05 05:44:54,237 valid 000 2.515176e-02 -0.505396
2019-11-05 05:45:04,897 valid 050 2.319743e-02 -0.577324
2019-11-05 05:45:14,412 validation loss; R2: 2.325418e-02 -0.565560
2019-11-05 05:45:14,494 epoch 155 lr 5.000000e-04
2019-11-05 05:45:15,196 train 000 2.413244e-02 -0.126248
2019-11-05 05:45:25,886 train 050 2.408530e-02 -0.437975
2019-11-05 05:45:36,756 train 100 2.423435e-02 -0.401601
2019-11-05 05:45:47,640 train 150 2.434431e-02 -3.168341
2019-11-05 05:45:58,490 train 200 2.441083e-02 -2.510147
2019-11-05 05:46:09,316 train 250 2.450568e-02 -2.132916
2019-11-05 05:46:20,138 train 300 2.450340e-02 -1.826899
2019-11-05 05:46:31,009 train 350 2.442834e-02 -1.637171
2019-11-05 05:46:41,906 train 400 2.440786e-02 -1.509707
2019-11-05 05:46:52,804 train 450 2.440772e-02 -1.389505
2019-11-05 05:47:03,711 train 500 2.437718e-02 -1.319635
2019-11-05 05:47:14,590 train 550 2.430897e-02 -1.236229
2019-11-05 05:47:25,516 train 600 2.429392e-02 -1.173759
2019-11-05 05:47:36,438 train 650 2.426947e-02 -1.116538
2019-11-05 05:47:47,336 train 700 2.431353e-02 -1.072310
2019-11-05 05:47:58,156 train 750 2.437349e-02 -1.037751
2019-11-05 05:48:08,982 train 800 2.438926e-02 -0.996927
2019-11-05 05:48:19,840 train 850 2.437025e-02 -0.973796
2019-11-05 05:48:23,029 training loss; R2: 2.436977e-02 -0.961770
2019-11-05 05:48:23,602 valid 000 2.212440e-02 -0.116101
2019-11-05 05:48:34,290 valid 050 2.195437e-02 -0.368884
2019-11-05 05:48:43,894 validation loss; R2: 2.184865e-02 -0.397439
2019-11-05 05:48:43,963 epoch 156 lr 5.000000e-04
2019-11-05 05:48:44,717 train 000 2.519286e-02 -0.502141
2019-11-05 05:48:55,442 train 050 2.358213e-02 -0.588607
2019-11-05 05:49:06,321 train 100 2.376717e-02 -0.527176
2019-11-05 05:49:17,234 train 150 2.396860e-02 -0.503031
2019-11-05 05:49:28,137 train 200 2.397536e-02 -0.476501
2019-11-05 05:49:38,966 train 250 2.410052e-02 -0.471726
2019-11-05 05:49:49,811 train 300 2.408709e-02 -0.459351
2019-11-05 05:50:00,611 train 350 2.405225e-02 -0.483153
2019-11-05 05:50:11,439 train 400 2.413183e-02 -0.487670
2019-11-05 05:50:22,361 train 450 2.414100e-02 -0.507049
2019-11-05 05:50:33,217 train 500 2.417953e-02 -0.519165
2019-11-05 05:50:44,003 train 550 2.419624e-02 -0.511501
2019-11-05 05:50:54,757 train 600 2.416091e-02 -0.505993
2019-11-05 05:51:05,352 train 650 2.418179e-02 -0.495667
2019-11-05 05:51:16,152 train 700 2.419770e-02 -0.502706
2019-11-05 05:51:27,016 train 750 2.421325e-02 -0.493611
2019-11-05 05:51:37,865 train 800 2.422994e-02 -0.489123
2019-11-05 05:51:48,713 train 850 2.428528e-02 -1.102050
2019-11-05 05:51:51,886 training loss; R2: 2.428083e-02 -1.090568
2019-11-05 05:51:52,492 valid 000 2.039235e-02 -0.022895
2019-11-05 05:52:03,118 valid 050 2.178637e-02 -0.399218
2019-11-05 05:52:12,840 validation loss; R2: 2.178819e-02 -0.328257
2019-11-05 05:52:12,905 epoch 157 lr 5.000000e-04
2019-11-05 05:52:13,643 train 000 2.467420e-02 -3.345945
2019-11-05 05:52:24,342 train 050 2.407730e-02 -0.416670
2019-11-05 05:52:35,162 train 100 2.390308e-02 -1.166730
2019-11-05 05:52:46,044 train 150 2.395181e-02 -0.913934
2019-11-05 05:52:56,869 train 200 2.411999e-02 -0.794312
2019-11-05 05:53:07,701 train 250 2.421254e-02 -0.716851
2019-11-05 05:53:18,603 train 300 2.439598e-02 -0.659662
2019-11-05 05:53:29,389 train 350 2.435528e-02 -0.662161
2019-11-05 05:53:40,177 train 400 2.431420e-02 -0.675817
2019-11-05 05:53:50,976 train 450 2.428489e-02 -0.649487
2019-11-05 05:54:01,730 train 500 2.430958e-02 -0.647884
2019-11-05 05:54:12,578 train 550 2.431287e-02 -0.624926
2019-11-05 05:54:23,411 train 600 2.429160e-02 -0.604313
2019-11-05 05:54:34,278 train 650 2.428807e-02 -0.596128
2019-11-05 05:54:45,181 train 700 2.425542e-02 -0.585357
2019-11-05 05:54:56,050 train 750 2.426689e-02 -0.581889
2019-11-05 05:55:06,869 train 800 2.429239e-02 -0.566333
2019-11-05 05:55:17,692 train 850 2.428255e-02 -0.551240
2019-11-05 05:55:20,928 training loss; R2: 2.427215e-02 -0.551628
2019-11-05 05:55:21,543 valid 000 2.087750e-02 -0.652477
2019-11-05 05:55:32,250 valid 050 2.112145e-02 -0.381871
2019-11-05 05:55:41,797 validation loss; R2: 2.121073e-02 -0.385509
2019-11-05 05:55:41,867 epoch 158 lr 5.000000e-04
2019-11-05 05:55:42,577 train 000 2.581627e-02 -0.771869
2019-11-05 05:55:53,526 train 050 2.425660e-02 -0.417229
2019-11-05 05:56:04,433 train 100 2.422623e-02 -0.430238
2019-11-05 05:56:15,385 train 150 2.412479e-02 -0.448042
2019-11-05 05:56:26,285 train 200 2.402354e-02 -0.454100
2019-11-05 05:56:37,170 train 250 2.394742e-02 -0.448700
2019-11-05 05:56:48,077 train 300 2.397245e-02 -0.439003
2019-11-05 05:56:58,935 train 350 2.399314e-02 -0.443372
2019-11-05 05:57:09,769 train 400 2.405117e-02 -0.459035
2019-11-05 05:57:20,635 train 450 2.408883e-02 -0.458585
2019-11-05 05:57:31,490 train 500 2.406616e-02 -0.449837
2019-11-05 05:57:42,303 train 550 2.410925e-02 -0.455149
2019-11-05 05:57:53,119 train 600 2.410162e-02 -0.442601
2019-11-05 05:58:03,939 train 650 2.415542e-02 -0.454249
2019-11-05 05:58:14,778 train 700 2.418185e-02 -0.460265
2019-11-05 05:58:25,627 train 750 2.419212e-02 -0.472967
2019-11-05 05:58:36,487 train 800 2.420146e-02 -0.466888
2019-11-05 05:58:47,354 train 850 2.424768e-02 -0.465470
2019-11-05 05:58:50,541 training loss; R2: 2.425403e-02 -0.474302
2019-11-05 05:58:51,117 valid 000 2.596743e-02 -0.306473
2019-11-05 05:59:01,795 valid 050 2.466801e-02 -0.571511
2019-11-05 05:59:11,551 validation loss; R2: 2.457975e-02 -0.529344
2019-11-05 05:59:11,630 epoch 159 lr 5.000000e-04
2019-11-05 05:59:12,383 train 000 2.504602e-02 -0.246172
2019-11-05 05:59:23,339 train 050 2.477242e-02 -0.353621
2019-11-05 05:59:34,250 train 100 2.447929e-02 -0.407246
2019-11-05 05:59:45,233 train 150 2.435781e-02 -0.396846
2019-11-05 05:59:55,924 train 200 2.423413e-02 -0.386488
2019-11-05 06:00:06,663 train 250 2.420947e-02 -2.405572
2019-11-05 06:00:17,413 train 300 2.420594e-02 -2.123402
2019-11-05 06:00:28,119 train 350 2.425567e-02 -1.873587
2019-11-05 06:00:38,865 train 400 2.424867e-02 -1.701627
2019-11-05 06:00:49,717 train 450 2.431122e-02 -1.580884
2019-11-05 06:01:00,592 train 500 2.430668e-02 -1.459706
2019-11-05 06:01:11,470 train 550 2.426945e-02 -1.365861
2019-11-05 06:01:22,331 train 600 2.431156e-02 -1.302403
2019-11-05 06:01:33,146 train 650 2.433458e-02 -1.240105
2019-11-05 06:01:43,994 train 700 2.429959e-02 -1.182512
2019-11-05 06:01:54,869 train 750 2.432723e-02 -1.145340
2019-11-05 06:02:05,708 train 800 2.432369e-02 -1.104754
2019-11-05 06:02:16,562 train 850 2.431666e-02 -1.056758
2019-11-05 06:02:19,721 training loss; R2: 2.432304e-02 -1.051897
2019-11-05 06:02:20,343 valid 000 1.944737e-02 -0.548628
2019-11-05 06:02:31,123 valid 050 2.135529e-02 -0.394151
2019-11-05 06:02:40,638 validation loss; R2: 2.142349e-02 -0.553396
2019-11-05 06:02:40,703 epoch 160 lr 5.000000e-04
2019-11-05 06:02:41,460 train 000 2.526113e-02 -0.423020
2019-11-05 06:02:52,247 train 050 2.457405e-02 -0.593615
2019-11-05 06:03:03,360 train 100 2.452627e-02 -0.541466
2019-11-05 06:03:14,194 train 150 2.421248e-02 -0.616993
2019-11-05 06:03:25,040 train 200 2.427740e-02 -0.554654
2019-11-05 06:03:35,865 train 250 2.430338e-02 -0.550582
2019-11-05 06:03:46,648 train 300 2.434053e-02 -0.530775
2019-11-05 06:03:57,265 train 350 2.431779e-02 -0.526658
2019-11-05 06:04:08,021 train 400 2.428535e-02 -0.509339
2019-11-05 06:04:18,818 train 450 2.428226e-02 -0.488491
2019-11-05 06:04:29,585 train 500 2.424829e-02 -0.506632
2019-11-05 06:04:40,277 train 550 2.430085e-02 -0.498035
2019-11-05 06:04:51,056 train 600 2.431487e-02 -0.492518
2019-11-05 06:05:01,728 train 650 2.432845e-02 -0.499363
2019-11-05 06:05:12,526 train 700 2.430244e-02 -0.480774
2019-11-05 06:05:23,231 train 750 2.429660e-02 -0.472390
2019-11-05 06:05:34,012 train 800 2.427210e-02 -0.472834
2019-11-05 06:05:44,764 train 850 2.432129e-02 -0.467106
2019-11-05 06:05:48,039 training loss; R2: 2.430944e-02 -0.475251
2019-11-05 06:05:48,608 valid 000 2.150299e-02 -0.097192
2019-11-05 06:05:59,330 valid 050 2.178401e-02 -0.443910
2019-11-05 06:06:08,765 validation loss; R2: 2.177920e-02 -0.488132
2019-11-05 06:06:08,828 epoch 161 lr 5.000000e-04
2019-11-05 06:06:09,585 train 000 2.793716e-02 -0.178721
2019-11-05 06:06:20,291 train 050 2.400692e-02 -0.504061
2019-11-05 06:06:31,330 train 100 2.415520e-02 -0.471407
2019-11-05 06:06:42,460 train 150 2.419782e-02 -1.553580
2019-11-05 06:06:53,362 train 200 2.413647e-02 -1.257599
2019-11-05 06:07:04,262 train 250 2.406805e-02 -1.109840
2019-11-05 06:07:15,154 train 300 2.403508e-02 -1.020057
2019-11-05 06:07:25,967 train 350 2.405538e-02 -0.946114
2019-11-05 06:07:36,822 train 400 2.406610e-02 -0.880626
2019-11-05 06:07:47,672 train 450 2.408733e-02 -0.897529
2019-11-05 06:07:58,548 train 500 2.410469e-02 -0.848620
2019-11-05 06:08:09,440 train 550 2.411425e-02 -0.806718
2019-11-05 06:08:20,265 train 600 2.412438e-02 -0.784382
2019-11-05 06:08:30,988 train 650 2.417594e-02 -0.746565
2019-11-05 06:08:41,791 train 700 2.421547e-02 -0.746126
2019-11-05 06:08:52,595 train 750 2.418841e-02 -0.734174
2019-11-05 06:09:03,380 train 800 2.420643e-02 -0.730128
2019-11-05 06:09:14,178 train 850 2.420037e-02 -0.710297
2019-11-05 06:09:17,421 training loss; R2: 2.421632e-02 -0.705085
2019-11-05 06:09:17,981 valid 000 2.358896e-02 -0.381070
2019-11-05 06:09:28,698 valid 050 2.309386e-02 -0.395981
2019-11-05 06:09:38,322 validation loss; R2: 2.330877e-02 -0.425438
2019-11-05 06:09:38,391 epoch 162 lr 5.000000e-04
2019-11-05 06:09:39,096 train 000 2.617369e-02 -0.054933
2019-11-05 06:09:49,699 train 050 2.490666e-02 -0.526565
2019-11-05 06:10:00,535 train 100 2.482984e-02 -0.577088
2019-11-05 06:10:11,380 train 150 2.469227e-02 -0.553650
2019-11-05 06:10:22,309 train 200 2.463102e-02 -0.564793
2019-11-05 06:10:33,041 train 250 2.449829e-02 -0.546444
2019-11-05 06:10:43,333 train 300 2.439257e-02 -0.533786
2019-11-05 06:10:53,617 train 350 2.432080e-02 -0.524833
2019-11-05 06:11:03,868 train 400 2.432386e-02 -0.513504
2019-11-05 06:11:14,151 train 450 2.427696e-02 -0.491932
2019-11-05 06:11:24,464 train 500 2.427770e-02 -0.507314
2019-11-05 06:11:34,691 train 550 2.429749e-02 -0.515725
2019-11-05 06:11:45,019 train 600 2.433023e-02 -0.505726
2019-11-05 06:11:55,365 train 650 2.434510e-02 -0.503003
2019-11-05 06:12:05,635 train 700 2.429815e-02 -0.544035
2019-11-05 06:12:15,869 train 750 2.429637e-02 -0.553389
2019-11-05 06:12:26,191 train 800 2.429164e-02 -0.599515
2019-11-05 06:12:36,450 train 850 2.427635e-02 -0.589848
2019-11-05 06:12:39,511 training loss; R2: 2.426623e-02 -0.586812
2019-11-05 06:12:40,072 valid 000 2.293587e-02 0.046242
2019-11-05 06:12:50,610 valid 050 2.285500e-02 -0.218362
2019-11-05 06:12:59,868 validation loss; R2: 2.286307e-02 -0.286206
2019-11-05 06:12:59,937 epoch 163 lr 5.000000e-04
2019-11-05 06:13:00,632 train 000 2.442390e-02 -0.315225
2019-11-05 06:13:11,077 train 050 2.403433e-02 -0.291261
2019-11-05 06:13:21,565 train 100 2.412907e-02 -0.461726
2019-11-05 06:13:32,015 train 150 2.420187e-02 -0.498875
2019-11-05 06:13:42,502 train 200 2.421084e-02 -0.458451
2019-11-05 06:13:52,938 train 250 2.414138e-02 -0.447893
2019-11-05 06:14:03,344 train 300 2.416077e-02 -0.484005
2019-11-05 06:14:13,794 train 350 2.413200e-02 -0.491933
2019-11-05 06:14:24,254 train 400 2.419195e-02 -0.500514
2019-11-05 06:14:34,770 train 450 2.419241e-02 -0.494575
2019-11-05 06:14:45,274 train 500 2.412481e-02 -0.509148
2019-11-05 06:14:55,748 train 550 2.415884e-02 -0.511043
2019-11-05 06:15:06,204 train 600 2.414823e-02 -0.498189
2019-11-05 06:15:16,684 train 650 2.415255e-02 -0.497042
2019-11-05 06:15:27,234 train 700 2.415832e-02 -0.490265
2019-11-05 06:15:37,754 train 750 2.413971e-02 -0.487169
2019-11-05 06:15:48,291 train 800 2.415047e-02 -0.483987
2019-11-05 06:15:58,804 train 850 2.414347e-02 -0.489937
2019-11-05 06:16:01,904 training loss; R2: 2.414492e-02 -0.494921
2019-11-05 06:16:02,482 valid 000 2.255206e-02 0.062057
2019-11-05 06:16:12,894 valid 050 2.155327e-02 -0.399472
2019-11-05 06:16:22,155 validation loss; R2: 2.131533e-02 -0.356769
2019-11-05 06:16:22,221 epoch 164 lr 5.000000e-04
2019-11-05 06:16:22,953 train 000 2.728968e-02 -0.339558
2019-11-05 06:16:33,470 train 050 2.417535e-02 -212.431792
2019-11-05 06:16:43,955 train 100 2.433393e-02 -107.604828
2019-11-05 06:16:54,457 train 150 2.415592e-02 -72.192166
2019-11-05 06:17:04,957 train 200 2.420619e-02 -54.320106
2019-11-05 06:17:15,438 train 250 2.422953e-02 -43.592060
2019-11-05 06:17:25,884 train 300 2.419620e-02 -36.435456
2019-11-05 06:17:36,396 train 350 2.414347e-02 -31.312457
2019-11-05 06:17:46,906 train 400 2.415226e-02 -27.460998
2019-11-05 06:17:57,344 train 450 2.415238e-02 -24.455452
2019-11-05 06:18:07,836 train 500 2.414874e-02 -22.061179
2019-11-05 06:18:18,350 train 550 2.418857e-02 -20.124019
2019-11-05 06:18:28,913 train 600 2.418210e-02 -18.490735
2019-11-05 06:18:39,502 train 650 2.415822e-02 -17.103825
2019-11-05 06:18:50,043 train 700 2.412738e-02 -15.912305
2019-11-05 06:19:00,611 train 750 2.410075e-02 -15.125066
2019-11-05 06:19:11,086 train 800 2.413016e-02 -14.217765
2019-11-05 06:19:21,477 train 850 2.416151e-02 -13.403609
2019-11-05 06:19:24,563 training loss; R2: 2.416876e-02 -13.183438
2019-11-05 06:19:25,150 valid 000 2.356006e-02 -0.517869
2019-11-05 06:19:35,517 valid 050 2.240233e-02 -0.425992
2019-11-05 06:19:44,681 validation loss; R2: 2.212351e-02 -0.462212
2019-11-05 06:19:44,740 epoch 165 lr 5.000000e-04
2019-11-05 06:19:45,453 train 000 1.991104e-02 -0.019596
2019-11-05 06:19:55,812 train 050 2.377469e-02 -0.317541
2019-11-05 06:20:06,090 train 100 2.383083e-02 -0.357252
2019-11-05 06:20:16,391 train 150 2.400315e-02 -0.430600
2019-11-05 06:20:26,701 train 200 2.410162e-02 -0.451494
2019-11-05 06:20:37,053 train 250 2.417563e-02 -0.453063
2019-11-05 06:20:47,386 train 300 2.416137e-02 -0.444775
2019-11-05 06:20:57,595 train 350 2.420783e-02 -0.443546
2019-11-05 06:21:07,852 train 400 2.423492e-02 -0.456666
2019-11-05 06:21:18,210 train 450 2.423080e-02 -0.447048
2019-11-05 06:21:28,470 train 500 2.419990e-02 -0.443765
2019-11-05 06:21:38,768 train 550 2.417103e-02 -0.432542
2019-11-05 06:21:49,119 train 600 2.416249e-02 -0.439977
2019-11-05 06:21:59,428 train 650 2.417845e-02 -0.437667
2019-11-05 06:22:09,684 train 700 2.418750e-02 -0.436152
2019-11-05 06:22:19,935 train 750 2.417375e-02 -0.445151
2019-11-05 06:22:30,280 train 800 2.419693e-02 -0.440252
2019-11-05 06:22:40,551 train 850 2.417863e-02 -0.554753
2019-11-05 06:22:43,600 training loss; R2: 2.417653e-02 -0.548955
2019-11-05 06:22:44,199 valid 000 2.094930e-02 -0.173977
2019-11-05 06:22:54,122 valid 050 2.137709e-02 -0.371816
2019-11-05 06:23:03,434 validation loss; R2: 2.130197e-02 -0.352127
2019-11-05 06:23:03,498 epoch 166 lr 5.000000e-04
2019-11-05 06:23:04,228 train 000 2.616255e-02 -0.577688
2019-11-05 06:23:14,520 train 050 2.376817e-02 -0.429658
2019-11-05 06:23:24,843 train 100 2.432421e-02 -0.353481
2019-11-05 06:23:35,260 train 150 2.447776e-02 -0.388939
2019-11-05 06:23:45,473 train 200 2.446743e-02 -0.393205
2019-11-05 06:23:55,825 train 250 2.445953e-02 -0.420123
2019-11-05 06:24:06,297 train 300 2.432156e-02 -0.423463
2019-11-05 06:24:16,557 train 350 2.437985e-02 -0.463499
2019-11-05 06:24:26,905 train 400 2.435848e-02 -0.460750
2019-11-05 06:24:37,207 train 450 2.430136e-02 -0.463723
2019-11-05 06:24:47,555 train 500 2.429678e-02 -0.453414
2019-11-05 06:24:57,972 train 550 2.428399e-02 -0.461572
2019-11-05 06:25:08,166 train 600 2.427572e-02 -0.475044
2019-11-05 06:25:18,462 train 650 2.429997e-02 -0.476581
2019-11-05 06:25:28,842 train 700 2.428134e-02 -0.475183
2019-11-05 06:25:39,171 train 750 2.424804e-02 -0.526092
2019-11-05 06:25:49,450 train 800 2.422347e-02 -0.523332
2019-11-05 06:25:59,637 train 850 2.422782e-02 -0.514921
2019-11-05 06:26:02,631 training loss; R2: 2.420926e-02 -0.520335
2019-11-05 06:26:03,205 valid 000 1.924538e-02 -0.133038
2019-11-05 06:26:13,476 valid 050 2.102130e-02 -0.253907
2019-11-05 06:26:22,698 validation loss; R2: 2.112799e-02 -0.341400
2019-11-05 06:26:22,768 epoch 167 lr 5.000000e-04
2019-11-05 06:26:23,467 train 000 2.681609e-02 -0.166931
2019-11-05 06:26:33,912 train 050 2.429669e-02 -0.435649
2019-11-05 06:26:44,385 train 100 2.402176e-02 -0.656638
2019-11-05 06:26:54,767 train 150 2.404841e-02 -0.633564
2019-11-05 06:27:05,110 train 200 2.408808e-02 -0.609086
2019-11-05 06:27:15,475 train 250 2.408742e-02 -0.571687
2019-11-05 06:27:25,818 train 300 2.411364e-02 -0.550477
2019-11-05 06:27:36,160 train 350 2.411768e-02 -0.525509
2019-11-05 06:27:46,478 train 400 2.412990e-02 -0.544464
2019-11-05 06:27:56,777 train 450 2.413035e-02 -0.536752
2019-11-05 06:28:07,075 train 500 2.411253e-02 -0.522172
2019-11-05 06:28:17,367 train 550 2.405858e-02 -0.518785
2019-11-05 06:28:27,769 train 600 2.411996e-02 -0.525346
2019-11-05 06:28:38,123 train 650 2.413183e-02 -0.564760
2019-11-05 06:28:48,470 train 700 2.414590e-02 -0.559652
2019-11-05 06:28:58,806 train 750 2.420549e-02 -0.545119
2019-11-05 06:29:09,106 train 800 2.416908e-02 -0.542719
2019-11-05 06:29:19,413 train 850 2.416540e-02 -0.537463
2019-11-05 06:29:22,437 training loss; R2: 2.415840e-02 -0.542036
2019-11-05 06:29:23,040 valid 000 2.423894e-02 -0.025834
2019-11-05 06:29:32,957 valid 050 2.291222e-02 -0.653725
2019-11-05 06:29:42,264 validation loss; R2: 2.303275e-02 -0.625733
2019-11-05 06:29:42,335 epoch 168 lr 5.000000e-04
2019-11-05 06:29:43,109 train 000 2.330423e-02 -0.038485
2019-11-05 06:29:53,652 train 050 2.431231e-02 -0.420800
2019-11-05 06:30:03,990 train 100 2.416831e-02 -0.443716
2019-11-05 06:30:14,345 train 150 2.419450e-02 -0.588885
2019-11-05 06:30:24,670 train 200 2.416020e-02 -0.545430
2019-11-05 06:30:35,012 train 250 2.427740e-02 -0.542048
2019-11-05 06:30:45,349 train 300 2.430773e-02 -0.515824
2019-11-05 06:30:55,689 train 350 2.434941e-02 -0.504570
2019-11-05 06:31:06,124 train 400 2.430000e-02 -0.501850
2019-11-05 06:31:16,409 train 450 2.427511e-02 -0.498582
2019-11-05 06:31:26,730 train 500 2.428821e-02 -0.493780
2019-11-05 06:31:37,041 train 550 2.422117e-02 -0.497889
2019-11-05 06:31:47,359 train 600 2.416731e-02 -0.495586
2019-11-05 06:31:57,693 train 650 2.415639e-02 -0.491905
2019-11-05 06:32:08,024 train 700 2.410109e-02 -0.489994
2019-11-05 06:32:18,368 train 750 2.409132e-02 -0.495049
2019-11-05 06:32:28,747 train 800 2.406761e-02 -0.491480
2019-11-05 06:32:38,906 train 850 2.409516e-02 -1.679125
2019-11-05 06:32:41,954 training loss; R2: 2.409387e-02 -1.656161
2019-11-05 06:32:42,518 valid 000 2.285728e-02 -0.243444
2019-11-05 06:32:52,714 valid 050 2.167016e-02 -0.488952
2019-11-05 06:33:01,895 validation loss; R2: 2.146506e-02 -0.445361
2019-11-05 06:33:01,955 epoch 169 lr 5.000000e-04
2019-11-05 06:33:02,668 train 000 2.571945e-02 -0.596176
2019-11-05 06:33:12,996 train 050 2.475275e-02 -0.452224
2019-11-05 06:33:23,356 train 100 2.432815e-02 -0.422808
2019-11-05 06:33:33,762 train 150 2.435536e-02 -0.428475
2019-11-05 06:33:44,044 train 200 2.445428e-02 -0.450952
2019-11-05 06:33:54,341 train 250 2.427802e-02 -0.450611
2019-11-05 06:34:04,598 train 300 2.432309e-02 -0.455744
2019-11-05 06:34:14,889 train 350 2.433306e-02 -0.478965
2019-11-05 06:34:25,187 train 400 2.429910e-02 -0.476135
2019-11-05 06:34:35,433 train 450 2.425655e-02 -0.465853
2019-11-05 06:34:45,687 train 500 2.421629e-02 -0.456647
2019-11-05 06:34:55,891 train 550 2.418072e-02 -0.470558
2019-11-05 06:35:06,155 train 600 2.417936e-02 -0.472313
2019-11-05 06:35:16,426 train 650 2.419002e-02 -0.463199
2019-11-05 06:35:26,669 train 700 2.417266e-02 -0.465912
2019-11-05 06:35:36,949 train 750 2.414701e-02 -0.556673
2019-11-05 06:35:47,251 train 800 2.419758e-02 -0.550729
2019-11-05 06:35:57,528 train 850 2.419456e-02 -0.542417
2019-11-05 06:36:00,567 training loss; R2: 2.418950e-02 -0.540414
2019-11-05 06:36:01,101 valid 000 2.308372e-02 -0.355586
2019-11-05 06:36:11,459 valid 050 2.193622e-02 -0.332612
2019-11-05 06:36:20,568 validation loss; R2: 2.165902e-02 -0.453189
2019-11-05 06:36:20,640 epoch 170 lr 5.000000e-04
2019-11-05 06:36:21,380 train 000 2.360235e-02 -0.471167
2019-11-05 06:36:31,754 train 050 2.453135e-02 -0.379318
2019-11-05 06:36:42,085 train 100 2.430256e-02 -0.411425
2019-11-05 06:36:52,383 train 150 2.428984e-02 -0.412531
2019-11-05 06:37:02,687 train 200 2.424033e-02 -0.413343
2019-11-05 06:37:13,009 train 250 2.417942e-02 -0.406937
2019-11-05 06:37:23,318 train 300 2.426959e-02 -0.387579
2019-11-05 06:37:33,620 train 350 2.426714e-02 -0.386460
2019-11-05 06:37:43,959 train 400 2.420597e-02 -0.403280
2019-11-05 06:37:54,303 train 450 2.419071e-02 -0.414662
2019-11-05 06:38:04,635 train 500 2.414397e-02 -0.436347
2019-11-05 06:38:14,932 train 550 2.416099e-02 -0.438307
2019-11-05 06:38:25,212 train 600 2.416306e-02 -0.437898
2019-11-05 06:38:35,503 train 650 2.415206e-02 -0.451273
2019-11-05 06:38:45,783 train 700 2.416164e-02 -0.467542
2019-11-05 06:38:56,093 train 750 2.418123e-02 -0.468971
2019-11-05 06:39:06,384 train 800 2.416850e-02 -0.469780
2019-11-05 06:39:16,650 train 850 2.415408e-02 -0.468274
2019-11-05 06:39:19,761 training loss; R2: 2.412899e-02 -0.474983
2019-11-05 06:39:20,328 valid 000 2.574704e-02 0.039866
2019-11-05 06:39:30,327 valid 050 2.109153e-02 -0.376652
2019-11-05 06:39:39,744 validation loss; R2: 2.139434e-02 -0.457803
2019-11-05 06:39:39,814 epoch 171 lr 5.000000e-04
2019-11-05 06:39:40,576 train 000 2.466861e-02 -0.452074
2019-11-05 06:39:50,822 train 050 2.442127e-02 -0.475679
2019-11-05 06:40:01,077 train 100 2.440209e-02 -0.433419
2019-11-05 06:40:11,374 train 150 2.445902e-02 -0.467105
2019-11-05 06:40:21,635 train 200 2.432812e-02 -0.447278
2019-11-05 06:40:31,894 train 250 2.426971e-02 -0.431220
2019-11-05 06:40:42,149 train 300 2.420557e-02 -0.437699
2019-11-05 06:40:52,434 train 350 2.414031e-02 -0.461743
2019-11-05 06:41:02,692 train 400 2.412758e-02 -0.479263
2019-11-05 06:41:12,956 train 450 2.409189e-02 -0.503666
2019-11-05 06:41:23,207 train 500 2.406101e-02 -0.518120
2019-11-05 06:41:33,487 train 550 2.407526e-02 -0.507439
2019-11-05 06:41:43,756 train 600 2.407401e-02 -0.499595
2019-11-05 06:41:54,024 train 650 2.408655e-02 -0.494166
2019-11-05 06:42:04,281 train 700 2.409354e-02 -0.495269
2019-11-05 06:42:14,538 train 750 2.411836e-02 -0.496480
2019-11-05 06:42:24,815 train 800 2.409580e-02 -0.498714
2019-11-05 06:42:35,093 train 850 2.408809e-02 -0.491516
2019-11-05 06:42:38,118 training loss; R2: 2.408479e-02 -0.489064
2019-11-05 06:42:38,700 valid 000 1.985279e-02 -0.154264
2019-11-05 06:42:48,929 valid 050 2.090578e-02 -0.510156
2019-11-05 06:42:57,960 validation loss; R2: 2.095520e-02 -0.516452
2019-11-05 06:42:58,027 epoch 172 lr 5.000000e-04
2019-11-05 06:42:58,825 train 000 2.339991e-02 -0.096915
2019-11-05 06:43:09,107 train 050 2.371590e-02 -0.474698
2019-11-05 06:43:19,382 train 100 2.405103e-02 -0.458782
2019-11-05 06:43:29,686 train 150 2.408494e-02 -0.494324
2019-11-05 06:43:40,006 train 200 2.401852e-02 -0.487179
2019-11-05 06:43:50,332 train 250 2.408852e-02 -0.516624
2019-11-05 06:44:00,628 train 300 2.414089e-02 -0.511514
2019-11-05 06:44:10,890 train 350 2.415045e-02 -0.493123
2019-11-05 06:44:21,162 train 400 2.417503e-02 -0.497101
2019-11-05 06:44:31,457 train 450 2.415418e-02 -0.486304
2019-11-05 06:44:41,754 train 500 2.417364e-02 -0.496511
2019-11-05 06:44:52,053 train 550 2.411468e-02 -0.478539
2019-11-05 06:45:02,337 train 600 2.410625e-02 -0.472686
2019-11-05 06:45:12,624 train 650 2.409373e-02 -0.465671
2019-11-05 06:45:22,938 train 700 2.410233e-02 -0.463419
2019-11-05 06:45:33,269 train 750 2.408682e-02 -0.459360
2019-11-05 06:45:43,594 train 800 2.411726e-02 -0.465801
2019-11-05 06:45:53,925 train 850 2.411669e-02 -0.463554
2019-11-05 06:45:56,982 training loss; R2: 2.411578e-02 -0.463518
2019-11-05 06:45:57,543 valid 000 2.142577e-02 -0.011023
2019-11-05 06:46:07,557 valid 050 2.182894e-02 -0.351407
2019-11-05 06:46:16,724 validation loss; R2: 2.158047e-02 -0.350917
2019-11-05 06:46:16,794 epoch 173 lr 5.000000e-04
2019-11-05 06:46:17,472 train 000 2.247225e-02 -0.727045
2019-11-05 06:46:27,950 train 050 2.429618e-02 -0.365074
2019-11-05 06:46:38,283 train 100 2.429507e-02 -0.359349
2019-11-05 06:46:48,629 train 150 2.414804e-02 -0.358960
2019-11-05 06:46:58,946 train 200 2.422145e-02 -0.397393
2019-11-05 06:47:09,251 train 250 2.417519e-02 -0.424080
2019-11-05 06:47:19,565 train 300 2.421871e-02 -0.427751
2019-11-05 06:47:29,879 train 350 2.417810e-02 -0.421609
2019-11-05 06:47:40,191 train 400 2.422337e-02 -0.417458
2019-11-05 06:47:50,525 train 450 2.422003e-02 -0.417533
2019-11-05 06:48:00,851 train 500 2.417070e-02 -0.425079
2019-11-05 06:48:11,165 train 550 2.416863e-02 -0.435576
2019-11-05 06:48:21,413 train 600 2.417825e-02 -0.466673
2019-11-05 06:48:31,654 train 650 2.416323e-02 -0.467481
2019-11-05 06:48:41,958 train 700 2.413547e-02 -0.474627
2019-11-05 06:48:52,270 train 750 2.414672e-02 -0.473598
2019-11-05 06:49:02,596 train 800 2.413297e-02 -0.468869
2019-11-05 06:49:12,907 train 850 2.412470e-02 -0.471092
2019-11-05 06:49:16,007 training loss; R2: 2.411706e-02 -0.473159
2019-11-05 06:49:16,599 valid 000 2.125792e-02 -0.784434
2019-11-05 06:49:26,609 valid 050 2.122147e-02 -0.444543
2019-11-05 06:49:35,749 validation loss; R2: 2.103998e-02 -0.535591
2019-11-05 06:49:35,818 epoch 174 lr 5.000000e-04
2019-11-05 06:49:36,550 train 000 2.401076e-02 -0.190017
2019-11-05 06:49:46,873 train 050 2.409900e-02 -0.469306
2019-11-05 06:49:57,223 train 100 2.404851e-02 -0.464329
2019-11-05 06:50:07,585 train 150 2.401128e-02 -0.427757
2019-11-05 06:50:17,926 train 200 2.407327e-02 -0.452535
2019-11-05 06:50:28,258 train 250 2.404963e-02 -0.471350
2019-11-05 06:50:38,537 train 300 2.400374e-02 -0.483825
2019-11-05 06:50:48,808 train 350 2.410099e-02 -0.469848
2019-11-05 06:50:59,121 train 400 2.411179e-02 -0.460559
2019-11-05 06:51:09,429 train 450 2.416361e-02 -0.461768
2019-11-05 06:51:19,757 train 500 2.424099e-02 -0.458468
2019-11-05 06:51:30,026 train 550 2.428760e-02 -0.489800
2019-11-05 06:51:40,305 train 600 2.426176e-02 -0.484919
2019-11-05 06:51:50,652 train 650 2.425894e-02 -0.489230
2019-11-05 06:52:01,000 train 700 2.422359e-02 -0.491059
2019-11-05 06:52:11,379 train 750 2.420169e-02 -0.489553
2019-11-05 06:52:21,732 train 800 2.415217e-02 -0.497276
2019-11-05 06:52:32,080 train 850 2.413784e-02 -0.499772
2019-11-05 06:52:35,190 training loss; R2: 2.414240e-02 -0.495329
2019-11-05 06:52:35,792 valid 000 2.169488e-02 0.017131
2019-11-05 06:52:45,764 valid 050 2.176520e-02 -0.376759
2019-11-05 06:52:54,967 validation loss; R2: 2.187665e-02 -0.376122
2019-11-05 06:52:55,043 epoch 175 lr 5.000000e-04
2019-11-05 06:52:55,791 train 000 2.301048e-02 -0.766498
2019-11-05 06:53:06,415 train 050 2.402486e-02 -0.544227
2019-11-05 06:53:16,952 train 100 2.411657e-02 -0.489630
2019-11-05 06:53:27,454 train 150 2.401233e-02 -0.456562
2019-11-05 06:53:37,935 train 200 2.405101e-02 -0.452211
2019-11-05 06:53:48,391 train 250 2.405623e-02 -0.433872
2019-11-05 06:53:58,863 train 300 2.401496e-02 -0.432573
2019-11-05 06:54:09,352 train 350 2.405772e-02 -0.443191
2019-11-05 06:54:19,815 train 400 2.409123e-02 -0.455940
2019-11-05 06:54:30,297 train 450 2.410656e-02 -0.484322
2019-11-05 06:54:40,772 train 500 2.406249e-02 -0.489493
2019-11-05 06:54:51,239 train 550 2.405265e-02 -0.775459
2019-11-05 06:55:01,702 train 600 2.404213e-02 -0.747766
2019-11-05 06:55:12,156 train 650 2.407946e-02 -0.730355
2019-11-05 06:55:22,618 train 700 2.407856e-02 -0.711587
2019-11-05 06:55:33,063 train 750 2.410282e-02 -0.938406
2019-11-05 06:55:43,517 train 800 2.412571e-02 -0.916582
2019-11-05 06:55:53,855 train 850 2.413369e-02 -0.888577
2019-11-05 06:55:56,860 training loss; R2: 2.412053e-02 -0.878662
2019-11-05 06:55:57,441 valid 000 2.004969e-02 -0.886380
2019-11-05 06:56:07,527 valid 050 2.175349e-02 -0.419214
2019-11-05 06:56:16,776 validation loss; R2: 2.210187e-02 -0.444605
2019-11-05 06:56:16,844 epoch 176 lr 5.000000e-04
2019-11-05 06:56:17,537 train 000 2.428379e-02 -0.123055
2019-11-05 06:56:27,804 train 050 2.364126e-02 -0.489131
2019-11-05 06:56:38,137 train 100 2.394991e-02 -0.462189
2019-11-05 06:56:48,509 train 150 2.401019e-02 -0.456590
2019-11-05 06:56:58,741 train 200 2.399193e-02 -0.462648
2019-11-05 06:57:09,069 train 250 2.391909e-02 -0.471668
2019-11-05 06:57:19,471 train 300 2.410721e-02 -0.480907
2019-11-05 06:57:29,705 train 350 2.410457e-02 -0.471849
2019-11-05 06:57:40,012 train 400 2.414416e-02 -0.463919
2019-11-05 06:57:50,267 train 450 2.414318e-02 -0.453271
2019-11-05 06:58:00,662 train 500 2.413740e-02 -0.460054
2019-11-05 06:58:10,876 train 550 2.413961e-02 -0.459740
2019-11-05 06:58:21,194 train 600 2.411801e-02 -0.452870
2019-11-05 06:58:31,639 train 650 2.407247e-02 -0.449075
2019-11-05 06:58:41,837 train 700 2.405605e-02 -0.447314
2019-11-05 06:58:52,143 train 750 2.405193e-02 -0.446611
2019-11-05 06:59:02,529 train 800 2.404655e-02 -0.441028
2019-11-05 06:59:12,698 train 850 2.405034e-02 -0.449966
2019-11-05 06:59:15,776 training loss; R2: 2.404637e-02 -0.448614
2019-11-05 06:59:16,385 valid 000 2.422898e-02 -0.625330
2019-11-05 06:59:26,379 valid 050 2.399191e-02 -0.651857
2019-11-05 06:59:35,593 validation loss; R2: 2.377701e-02 -0.648969
2019-11-05 06:59:35,664 epoch 177 lr 5.000000e-04
2019-11-05 06:59:36,411 train 000 2.607494e-02 -0.490816
2019-11-05 06:59:46,896 train 050 2.416235e-02 -0.450588
2019-11-05 06:59:57,266 train 100 2.427809e-02 -0.449754
2019-11-05 07:00:07,525 train 150 2.436609e-02 -0.454859
2019-11-05 07:00:17,763 train 200 2.423069e-02 -0.447233
2019-11-05 07:00:28,000 train 250 2.412800e-02 -0.460514
2019-11-05 07:00:38,214 train 300 2.411972e-02 -0.483097
2019-11-05 07:00:48,431 train 350 2.405221e-02 -0.563611
2019-11-05 07:00:58,629 train 400 2.405054e-02 -0.545232
2019-11-05 07:01:08,818 train 450 2.403206e-02 -0.534026
2019-11-05 07:01:19,026 train 500 2.398581e-02 -0.538950
2019-11-05 07:01:29,210 train 550 2.396684e-02 -0.541063
2019-11-05 07:01:39,411 train 600 2.399959e-02 -0.524232
2019-11-05 07:01:49,630 train 650 2.403307e-02 -0.515424
2019-11-05 07:01:59,812 train 700 2.400270e-02 -0.534289
2019-11-05 07:02:10,013 train 750 2.401977e-02 -0.525710
2019-11-05 07:02:20,145 train 800 2.402385e-02 -0.515721
2019-11-05 07:02:30,235 train 850 2.403151e-02 -0.511412
2019-11-05 07:02:33,210 training loss; R2: 2.402441e-02 -0.506730
2019-11-05 07:02:33,783 valid 000 2.116205e-02 -0.184070
2019-11-05 07:02:43,826 valid 050 2.191177e-02 -0.275422
2019-11-05 07:02:52,938 validation loss; R2: 2.153081e-02 -0.341500
2019-11-05 07:02:52,997 epoch 178 lr 5.000000e-04
2019-11-05 07:02:53,712 train 000 2.417458e-02 -0.070965
2019-11-05 07:03:04,059 train 050 2.415960e-02 -0.432840
2019-11-05 07:03:14,294 train 100 2.378041e-02 -0.527197
2019-11-05 07:03:24,498 train 150 2.386891e-02 -0.479679
2019-11-05 07:03:34,686 train 200 2.387352e-02 -0.493715
2019-11-05 07:03:44,893 train 250 2.387075e-02 -0.523084
2019-11-05 07:03:55,095 train 300 2.386237e-02 -0.510174
2019-11-05 07:04:05,313 train 350 2.396426e-02 -0.502814
2019-11-05 07:04:15,449 train 400 2.396321e-02 -0.492462
2019-11-05 07:04:25,642 train 450 2.390385e-02 -0.484892
2019-11-05 07:04:35,798 train 500 2.389198e-02 -0.474572
2019-11-05 07:04:45,941 train 550 2.389122e-02 -0.469934
2019-11-05 07:04:56,170 train 600 2.386479e-02 -0.486514
2019-11-05 07:05:06,375 train 650 2.392063e-02 -0.486889
2019-11-05 07:05:16,490 train 700 2.391953e-02 -0.502530
2019-11-05 07:05:26,579 train 750 2.392160e-02 -0.508836
2019-11-05 07:05:36,821 train 800 2.389354e-02 -0.508290
2019-11-05 07:05:46,900 train 850 2.389980e-02 -0.513568
2019-11-05 07:05:49,937 training loss; R2: 2.389044e-02 -0.515630
2019-11-05 07:05:50,555 valid 000 1.748421e-02 -0.188509
2019-11-05 07:06:00,529 valid 050 2.079232e-02 -0.462682
2019-11-05 07:06:09,657 validation loss; R2: 2.088662e-02 -0.417138
2019-11-05 07:06:09,730 epoch 179 lr 5.000000e-04
2019-11-05 07:06:10,467 train 000 1.768037e-02 -0.336722
2019-11-05 07:06:20,930 train 050 2.419745e-02 -0.433400
2019-11-05 07:06:31,279 train 100 2.392978e-02 -0.434657
2019-11-05 07:06:41,582 train 150 2.413841e-02 -0.440835
2019-11-05 07:06:51,856 train 200 2.402037e-02 -0.449793
2019-11-05 07:07:02,170 train 250 2.398930e-02 -0.456364
2019-11-05 07:07:12,495 train 300 2.397030e-02 -0.449967
2019-11-05 07:07:22,811 train 350 2.394889e-02 -0.460612
2019-11-05 07:07:33,120 train 400 2.389047e-02 -0.472670
2019-11-05 07:07:43,394 train 450 2.389562e-02 -0.479173
2019-11-05 07:07:53,692 train 500 2.393143e-02 -0.476799
2019-11-05 07:08:04,025 train 550 2.397166e-02 -0.472673
2019-11-05 07:08:14,394 train 600 2.394904e-02 -0.467058
2019-11-05 07:08:24,753 train 650 2.392058e-02 -0.463730
2019-11-05 07:08:35,140 train 700 2.392584e-02 -0.461860
2019-11-05 07:08:45,443 train 750 2.395134e-02 -0.458763
2019-11-05 07:08:55,658 train 800 2.392947e-02 -0.581942
2019-11-05 07:09:05,882 train 850 2.392208e-02 -0.573150
2019-11-05 07:09:08,914 training loss; R2: 2.393302e-02 -0.572755
2019-11-05 07:09:09,461 valid 000 1.971217e-02 -0.370498
2019-11-05 07:09:19,834 valid 050 2.088179e-02 -0.305878
2019-11-05 07:09:29,131 validation loss; R2: 2.093609e-02 -0.503053
2019-11-05 07:09:29,215 epoch 180 lr 5.000000e-04
2019-11-05 07:09:29,897 train 000 2.556418e-02 -0.101685
2019-11-05 07:09:40,338 train 050 2.408560e-02 -0.454825
2019-11-05 07:09:50,829 train 100 2.431202e-02 -0.427660
2019-11-05 07:10:01,234 train 150 2.418804e-02 -0.475735
2019-11-05 07:10:11,531 train 200 2.413229e-02 -0.508404
2019-11-05 07:10:21,734 train 250 2.403559e-02 -0.497208
2019-11-05 07:10:31,854 train 300 2.393327e-02 -0.501871
2019-11-05 07:10:42,114 train 350 2.395018e-02 -0.520636
2019-11-05 07:10:52,280 train 400 2.391481e-02 -0.535016
2019-11-05 07:11:02,421 train 450 2.391626e-02 -0.519762
2019-11-05 07:11:12,583 train 500 2.393653e-02 -0.508954
2019-11-05 07:11:22,752 train 550 2.388482e-02 -0.499173
2019-11-05 07:11:32,940 train 600 2.389606e-02 -0.506883
2019-11-05 07:11:43,146 train 650 2.390226e-02 -0.495369
2019-11-05 07:11:53,359 train 700 2.389442e-02 -0.490840
2019-11-05 07:12:03,567 train 750 2.391100e-02 -0.495127
2019-11-05 07:12:13,769 train 800 2.393526e-02 -0.514367
2019-11-05 07:12:23,970 train 850 2.392225e-02 -0.509028
2019-11-05 07:12:26,999 training loss; R2: 2.391256e-02 -0.507694
2019-11-05 07:12:27,595 valid 000 1.783287e-02 -0.407323
2019-11-05 07:12:37,787 valid 050 2.188963e-02 -0.567704
2019-11-05 07:12:46,645 validation loss; R2: 2.187454e-02 -0.569206
2019-11-05 07:12:46,706 epoch 181 lr 5.000000e-04
2019-11-05 07:12:47,465 train 000 2.529202e-02 -0.194001
2019-11-05 07:12:57,486 train 050 2.380282e-02 -0.498396
2019-11-05 07:13:07,511 train 100 2.343426e-02 -0.448975
2019-11-05 07:13:17,547 train 150 2.354667e-02 -0.519043
2019-11-05 07:13:27,576 train 200 2.366883e-02 -0.492256
2019-11-05 07:13:37,705 train 250 2.369543e-02 -0.487717
2019-11-05 07:13:48,066 train 300 2.375629e-02 -0.480654
2019-11-05 07:13:58,463 train 350 2.378670e-02 -0.477454
2019-11-05 07:14:08,774 train 400 2.379259e-02 -0.462526
2019-11-05 07:14:19,013 train 450 2.381160e-02 -0.468855
2019-11-05 07:14:29,281 train 500 2.383305e-02 -0.487125
2019-11-05 07:14:39,570 train 550 2.385915e-02 -0.488268
2019-11-05 07:14:49,883 train 600 2.388905e-02 -0.495904
2019-11-05 07:15:00,151 train 650 2.388501e-02 -0.485690
2019-11-05 07:15:10,459 train 700 2.386707e-02 -0.539043
2019-11-05 07:15:20,770 train 750 2.385658e-02 -0.533190
2019-11-05 07:15:31,096 train 800 2.383851e-02 -0.537847
2019-11-05 07:15:41,426 train 850 2.382642e-02 -0.537215
2019-11-05 07:15:44,477 training loss; R2: 2.382465e-02 -0.533243
2019-11-05 07:15:45,034 valid 000 2.275967e-02 -0.506674
2019-11-05 07:15:55,442 valid 050 2.123413e-02 -0.279825
2019-11-05 07:16:04,563 validation loss; R2: 2.130447e-02 -0.352178
2019-11-05 07:16:04,639 epoch 182 lr 5.000000e-04
2019-11-05 07:16:05,371 train 000 2.207567e-02 -0.419094
2019-11-05 07:16:15,886 train 050 2.313053e-02 -0.549103
2019-11-05 07:16:26,343 train 100 2.358164e-02 -0.559010
2019-11-05 07:16:36,818 train 150 2.368765e-02 -0.538710
2019-11-05 07:16:47,299 train 200 2.385116e-02 -0.505013
2019-11-05 07:16:57,774 train 250 2.375994e-02 -0.511120
2019-11-05 07:17:08,242 train 300 2.376887e-02 -0.489324
2019-11-05 07:17:18,689 train 350 2.380266e-02 -0.495116
2019-11-05 07:17:29,141 train 400 2.381389e-02 -0.493874
2019-11-05 07:17:39,601 train 450 2.385172e-02 -0.577479
2019-11-05 07:17:50,055 train 500 2.381116e-02 -0.565114
2019-11-05 07:18:00,516 train 550 2.378805e-02 -0.550497
2019-11-05 07:18:10,953 train 600 2.383063e-02 -0.548985
2019-11-05 07:18:21,399 train 650 2.385657e-02 -0.553489
2019-11-05 07:18:31,841 train 700 2.386948e-02 -0.547923
2019-11-05 07:18:42,277 train 750 2.386689e-02 -0.549637
2019-11-05 07:18:52,688 train 800 2.385710e-02 -0.546041
2019-11-05 07:19:03,053 train 850 2.383759e-02 -0.532747
2019-11-05 07:19:06,006 training loss; R2: 2.383935e-02 -0.530242
2019-11-05 07:19:06,521 valid 000 2.003130e-02 -1.185318
2019-11-05 07:19:16,275 valid 050 2.127966e-02 -0.682153
2019-11-05 07:19:24,932 validation loss; R2: 2.121449e-02 -0.629287
2019-11-05 07:19:25,011 epoch 183 lr 5.000000e-04
2019-11-05 07:19:25,698 train 000 2.604998e-02 -0.071203
2019-11-05 07:19:35,939 train 050 2.359284e-02 -0.462222
2019-11-05 07:19:46,226 train 100 2.353189e-02 -0.442727
2019-11-05 07:19:56,544 train 150 2.355584e-02 -0.488225
2019-11-05 07:20:06,903 train 200 2.362193e-02 -0.479649
2019-11-05 07:20:17,230 train 250 2.364358e-02 -0.980294
2019-11-05 07:20:27,541 train 300 2.371953e-02 -0.895264
2019-11-05 07:20:37,853 train 350 2.372081e-02 -0.824125
2019-11-05 07:20:48,166 train 400 2.368073e-02 -0.768012
2019-11-05 07:20:58,456 train 450 2.363885e-02 -0.741405
2019-11-05 07:21:08,727 train 500 2.364244e-02 -0.705228
2019-11-05 07:21:18,974 train 550 2.364735e-02 -0.675477
2019-11-05 07:21:29,247 train 600 2.367269e-02 -0.659926
2019-11-05 07:21:39,495 train 650 2.365478e-02 -0.643822
2019-11-05 07:21:49,763 train 700 2.369103e-02 -0.635666
2019-11-05 07:22:00,051 train 750 2.368827e-02 -0.634194
2019-11-05 07:22:10,382 train 800 2.368959e-02 -0.621030
2019-11-05 07:22:20,731 train 850 2.366650e-02 -0.613180
2019-11-05 07:22:23,843 training loss; R2: 2.367084e-02 -0.609827
2019-11-05 07:22:24,414 valid 000 1.994303e-02 -0.768385
2019-11-05 07:22:34,704 valid 050 2.221396e-02 -0.584702
2019-11-05 07:22:44,021 validation loss; R2: 2.211544e-02 -0.723238
2019-11-05 07:22:44,090 epoch 184 lr 5.000000e-04
2019-11-05 07:22:44,841 train 000 2.074229e-02 -0.196127
2019-11-05 07:22:55,246 train 050 2.393060e-02 -0.380535
2019-11-05 07:23:05,575 train 100 2.369692e-02 -0.442087
2019-11-05 07:23:15,886 train 150 2.374087e-02 -0.439976
2019-11-05 07:23:26,237 train 200 2.382205e-02 -0.448474
2019-11-05 07:23:36,569 train 250 2.381982e-02 -0.458460
2019-11-05 07:23:46,917 train 300 2.381040e-02 -0.449206
2019-11-05 07:23:57,267 train 350 2.375885e-02 -0.444848
2019-11-05 07:24:07,601 train 400 2.373962e-02 -0.447361
2019-11-05 07:24:17,943 train 450 2.370003e-02 -0.459280
2019-11-05 07:24:28,269 train 500 2.368118e-02 -0.470515
2019-11-05 07:24:38,602 train 550 2.367931e-02 -0.471746
2019-11-05 07:24:48,941 train 600 2.363475e-02 -0.485320
2019-11-05 07:24:59,309 train 650 2.363144e-02 -0.501179
2019-11-05 07:25:09,688 train 700 2.363049e-02 -0.497318
2019-11-05 07:25:20,073 train 750 2.367258e-02 -0.490008
2019-11-05 07:25:30,445 train 800 2.368293e-02 -2.184697
2019-11-05 07:25:40,824 train 850 2.366964e-02 -2.084496
2019-11-05 07:25:43,847 training loss; R2: 2.367363e-02 -2.055517
2019-11-05 07:25:44,404 valid 000 2.477544e-02 -0.510859
2019-11-05 07:25:54,420 valid 050 2.408466e-02 -0.484128
2019-11-05 07:26:03,535 validation loss; R2: 2.404962e-02 -0.476612
2019-11-05 07:26:03,599 epoch 185 lr 5.000000e-04
2019-11-05 07:26:04,296 train 000 2.276056e-02 -0.311093
2019-11-05 07:26:14,633 train 050 2.387091e-02 -0.851689
2019-11-05 07:26:24,924 train 100 2.349649e-02 -0.616922
2019-11-05 07:26:35,210 train 150 2.340099e-02 -0.538730
2019-11-05 07:26:45,491 train 200 2.348321e-02 -0.562662
2019-11-05 07:26:55,750 train 250 2.349325e-02 -0.531479
2019-11-05 07:27:06,003 train 300 2.354566e-02 -0.514776
2019-11-05 07:27:16,228 train 350 2.357243e-02 -0.491130
2019-11-05 07:27:26,481 train 400 2.359084e-02 -0.471181
2019-11-05 07:27:36,754 train 450 2.357574e-02 -0.479409
2019-11-05 07:27:47,030 train 500 2.362518e-02 -0.478383
2019-11-05 07:27:57,304 train 550 2.368410e-02 -0.485184
2019-11-05 07:28:07,531 train 600 2.371279e-02 -0.477924
2019-11-05 07:28:17,692 train 650 2.371535e-02 -0.490933
2019-11-05 07:28:27,879 train 700 2.372820e-02 -0.495600
2019-11-05 07:28:38,144 train 750 2.371089e-02 -0.496933
2019-11-05 07:28:48,389 train 800 2.368421e-02 -0.493060
2019-11-05 07:28:58,675 train 850 2.369394e-02 -0.506524
2019-11-05 07:29:01,711 training loss; R2: 2.370381e-02 -0.505009
2019-11-05 07:29:02,256 valid 000 1.899930e-02 -1.327758
2019-11-05 07:29:12,596 valid 050 2.068112e-02 -0.278173
2019-11-05 07:29:21,692 validation loss; R2: 2.054438e-02 -0.320347
2019-11-05 07:29:21,777 epoch 186 lr 5.000000e-04
2019-11-05 07:29:22,516 train 000 2.283668e-02 -0.129712
2019-11-05 07:29:32,759 train 050 2.339036e-02 -0.460996
2019-11-05 07:29:43,038 train 100 2.357168e-02 -0.590830
2019-11-05 07:29:53,294 train 150 2.350761e-02 -0.573158
2019-11-05 07:30:03,538 train 200 2.367430e-02 -0.597434
2019-11-05 07:30:13,844 train 250 2.370687e-02 -0.559748
2019-11-05 07:30:24,111 train 300 2.359081e-02 -0.568143
2019-11-05 07:30:34,362 train 350 2.364155e-02 -0.545301
2019-11-05 07:30:44,637 train 400 2.354139e-02 -0.543510
2019-11-05 07:30:54,922 train 450 2.362112e-02 -0.545334
2019-11-05 07:31:05,189 train 500 2.361541e-02 -0.543424
2019-11-05 07:31:15,466 train 550 2.359562e-02 -0.544943
2019-11-05 07:31:25,750 train 600 2.357993e-02 -0.536493
2019-11-05 07:31:36,045 train 650 2.359892e-02 -0.529743
2019-11-05 07:31:46,345 train 700 2.361361e-02 -0.520599
2019-11-05 07:31:56,609 train 750 2.364129e-02 -0.526187
2019-11-05 07:32:06,905 train 800 2.366307e-02 -0.530350
2019-11-05 07:32:17,156 train 850 2.367824e-02 -0.535049
2019-11-05 07:32:20,274 training loss; R2: 2.367781e-02 -0.532608
2019-11-05 07:32:20,839 valid 000 2.101691e-02 -0.843244
2019-11-05 07:32:30,855 valid 050 2.239392e-02 -1.333589
2019-11-05 07:32:39,928 validation loss; R2: 2.238016e-02 -1.095370
2019-11-05 07:32:40,001 epoch 187 lr 5.000000e-04
2019-11-05 07:32:40,758 train 000 2.352018e-02 -0.118089
2019-11-05 07:32:51,196 train 050 2.339880e-02 -0.366011
2019-11-05 07:33:01,687 train 100 2.363526e-02 -0.491772
2019-11-05 07:33:12,140 train 150 2.358139e-02 -0.483908
2019-11-05 07:33:22,535 train 200 2.343572e-02 -0.462776
2019-11-05 07:33:32,973 train 250 2.337687e-02 -0.469060
2019-11-05 07:33:43,392 train 300 2.349174e-02 -0.571552
2019-11-05 07:33:53,750 train 350 2.358465e-02 -0.566377
2019-11-05 07:34:04,121 train 400 2.356256e-02 -0.535695
2019-11-05 07:34:14,505 train 450 2.355290e-02 -0.541816
2019-11-05 07:34:24,954 train 500 2.355054e-02 -0.548972
2019-11-05 07:34:35,291 train 550 2.359026e-02 -0.529821
2019-11-05 07:34:45,698 train 600 2.362279e-02 -0.519678
2019-11-05 07:34:56,123 train 650 2.362455e-02 -0.516751
2019-11-05 07:35:06,507 train 700 2.358884e-02 -0.506190
2019-11-05 07:35:16,838 train 750 2.361690e-02 -0.500702
2019-11-05 07:35:27,237 train 800 2.363185e-02 -0.508093
2019-11-05 07:35:37,622 train 850 2.363674e-02 -0.499971
2019-11-05 07:35:40,692 training loss; R2: 2.362095e-02 -0.506982
2019-11-05 07:35:41,243 valid 000 1.620348e-02 -0.451862
2019-11-05 07:35:51,073 valid 050 2.093860e-02 -0.519042
2019-11-05 07:35:59,771 validation loss; R2: 2.067436e-02 -0.577854
2019-11-05 07:35:59,840 epoch 188 lr 5.000000e-04
2019-11-05 07:36:00,541 train 000 2.639372e-02 -0.093191
2019-11-05 07:36:11,042 train 050 2.355204e-02 -0.370317
2019-11-05 07:36:21,532 train 100 2.351294e-02 -0.424073
2019-11-05 07:36:32,013 train 150 2.351936e-02 -0.478232
2019-11-05 07:36:42,485 train 200 2.359046e-02 -0.463985
2019-11-05 07:36:52,967 train 250 2.362299e-02 -0.479926
2019-11-05 07:37:03,427 train 300 2.362347e-02 -0.451488
2019-11-05 07:37:13,898 train 350 2.360177e-02 -0.466178
2019-11-05 07:37:24,366 train 400 2.355556e-02 -0.481924
2019-11-05 07:37:34,834 train 450 2.352920e-02 -0.498074
2019-11-05 07:37:45,337 train 500 2.352434e-02 -0.485116
2019-11-05 07:37:55,842 train 550 2.353261e-02 -0.498247
2019-11-05 07:38:06,329 train 600 2.356547e-02 -0.495048
2019-11-05 07:38:16,813 train 650 2.360183e-02 -0.483380
2019-11-05 07:38:27,284 train 700 2.363871e-02 -0.534567
2019-11-05 07:38:37,726 train 750 2.361762e-02 -0.530578
2019-11-05 07:38:48,173 train 800 2.358625e-02 -0.528139
2019-11-05 07:38:58,587 train 850 2.358007e-02 -0.522713
2019-11-05 07:39:01,697 training loss; R2: 2.357713e-02 -0.519085
2019-11-05 07:39:02,253 valid 000 2.139403e-02 -0.019770
2019-11-05 07:39:12,560 valid 050 2.075934e-02 -0.319878
2019-11-05 07:39:21,679 validation loss; R2: 2.071552e-02 -0.368046
2019-11-05 07:39:21,745 epoch 189 lr 5.000000e-04
2019-11-05 07:39:22,459 train 000 2.107669e-02 -0.783156
2019-11-05 07:39:32,519 train 050 2.376377e-02 -0.727722
2019-11-05 07:39:42,611 train 100 2.370552e-02 -0.764901
2019-11-05 07:39:52,730 train 150 2.364505e-02 -0.718253
2019-11-05 07:40:02,811 train 200 2.359119e-02 -0.681728
2019-11-05 07:40:12,884 train 250 2.363575e-02 -0.640183
2019-11-05 07:40:22,946 train 300 2.366709e-02 -0.619648
2019-11-05 07:40:33,008 train 350 2.366326e-02 -0.593163
2019-11-05 07:40:43,074 train 400 2.364625e-02 -0.589276
2019-11-05 07:40:53,089 train 450 2.364740e-02 -0.595485
2019-11-05 07:41:03,122 train 500 2.362600e-02 -0.579612
2019-11-05 07:41:13,164 train 550 2.361845e-02 -0.563956
2019-11-05 07:41:23,194 train 600 2.363252e-02 -0.548150
2019-11-05 07:41:33,264 train 650 2.357998e-02 -0.544351
2019-11-05 07:41:43,263 train 700 2.358262e-02 -0.541349
2019-11-05 07:41:53,276 train 750 2.359910e-02 -0.532670
2019-11-05 07:42:03,305 train 800 2.360038e-02 -0.523645
2019-11-05 07:42:13,339 train 850 2.357917e-02 -0.526118
2019-11-05 07:42:16,287 training loss; R2: 2.356075e-02 -0.524261
2019-11-05 07:42:16,844 valid 000 2.181808e-02 -0.553021
2019-11-05 07:42:27,087 valid 050 2.318125e-02 -0.392953
2019-11-05 07:42:36,267 validation loss; R2: 2.330111e-02 -0.337445
2019-11-05 07:42:36,337 epoch 190 lr 5.000000e-04
2019-11-05 07:42:37,017 train 000 2.122000e-02 -0.274614
2019-11-05 07:42:47,334 train 050 2.373956e-02 -0.432136
2019-11-05 07:42:57,746 train 100 2.340529e-02 -0.478907
2019-11-05 07:43:08,202 train 150 2.359199e-02 -0.506024
2019-11-05 07:43:18,653 train 200 2.360413e-02 -0.478535
2019-11-05 07:43:29,092 train 250 2.373006e-02 -0.448375
2019-11-05 07:43:39,537 train 300 2.367040e-02 -0.451377
2019-11-05 07:43:49,972 train 350 2.364610e-02 -0.447999
2019-11-05 07:44:00,417 train 400 2.365637e-02 -0.926102
2019-11-05 07:44:10,861 train 450 2.365912e-02 -0.878608
2019-11-05 07:44:21,314 train 500 2.362208e-02 -0.826144
2019-11-05 07:44:31,776 train 550 2.362163e-02 -0.792018
2019-11-05 07:44:42,230 train 600 2.362438e-02 -0.753999
2019-11-05 07:44:52,689 train 650 2.365009e-02 -0.751652
2019-11-05 07:45:03,110 train 700 2.366848e-02 -0.730158
2019-11-05 07:45:13,543 train 750 2.367774e-02 -0.725340
2019-11-05 07:45:23,973 train 800 2.367164e-02 -0.747572
2019-11-05 07:45:34,437 train 850 2.366047e-02 -0.735627
2019-11-05 07:45:37,576 training loss; R2: 2.366041e-02 -0.727681
2019-11-05 07:45:38,127 valid 000 2.491928e-02 -0.340478
2019-11-05 07:45:48,071 valid 050 2.111957e-02 -0.385454
2019-11-05 07:45:56,864 validation loss; R2: 2.121223e-02 -0.408304
2019-11-05 07:45:56,939 epoch 191 lr 5.000000e-04
2019-11-05 07:45:57,665 train 000 2.356304e-02 -0.843849
2019-11-05 07:46:07,748 train 050 2.343794e-02 -0.327738
2019-11-05 07:46:17,838 train 100 2.343066e-02 -0.400778
2019-11-05 07:46:27,926 train 150 2.340543e-02 -0.415373
2019-11-05 07:46:37,953 train 200 2.338040e-02 -0.470191
2019-11-05 07:46:47,969 train 250 2.347173e-02 -0.451708
2019-11-05 07:46:57,981 train 300 2.349228e-02 -0.466938
2019-11-05 07:47:08,033 train 350 2.353339e-02 -0.487506
2019-11-05 07:47:18,072 train 400 2.349529e-02 -0.481289
2019-11-05 07:47:28,120 train 450 2.351345e-02 -0.483712
2019-11-05 07:47:38,272 train 500 2.357362e-02 -0.483731
2019-11-05 07:47:48,374 train 550 2.355132e-02 -0.482233
2019-11-05 07:47:58,453 train 600 2.353183e-02 -0.490540
2019-11-05 07:48:08,553 train 650 2.354151e-02 -0.490461
2019-11-05 07:48:18,565 train 700 2.356821e-02 -0.494792
2019-11-05 07:48:28,638 train 750 2.359223e-02 -0.488167
2019-11-05 07:48:38,664 train 800 2.356776e-02 -0.484368
2019-11-05 07:48:48,681 train 850 2.359759e-02 -0.475013
2019-11-05 07:48:51,679 training loss; R2: 2.360868e-02 -0.472914
2019-11-05 07:48:52,253 valid 000 2.373986e-02 -2.662891
2019-11-05 07:49:02,479 valid 050 2.290050e-02 -0.471325
2019-11-05 07:49:11,328 validation loss; R2: 2.299022e-02 -0.391756
2019-11-05 07:49:11,395 epoch 192 lr 5.000000e-04
2019-11-05 07:49:12,105 train 000 2.342534e-02 -0.057142
2019-11-05 07:49:22,124 train 050 2.405337e-02 -0.577662
2019-11-05 07:49:32,105 train 100 2.400093e-02 -0.546849
2019-11-05 07:49:42,418 train 150 2.365352e-02 -0.525064
2019-11-05 07:49:52,639 train 200 2.355314e-02 -0.530730
2019-11-05 07:50:02,893 train 250 2.350237e-02 -0.519042
2019-11-05 07:50:13,196 train 300 2.354902e-02 -0.505491
2019-11-05 07:50:23,493 train 350 2.350986e-02 -0.509863
2019-11-05 07:50:33,740 train 400 2.347910e-02 -0.496352
2019-11-05 07:50:43,964 train 450 2.347516e-02 -0.524692
2019-11-05 07:50:54,203 train 500 2.347005e-02 -0.521662
2019-11-05 07:51:04,500 train 550 2.350476e-02 -0.509498
2019-11-05 07:51:14,789 train 600 2.346686e-02 -0.497566
2019-11-05 07:51:25,049 train 650 2.349967e-02 -0.520893
2019-11-05 07:51:35,313 train 700 2.350218e-02 -0.519418
2019-11-05 07:51:45,619 train 750 2.351213e-02 -0.509446
2019-11-05 07:51:55,947 train 800 2.350548e-02 -0.506779
2019-11-05 07:52:06,276 train 850 2.353196e-02 -0.502890
2019-11-05 07:52:09,317 training loss; R2: 2.351734e-02 -0.501854
2019-11-05 07:52:09,896 valid 000 2.126113e-02 -0.366407
2019-11-05 07:52:20,116 valid 050 1.992216e-02 -0.351879
2019-11-05 07:52:29,043 validation loss; R2: 1.997720e-02 -0.381562
2019-11-05 07:52:29,109 epoch 193 lr 5.000000e-04
2019-11-05 07:52:29,833 train 000 2.523750e-02 -0.179476
2019-11-05 07:52:39,973 train 050 2.379010e-02 -0.554589
2019-11-05 07:52:50,303 train 100 2.377994e-02 -0.478339
2019-11-05 07:53:00,659 train 150 2.378500e-02 -0.477943
2019-11-05 07:53:11,003 train 200 2.371574e-02 -0.530938
2019-11-05 07:53:21,352 train 250 2.367543e-02 -0.494247
2019-11-05 07:53:31,699 train 300 2.366457e-02 -0.497194
2019-11-05 07:53:42,002 train 350 2.364776e-02 -0.510285
2019-11-05 07:53:52,303 train 400 2.362454e-02 -0.509562
2019-11-05 07:54:02,635 train 450 2.358791e-02 -0.504407
2019-11-05 07:54:12,983 train 500 2.355983e-02 -0.517546
2019-11-05 07:54:23,359 train 550 2.357173e-02 -0.505535
2019-11-05 07:54:33,687 train 600 2.358295e-02 -0.505838
2019-11-05 07:54:44,030 train 650 2.354217e-02 -0.519090
2019-11-05 07:54:54,363 train 700 2.356226e-02 -0.505202
2019-11-05 07:55:04,660 train 750 2.357783e-02 -0.515162
2019-11-05 07:55:14,981 train 800 2.360154e-02 -0.513215
2019-11-05 07:55:25,293 train 850 2.359498e-02 -0.515140
2019-11-05 07:55:28,342 training loss; R2: 2.359062e-02 -0.514423
2019-11-05 07:55:28,903 valid 000 1.964836e-02 -1.366915
2019-11-05 07:55:39,123 valid 050 2.024694e-02 -0.679489
2019-11-05 07:55:48,194 validation loss; R2: 2.049737e-02 -0.559003
2019-11-05 07:55:48,267 epoch 194 lr 5.000000e-04
2019-11-05 07:55:49,009 train 000 1.915301e-02 -0.475614
2019-11-05 07:55:59,367 train 050 2.311759e-02 -0.535927
2019-11-05 07:56:09,671 train 100 2.342067e-02 -0.506871
2019-11-05 07:56:19,983 train 150 2.360382e-02 -0.496211
2019-11-05 07:56:30,370 train 200 2.366097e-02 -0.459267
2019-11-05 07:56:40,751 train 250 2.378558e-02 -0.434883
2019-11-05 07:56:50,969 train 300 2.370327e-02 -0.453886
2019-11-05 07:57:01,284 train 350 2.373760e-02 -0.493199
2019-11-05 07:57:11,597 train 400 2.375284e-02 -0.950678
2019-11-05 07:57:21,955 train 450 2.373550e-02 -1.234366
2019-11-05 07:57:32,290 train 500 2.372515e-02 -1.148363
2019-11-05 07:57:42,668 train 550 2.371385e-02 -1.093159
2019-11-05 07:57:53,229 train 600 2.370183e-02 -1.030840
2019-11-05 07:58:03,745 train 650 2.366649e-02 -1.001101
2019-11-05 07:58:14,178 train 700 2.363059e-02 -0.968871
2019-11-05 07:58:24,645 train 750 2.359311e-02 -0.936574
2019-11-05 07:58:34,990 train 800 2.357205e-02 -0.896717
2019-11-05 07:58:45,346 train 850 2.360398e-02 -0.870939
2019-11-05 07:58:48,375 training loss; R2: 2.361451e-02 -0.863988
2019-11-05 07:58:48,971 valid 000 2.067259e-02 -0.109322
2019-11-05 07:58:59,350 valid 050 2.033222e-02 -0.534643
2019-11-05 07:59:08,477 validation loss; R2: 2.044039e-02 -0.505136
2019-11-05 07:59:08,532 epoch 195 lr 5.000000e-04
2019-11-05 07:59:09,269 train 000 2.091777e-02 -0.455869
2019-11-05 07:59:19,465 train 050 2.334183e-02 -0.382411
2019-11-05 07:59:29,813 train 100 2.347668e-02 -0.449743
2019-11-05 07:59:40,039 train 150 2.335956e-02 -0.469324
2019-11-05 07:59:50,394 train 200 2.326676e-02 -0.470003
2019-11-05 08:00:00,633 train 250 2.326090e-02 -0.476470
2019-11-05 08:00:11,056 train 300 2.334928e-02 -0.475230
2019-11-05 08:00:21,241 train 350 2.337956e-02 -0.485752
2019-11-05 08:00:31,595 train 400 2.337885e-02 -0.478878
2019-11-05 08:00:41,858 train 450 2.337971e-02 -0.478782
2019-11-05 08:00:52,236 train 500 2.344339e-02 -0.478215
2019-11-05 08:01:02,524 train 550 2.342123e-02 -0.496084
2019-11-05 08:01:12,877 train 600 2.346222e-02 -0.497931
2019-11-05 08:01:23,107 train 650 2.344972e-02 -0.500974
2019-11-05 08:01:33,430 train 700 2.342934e-02 -0.500070
2019-11-05 08:01:43,680 train 750 2.341597e-02 -0.498003
2019-11-05 08:01:54,039 train 800 2.344218e-02 -0.493025
2019-11-05 08:02:04,274 train 850 2.347524e-02 -0.489040
2019-11-05 08:02:07,422 training loss; R2: 2.346897e-02 -0.489719
2019-11-05 08:02:08,005 valid 000 1.975960e-02 -0.207208
2019-11-05 08:02:18,382 valid 050 2.060685e-02 -0.473810
2019-11-05 08:02:27,247 validation loss; R2: 2.051385e-02 -0.472453
2019-11-05 08:02:27,315 epoch 196 lr 5.000000e-04
2019-11-05 08:02:28,033 train 000 2.426091e-02 -0.164013
2019-11-05 08:02:38,120 train 050 2.335922e-02 -0.399434
2019-11-05 08:02:48,209 train 100 2.345627e-02 -0.473540
2019-11-05 08:02:58,292 train 150 2.338811e-02 -0.513838
2019-11-05 08:03:08,320 train 200 2.360074e-02 -0.492502
2019-11-05 08:03:18,387 train 250 2.362424e-02 -0.477996
2019-11-05 08:03:28,458 train 300 2.367763e-02 -0.475116
2019-11-05 08:03:38,516 train 350 2.365279e-02 -0.470813
2019-11-05 08:03:48,565 train 400 2.362125e-02 -0.467429
2019-11-05 08:03:58,611 train 450 2.358823e-02 -0.475726
2019-11-05 08:04:08,682 train 500 2.358154e-02 -0.486480
2019-11-05 08:04:18,732 train 550 2.358698e-02 -0.494388
2019-11-05 08:04:28,775 train 600 2.358099e-02 -0.485361
2019-11-05 08:04:38,807 train 650 2.363527e-02 -0.477000
2019-11-05 08:04:48,874 train 700 2.360962e-02 -0.484713
2019-11-05 08:04:58,889 train 750 2.359420e-02 -0.543133
2019-11-05 08:05:08,915 train 800 2.360093e-02 -0.534405
2019-11-05 08:05:18,959 train 850 2.356350e-02 -0.522664
2019-11-05 08:05:21,924 training loss; R2: 2.356913e-02 -0.519610
2019-11-05 08:05:22,476 valid 000 2.408518e-02 0.069810
2019-11-05 08:05:32,602 valid 050 2.019702e-02 -0.266056
2019-11-05 08:05:41,574 validation loss; R2: 2.022144e-02 -0.341241
2019-11-05 08:05:41,642 epoch 197 lr 5.000000e-04
2019-11-05 08:05:42,380 train 000 2.747565e-02 0.047637
2019-11-05 08:05:52,577 train 050 2.356457e-02 -0.466464
2019-11-05 08:06:02,665 train 100 2.333833e-02 -0.467555
2019-11-05 08:06:12,714 train 150 2.322056e-02 -0.437592
2019-11-05 08:06:22,785 train 200 2.330441e-02 -0.453068
2019-11-05 08:06:32,871 train 250 2.343101e-02 -0.464923
2019-11-05 08:06:42,948 train 300 2.343194e-02 -0.473217
2019-11-05 08:06:52,998 train 350 2.353257e-02 -0.477481
2019-11-05 08:07:03,077 train 400 2.348853e-02 -0.461737
2019-11-05 08:07:13,116 train 450 2.351636e-02 -0.479961
2019-11-05 08:07:23,206 train 500 2.354252e-02 -0.479488
2019-11-05 08:07:33,283 train 550 2.350634e-02 -0.468721
2019-11-05 08:07:43,424 train 600 2.349359e-02 -0.474047
2019-11-05 08:07:53,479 train 650 2.350740e-02 -0.469558
2019-11-05 08:08:03,665 train 700 2.352589e-02 -0.480589
2019-11-05 08:08:13,889 train 750 2.352210e-02 -0.478527
2019-11-05 08:08:24,131 train 800 2.349734e-02 -0.488576
2019-11-05 08:08:34,385 train 850 2.352716e-02 -0.490254
2019-11-05 08:08:37,418 training loss; R2: 2.352948e-02 -0.488394
2019-11-05 08:08:37,957 valid 000 2.661332e-02 -0.856982
2019-11-05 08:08:48,158 valid 050 2.156283e-02 -0.378367
2019-11-05 08:08:57,122 validation loss; R2: 2.160952e-02 -0.382099
2019-11-05 08:08:57,190 epoch 198 lr 5.000000e-04
2019-11-05 08:08:57,872 train 000 1.988867e-02 -0.114439
2019-11-05 08:09:08,265 train 050 2.321428e-02 -0.568763
2019-11-05 08:09:18,485 train 100 2.338773e-02 -0.522151
2019-11-05 08:09:28,618 train 150 2.347509e-02 -0.512517
2019-11-05 08:09:38,937 train 200 2.343961e-02 -0.519984
2019-11-05 08:09:49,250 train 250 2.347676e-02 -0.504426
2019-11-05 08:09:59,569 train 300 2.342622e-02 -0.490048
2019-11-05 08:10:09,917 train 350 2.352137e-02 -0.472038
2019-11-05 08:10:20,315 train 400 2.351055e-02 -0.471724
2019-11-05 08:10:30,657 train 450 2.352391e-02 -0.468997
2019-11-05 08:10:40,991 train 500 2.352841e-02 -0.481057
2019-11-05 08:10:51,254 train 550 2.358207e-02 -0.486259
2019-11-05 08:11:01,544 train 600 2.355669e-02 -0.498341
2019-11-05 08:11:11,849 train 650 2.353030e-02 -0.501065
2019-11-05 08:11:22,119 train 700 2.352496e-02 -0.497809
2019-11-05 08:11:32,365 train 750 2.355023e-02 -0.499080
2019-11-05 08:11:42,634 train 800 2.355084e-02 -0.495008
2019-11-05 08:11:52,912 train 850 2.351394e-02 -0.497482
2019-11-05 08:11:56,002 training loss; R2: 2.351022e-02 -0.494263
2019-11-05 08:11:56,528 valid 000 2.186675e-02 -0.417881
2019-11-05 08:12:06,696 valid 050 2.020558e-02 -0.237824
2019-11-05 08:12:15,712 validation loss; R2: 2.015707e-02 -0.334397
2019-11-05 08:12:15,774 epoch 199 lr 5.000000e-04
2019-11-05 08:12:16,452 train 000 2.173319e-02 -0.123366
2019-11-05 08:12:26,863 train 050 2.329621e-02 -0.535312
2019-11-05 08:12:37,121 train 100 2.335550e-02 -0.527546
2019-11-05 08:12:47,202 train 150 2.342764e-02 -0.499996
2019-11-05 08:12:57,659 train 200 2.355145e-02 -0.499901
2019-11-05 08:13:08,230 train 250 2.351384e-02 -0.508779
2019-11-05 08:13:18,687 train 300 2.353431e-02 -0.548062
2019-11-05 08:13:29,195 train 350 2.364247e-02 -0.566259
2019-11-05 08:13:39,565 train 400 2.361992e-02 -0.540307
2019-11-05 08:13:49,991 train 450 2.356096e-02 -0.535355
2019-11-05 08:14:00,318 train 500 2.361010e-02 -0.515172
2019-11-05 08:14:10,642 train 550 2.356819e-02 -0.521892
2019-11-05 08:14:20,981 train 600 2.352360e-02 -0.514144
2019-11-05 08:14:31,271 train 650 2.353632e-02 -0.512000
2019-11-05 08:14:41,545 train 700 2.353252e-02 -0.512422
2019-11-05 08:14:51,839 train 750 2.350284e-02 -0.509305
2019-11-05 08:15:02,095 train 800 2.348858e-02 -0.508570
2019-11-05 08:15:12,378 train 850 2.351975e-02 -0.501729
2019-11-05 08:15:15,471 training loss; R2: 2.352000e-02 -0.500152
2019-11-05 08:15:16,012 valid 000 2.079917e-02 -1.781744
2019-11-05 08:15:26,143 valid 050 2.092966e-02 -0.573970
2019-11-05 08:15:35,357 validation loss; R2: 2.095478e-02 -0.659647
2019-11-05 08:15:35,428 epoch 200 lr 5.000000e-04
2019-11-05 08:15:36,167 train 000 2.663808e-02 -0.499417
2019-11-05 08:15:46,446 train 050 2.373671e-02 -3.824618
2019-11-05 08:15:57,038 train 100 2.351501e-02 -2.155235
2019-11-05 08:16:07,152 train 150 2.351569e-02 -1.558497
2019-11-05 08:16:17,713 train 200 2.349999e-02 -1.275993
2019-11-05 08:16:28,261 train 250 2.348117e-02 -1.231293
2019-11-05 08:16:38,792 train 300 2.353871e-02 -1.118066
2019-11-05 08:16:49,285 train 350 2.353066e-02 -1.019674
2019-11-05 08:16:59,771 train 400 2.354329e-02 -0.937258
2019-11-05 08:17:10,238 train 450 2.354701e-02 -0.905019
2019-11-05 08:17:20,716 train 500 2.361812e-02 -0.846206
2019-11-05 08:17:31,183 train 550 2.358503e-02 -0.811534
2019-11-05 08:17:41,643 train 600 2.355740e-02 -0.779683
2019-11-05 08:17:52,119 train 650 2.354763e-02 -0.758990
2019-11-05 08:18:02,600 train 700 2.351173e-02 -0.747465
2019-11-05 08:18:13,091 train 750 2.351965e-02 -0.729526
2019-11-05 08:18:23,566 train 800 2.351009e-02 -0.712704
2019-11-05 08:18:33,837 train 850 2.347957e-02 -0.700459
2019-11-05 08:18:36,847 training loss; R2: 2.348401e-02 -0.694483
2019-11-05 08:18:37,486 valid 000 2.226012e-02 -0.259181
2019-11-05 08:18:47,764 valid 050 2.244249e-02 -0.262438
2019-11-05 08:18:56,833 validation loss; R2: 2.239816e-02 -0.415598
2019-11-05 08:18:56,902 epoch 201 lr 5.000000e-04
2019-11-05 08:18:57,589 train 000 2.300748e-02 -0.518835
2019-11-05 08:19:07,881 train 050 2.287638e-02 -0.449358
2019-11-05 08:19:18,144 train 100 2.324220e-02 -0.438190
2019-11-05 08:19:28,191 train 150 2.310085e-02 -0.469119
2019-11-05 08:19:38,611 train 200 2.321202e-02 -0.491234
2019-11-05 08:19:48,867 train 250 2.328814e-02 -0.456324
2019-11-05 08:19:59,166 train 300 2.337209e-02 -0.479519
2019-11-05 08:20:09,365 train 350 2.332937e-02 -0.477573
2019-11-05 08:20:19,700 train 400 2.334335e-02 -0.468713
2019-11-05 08:20:29,990 train 450 2.337285e-02 -0.463908
2019-11-05 08:20:40,258 train 500 2.337648e-02 -0.462235
2019-11-05 08:20:50,624 train 550 2.343888e-02 -0.463351
2019-11-05 08:21:00,798 train 600 2.344701e-02 -0.461503
2019-11-05 08:21:11,169 train 650 2.348901e-02 -0.457449
2019-11-05 08:21:21,415 train 700 2.350292e-02 -0.464578
2019-11-05 08:21:31,724 train 750 2.349723e-02 -0.475045
2019-11-05 08:21:41,933 train 800 2.346969e-02 -0.467154
2019-11-05 08:21:52,225 train 850 2.345794e-02 -0.467749
2019-11-05 08:21:55,300 training loss; R2: 2.346944e-02 -0.464690
2019-11-05 08:21:55,859 valid 000 1.615797e-02 -0.033402
2019-11-05 08:22:06,133 valid 050 2.045061e-02 -0.266905
2019-11-05 08:22:15,365 validation loss; R2: 2.050628e-02 -0.315711
2019-11-05 08:22:15,432 epoch 202 lr 5.000000e-04
2019-11-05 08:22:16,119 train 000 2.242084e-02 -0.025014
2019-11-05 08:22:26,562 train 050 2.354343e-02 -0.602434
2019-11-05 08:22:36,631 train 100 2.406799e-02 -0.885289
2019-11-05 08:22:46,703 train 150 2.399223e-02 -0.747633
2019-11-05 08:22:56,807 train 200 2.386572e-02 -0.668540
2019-11-05 08:23:06,855 train 250 2.374446e-02 -0.634634
2019-11-05 08:23:16,889 train 300 2.369048e-02 -0.612768
2019-11-05 08:23:26,933 train 350 2.366195e-02 -0.585809
2019-11-05 08:23:36,982 train 400 2.365165e-02 -0.559688
2019-11-05 08:23:47,063 train 450 2.357167e-02 -0.569132
2019-11-05 08:23:57,138 train 500 2.359084e-02 -0.564228
2019-11-05 08:24:07,235 train 550 2.361618e-02 -0.556256
2019-11-05 08:24:17,305 train 600 2.363140e-02 -0.533371
2019-11-05 08:24:27,407 train 650 2.361422e-02 -0.526429
2019-11-05 08:24:37,485 train 700 2.363043e-02 -0.526805
2019-11-05 08:24:47,518 train 750 2.361613e-02 -0.532081
2019-11-05 08:24:57,529 train 800 2.360297e-02 -0.525363
2019-11-05 08:25:07,566 train 850 2.357925e-02 -0.523329
2019-11-05 08:25:10,578 training loss; R2: 2.360316e-02 -0.522082
2019-11-05 08:25:11,129 valid 000 2.498199e-02 -0.068516
2019-11-05 08:25:21,272 valid 050 2.113106e-02 -0.525767
2019-11-05 08:25:30,273 validation loss; R2: 2.128091e-02 -0.539274
2019-11-05 08:25:30,339 epoch 203 lr 5.000000e-04
2019-11-05 08:25:31,022 train 000 2.671343e-02 -0.218377
2019-11-05 08:25:41,375 train 050 2.323315e-02 -0.634868
2019-11-05 08:25:51,755 train 100 2.309399e-02 -0.567054
2019-11-05 08:26:01,995 train 150 2.321723e-02 -0.527317
2019-11-05 08:26:12,207 train 200 2.314803e-02 -0.553724
2019-11-05 08:26:22,612 train 250 2.334847e-02 -0.543245
2019-11-05 08:26:32,905 train 300 2.336965e-02 -0.526143
2019-11-05 08:26:43,142 train 350 2.334081e-02 -0.530241
2019-11-05 08:26:53,461 train 400 2.336681e-02 -0.514647
2019-11-05 08:27:03,746 train 450 2.340704e-02 -0.523391
2019-11-05 08:27:13,994 train 500 2.343888e-02 -1.379937
2019-11-05 08:27:24,261 train 550 2.345610e-02 -1.315309
2019-11-05 08:27:34,532 train 600 2.342825e-02 -1.261336
2019-11-05 08:27:44,783 train 650 2.338193e-02 -1.199048
2019-11-05 08:27:55,098 train 700 2.339087e-02 -1.143306
2019-11-05 08:28:05,435 train 750 2.342383e-02 -1.104249
2019-11-05 08:28:15,749 train 800 2.345990e-02 -1.059664
2019-11-05 08:28:26,087 train 850 2.345971e-02 -1.028869
2019-11-05 08:28:29,130 training loss; R2: 2.346055e-02 -1.021785
2019-11-05 08:28:29,713 valid 000 2.131239e-02 -0.332407
2019-11-05 08:28:39,976 valid 050 2.101155e-02 -0.470248
2019-11-05 08:28:49,016 validation loss; R2: 2.081034e-02 -0.418766
2019-11-05 08:28:49,083 epoch 204 lr 5.000000e-04
2019-11-05 08:28:49,817 train 000 2.013317e-02 -0.186358
2019-11-05 08:29:00,237 train 050 2.324240e-02 -0.438173
2019-11-05 08:29:10,576 train 100 2.348777e-02 -0.452731
2019-11-05 08:29:20,755 train 150 2.345148e-02 -0.709086
2019-11-05 08:29:31,154 train 200 2.346262e-02 -0.640198
2019-11-05 08:29:41,358 train 250 2.341067e-02 -0.615338
2019-11-05 08:29:51,691 train 300 2.348234e-02 -0.577782
2019-11-05 08:30:02,050 train 350 2.350058e-02 -0.577679
2019-11-05 08:30:12,367 train 400 2.348326e-02 -0.580144
2019-11-05 08:30:22,679 train 450 2.348669e-02 -0.563974
2019-11-05 08:30:32,998 train 500 2.348830e-02 -0.555839
2019-11-05 08:30:43,271 train 550 2.350308e-02 -0.606371
2019-11-05 08:30:53,592 train 600 2.354121e-02 -0.600611
2019-11-05 08:31:03,826 train 650 2.359303e-02 -0.595365
2019-11-05 08:31:14,128 train 700 2.357288e-02 -0.590312
2019-11-05 08:31:24,517 train 750 2.356281e-02 -0.578858
2019-11-05 08:31:34,726 train 800 2.357265e-02 -0.567876
2019-11-05 08:31:45,080 train 850 2.356154e-02 -0.560913
2019-11-05 08:31:48,145 training loss; R2: 2.354744e-02 -0.557966
2019-11-05 08:31:48,782 valid 000 2.252832e-02 -0.033218
2019-11-05 08:31:58,905 valid 050 2.071826e-02 -0.249913
2019-11-05 08:32:08,103 validation loss; R2: 2.075515e-02 -0.246760
2019-11-05 08:32:08,163 epoch 205 lr 5.000000e-04
2019-11-05 08:32:08,878 train 000 2.396690e-02 -0.581582
2019-11-05 08:32:19,495 train 050 2.329621e-02 -0.523651
2019-11-05 08:32:30,002 train 100 2.363690e-02 -0.471742
2019-11-05 08:32:40,317 train 150 2.362395e-02 -0.551437
2019-11-05 08:32:50,606 train 200 2.367907e-02 -0.507247
2019-11-05 08:33:00,900 train 250 2.349718e-02 -0.687071
2019-11-05 08:33:11,139 train 300 2.346177e-02 -0.641893
2019-11-05 08:33:21,398 train 350 2.349356e-02 -0.621940
2019-11-05 08:33:31,656 train 400 2.346955e-02 -0.615150
2019-11-05 08:33:41,963 train 450 2.345401e-02 -0.585785
2019-11-05 08:33:52,275 train 500 2.339858e-02 -0.568547
2019-11-05 08:34:02,559 train 550 2.341827e-02 -0.554965
2019-11-05 08:34:12,906 train 600 2.342357e-02 -0.543897
2019-11-05 08:34:23,250 train 650 2.340052e-02 -0.530756
2019-11-05 08:34:33,546 train 700 2.341721e-02 -0.529052
2019-11-05 08:34:43,824 train 750 2.341995e-02 -0.525445
2019-11-05 08:34:54,106 train 800 2.341584e-02 -0.525324
2019-11-05 08:35:04,382 train 850 2.345030e-02 -0.522479
2019-11-05 08:35:07,471 training loss; R2: 2.344518e-02 -0.519870
2019-11-05 08:35:08,053 valid 000 1.903498e-02 -0.050333
2019-11-05 08:35:18,255 valid 050 2.080246e-02 -0.328079
2019-11-05 08:35:27,661 validation loss; R2: 2.103598e-02 -0.316248
2019-11-05 08:35:27,739 epoch 206 lr 5.000000e-04
2019-11-05 08:35:28,467 train 000 2.344996e-02 -2.409353
2019-11-05 08:35:38,810 train 050 2.366940e-02 -0.597523
2019-11-05 08:35:49,223 train 100 2.363157e-02 -1.155074
2019-11-05 08:35:59,597 train 150 2.355140e-02 -1.074244
2019-11-05 08:36:09,905 train 200 2.347716e-02 -0.921720
2019-11-05 08:36:20,218 train 250 2.350179e-02 -0.846377
2019-11-05 08:36:30,545 train 300 2.346980e-02 -0.788266
2019-11-05 08:36:40,856 train 350 2.345668e-02 -0.741639
2019-11-05 08:36:51,167 train 400 2.344997e-02 -0.719805
2019-11-05 08:37:01,479 train 450 2.341446e-02 -0.690137
2019-11-05 08:37:11,791 train 500 2.342072e-02 -0.668102
2019-11-05 08:37:22,087 train 550 2.346843e-02 -0.654210
2019-11-05 08:37:32,406 train 600 2.345653e-02 -0.674058
2019-11-05 08:37:42,747 train 650 2.342517e-02 -0.645193
2019-11-05 08:37:53,076 train 700 2.342694e-02 -0.678673
2019-11-05 08:38:03,406 train 750 2.338629e-02 -0.660928
2019-11-05 08:38:13,721 train 800 2.337159e-02 -0.660560
2019-11-05 08:38:24,040 train 850 2.338150e-02 -0.655007
2019-11-05 08:38:27,046 training loss; R2: 2.338090e-02 -0.655828
2019-11-05 08:38:27,639 valid 000 1.976388e-02 -0.034673
2019-11-05 08:38:37,944 valid 050 2.054409e-02 -0.388162
2019-11-05 08:38:47,272 validation loss; R2: 2.046587e-02 -0.396691
2019-11-05 08:38:47,347 epoch 207 lr 5.000000e-04
2019-11-05 08:38:48,087 train 000 2.699253e-02 -0.382740
2019-11-05 08:38:58,357 train 050 2.329188e-02 -0.351386
2019-11-05 08:39:08,632 train 100 2.355883e-02 -0.396627
2019-11-05 08:39:18,919 train 150 2.351904e-02 -0.614573
2019-11-05 08:39:29,229 train 200 2.350707e-02 -0.568544
2019-11-05 08:39:39,535 train 250 2.341354e-02 -0.518513
2019-11-05 08:39:49,844 train 300 2.342648e-02 -0.551486
2019-11-05 08:40:00,114 train 350 2.339621e-02 -0.532930
2019-11-05 08:40:10,363 train 400 2.334564e-02 -0.505512
2019-11-05 08:40:20,692 train 450 2.336678e-02 -0.514514
2019-11-05 08:40:30,975 train 500 2.338720e-02 -0.516642
2019-11-05 08:40:41,267 train 550 2.340162e-02 -0.511863
2019-11-05 08:40:51,553 train 600 2.339075e-02 -0.513328
2019-11-05 08:41:01,802 train 650 2.336233e-02 -0.522826
2019-11-05 08:41:12,072 train 700 2.335073e-02 -0.523593
2019-11-05 08:41:22,337 train 750 2.339140e-02 -0.525074
2019-11-05 08:41:32,596 train 800 2.338597e-02 -0.513046
2019-11-05 08:41:42,879 train 850 2.339510e-02 -0.505274
2019-11-05 08:41:45,916 training loss; R2: 2.340722e-02 -0.506367
2019-11-05 08:41:46,494 valid 000 2.150914e-02 -0.848949
2019-11-05 08:41:56,672 valid 050 2.080781e-02 -0.344428
2019-11-05 08:42:06,054 validation loss; R2: 2.093593e-02 -0.392306
2019-11-05 08:42:06,122 epoch 208 lr 5.000000e-04
2019-11-05 08:42:06,870 train 000 2.248594e-02 -1.155101
2019-11-05 08:42:17,190 train 050 2.350747e-02 -0.435962
2019-11-05 08:42:27,487 train 100 2.361223e-02 -0.528409
2019-11-05 08:42:37,742 train 150 2.347442e-02 -0.581670
2019-11-05 08:42:47,927 train 200 2.345250e-02 -0.564097
2019-11-05 08:42:58,293 train 250 2.345139e-02 -0.529070
2019-11-05 08:43:08,584 train 300 2.346165e-02 -0.496294
2019-11-05 08:43:18,898 train 350 2.341613e-02 -0.503938
2019-11-05 08:43:29,151 train 400 2.349109e-02 -0.511154
2019-11-05 08:43:39,461 train 450 2.342275e-02 -0.519033
2019-11-05 08:43:49,783 train 500 2.345825e-02 -0.507168
2019-11-05 08:44:00,085 train 550 2.345444e-02 -0.538298
2019-11-05 08:44:10,361 train 600 2.340817e-02 -0.542611
2019-11-05 08:44:20,644 train 650 2.340659e-02 -0.545140
2019-11-05 08:44:30,965 train 700 2.340588e-02 -0.536850
2019-11-05 08:44:41,237 train 750 2.343491e-02 -0.602454
2019-11-05 08:44:51,554 train 800 2.343246e-02 -0.604368
2019-11-05 08:45:01,931 train 850 2.345001e-02 -0.595844
2019-11-05 08:45:04,916 training loss; R2: 2.345510e-02 -0.591160
2019-11-05 08:45:05,491 valid 000 2.045061e-02 -0.190146
2019-11-05 08:45:15,676 valid 050 2.134154e-02 -0.431268
2019-11-05 08:45:24,933 validation loss; R2: 2.121544e-02 -0.498104
2019-11-05 08:45:24,994 epoch 209 lr 5.000000e-04
2019-11-05 08:45:25,725 train 000 2.321080e-02 -0.047913
2019-11-05 08:45:36,332 train 050 2.321307e-02 -0.373726
2019-11-05 08:45:46,904 train 100 2.307953e-02 -0.421063
2019-11-05 08:45:57,161 train 150 2.317319e-02 -0.513491
2019-11-05 08:46:07,370 train 200 2.338402e-02 -0.548232
2019-11-05 08:46:17,677 train 250 2.346852e-02 -0.554609
2019-11-05 08:46:28,047 train 300 2.351050e-02 -0.546419
2019-11-05 08:46:38,291 train 350 2.345999e-02 -0.541606
2019-11-05 08:46:48,551 train 400 2.342777e-02 -0.545614
2019-11-05 08:46:58,658 train 450 2.346295e-02 -0.550394
2019-11-05 08:47:08,926 train 500 2.339799e-02 -0.554050
2019-11-05 08:47:19,287 train 550 2.343321e-02 -0.547537
2019-11-05 08:47:29,703 train 600 2.344820e-02 -0.532815
2019-11-05 08:47:40,222 train 650 2.342161e-02 -0.540972
2019-11-05 08:47:50,741 train 700 2.342733e-02 -0.534253
2019-11-05 08:48:01,236 train 750 2.340809e-02 -0.531353
2019-11-05 08:48:11,712 train 800 2.344673e-02 -0.535224
2019-11-05 08:48:22,220 train 850 2.344330e-02 -0.526918
2019-11-05 08:48:25,385 training loss; R2: 2.343829e-02 -0.523968
2019-11-05 08:48:25,973 valid 000 1.760452e-02 -0.051326
2019-11-05 08:48:36,343 valid 050 2.041003e-02 -0.723198
2019-11-05 08:48:45,550 validation loss; R2: 2.047183e-02 -0.580640
2019-11-05 08:48:45,615 epoch 210 lr 5.000000e-04
2019-11-05 08:48:46,286 train 000 2.262898e-02 -0.073374
2019-11-05 08:48:56,791 train 050 2.312539e-02 -0.658670
2019-11-05 08:49:07,269 train 100 2.347544e-02 -0.563911
2019-11-05 08:49:17,511 train 150 2.337814e-02 -0.641040
2019-11-05 08:49:27,771 train 200 2.330125e-02 -0.597943
2019-11-05 08:49:37,998 train 250 2.327925e-02 -0.573179
2019-11-05 08:49:48,248 train 300 2.329104e-02 -0.564554
2019-11-05 08:49:58,492 train 350 2.333621e-02 -0.570951
2019-11-05 08:50:08,689 train 400 2.328851e-02 -0.577615
2019-11-05 08:50:18,933 train 450 2.333100e-02 -0.571393
2019-11-05 08:50:29,178 train 500 2.332856e-02 -0.549778
2019-11-05 08:50:39,457 train 550 2.335270e-02 -0.532874
2019-11-05 08:50:49,744 train 600 2.337461e-02 -0.540594
2019-11-05 08:50:59,933 train 650 2.334812e-02 -2.208386
2019-11-05 08:51:10,178 train 700 2.337204e-02 -2.082010
2019-11-05 08:51:20,414 train 750 2.337959e-02 -1.987334
2019-11-05 08:51:30,656 train 800 2.339482e-02 -1.900358
2019-11-05 08:51:40,932 train 850 2.337394e-02 -1.809839
2019-11-05 08:51:43,915 training loss; R2: 2.335937e-02 -1.787569
2019-11-05 08:51:44,524 valid 000 2.057951e-02 -0.363097
2019-11-05 08:51:54,784 valid 050 2.176107e-02 -0.351685
2019-11-05 08:52:04,044 validation loss; R2: 2.175468e-02 -0.352683
2019-11-05 08:52:04,113 epoch 211 lr 5.000000e-04
2019-11-05 08:52:04,852 train 000 2.192479e-02 -0.639180
2019-11-05 08:52:15,122 train 050 2.322262e-02 -0.642498
2019-11-05 08:52:25,432 train 100 2.352126e-02 -0.499277
2019-11-05 08:52:35,751 train 150 2.347222e-02 -0.513895
2019-11-05 08:52:46,050 train 200 2.336985e-02 -0.544121
2019-11-05 08:52:56,351 train 250 2.333989e-02 -0.519181
2019-11-05 08:53:06,677 train 300 2.340518e-02 -0.492009
2019-11-05 08:53:17,026 train 350 2.341270e-02 -0.984434
2019-11-05 08:53:27,402 train 400 2.339053e-02 -0.929020
2019-11-05 08:53:37,731 train 450 2.338705e-02 -0.865204
2019-11-05 08:53:48,079 train 500 2.336753e-02 -0.817459
2019-11-05 08:53:58,430 train 550 2.341693e-02 -0.784810
2019-11-05 08:54:08,745 train 600 2.337650e-02 -0.757452
2019-11-05 08:54:19,064 train 650 2.336088e-02 -0.778730
2019-11-05 08:54:29,399 train 700 2.335535e-02 -0.782771
2019-11-05 08:54:39,725 train 750 2.337060e-02 -0.766286
2019-11-05 08:54:50,079 train 800 2.337027e-02 -0.737327
2019-11-05 08:55:00,331 train 850 2.333342e-02 -0.720348
2019-11-05 08:55:03,414 training loss; R2: 2.335071e-02 -0.711675
2019-11-05 08:55:03,990 valid 000 1.894549e-02 -0.167880
2019-11-05 08:55:14,163 valid 050 2.064573e-02 -9.733228
2019-11-05 08:55:23,508 validation loss; R2: 2.071287e-02 -5.447067
2019-11-05 08:55:23,570 epoch 212 lr 5.000000e-04
2019-11-05 08:55:24,275 train 000 2.580791e-02 -0.226100
2019-11-05 08:55:34,788 train 050 2.301626e-02 -0.323253
2019-11-05 08:55:45,314 train 100 2.287775e-02 -0.544015
2019-11-05 08:55:55,392 train 150 2.307770e-02 -0.582302
2019-11-05 08:56:05,442 train 200 2.303801e-02 -0.582204
2019-11-05 08:56:15,510 train 250 2.303777e-02 -0.571453
2019-11-05 08:56:25,586 train 300 2.307040e-02 -0.568061
2019-11-05 08:56:35,745 train 350 2.319099e-02 -0.630774
2019-11-05 08:56:45,782 train 400 2.320702e-02 -0.622687
2019-11-05 08:56:55,862 train 450 2.320474e-02 -0.605025
2019-11-05 08:57:05,942 train 500 2.323067e-02 -0.594875
2019-11-05 08:57:15,998 train 550 2.328353e-02 -0.574615
2019-11-05 08:57:26,090 train 600 2.328586e-02 -0.561774
2019-11-05 08:57:36,168 train 650 2.327890e-02 -0.559686
2019-11-05 08:57:46,257 train 700 2.329638e-02 -0.572781
2019-11-05 08:57:56,321 train 750 2.330512e-02 -0.569265
2019-11-05 08:58:06,469 train 800 2.334820e-02 -0.560709
2019-11-05 08:58:16,544 train 850 2.337549e-02 -0.552088
2019-11-05 08:58:19,575 training loss; R2: 2.337308e-02 -0.551229
2019-11-05 08:58:20,169 valid 000 1.770101e-02 -0.127644
2019-11-05 08:58:30,501 valid 050 2.065053e-02 -0.751052
2019-11-05 08:58:39,622 validation loss; R2: 2.078991e-02 -0.690716
2019-11-05 08:58:39,689 epoch 213 lr 5.000000e-04
2019-11-05 08:58:40,446 train 000 2.172684e-02 -0.168699
2019-11-05 08:58:50,942 train 050 2.341365e-02 -0.453707
2019-11-05 08:59:01,415 train 100 2.333285e-02 -0.495132
2019-11-05 08:59:11,676 train 150 2.334485e-02 -0.499572
2019-11-05 08:59:21,747 train 200 2.338627e-02 -0.536498
2019-11-05 08:59:31,850 train 250 2.338584e-02 -0.503279
2019-11-05 08:59:41,961 train 300 2.341644e-02 -0.504941
2019-11-05 08:59:52,055 train 350 2.334903e-02 -8.572900
2019-11-05 09:00:02,157 train 400 2.338207e-02 -7.565072
2019-11-05 09:00:12,291 train 450 2.343467e-02 -6.785279
2019-11-05 09:00:22,424 train 500 2.344627e-02 -6.150987
2019-11-05 09:00:32,509 train 550 2.347098e-02 -5.634678
2019-11-05 09:00:42,601 train 600 2.347393e-02 -5.223366
2019-11-05 09:00:52,705 train 650 2.344539e-02 -4.856004
2019-11-05 09:01:02,772 train 700 2.341895e-02 -4.547037
2019-11-05 09:01:12,851 train 750 2.341502e-02 -4.277824
2019-11-05 09:01:22,933 train 800 2.340859e-02 -4.037282
2019-11-05 09:01:33,031 train 850 2.338799e-02 -3.837938
2019-11-05 09:01:36,065 training loss; R2: 2.338168e-02 -3.779800
2019-11-05 09:01:36,603 valid 000 2.368340e-02 -0.210492
2019-11-05 09:01:46,784 valid 050 1.968609e-02 -0.373760
2019-11-05 09:01:55,746 validation loss; R2: 1.990467e-02 -0.412038
2019-11-05 09:01:55,825 epoch 214 lr 5.000000e-04
2019-11-05 09:01:56,489 train 000 2.012633e-02 -1.294829
2019-11-05 09:02:06,870 train 050 2.339954e-02 -0.457634
2019-11-05 09:02:17,215 train 100 2.314548e-02 -0.423644
2019-11-05 09:02:27,550 train 150 2.311377e-02 -0.436025
2019-11-05 09:02:37,858 train 200 2.322507e-02 -0.405959
2019-11-05 09:02:47,930 train 250 2.324106e-02 -0.413661
2019-11-05 09:02:58,287 train 300 2.318199e-02 -0.438878
2019-11-05 09:03:08,609 train 350 2.321585e-02 -0.443928
2019-11-05 09:03:18,943 train 400 2.322522e-02 -0.450023
2019-11-05 09:03:29,247 train 450 2.333775e-02 -0.470570
2019-11-05 09:03:39,547 train 500 2.333472e-02 -0.480001
2019-11-05 09:03:49,780 train 550 2.336376e-02 -0.471425
2019-11-05 09:04:00,018 train 600 2.337853e-02 -0.464254
2019-11-05 09:04:10,240 train 650 2.335535e-02 -0.469442
2019-11-05 09:04:20,442 train 700 2.335973e-02 -0.465713
2019-11-05 09:04:30,687 train 750 2.338006e-02 -0.473187
2019-11-05 09:04:40,937 train 800 2.337860e-02 -0.469792
2019-11-05 09:04:51,168 train 850 2.339734e-02 -0.473694
2019-11-05 09:04:54,173 training loss; R2: 2.342044e-02 -0.472783
2019-11-05 09:04:54,709 valid 000 2.345620e-02 -0.665092
2019-11-05 09:05:04,867 valid 050 2.109189e-02 -0.476806
2019-11-05 09:05:13,815 validation loss; R2: 2.117140e-02 -0.534716
2019-11-05 09:05:13,880 epoch 215 lr 5.000000e-04
2019-11-05 09:05:14,608 train 000 2.665418e-02 -0.581498
2019-11-05 09:05:24,896 train 050 2.347392e-02 -0.402720
2019-11-05 09:05:35,119 train 100 2.334468e-02 -0.532059
2019-11-05 09:05:45,453 train 150 2.321195e-02 -0.510375
2019-11-05 09:05:55,678 train 200 2.309769e-02 -0.495906
2019-11-05 09:06:05,707 train 250 2.312535e-02 -0.497471
2019-11-05 09:06:16,010 train 300 2.313473e-02 -0.477487
2019-11-05 09:06:26,290 train 350 2.317010e-02 -0.459412
2019-11-05 09:06:36,622 train 400 2.315656e-02 -0.460577
2019-11-05 09:06:46,874 train 450 2.317155e-02 -0.467769
2019-11-05 09:06:57,037 train 500 2.323117e-02 -0.463570
2019-11-05 09:07:07,241 train 550 2.331131e-02 -0.455700
2019-11-05 09:07:17,557 train 600 2.334409e-02 -0.453712
2019-11-05 09:07:27,736 train 650 2.336621e-02 -0.452950
2019-11-05 09:07:38,035 train 700 2.332684e-02 -0.449855
2019-11-05 09:07:48,318 train 750 2.333851e-02 -0.458713
2019-11-05 09:07:58,490 train 800 2.335337e-02 -0.460668
2019-11-05 09:08:08,754 train 850 2.336577e-02 -0.457205
2019-11-05 09:08:11,853 training loss; R2: 2.336517e-02 -0.459496
2019-11-05 09:08:12,434 valid 000 1.840229e-02 -0.279752
2019-11-05 09:08:22,608 valid 050 2.110424e-02 -0.436942
2019-11-05 09:08:31,570 validation loss; R2: 2.119791e-02 -0.383410
2019-11-05 09:08:31,638 epoch 216 lr 5.000000e-04
2019-11-05 09:08:32,366 train 000 2.006504e-02 -0.380417
2019-11-05 09:08:42,655 train 050 2.331227e-02 -0.471865
2019-11-05 09:08:52,917 train 100 2.344895e-02 -0.608250
2019-11-05 09:09:03,153 train 150 2.371222e-02 -0.643192
2019-11-05 09:09:13,497 train 200 2.363953e-02 -0.588096
2019-11-05 09:09:23,724 train 250 2.356555e-02 -0.591421
2019-11-05 09:09:33,976 train 300 2.353328e-02 -0.573844
2019-11-05 09:09:44,204 train 350 2.356018e-02 -0.562751
2019-11-05 09:09:54,558 train 400 2.366374e-02 -0.543797
2019-11-05 09:10:04,742 train 450 2.364250e-02 -0.543101
2019-11-05 09:10:14,969 train 500 2.361854e-02 -0.540272
2019-11-05 09:10:25,336 train 550 2.354785e-02 -0.535249
2019-11-05 09:10:35,585 train 600 2.351834e-02 -0.520800
2019-11-05 09:10:45,905 train 650 2.346948e-02 -0.513028
2019-11-05 09:10:56,171 train 700 2.346537e-02 -0.515738
2019-11-05 09:11:06,487 train 750 2.343719e-02 -0.516035
2019-11-05 09:11:16,718 train 800 2.341804e-02 -0.516666
2019-11-05 09:11:26,975 train 850 2.341662e-02 -0.519388
2019-11-05 09:11:30,043 training loss; R2: 2.340671e-02 -0.514509
2019-11-05 09:11:30,674 valid 000 1.933591e-02 -0.385300
2019-11-05 09:11:40,846 valid 050 1.984581e-02 -0.670703
2019-11-05 09:11:50,096 validation loss; R2: 1.996374e-02 -0.744069
2019-11-05 09:11:50,153 epoch 217 lr 5.000000e-04
2019-11-05 09:11:50,846 train 000 2.218913e-02 -0.132676
2019-11-05 09:12:01,199 train 050 2.295187e-02 -0.388922
2019-11-05 09:12:11,543 train 100 2.301333e-02 -0.432506
2019-11-05 09:12:21,854 train 150 2.318121e-02 -0.402468
2019-11-05 09:12:32,191 train 200 2.343594e-02 -0.410524
2019-11-05 09:12:42,361 train 250 2.340860e-02 -0.430547
2019-11-05 09:12:52,697 train 300 2.333998e-02 -0.452163
2019-11-05 09:13:02,964 train 350 2.333846e-02 -0.463043
2019-11-05 09:13:13,207 train 400 2.335660e-02 -0.495074
2019-11-05 09:13:23,766 train 450 2.338151e-02 -0.498673
2019-11-05 09:13:34,217 train 500 2.334935e-02 -0.495247
2019-11-05 09:13:44,534 train 550 2.336424e-02 -0.492472
2019-11-05 09:13:54,969 train 600 2.339744e-02 -0.489667
2019-11-05 09:14:05,354 train 650 2.337752e-02 -0.487745
2019-11-05 09:14:15,710 train 700 2.337690e-02 -0.493815
2019-11-05 09:14:26,116 train 750 2.334357e-02 -0.535194
2019-11-05 09:14:36,556 train 800 2.333629e-02 -0.538329
2019-11-05 09:14:46,989 train 850 2.333845e-02 -0.530071
2019-11-05 09:14:50,040 training loss; R2: 2.333759e-02 -0.529644
2019-11-05 09:14:50,610 valid 000 2.141509e-02 -0.115152
2019-11-05 09:15:00,947 valid 050 1.986936e-02 -0.618573
2019-11-05 09:15:10,371 validation loss; R2: 1.993415e-02 -0.509917
2019-11-05 09:15:10,444 epoch 218 lr 5.000000e-04
2019-11-05 09:15:11,156 train 000 2.454192e-02 -0.288897
2019-11-05 09:15:21,768 train 050 2.326069e-02 -25.768009
2019-11-05 09:15:32,369 train 100 2.343153e-02 -13.258483
2019-11-05 09:15:43,053 train 150 2.334962e-02 -9.029356
2019-11-05 09:15:53,581 train 200 2.322300e-02 -6.879053
2019-11-05 09:16:04,011 train 250 2.325274e-02 -5.594413
2019-11-05 09:16:14,419 train 300 2.327974e-02 -4.736486
2019-11-05 09:16:24,889 train 350 2.332522e-02 -4.147884
2019-11-05 09:16:35,329 train 400 2.326502e-02 -3.724768
2019-11-05 09:16:45,795 train 450 2.326679e-02 -3.373243
2019-11-05 09:16:56,344 train 500 2.327932e-02 -3.072539
2019-11-05 09:17:06,896 train 550 2.329204e-02 -2.828455
2019-11-05 09:17:17,680 train 600 2.330727e-02 -2.634967
