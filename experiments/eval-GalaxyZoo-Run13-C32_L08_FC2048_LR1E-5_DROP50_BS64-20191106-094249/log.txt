2019-11-06 09:42:49,573 gpu device = 1
2019-11-06 09:42:49,573 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=64, cutout=False, cutout_length=16, data='../data', dataset='GalaxyZoo', drop_path_prob=0.5, epochs=1000, fc1_size=2048, fc2_size=2048, gpu=1, grad_clip=5, init_channels=32, layers=8, learning_rate=1e-05, model_path='saved_models', momentum=0.9, optimizer='Adam', random=False, report_freq=50, save='eval-GalaxyZoo-Run13-C32_L08_FC2048_LR1E-5_DROP50_BS64-20191106-094249', seed=0, val_portion=0.1, weight_decay=0.0001)
2019-11-06 09:42:52,865 param size = 6.305669MB
2019-11-06 09:42:52,869 epoch 0 lr 1.000000e-05
2019-11-06 09:42:55,610 train 000 4.947456e-02 -5.226021
2019-11-06 09:43:05,411 train 050 3.765613e-02 -2.902855
2019-11-06 09:43:15,050 train 100 3.518849e-02 -2.613588
2019-11-06 09:43:24,703 train 150 3.390312e-02 -2.376584
2019-11-06 09:43:34,347 train 200 3.315145e-02 -2.186281
2019-11-06 09:43:43,999 train 250 3.252992e-02 -2.054841
2019-11-06 09:43:53,673 train 300 3.199694e-02 -1.913687
2019-11-06 09:44:03,345 train 350 3.152992e-02 -1.813113
2019-11-06 09:44:13,033 train 400 3.121759e-02 -1.728513
2019-11-06 09:44:22,737 train 450 3.092877e-02 -1.640686
2019-11-06 09:44:32,447 train 500 3.066953e-02 -1.568600
2019-11-06 09:44:42,203 train 550 3.050294e-02 -1.496849
2019-11-06 09:44:52,012 train 600 3.031387e-02 -1.438969
2019-11-06 09:45:01,824 train 650 3.010837e-02 -1.500219
2019-11-06 09:45:11,632 train 700 2.998759e-02 -1.449965
2019-11-06 09:45:21,444 train 750 2.986295e-02 -1.407893
2019-11-06 09:45:31,260 train 800 2.971049e-02 -1.363355
2019-11-06 09:45:41,090 train 850 2.960027e-02 -1.324969
2019-11-06 09:45:44,969 training loss; R2: 2.956260e-02 -1.315012
2019-11-06 09:45:45,630 valid 000 2.581023e-02 -1.329015
2019-11-06 09:45:54,970 valid 050 2.682470e-02 -0.846757
2019-11-06 09:46:03,390 validation loss; R2: 2.701296e-02 -0.851060
2019-11-06 09:46:03,440 epoch 1 lr 1.000000e-05
2019-11-06 09:46:04,314 train 000 2.844123e-02 -0.268392
2019-11-06 09:46:14,088 train 050 2.765128e-02 -0.794955
2019-11-06 09:46:23,900 train 100 2.752653e-02 -0.627246
2019-11-06 09:46:33,728 train 150 2.766119e-02 -0.612631
2019-11-06 09:46:43,585 train 200 2.757889e-02 -0.645105
2019-11-06 09:46:53,413 train 250 2.746728e-02 -0.629988
2019-11-06 09:47:03,251 train 300 2.752868e-02 -0.602064
2019-11-06 09:47:13,098 train 350 2.743901e-02 -0.608330
2019-11-06 09:47:22,963 train 400 2.741976e-02 -0.592512
2019-11-06 09:47:32,832 train 450 2.732891e-02 -0.609901
2019-11-06 09:47:42,711 train 500 2.736776e-02 -0.597199
2019-11-06 09:47:52,595 train 550 2.738647e-02 -0.584671
2019-11-06 09:48:02,474 train 600 2.734248e-02 -0.576980
2019-11-06 09:48:12,342 train 650 2.732277e-02 -0.578972
2019-11-06 09:48:22,214 train 700 2.732937e-02 -0.567884
2019-11-06 09:48:32,076 train 750 2.732607e-02 -0.559755
2019-11-06 09:48:41,946 train 800 2.733304e-02 -0.562582
2019-11-06 09:48:51,831 train 850 2.733115e-02 -0.559391
2019-11-06 09:48:54,785 training loss; R2: 2.731488e-02 -0.561879
2019-11-06 09:48:55,478 valid 000 2.509836e-02 -0.260786
2019-11-06 09:49:04,826 valid 050 2.695747e-02 -0.423095
2019-11-06 09:49:13,339 validation loss; R2: 2.690851e-02 -0.494334
2019-11-06 09:49:13,407 epoch 2 lr 1.000000e-05
2019-11-06 09:49:14,190 train 000 2.542347e-02 -0.117572
2019-11-06 09:49:24,016 train 050 2.668407e-02 -0.405470
2019-11-06 09:49:33,996 train 100 2.710323e-02 -0.450309
2019-11-06 09:49:44,211 train 150 2.704649e-02 -0.434025
2019-11-06 09:49:54,437 train 200 2.701792e-02 -0.494876
2019-11-06 09:50:04,665 train 250 2.700834e-02 -0.560812
2019-11-06 09:50:14,896 train 300 2.697471e-02 -0.558823
2019-11-06 09:50:25,107 train 350 2.701949e-02 -0.552825
2019-11-06 09:50:35,336 train 400 2.705196e-02 -0.533533
2019-11-06 09:50:45,590 train 450 2.704562e-02 -0.536284
2019-11-06 09:50:55,855 train 500 2.701313e-02 -0.548761
2019-11-06 09:51:06,098 train 550 2.701190e-02 -0.534062
2019-11-06 09:51:16,077 train 600 2.695215e-02 -0.552620
2019-11-06 09:51:26,016 train 650 2.696189e-02 -0.542068
2019-11-06 09:51:35,920 train 700 2.698545e-02 -0.543663
2019-11-06 09:51:45,821 train 750 2.698887e-02 -0.538284
2019-11-06 09:51:55,710 train 800 2.698620e-02 -0.528748
2019-11-06 09:52:05,615 train 850 2.698261e-02 -0.538644
2019-11-06 09:52:08,581 training loss; R2: 2.698362e-02 -0.542344
2019-11-06 09:52:09,233 valid 000 2.724037e-02 -0.999908
2019-11-06 09:52:18,669 valid 050 2.686659e-02 -0.470931
2019-11-06 09:52:27,016 validation loss; R2: 2.661136e-02 -0.455112
2019-11-06 09:52:27,084 epoch 3 lr 1.000000e-05
2019-11-06 09:52:27,868 train 000 2.862217e-02 -0.620787
2019-11-06 09:52:37,715 train 050 2.667208e-02 -0.407990
2019-11-06 09:52:47,573 train 100 2.692549e-02 -0.464702
2019-11-06 09:52:57,450 train 150 2.686625e-02 -0.514530
2019-11-06 09:53:07,335 train 200 2.695559e-02 -0.478082
2019-11-06 09:53:17,235 train 250 2.696347e-02 -0.491440
2019-11-06 09:53:27,100 train 300 2.692865e-02 -0.473727
2019-11-06 09:53:36,974 train 350 2.692359e-02 -0.501337
2019-11-06 09:53:46,833 train 400 2.693353e-02 -0.528770
2019-11-06 09:53:56,697 train 450 2.692313e-02 -0.516641
2019-11-06 09:54:06,583 train 500 2.692071e-02 -0.509366
2019-11-06 09:54:16,440 train 550 2.687280e-02 -0.539800
2019-11-06 09:54:26,335 train 600 2.684342e-02 -0.528398
2019-11-06 09:54:36,247 train 650 2.678150e-02 -0.524464
2019-11-06 09:54:46,150 train 700 2.676632e-02 -0.518056
2019-11-06 09:54:56,035 train 750 2.674731e-02 -0.518298
2019-11-06 09:55:05,919 train 800 2.675139e-02 -0.512434
2019-11-06 09:55:15,796 train 850 2.673853e-02 -0.507425
2019-11-06 09:55:18,751 training loss; R2: 2.672041e-02 -0.505022
2019-11-06 09:55:19,404 valid 000 2.647477e-02 -0.236516
2019-11-06 09:55:28,889 valid 050 2.607524e-02 -1.567390
2019-11-06 09:55:37,279 validation loss; R2: 2.624306e-02 -1.218757
2019-11-06 09:55:37,348 epoch 4 lr 1.000000e-05
2019-11-06 09:55:38,133 train 000 2.369930e-02 -0.283161
2019-11-06 09:55:47,963 train 050 2.655594e-02 -0.461816
2019-11-06 09:55:57,845 train 100 2.632911e-02 -0.489146
2019-11-06 09:56:07,724 train 150 2.651121e-02 -0.486701
2019-11-06 09:56:17,622 train 200 2.655006e-02 -0.512222
2019-11-06 09:56:27,513 train 250 2.655393e-02 -0.506253
2019-11-06 09:56:37,418 train 300 2.652339e-02 -0.522942
2019-11-06 09:56:47,334 train 350 2.651440e-02 -0.519587
2019-11-06 09:56:57,236 train 400 2.653626e-02 -0.502624
2019-11-06 09:57:07,153 train 450 2.649532e-02 -0.502340
2019-11-06 09:57:17,064 train 500 2.650741e-02 -0.489062
2019-11-06 09:57:26,993 train 550 2.656420e-02 -0.484407
2019-11-06 09:57:36,911 train 600 2.654977e-02 -0.501079
2019-11-06 09:57:46,828 train 650 2.653511e-02 -0.495249
2019-11-06 09:57:56,760 train 700 2.651568e-02 -0.491559
2019-11-06 09:58:06,678 train 750 2.652786e-02 -0.503764
2019-11-06 09:58:16,609 train 800 2.651396e-02 -0.509215
2019-11-06 09:58:26,509 train 850 2.650273e-02 -0.508254
2019-11-06 09:58:29,465 training loss; R2: 2.649981e-02 -0.505963
2019-11-06 09:58:30,080 valid 000 2.640582e-02 -0.123851
2019-11-06 09:58:39,511 valid 050 2.578427e-02 -0.384069
2019-11-06 09:58:47,991 validation loss; R2: 2.565569e-02 -0.501016
2019-11-06 09:58:48,055 epoch 5 lr 1.000000e-05
2019-11-06 09:58:48,810 train 000 2.418806e-02 -1.151032
2019-11-06 09:58:58,631 train 050 2.627875e-02 -0.530100
2019-11-06 09:59:08,448 train 100 2.645674e-02 -0.565888
2019-11-06 09:59:18,282 train 150 2.652382e-02 -0.557367
2019-11-06 09:59:28,125 train 200 2.655606e-02 -0.519831
2019-11-06 09:59:37,971 train 250 2.652935e-02 -0.532893
2019-11-06 09:59:47,824 train 300 2.647426e-02 -0.545650
2019-11-06 09:59:57,687 train 350 2.651148e-02 -0.554673
2019-11-06 10:00:07,552 train 400 2.649294e-02 -0.567596
2019-11-06 10:00:17,416 train 450 2.652405e-02 -0.561256
2019-11-06 10:00:27,288 train 500 2.651714e-02 -0.543208
2019-11-06 10:00:37,160 train 550 2.642867e-02 -0.590188
2019-11-06 10:00:47,033 train 600 2.640190e-02 -0.586295
2019-11-06 10:00:56,917 train 650 2.641687e-02 -0.582714
2019-11-06 10:01:06,799 train 700 2.640098e-02 -0.569549
2019-11-06 10:01:16,679 train 750 2.638460e-02 -0.567646
2019-11-06 10:01:26,576 train 800 2.635406e-02 -0.574486
2019-11-06 10:01:36,500 train 850 2.634193e-02 -0.565356
2019-11-06 10:01:39,454 training loss; R2: 2.635071e-02 -0.564593
2019-11-06 10:01:40,101 valid 000 2.494510e-02 -0.121508
2019-11-06 10:01:49,565 valid 050 2.539697e-02 -0.552915
2019-11-06 10:01:57,918 validation loss; R2: 2.556529e-02 -0.464398
2019-11-06 10:01:57,986 epoch 6 lr 1.000000e-05
2019-11-06 10:01:58,760 train 000 2.852923e-02 -0.954759
2019-11-06 10:02:08,571 train 050 2.611530e-02 -0.752648
2019-11-06 10:02:18,403 train 100 2.639359e-02 -0.580972
2019-11-06 10:02:28,243 train 150 2.625678e-02 -0.600964
2019-11-06 10:02:38,082 train 200 2.614240e-02 -0.575670
2019-11-06 10:02:47,922 train 250 2.606088e-02 -0.620479
2019-11-06 10:02:57,778 train 300 2.614142e-02 -0.588534
2019-11-06 10:03:07,630 train 350 2.621482e-02 -0.571958
2019-11-06 10:03:17,489 train 400 2.621933e-02 -0.550770
2019-11-06 10:03:27,348 train 450 2.622802e-02 -0.540860
2019-11-06 10:03:37,215 train 500 2.619862e-02 -0.530927
2019-11-06 10:03:47,069 train 550 2.621991e-02 -0.528725
2019-11-06 10:03:56,935 train 600 2.619831e-02 -0.529477
2019-11-06 10:04:06,806 train 650 2.621984e-02 -0.521859
2019-11-06 10:04:16,679 train 700 2.619637e-02 -0.520936
2019-11-06 10:04:26,557 train 750 2.618824e-02 -0.544946
2019-11-06 10:04:36,428 train 800 2.622421e-02 -0.550285
2019-11-06 10:04:46,310 train 850 2.622456e-02 -0.557099
2019-11-06 10:04:49,300 training loss; R2: 2.622081e-02 -0.552674
2019-11-06 10:04:49,909 valid 000 2.556497e-02 -2.700897
2019-11-06 10:04:59,405 valid 050 2.512453e-02 -0.509287
2019-11-06 10:05:07,872 validation loss; R2: 2.497024e-02 -0.602561
2019-11-06 10:05:07,955 epoch 7 lr 1.000000e-05
2019-11-06 10:05:08,756 train 000 2.764366e-02 -0.178917
2019-11-06 10:05:18,932 train 050 2.662980e-02 -0.454540
2019-11-06 10:05:29,117 train 100 2.648137e-02 -0.497074
2019-11-06 10:05:39,304 train 150 2.630964e-02 -0.540183
2019-11-06 10:05:49,484 train 200 2.624121e-02 -0.533248
2019-11-06 10:05:59,678 train 250 2.626078e-02 -0.536553
2019-11-06 10:06:09,889 train 300 2.631349e-02 -1.009930
2019-11-06 10:06:20,077 train 350 2.626368e-02 -1.004898
2019-11-06 10:06:30,285 train 400 2.622842e-02 -0.951512
2019-11-06 10:06:40,491 train 450 2.616399e-02 -0.965714
2019-11-06 10:06:50,693 train 500 2.613860e-02 -0.937308
2019-11-06 10:07:00,908 train 550 2.615136e-02 -0.910839
2019-11-06 10:07:11,127 train 600 2.613680e-02 -0.886105
2019-11-06 10:07:21,358 train 650 2.610741e-02 -0.847984
2019-11-06 10:07:31,589 train 700 2.610923e-02 -0.848034
2019-11-06 10:07:41,814 train 750 2.608045e-02 -0.823587
2019-11-06 10:07:52,035 train 800 2.608917e-02 -0.809220
2019-11-06 10:08:02,257 train 850 2.607392e-02 -0.793282
2019-11-06 10:08:05,315 training loss; R2: 2.606914e-02 -0.790938
2019-11-06 10:08:05,935 valid 000 2.481324e-02 -3.321408
2019-11-06 10:08:15,395 valid 050 2.516328e-02 -0.455966
2019-11-06 10:08:23,738 validation loss; R2: 2.491842e-02 -0.468869
2019-11-06 10:08:23,826 epoch 8 lr 1.000000e-05
2019-11-06 10:08:24,595 train 000 2.608167e-02 -0.174595
2019-11-06 10:08:34,425 train 050 2.598872e-02 -0.316735
2019-11-06 10:08:44,274 train 100 2.579604e-02 -0.367667
2019-11-06 10:08:54,155 train 150 2.587698e-02 -0.435636
2019-11-06 10:09:04,036 train 200 2.584739e-02 -0.459262
2019-11-06 10:09:13,924 train 250 2.587630e-02 -0.468149
2019-11-06 10:09:23,823 train 300 2.591789e-02 -0.509660
2019-11-06 10:09:33,740 train 350 2.593649e-02 -0.498991
2019-11-06 10:09:43,678 train 400 2.592036e-02 -0.532876
2019-11-06 10:09:53,600 train 450 2.593228e-02 -0.529847
2019-11-06 10:10:03,507 train 500 2.597567e-02 -0.519676
2019-11-06 10:10:13,416 train 550 2.600121e-02 -0.531853
2019-11-06 10:10:23,314 train 600 2.601149e-02 -0.539071
2019-11-06 10:10:33,225 train 650 2.601836e-02 -0.539594
2019-11-06 10:10:43,146 train 700 2.599220e-02 -0.536425
2019-11-06 10:10:53,061 train 750 2.599380e-02 -0.532883
2019-11-06 10:11:03,008 train 800 2.600924e-02 -0.530706
2019-11-06 10:11:12,940 train 850 2.599841e-02 -0.532836
2019-11-06 10:11:15,905 training loss; R2: 2.599275e-02 -0.532692
2019-11-06 10:11:16,544 valid 000 2.702331e-02 -0.228364
2019-11-06 10:11:25,984 valid 050 2.434633e-02 -0.454715
2019-11-06 10:11:34,348 validation loss; R2: 2.454065e-02 -0.520185
2019-11-06 10:11:34,415 epoch 9 lr 1.000000e-05
2019-11-06 10:11:35,175 train 000 2.462989e-02 -0.797527
2019-11-06 10:11:45,014 train 050 2.582424e-02 -0.375132
2019-11-06 10:11:54,872 train 100 2.612568e-02 -0.499237
2019-11-06 10:12:04,755 train 150 2.588080e-02 -0.528756
2019-11-06 10:12:14,639 train 200 2.599190e-02 -0.506481
2019-11-06 10:12:24,541 train 250 2.590330e-02 -0.512952
2019-11-06 10:12:34,437 train 300 2.595928e-02 -0.509392
2019-11-06 10:12:44,329 train 350 2.600699e-02 -0.500740
2019-11-06 10:12:54,228 train 400 2.604720e-02 -0.509150
2019-11-06 10:13:04,124 train 450 2.604800e-02 -0.496140
2019-11-06 10:13:14,022 train 500 2.599481e-02 -0.497423
2019-11-06 10:13:23,915 train 550 2.598993e-02 -0.493656
2019-11-06 10:13:33,821 train 600 2.596693e-02 -0.499741
2019-11-06 10:13:43,748 train 650 2.593799e-02 -0.498297
2019-11-06 10:13:53,656 train 700 2.588216e-02 -0.501053
2019-11-06 10:14:03,581 train 750 2.588088e-02 -0.493382
2019-11-06 10:14:13,467 train 800 2.589799e-02 -0.496948
2019-11-06 10:14:23,329 train 850 2.589104e-02 -0.513642
2019-11-06 10:14:26,275 training loss; R2: 2.587999e-02 -0.514595
2019-11-06 10:14:26,963 valid 000 2.772672e-02 -0.300987
2019-11-06 10:14:36,315 valid 050 2.479034e-02 -0.577132
2019-11-06 10:14:44,812 validation loss; R2: 2.434953e-02 -0.655742
2019-11-06 10:14:44,876 epoch 10 lr 1.000000e-05
2019-11-06 10:14:45,618 train 000 2.530457e-02 -1.128620
2019-11-06 10:14:55,460 train 050 2.514566e-02 -0.675682
2019-11-06 10:15:05,329 train 100 2.569305e-02 -0.658128
2019-11-06 10:15:15,195 train 150 2.564733e-02 -0.594597
2019-11-06 10:15:25,056 train 200 2.572514e-02 -0.591330
2019-11-06 10:15:34,937 train 250 2.564008e-02 -0.604972
2019-11-06 10:15:44,828 train 300 2.559415e-02 -0.596568
2019-11-06 10:15:54,722 train 350 2.550547e-02 -0.595190
2019-11-06 10:16:04,617 train 400 2.555414e-02 -0.592322
2019-11-06 10:16:14,520 train 450 2.563463e-02 -0.582190
2019-11-06 10:16:24,412 train 500 2.565611e-02 -11.779605
2019-11-06 10:16:34,306 train 550 2.569362e-02 -10.757952
2019-11-06 10:16:44,212 train 600 2.569825e-02 -9.910817
2019-11-06 10:16:54,125 train 650 2.570980e-02 -9.187474
2019-11-06 10:17:04,032 train 700 2.573316e-02 -8.558965
2019-11-06 10:17:13,955 train 750 2.572905e-02 -8.030345
2019-11-06 10:17:23,871 train 800 2.577518e-02 -7.562219
2019-11-06 10:17:33,781 train 850 2.578029e-02 -7.157718
2019-11-06 10:17:36,728 training loss; R2: 2.580487e-02 -7.041062
2019-11-06 10:17:37,344 valid 000 2.427036e-02 -0.069797
2019-11-06 10:17:46,822 valid 050 2.362400e-02 -0.529615
2019-11-06 10:17:55,148 validation loss; R2: 2.400041e-02 -0.524538
2019-11-06 10:17:55,216 epoch 11 lr 1.000000e-05
2019-11-06 10:17:55,967 train 000 2.431419e-02 -0.879122
2019-11-06 10:18:05,757 train 050 2.592063e-02 -0.416882
2019-11-06 10:18:15,555 train 100 2.587713e-02 -0.556611
2019-11-06 10:18:25,370 train 150 2.588657e-02 -0.538715
2019-11-06 10:18:35,198 train 200 2.582508e-02 -0.589467
2019-11-06 10:18:45,058 train 250 2.582383e-02 -0.588303
2019-11-06 10:18:54,918 train 300 2.579328e-02 -0.584840
2019-11-06 10:19:04,788 train 350 2.583420e-02 -0.574937
2019-11-06 10:19:14,641 train 400 2.578513e-02 -0.560397
2019-11-06 10:19:24,477 train 450 2.578375e-02 -0.551970
2019-11-06 10:19:34,329 train 500 2.579411e-02 -0.558903
2019-11-06 10:19:44,239 train 550 2.580553e-02 -0.565401
2019-11-06 10:19:54,343 train 600 2.581515e-02 -0.566567
2019-11-06 10:20:04,566 train 650 2.579668e-02 -0.556829
2019-11-06 10:20:14,780 train 700 2.578350e-02 -0.551907
2019-11-06 10:20:24,985 train 750 2.577488e-02 -0.545655
2019-11-06 10:20:35,186 train 800 2.574415e-02 -0.546788
2019-11-06 10:20:45,391 train 850 2.576138e-02 -0.543034
2019-11-06 10:20:48,440 training loss; R2: 2.577554e-02 -0.540014
2019-11-06 10:20:49,144 valid 000 2.487977e-02 -0.603886
2019-11-06 10:20:58,527 valid 050 2.387788e-02 -0.434021
2019-11-06 10:21:07,080 validation loss; R2: 2.400049e-02 -0.443698
2019-11-06 10:21:07,149 epoch 12 lr 1.000000e-05
2019-11-06 10:21:07,946 train 000 2.618657e-02 -0.743099
2019-11-06 10:21:18,100 train 050 2.622101e-02 -70.982384
2019-11-06 10:21:27,942 train 100 2.615633e-02 -36.175276
2019-11-06 10:21:37,768 train 150 2.598124e-02 -24.425138
2019-11-06 10:21:47,598 train 200 2.605294e-02 -18.476368
2019-11-06 10:21:57,428 train 250 2.597890e-02 -14.939649
2019-11-06 10:22:07,263 train 300 2.588714e-02 -12.563468
2019-11-06 10:22:17,113 train 350 2.582167e-02 -10.840318
2019-11-06 10:22:26,952 train 400 2.580885e-02 -9.569260
2019-11-06 10:22:36,785 train 450 2.572750e-02 -8.559214
2019-11-06 10:22:46,619 train 500 2.573596e-02 -7.796626
2019-11-06 10:22:56,448 train 550 2.574728e-02 -7.145017
2019-11-06 10:23:06,280 train 600 2.581269e-02 -6.598544
2019-11-06 10:23:16,119 train 650 2.580706e-02 -6.144192
2019-11-06 10:23:25,958 train 700 2.577091e-02 -5.739306
2019-11-06 10:23:35,786 train 750 2.575870e-02 -5.391103
2019-11-06 10:23:45,624 train 800 2.574276e-02 -5.094372
2019-11-06 10:23:55,453 train 850 2.571293e-02 -4.830997
2019-11-06 10:23:58,395 training loss; R2: 2.571783e-02 -4.755246
2019-11-06 10:23:59,084 valid 000 2.426131e-02 -0.774514
2019-11-06 10:24:08,510 valid 050 2.356162e-02 -0.469451
2019-11-06 10:24:16,939 validation loss; R2: 2.383761e-02 -0.525262
2019-11-06 10:24:17,007 epoch 13 lr 1.000000e-05
2019-11-06 10:24:17,789 train 000 2.356233e-02 -0.511451
2019-11-06 10:24:27,572 train 050 2.527413e-02 -0.442631
2019-11-06 10:24:37,361 train 100 2.522139e-02 -0.539772
2019-11-06 10:24:47,164 train 150 2.549182e-02 -0.713400
2019-11-06 10:24:56,974 train 200 2.549561e-02 -0.664872
2019-11-06 10:25:06,794 train 250 2.547567e-02 -0.681317
2019-11-06 10:25:16,626 train 300 2.557032e-02 -0.659204
2019-11-06 10:25:26,459 train 350 2.551700e-02 -0.630934
2019-11-06 10:25:36,296 train 400 2.550960e-02 -0.617060
2019-11-06 10:25:46,129 train 450 2.557128e-02 -0.608143
2019-11-06 10:25:55,976 train 500 2.558582e-02 -3.038276
2019-11-06 10:26:05,889 train 550 2.561338e-02 -2.802169
2019-11-06 10:26:15,754 train 600 2.560370e-02 -2.605363
2019-11-06 10:26:25,595 train 650 2.560024e-02 -2.465781
2019-11-06 10:26:35,460 train 700 2.559838e-02 -2.338796
2019-11-06 10:26:45,345 train 750 2.557914e-02 -2.240022
2019-11-06 10:26:55,232 train 800 2.558734e-02 -2.139242
2019-11-06 10:27:05,123 train 850 2.556707e-02 -2.067468
2019-11-06 10:27:08,080 training loss; R2: 2.556110e-02 -2.043688
2019-11-06 10:27:08,756 valid 000 2.296717e-02 -0.481244
2019-11-06 10:27:18,188 valid 050 2.386047e-02 -0.482846
2019-11-06 10:27:26,541 validation loss; R2: 2.361421e-02 -0.483835
2019-11-06 10:27:26,608 epoch 14 lr 1.000000e-05
2019-11-06 10:27:27,400 train 000 2.537370e-02 -0.241790
2019-11-06 10:27:37,218 train 050 2.592974e-02 -0.537306
2019-11-06 10:27:47,064 train 100 2.571608e-02 -0.460055
2019-11-06 10:27:56,911 train 150 2.565551e-02 -0.528241
2019-11-06 10:28:06,767 train 200 2.568087e-02 -0.524482
2019-11-06 10:28:16,629 train 250 2.562114e-02 -0.528004
2019-11-06 10:28:26,492 train 300 2.568102e-02 -0.528015
2019-11-06 10:28:36,376 train 350 2.566546e-02 -0.575827
2019-11-06 10:28:46,222 train 400 2.560872e-02 -0.593712
2019-11-06 10:28:56,025 train 450 2.558444e-02 -0.604126
2019-11-06 10:29:05,829 train 500 2.556219e-02 -0.587358
2019-11-06 10:29:15,637 train 550 2.553970e-02 -0.584501
2019-11-06 10:29:25,445 train 600 2.553433e-02 -0.590622
2019-11-06 10:29:35,256 train 650 2.552847e-02 -0.626120
2019-11-06 10:29:45,060 train 700 2.549972e-02 -0.623880
2019-11-06 10:29:54,872 train 750 2.549586e-02 -0.623344
2019-11-06 10:30:04,680 train 800 2.547505e-02 -0.610137
2019-11-06 10:30:14,492 train 850 2.547770e-02 -0.603622
2019-11-06 10:30:17,464 training loss; R2: 2.547399e-02 -0.603579
2019-11-06 10:30:18,117 valid 000 2.439523e-02 -0.876823
2019-11-06 10:30:27,559 valid 050 2.360521e-02 -0.711417
2019-11-06 10:30:36,040 validation loss; R2: 2.359683e-02 -0.555567
2019-11-06 10:30:36,122 epoch 15 lr 1.000000e-05
2019-11-06 10:30:36,937 train 000 3.000960e-02 -0.136964
2019-11-06 10:30:47,118 train 050 2.538534e-02 -0.607905
2019-11-06 10:30:57,335 train 100 2.543456e-02 -0.583160
2019-11-06 10:31:07,548 train 150 2.541969e-02 -0.747936
2019-11-06 10:31:17,770 train 200 2.526477e-02 -0.754284
2019-11-06 10:31:28,001 train 250 2.531638e-02 -0.738558
2019-11-06 10:31:38,228 train 300 2.542490e-02 -0.715126
2019-11-06 10:31:48,452 train 350 2.540160e-02 -0.674123
2019-11-06 10:31:58,692 train 400 2.536323e-02 -0.658870
2019-11-06 10:32:08,922 train 450 2.536842e-02 -0.654684
2019-11-06 10:32:19,147 train 500 2.536830e-02 -0.657284
2019-11-06 10:32:29,377 train 550 2.539980e-02 -0.660431
2019-11-06 10:32:39,608 train 600 2.537466e-02 -0.647531
2019-11-06 10:32:49,862 train 650 2.537663e-02 -0.638028
2019-11-06 10:33:00,117 train 700 2.535199e-02 -0.632571
2019-11-06 10:33:10,349 train 750 2.530962e-02 -0.636923
2019-11-06 10:33:20,610 train 800 2.530497e-02 -0.626771
2019-11-06 10:33:30,861 train 850 2.531679e-02 -0.615179
2019-11-06 10:33:33,876 training loss; R2: 2.530159e-02 -0.613433
2019-11-06 10:33:34,565 valid 000 2.624087e-02 -0.127263
2019-11-06 10:33:43,979 valid 050 2.336561e-02 -0.736086
2019-11-06 10:33:52,407 validation loss; R2: 2.334447e-02 -0.833653
2019-11-06 10:33:52,472 epoch 16 lr 1.000000e-05
2019-11-06 10:33:53,275 train 000 2.683211e-02 -0.093025
2019-11-06 10:34:03,104 train 050 2.543156e-02 -0.529872
2019-11-06 10:34:12,964 train 100 2.526349e-02 -0.488999
2019-11-06 10:34:22,823 train 150 2.533910e-02 -0.509551
2019-11-06 10:34:32,706 train 200 2.534553e-02 -0.524530
2019-11-06 10:34:42,591 train 250 2.535879e-02 -0.531238
2019-11-06 10:34:52,468 train 300 2.533442e-02 -0.563578
2019-11-06 10:35:02,356 train 350 2.531805e-02 -0.572517
2019-11-06 10:35:12,240 train 400 2.526888e-02 -0.585372
2019-11-06 10:35:22,117 train 450 2.526805e-02 -0.622683
2019-11-06 10:35:31,998 train 500 2.518354e-02 -0.626004
2019-11-06 10:35:41,881 train 550 2.520719e-02 -0.631711
2019-11-06 10:35:51,763 train 600 2.521060e-02 -0.619616
2019-11-06 10:36:01,647 train 650 2.522104e-02 -0.606812
2019-11-06 10:36:11,535 train 700 2.521386e-02 -0.596835
2019-11-06 10:36:21,425 train 750 2.523066e-02 -0.588520
2019-11-06 10:36:31,330 train 800 2.522549e-02 -0.589685
2019-11-06 10:36:41,236 train 850 2.519157e-02 -0.593319
2019-11-06 10:36:44,196 training loss; R2: 2.517736e-02 -0.593146
2019-11-06 10:36:44,865 valid 000 2.387303e-02 -0.297738
2019-11-06 10:36:54,355 valid 050 2.301233e-02 -0.647886
2019-11-06 10:37:02,689 validation loss; R2: 2.324858e-02 -1.228739
2019-11-06 10:37:02,757 epoch 17 lr 1.000000e-05
2019-11-06 10:37:03,532 train 000 2.233169e-02 -0.163586
2019-11-06 10:37:13,361 train 050 2.484994e-02 -0.540242
2019-11-06 10:37:23,217 train 100 2.492646e-02 -0.684692
2019-11-06 10:37:33,073 train 150 2.505516e-02 -0.635006
2019-11-06 10:37:42,949 train 200 2.520966e-02 -0.613183
2019-11-06 10:37:52,840 train 250 2.531545e-02 -0.596712
2019-11-06 10:38:02,744 train 300 2.529541e-02 -0.594076
2019-11-06 10:38:12,633 train 350 2.525476e-02 -0.576588
2019-11-06 10:38:22,513 train 400 2.520274e-02 -0.564912
2019-11-06 10:38:32,397 train 450 2.516839e-02 -0.562492
2019-11-06 10:38:42,280 train 500 2.517689e-02 -0.562347
2019-11-06 10:38:52,165 train 550 2.517234e-02 -0.556959
2019-11-06 10:39:02,047 train 600 2.516674e-02 -0.561816
2019-11-06 10:39:11,924 train 650 2.515988e-02 -0.588791
2019-11-06 10:39:21,808 train 700 2.513614e-02 -0.579111
2019-11-06 10:39:31,692 train 750 2.510452e-02 -0.628617
2019-11-06 10:39:41,584 train 800 2.505586e-02 -0.633845
2019-11-06 10:39:51,453 train 850 2.505942e-02 -0.622374
2019-11-06 10:39:54,405 training loss; R2: 2.505239e-02 -0.623734
2019-11-06 10:39:55,093 valid 000 2.525381e-02 -3.562505
2019-11-06 10:40:04,565 valid 050 2.345788e-02 -0.566091
2019-11-06 10:40:12,938 validation loss; R2: 2.319554e-02 -0.597507
2019-11-06 10:40:13,008 epoch 18 lr 1.000000e-05
2019-11-06 10:40:13,762 train 000 2.460211e-02 -0.230504
2019-11-06 10:40:23,537 train 050 2.469683e-02 -0.517086
2019-11-06 10:40:33,348 train 100 2.494527e-02 -0.513121
2019-11-06 10:40:43,139 train 150 2.494858e-02 -0.540488
2019-11-06 10:40:52,938 train 200 2.500180e-02 -0.628499
2019-11-06 10:41:02,753 train 250 2.492510e-02 -0.671846
2019-11-06 10:41:12,566 train 300 2.487875e-02 -0.640153
2019-11-06 10:41:22,379 train 350 2.488548e-02 -0.618146
2019-11-06 10:41:32,199 train 400 2.493633e-02 -0.613721
2019-11-06 10:41:42,015 train 450 2.491573e-02 -0.605349
2019-11-06 10:41:51,839 train 500 2.492196e-02 -0.601709
2019-11-06 10:42:01,661 train 550 2.490063e-02 -0.592465
2019-11-06 10:42:11,484 train 600 2.490455e-02 -0.578213
2019-11-06 10:42:21,303 train 650 2.497251e-02 -0.584394
2019-11-06 10:42:31,122 train 700 2.495369e-02 -0.592754
2019-11-06 10:42:40,939 train 750 2.491327e-02 -0.589386
2019-11-06 10:42:50,758 train 800 2.490698e-02 -0.590916
2019-11-06 10:43:00,590 train 850 2.493084e-02 -0.587557
2019-11-06 10:43:03,533 training loss; R2: 2.492084e-02 -0.584375
2019-11-06 10:43:04,167 valid 000 2.320981e-02 -0.237390
2019-11-06 10:43:13,631 valid 050 2.337013e-02 -0.648315
2019-11-06 10:43:22,024 validation loss; R2: 2.310611e-02 -0.600059
2019-11-06 10:43:22,091 epoch 19 lr 1.000000e-05
2019-11-06 10:43:22,867 train 000 2.054918e-02 -0.299143
2019-11-06 10:43:32,635 train 050 2.483476e-02 -0.539603
2019-11-06 10:43:42,412 train 100 2.491758e-02 -0.489446
2019-11-06 10:43:52,217 train 150 2.464989e-02 -0.525186
2019-11-06 10:44:02,052 train 200 2.457821e-02 -0.624401
2019-11-06 10:44:11,865 train 250 2.463793e-02 -0.623164
2019-11-06 10:44:21,684 train 300 2.464948e-02 -0.726919
2019-11-06 10:44:31,514 train 350 2.467898e-02 -0.698885
2019-11-06 10:44:41,337 train 400 2.462631e-02 -0.683204
2019-11-06 10:44:51,165 train 450 2.458064e-02 -0.667455
2019-11-06 10:45:00,995 train 500 2.456551e-02 -0.683584
2019-11-06 10:45:10,817 train 550 2.455653e-02 -0.690461
2019-11-06 10:45:20,646 train 600 2.454788e-02 -0.695936
2019-11-06 10:45:30,480 train 650 2.460184e-02 -0.679960
2019-11-06 10:45:40,303 train 700 2.459744e-02 -0.681879
2019-11-06 10:45:50,145 train 750 2.459751e-02 -0.664643
2019-11-06 10:45:59,982 train 800 2.457080e-02 -0.664214
2019-11-06 10:46:09,817 train 850 2.457612e-02 -0.657522
2019-11-06 10:46:12,755 training loss; R2: 2.457288e-02 -0.657337
2019-11-06 10:46:13,453 valid 000 2.375683e-02 -0.505090
2019-11-06 10:46:22,980 valid 050 2.277559e-02 -0.410839
2019-11-06 10:46:31,359 validation loss; R2: 2.304492e-02 -0.464875
2019-11-06 10:46:31,434 epoch 20 lr 1.000000e-05
2019-11-06 10:46:32,197 train 000 2.784739e-02 -0.561375
2019-11-06 10:46:41,958 train 050 2.462961e-02 -0.534376
2019-11-06 10:46:51,718 train 100 2.461644e-02 -0.605568
2019-11-06 10:47:01,518 train 150 2.447181e-02 -0.619943
2019-11-06 10:47:11,330 train 200 2.428837e-02 -0.686624
2019-11-06 10:47:21,132 train 250 2.432339e-02 -0.652064
2019-11-06 10:47:30,963 train 300 2.436076e-02 -0.643467
2019-11-06 10:47:40,789 train 350 2.437715e-02 -0.626313
2019-11-06 10:47:50,628 train 400 2.444429e-02 -0.639043
2019-11-06 10:48:00,454 train 450 2.446820e-02 -0.643275
2019-11-06 10:48:10,282 train 500 2.452127e-02 -0.653502
2019-11-06 10:48:20,112 train 550 2.450544e-02 -0.654785
2019-11-06 10:48:29,954 train 600 2.450935e-02 -0.639535
2019-11-06 10:48:39,794 train 650 2.448191e-02 -0.633429
2019-11-06 10:48:49,629 train 700 2.449061e-02 -0.661723
2019-11-06 10:48:59,469 train 750 2.449234e-02 -0.655481
2019-11-06 10:49:09,312 train 800 2.448941e-02 -0.653787
2019-11-06 10:49:19,150 train 850 2.446667e-02 -0.648565
2019-11-06 10:49:22,092 training loss; R2: 2.446508e-02 -0.647979
2019-11-06 10:49:22,757 valid 000 2.312267e-02 -0.144306
2019-11-06 10:49:32,243 valid 050 2.279460e-02 -0.669934
2019-11-06 10:49:40,601 validation loss; R2: 2.296869e-02 -0.546932
2019-11-06 10:49:40,668 epoch 21 lr 1.000000e-05
2019-11-06 10:49:41,457 train 000 2.241549e-02 -1.014407
2019-11-06 10:49:51,215 train 050 2.397160e-02 -1.722979
2019-11-06 10:50:00,992 train 100 2.427668e-02 -1.202365
2019-11-06 10:50:10,804 train 150 2.421571e-02 -0.979136
2019-11-06 10:50:20,645 train 200 2.430985e-02 -0.900588
2019-11-06 10:50:30,461 train 250 2.430152e-02 -0.823311
2019-11-06 10:50:40,285 train 300 2.428267e-02 -0.793746
2019-11-06 10:50:50,091 train 350 2.415728e-02 -0.779623
2019-11-06 10:50:59,912 train 400 2.418514e-02 -0.787376
2019-11-06 10:51:09,732 train 450 2.416689e-02 -0.767293
2019-11-06 10:51:19,562 train 500 2.420836e-02 -4.466669
2019-11-06 10:51:29,393 train 550 2.420257e-02 -4.114604
2019-11-06 10:51:39,233 train 600 2.422789e-02 -3.812840
2019-11-06 10:51:49,068 train 650 2.425927e-02 -3.557554
2019-11-06 10:51:58,914 train 700 2.426126e-02 -3.337005
2019-11-06 10:52:08,756 train 750 2.426573e-02 -3.153454
2019-11-06 10:52:18,605 train 800 2.426750e-02 -2.993353
2019-11-06 10:52:28,430 train 850 2.427318e-02 -2.874946
2019-11-06 10:52:31,371 training loss; R2: 2.427021e-02 -2.834292
2019-11-06 10:52:32,048 valid 000 2.415808e-02 -0.152852
2019-11-06 10:52:41,529 valid 050 2.294017e-02 -0.757641
2019-11-06 10:52:49,883 validation loss; R2: 2.278814e-02 -1.073133
2019-11-06 10:52:49,950 epoch 22 lr 1.000000e-05
2019-11-06 10:52:50,729 train 000 2.301083e-02 -0.063996
2019-11-06 10:53:00,488 train 050 2.370154e-02 -0.726125
2019-11-06 10:53:10,244 train 100 2.394812e-02 -0.667615
2019-11-06 10:53:20,034 train 150 2.407277e-02 -0.605213
2019-11-06 10:53:29,843 train 200 2.407992e-02 -0.591988
2019-11-06 10:53:39,647 train 250 2.408377e-02 -0.575622
2019-11-06 10:53:49,454 train 300 2.406204e-02 -0.622477
2019-11-06 10:53:59,256 train 350 2.405708e-02 -0.608498
2019-11-06 10:54:09,068 train 400 2.408672e-02 -0.616408
2019-11-06 10:54:18,879 train 450 2.404939e-02 -0.619821
2019-11-06 10:54:28,700 train 500 2.403169e-02 -0.614236
2019-11-06 10:54:38,532 train 550 2.403469e-02 -0.616645
2019-11-06 10:54:48,369 train 600 2.403634e-02 -0.618799
2019-11-06 10:54:58,184 train 650 2.406196e-02 -0.607894
2019-11-06 10:55:07,991 train 700 2.406487e-02 -0.614201
2019-11-06 10:55:17,809 train 750 2.404956e-02 -0.616532
2019-11-06 10:55:27,627 train 800 2.405860e-02 -0.613771
2019-11-06 10:55:37,438 train 850 2.407026e-02 -0.602851
2019-11-06 10:55:40,376 training loss; R2: 2.407353e-02 -0.600118
2019-11-06 10:55:41,037 valid 000 2.231428e-02 -0.150442
2019-11-06 10:55:50,455 valid 050 2.308757e-02 -0.534285
2019-11-06 10:55:58,834 validation loss; R2: 2.295266e-02 -0.498614
2019-11-06 10:55:58,903 epoch 23 lr 1.000000e-05
2019-11-06 10:55:59,685 train 000 2.222976e-02 -0.830737
2019-11-06 10:56:09,460 train 050 2.375444e-02 -0.447500
2019-11-06 10:56:19,248 train 100 2.378198e-02 -0.494432
2019-11-06 10:56:29,052 train 150 2.394323e-02 -0.571306
2019-11-06 10:56:38,861 train 200 2.394464e-02 -0.573135
2019-11-06 10:56:48,674 train 250 2.394486e-02 -0.568310
2019-11-06 10:56:58,487 train 300 2.390264e-02 -0.565542
2019-11-06 10:57:08,311 train 350 2.386238e-02 -0.598321
2019-11-06 10:57:18,124 train 400 2.387826e-02 -0.573666
2019-11-06 10:57:27,945 train 450 2.384349e-02 -0.594723
2019-11-06 10:57:37,740 train 500 2.384332e-02 -0.576675
2019-11-06 10:57:47,525 train 550 2.385088e-02 -0.584945
2019-11-06 10:57:57,323 train 600 2.385668e-02 -0.581129
2019-11-06 10:58:07,114 train 650 2.385867e-02 -0.581336
2019-11-06 10:58:16,901 train 700 2.382758e-02 -0.573094
2019-11-06 10:58:26,702 train 750 2.383653e-02 -0.597390
2019-11-06 10:58:36,502 train 800 2.384486e-02 -0.595780
2019-11-06 10:58:46,301 train 850 2.386994e-02 -0.616205
2019-11-06 10:58:49,228 training loss; R2: 2.387888e-02 -0.615152
2019-11-06 10:58:49,925 valid 000 2.225075e-02 -0.387273
2019-11-06 10:58:59,394 valid 050 2.283420e-02 -0.650349
2019-11-06 10:59:07,740 validation loss; R2: 2.280077e-02 -0.614293
2019-11-06 10:59:07,807 epoch 24 lr 1.000000e-05
2019-11-06 10:59:08,612 train 000 2.170278e-02 -0.513518
2019-11-06 10:59:18,335 train 050 2.433805e-02 -0.541171
2019-11-06 10:59:28,054 train 100 2.420418e-02 -0.589762
2019-11-06 10:59:37,815 train 150 2.425640e-02 -0.564110
2019-11-06 10:59:47,590 train 200 2.409819e-02 -0.593421
2019-11-06 10:59:57,364 train 250 2.406621e-02 -0.993192
2019-11-06 11:00:07,150 train 300 2.400841e-02 -0.907352
2019-11-06 11:00:16,930 train 350 2.399217e-02 -0.858698
2019-11-06 11:00:26,710 train 400 2.394659e-02 -0.844159
2019-11-06 11:00:36,481 train 450 2.389449e-02 -0.802834
2019-11-06 11:00:46,255 train 500 2.389031e-02 -0.777037
2019-11-06 11:00:56,026 train 550 2.388463e-02 -0.747512
2019-11-06 11:01:05,813 train 600 2.388706e-02 -0.752478
2019-11-06 11:01:15,591 train 650 2.388101e-02 -0.734879
2019-11-06 11:01:25,368 train 700 2.386074e-02 -0.753577
2019-11-06 11:01:35,158 train 750 2.382442e-02 -0.749645
2019-11-06 11:01:44,946 train 800 2.381912e-02 -0.745115
2019-11-06 11:01:54,735 train 850 2.379317e-02 -0.732969
2019-11-06 11:01:57,663 training loss; R2: 2.381545e-02 -0.729958
2019-11-06 11:01:58,357 valid 000 2.180429e-02 -0.301594
2019-11-06 11:02:07,751 valid 050 2.270260e-02 -0.668974
2019-11-06 11:02:16,195 validation loss; R2: 2.257999e-02 -0.559866
2019-11-06 11:02:16,264 epoch 25 lr 1.000000e-05
2019-11-06 11:02:17,005 train 000 2.506225e-02 -0.305274
2019-11-06 11:02:26,731 train 050 2.344353e-02 -0.669840
2019-11-06 11:02:36,493 train 100 2.347611e-02 -0.677020
2019-11-06 11:02:46,263 train 150 2.354804e-02 -0.705155
2019-11-06 11:02:56,043 train 200 2.370390e-02 -0.713867
2019-11-06 11:03:05,850 train 250 2.373897e-02 -0.675074
2019-11-06 11:03:15,635 train 300 2.366210e-02 -0.677776
2019-11-06 11:03:25,427 train 350 2.363264e-02 -0.662330
2019-11-06 11:03:35,223 train 400 2.358292e-02 -0.682154
2019-11-06 11:03:45,015 train 450 2.364461e-02 -0.728131
2019-11-06 11:03:54,826 train 500 2.364810e-02 -0.739472
2019-11-06 11:04:04,629 train 550 2.363073e-02 -0.731369
2019-11-06 11:04:14,432 train 600 2.364532e-02 -0.716858
2019-11-06 11:04:24,237 train 650 2.367600e-02 -0.716738
2019-11-06 11:04:34,056 train 700 2.365526e-02 -2.449434
2019-11-06 11:04:43,878 train 750 2.368260e-02 -2.334836
2019-11-06 11:04:53,717 train 800 2.367200e-02 -2.238226
2019-11-06 11:05:03,555 train 850 2.368613e-02 -2.154883
2019-11-06 11:05:06,494 training loss; R2: 2.369192e-02 -2.146601
2019-11-06 11:05:07,204 valid 000 1.930526e-02 -0.369422
2019-11-06 11:05:16,640 valid 050 2.235087e-02 -0.665463
2019-11-06 11:05:25,116 validation loss; R2: 2.233847e-02 -0.641977
2019-11-06 11:05:25,185 epoch 26 lr 1.000000e-05
2019-11-06 11:05:25,952 train 000 2.723311e-02 -0.224857
2019-11-06 11:05:35,692 train 050 2.381927e-02 -0.446958
2019-11-06 11:05:45,425 train 100 2.364555e-02 -0.593004
2019-11-06 11:05:55,195 train 150 2.351555e-02 -0.593005
2019-11-06 11:06:04,975 train 200 2.365067e-02 -0.581405
2019-11-06 11:06:14,760 train 250 2.361372e-02 -0.582458
2019-11-06 11:06:24,551 train 300 2.370757e-02 -0.585674
2019-11-06 11:06:34,337 train 350 2.364200e-02 -0.600002
2019-11-06 11:06:44,141 train 400 2.355903e-02 -0.618119
2019-11-06 11:06:53,942 train 450 2.360548e-02 -0.603183
2019-11-06 11:07:03,749 train 500 2.358931e-02 -0.597315
2019-11-06 11:07:13,564 train 550 2.357933e-02 -0.615495
2019-11-06 11:07:23,397 train 600 2.360576e-02 -0.605697
2019-11-06 11:07:33,232 train 650 2.361736e-02 -0.610389
2019-11-06 11:07:43,074 train 700 2.359155e-02 -0.606718
2019-11-06 11:07:52,944 train 750 2.360788e-02 -0.594073
2019-11-06 11:08:02,800 train 800 2.357344e-02 -0.594119
2019-11-06 11:08:12,653 train 850 2.357597e-02 -0.586737
2019-11-06 11:08:15,604 training loss; R2: 2.358933e-02 -0.585650
2019-11-06 11:08:16,257 valid 000 2.237643e-02 -0.210352
2019-11-06 11:08:25,737 valid 050 2.209045e-02 -0.501578
2019-11-06 11:08:34,187 validation loss; R2: 2.213019e-02 -0.470851
2019-11-06 11:08:34,256 epoch 27 lr 1.000000e-05
2019-11-06 11:08:35,121 train 000 2.688948e-02 -0.584521
2019-11-06 11:08:44,880 train 050 2.327778e-02 -0.611893
2019-11-06 11:08:54,682 train 100 2.351396e-02 -0.593681
2019-11-06 11:09:04,472 train 150 2.349001e-02 -0.570311
2019-11-06 11:09:14,261 train 200 2.348690e-02 -0.670769
2019-11-06 11:09:24,055 train 250 2.338031e-02 -0.633327
2019-11-06 11:09:33,864 train 300 2.345899e-02 -0.639388
2019-11-06 11:09:43,657 train 350 2.349395e-02 -1.126621
2019-11-06 11:09:53,450 train 400 2.343572e-02 -1.060078
2019-11-06 11:10:03,227 train 450 2.342107e-02 -1.000548
2019-11-06 11:10:13,029 train 500 2.342247e-02 -0.963942
2019-11-06 11:10:22,823 train 550 2.339913e-02 -0.927454
2019-11-06 11:10:32,628 train 600 2.339646e-02 -0.912682
2019-11-06 11:10:42,445 train 650 2.337996e-02 -0.932676
2019-11-06 11:10:52,277 train 700 2.338659e-02 -0.910072
2019-11-06 11:11:02,055 train 750 2.339662e-02 -0.899397
2019-11-06 11:11:11,837 train 800 2.337903e-02 -0.889733
2019-11-06 11:11:21,632 train 850 2.337843e-02 -0.876838
2019-11-06 11:11:24,567 training loss; R2: 2.337847e-02 -0.871895
2019-11-06 11:11:25,201 valid 000 1.864613e-02 0.035027
2019-11-06 11:11:34,687 valid 050 2.238286e-02 -0.643956
2019-11-06 11:11:43,105 validation loss; R2: 2.229900e-02 -0.586597
2019-11-06 11:11:43,171 epoch 28 lr 1.000000e-05
2019-11-06 11:11:43,916 train 000 2.387547e-02 -0.050558
2019-11-06 11:11:53,693 train 050 2.323181e-02 -0.465286
2019-11-06 11:12:03,499 train 100 2.314812e-02 -0.508763
2019-11-06 11:12:13,306 train 150 2.322472e-02 -0.678753
2019-11-06 11:12:23,128 train 200 2.331835e-02 -0.611066
2019-11-06 11:12:32,938 train 250 2.328746e-02 -0.615196
2019-11-06 11:12:42,754 train 300 2.330336e-02 -0.632851
2019-11-06 11:12:52,569 train 350 2.331334e-02 -0.657096
2019-11-06 11:13:02,381 train 400 2.330296e-02 -0.682298
2019-11-06 11:13:12,148 train 450 2.330873e-02 -0.664066
2019-11-06 11:13:21,913 train 500 2.330528e-02 -0.651837
2019-11-06 11:13:31,678 train 550 2.333413e-02 -0.638928
2019-11-06 11:13:41,451 train 600 2.330996e-02 -0.626317
2019-11-06 11:13:51,217 train 650 2.333586e-02 -0.617225
2019-11-06 11:14:00,983 train 700 2.330075e-02 -0.615572
2019-11-06 11:14:10,745 train 750 2.330507e-02 -0.632476
2019-11-06 11:14:20,515 train 800 2.327726e-02 -0.669538
2019-11-06 11:14:30,284 train 850 2.327926e-02 -0.667166
2019-11-06 11:14:33,200 training loss; R2: 2.328693e-02 -0.666111
2019-11-06 11:14:33,882 valid 000 2.019100e-02 -0.146397
2019-11-06 11:14:43,306 valid 050 2.211635e-02 -0.561368
2019-11-06 11:14:51,760 validation loss; R2: 2.213863e-02 -0.608004
2019-11-06 11:14:51,823 epoch 29 lr 1.000000e-05
2019-11-06 11:14:52,574 train 000 2.351429e-02 -0.495939
2019-11-06 11:15:02,279 train 050 2.296219e-02 -0.624896
2019-11-06 11:15:11,978 train 100 2.308710e-02 -0.613300
2019-11-06 11:15:21,716 train 150 2.314865e-02 -0.637810
2019-11-06 11:15:31,475 train 200 2.321824e-02 -0.607242
2019-11-06 11:15:41,224 train 250 2.321758e-02 -0.642598
2019-11-06 11:15:50,980 train 300 2.325827e-02 -0.673441
2019-11-06 11:16:00,736 train 350 2.332567e-02 -0.658356
2019-11-06 11:16:10,493 train 400 2.326464e-02 -0.636178
2019-11-06 11:16:20,260 train 450 2.329137e-02 -0.627684
2019-11-06 11:16:30,034 train 500 2.329377e-02 -0.622783
2019-11-06 11:16:39,800 train 550 2.328630e-02 -0.606042
2019-11-06 11:16:49,575 train 600 2.327515e-02 -0.616415
2019-11-06 11:16:59,361 train 650 2.327825e-02 -0.605776
2019-11-06 11:17:09,178 train 700 2.325243e-02 -0.606725
2019-11-06 11:17:19,022 train 750 2.323672e-02 -0.614828
2019-11-06 11:17:28,858 train 800 2.321288e-02 -0.612584
2019-11-06 11:17:38,710 train 850 2.319264e-02 -0.624666
2019-11-06 11:17:41,653 training loss; R2: 2.318962e-02 -0.623439
2019-11-06 11:17:42,357 valid 000 1.985240e-02 -0.307020
2019-11-06 11:17:51,782 valid 050 2.184040e-02 -0.455251
2019-11-06 11:18:00,116 validation loss; R2: 2.187286e-02 -0.504768
2019-11-06 11:18:00,181 epoch 30 lr 1.000000e-05
2019-11-06 11:18:00,961 train 000 2.216054e-02 -0.010983
2019-11-06 11:18:10,724 train 050 2.303971e-02 -0.546622
2019-11-06 11:18:20,502 train 100 2.316046e-02 -0.580818
2019-11-06 11:18:30,292 train 150 2.304002e-02 -0.700542
2019-11-06 11:18:40,092 train 200 2.316235e-02 -0.703054
2019-11-06 11:18:49,882 train 250 2.317868e-02 -0.934528
2019-11-06 11:18:59,687 train 300 2.311969e-02 -0.858428
2019-11-06 11:19:09,492 train 350 2.307751e-02 -0.856919
2019-11-06 11:19:19,285 train 400 2.305480e-02 -0.857730
2019-11-06 11:19:29,083 train 450 2.308943e-02 -0.847323
2019-11-06 11:19:38,857 train 500 2.305868e-02 -0.807958
2019-11-06 11:19:48,628 train 550 2.308333e-02 -0.778860
2019-11-06 11:19:58,408 train 600 2.305334e-02 -0.752583
2019-11-06 11:20:08,182 train 650 2.307702e-02 -0.744275
2019-11-06 11:20:17,946 train 700 2.308588e-02 -0.727613
2019-11-06 11:20:27,720 train 750 2.306830e-02 -0.726827
2019-11-06 11:20:37,498 train 800 2.307963e-02 -0.714099
2019-11-06 11:20:47,287 train 850 2.309826e-02 -0.704056
2019-11-06 11:20:50,205 training loss; R2: 2.309381e-02 -0.700991
2019-11-06 11:20:50,892 valid 000 2.097630e-02 -1.121340
2019-11-06 11:21:00,320 valid 050 2.166496e-02 -0.665122
2019-11-06 11:21:08,658 validation loss; R2: 2.172412e-02 -0.689990
2019-11-06 11:21:08,725 epoch 31 lr 1.000000e-05
2019-11-06 11:21:09,498 train 000 2.532526e-02 -0.232791
2019-11-06 11:21:19,209 train 050 2.246619e-02 -0.556040
2019-11-06 11:21:28,925 train 100 2.288599e-02 -0.565279
2019-11-06 11:21:38,680 train 150 2.301471e-02 -0.530205
2019-11-06 11:21:48,442 train 200 2.301531e-02 -0.507090
2019-11-06 11:21:58,204 train 250 2.292366e-02 -0.558358
2019-11-06 11:22:07,964 train 300 2.289439e-02 -0.621177
2019-11-06 11:22:17,728 train 350 2.291803e-02 -0.616170
2019-11-06 11:22:27,500 train 400 2.293483e-02 -0.620029
2019-11-06 11:22:37,263 train 450 2.290684e-02 -0.610663
2019-11-06 11:22:47,033 train 500 2.292914e-02 -0.624511
2019-11-06 11:22:56,798 train 550 2.296494e-02 -0.619635
2019-11-06 11:23:06,567 train 600 2.295202e-02 -0.611982
2019-11-06 11:23:16,332 train 650 2.295112e-02 -0.637418
2019-11-06 11:23:26,110 train 700 2.295472e-02 -0.639534
2019-11-06 11:23:35,873 train 750 2.294220e-02 -6.618023
2019-11-06 11:23:45,647 train 800 2.292896e-02 -6.234685
2019-11-06 11:23:55,420 train 850 2.290423e-02 -5.910798
2019-11-06 11:23:58,337 training loss; R2: 2.290086e-02 -5.816599
2019-11-06 11:23:58,970 valid 000 1.910137e-02 -0.434220
2019-11-06 11:24:08,416 valid 050 2.158686e-02 -9.755646
2019-11-06 11:24:16,741 validation loss; R2: 2.156586e-02 -5.508371
2019-11-06 11:24:16,810 epoch 32 lr 1.000000e-05
2019-11-06 11:24:17,545 train 000 2.508838e-02 -0.318872
2019-11-06 11:24:27,262 train 050 2.297036e-02 -33.759316
2019-11-06 11:24:37,009 train 100 2.280663e-02 -17.447341
2019-11-06 11:24:46,792 train 150 2.282492e-02 -11.821652
2019-11-06 11:24:56,589 train 200 2.273941e-02 -9.070281
2019-11-06 11:25:06,394 train 250 2.273391e-02 -7.405810
2019-11-06 11:25:16,192 train 300 2.276041e-02 -6.313123
2019-11-06 11:25:26,000 train 350 2.283294e-02 -5.525401
2019-11-06 11:25:35,807 train 400 2.282827e-02 -4.892905
2019-11-06 11:25:45,627 train 450 2.285829e-02 -4.406102
2019-11-06 11:25:55,435 train 500 2.284539e-02 -4.034136
2019-11-06 11:26:05,489 train 550 2.280228e-02 -3.757487
2019-11-06 11:26:15,654 train 600 2.276970e-02 -3.517868
2019-11-06 11:26:25,818 train 650 2.274445e-02 -3.302257
2019-11-06 11:26:35,985 train 700 2.275897e-02 -3.095005
2019-11-06 11:26:46,139 train 750 2.274514e-02 -2.930182
2019-11-06 11:26:56,298 train 800 2.275244e-02 -2.779988
2019-11-06 11:27:06,461 train 850 2.276960e-02 -2.654329
2019-11-06 11:27:09,492 training loss; R2: 2.276734e-02 -2.621385
2019-11-06 11:27:10,192 valid 000 2.386951e-02 -2.892274
2019-11-06 11:27:19,601 valid 050 2.129781e-02 -0.884518
2019-11-06 11:27:28,065 validation loss; R2: 2.121485e-02 -0.855865
2019-11-06 11:27:28,136 epoch 33 lr 1.000000e-05
2019-11-06 11:27:28,903 train 000 1.800862e-02 -0.071395
2019-11-06 11:27:39,024 train 050 2.308963e-02 -0.896868
2019-11-06 11:27:49,167 train 100 2.274812e-02 -0.740021
2019-11-06 11:27:59,317 train 150 2.284781e-02 -0.709674
2019-11-06 11:28:09,473 train 200 2.277331e-02 -0.716466
2019-11-06 11:28:19,623 train 250 2.274826e-02 -0.673525
2019-11-06 11:28:29,799 train 300 2.275622e-02 -0.688736
2019-11-06 11:28:39,950 train 350 2.279066e-02 -0.682446
2019-11-06 11:28:50,121 train 400 2.273501e-02 -0.667945
2019-11-06 11:29:00,288 train 450 2.275327e-02 -0.655443
2019-11-06 11:29:10,455 train 500 2.277807e-02 -0.635875
2019-11-06 11:29:20,625 train 550 2.276012e-02 -0.655910
2019-11-06 11:29:30,785 train 600 2.276567e-02 -0.646943
2019-11-06 11:29:40,960 train 650 2.274486e-02 -0.642144
2019-11-06 11:29:51,157 train 700 2.271442e-02 -0.675254
2019-11-06 11:30:01,344 train 750 2.270889e-02 -0.688667
2019-11-06 11:30:11,524 train 800 2.272957e-02 -0.699201
2019-11-06 11:30:21,695 train 850 2.269392e-02 -0.690178
2019-11-06 11:30:24,735 training loss; R2: 2.270364e-02 -0.730507
2019-11-06 11:30:25,393 valid 000 2.188953e-02 -0.795664
2019-11-06 11:30:34,830 valid 050 2.080617e-02 -0.853146
2019-11-06 11:30:43,196 validation loss; R2: 2.102004e-02 -0.659447
2019-11-06 11:30:43,278 epoch 34 lr 1.000000e-05
2019-11-06 11:30:44,091 train 000 2.384244e-02 -0.921736
2019-11-06 11:30:53,831 train 050 2.264496e-02 -1.029964
2019-11-06 11:31:03,579 train 100 2.278603e-02 -0.816088
2019-11-06 11:31:13,333 train 150 2.268166e-02 -0.886494
2019-11-06 11:31:23,115 train 200 2.249539e-02 -0.801146
2019-11-06 11:31:32,892 train 250 2.246063e-02 -0.750401
2019-11-06 11:31:42,680 train 300 2.244672e-02 -0.744373
2019-11-06 11:31:52,472 train 350 2.243076e-02 -0.729540
2019-11-06 11:32:02,257 train 400 2.242542e-02 -0.716742
2019-11-06 11:32:12,044 train 450 2.249204e-02 -0.686218
2019-11-06 11:32:21,823 train 500 2.252641e-02 -0.676859
2019-11-06 11:32:31,610 train 550 2.251219e-02 -0.674381
2019-11-06 11:32:41,403 train 600 2.251163e-02 -0.664246
2019-11-06 11:32:51,202 train 650 2.249868e-02 -0.647083
2019-11-06 11:33:01,003 train 700 2.253466e-02 -0.668738
2019-11-06 11:33:10,793 train 750 2.254134e-02 -0.660203
2019-11-06 11:33:20,583 train 800 2.254226e-02 -0.660587
2019-11-06 11:33:30,371 train 850 2.254357e-02 -0.663665
2019-11-06 11:33:33,294 training loss; R2: 2.256012e-02 -0.660901
2019-11-06 11:33:33,919 valid 000 2.157321e-02 -0.136731
2019-11-06 11:33:43,316 valid 050 2.142082e-02 -0.784007
2019-11-06 11:33:51,777 validation loss; R2: 2.099042e-02 -0.782056
2019-11-06 11:33:51,846 epoch 35 lr 1.000000e-05
2019-11-06 11:33:52,644 train 000 2.406408e-02 -0.355786
2019-11-06 11:34:02,397 train 050 2.294621e-02 -1.364728
2019-11-06 11:34:12,159 train 100 2.258720e-02 -0.983819
2019-11-06 11:34:21,974 train 150 2.260567e-02 -0.884436
2019-11-06 11:34:31,800 train 200 2.261684e-02 -0.828993
2019-11-06 11:34:41,630 train 250 2.258443e-02 -0.780643
2019-11-06 11:34:51,464 train 300 2.257325e-02 -0.738465
2019-11-06 11:35:01,294 train 350 2.248208e-02 -0.705559
2019-11-06 11:35:11,128 train 400 2.243221e-02 -0.706650
2019-11-06 11:35:20,953 train 450 2.240133e-02 -0.680430
2019-11-06 11:35:30,786 train 500 2.245612e-02 -0.680578
2019-11-06 11:35:40,616 train 550 2.243575e-02 -0.665756
2019-11-06 11:35:50,456 train 600 2.243867e-02 -0.665808
2019-11-06 11:36:00,295 train 650 2.243757e-02 -0.671710
2019-11-06 11:36:10,135 train 700 2.242650e-02 -0.651429
2019-11-06 11:36:19,977 train 750 2.243096e-02 -0.690684
2019-11-06 11:36:29,826 train 800 2.243339e-02 -0.684472
2019-11-06 11:36:39,662 train 850 2.245274e-02 -0.696113
2019-11-06 11:36:42,624 training loss; R2: 2.247185e-02 -0.700553
2019-11-06 11:36:43,349 valid 000 2.206730e-02 -0.859351
2019-11-06 11:36:52,743 valid 050 2.063987e-02 -0.983577
2019-11-06 11:37:01,189 validation loss; R2: 2.073814e-02 -0.799283
2019-11-06 11:37:01,273 epoch 36 lr 1.000000e-05
2019-11-06 11:37:02,045 train 000 2.286168e-02 -0.169708
2019-11-06 11:37:12,182 train 050 2.180137e-02 -0.585783
2019-11-06 11:37:22,352 train 100 2.203985e-02 -0.598934
2019-11-06 11:37:32,511 train 150 2.218785e-02 -0.619691
2019-11-06 11:37:42,705 train 200 2.233774e-02 -0.633932
2019-11-06 11:37:52,889 train 250 2.238823e-02 -0.666432
2019-11-06 11:38:03,089 train 300 2.239799e-02 -0.683422
2019-11-06 11:38:13,273 train 350 2.238635e-02 -0.672026
2019-11-06 11:38:23,453 train 400 2.235301e-02 -0.651544
2019-11-06 11:38:33,618 train 450 2.232495e-02 -0.635240
2019-11-06 11:38:43,784 train 500 2.234164e-02 -0.619309
2019-11-06 11:38:53,962 train 550 2.237183e-02 -0.632434
2019-11-06 11:39:04,137 train 600 2.234080e-02 -0.643024
2019-11-06 11:39:14,316 train 650 2.231429e-02 -0.668038
2019-11-06 11:39:24,511 train 700 2.230290e-02 -0.649861
2019-11-06 11:39:34,694 train 750 2.227202e-02 -0.647880
2019-11-06 11:39:44,871 train 800 2.229789e-02 -0.636821
2019-11-06 11:39:55,049 train 850 2.233501e-02 -0.636186
2019-11-06 11:39:58,088 training loss; R2: 2.234025e-02 -0.631669
2019-11-06 11:39:58,767 valid 000 1.922984e-02 -0.341810
2019-11-06 11:40:08,178 valid 050 2.029686e-02 -0.820194
2019-11-06 11:40:16,668 validation loss; R2: 2.022079e-02 -0.735834
2019-11-06 11:40:16,739 epoch 37 lr 1.000000e-05
2019-11-06 11:40:17,542 train 000 2.492971e-02 0.005607
2019-11-06 11:40:27,661 train 050 2.216676e-02 -0.631207
2019-11-06 11:40:37,792 train 100 2.249668e-02 -0.692351
2019-11-06 11:40:47,929 train 150 2.245448e-02 -0.674015
2019-11-06 11:40:58,087 train 200 2.236042e-02 -0.670415
2019-11-06 11:41:08,245 train 250 2.228715e-02 -0.713756
2019-11-06 11:41:18,402 train 300 2.234573e-02 -0.691328
2019-11-06 11:41:28,564 train 350 2.237541e-02 -0.682421
2019-11-06 11:41:38,711 train 400 2.240114e-02 -0.680173
2019-11-06 11:41:48,869 train 450 2.235449e-02 -1.101749
2019-11-06 11:41:59,032 train 500 2.237757e-02 -1.070384
2019-11-06 11:42:09,183 train 550 2.234606e-02 -1.072987
2019-11-06 11:42:19,360 train 600 2.235353e-02 -1.034872
2019-11-06 11:42:29,527 train 650 2.238813e-02 -0.994721
2019-11-06 11:42:39,573 train 700 2.236651e-02 -0.959124
2019-11-06 11:42:49,365 train 750 2.234905e-02 -0.930453
2019-11-06 11:42:59,161 train 800 2.233149e-02 -0.910115
2019-11-06 11:43:08,960 train 850 2.233304e-02 -0.905529
2019-11-06 11:43:11,893 training loss; R2: 2.234015e-02 -0.899952
2019-11-06 11:43:12,544 valid 000 2.029276e-02 -0.956173
2019-11-06 11:43:22,048 valid 050 2.038670e-02 -0.707849
2019-11-06 11:43:30,511 validation loss; R2: 2.045706e-02 -0.684610
2019-11-06 11:43:30,592 epoch 38 lr 1.000000e-05
2019-11-06 11:43:31,366 train 000 2.176708e-02 -0.146680
2019-11-06 11:43:41,123 train 050 2.246541e-02 -0.507558
2019-11-06 11:43:50,887 train 100 2.235671e-02 -0.640605
2019-11-06 11:44:00,670 train 150 2.234690e-02 -0.641873
2019-11-06 11:44:10,497 train 200 2.221347e-02 -0.684314
2019-11-06 11:44:20,317 train 250 2.230755e-02 -0.673162
2019-11-06 11:44:30,142 train 300 2.231470e-02 -0.658992
2019-11-06 11:44:39,941 train 350 2.231155e-02 -0.669948
2019-11-06 11:44:49,723 train 400 2.230293e-02 -0.680756
2019-11-06 11:44:59,506 train 450 2.228498e-02 -0.683414
2019-11-06 11:45:09,300 train 500 2.224544e-02 -0.666690
2019-11-06 11:45:19,107 train 550 2.227958e-02 -0.652990
2019-11-06 11:45:28,932 train 600 2.223070e-02 -0.651074
2019-11-06 11:45:38,743 train 650 2.221597e-02 -0.641539
2019-11-06 11:45:48,548 train 700 2.223319e-02 -0.642470
2019-11-06 11:45:58,368 train 750 2.220959e-02 -0.660993
2019-11-06 11:46:08,189 train 800 2.219258e-02 -0.656587
2019-11-06 11:46:18,000 train 850 2.219420e-02 -0.669075
2019-11-06 11:46:20,937 training loss; R2: 2.219824e-02 -0.666521
2019-11-06 11:46:21,605 valid 000 2.110292e-02 -1.102588
2019-11-06 11:46:31,041 valid 050 2.020118e-02 -0.549006
2019-11-06 11:46:39,413 validation loss; R2: 2.002336e-02 -0.618472
2019-11-06 11:46:39,480 epoch 39 lr 1.000000e-05
2019-11-06 11:46:40,264 train 000 2.136375e-02 -0.892998
2019-11-06 11:46:50,020 train 050 2.221846e-02 -0.545119
2019-11-06 11:46:59,819 train 100 2.215370e-02 -0.577070
2019-11-06 11:47:09,608 train 150 2.213733e-02 -0.584787
2019-11-06 11:47:19,400 train 200 2.205147e-02 -0.559409
2019-11-06 11:47:29,207 train 250 2.203798e-02 -0.554420
2019-11-06 11:47:39,012 train 300 2.198528e-02 -0.555898
2019-11-06 11:47:48,815 train 350 2.197930e-02 -0.583250
2019-11-06 11:47:58,635 train 400 2.198238e-02 -0.576730
2019-11-06 11:48:08,449 train 450 2.199504e-02 -0.568927
2019-11-06 11:48:18,256 train 500 2.200350e-02 -0.580717
2019-11-06 11:48:28,074 train 550 2.198121e-02 -0.587919
2019-11-06 11:48:37,880 train 600 2.201674e-02 -0.584024
2019-11-06 11:48:47,693 train 650 2.200154e-02 -0.603517
2019-11-06 11:48:57,514 train 700 2.200986e-02 -0.609826
2019-11-06 11:49:07,326 train 750 2.203833e-02 -0.601195
2019-11-06 11:49:17,140 train 800 2.203675e-02 -0.607371
2019-11-06 11:49:26,950 train 850 2.204592e-02 -0.609728
2019-11-06 11:49:29,914 training loss; R2: 2.205188e-02 -0.606191
2019-11-06 11:49:30,518 valid 000 1.934609e-02 -0.548290
2019-11-06 11:49:40,034 valid 050 1.987791e-02 -0.644006
2019-11-06 11:49:48,437 validation loss; R2: 1.989733e-02 -0.630959
2019-11-06 11:49:48,513 epoch 40 lr 1.000000e-05
2019-11-06 11:49:49,305 train 000 1.995337e-02 -1.355456
2019-11-06 11:49:59,058 train 050 2.169879e-02 -0.603823
2019-11-06 11:50:08,822 train 100 2.187727e-02 -0.717678
2019-11-06 11:50:18,629 train 150 2.190598e-02 -0.765282
2019-11-06 11:50:28,458 train 200 2.200626e-02 -0.784315
2019-11-06 11:50:38,278 train 250 2.196540e-02 -0.747677
2019-11-06 11:50:48,082 train 300 2.198750e-02 -0.792822
2019-11-06 11:50:57,877 train 350 2.200192e-02 -0.741485
2019-11-06 11:51:07,682 train 400 2.203436e-02 -0.829278
2019-11-06 11:51:17,494 train 450 2.200900e-02 -0.815989
2019-11-06 11:51:27,328 train 500 2.199226e-02 -0.791615
2019-11-06 11:51:37,149 train 550 2.196029e-02 -0.770981
2019-11-06 11:51:47,001 train 600 2.199100e-02 -0.764258
2019-11-06 11:51:56,850 train 650 2.197279e-02 -0.743745
2019-11-06 11:52:06,700 train 700 2.196794e-02 -0.756704
2019-11-06 11:52:16,558 train 750 2.196056e-02 -0.741608
2019-11-06 11:52:26,372 train 800 2.196804e-02 -0.726954
2019-11-06 11:52:36,184 train 850 2.192975e-02 -0.714839
2019-11-06 11:52:39,121 training loss; R2: 2.193565e-02 -0.711353
2019-11-06 11:52:39,819 valid 000 1.776993e-02 -0.113844
2019-11-06 11:52:49,243 valid 050 2.023821e-02 -0.719639
2019-11-06 11:52:57,613 validation loss; R2: 2.016666e-02 -0.728141
2019-11-06 11:52:57,679 epoch 41 lr 1.000000e-05
2019-11-06 11:52:58,465 train 000 2.047429e-02 -0.233293
2019-11-06 11:53:08,222 train 050 2.181434e-02 -0.742590
2019-11-06 11:53:17,995 train 100 2.192631e-02 -0.999151
2019-11-06 11:53:27,804 train 150 2.181114e-02 -0.856320
2019-11-06 11:53:37,613 train 200 2.189059e-02 -0.842381
2019-11-06 11:53:47,424 train 250 2.196670e-02 -0.783442
2019-11-06 11:53:57,232 train 300 2.186118e-02 -0.750375
2019-11-06 11:54:07,053 train 350 2.186074e-02 -0.760941
2019-11-06 11:54:16,865 train 400 2.189492e-02 -0.726949
2019-11-06 11:54:26,671 train 450 2.189263e-02 -0.728941
2019-11-06 11:54:36,478 train 500 2.192922e-02 -0.739728
2019-11-06 11:54:46,293 train 550 2.192077e-02 -0.719586
2019-11-06 11:54:56,102 train 600 2.189665e-02 -0.708109
2019-11-06 11:55:05,915 train 650 2.193271e-02 -0.707859
2019-11-06 11:55:15,750 train 700 2.195267e-02 -0.704413
2019-11-06 11:55:25,569 train 750 2.195921e-02 -0.713022
2019-11-06 11:55:35,392 train 800 2.192366e-02 -0.723034
2019-11-06 11:55:45,203 train 850 2.190050e-02 -0.752112
2019-11-06 11:55:48,154 training loss; R2: 2.189782e-02 -0.768833
2019-11-06 11:55:48,836 valid 000 2.425234e-02 -0.140732
2019-11-06 11:55:58,226 valid 050 1.939141e-02 -0.541494
2019-11-06 11:56:06,744 validation loss; R2: 1.937907e-02 -0.555544
2019-11-06 11:56:06,823 epoch 42 lr 1.000000e-05
2019-11-06 11:56:07,630 train 000 2.023206e-02 -0.779671
2019-11-06 11:56:17,374 train 050 2.236977e-02 -0.535956
2019-11-06 11:56:27,136 train 100 2.206629e-02 -0.546170
2019-11-06 11:56:36,938 train 150 2.208902e-02 -0.604874
2019-11-06 11:56:46,746 train 200 2.207800e-02 -0.593167
2019-11-06 11:56:56,548 train 250 2.207868e-02 -0.620428
2019-11-06 11:57:06,357 train 300 2.209018e-02 -0.610227
2019-11-06 11:57:16,169 train 350 2.208319e-02 -0.615273
2019-11-06 11:57:25,981 train 400 2.205095e-02 -0.624361
2019-11-06 11:57:35,802 train 450 2.203215e-02 -0.620419
2019-11-06 11:57:45,610 train 500 2.200553e-02 -0.605980
2019-11-06 11:57:55,396 train 550 2.195615e-02 -0.624320
2019-11-06 11:58:05,197 train 600 2.194658e-02 -0.632977
2019-11-06 11:58:15,024 train 650 2.193500e-02 -0.625564
2019-11-06 11:58:24,849 train 700 2.191628e-02 -0.628268
2019-11-06 11:58:34,671 train 750 2.192734e-02 -0.626566
2019-11-06 11:58:44,502 train 800 2.189012e-02 -0.632094
2019-11-06 11:58:54,336 train 850 2.187590e-02 -0.626055
2019-11-06 11:58:57,268 training loss; R2: 2.188248e-02 -0.624634
2019-11-06 11:58:57,907 valid 000 1.831925e-02 -0.470662
2019-11-06 11:59:07,339 valid 050 1.913534e-02 -0.665098
2019-11-06 11:59:15,719 validation loss; R2: 1.927283e-02 -0.646543
2019-11-06 11:59:15,789 epoch 43 lr 1.000000e-05
2019-11-06 11:59:16,560 train 000 2.529757e-02 -0.866298
2019-11-06 11:59:26,331 train 050 2.174853e-02 -0.671362
2019-11-06 11:59:36,127 train 100 2.176300e-02 -0.611614
2019-11-06 11:59:45,941 train 150 2.168523e-02 -0.597608
2019-11-06 11:59:55,747 train 200 2.171597e-02 -0.594253
2019-11-06 12:00:05,564 train 250 2.176556e-02 -0.595941
2019-11-06 12:00:15,375 train 300 2.176824e-02 -0.584545
2019-11-06 12:00:25,182 train 350 2.178231e-02 -0.619504
2019-11-06 12:00:34,978 train 400 2.175268e-02 -0.618042
2019-11-06 12:00:44,765 train 450 2.175905e-02 -0.634332
2019-11-06 12:00:54,559 train 500 2.180814e-02 -0.628646
2019-11-06 12:01:04,355 train 550 2.177206e-02 -0.627312
2019-11-06 12:01:14,153 train 600 2.176992e-02 -0.637076
2019-11-06 12:01:23,944 train 650 2.179130e-02 -0.636559
2019-11-06 12:01:33,739 train 700 2.178206e-02 -0.644861
2019-11-06 12:01:43,543 train 750 2.178947e-02 -0.651115
2019-11-06 12:01:53,347 train 800 2.178361e-02 -0.645683
2019-11-06 12:02:03,139 train 850 2.177018e-02 -2.303383
2019-11-06 12:02:06,071 training loss; R2: 2.177690e-02 -2.282405
2019-11-06 12:02:06,766 valid 000 2.025734e-02 -0.644814
2019-11-06 12:02:16,131 valid 050 1.979804e-02 -1.132586
2019-11-06 12:02:24,653 validation loss; R2: 1.960976e-02 -0.870620
2019-11-06 12:02:24,721 epoch 44 lr 1.000000e-05
2019-11-06 12:02:25,510 train 000 2.429742e-02 -0.091514
2019-11-06 12:02:35,247 train 050 2.163915e-02 -0.606950
2019-11-06 12:02:44,980 train 100 2.145650e-02 -0.649436
2019-11-06 12:02:54,763 train 150 2.154597e-02 -0.599992
2019-11-06 12:03:04,561 train 200 2.149774e-02 -0.587135
2019-11-06 12:03:14,358 train 250 2.150194e-02 -0.796887
2019-11-06 12:03:24,151 train 300 2.152221e-02 -0.742148
2019-11-06 12:03:33,947 train 350 2.148880e-02 -0.755930
2019-11-06 12:03:43,750 train 400 2.153808e-02 -0.745506
2019-11-06 12:03:53,555 train 450 2.157237e-02 -0.715796
2019-11-06 12:04:03,367 train 500 2.161276e-02 -0.709554
2019-11-06 12:04:13,173 train 550 2.160934e-02 -0.706561
2019-11-06 12:04:22,981 train 600 2.163945e-02 -0.697133
2019-11-06 12:04:32,779 train 650 2.162249e-02 -0.709912
2019-11-06 12:04:42,574 train 700 2.167125e-02 -0.723128
2019-11-06 12:04:52,387 train 750 2.168872e-02 -0.732483
2019-11-06 12:05:02,198 train 800 2.168602e-02 -0.727892
2019-11-06 12:05:12,012 train 850 2.169424e-02 -0.744583
2019-11-06 12:05:14,945 training loss; R2: 2.170087e-02 -0.740730
2019-11-06 12:05:15,643 valid 000 1.930786e-02 -0.763917
2019-11-06 12:05:25,050 valid 050 1.909174e-02 -0.622376
2019-11-06 12:05:33,412 validation loss; R2: 1.908004e-02 -0.607370
2019-11-06 12:05:33,479 epoch 45 lr 1.000000e-05
2019-11-06 12:05:34,248 train 000 2.104657e-02 -0.322219
2019-11-06 12:05:43,991 train 050 2.183618e-02 -0.684140
2019-11-06 12:05:53,752 train 100 2.170711e-02 -0.668045
2019-11-06 12:06:03,514 train 150 2.172885e-02 -0.699233
2019-11-06 12:06:13,304 train 200 2.175441e-02 -0.801555
2019-11-06 12:06:23,056 train 250 2.171329e-02 -0.779411
2019-11-06 12:06:32,846 train 300 2.173427e-02 -0.764126
2019-11-06 12:06:42,602 train 350 2.164932e-02 -0.775471
2019-11-06 12:06:52,382 train 400 2.161612e-02 -0.769483
2019-11-06 12:07:02,207 train 450 2.162084e-02 -0.748765
2019-11-06 12:07:12,028 train 500 2.156995e-02 -0.741649
2019-11-06 12:07:21,840 train 550 2.156142e-02 -0.716044
2019-11-06 12:07:31,656 train 600 2.157477e-02 -0.708487
2019-11-06 12:07:41,483 train 650 2.158803e-02 -0.695812
2019-11-06 12:07:51,291 train 700 2.159178e-02 -0.689395
2019-11-06 12:08:01,049 train 750 2.158368e-02 -0.683495
2019-11-06 12:08:10,841 train 800 2.156676e-02 -0.686062
2019-11-06 12:08:20,647 train 850 2.158895e-02 -0.694651
2019-11-06 12:08:23,578 training loss; R2: 2.157757e-02 -0.690760
2019-11-06 12:08:24,215 valid 000 1.677516e-02 -0.280631
2019-11-06 12:08:33,739 valid 050 1.939153e-02 -0.771294
2019-11-06 12:08:42,103 validation loss; R2: 1.933690e-02 -0.806990
2019-11-06 12:08:42,169 epoch 46 lr 1.000000e-05
2019-11-06 12:08:42,939 train 000 2.580177e-02 -0.558843
2019-11-06 12:08:52,730 train 050 2.158522e-02 -0.879108
2019-11-06 12:09:02,534 train 100 2.163857e-02 -0.785700
2019-11-06 12:09:12,362 train 150 2.169364e-02 -0.695504
2019-11-06 12:09:22,177 train 200 2.163152e-02 -0.619990
2019-11-06 12:09:31,995 train 250 2.170279e-02 -0.608711
2019-11-06 12:09:41,824 train 300 2.166959e-02 -0.624241
2019-11-06 12:09:51,646 train 350 2.160654e-02 -0.642462
2019-11-06 12:10:01,484 train 400 2.163245e-02 -0.644234
2019-11-06 12:10:11,339 train 450 2.162133e-02 -0.634914
2019-11-06 12:10:21,185 train 500 2.164082e-02 -0.652764
2019-11-06 12:10:31,021 train 550 2.161680e-02 -0.669135
2019-11-06 12:10:40,828 train 600 2.160233e-02 -0.668166
2019-11-06 12:10:50,643 train 650 2.160871e-02 -0.653088
2019-11-06 12:11:00,464 train 700 2.161343e-02 -0.648768
2019-11-06 12:11:10,292 train 750 2.162749e-02 -0.635804
2019-11-06 12:11:20,132 train 800 2.162099e-02 -0.627338
2019-11-06 12:11:29,979 train 850 2.158847e-02 -0.628757
2019-11-06 12:11:32,920 training loss; R2: 2.159408e-02 -0.626678
2019-11-06 12:11:33,551 valid 000 1.684993e-02 -0.508593
2019-11-06 12:11:43,034 valid 050 1.925963e-02 -0.802945
2019-11-06 12:11:51,441 validation loss; R2: 1.932147e-02 -0.794473
2019-11-06 12:11:51,510 epoch 47 lr 1.000000e-05
2019-11-06 12:11:52,268 train 000 2.331384e-02 -0.244914
2019-11-06 12:12:02,055 train 050 2.184275e-02 -0.518724
2019-11-06 12:12:11,864 train 100 2.185573e-02 -0.650969
2019-11-06 12:12:21,675 train 150 2.180035e-02 -0.618922
2019-11-06 12:12:31,483 train 200 2.173278e-02 -0.636866
2019-11-06 12:12:41,291 train 250 2.164412e-02 -0.665356
2019-11-06 12:12:51,096 train 300 2.163199e-02 -0.636764
2019-11-06 12:13:00,904 train 350 2.154909e-02 -0.641786
2019-11-06 12:13:10,716 train 400 2.153254e-02 -0.618282
2019-11-06 12:13:20,523 train 450 2.158522e-02 -0.620930
2019-11-06 12:13:30,332 train 500 2.158945e-02 -0.608526
2019-11-06 12:13:40,148 train 550 2.161642e-02 -0.609290
2019-11-06 12:13:49,951 train 600 2.160617e-02 -0.610257
2019-11-06 12:13:59,755 train 650 2.159088e-02 -0.622938
2019-11-06 12:14:09,578 train 700 2.155814e-02 -0.624373
2019-11-06 12:14:19,402 train 750 2.155585e-02 -0.626378
2019-11-06 12:14:29,224 train 800 2.156055e-02 -0.641763
2019-11-06 12:14:39,040 train 850 2.156334e-02 -0.636777
2019-11-06 12:14:41,981 training loss; R2: 2.155346e-02 -0.635312
2019-11-06 12:14:42,667 valid 000 2.062291e-02 -0.409169
2019-11-06 12:14:52,106 valid 050 1.928706e-02 -0.783225
2019-11-06 12:15:00,478 validation loss; R2: 1.936224e-02 -0.735285
2019-11-06 12:15:00,539 epoch 48 lr 1.000000e-05
2019-11-06 12:15:01,313 train 000 2.083243e-02 -0.297180
2019-11-06 12:15:11,087 train 050 2.160173e-02 -0.703345
2019-11-06 12:15:20,899 train 100 2.129374e-02 -0.734024
2019-11-06 12:15:30,698 train 150 2.124782e-02 -0.690577
2019-11-06 12:15:40,503 train 200 2.137097e-02 -0.656800
2019-11-06 12:15:50,350 train 250 2.140158e-02 -0.640597
2019-11-06 12:16:00,521 train 300 2.136819e-02 -0.663754
2019-11-06 12:16:10,682 train 350 2.134452e-02 -0.626605
2019-11-06 12:16:20,859 train 400 2.135713e-02 -0.632149
2019-11-06 12:16:31,024 train 450 2.144461e-02 -0.656344
2019-11-06 12:16:41,192 train 500 2.147174e-02 -0.669777
2019-11-06 12:16:51,371 train 550 2.144051e-02 -0.699245
2019-11-06 12:17:01,555 train 600 2.142763e-02 -0.703049
2019-11-06 12:17:11,727 train 650 2.143140e-02 -0.702295
2019-11-06 12:17:21,906 train 700 2.144075e-02 -0.718954
2019-11-06 12:17:32,078 train 750 2.145728e-02 -0.716033
2019-11-06 12:17:42,262 train 800 2.145524e-02 -0.722522
2019-11-06 12:17:52,448 train 850 2.146571e-02 -0.720796
2019-11-06 12:17:55,487 training loss; R2: 2.145807e-02 -0.719745
2019-11-06 12:17:56,123 valid 000 1.957618e-02 -2.938744
2019-11-06 12:18:05,597 valid 050 1.949828e-02 -1.111325
2019-11-06 12:18:13,931 validation loss; R2: 1.967544e-02 -0.877652
2019-11-06 12:18:14,000 epoch 49 lr 1.000000e-05
2019-11-06 12:18:14,849 train 000 2.003363e-02 -0.153975
2019-11-06 12:18:25,029 train 050 2.121917e-02 -1.005270
2019-11-06 12:18:35,221 train 100 2.119451e-02 -0.914916
2019-11-06 12:18:45,414 train 150 2.137014e-02 -0.815770
2019-11-06 12:18:55,603 train 200 2.137181e-02 -0.814925
2019-11-06 12:19:05,796 train 250 2.136005e-02 -0.754811
2019-11-06 12:19:15,989 train 300 2.147557e-02 -0.747908
2019-11-06 12:19:26,187 train 350 2.146736e-02 -0.709136
2019-11-06 12:19:36,364 train 400 2.145360e-02 -0.688341
2019-11-06 12:19:46,549 train 450 2.142416e-02 -0.686825
2019-11-06 12:19:56,729 train 500 2.142353e-02 -0.666321
2019-11-06 12:20:06,921 train 550 2.146483e-02 -0.647831
2019-11-06 12:20:17,114 train 600 2.141381e-02 -0.666688
2019-11-06 12:20:27,288 train 650 2.143456e-02 -0.670445
2019-11-06 12:20:37,458 train 700 2.140310e-02 -0.669640
2019-11-06 12:20:47,608 train 750 2.138265e-02 -0.657593
2019-11-06 12:20:57,780 train 800 2.137115e-02 -0.662456
2019-11-06 12:21:07,970 train 850 2.139613e-02 -0.648963
2019-11-06 12:21:11,009 training loss; R2: 2.137974e-02 -0.643496
2019-11-06 12:21:11,688 valid 000 2.075028e-02 -0.483183
2019-11-06 12:21:21,135 valid 050 1.929052e-02 -0.721411
2019-11-06 12:21:29,610 validation loss; R2: 1.953060e-02 -0.682993
2019-11-06 12:21:29,687 epoch 50 lr 1.000000e-05
2019-11-06 12:21:30,432 train 000 2.108379e-02 -0.488166
2019-11-06 12:21:40,175 train 050 2.117256e-02 -0.740303
2019-11-06 12:21:49,956 train 100 2.120174e-02 -0.662986
2019-11-06 12:21:59,741 train 150 2.123235e-02 -0.652717
2019-11-06 12:22:09,541 train 200 2.132166e-02 -0.602933
2019-11-06 12:22:19,330 train 250 2.128998e-02 -0.605574
2019-11-06 12:22:29,125 train 300 2.128001e-02 -0.601527
2019-11-06 12:22:38,909 train 350 2.128618e-02 -0.617788
2019-11-06 12:22:48,705 train 400 2.130098e-02 -0.673173
2019-11-06 12:22:58,499 train 450 2.127555e-02 -0.854624
2019-11-06 12:23:08,312 train 500 2.127377e-02 -0.818489
2019-11-06 12:23:18,100 train 550 2.130580e-02 -0.803896
2019-11-06 12:23:27,904 train 600 2.129854e-02 -0.775934
2019-11-06 12:23:37,695 train 650 2.127687e-02 -0.777912
2019-11-06 12:23:47,498 train 700 2.129399e-02 -0.768532
2019-11-06 12:23:57,295 train 750 2.131595e-02 -0.761987
2019-11-06 12:24:07,095 train 800 2.130597e-02 -0.757578
2019-11-06 12:24:16,899 train 850 2.131784e-02 -0.744816
2019-11-06 12:24:19,831 training loss; R2: 2.131024e-02 -0.764647
2019-11-06 12:24:20,532 valid 000 1.897740e-02 -0.746368
2019-11-06 12:24:29,962 valid 050 1.994986e-02 -1.248774
2019-11-06 12:24:38,290 validation loss; R2: 1.999337e-02 -0.971652
2019-11-06 12:24:38,357 epoch 51 lr 1.000000e-05
2019-11-06 12:24:39,085 train 000 1.999898e-02 -0.278517
2019-11-06 12:24:48,879 train 050 2.114083e-02 -0.643072
2019-11-06 12:24:58,696 train 100 2.107693e-02 -0.562871
2019-11-06 12:25:08,516 train 150 2.127519e-02 -0.587293
2019-11-06 12:25:18,331 train 200 2.125304e-02 -0.614554
2019-11-06 12:25:28,148 train 250 2.125950e-02 -0.624705
2019-11-06 12:25:37,985 train 300 2.125127e-02 -0.626674
2019-11-06 12:25:47,809 train 350 2.131330e-02 -0.627602
2019-11-06 12:25:57,630 train 400 2.127228e-02 -0.645063
2019-11-06 12:26:07,465 train 450 2.124146e-02 -0.650996
2019-11-06 12:26:17,285 train 500 2.129008e-02 -0.648734
2019-11-06 12:26:27,112 train 550 2.130405e-02 -0.640522
2019-11-06 12:26:36,925 train 600 2.130014e-02 -0.639955
2019-11-06 12:26:46,744 train 650 2.129683e-02 -0.634408
2019-11-06 12:26:56,561 train 700 2.131777e-02 -0.633560
2019-11-06 12:27:06,372 train 750 2.131127e-02 -0.627506
2019-11-06 12:27:16,217 train 800 2.131612e-02 -0.627138
2019-11-06 12:27:26,040 train 850 2.130949e-02 -0.664070
2019-11-06 12:27:28,979 training loss; R2: 2.132634e-02 -0.664729
2019-11-06 12:27:29,622 valid 000 2.382980e-02 -0.064733
2019-11-06 12:27:39,088 valid 050 2.024357e-02 -0.730002
2019-11-06 12:27:47,433 validation loss; R2: 2.037476e-02 -0.735816
2019-11-06 12:27:47,502 epoch 52 lr 1.000000e-05
2019-11-06 12:27:48,280 train 000 2.279324e-02 -0.189041
2019-11-06 12:27:58,050 train 050 2.144992e-02 -0.428203
2019-11-06 12:28:07,836 train 100 2.158983e-02 -0.487071
2019-11-06 12:28:17,625 train 150 2.149224e-02 -0.555274
2019-11-06 12:28:27,407 train 200 2.143590e-02 -0.541309
2019-11-06 12:28:37,194 train 250 2.143772e-02 -0.608639
2019-11-06 12:28:46,988 train 300 2.133530e-02 -0.588962
2019-11-06 12:28:56,800 train 350 2.133260e-02 -0.602864
2019-11-06 12:29:06,616 train 400 2.129946e-02 -0.594901
2019-11-06 12:29:16,434 train 450 2.124925e-02 -0.587934
2019-11-06 12:29:26,257 train 500 2.126311e-02 -0.594272
2019-11-06 12:29:36,074 train 550 2.127620e-02 -0.596910
2019-11-06 12:29:45,912 train 600 2.124356e-02 -0.605582
2019-11-06 12:29:55,743 train 650 2.125511e-02 -0.604837
2019-11-06 12:30:05,586 train 700 2.125651e-02 -0.609800
2019-11-06 12:30:15,409 train 750 2.127942e-02 -0.621778
2019-11-06 12:30:25,248 train 800 2.125392e-02 -0.618633
2019-11-06 12:30:35,095 train 850 2.124964e-02 -0.619744
2019-11-06 12:30:38,038 training loss; R2: 2.124540e-02 -0.617400
2019-11-06 12:30:38,723 valid 000 2.177331e-02 -1.284668
2019-11-06 12:30:48,129 valid 050 2.038709e-02 -0.636910
2019-11-06 12:30:56,518 validation loss; R2: 2.045314e-02 -0.738166
2019-11-06 12:30:56,600 epoch 53 lr 1.000000e-05
2019-11-06 12:30:57,396 train 000 2.176214e-02 -0.173620
2019-11-06 12:31:07,197 train 050 2.147515e-02 -0.862434
2019-11-06 12:31:17,022 train 100 2.126843e-02 -0.737816
2019-11-06 12:31:26,832 train 150 2.133954e-02 -0.640321
2019-11-06 12:31:36,663 train 200 2.143179e-02 -0.682568
2019-11-06 12:31:46,497 train 250 2.134585e-02 -0.683974
2019-11-06 12:31:56,313 train 300 2.138329e-02 -0.687568
2019-11-06 12:32:06,128 train 350 2.131102e-02 -0.675014
2019-11-06 12:32:15,945 train 400 2.136653e-02 -0.677424
2019-11-06 12:32:25,760 train 450 2.138201e-02 -0.685383
2019-11-06 12:32:35,578 train 500 2.137522e-02 -0.715204
2019-11-06 12:32:45,401 train 550 2.134911e-02 -0.714768
2019-11-06 12:32:55,232 train 600 2.131909e-02 -0.689545
2019-11-06 12:33:05,072 train 650 2.132306e-02 -0.690478
2019-11-06 12:33:14,924 train 700 2.132467e-02 -0.696924
2019-11-06 12:33:24,774 train 750 2.126158e-02 -0.687360
2019-11-06 12:33:34,625 train 800 2.127878e-02 -0.699890
2019-11-06 12:33:44,481 train 850 2.124209e-02 -0.684731
2019-11-06 12:33:47,419 training loss; R2: 2.126727e-02 -0.678679
2019-11-06 12:33:48,109 valid 000 2.274932e-02 -0.086426
2019-11-06 12:33:57,510 valid 050 1.950151e-02 -0.592787
2019-11-06 12:34:05,979 validation loss; R2: 1.956772e-02 -0.669224
2019-11-06 12:34:06,045 epoch 54 lr 1.000000e-05
2019-11-06 12:34:06,791 train 000 2.327971e-02 -0.654086
2019-11-06 12:34:16,514 train 050 2.094891e-02 -0.686201
2019-11-06 12:34:26,243 train 100 2.104481e-02 -0.622766
2019-11-06 12:34:35,995 train 150 2.110529e-02 -0.621368
2019-11-06 12:34:45,754 train 200 2.107374e-02 -0.614784
2019-11-06 12:34:55,517 train 250 2.107956e-02 -0.597304
2019-11-06 12:35:05,268 train 300 2.116556e-02 -0.619596
2019-11-06 12:35:15,058 train 350 2.114012e-02 -0.619908
2019-11-06 12:35:24,849 train 400 2.113757e-02 -0.614927
2019-11-06 12:35:34,643 train 450 2.114498e-02 -0.625474
2019-11-06 12:35:44,440 train 500 2.117485e-02 -0.622837
2019-11-06 12:35:54,241 train 550 2.120204e-02 -0.642588
2019-11-06 12:36:04,071 train 600 2.119683e-02 -0.636636
2019-11-06 12:36:13,885 train 650 2.118825e-02 -0.640445
2019-11-06 12:36:23,698 train 700 2.119793e-02 -0.650663
2019-11-06 12:36:33,508 train 750 2.119842e-02 -0.646171
2019-11-06 12:36:43,326 train 800 2.118135e-02 -0.642432
2019-11-06 12:36:53,161 train 850 2.120995e-02 -0.644565
2019-11-06 12:36:56,097 training loss; R2: 2.120851e-02 -0.645510
2019-11-06 12:36:56,715 valid 000 1.583510e-02 -2.577408
2019-11-06 12:37:06,113 valid 050 1.903602e-02 -0.935699
2019-11-06 12:37:14,588 validation loss; R2: 1.924536e-02 -0.752595
2019-11-06 12:37:14,657 epoch 55 lr 1.000000e-05
2019-11-06 12:37:15,470 train 000 1.961870e-02 -0.909413
2019-11-06 12:37:25,235 train 050 2.105438e-02 -0.719950
2019-11-06 12:37:35,014 train 100 2.118821e-02 -0.586099
2019-11-06 12:37:44,811 train 150 2.111747e-02 -0.697757
2019-11-06 12:37:54,609 train 200 2.123443e-02 -0.700574
2019-11-06 12:38:04,404 train 250 2.114102e-02 -0.731411
2019-11-06 12:38:14,197 train 300 2.113151e-02 -0.835691
2019-11-06 12:38:23,989 train 350 2.114457e-02 -0.816295
2019-11-06 12:38:33,808 train 400 2.111390e-02 -0.775264
2019-11-06 12:38:43,635 train 450 2.113534e-02 -0.757431
2019-11-06 12:38:53,811 train 500 2.111143e-02 -0.770970
2019-11-06 12:39:04,046 train 550 2.108781e-02 -0.749981
2019-11-06 12:39:14,279 train 600 2.109386e-02 -0.736350
2019-11-06 12:39:24,520 train 650 2.108864e-02 -0.721950
2019-11-06 12:39:34,766 train 700 2.109513e-02 -0.698198
2019-11-06 12:39:45,012 train 750 2.109516e-02 -0.686768
2019-11-06 12:39:55,243 train 800 2.112540e-02 -0.665943
2019-11-06 12:40:05,477 train 850 2.109838e-02 -0.663208
2019-11-06 12:40:08,539 training loss; R2: 2.108981e-02 -0.661876
2019-11-06 12:40:09,257 valid 000 1.802157e-02 -0.462593
2019-11-06 12:40:18,660 valid 050 2.027380e-02 -0.798157
2019-11-06 12:40:27,046 validation loss; R2: 2.032220e-02 -0.749619
2019-11-06 12:40:27,115 epoch 56 lr 1.000000e-05
2019-11-06 12:40:27,931 train 000 2.800338e-02 -1.385969
2019-11-06 12:40:38,102 train 050 2.105842e-02 -0.585873
2019-11-06 12:40:48,289 train 100 2.117671e-02 -0.670646
2019-11-06 12:40:58,487 train 150 2.113999e-02 -0.645777
2019-11-06 12:41:08,694 train 200 2.110292e-02 -0.716036
2019-11-06 12:41:18,910 train 250 2.107618e-02 -0.719144
2019-11-06 12:41:29,129 train 300 2.106107e-02 -0.725110
2019-11-06 12:41:39,333 train 350 2.102020e-02 -0.687725
2019-11-06 12:41:49,499 train 400 2.107895e-02 -0.690710
2019-11-06 12:41:59,337 train 450 2.108037e-02 -0.699507
2019-11-06 12:42:09,198 train 500 2.109935e-02 -0.705552
2019-11-06 12:42:19,047 train 550 2.111280e-02 -0.715738
2019-11-06 12:42:28,908 train 600 2.109661e-02 -0.706767
2019-11-06 12:42:38,770 train 650 2.106803e-02 -0.711003
2019-11-06 12:42:48,637 train 700 2.109331e-02 -0.717048
2019-11-06 12:42:58,502 train 750 2.108254e-02 -0.714214
2019-11-06 12:43:08,390 train 800 2.110671e-02 -0.706358
2019-11-06 12:43:18,277 train 850 2.111007e-02 -0.702939
2019-11-06 12:43:21,230 training loss; R2: 2.110505e-02 -0.700462
2019-11-06 12:43:21,867 valid 000 1.813706e-02 -0.101106
2019-11-06 12:43:31,380 valid 050 2.056607e-02 -0.804980
2019-11-06 12:43:39,751 validation loss; R2: 2.069667e-02 -0.809129
2019-11-06 12:43:39,823 epoch 57 lr 1.000000e-05
2019-11-06 12:43:40,553 train 000 2.165517e-02 -3.209525
2019-11-06 12:43:50,400 train 050 2.114303e-02 -0.749323
2019-11-06 12:44:00,245 train 100 2.111974e-02 -0.704808
2019-11-06 12:44:10,059 train 150 2.110405e-02 -0.657030
2019-11-06 12:44:19,879 train 200 2.106574e-02 -0.620810
2019-11-06 12:44:29,712 train 250 2.112667e-02 -0.610775
2019-11-06 12:44:39,596 train 300 2.104600e-02 -0.609362
2019-11-06 12:44:49,475 train 350 2.103894e-02 -0.592440
2019-11-06 12:44:59,357 train 400 2.100805e-02 -0.569889
2019-11-06 12:45:09,260 train 450 2.105602e-02 -0.591175
2019-11-06 12:45:19,158 train 500 2.108965e-02 -0.594599
2019-11-06 12:45:29,013 train 550 2.107719e-02 -0.597395
2019-11-06 12:45:38,893 train 600 2.108579e-02 -0.635092
2019-11-06 12:45:48,773 train 650 2.110771e-02 -0.648387
2019-11-06 12:45:58,636 train 700 2.109991e-02 -0.652742
2019-11-06 12:46:08,513 train 750 2.110000e-02 -0.638839
2019-11-06 12:46:18,385 train 800 2.108181e-02 -0.644904
2019-11-06 12:46:28,256 train 850 2.110684e-02 -0.640697
2019-11-06 12:46:31,228 training loss; R2: 2.111048e-02 -0.647094
2019-11-06 12:46:31,831 valid 000 1.924235e-02 -0.052347
2019-11-06 12:46:41,374 valid 050 1.994382e-02 -0.644412
2019-11-06 12:46:49,765 validation loss; R2: 1.957655e-02 -0.682348
2019-11-06 12:46:49,845 epoch 58 lr 1.000000e-05
2019-11-06 12:46:50,656 train 000 2.482994e-02 -1.186374
2019-11-06 12:47:00,451 train 050 2.132418e-02 -0.842239
2019-11-06 12:47:10,259 train 100 2.139845e-02 -0.770225
2019-11-06 12:47:20,066 train 150 2.136373e-02 -0.695864
2019-11-06 12:47:29,875 train 200 2.109646e-02 -0.640265
2019-11-06 12:47:39,693 train 250 2.114263e-02 -0.616364
2019-11-06 12:47:49,522 train 300 2.105844e-02 -0.663802
2019-11-06 12:47:59,351 train 350 2.105548e-02 -0.650904
2019-11-06 12:48:09,190 train 400 2.106907e-02 -0.865748
2019-11-06 12:48:19,026 train 450 2.107381e-02 -0.863009
2019-11-06 12:48:28,853 train 500 2.111135e-02 -0.825928
2019-11-06 12:48:38,687 train 550 2.107367e-02 -0.816163
2019-11-06 12:48:48,521 train 600 2.104988e-02 -0.795148
2019-11-06 12:48:58,372 train 650 2.105906e-02 -0.782463
2019-11-06 12:49:08,228 train 700 2.107982e-02 -0.766143
2019-11-06 12:49:18,088 train 750 2.106738e-02 -0.782068
2019-11-06 12:49:27,953 train 800 2.106471e-02 -0.762633
2019-11-06 12:49:37,820 train 850 2.106675e-02 -1.083552
2019-11-06 12:49:40,771 training loss; R2: 2.106091e-02 -1.073647
2019-11-06 12:49:41,454 valid 000 1.679478e-02 -1.233314
2019-11-06 12:49:50,842 valid 050 2.024295e-02 -0.819645
2019-11-06 12:49:59,196 validation loss; R2: 2.009429e-02 -0.750589
2019-11-06 12:49:59,271 epoch 59 lr 1.000000e-05
2019-11-06 12:50:00,060 train 000 2.307555e-02 -0.216268
2019-11-06 12:50:09,838 train 050 2.089882e-02 -0.761867
2019-11-06 12:50:19,670 train 100 2.097718e-02 -0.719602
2019-11-06 12:50:29,532 train 150 2.098095e-02 -0.728331
2019-11-06 12:50:39,398 train 200 2.107445e-02 -0.714798
2019-11-06 12:50:49,261 train 250 2.105585e-02 -0.757814
2019-11-06 12:50:59,134 train 300 2.102880e-02 -0.727359
2019-11-06 12:51:09,003 train 350 2.105979e-02 -0.705852
2019-11-06 12:51:18,873 train 400 2.112119e-02 -0.695306
2019-11-06 12:51:28,752 train 450 2.110241e-02 -0.682719
2019-11-06 12:51:38,629 train 500 2.105179e-02 -0.684143
2019-11-06 12:51:48,496 train 550 2.105119e-02 -0.674083
2019-11-06 12:51:58,364 train 600 2.103390e-02 -0.651716
2019-11-06 12:52:08,240 train 650 2.102996e-02 -0.654288
2019-11-06 12:52:18,131 train 700 2.105117e-02 -0.661630
2019-11-06 12:52:28,023 train 750 2.103134e-02 -0.712916
2019-11-06 12:52:37,904 train 800 2.102885e-02 -0.701014
2019-11-06 12:52:47,801 train 850 2.102971e-02 -0.706750
2019-11-06 12:52:50,751 training loss; R2: 2.102850e-02 -0.712549
2019-11-06 12:52:51,432 valid 000 1.771786e-02 -0.025042
2019-11-06 12:53:00,905 valid 050 2.027308e-02 -0.990135
2019-11-06 12:53:09,320 validation loss; R2: 2.009028e-02 -1.095336
2019-11-06 12:53:09,406 epoch 60 lr 1.000000e-05
2019-11-06 12:53:10,165 train 000 2.019038e-02 -0.842260
2019-11-06 12:53:19,968 train 050 2.159461e-02 -0.486027
2019-11-06 12:53:29,783 train 100 2.111323e-02 -0.542807
2019-11-06 12:53:39,596 train 150 2.108231e-02 -0.933020
2019-11-06 12:53:49,415 train 200 2.099395e-02 -1.040982
2019-11-06 12:53:59,240 train 250 2.096616e-02 -0.964503
2019-11-06 12:54:09,071 train 300 2.104424e-02 -0.911081
2019-11-06 12:54:18,913 train 350 2.101652e-02 -0.991317
2019-11-06 12:54:28,759 train 400 2.109288e-02 -0.933486
2019-11-06 12:54:38,600 train 450 2.108596e-02 -2.434834
2019-11-06 12:54:48,448 train 500 2.107941e-02 -2.272796
2019-11-06 12:54:58,295 train 550 2.108439e-02 -2.119193
2019-11-06 12:55:08,147 train 600 2.107008e-02 -2.054908
2019-11-06 12:55:18,045 train 650 2.103751e-02 -1.934603
2019-11-06 12:55:27,930 train 700 2.103305e-02 -2.067184
2019-11-06 12:55:37,796 train 750 2.103619e-02 -1.961406
2019-11-06 12:55:47,655 train 800 2.103290e-02 -1.916244
2019-11-06 12:55:57,517 train 850 2.103954e-02 -1.835817
2019-11-06 12:56:00,468 training loss; R2: 2.103163e-02 -1.814558
2019-11-06 12:56:01,131 valid 000 2.154431e-02 -2.264827
2019-11-06 12:56:10,572 valid 050 2.017461e-02 -0.753021
2019-11-06 12:56:19,006 validation loss; R2: 1.988536e-02 -1.091429
2019-11-06 12:56:19,069 epoch 61 lr 1.000000e-05
2019-11-06 12:56:19,832 train 000 2.227663e-02 -0.582968
2019-11-06 12:56:29,615 train 050 2.089838e-02 -0.692226
2019-11-06 12:56:39,429 train 100 2.070741e-02 -0.660907
2019-11-06 12:56:49,237 train 150 2.094055e-02 -0.610399
2019-11-06 12:56:59,034 train 200 2.086187e-02 -0.660266
2019-11-06 12:57:08,839 train 250 2.090286e-02 -0.680034
2019-11-06 12:57:18,654 train 300 2.092241e-02 -0.683487
2019-11-06 12:57:28,460 train 350 2.093769e-02 -0.684173
2019-11-06 12:57:38,272 train 400 2.096902e-02 -0.671352
2019-11-06 12:57:48,081 train 450 2.099847e-02 -0.677589
2019-11-06 12:57:57,889 train 500 2.097507e-02 -0.658742
2019-11-06 12:58:07,706 train 550 2.099678e-02 -0.650566
2019-11-06 12:58:17,526 train 600 2.098758e-02 -0.646005
2019-11-06 12:58:27,342 train 650 2.095828e-02 -0.650604
2019-11-06 12:58:37,157 train 700 2.098930e-02 -0.649750
2019-11-06 12:58:46,988 train 750 2.098463e-02 -0.644876
2019-11-06 12:58:56,819 train 800 2.099708e-02 -0.633957
2019-11-06 12:59:06,643 train 850 2.099122e-02 -0.629215
2019-11-06 12:59:09,610 training loss; R2: 2.098360e-02 -0.634372
2019-11-06 12:59:10,278 valid 000 1.713538e-02 -0.602648
2019-11-06 12:59:19,705 valid 050 2.013024e-02 -0.842648
2019-11-06 12:59:28,196 validation loss; R2: 1.999859e-02 -0.803208
2019-11-06 12:59:28,264 epoch 62 lr 1.000000e-05
2019-11-06 12:59:29,029 train 000 1.711585e-02 -0.294039
2019-11-06 12:59:38,781 train 050 2.117181e-02 -0.581341
2019-11-06 12:59:48,543 train 100 2.111759e-02 -0.621258
2019-11-06 12:59:58,315 train 150 2.118002e-02 -0.587500
2019-11-06 13:00:08,087 train 200 2.109808e-02 -0.580854
2019-11-06 13:00:17,867 train 250 2.106026e-02 -0.568228
2019-11-06 13:00:27,664 train 300 2.109961e-02 -0.559780
2019-11-06 13:00:37,458 train 350 2.114998e-02 -0.575882
2019-11-06 13:00:47,260 train 400 2.113420e-02 -0.583585
2019-11-06 13:00:57,050 train 450 2.114312e-02 -0.712082
2019-11-06 13:01:06,848 train 500 2.114949e-02 -0.725708
2019-11-06 13:01:16,637 train 550 2.112495e-02 -0.729061
2019-11-06 13:01:26,433 train 600 2.111885e-02 -0.707832
2019-11-06 13:01:36,231 train 650 2.108184e-02 -0.719707
2019-11-06 13:01:46,029 train 700 2.105731e-02 -0.707313
2019-11-06 13:01:55,833 train 750 2.105625e-02 -0.708264
2019-11-06 13:02:05,634 train 800 2.106034e-02 -0.702308
2019-11-06 13:02:15,448 train 850 2.104807e-02 -0.737600
2019-11-06 13:02:18,390 training loss; R2: 2.103291e-02 -0.735408
2019-11-06 13:02:19,061 valid 000 2.375094e-02 -0.112720
2019-11-06 13:02:28,490 valid 050 2.073768e-02 -1.010802
2019-11-06 13:02:36,848 validation loss; R2: 2.057856e-02 -0.878989
2019-11-06 13:02:36,938 epoch 63 lr 1.000000e-05
2019-11-06 13:02:37,717 train 000 1.859215e-02 -0.416855
2019-11-06 13:02:47,865 train 050 2.123349e-02 -0.536461
2019-11-06 13:02:58,032 train 100 2.080155e-02 -0.554872
2019-11-06 13:03:08,044 train 150 2.085409e-02 -0.596933
2019-11-06 13:03:17,838 train 200 2.085409e-02 -0.576010
2019-11-06 13:03:27,640 train 250 2.094382e-02 -0.667636
2019-11-06 13:03:37,445 train 300 2.099733e-02 -0.650957
2019-11-06 13:03:47,254 train 350 2.104514e-02 -0.663306
2019-11-06 13:03:57,073 train 400 2.101013e-02 -0.651783
2019-11-06 13:04:06,901 train 450 2.097017e-02 -0.674672
2019-11-06 13:04:16,718 train 500 2.097033e-02 -0.688612
2019-11-06 13:04:26,531 train 550 2.096039e-02 -0.692479
2019-11-06 13:04:36,339 train 600 2.093626e-02 -0.677216
2019-11-06 13:04:46,159 train 650 2.092891e-02 -0.660927
2019-11-06 13:04:55,982 train 700 2.093409e-02 -0.664952
2019-11-06 13:05:05,807 train 750 2.095511e-02 -0.695253
2019-11-06 13:05:15,624 train 800 2.093365e-02 -0.689764
2019-11-06 13:05:25,438 train 850 2.093930e-02 -0.688758
2019-11-06 13:05:28,369 training loss; R2: 2.093675e-02 -0.690638
2019-11-06 13:05:29,110 valid 000 2.598423e-02 -0.037917
2019-11-06 13:05:38,570 valid 050 2.022654e-02 -0.576621
2019-11-06 13:05:46,925 validation loss; R2: 2.024073e-02 -0.627244
2019-11-06 13:05:46,993 epoch 64 lr 1.000000e-05
2019-11-06 13:05:47,764 train 000 2.008038e-02 -0.137429
2019-11-06 13:05:57,521 train 050 2.104595e-02 -0.569173
2019-11-06 13:06:07,299 train 100 2.088375e-02 -0.699704
2019-11-06 13:06:17,075 train 150 2.088232e-02 -0.704318
2019-11-06 13:06:26,873 train 200 2.090842e-02 -0.748043
2019-11-06 13:06:36,676 train 250 2.099817e-02 -0.750919
2019-11-06 13:06:46,481 train 300 2.101708e-02 -0.748715
2019-11-06 13:06:56,294 train 350 2.096798e-02 -0.722965
2019-11-06 13:07:06,112 train 400 2.097202e-02 -0.711991
2019-11-06 13:07:15,926 train 450 2.097913e-02 -0.680529
2019-11-06 13:07:25,727 train 500 2.097578e-02 -0.684976
2019-11-06 13:07:35,558 train 550 2.099152e-02 -1.080772
2019-11-06 13:07:45,384 train 600 2.096925e-02 -1.071462
2019-11-06 13:07:55,215 train 650 2.098491e-02 -1.027012
2019-11-06 13:08:05,037 train 700 2.099207e-02 -1.069351
2019-11-06 13:08:14,881 train 750 2.097298e-02 -1.040252
2019-11-06 13:08:24,734 train 800 2.100588e-02 -1.010150
2019-11-06 13:08:34,567 train 850 2.100051e-02 -1.009657
2019-11-06 13:08:37,539 training loss; R2: 2.100829e-02 -1.001461
2019-11-06 13:08:38,204 valid 000 1.918165e-02 -2.532300
2019-11-06 13:08:47,636 valid 050 2.028366e-02 -0.805114
2019-11-06 13:08:55,993 validation loss; R2: 2.043588e-02 -0.829931
2019-11-06 13:08:56,070 epoch 65 lr 1.000000e-05
2019-11-06 13:08:56,836 train 000 2.115634e-02 -0.711150
2019-11-06 13:09:06,607 train 050 2.080077e-02 -0.798923
2019-11-06 13:09:16,377 train 100 2.078214e-02 -0.727297
2019-11-06 13:09:26,156 train 150 2.087755e-02 -0.722153
2019-11-06 13:09:35,941 train 200 2.093152e-02 -0.685165
2019-11-06 13:09:45,730 train 250 2.097655e-02 -0.666410
2019-11-06 13:09:55,533 train 300 2.096587e-02 -0.677551
2019-11-06 13:10:05,340 train 350 2.097814e-02 -0.670476
2019-11-06 13:10:15,178 train 400 2.098170e-02 -0.662182
2019-11-06 13:10:24,999 train 450 2.100513e-02 -0.647257
2019-11-06 13:10:34,821 train 500 2.099229e-02 -0.658963
2019-11-06 13:10:44,633 train 550 2.099741e-02 -0.648316
2019-11-06 13:10:54,448 train 600 2.101767e-02 -0.699736
2019-11-06 13:11:04,270 train 650 2.098735e-02 -0.703414
2019-11-06 13:11:14,129 train 700 2.098773e-02 -0.704788
2019-11-06 13:11:24,053 train 750 2.101075e-02 -0.698899
2019-11-06 13:11:34,261 train 800 2.101265e-02 -0.693653
2019-11-06 13:11:44,463 train 850 2.099497e-02 -0.690765
2019-11-06 13:11:47,518 training loss; R2: 2.099376e-02 -0.700636
2019-11-06 13:11:48,206 valid 000 2.295832e-02 0.066672
2019-11-06 13:11:57,581 valid 050 1.959085e-02 -0.730798
2019-11-06 13:12:06,051 validation loss; R2: 1.987879e-02 -0.957927
2019-11-06 13:12:06,127 epoch 66 lr 1.000000e-05
2019-11-06 13:12:06,892 train 000 2.398716e-02 -0.236441
2019-11-06 13:12:16,992 train 050 2.125186e-02 -0.814060
2019-11-06 13:12:27,133 train 100 2.107127e-02 -0.635487
2019-11-06 13:12:37,281 train 150 2.102953e-02 -0.706019
2019-11-06 13:12:47,434 train 200 2.098616e-02 -0.727204
2019-11-06 13:12:57,594 train 250 2.090806e-02 -0.703057
2019-11-06 13:13:07,761 train 300 2.098632e-02 -0.668801
2019-11-06 13:13:17,932 train 350 2.100920e-02 -0.647588
2019-11-06 13:13:28,115 train 400 2.103950e-02 -0.638977
2019-11-06 13:13:38,306 train 450 2.107093e-02 -0.729716
2019-11-06 13:13:48,505 train 500 2.108021e-02 -0.762011
2019-11-06 13:13:58,701 train 550 2.103259e-02 -0.750367
2019-11-06 13:14:08,896 train 600 2.103149e-02 -0.740128
2019-11-06 13:14:19,103 train 650 2.102903e-02 -0.738439
2019-11-06 13:14:29,304 train 700 2.098641e-02 -0.732591
2019-11-06 13:14:39,498 train 750 2.100564e-02 -0.737485
2019-11-06 13:14:49,588 train 800 2.099506e-02 -0.740214
2019-11-06 13:14:59,483 train 850 2.100124e-02 -0.741252
2019-11-06 13:15:02,443 training loss; R2: 2.099049e-02 -0.737846
2019-11-06 13:15:03,089 valid 000 2.192660e-02 0.040249
2019-11-06 13:15:12,574 valid 050 2.060126e-02 -1.029892
2019-11-06 13:15:20,942 validation loss; R2: 2.067048e-02 -0.984007
2019-11-06 13:15:21,017 epoch 67 lr 1.000000e-05
2019-11-06 13:15:21,807 train 000 2.161330e-02 -0.312187
2019-11-06 13:15:31,598 train 050 2.083917e-02 -0.847128
2019-11-06 13:15:41,437 train 100 2.114449e-02 -0.768647
2019-11-06 13:15:51,298 train 150 2.101946e-02 -0.707541
2019-11-06 13:16:01,173 train 200 2.110226e-02 -0.825560
2019-11-06 13:16:11,034 train 250 2.106568e-02 -0.777111
2019-11-06 13:16:20,874 train 300 2.103070e-02 -0.788582
2019-11-06 13:16:30,686 train 350 2.101591e-02 -0.794989
2019-11-06 13:16:40,524 train 400 2.105006e-02 -0.934599
2019-11-06 13:16:50,350 train 450 2.102653e-02 -0.869601
2019-11-06 13:17:00,192 train 500 2.098939e-02 -0.839778
2019-11-06 13:17:10,030 train 550 2.096101e-02 -0.832715
2019-11-06 13:17:19,898 train 600 2.100478e-02 -0.855464
2019-11-06 13:17:29,777 train 650 2.102942e-02 -0.832065
2019-11-06 13:17:39,635 train 700 2.100911e-02 -0.884887
2019-11-06 13:17:49,515 train 750 2.099416e-02 -0.871453
2019-11-06 13:17:59,383 train 800 2.099666e-02 -0.879550
2019-11-06 13:18:09,250 train 850 2.099200e-02 -0.873246
2019-11-06 13:18:12,198 training loss; R2: 2.098295e-02 -0.866773
2019-11-06 13:18:12,874 valid 000 1.990131e-02 -0.955119
2019-11-06 13:18:22,295 valid 050 2.025901e-02 -0.630799
2019-11-06 13:18:30,793 validation loss; R2: 2.043504e-02 -0.714164
2019-11-06 13:18:30,862 epoch 68 lr 1.000000e-05
2019-11-06 13:18:31,682 train 000 2.178767e-02 -3.253516
2019-11-06 13:18:41,419 train 050 2.056383e-02 -0.789407
2019-11-06 13:18:51,167 train 100 2.058453e-02 -0.878616
2019-11-06 13:19:00,963 train 150 2.066309e-02 -0.745918
2019-11-06 13:19:10,768 train 200 2.078608e-02 -0.726611
2019-11-06 13:19:20,593 train 250 2.081142e-02 -0.701697
2019-11-06 13:19:30,447 train 300 2.082727e-02 -0.720853
2019-11-06 13:19:40,300 train 350 2.085253e-02 -0.679369
2019-11-06 13:19:50,158 train 400 2.086196e-02 -0.679009
2019-11-06 13:20:00,018 train 450 2.085271e-02 -0.670843
2019-11-06 13:20:09,881 train 500 2.089894e-02 -0.657369
2019-11-06 13:20:19,742 train 550 2.091080e-02 -0.691370
2019-11-06 13:20:29,602 train 600 2.091734e-02 -0.687570
2019-11-06 13:20:39,463 train 650 2.091102e-02 -0.707909
2019-11-06 13:20:49,338 train 700 2.089441e-02 -0.726561
2019-11-06 13:20:59,197 train 750 2.090094e-02 -0.712650
2019-11-06 13:21:09,048 train 800 2.090757e-02 -0.704267
2019-11-06 13:21:18,903 train 850 2.092994e-02 -0.688572
2019-11-06 13:21:21,854 training loss; R2: 2.093238e-02 -0.686209
2019-11-06 13:21:22,491 valid 000 2.264984e-02 0.037370
2019-11-06 13:21:31,952 valid 050 1.982744e-02 -0.560224
2019-11-06 13:21:40,297 validation loss; R2: 1.963735e-02 -0.680552
2019-11-06 13:21:40,363 epoch 69 lr 1.000000e-05
2019-11-06 13:21:41,150 train 000 2.075067e-02 -0.088331
2019-11-06 13:21:50,897 train 050 2.064785e-02 -0.574199
2019-11-06 13:22:00,643 train 100 2.079265e-02 -0.731791
2019-11-06 13:22:10,444 train 150 2.098218e-02 -0.692161
2019-11-06 13:22:20,245 train 200 2.097720e-02 -0.685308
2019-11-06 13:22:30,054 train 250 2.097516e-02 -0.672188
2019-11-06 13:22:39,856 train 300 2.092875e-02 -0.667704
2019-11-06 13:22:49,658 train 350 2.094715e-02 -0.695483
2019-11-06 13:22:59,479 train 400 2.093684e-02 -0.716470
2019-11-06 13:23:09,294 train 450 2.093144e-02 -0.695734
2019-11-06 13:23:19,136 train 500 2.092592e-02 -0.679795
2019-11-06 13:23:28,978 train 550 2.094285e-02 -0.767943
2019-11-06 13:23:38,825 train 600 2.093944e-02 -0.761708
2019-11-06 13:23:48,667 train 650 2.090621e-02 -0.773020
2019-11-06 13:23:58,509 train 700 2.094172e-02 -0.758164
2019-11-06 13:24:08,377 train 750 2.092578e-02 -0.752320
2019-11-06 13:24:18,241 train 800 2.095834e-02 -0.749543
2019-11-06 13:24:28,112 train 850 2.096525e-02 -0.749138
2019-11-06 13:24:31,058 training loss; R2: 2.095639e-02 -0.760426
2019-11-06 13:24:31,695 valid 000 2.417562e-02 -1.043458
2019-11-06 13:24:41,119 valid 050 2.080384e-02 -0.945305
2019-11-06 13:24:49,604 validation loss; R2: 2.078440e-02 -0.813301
2019-11-06 13:24:49,674 epoch 70 lr 1.000000e-05
2019-11-06 13:24:50,497 train 000 2.230350e-02 -1.771489
2019-11-06 13:25:00,250 train 050 2.096223e-02 -3.819814
2019-11-06 13:25:10,022 train 100 2.088420e-02 -2.244753
2019-11-06 13:25:19,803 train 150 2.088384e-02 -1.733358
2019-11-06 13:25:29,611 train 200 2.084549e-02 -1.496541
2019-11-06 13:25:39,436 train 250 2.090197e-02 -1.305476
2019-11-06 13:25:49,248 train 300 2.090603e-02 -1.187450
2019-11-06 13:25:59,061 train 350 2.090673e-02 -1.081639
2019-11-06 13:26:08,880 train 400 2.091632e-02 -1.032835
2019-11-06 13:26:18,694 train 450 2.091421e-02 -0.991563
2019-11-06 13:26:28,501 train 500 2.091869e-02 -0.969281
2019-11-06 13:26:38,301 train 550 2.095837e-02 -0.933956
2019-11-06 13:26:48,106 train 600 2.094723e-02 -0.907354
2019-11-06 13:26:57,912 train 650 2.095260e-02 -0.882974
2019-11-06 13:27:07,724 train 700 2.094126e-02 -0.865098
2019-11-06 13:27:17,529 train 750 2.091272e-02 -0.875194
2019-11-06 13:27:27,339 train 800 2.092050e-02 -0.849325
2019-11-06 13:27:37,141 train 850 2.088177e-02 -0.843432
2019-11-06 13:27:40,075 training loss; R2: 2.089325e-02 -0.841523
2019-11-06 13:27:40,714 valid 000 2.411673e-02 -1.552689
2019-11-06 13:27:50,168 valid 050 2.093270e-02 -1.401148
2019-11-06 13:27:58,544 validation loss; R2: 2.073786e-02 -1.173190
2019-11-06 13:27:58,603 epoch 71 lr 1.000000e-05
2019-11-06 13:27:59,391 train 000 1.864901e-02 -0.111115
2019-11-06 13:28:09,133 train 050 2.065285e-02 -0.623886
2019-11-06 13:28:18,898 train 100 2.071530e-02 -0.568154
2019-11-06 13:28:28,678 train 150 2.067959e-02 -0.566608
2019-11-06 13:28:38,468 train 200 2.081068e-02 -0.763336
2019-11-06 13:28:48,261 train 250 2.089974e-02 -0.739213
2019-11-06 13:28:58,048 train 300 2.078875e-02 -0.737744
2019-11-06 13:29:07,849 train 350 2.081382e-02 -0.763921
2019-11-06 13:29:17,662 train 400 2.079780e-02 -0.780132
2019-11-06 13:29:27,486 train 450 2.084047e-02 -1.382912
2019-11-06 13:29:37,290 train 500 2.084431e-02 -1.300562
2019-11-06 13:29:47,095 train 550 2.084895e-02 -1.219277
2019-11-06 13:29:56,914 train 600 2.087723e-02 -1.165058
2019-11-06 13:30:06,740 train 650 2.087396e-02 -1.118728
2019-11-06 13:30:16,569 train 700 2.088455e-02 -1.070041
2019-11-06 13:30:26,399 train 750 2.091182e-02 -1.041897
2019-11-06 13:30:36,226 train 800 2.091763e-02 -1.021429
2019-11-06 13:30:46,054 train 850 2.094340e-02 -1.013410
2019-11-06 13:30:49,021 training loss; R2: 2.094006e-02 -1.003279
2019-11-06 13:30:49,727 valid 000 1.931641e-02 0.008773
2019-11-06 13:30:59,138 valid 050 2.034206e-02 -0.613838
2019-11-06 13:31:07,486 validation loss; R2: 2.021217e-02 -0.734635
2019-11-06 13:31:07,576 epoch 72 lr 1.000000e-05
2019-11-06 13:31:08,344 train 000 2.128108e-02 -0.315332
2019-11-06 13:31:18,096 train 050 2.111949e-02 -0.653074
2019-11-06 13:31:27,871 train 100 2.105775e-02 -0.709578
2019-11-06 13:31:37,671 train 150 2.101814e-02 -0.690174
2019-11-06 13:31:47,476 train 200 2.109557e-02 -0.681168
2019-11-06 13:31:57,291 train 250 2.106519e-02 -0.698405
2019-11-06 13:32:07,115 train 300 2.095716e-02 -0.707388
2019-11-06 13:32:16,919 train 350 2.097157e-02 -0.730859
2019-11-06 13:32:26,740 train 400 2.092232e-02 -0.714820
2019-11-06 13:32:36,558 train 450 2.094347e-02 -1.040527
2019-11-06 13:32:46,375 train 500 2.092271e-02 -1.000385
2019-11-06 13:32:56,179 train 550 2.090477e-02 -0.975656
2019-11-06 13:33:05,999 train 600 2.088779e-02 -0.940660
2019-11-06 13:33:15,819 train 650 2.089825e-02 -0.910153
2019-11-06 13:33:25,625 train 700 2.092338e-02 -0.893061
2019-11-06 13:33:35,439 train 750 2.090320e-02 -0.887970
2019-11-06 13:33:45,251 train 800 2.090325e-02 -0.863521
2019-11-06 13:33:55,059 train 850 2.087998e-02 -0.844440
2019-11-06 13:33:57,989 training loss; R2: 2.090300e-02 -0.844233
2019-11-06 13:33:58,670 valid 000 2.312132e-02 -0.884027
2019-11-06 13:34:08,112 valid 050 2.091609e-02 -0.745290
2019-11-06 13:34:16,466 validation loss; R2: 2.085878e-02 -1.695765
2019-11-06 13:34:16,533 epoch 73 lr 1.000000e-05
2019-11-06 13:34:17,320 train 000 2.031577e-02 -0.653019
2019-11-06 13:34:27,041 train 050 2.126346e-02 -0.661365
2019-11-06 13:34:36,791 train 100 2.098791e-02 -0.795183
2019-11-06 13:34:46,549 train 150 2.076861e-02 -0.786638
2019-11-06 13:34:56,342 train 200 2.083149e-02 -1.205611
2019-11-06 13:35:06,131 train 250 2.084983e-02 -1.092141
2019-11-06 13:35:15,921 train 300 2.086748e-02 -1.031314
2019-11-06 13:35:25,701 train 350 2.086542e-02 -1.019502
2019-11-06 13:35:35,490 train 400 2.087154e-02 -0.959909
2019-11-06 13:35:45,285 train 450 2.091958e-02 -0.928023
2019-11-06 13:35:55,087 train 500 2.094114e-02 -0.925780
2019-11-06 13:36:04,874 train 550 2.091677e-02 -0.927294
2019-11-06 13:36:14,674 train 600 2.090673e-02 -0.917397
2019-11-06 13:36:24,469 train 650 2.087555e-02 -0.889354
2019-11-06 13:36:34,265 train 700 2.089016e-02 -0.887374
2019-11-06 13:36:44,054 train 750 2.090918e-02 -1.099462
2019-11-06 13:36:53,849 train 800 2.091631e-02 -1.077021
2019-11-06 13:37:03,639 train 850 2.090551e-02 -1.055352
2019-11-06 13:37:06,565 training loss; R2: 2.091092e-02 -1.049778
2019-11-06 13:37:07,199 valid 000 1.554752e-02 -1.437930
2019-11-06 13:37:16,627 valid 050 2.011182e-02 -0.742327
2019-11-06 13:37:25,011 validation loss; R2: 2.026343e-02 -0.707110
2019-11-06 13:37:25,083 epoch 74 lr 1.000000e-05
2019-11-06 13:37:25,825 train 000 1.770599e-02 -0.327084
2019-11-06 13:37:35,593 train 050 2.089245e-02 -0.728753
2019-11-06 13:37:45,373 train 100 2.086539e-02 -0.772864
2019-11-06 13:37:55,166 train 150 2.061424e-02 -0.715845
2019-11-06 13:38:04,979 train 200 2.081918e-02 -2.375491
2019-11-06 13:38:14,797 train 250 2.086296e-02 -2.101187
2019-11-06 13:38:24,635 train 300 2.094687e-02 -2.507800
2019-11-06 13:38:34,461 train 350 2.093649e-02 -2.222963
2019-11-06 13:38:44,264 train 400 2.086711e-02 -2.085235
2019-11-06 13:38:54,062 train 450 2.090197e-02 -1.977003
2019-11-06 13:39:03,887 train 500 2.087271e-02 -1.837434
2019-11-06 13:39:13,683 train 550 2.084673e-02 -1.762267
2019-11-06 13:39:23,496 train 600 2.083903e-02 -1.662586
2019-11-06 13:39:33,310 train 650 2.082176e-02 -1.581251
2019-11-06 13:39:43,120 train 700 2.079289e-02 -1.512870
2019-11-06 13:39:52,926 train 750 2.076325e-02 -1.442131
2019-11-06 13:40:02,726 train 800 2.077873e-02 -1.381696
2019-11-06 13:40:12,544 train 850 2.080195e-02 -1.337446
2019-11-06 13:40:15,474 training loss; R2: 2.080847e-02 -1.324826
2019-11-06 13:40:16,078 valid 000 2.224888e-02 -0.055906
2019-11-06 13:40:25,562 valid 050 2.095477e-02 -0.891140
2019-11-06 13:40:33,898 validation loss; R2: 2.100611e-02 -0.986321
2019-11-06 13:40:33,966 epoch 75 lr 1.000000e-05
2019-11-06 13:40:34,738 train 000 2.153019e-02 -0.002893
2019-11-06 13:40:44,510 train 050 2.103955e-02 -0.659898
2019-11-06 13:40:54,301 train 100 2.091923e-02 -0.508459
2019-11-06 13:41:04,101 train 150 2.076305e-02 -0.516261
2019-11-06 13:41:13,921 train 200 2.079323e-02 -0.506160
2019-11-06 13:41:23,748 train 250 2.075452e-02 -0.566766
2019-11-06 13:41:33,572 train 300 2.088600e-02 -0.605778
2019-11-06 13:41:43,398 train 350 2.089578e-02 -0.608847
2019-11-06 13:41:53,223 train 400 2.089241e-02 -0.611861
2019-11-06 13:42:03,048 train 450 2.089004e-02 -0.611985
2019-11-06 13:42:12,868 train 500 2.084079e-02 -0.614969
2019-11-06 13:42:22,682 train 550 2.086048e-02 -0.627421
2019-11-06 13:42:32,503 train 600 2.084835e-02 -0.636816
2019-11-06 13:42:42,328 train 650 2.080043e-02 -0.643022
2019-11-06 13:42:52,148 train 700 2.076880e-02 -0.648270
2019-11-06 13:43:01,983 train 750 2.078731e-02 -0.680928
2019-11-06 13:43:12,174 train 800 2.080482e-02 -0.672265
2019-11-06 13:43:22,382 train 850 2.082842e-02 -0.673171
2019-11-06 13:43:25,430 training loss; R2: 2.082975e-02 -0.676149
2019-11-06 13:43:26,021 valid 000 1.810435e-02 -0.380167
2019-11-06 13:43:35,537 valid 050 2.137620e-02 -0.783241
2019-11-06 13:43:43,896 validation loss; R2: 2.098210e-02 -0.789480
2019-11-06 13:43:43,967 epoch 76 lr 1.000000e-05
2019-11-06 13:43:44,750 train 000 1.964096e-02 -0.089742
2019-11-06 13:43:54,890 train 050 2.098111e-02 -0.546350
2019-11-06 13:44:04,805 train 100 2.075005e-02 -0.491691
2019-11-06 13:44:14,594 train 150 2.080327e-02 -0.512740
2019-11-06 13:44:24,384 train 200 2.097251e-02 -0.546862
2019-11-06 13:44:34,178 train 250 2.086749e-02 -0.586646
2019-11-06 13:44:43,972 train 300 2.087928e-02 -0.608767
2019-11-06 13:44:53,777 train 350 2.083743e-02 -0.607085
2019-11-06 13:45:03,568 train 400 2.075388e-02 -0.626012
2019-11-06 13:45:13,356 train 450 2.069186e-02 -0.630572
2019-11-06 13:45:23,152 train 500 2.070467e-02 -0.639119
2019-11-06 13:45:32,954 train 550 2.076530e-02 -0.641930
2019-11-06 13:45:42,758 train 600 2.070767e-02 -0.647383
2019-11-06 13:45:52,554 train 650 2.073559e-02 -0.673602
2019-11-06 13:46:02,360 train 700 2.077858e-02 -0.668933
2019-11-06 13:46:12,163 train 750 2.076451e-02 -0.659388
2019-11-06 13:46:21,969 train 800 2.076497e-02 -0.662831
2019-11-06 13:46:31,772 train 850 2.076487e-02 -0.668296
2019-11-06 13:46:34,737 training loss; R2: 2.074931e-02 -0.663780
2019-11-06 13:46:35,367 valid 000 2.496579e-02 -0.389554
2019-11-06 13:46:44,867 valid 050 2.099309e-02 -0.883319
2019-11-06 13:46:53,234 validation loss; R2: 2.086038e-02 -0.748886
2019-11-06 13:46:53,313 epoch 77 lr 1.000000e-05
2019-11-06 13:46:54,174 train 000 2.083120e-02 -1.393627
2019-11-06 13:47:04,295 train 050 2.108154e-02 -0.642436
2019-11-06 13:47:14,439 train 100 2.073274e-02 -0.615530
2019-11-06 13:47:24,560 train 150 2.079196e-02 -0.673762
2019-11-06 13:47:34,719 train 200 2.095744e-02 -0.732428
2019-11-06 13:47:44,871 train 250 2.094645e-02 -0.693535
2019-11-06 13:47:55,020 train 300 2.091649e-02 -0.672594
2019-11-06 13:48:05,175 train 350 2.090588e-02 -0.645296
2019-11-06 13:48:15,072 train 400 2.086886e-02 -0.654841
2019-11-06 13:48:24,816 train 450 2.087616e-02 -0.683614
2019-11-06 13:48:34,564 train 500 2.086482e-02 -0.687453
2019-11-06 13:48:44,327 train 550 2.087443e-02 -0.680425
2019-11-06 13:48:54,089 train 600 2.084409e-02 -0.688310
2019-11-06 13:49:03,856 train 650 2.082063e-02 -0.671910
2019-11-06 13:49:13,614 train 700 2.081358e-02 -0.742345
2019-11-06 13:49:23,378 train 750 2.080198e-02 -0.773898
2019-11-06 13:49:33,161 train 800 2.078577e-02 -0.771102
2019-11-06 13:49:42,941 train 850 2.078639e-02 -0.763663
2019-11-06 13:49:45,870 training loss; R2: 2.079128e-02 -0.763907
2019-11-06 13:49:46,504 valid 000 1.659459e-02 -0.081895
2019-11-06 13:49:55,916 valid 050 2.157516e-02 -0.787323
2019-11-06 13:50:04,326 validation loss; R2: 2.163938e-02 -0.843424
2019-11-06 13:50:04,392 epoch 78 lr 1.000000e-05
2019-11-06 13:50:05,183 train 000 2.089711e-02 -0.092718
2019-11-06 13:50:14,896 train 050 2.091891e-02 -0.589508
2019-11-06 13:50:24,614 train 100 2.095982e-02 -0.579846
2019-11-06 13:50:34,370 train 150 2.076184e-02 -0.625037
2019-11-06 13:50:44,129 train 200 2.078745e-02 -0.634186
2019-11-06 13:50:53,885 train 250 2.085916e-02 -0.621918
2019-11-06 13:51:03,652 train 300 2.077080e-02 -0.646985
2019-11-06 13:51:13,422 train 350 2.085855e-02 -0.628532
2019-11-06 13:51:23,179 train 400 2.084388e-02 -0.627963
2019-11-06 13:51:32,930 train 450 2.080005e-02 -0.604279
2019-11-06 13:51:42,701 train 500 2.078021e-02 -0.656482
2019-11-06 13:51:52,467 train 550 2.080883e-02 -0.639140
2019-11-06 13:52:02,234 train 600 2.081601e-02 -0.638803
2019-11-06 13:52:12,031 train 650 2.078723e-02 -0.645049
2019-11-06 13:52:21,810 train 700 2.082879e-02 -0.649375
2019-11-06 13:52:31,601 train 750 2.078635e-02 -0.660022
2019-11-06 13:52:41,409 train 800 2.078722e-02 -0.701780
2019-11-06 13:52:51,206 train 850 2.076897e-02 -0.703945
2019-11-06 13:52:54,133 training loss; R2: 2.076570e-02 -0.700299
2019-11-06 13:52:54,830 valid 000 2.203723e-02 -2.218363
2019-11-06 13:53:04,276 valid 050 2.094892e-02 -0.732228
2019-11-06 13:53:12,624 validation loss; R2: 2.087711e-02 -0.814788
2019-11-06 13:53:12,691 epoch 79 lr 1.000000e-05
2019-11-06 13:53:13,426 train 000 2.103720e-02 -0.456625
2019-11-06 13:53:23,139 train 050 2.094870e-02 -0.695759
2019-11-06 13:53:32,845 train 100 2.095020e-02 -0.753613
2019-11-06 13:53:42,601 train 150 2.085180e-02 -0.742725
2019-11-06 13:53:52,361 train 200 2.075588e-02 -0.728671
2019-11-06 13:54:02,112 train 250 2.073698e-02 -0.690582
2019-11-06 13:54:11,867 train 300 2.071380e-02 -0.663304
2019-11-06 13:54:21,621 train 350 2.072969e-02 -0.664642
2019-11-06 13:54:31,375 train 400 2.076459e-02 -0.639069
2019-11-06 13:54:41,136 train 450 2.077625e-02 -0.624129
2019-11-06 13:54:50,897 train 500 2.071894e-02 -0.627144
2019-11-06 13:55:00,657 train 550 2.067593e-02 -0.631855
2019-11-06 13:55:10,421 train 600 2.072240e-02 -0.618863
2019-11-06 13:55:20,195 train 650 2.068319e-02 -0.614319
2019-11-06 13:55:29,971 train 700 2.065155e-02 -0.612457
2019-11-06 13:55:39,749 train 750 2.065599e-02 -0.702532
2019-11-06 13:55:49,524 train 800 2.065978e-02 -0.735043
2019-11-06 13:55:59,301 train 850 2.065563e-02 -0.741055
2019-11-06 13:56:02,228 training loss; R2: 2.064986e-02 -0.736039
2019-11-06 13:56:02,853 valid 000 1.669045e-02 -0.804508
2019-11-06 13:56:12,341 valid 050 2.008965e-02 -1.527150
2019-11-06 13:56:20,681 validation loss; R2: 2.012212e-02 -1.132455
2019-11-06 13:56:20,747 epoch 80 lr 1.000000e-05
2019-11-06 13:56:21,515 train 000 2.220797e-02 -0.145900
2019-11-06 13:56:31,221 train 050 2.057059e-02 -0.671166
2019-11-06 13:56:40,983 train 100 2.047395e-02 -0.537637
2019-11-06 13:56:50,767 train 150 2.072166e-02 -0.517368
2019-11-06 13:57:00,558 train 200 2.075802e-02 -0.577336
2019-11-06 13:57:10,341 train 250 2.066996e-02 -0.633883
2019-11-06 13:57:20,114 train 300 2.072370e-02 -0.644738
2019-11-06 13:57:29,888 train 350 2.070239e-02 -0.627756
2019-11-06 13:57:39,666 train 400 2.074517e-02 -0.622244
2019-11-06 13:57:49,413 train 450 2.075158e-02 -0.696007
2019-11-06 13:57:59,169 train 500 2.073372e-02 -0.736681
2019-11-06 13:58:08,919 train 550 2.074263e-02 -0.713602
2019-11-06 13:58:18,679 train 600 2.069649e-02 -0.774914
2019-11-06 13:58:28,442 train 650 2.068274e-02 -0.768529
2019-11-06 13:58:38,207 train 700 2.067808e-02 -0.775615
2019-11-06 13:58:47,977 train 750 2.066978e-02 -0.759935
2019-11-06 13:58:57,755 train 800 2.065253e-02 -0.757457
2019-11-06 13:59:07,530 train 850 2.066971e-02 -0.751133
2019-11-06 13:59:10,464 training loss; R2: 2.067055e-02 -0.757071
2019-11-06 13:59:11,060 valid 000 2.042766e-02 -0.119322
2019-11-06 13:59:20,573 valid 050 2.126513e-02 -2.446585
2019-11-06 13:59:28,959 validation loss; R2: 2.095749e-02 -1.675487
2019-11-06 13:59:29,027 epoch 81 lr 1.000000e-05
2019-11-06 13:59:29,746 train 000 1.787071e-02 -0.428691
2019-11-06 13:59:39,497 train 050 2.071135e-02 -0.744595
2019-11-06 13:59:49,277 train 100 2.078892e-02 -0.601002
2019-11-06 13:59:59,070 train 150 2.069488e-02 -0.618416
2019-11-06 14:00:08,852 train 200 2.082283e-02 -0.596277
2019-11-06 14:00:18,647 train 250 2.085497e-02 -0.592970
2019-11-06 14:00:28,434 train 300 2.083612e-02 -0.579889
2019-11-06 14:00:38,187 train 350 2.082107e-02 -0.571458
2019-11-06 14:00:47,952 train 400 2.078313e-02 -0.571137
2019-11-06 14:00:57,718 train 450 2.074530e-02 -0.581061
2019-11-06 14:01:07,511 train 500 2.076126e-02 -0.592119
2019-11-06 14:01:17,304 train 550 2.071868e-02 -0.613332
2019-11-06 14:01:27,113 train 600 2.069128e-02 -0.620084
2019-11-06 14:01:36,929 train 650 2.066900e-02 -0.620622
2019-11-06 14:01:46,759 train 700 2.067544e-02 -0.625476
2019-11-06 14:01:56,582 train 750 2.064060e-02 -0.617658
2019-11-06 14:02:06,413 train 800 2.065964e-02 -0.620261
2019-11-06 14:02:16,242 train 850 2.064704e-02 -0.633681
2019-11-06 14:02:19,176 training loss; R2: 2.063737e-02 -0.631324
2019-11-06 14:02:19,811 valid 000 2.188891e-02 -0.591803
2019-11-06 14:02:29,236 valid 050 2.058426e-02 -0.641612
2019-11-06 14:02:37,649 validation loss; R2: 2.063485e-02 -0.661291
2019-11-06 14:02:37,715 epoch 82 lr 1.000000e-05
2019-11-06 14:02:38,493 train 000 1.895009e-02 -0.390691
2019-11-06 14:02:48,252 train 050 2.058120e-02 -0.763300
2019-11-06 14:02:58,047 train 100 2.073947e-02 -0.661496
2019-11-06 14:03:07,866 train 150 2.066065e-02 -0.831418
2019-11-06 14:03:17,665 train 200 2.067703e-02 -0.794750
2019-11-06 14:03:27,476 train 250 2.068405e-02 -0.737053
2019-11-06 14:03:37,299 train 300 2.061733e-02 -0.696270
2019-11-06 14:03:47,120 train 350 2.061665e-02 -0.666067
2019-11-06 14:03:56,927 train 400 2.065673e-02 -0.643673
2019-11-06 14:04:06,736 train 450 2.067174e-02 -0.657671
2019-11-06 14:04:16,580 train 500 2.065880e-02 -0.680990
2019-11-06 14:04:26,419 train 550 2.068026e-02 -0.692247
2019-11-06 14:04:36,286 train 600 2.069242e-02 -0.682610
2019-11-06 14:04:46,169 train 650 2.070274e-02 -0.674072
2019-11-06 14:04:56,049 train 700 2.069954e-02 -0.689585
2019-11-06 14:05:05,930 train 750 2.072157e-02 -0.679315
2019-11-06 14:05:15,814 train 800 2.071714e-02 -0.680744
2019-11-06 14:05:25,706 train 850 2.069920e-02 -0.686371
2019-11-06 14:05:28,651 training loss; R2: 2.070565e-02 -0.682848
2019-11-06 14:05:29,367 valid 000 2.219133e-02 -0.460188
2019-11-06 14:05:38,757 valid 050 2.065245e-02 -0.963780
2019-11-06 14:05:47,090 validation loss; R2: 2.083737e-02 -0.821531
2019-11-06 14:05:47,151 epoch 83 lr 1.000000e-05
2019-11-06 14:05:47,939 train 000 2.187069e-02 -0.147629
2019-11-06 14:05:57,701 train 050 2.103456e-02 -0.414373
2019-11-06 14:06:07,490 train 100 2.082827e-02 -0.521611
2019-11-06 14:06:17,305 train 150 2.073387e-02 -0.539016
2019-11-06 14:06:27,129 train 200 2.072838e-02 -0.625921
2019-11-06 14:06:36,946 train 250 2.065406e-02 -0.644199
2019-11-06 14:06:46,770 train 300 2.056028e-02 -0.736849
2019-11-06 14:06:56,599 train 350 2.057000e-02 -0.758171
2019-11-06 14:07:06,419 train 400 2.058545e-02 -0.756441
2019-11-06 14:07:16,240 train 450 2.059878e-02 -0.734607
2019-11-06 14:07:26,073 train 500 2.055022e-02 -0.745166
2019-11-06 14:07:35,900 train 550 2.056681e-02 -0.730620
2019-11-06 14:07:45,756 train 600 2.056849e-02 -0.728737
2019-11-06 14:07:55,602 train 650 2.057141e-02 -0.717775
2019-11-06 14:08:05,449 train 700 2.053875e-02 -0.756635
2019-11-06 14:08:15,286 train 750 2.052911e-02 -0.753261
2019-11-06 14:08:25,148 train 800 2.052396e-02 -0.741720
2019-11-06 14:08:34,979 train 850 2.055695e-02 -0.754804
2019-11-06 14:08:37,916 training loss; R2: 2.055828e-02 -0.753804
2019-11-06 14:08:38,551 valid 000 1.986698e-02 -0.534788
2019-11-06 14:08:48,023 valid 050 2.139507e-02 -0.718785
2019-11-06 14:08:56,359 validation loss; R2: 2.142195e-02 -0.777859
2019-11-06 14:08:56,424 epoch 84 lr 1.000000e-05
2019-11-06 14:08:57,203 train 000 1.754711e-02 -0.250930
2019-11-06 14:09:06,970 train 050 2.049106e-02 -0.577281
2019-11-06 14:09:16,763 train 100 2.058013e-02 -1.073898
2019-11-06 14:09:26,551 train 150 2.064853e-02 -0.896043
2019-11-06 14:09:36,353 train 200 2.076937e-02 -0.869971
2019-11-06 14:09:46,153 train 250 2.078005e-02 -0.824445
2019-11-06 14:09:55,957 train 300 2.067956e-02 -0.778966
2019-11-06 14:10:05,763 train 350 2.066981e-02 -0.746851
2019-11-06 14:10:15,581 train 400 2.074286e-02 -0.716874
2019-11-06 14:10:25,382 train 450 2.071492e-02 -0.713395
2019-11-06 14:10:35,194 train 500 2.068791e-02 -0.702927
2019-11-06 14:10:45,017 train 550 2.069206e-02 -0.717114
2019-11-06 14:10:54,841 train 600 2.069445e-02 -0.703844
2019-11-06 14:11:04,666 train 650 2.067195e-02 -0.692593
2019-11-06 14:11:14,502 train 700 2.064135e-02 -0.676613
2019-11-06 14:11:24,327 train 750 2.065922e-02 -0.670996
2019-11-06 14:11:34,177 train 800 2.062917e-02 -0.675736
2019-11-06 14:11:44,001 train 850 2.063266e-02 -0.714009
2019-11-06 14:11:46,979 training loss; R2: 2.062754e-02 -0.707722
2019-11-06 14:11:47,662 valid 000 2.152357e-02 -0.190699
2019-11-06 14:11:57,095 valid 050 2.173018e-02 -0.960218
2019-11-06 14:12:05,442 validation loss; R2: 2.181101e-02 -0.881083
2019-11-06 14:12:05,515 epoch 85 lr 1.000000e-05
2019-11-06 14:12:06,299 train 000 2.144051e-02 -0.151212
2019-11-06 14:12:16,438 train 050 2.043935e-02 -0.512496
2019-11-06 14:12:26,639 train 100 2.044544e-02 -0.545067
2019-11-06 14:12:36,825 train 150 2.056823e-02 -0.608152
2019-11-06 14:12:46,996 train 200 2.056792e-02 -0.694231
2019-11-06 14:12:57,157 train 250 2.055139e-02 -0.672379
2019-11-06 14:13:07,323 train 300 2.049821e-02 -0.653099
2019-11-06 14:13:17,477 train 350 2.053714e-02 -0.647022
2019-11-06 14:13:27,646 train 400 2.055356e-02 -0.670390
2019-11-06 14:13:37,812 train 450 2.056793e-02 -0.663074
2019-11-06 14:13:47,985 train 500 2.059560e-02 -0.664695
2019-11-06 14:13:58,136 train 550 2.062723e-02 -0.674121
2019-11-06 14:14:08,310 train 600 2.059939e-02 -0.666079
2019-11-06 14:14:18,482 train 650 2.059683e-02 -0.678981
2019-11-06 14:14:28,655 train 700 2.061258e-02 -0.698628
2019-11-06 14:14:38,811 train 750 2.062183e-02 -0.708068
2019-11-06 14:14:48,985 train 800 2.060786e-02 -0.698103
2019-11-06 14:14:59,160 train 850 2.057949e-02 -0.689983
2019-11-06 14:15:02,197 training loss; R2: 2.057775e-02 -0.690834
2019-11-06 14:15:02,865 valid 000 2.353645e-02 -0.705233
2019-11-06 14:15:12,262 valid 050 2.085502e-02 -0.901664
2019-11-06 14:15:20,668 validation loss; R2: 2.103409e-02 -0.794758
2019-11-06 14:15:20,748 epoch 86 lr 1.000000e-05
2019-11-06 14:15:21,502 train 000 2.311342e-02 -0.160281
2019-11-06 14:15:31,269 train 050 2.038401e-02 -1.415541
2019-11-06 14:15:41,058 train 100 2.032315e-02 -1.020253
2019-11-06 14:15:50,866 train 150 2.055422e-02 -0.898362
2019-11-06 14:16:00,699 train 200 2.054181e-02 -0.856025
2019-11-06 14:16:10,545 train 250 2.044046e-02 -0.784088
2019-11-06 14:16:20,403 train 300 2.051344e-02 -0.745793
2019-11-06 14:16:30,255 train 350 2.051964e-02 -1.329072
2019-11-06 14:16:40,123 train 400 2.053679e-02 -1.237943
2019-11-06 14:16:49,971 train 450 2.053946e-02 -1.176502
2019-11-06 14:16:59,825 train 500 2.052097e-02 -1.119285
2019-11-06 14:17:09,692 train 550 2.051163e-02 -1.089278
2019-11-06 14:17:19,549 train 600 2.054009e-02 -1.055155
2019-11-06 14:17:29,399 train 650 2.053234e-02 -1.021230
2019-11-06 14:17:39,256 train 700 2.054514e-02 -0.984464
2019-11-06 14:17:49,119 train 750 2.054060e-02 -0.962080
2019-11-06 14:17:58,999 train 800 2.057174e-02 -0.936883
2019-11-06 14:18:08,865 train 850 2.059286e-02 -0.918264
2019-11-06 14:18:11,821 training loss; R2: 2.059739e-02 -1.261982
2019-11-06 14:18:12,408 valid 000 1.851906e-02 -0.235425
2019-11-06 14:18:21,874 valid 050 2.149326e-02 -0.694900
2019-11-06 14:18:30,200 validation loss; R2: 2.170886e-02 -0.792576
2019-11-06 14:18:30,267 epoch 87 lr 1.000000e-05
2019-11-06 14:18:31,012 train 000 1.998164e-02 -0.499028
2019-11-06 14:18:40,812 train 050 2.070706e-02 -0.751388
2019-11-06 14:18:50,634 train 100 2.082994e-02 -0.792697
2019-11-06 14:19:00,474 train 150 2.073089e-02 -0.787902
2019-11-06 14:19:10,317 train 200 2.071866e-02 -0.779564
2019-11-06 14:19:20,133 train 250 2.077911e-02 -0.734312
2019-11-06 14:19:29,924 train 300 2.062272e-02 -0.705743
2019-11-06 14:19:39,724 train 350 2.063371e-02 -0.704314
2019-11-06 14:19:49,505 train 400 2.056951e-02 -0.716195
2019-11-06 14:19:59,320 train 450 2.055069e-02 -0.730464
2019-11-06 14:20:09,145 train 500 2.056220e-02 -0.714447
2019-11-06 14:20:18,976 train 550 2.057198e-02 -0.756229
2019-11-06 14:20:28,804 train 600 2.054713e-02 -0.765144
2019-11-06 14:20:38,630 train 650 2.053004e-02 -0.766680
2019-11-06 14:20:48,458 train 700 2.053392e-02 -0.744687
2019-11-06 14:20:58,298 train 750 2.052132e-02 -0.729842
2019-11-06 14:21:08,156 train 800 2.054973e-02 -0.720126
2019-11-06 14:21:17,987 train 850 2.054180e-02 -0.741325
2019-11-06 14:21:20,929 training loss; R2: 2.055215e-02 -0.735761
2019-11-06 14:21:21,588 valid 000 1.911282e-02 -0.530972
2019-11-06 14:21:31,020 valid 050 2.113900e-02 -0.559653
2019-11-06 14:21:39,356 validation loss; R2: 2.115895e-02 -0.753283
2019-11-06 14:21:39,418 epoch 88 lr 1.000000e-05
2019-11-06 14:21:40,189 train 000 2.062293e-02 -0.545731
2019-11-06 14:21:49,975 train 050 2.073929e-02 -0.688556
2019-11-06 14:21:59,782 train 100 2.064881e-02 -0.606829
2019-11-06 14:22:09,603 train 150 2.055079e-02 -0.654029
2019-11-06 14:22:19,422 train 200 2.057872e-02 -0.624625
2019-11-06 14:22:29,242 train 250 2.055402e-02 -0.630041
2019-11-06 14:22:39,051 train 300 2.061332e-02 -0.691304
2019-11-06 14:22:48,880 train 350 2.060087e-02 -0.672322
2019-11-06 14:22:58,717 train 400 2.062386e-02 -0.698098
2019-11-06 14:23:08,550 train 450 2.057377e-02 -0.685594
2019-11-06 14:23:18,376 train 500 2.056688e-02 -0.688259
2019-11-06 14:23:28,206 train 550 2.052871e-02 -0.684919
2019-11-06 14:23:38,031 train 600 2.054941e-02 -0.672941
2019-11-06 14:23:47,883 train 650 2.056838e-02 -0.674067
2019-11-06 14:23:57,725 train 700 2.053906e-02 -0.684868
2019-11-06 14:24:07,568 train 750 2.056377e-02 -0.695233
2019-11-06 14:24:17,409 train 800 2.056072e-02 -0.699225
2019-11-06 14:24:27,259 train 850 2.056351e-02 -0.792181
2019-11-06 14:24:30,198 training loss; R2: 2.056942e-02 -0.791497
2019-11-06 14:24:30,852 valid 000 2.351254e-02 -1.511585
2019-11-06 14:24:40,286 valid 050 2.118123e-02 -0.822051
2019-11-06 14:24:48,761 validation loss; R2: 2.123854e-02 -0.773587
2019-11-06 14:24:48,832 epoch 89 lr 1.000000e-05
2019-11-06 14:24:49,627 train 000 1.882243e-02 -0.206995
2019-11-06 14:24:59,373 train 050 2.038407e-02 -0.586578
2019-11-06 14:25:09,164 train 100 2.058798e-02 -0.589214
2019-11-06 14:25:18,943 train 150 2.065239e-02 -0.603209
2019-11-06 14:25:28,722 train 200 2.053018e-02 -0.608433
2019-11-06 14:25:38,508 train 250 2.050776e-02 -0.619123
2019-11-06 14:25:48,293 train 300 2.056695e-02 -0.672657
2019-11-06 14:25:58,077 train 350 2.057944e-02 -0.692251
2019-11-06 14:26:07,869 train 400 2.058748e-02 -0.676658
2019-11-06 14:26:17,669 train 450 2.061586e-02 -0.702349
2019-11-06 14:26:27,478 train 500 2.057639e-02 -0.702992
2019-11-06 14:26:37,291 train 550 2.054725e-02 -0.687528
2019-11-06 14:26:47,114 train 600 2.052811e-02 -0.768038
2019-11-06 14:26:56,943 train 650 2.053876e-02 -0.747758
2019-11-06 14:27:06,778 train 700 2.056828e-02 -0.742570
2019-11-06 14:27:16,607 train 750 2.052787e-02 -0.733018
2019-11-06 14:27:26,435 train 800 2.054301e-02 -0.708445
2019-11-06 14:27:36,266 train 850 2.055276e-02 -0.771381
2019-11-06 14:27:39,206 training loss; R2: 2.053228e-02 -0.768752
2019-11-06 14:27:39,841 valid 000 2.134010e-02 0.012886
2019-11-06 14:27:49,309 valid 050 2.009216e-02 -0.711743
2019-11-06 14:27:57,703 validation loss; R2: 2.015284e-02 -0.736777
2019-11-06 14:27:57,773 epoch 90 lr 1.000000e-05
2019-11-06 14:27:58,566 train 000 2.025980e-02 -0.008121
2019-11-06 14:28:08,316 train 050 2.059333e-02 -0.505254
2019-11-06 14:28:18,072 train 100 2.058364e-02 -0.683871
2019-11-06 14:28:27,854 train 150 2.044602e-02 -0.680446
2019-11-06 14:28:37,658 train 200 2.046217e-02 -0.657822
2019-11-06 14:28:47,452 train 250 2.047678e-02 -0.700247
2019-11-06 14:28:57,242 train 300 2.046674e-02 -0.644904
2019-11-06 14:29:07,035 train 350 2.043317e-02 -0.627015
2019-11-06 14:29:16,830 train 400 2.037619e-02 -0.643659
2019-11-06 14:29:26,632 train 450 2.039540e-02 -0.667586
2019-11-06 14:29:36,435 train 500 2.042861e-02 -0.699827
2019-11-06 14:29:46,233 train 550 2.042913e-02 -0.738245
2019-11-06 14:29:56,048 train 600 2.049044e-02 -0.732127
2019-11-06 14:30:05,859 train 650 2.048479e-02 -0.705506
2019-11-06 14:30:15,683 train 700 2.049538e-02 -0.691230
2019-11-06 14:30:25,503 train 750 2.047303e-02 -0.718082
2019-11-06 14:30:35,338 train 800 2.047292e-02 -0.709992
2019-11-06 14:30:45,166 train 850 2.043978e-02 -0.702572
2019-11-06 14:30:48,109 training loss; R2: 2.044231e-02 -0.700208
2019-11-06 14:30:48,749 valid 000 2.220081e-02 -0.478211
2019-11-06 14:30:58,214 valid 050 2.148370e-02 -0.559433
2019-11-06 14:31:06,583 validation loss; R2: 2.171596e-02 -0.726816
2019-11-06 14:31:06,654 epoch 91 lr 1.000000e-05
2019-11-06 14:31:07,449 train 000 2.261798e-02 0.001288
2019-11-06 14:31:17,201 train 050 2.017645e-02 -0.821289
2019-11-06 14:31:26,961 train 100 2.030237e-02 -0.649311
2019-11-06 14:31:36,737 train 150 2.049909e-02 -0.628465
2019-11-06 14:31:46,516 train 200 2.066016e-02 -0.672967
2019-11-06 14:31:56,301 train 250 2.064031e-02 -0.836455
2019-11-06 14:32:06,092 train 300 2.055482e-02 -0.810254
2019-11-06 14:32:15,882 train 350 2.056155e-02 -0.761964
2019-11-06 14:32:25,668 train 400 2.057850e-02 -0.769838
2019-11-06 14:32:35,423 train 450 2.047944e-02 -0.751696
2019-11-06 14:32:45,191 train 500 2.046024e-02 -0.750738
2019-11-06 14:32:54,966 train 550 2.046510e-02 -0.738172
2019-11-06 14:33:04,750 train 600 2.044983e-02 -0.733830
2019-11-06 14:33:14,540 train 650 2.046899e-02 -0.723790
2019-11-06 14:33:24,356 train 700 2.049176e-02 -0.705121
2019-11-06 14:33:34,148 train 750 2.047648e-02 -0.692099
2019-11-06 14:33:43,965 train 800 2.047003e-02 -0.681295
2019-11-06 14:33:53,774 train 850 2.045449e-02 -0.681220
2019-11-06 14:33:56,713 training loss; R2: 2.045095e-02 -0.678768
2019-11-06 14:33:57,325 valid 000 1.758703e-02 -0.511934
2019-11-06 14:34:06,801 valid 050 2.099802e-02 -0.782217
2019-11-06 14:34:15,234 validation loss; R2: 2.098572e-02 -1.003510
2019-11-06 14:34:15,302 epoch 92 lr 1.000000e-05
2019-11-06 14:34:16,147 train 000 1.824048e-02 -0.257315
2019-11-06 14:34:25,857 train 050 2.054708e-02 -0.684040
2019-11-06 14:34:35,587 train 100 2.046852e-02 -0.706924
2019-11-06 14:34:45,344 train 150 2.044067e-02 -0.705541
2019-11-06 14:34:55,097 train 200 2.040615e-02 -0.723901
2019-11-06 14:35:04,866 train 250 2.039378e-02 -0.718933
2019-11-06 14:35:14,627 train 300 2.040916e-02 -0.701542
2019-11-06 14:35:24,383 train 350 2.046004e-02 -0.694559
2019-11-06 14:35:34,155 train 400 2.042930e-02 -0.682476
2019-11-06 14:35:43,916 train 450 2.048837e-02 -0.691448
2019-11-06 14:35:53,681 train 500 2.050316e-02 -0.725055
2019-11-06 14:36:03,454 train 550 2.045692e-02 -0.814840
2019-11-06 14:36:13,234 train 600 2.045227e-02 -0.788945
2019-11-06 14:36:23,015 train 650 2.047442e-02 -0.777639
2019-11-06 14:36:32,814 train 700 2.046585e-02 -0.765069
2019-11-06 14:36:42,597 train 750 2.045284e-02 -0.769999
2019-11-06 14:36:52,392 train 800 2.042039e-02 -0.771685
2019-11-06 14:37:02,184 train 850 2.042845e-02 -0.773448
2019-11-06 14:37:05,111 training loss; R2: 2.042828e-02 -0.764365
2019-11-06 14:37:05,730 valid 000 1.900692e-02 -0.305758
2019-11-06 14:37:15,258 valid 050 2.074740e-02 -0.890335
2019-11-06 14:37:23,685 validation loss; R2: 2.078656e-02 -0.887653
2019-11-06 14:37:23,749 epoch 93 lr 1.000000e-05
2019-11-06 14:37:24,488 train 000 2.131979e-02 -0.696372
2019-11-06 14:37:34,248 train 050 2.033163e-02 -0.442424
2019-11-06 14:37:44,008 train 100 2.051136e-02 -0.783920
2019-11-06 14:37:53,789 train 150 2.044667e-02 -0.739684
2019-11-06 14:38:03,582 train 200 2.045158e-02 -0.711423
2019-11-06 14:38:13,367 train 250 2.048905e-02 -0.691148
2019-11-06 14:38:23,154 train 300 2.039483e-02 -0.676950
2019-11-06 14:38:32,943 train 350 2.041305e-02 -0.663818
2019-11-06 14:38:42,733 train 400 2.040450e-02 -0.691244
2019-11-06 14:38:52,536 train 450 2.039560e-02 -0.691609
2019-11-06 14:39:02,344 train 500 2.039960e-02 -0.674432
2019-11-06 14:39:12,145 train 550 2.034982e-02 -0.666780
2019-11-06 14:39:21,972 train 600 2.032307e-02 -0.662112
2019-11-06 14:39:31,801 train 650 2.032009e-02 -0.670858
2019-11-06 14:39:41,616 train 700 2.030978e-02 -0.681412
2019-11-06 14:39:51,437 train 750 2.030262e-02 -0.682468
2019-11-06 14:40:01,268 train 800 2.032866e-02 -0.666445
2019-11-06 14:40:11,106 train 850 2.034880e-02 -0.657453
2019-11-06 14:40:14,042 training loss; R2: 2.033771e-02 -0.656068
2019-11-06 14:40:14,706 valid 000 1.837393e-02 -0.737215
2019-11-06 14:40:24,171 valid 050 2.147214e-02 -0.685211
2019-11-06 14:40:32,497 validation loss; R2: 2.110118e-02 -0.832057
2019-11-06 14:40:32,563 epoch 94 lr 1.000000e-05
2019-11-06 14:40:33,349 train 000 2.175105e-02 -0.519858
2019-11-06 14:40:43,110 train 050 2.069154e-02 -0.532323
2019-11-06 14:40:52,901 train 100 2.049320e-02 -0.719831
2019-11-06 14:41:02,691 train 150 2.047536e-02 -0.775060
2019-11-06 14:41:12,482 train 200 2.052882e-02 -0.721136
2019-11-06 14:41:22,278 train 250 2.044140e-02 -0.693221
2019-11-06 14:41:32,071 train 300 2.044264e-02 -0.714889
2019-11-06 14:41:41,876 train 350 2.042967e-02 -0.696892
2019-11-06 14:41:51,688 train 400 2.042431e-02 -0.690717
2019-11-06 14:42:01,495 train 450 2.034943e-02 -0.720110
2019-11-06 14:42:11,324 train 500 2.036656e-02 -0.714052
2019-11-06 14:42:21,155 train 550 2.031702e-02 -0.710070
2019-11-06 14:42:30,995 train 600 2.038416e-02 -0.698363
2019-11-06 14:42:40,843 train 650 2.035985e-02 -0.688003
2019-11-06 14:42:50,709 train 700 2.035552e-02 -0.685104
2019-11-06 14:43:00,587 train 750 2.037008e-02 -0.674110
2019-11-06 14:43:10,451 train 800 2.038321e-02 -0.660274
2019-11-06 14:43:20,314 train 850 2.038422e-02 -0.678198
2019-11-06 14:43:23,264 training loss; R2: 2.037691e-02 -0.674299
2019-11-06 14:43:23,893 valid 000 2.574301e-02 -0.458499
2019-11-06 14:43:33,351 valid 050 2.056159e-02 -1.743977
2019-11-06 14:43:41,674 validation loss; R2: 2.075187e-02 -1.203834
2019-11-06 14:43:41,742 epoch 95 lr 1.000000e-05
2019-11-06 14:43:42,527 train 000 1.964244e-02 -0.630043
2019-11-06 14:43:52,311 train 050 2.046280e-02 -0.904371
2019-11-06 14:44:02,097 train 100 2.037755e-02 -0.753114
2019-11-06 14:44:11,892 train 150 2.044311e-02 -0.704468
2019-11-06 14:44:21,676 train 200 2.021962e-02 -0.741803
2019-11-06 14:44:31,469 train 250 2.014653e-02 -0.716167
2019-11-06 14:44:41,264 train 300 2.017341e-02 -0.759378
2019-11-06 14:44:51,054 train 350 2.019300e-02 -0.738881
2019-11-06 14:45:00,851 train 400 2.021423e-02 -0.740148
2019-11-06 14:45:10,635 train 450 2.021074e-02 -0.721227
2019-11-06 14:45:20,420 train 500 2.022872e-02 -0.714478
2019-11-06 14:45:30,229 train 550 2.025639e-02 -0.715684
2019-11-06 14:45:40,048 train 600 2.026221e-02 -0.715751
2019-11-06 14:45:49,839 train 650 2.024059e-02 -0.726954
2019-11-06 14:45:59,639 train 700 2.023101e-02 -0.717623
2019-11-06 14:46:09,695 train 750 2.024975e-02 -0.704445
2019-11-06 14:46:19,921 train 800 2.026783e-02 -0.714698
2019-11-06 14:46:30,160 train 850 2.025515e-02 -0.707216
2019-11-06 14:46:33,215 training loss; R2: 2.027670e-02 -0.710700
2019-11-06 14:46:33,810 valid 000 1.912664e-02 -0.369288
2019-11-06 14:46:43,309 valid 050 2.128619e-02 -0.724826
2019-11-06 14:46:51,670 validation loss; R2: 2.120375e-02 -0.948981
2019-11-06 14:46:51,751 epoch 96 lr 1.000000e-05
2019-11-06 14:46:52,540 train 000 1.838289e-02 -0.086880
2019-11-06 14:47:02,337 train 050 2.017544e-02 -0.680366
2019-11-06 14:47:12,167 train 100 2.005133e-02 -0.570771
2019-11-06 14:47:21,997 train 150 2.020587e-02 -0.562465
2019-11-06 14:47:31,826 train 200 2.032235e-02 -0.579046
2019-11-06 14:47:41,640 train 250 2.038505e-02 -0.576800
2019-11-06 14:47:51,433 train 300 2.038503e-02 -0.588257
2019-11-06 14:48:01,229 train 350 2.034005e-02 -0.652966
2019-11-06 14:48:11,032 train 400 2.040355e-02 -0.639483
2019-11-06 14:48:20,836 train 450 2.040533e-02 -0.660998
2019-11-06 14:48:30,633 train 500 2.037655e-02 -0.679436
2019-11-06 14:48:40,432 train 550 2.032528e-02 -0.692172
2019-11-06 14:48:50,248 train 600 2.031928e-02 -0.675292
2019-11-06 14:49:00,060 train 650 2.034415e-02 -0.669543
2019-11-06 14:49:09,886 train 700 2.033124e-02 -0.682326
2019-11-06 14:49:19,739 train 750 2.032440e-02 -0.678171
2019-11-06 14:49:29,577 train 800 2.032090e-02 -0.692049
2019-11-06 14:49:39,411 train 850 2.031074e-02 -0.701432
2019-11-06 14:49:42,376 training loss; R2: 2.031650e-02 -0.705863
2019-11-06 14:49:43,025 valid 000 2.136669e-02 -0.709313
2019-11-06 14:49:52,424 valid 050 2.126143e-02 -0.876121
2019-11-06 14:50:00,815 validation loss; R2: 2.123059e-02 -0.986522
2019-11-06 14:50:00,886 epoch 97 lr 1.000000e-05
2019-11-06 14:50:01,663 train 000 2.297767e-02 -0.285535
2019-11-06 14:50:11,452 train 050 1.988961e-02 -0.533659
2019-11-06 14:50:21,250 train 100 1.994846e-02 -0.604898
2019-11-06 14:50:31,070 train 150 1.987076e-02 -0.703345
2019-11-06 14:50:40,887 train 200 2.003931e-02 -0.663401
2019-11-06 14:50:50,700 train 250 2.002016e-02 -0.686387
2019-11-06 14:51:00,530 train 300 2.014409e-02 -0.681879
2019-11-06 14:51:10,348 train 350 2.018983e-02 -0.667047
2019-11-06 14:51:20,175 train 400 2.019439e-02 -0.682835
2019-11-06 14:51:29,992 train 450 2.025461e-02 -0.711030
2019-11-06 14:51:39,814 train 500 2.029206e-02 -0.703340
2019-11-06 14:51:49,624 train 550 2.029201e-02 -0.693725
2019-11-06 14:51:59,458 train 600 2.028275e-02 -0.686981
2019-11-06 14:52:09,300 train 650 2.027317e-02 -0.723453
2019-11-06 14:52:19,148 train 700 2.030122e-02 -0.713931
2019-11-06 14:52:28,979 train 750 2.031316e-02 -0.705680
2019-11-06 14:52:38,802 train 800 2.030303e-02 -0.707015
2019-11-06 14:52:48,620 train 850 2.029569e-02 -0.695671
2019-11-06 14:52:51,554 training loss; R2: 2.028493e-02 -0.699732
2019-11-06 14:52:52,221 valid 000 2.250462e-02 -0.827069
2019-11-06 14:53:01,659 valid 050 2.207748e-02 -0.878373
2019-11-06 14:53:10,004 validation loss; R2: 2.179939e-02 -0.797115
2019-11-06 14:53:10,073 epoch 98 lr 1.000000e-05
2019-11-06 14:53:10,872 train 000 2.369208e-02 -0.217530
2019-11-06 14:53:20,629 train 050 2.060017e-02 -0.671341
2019-11-06 14:53:30,419 train 100 2.038950e-02 -0.595070
2019-11-06 14:53:40,204 train 150 2.034501e-02 -0.726989
2019-11-06 14:53:49,987 train 200 2.038816e-02 -0.823467
2019-11-06 14:53:59,783 train 250 2.028928e-02 -1.139072
2019-11-06 14:54:09,577 train 300 2.035912e-02 -1.059262
2019-11-06 14:54:19,367 train 350 2.032298e-02 -1.002516
2019-11-06 14:54:29,175 train 400 2.031843e-02 -0.973229
2019-11-06 14:54:38,965 train 450 2.032293e-02 -0.924385
2019-11-06 14:54:48,760 train 500 2.037595e-02 -0.879233
2019-11-06 14:54:58,550 train 550 2.038976e-02 -0.860843
2019-11-06 14:55:08,347 train 600 2.035959e-02 -1.103980
2019-11-06 14:55:18,151 train 650 2.034870e-02 -12.748526
2019-11-06 14:55:27,965 train 700 2.031438e-02 -11.888625
2019-11-06 14:55:37,770 train 750 2.029905e-02 -11.141535
2019-11-06 14:55:47,583 train 800 2.032380e-02 -10.477655
2019-11-06 14:55:57,415 train 850 2.031801e-02 -9.893466
2019-11-06 14:56:00,411 training loss; R2: 2.031377e-02 -9.737169
2019-11-06 14:56:01,027 valid 000 2.073588e-02 -0.169844
2019-11-06 14:56:10,470 valid 050 2.137757e-02 -0.574285
2019-11-06 14:56:18,787 validation loss; R2: 2.129963e-02 -0.645191
2019-11-06 14:56:18,866 epoch 99 lr 1.000000e-05
2019-11-06 14:56:19,667 train 000 1.748778e-02 -0.756016
2019-11-06 14:56:29,420 train 050 2.025827e-02 -0.491925
2019-11-06 14:56:39,220 train 100 2.072087e-02 -0.980324
2019-11-06 14:56:49,003 train 150 2.048217e-02 -0.837485
2019-11-06 14:56:58,798 train 200 2.035972e-02 -0.949110
2019-11-06 14:57:08,587 train 250 2.027830e-02 -6.110876
2019-11-06 14:57:18,382 train 300 2.032698e-02 -5.184459
2019-11-06 14:57:28,188 train 350 2.029980e-02 -4.522853
2019-11-06 14:57:37,989 train 400 2.023821e-02 -4.948825
2019-11-06 14:57:47,794 train 450 2.031205e-02 -4.518830
2019-11-06 14:57:57,619 train 500 2.029930e-02 -4.143064
2019-11-06 14:58:07,431 train 550 2.028960e-02 -3.839006
2019-11-06 14:58:17,281 train 600 2.029339e-02 -3.584101
2019-11-06 14:58:27,103 train 650 2.029836e-02 -3.366995
2019-11-06 14:58:36,951 train 700 2.030571e-02 -3.159079
2019-11-06 14:58:46,801 train 750 2.026848e-02 -3.007373
2019-11-06 14:58:56,664 train 800 2.025871e-02 -4.382562
2019-11-06 14:59:06,540 train 850 2.027026e-02 -4.163668
2019-11-06 14:59:09,492 training loss; R2: 2.027524e-02 -4.100308
2019-11-06 14:59:10,196 valid 000 1.925930e-02 -0.279252
2019-11-06 14:59:19,636 valid 050 2.040902e-02 -0.668979
2019-11-06 14:59:28,000 validation loss; R2: 2.055934e-02 -0.679341
2019-11-06 14:59:28,069 epoch 100 lr 1.000000e-05
2019-11-06 14:59:28,795 train 000 1.887727e-02 -0.270507
2019-11-06 14:59:38,600 train 050 2.031741e-02 -0.567527
2019-11-06 14:59:48,419 train 100 2.030629e-02 -0.514206
2019-11-06 14:59:58,227 train 150 2.028644e-02 -0.715502
2019-11-06 15:00:08,035 train 200 2.023455e-02 -0.648342
2019-11-06 15:00:17,837 train 250 2.016958e-02 -0.685311
2019-11-06 15:00:27,657 train 300 2.017445e-02 -0.694466
2019-11-06 15:00:37,475 train 350 2.023936e-02 -0.694468
2019-11-06 15:00:47,303 train 400 2.021344e-02 -0.721306
2019-11-06 15:00:57,111 train 450 2.025007e-02 -0.727379
2019-11-06 15:01:06,941 train 500 2.022287e-02 -0.706405
2019-11-06 15:01:16,763 train 550 2.022472e-02 -0.710340
2019-11-06 15:01:26,600 train 600 2.023427e-02 -0.727657
2019-11-06 15:01:36,429 train 650 2.021355e-02 -0.728905
2019-11-06 15:01:46,279 train 700 2.019454e-02 -0.713653
2019-11-06 15:01:56,113 train 750 2.018511e-02 -0.712625
2019-11-06 15:02:05,961 train 800 2.018763e-02 -0.702699
2019-11-06 15:02:15,807 train 850 2.018841e-02 -0.704257
2019-11-06 15:02:18,742 training loss; R2: 2.019716e-02 -0.709317
2019-11-06 15:02:19,367 valid 000 1.902699e-02 -0.575869
2019-11-06 15:02:28,859 valid 050 2.112238e-02 -1.113506
2019-11-06 15:02:37,224 validation loss; R2: 2.122235e-02 -0.836637
2019-11-06 15:02:37,288 epoch 101 lr 1.000000e-05
2019-11-06 15:02:38,053 train 000 2.208398e-02 -0.258277
2019-11-06 15:02:47,817 train 050 1.998721e-02 -0.670372
2019-11-06 15:02:57,587 train 100 2.021710e-02 -0.655275
2019-11-06 15:03:07,368 train 150 2.003462e-02 -0.606102
2019-11-06 15:03:17,154 train 200 2.012984e-02 -0.655513
2019-11-06 15:03:26,958 train 250 2.017404e-02 -0.696737
2019-11-06 15:03:36,766 train 300 2.017195e-02 -0.678325
2019-11-06 15:03:46,578 train 350 2.014433e-02 -0.684175
2019-11-06 15:03:56,409 train 400 2.016540e-02 -0.665920
2019-11-06 15:04:06,239 train 450 2.019987e-02 -0.646207
2019-11-06 15:04:16,088 train 500 2.024205e-02 -0.692748
2019-11-06 15:04:25,957 train 550 2.024768e-02 -0.745703
2019-11-06 15:04:35,816 train 600 2.023797e-02 -0.771303
2019-11-06 15:04:45,689 train 650 2.026495e-02 -0.780116
2019-11-06 15:04:55,553 train 700 2.024718e-02 -0.800172
2019-11-06 15:05:05,408 train 750 2.022735e-02 -0.788604
2019-11-06 15:05:15,274 train 800 2.019333e-02 -0.788882
2019-11-06 15:05:25,151 train 850 2.017190e-02 -0.785842
2019-11-06 15:05:28,101 training loss; R2: 2.018812e-02 -0.781754
2019-11-06 15:05:28,715 valid 000 1.864881e-02 -0.690189
2019-11-06 15:05:38,113 valid 050 2.170667e-02 -1.170272
2019-11-06 15:05:46,507 validation loss; R2: 2.137353e-02 -1.125124
2019-11-06 15:05:46,574 epoch 102 lr 1.000000e-05
2019-11-06 15:05:47,356 train 000 1.880183e-02 -0.304645
2019-11-06 15:05:57,114 train 050 1.979012e-02 -0.533084
2019-11-06 15:06:06,888 train 100 2.006291e-02 -0.598235
2019-11-06 15:06:16,676 train 150 2.004683e-02 -0.659751
2019-11-06 15:06:26,462 train 200 2.012238e-02 -0.618321
2019-11-06 15:06:36,255 train 250 2.010846e-02 -0.638778
2019-11-06 15:06:46,049 train 300 2.008750e-02 -0.643878
2019-11-06 15:06:55,840 train 350 2.009311e-02 -0.626821
2019-11-06 15:07:05,630 train 400 2.004825e-02 -0.634155
2019-11-06 15:07:15,433 train 450 2.010642e-02 -0.661250
2019-11-06 15:07:25,263 train 500 2.016529e-02 -0.672604
2019-11-06 15:07:35,097 train 550 2.011318e-02 -0.693818
2019-11-06 15:07:44,929 train 600 2.010312e-02 -0.712667
2019-11-06 15:07:54,777 train 650 2.009806e-02 -0.713272
2019-11-06 15:08:04,634 train 700 2.009694e-02 -0.709460
2019-11-06 15:08:14,490 train 750 2.011116e-02 -0.757659
2019-11-06 15:08:24,358 train 800 2.011104e-02 -0.747101
2019-11-06 15:08:34,217 train 850 2.011668e-02 -0.728912
2019-11-06 15:08:37,194 training loss; R2: 2.012059e-02 -0.724444
2019-11-06 15:08:37,811 valid 000 2.086461e-02 -0.447640
2019-11-06 15:08:47,336 valid 050 2.172588e-02 -0.714666
2019-11-06 15:08:55,681 validation loss; R2: 2.120054e-02 -0.766593
2019-11-06 15:08:55,758 epoch 103 lr 1.000000e-05
2019-11-06 15:08:56,536 train 000 1.845014e-02 -0.294996
2019-11-06 15:09:06,296 train 050 2.043925e-02 -0.509994
2019-11-06 15:09:16,100 train 100 2.045520e-02 -0.568420
2019-11-06 15:09:25,914 train 150 2.026079e-02 -0.626647
2019-11-06 15:09:35,711 train 200 2.024888e-02 -0.637023
2019-11-06 15:09:45,504 train 250 2.021881e-02 -0.595480
2019-11-06 15:09:55,312 train 300 2.018950e-02 -0.579456
2019-11-06 15:10:05,105 train 350 2.020194e-02 -0.607937
2019-11-06 15:10:15,238 train 400 2.023383e-02 -0.592631
2019-11-06 15:10:25,413 train 450 2.019287e-02 -0.596787
2019-11-06 15:10:35,605 train 500 2.021077e-02 -0.618218
2019-11-06 15:10:45,774 train 550 2.020215e-02 -0.618523
2019-11-06 15:10:55,966 train 600 2.018198e-02 -0.623876
2019-11-06 15:11:06,146 train 650 2.017052e-02 -0.625926
2019-11-06 15:11:16,333 train 700 2.017048e-02 -0.622611
2019-11-06 15:11:26,531 train 750 2.015350e-02 -0.621261
2019-11-06 15:11:36,743 train 800 2.014179e-02 -0.620237
2019-11-06 15:11:46,940 train 850 2.013490e-02 -0.635117
2019-11-06 15:11:49,988 training loss; R2: 2.013863e-02 -0.636666
2019-11-06 15:11:50,648 valid 000 2.177482e-02 -0.365982
2019-11-06 15:12:00,095 valid 050 2.036918e-02 -0.721265
2019-11-06 15:12:08,444 validation loss; R2: 2.076881e-02 -0.614680
2019-11-06 15:12:08,527 epoch 104 lr 1.000000e-05
2019-11-06 15:12:09,330 train 000 1.847468e-02 -0.558725
2019-11-06 15:12:19,483 train 050 2.008618e-02 -3.231579
2019-11-06 15:12:29,659 train 100 1.988237e-02 -2.018477
2019-11-06 15:12:39,828 train 150 1.988934e-02 -1.559787
2019-11-06 15:12:50,011 train 200 2.004155e-02 -1.335145
2019-11-06 15:13:00,180 train 250 2.012283e-02 -1.176344
2019-11-06 15:13:10,347 train 300 2.014655e-02 -1.115933
2019-11-06 15:13:20,521 train 350 2.015518e-02 -1.084979
2019-11-06 15:13:30,686 train 400 2.018810e-02 -1.049603
2019-11-06 15:13:40,863 train 450 2.018728e-02 -0.986347
2019-11-06 15:13:51,034 train 500 2.015211e-02 -1.215950
2019-11-06 15:14:01,200 train 550 2.013758e-02 -1.167530
2019-11-06 15:14:11,372 train 600 2.011057e-02 -1.131873
2019-11-06 15:14:21,539 train 650 2.010121e-02 -1.089977
2019-11-06 15:14:31,704 train 700 2.012060e-02 -1.068716
2019-11-06 15:14:41,890 train 750 2.012266e-02 -1.046926
2019-11-06 15:14:52,079 train 800 2.012404e-02 -1.022329
2019-11-06 15:15:02,256 train 850 2.016206e-02 -0.992442
2019-11-06 15:15:05,303 training loss; R2: 2.017988e-02 -0.980351
2019-11-06 15:15:05,978 valid 000 2.361104e-02 -0.100494
2019-11-06 15:15:15,470 valid 050 2.112144e-02 -0.633444
2019-11-06 15:15:23,828 validation loss; R2: 2.105204e-02 -0.623930
2019-11-06 15:15:23,910 epoch 105 lr 1.000000e-05
2019-11-06 15:15:24,628 train 000 2.290111e-02 -0.099050
2019-11-06 15:15:34,395 train 050 2.047574e-02 -0.551721
2019-11-06 15:15:44,132 train 100 2.051434e-02 -0.588808
2019-11-06 15:15:53,888 train 150 2.036376e-02 -0.612859
2019-11-06 15:16:03,635 train 200 2.025295e-02 -0.585667
2019-11-06 15:16:13,393 train 250 2.020110e-02 -0.592869
2019-11-06 15:16:23,133 train 300 2.012316e-02 -0.714422
2019-11-06 15:16:32,870 train 350 2.014276e-02 -0.682559
2019-11-06 15:16:42,626 train 400 2.015735e-02 -0.663475
2019-11-06 15:16:52,369 train 450 2.011935e-02 -0.783209
2019-11-06 15:17:02,125 train 500 2.011972e-02 -0.823267
2019-11-06 15:17:11,878 train 550 2.009794e-02 -0.802035
2019-11-06 15:17:21,655 train 600 2.009113e-02 -0.811141
2019-11-06 15:17:31,438 train 650 2.007832e-02 -0.802727
2019-11-06 15:17:41,219 train 700 2.005472e-02 -0.795069
2019-11-06 15:17:51,012 train 750 2.006492e-02 -0.795831
2019-11-06 15:18:00,825 train 800 2.005947e-02 -0.786578
2019-11-06 15:18:10,677 train 850 2.006632e-02 -0.781115
2019-11-06 15:18:13,631 training loss; R2: 2.007409e-02 -0.778368
2019-11-06 15:18:14,311 valid 000 2.468799e-02 -0.240400
2019-11-06 15:18:23,736 valid 050 2.079164e-02 -0.846920
2019-11-06 15:18:32,122 validation loss; R2: 2.059045e-02 -0.829364
2019-11-06 15:18:32,198 epoch 106 lr 1.000000e-05
2019-11-06 15:18:32,969 train 000 2.011733e-02 -0.006036
2019-11-06 15:18:42,774 train 050 2.012717e-02 -0.581198
2019-11-06 15:18:52,591 train 100 2.011429e-02 -0.607320
2019-11-06 15:19:02,406 train 150 2.002729e-02 -0.597445
2019-11-06 15:19:12,229 train 200 2.003487e-02 -0.578083
2019-11-06 15:19:22,046 train 250 2.004998e-02 -0.619371
2019-11-06 15:19:31,877 train 300 2.003143e-02 -0.619296
2019-11-06 15:19:41,697 train 350 2.007613e-02 -0.651154
2019-11-06 15:19:51,513 train 400 2.004194e-02 -0.676944
2019-11-06 15:20:01,344 train 450 2.007796e-02 -0.672542
2019-11-06 15:20:11,155 train 500 2.002403e-02 -0.659544
2019-11-06 15:20:20,973 train 550 2.006360e-02 -0.679614
2019-11-06 15:20:30,796 train 600 2.004647e-02 -0.683895
2019-11-06 15:20:40,613 train 650 2.008340e-02 -0.687060
2019-11-06 15:20:50,433 train 700 2.009518e-02 -0.699952
2019-11-06 15:21:00,242 train 750 2.006967e-02 -0.685955
2019-11-06 15:21:10,055 train 800 2.007392e-02 -0.675712
2019-11-06 15:21:19,858 train 850 2.006821e-02 -0.674886
2019-11-06 15:21:22,790 training loss; R2: 2.006845e-02 -0.669747
2019-11-06 15:21:23,438 valid 000 2.628366e-02 -0.055197
2019-11-06 15:21:32,858 valid 050 2.080918e-02 -0.596041
2019-11-06 15:21:41,211 validation loss; R2: 2.073152e-02 -1.680075
2019-11-06 15:21:41,279 epoch 107 lr 1.000000e-05
2019-11-06 15:21:42,031 train 000 1.929141e-02 -0.243746
2019-11-06 15:21:51,752 train 050 1.976015e-02 -0.571178
2019-11-06 15:22:01,485 train 100 1.978419e-02 -0.569127
2019-11-06 15:22:11,224 train 150 1.983033e-02 -0.585340
2019-11-06 15:22:20,971 train 200 1.991267e-02 -0.580319
2019-11-06 15:22:30,713 train 250 1.988989e-02 -0.594254
2019-11-06 15:22:40,496 train 300 1.996070e-02 -0.584931
2019-11-06 15:22:50,281 train 350 1.999434e-02 -0.572500
2019-11-06 15:23:00,065 train 400 1.995975e-02 -0.697730
2019-11-06 15:23:09,852 train 450 1.997259e-02 -0.670136
2019-11-06 15:23:19,631 train 500 1.999709e-02 -0.665565
2019-11-06 15:23:29,435 train 550 1.997110e-02 -0.664438
2019-11-06 15:23:39,247 train 600 1.997180e-02 -0.677374
2019-11-06 15:23:49,054 train 650 2.000432e-02 -0.681049
2019-11-06 15:23:58,869 train 700 2.001253e-02 -0.694428
2019-11-06 15:24:08,683 train 750 2.003079e-02 -0.676036
2019-11-06 15:24:18,520 train 800 2.004325e-02 -29.923337
2019-11-06 15:24:28,345 train 850 2.003633e-02 -28.206256
2019-11-06 15:24:31,289 training loss; R2: 2.001756e-02 -27.730688
2019-11-06 15:24:31,975 valid 000 2.085721e-02 -1.487382
2019-11-06 15:24:41,301 valid 050 2.155421e-02 -0.456933
2019-11-06 15:24:49,729 validation loss; R2: 2.144021e-02 -0.760197
2019-11-06 15:24:49,795 epoch 108 lr 1.000000e-05
2019-11-06 15:24:50,598 train 000 1.959464e-02 -0.464264
2019-11-06 15:25:00,369 train 050 1.971345e-02 -0.581471
2019-11-06 15:25:10,153 train 100 1.961495e-02 -0.636356
2019-11-06 15:25:19,932 train 150 1.978713e-02 -0.615396
2019-11-06 15:25:29,706 train 200 1.979253e-02 -0.627387
2019-11-06 15:25:39,483 train 250 1.983014e-02 -0.677972
2019-11-06 15:25:49,258 train 300 1.983563e-02 -2.014932
2019-11-06 15:25:59,042 train 350 1.993311e-02 -1.842305
2019-11-06 15:26:08,829 train 400 1.992191e-02 -1.680844
2019-11-06 15:26:18,624 train 450 1.992239e-02 -1.584637
2019-11-06 15:26:28,430 train 500 1.995521e-02 -1.503483
2019-11-06 15:26:38,237 train 550 1.998142e-02 -1.412646
2019-11-06 15:26:48,044 train 600 1.998207e-02 -1.374965
2019-11-06 15:26:57,849 train 650 1.998593e-02 -1.311453
2019-11-06 15:27:07,644 train 700 1.997824e-02 -1.262769
2019-11-06 15:27:17,448 train 750 1.997448e-02 -1.244428
2019-11-06 15:27:27,240 train 800 1.996918e-02 -1.203221
2019-11-06 15:27:37,044 train 850 1.995923e-02 -1.174171
2019-11-06 15:27:40,012 training loss; R2: 1.996787e-02 -1.167653
2019-11-06 15:27:40,597 valid 000 2.141203e-02 -1.346110
2019-11-06 15:27:50,058 valid 050 2.088086e-02 -1.018624
2019-11-06 15:27:58,433 validation loss; R2: 2.107391e-02 -0.798484
2019-11-06 15:27:58,500 epoch 109 lr 1.000000e-05
2019-11-06 15:27:59,281 train 000 1.574684e-02 -0.000805
2019-11-06 15:28:09,066 train 050 1.995123e-02 -0.998397
2019-11-06 15:28:19,095 train 100 1.974025e-02 -0.891988
2019-11-06 15:28:29,281 train 150 1.979251e-02 -0.877849
2019-11-06 15:28:39,440 train 200 1.984634e-02 -0.821780
2019-11-06 15:28:49,596 train 250 1.990502e-02 -0.799653
2019-11-06 15:28:59,763 train 300 1.988229e-02 -0.800488
2019-11-06 15:29:09,930 train 350 1.991253e-02 -0.769702
2019-11-06 15:29:20,103 train 400 1.992312e-02 -0.771600
2019-11-06 15:29:30,265 train 450 1.997654e-02 -0.748153
2019-11-06 15:29:40,414 train 500 2.003823e-02 -0.751034
2019-11-06 15:29:50,564 train 550 2.001641e-02 -0.744856
2019-11-06 15:30:00,725 train 600 2.000793e-02 -0.719063
2019-11-06 15:30:10,911 train 650 2.000547e-02 -0.708078
2019-11-06 15:30:21,087 train 700 2.000879e-02 -0.717037
2019-11-06 15:30:31,276 train 750 2.002228e-02 -0.728085
2019-11-06 15:30:41,465 train 800 2.004239e-02 -0.727862
2019-11-06 15:30:51,647 train 850 2.001076e-02 -0.745245
2019-11-06 15:30:54,683 training loss; R2: 2.000394e-02 -0.741992
2019-11-06 15:30:55,322 valid 000 2.421818e-02 -0.778666
2019-11-06 15:31:04,775 valid 050 2.073920e-02 -1.126630
2019-11-06 15:31:13,152 validation loss; R2: 2.061634e-02 -1.763516
2019-11-06 15:31:13,219 epoch 110 lr 1.000000e-05
2019-11-06 15:31:14,012 train 000 1.842528e-02 -0.116740
2019-11-06 15:31:24,150 train 050 2.014463e-02 -0.947679
2019-11-06 15:31:34,308 train 100 1.991747e-02 -0.764205
2019-11-06 15:31:44,465 train 150 1.989687e-02 -0.776733
2019-11-06 15:31:54,235 train 200 1.991294e-02 -0.792390
2019-11-06 15:32:04,020 train 250 1.991761e-02 -0.752848
2019-11-06 15:32:13,807 train 300 1.997880e-02 -0.742566
2019-11-06 15:32:23,594 train 350 1.994609e-02 -0.737083
2019-11-06 15:32:33,396 train 400 1.997066e-02 -0.733857
2019-11-06 15:32:43,203 train 450 1.993436e-02 -0.739193
2019-11-06 15:32:53,037 train 500 1.990363e-02 -1.255310
2019-11-06 15:33:02,851 train 550 1.990649e-02 -1.190385
2019-11-06 15:33:12,668 train 600 1.987540e-02 -1.149547
2019-11-06 15:33:22,482 train 650 1.988277e-02 -1.092609
2019-11-06 15:33:32,291 train 700 1.986790e-02 -1.058565
2019-11-06 15:33:42,099 train 750 1.990347e-02 -1.036007
2019-11-06 15:33:51,923 train 800 1.988937e-02 -1.010164
2019-11-06 15:34:01,744 train 850 1.990877e-02 -0.985092
2019-11-06 15:34:04,715 training loss; R2: 1.990860e-02 -0.978008
2019-11-06 15:34:05,351 valid 000 2.326572e-02 -0.778468
2019-11-06 15:34:14,771 valid 050 2.014220e-02 -0.646019
2019-11-06 15:34:23,102 validation loss; R2: 2.048239e-02 -0.578708
2019-11-06 15:34:23,184 epoch 111 lr 1.000000e-05
2019-11-06 15:34:24,041 train 000 2.300046e-02 -0.836538
2019-11-06 15:34:33,784 train 050 1.981328e-02 -0.847337
2019-11-06 15:34:43,556 train 100 1.995952e-02 -0.719594
2019-11-06 15:34:53,352 train 150 1.995687e-02 -0.745444
2019-11-06 15:35:03,140 train 200 1.989327e-02 -0.697083
2019-11-06 15:35:12,944 train 250 1.993282e-02 -0.680166
2019-11-06 15:35:22,741 train 300 1.999412e-02 -0.718000
2019-11-06 15:35:32,532 train 350 2.004924e-02 -0.734393
2019-11-06 15:35:42,332 train 400 2.006289e-02 -0.709176
2019-11-06 15:35:52,168 train 450 2.011969e-02 -0.716422
2019-11-06 15:36:01,991 train 500 2.011016e-02 -0.724577
2019-11-06 15:36:11,814 train 550 2.003740e-02 -0.735752
2019-11-06 15:36:21,649 train 600 2.000912e-02 -0.737017
2019-11-06 15:36:31,475 train 650 2.001085e-02 -0.738182
2019-11-06 15:36:41,286 train 700 2.002461e-02 -0.719638
2019-11-06 15:36:51,105 train 750 2.001359e-02 -0.726183
2019-11-06 15:37:00,931 train 800 2.001513e-02 -0.713724
2019-11-06 15:37:10,760 train 850 2.001431e-02 -0.699402
2019-11-06 15:37:13,698 training loss; R2: 2.000640e-02 -0.703455
2019-11-06 15:37:14,384 valid 000 2.102182e-02 -0.240831
2019-11-06 15:37:23,749 valid 050 2.103436e-02 -0.626951
2019-11-06 15:37:32,127 validation loss; R2: 2.139145e-02 -0.817383
2019-11-06 15:37:32,192 epoch 112 lr 1.000000e-05
2019-11-06 15:37:32,973 train 000 2.202080e-02 -1.673517
2019-11-06 15:37:42,735 train 050 2.077183e-02 -0.825607
2019-11-06 15:37:52,518 train 100 2.030553e-02 -0.826211
2019-11-06 15:38:02,307 train 150 2.012917e-02 -0.697801
2019-11-06 15:38:12,112 train 200 2.004311e-02 -0.674843
2019-11-06 15:38:21,910 train 250 2.001350e-02 -0.643446
2019-11-06 15:38:31,688 train 300 2.000754e-02 -0.637424
2019-11-06 15:38:41,460 train 350 1.994865e-02 -0.648360
2019-11-06 15:38:51,244 train 400 1.995184e-02 -0.660355
2019-11-06 15:39:01,044 train 450 1.991039e-02 -0.639733
2019-11-06 15:39:10,864 train 500 1.991347e-02 -0.662235
2019-11-06 15:39:20,672 train 550 1.993927e-02 -0.645858
2019-11-06 15:39:30,479 train 600 1.992425e-02 -0.646477
2019-11-06 15:39:40,294 train 650 1.992771e-02 -0.672025
2019-11-06 15:39:50,103 train 700 1.990258e-02 -0.681694
2019-11-06 15:39:59,907 train 750 1.992363e-02 -0.671428
2019-11-06 15:40:09,721 train 800 1.991086e-02 -0.669340
2019-11-06 15:40:19,529 train 850 1.990904e-02 -0.675534
2019-11-06 15:40:22,461 training loss; R2: 1.991352e-02 -0.674429
2019-11-06 15:40:23,150 valid 000 1.961494e-02 -0.121497
2019-11-06 15:40:32,507 valid 050 2.091817e-02 -0.650867
2019-11-06 15:40:40,860 validation loss; R2: 2.101805e-02 -1.637132
2019-11-06 15:40:40,926 epoch 113 lr 1.000000e-05
2019-11-06 15:40:41,669 train 000 2.097522e-02 -4.457025
2019-11-06 15:40:51,429 train 050 2.031802e-02 -0.647874
2019-11-06 15:41:01,200 train 100 2.018407e-02 -0.604100
2019-11-06 15:41:10,975 train 150 2.014222e-02 -0.623573
2019-11-06 15:41:20,748 train 200 2.014964e-02 -0.629500
2019-11-06 15:41:30,528 train 250 1.998051e-02 -0.640250
2019-11-06 15:41:40,301 train 300 2.001893e-02 -0.638302
2019-11-06 15:41:50,081 train 350 2.000647e-02 -0.659126
2019-11-06 15:41:59,868 train 400 2.004342e-02 -0.654126
2019-11-06 15:42:09,668 train 450 2.002707e-02 -0.670571
2019-11-06 15:42:19,465 train 500 1.998628e-02 -0.688721
2019-11-06 15:42:29,273 train 550 1.998068e-02 -0.700728
2019-11-06 15:42:39,074 train 600 1.996710e-02 -0.711011
2019-11-06 15:42:48,891 train 650 1.996610e-02 -0.699032
2019-11-06 15:42:58,703 train 700 1.994113e-02 -0.707986
2019-11-06 15:43:08,504 train 750 1.994732e-02 -0.714744
2019-11-06 15:43:18,322 train 800 1.994314e-02 -0.705552
2019-11-06 15:43:28,153 train 850 1.995055e-02 -0.711653
2019-11-06 15:43:31,089 training loss; R2: 1.994187e-02 -0.709675
2019-11-06 15:43:31,706 valid 000 1.806351e-02 -0.676013
2019-11-06 15:43:41,163 valid 050 1.996763e-02 -0.911604
2019-11-06 15:43:49,461 validation loss; R2: 1.997150e-02 -0.766265
2019-11-06 15:43:49,525 epoch 114 lr 1.000000e-05
2019-11-06 15:43:50,260 train 000 1.765484e-02 -0.246966
2019-11-06 15:44:00,001 train 050 2.001525e-02 -0.683163
2019-11-06 15:44:09,737 train 100 1.982835e-02 -0.611148
2019-11-06 15:44:19,512 train 150 2.005690e-02 -0.654741
2019-11-06 15:44:29,273 train 200 2.013060e-02 -0.706837
2019-11-06 15:44:39,038 train 250 2.004045e-02 -0.675233
2019-11-06 15:44:48,826 train 300 2.001930e-02 -0.716302
2019-11-06 15:44:58,623 train 350 1.999895e-02 -0.761058
2019-11-06 15:45:08,406 train 400 1.996041e-02 -0.744928
2019-11-06 15:45:18,166 train 450 2.000098e-02 -1.094884
2019-11-06 15:45:27,919 train 500 1.995302e-02 -1.037416
2019-11-06 15:45:37,679 train 550 1.994339e-02 -1.011206
2019-11-06 15:45:47,443 train 600 1.994040e-02 -0.969505
2019-11-06 15:45:57,205 train 650 1.992209e-02 -0.946368
2019-11-06 15:46:06,984 train 700 1.992202e-02 -0.930717
2019-11-06 15:46:16,751 train 750 1.993227e-02 -0.908842
2019-11-06 15:46:26,531 train 800 1.993836e-02 -0.895693
2019-11-06 15:46:36,301 train 850 1.991918e-02 -0.880555
2019-11-06 15:46:39,220 training loss; R2: 1.990990e-02 -0.886130
2019-11-06 15:46:39,916 valid 000 2.196155e-02 -1.354630
2019-11-06 15:46:49,331 valid 050 2.222862e-02 -0.837228
2019-11-06 15:46:57,618 validation loss; R2: 2.229723e-02 -0.859072
2019-11-06 15:46:57,682 epoch 115 lr 1.000000e-05
2019-11-06 15:46:58,455 train 000 1.793725e-02 -0.299578
2019-11-06 15:47:08,148 train 050 1.998310e-02 -0.572962
2019-11-06 15:47:17,854 train 100 2.000769e-02 -0.713420
2019-11-06 15:47:27,582 train 150 1.995677e-02 -0.687369
2019-11-06 15:47:37,305 train 200 1.998080e-02 -0.660023
2019-11-06 15:47:47,039 train 250 1.990327e-02 -0.636447
2019-11-06 15:47:56,780 train 300 1.988420e-02 -2.876459
2019-11-06 15:48:06,531 train 350 1.988963e-02 -2.956983
2019-11-06 15:48:16,290 train 400 1.990120e-02 -2.704781
2019-11-06 15:48:26,044 train 450 1.990025e-02 -2.495346
2019-11-06 15:48:35,852 train 500 1.988497e-02 -2.315110
2019-11-06 15:48:45,694 train 550 1.989263e-02 -2.159374
2019-11-06 15:48:55,540 train 600 1.990370e-02 -2.023079
2019-11-06 15:49:05,389 train 650 1.990445e-02 -1.940342
2019-11-06 15:49:15,232 train 700 1.990208e-02 -2.194329
2019-11-06 15:49:25,075 train 750 1.991471e-02 -2.088323
2019-11-06 15:49:34,921 train 800 1.992229e-02 -2.003419
2019-11-06 15:49:44,769 train 850 1.995401e-02 -1.941861
2019-11-06 15:49:47,711 training loss; R2: 1.995178e-02 -1.917989
2019-11-06 15:49:48,383 valid 000 2.212821e-02 -0.514129
2019-11-06 15:49:57,730 valid 050 2.095861e-02 -0.630629
2019-11-06 15:50:06,190 validation loss; R2: 2.075433e-02 -0.730987
2019-11-06 15:50:06,249 epoch 116 lr 1.000000e-05
2019-11-06 15:50:07,049 train 000 2.054170e-02 -0.180564
2019-11-06 15:50:16,818 train 050 2.007240e-02 -0.574919
2019-11-06 15:50:26,605 train 100 2.007450e-02 -0.578786
2019-11-06 15:50:36,403 train 150 2.003430e-02 -0.602021
2019-11-06 15:50:46,206 train 200 1.999514e-02 -0.632353
2019-11-06 15:50:55,999 train 250 1.999840e-02 -0.608339
2019-11-06 15:51:05,794 train 300 2.000826e-02 -0.633427
2019-11-06 15:51:15,601 train 350 1.999822e-02 -0.632521
2019-11-06 15:51:25,435 train 400 1.998663e-02 -0.650194
2019-11-06 15:51:35,267 train 450 1.993439e-02 -0.640622
2019-11-06 15:51:45,106 train 500 1.989561e-02 -0.643834
2019-11-06 15:51:54,919 train 550 1.985939e-02 -0.642301
2019-11-06 15:52:04,749 train 600 1.985360e-02 -0.638539
2019-11-06 15:52:14,566 train 650 1.985787e-02 -0.648241
2019-11-06 15:52:24,388 train 700 1.986721e-02 -0.642035
2019-11-06 15:52:34,223 train 750 1.990727e-02 -0.650083
2019-11-06 15:52:44,050 train 800 1.991363e-02 -0.667229
2019-11-06 15:52:53,866 train 850 1.990035e-02 -0.664393
2019-11-06 15:52:56,809 training loss; R2: 1.989410e-02 -0.658132
2019-11-06 15:52:57,501 valid 000 2.273185e-02 -0.474514
2019-11-06 15:53:06,926 valid 050 2.137241e-02 -0.602522
2019-11-06 15:53:15,297 validation loss; R2: 2.139999e-02 -6.582082
2019-11-06 15:53:15,363 epoch 117 lr 1.000000e-05
2019-11-06 15:53:16,103 train 000 2.112007e-02 -5.731318
2019-11-06 15:53:25,843 train 050 1.955632e-02 -0.629071
2019-11-06 15:53:35,617 train 100 1.937217e-02 -0.682700
2019-11-06 15:53:45,404 train 150 1.951302e-02 -0.783558
2019-11-06 15:53:55,192 train 200 1.948227e-02 -0.714256
2019-11-06 15:54:04,977 train 250 1.964882e-02 -0.705811
2019-11-06 15:54:14,781 train 300 1.964606e-02 -0.690804
2019-11-06 15:54:24,594 train 350 1.971606e-02 -0.705019
2019-11-06 15:54:34,400 train 400 1.967158e-02 -0.670236
2019-11-06 15:54:44,223 train 450 1.968126e-02 -0.697639
2019-11-06 15:54:54,044 train 500 1.970487e-02 -0.698042
2019-11-06 15:55:03,857 train 550 1.973552e-02 -0.699127
2019-11-06 15:55:13,678 train 600 1.972854e-02 -0.681524
2019-11-06 15:55:23,498 train 650 1.976502e-02 -0.703930
2019-11-06 15:55:33,324 train 700 1.979100e-02 -0.705339
2019-11-06 15:55:43,149 train 750 1.978982e-02 -0.689876
2019-11-06 15:55:52,985 train 800 1.980241e-02 -0.690033
2019-11-06 15:56:02,827 train 850 1.981158e-02 -0.702500
2019-11-06 15:56:05,767 training loss; R2: 1.981276e-02 -0.696794
2019-11-06 15:56:06,422 valid 000 2.039574e-02 -0.486437
2019-11-06 15:56:15,838 valid 050 2.051854e-02 -0.630909
2019-11-06 15:56:24,182 validation loss; R2: 2.049514e-02 -0.697416
2019-11-06 15:56:24,249 epoch 118 lr 1.000000e-05
2019-11-06 15:56:24,981 train 000 1.916817e-02 -0.380442
2019-11-06 15:56:34,732 train 050 1.967811e-02 -0.782400
2019-11-06 15:56:44,456 train 100 1.956494e-02 -0.870626
2019-11-06 15:56:54,220 train 150 1.955146e-02 -0.735507
2019-11-06 15:57:03,995 train 200 1.956642e-02 -0.667641
2019-11-06 15:57:13,784 train 250 1.970244e-02 -0.636740
2019-11-06 15:57:23,564 train 300 1.973387e-02 -0.659087
2019-11-06 15:57:33,357 train 350 1.978142e-02 -0.679878
2019-11-06 15:57:43,153 train 400 1.983571e-02 -0.695750
2019-11-06 15:57:52,952 train 450 1.981952e-02 -0.679228
2019-11-06 15:58:02,755 train 500 1.984861e-02 -0.669022
2019-11-06 15:58:12,546 train 550 1.979015e-02 -0.654727
2019-11-06 15:58:22,353 train 600 1.978323e-02 -0.652198
2019-11-06 15:58:32,171 train 650 1.979887e-02 -0.647773
2019-11-06 15:58:41,968 train 700 1.978820e-02 -0.652532
2019-11-06 15:58:51,778 train 750 1.979908e-02 -0.665063
2019-11-06 15:59:01,596 train 800 1.979723e-02 -0.853068
2019-11-06 15:59:11,412 train 850 1.978644e-02 -0.839537
2019-11-06 15:59:14,346 training loss; R2: 1.978693e-02 -0.838092
2019-11-06 15:59:14,969 valid 000 2.013616e-02 -0.468057
2019-11-06 15:59:24,432 valid 050 2.072173e-02 -0.717356
2019-11-06 15:59:32,774 validation loss; R2: 2.073967e-02 -0.929190
2019-11-06 15:59:32,839 epoch 119 lr 1.000000e-05
2019-11-06 15:59:33,610 train 000 1.667850e-02 -0.890266
2019-11-06 15:59:43,356 train 050 1.980501e-02 -0.591150
2019-11-06 15:59:53,125 train 100 1.980737e-02 -0.548343
2019-11-06 16:00:02,900 train 150 1.968377e-02 -0.560576
2019-11-06 16:00:12,675 train 200 1.968589e-02 -0.642738
2019-11-06 16:00:22,452 train 250 1.971574e-02 -0.701404
2019-11-06 16:00:32,239 train 300 1.966608e-02 -0.789963
2019-11-06 16:00:42,024 train 350 1.960883e-02 -0.821133
2019-11-06 16:00:51,823 train 400 1.965902e-02 -0.791417
2019-11-06 16:01:01,629 train 450 1.972005e-02 -0.786428
2019-11-06 16:01:11,433 train 500 1.977646e-02 -0.776878
2019-11-06 16:01:21,222 train 550 1.976934e-02 -0.762370
2019-11-06 16:01:31,024 train 600 1.978467e-02 -0.742161
2019-11-06 16:01:40,828 train 650 1.976837e-02 -0.763571
2019-11-06 16:01:50,635 train 700 1.975115e-02 -0.749282
2019-11-06 16:02:00,444 train 750 1.973827e-02 -0.774488
2019-11-06 16:02:10,254 train 800 1.973107e-02 -0.766876
2019-11-06 16:02:20,066 train 850 1.972804e-02 -0.779215
2019-11-06 16:02:22,995 training loss; R2: 1.971464e-02 -0.772131
2019-11-06 16:02:23,635 valid 000 2.376221e-02 -0.079393
2019-11-06 16:02:33,078 valid 050 2.061454e-02 -0.664507
2019-11-06 16:02:41,450 validation loss; R2: 2.047898e-02 -0.662233
2019-11-06 16:02:41,514 epoch 120 lr 1.000000e-05
2019-11-06 16:02:42,255 train 000 1.515823e-02 -0.162143
2019-11-06 16:02:51,999 train 050 1.977369e-02 -0.570546
2019-11-06 16:03:01,755 train 100 1.980635e-02 -0.703854
2019-11-06 16:03:11,529 train 150 1.969095e-02 -0.813573
2019-11-06 16:03:21,299 train 200 1.965511e-02 -0.770256
2019-11-06 16:03:31,100 train 250 1.965128e-02 -0.773040
2019-11-06 16:03:40,896 train 300 1.970111e-02 -0.742105
2019-11-06 16:03:50,688 train 350 1.967160e-02 -0.709514
2019-11-06 16:04:00,486 train 400 1.968326e-02 -0.682216
2019-11-06 16:04:10,288 train 450 1.970426e-02 -0.776689
2019-11-06 16:04:20,077 train 500 1.971651e-02 -0.783906
2019-11-06 16:04:29,870 train 550 1.976210e-02 -0.769207
2019-11-06 16:04:39,661 train 600 1.972389e-02 -0.751938
2019-11-06 16:04:49,460 train 650 1.973206e-02 -0.746748
2019-11-06 16:04:59,259 train 700 1.971745e-02 -0.750185
2019-11-06 16:05:09,071 train 750 1.974978e-02 -0.735699
2019-11-06 16:05:18,869 train 800 1.971349e-02 -0.732586
2019-11-06 16:05:28,669 train 850 1.972097e-02 -0.733687
2019-11-06 16:05:31,601 training loss; R2: 1.971300e-02 -0.738319
2019-11-06 16:05:32,283 valid 000 1.881713e-02 -0.749166
2019-11-06 16:05:41,641 valid 050 2.205517e-02 -2.219975
2019-11-06 16:05:49,948 validation loss; R2: 2.235480e-02 -1.516292
2019-11-06 16:05:50,016 epoch 121 lr 1.000000e-05
2019-11-06 16:05:50,777 train 000 2.095006e-02 0.089437
2019-11-06 16:06:00,508 train 050 1.988583e-02 -0.627770
2019-11-06 16:06:10,248 train 100 1.993653e-02 -0.650171
2019-11-06 16:06:20,008 train 150 1.992192e-02 -0.660921
2019-11-06 16:06:29,759 train 200 1.993954e-02 -0.673561
2019-11-06 16:06:39,542 train 250 1.983960e-02 -0.744715
2019-11-06 16:06:49,346 train 300 1.984736e-02 -0.742444
2019-11-06 16:06:59,136 train 350 1.976303e-02 -0.773258
2019-11-06 16:07:08,940 train 400 1.981292e-02 -0.741457
2019-11-06 16:07:18,748 train 450 1.984667e-02 -1.021401
2019-11-06 16:07:28,562 train 500 1.983323e-02 -0.980060
2019-11-06 16:07:38,363 train 550 1.980334e-02 -0.984479
2019-11-06 16:07:48,143 train 600 1.978967e-02 -0.977940
2019-11-06 16:07:57,923 train 650 1.977986e-02 -0.949982
2019-11-06 16:08:07,695 train 700 1.978290e-02 -0.933076
2019-11-06 16:08:17,477 train 750 1.973224e-02 -0.916802
2019-11-06 16:08:27,248 train 800 1.972040e-02 -0.913569
2019-11-06 16:08:37,030 train 850 1.974133e-02 -2.605718
2019-11-06 16:08:39,950 training loss; R2: 1.973976e-02 -2.568428
2019-11-06 16:08:40,577 valid 000 2.076835e-02 -0.089020
2019-11-06 16:08:50,014 valid 050 1.975024e-02 -0.528616
2019-11-06 16:08:58,361 validation loss; R2: 1.983407e-02 -0.562368
2019-11-06 16:08:58,424 epoch 122 lr 1.000000e-05
2019-11-06 16:08:59,144 train 000 1.781424e-02 -0.532553
2019-11-06 16:09:08,866 train 050 1.930520e-02 -0.832320
2019-11-06 16:09:18,584 train 100 1.958607e-02 -0.853337
2019-11-06 16:09:28,333 train 150 1.947623e-02 -0.807186
2019-11-06 16:09:38,090 train 200 1.951469e-02 -0.757653
2019-11-06 16:09:47,871 train 250 1.958869e-02 -0.686343
2019-11-06 16:09:57,653 train 300 1.963757e-02 -0.698212
2019-11-06 16:10:07,409 train 350 1.961678e-02 -0.690275
2019-11-06 16:10:17,153 train 400 1.968658e-02 -0.830921
2019-11-06 16:10:26,901 train 450 1.967708e-02 -0.802732
2019-11-06 16:10:36,657 train 500 1.965737e-02 -0.803083
2019-11-06 16:10:46,433 train 550 1.966873e-02 -1.102210
2019-11-06 16:10:56,198 train 600 1.968723e-02 -1.061651
2019-11-06 16:11:05,963 train 650 1.966262e-02 -1.046129
2019-11-06 16:11:15,740 train 700 1.965821e-02 -1.055117
2019-11-06 16:11:25,530 train 750 1.968030e-02 -1.040591
2019-11-06 16:11:35,325 train 800 1.968654e-02 -1.021193
2019-11-06 16:11:45,150 train 850 1.968327e-02 -1.001834
2019-11-06 16:11:48,086 training loss; R2: 1.967518e-02 -0.993755
2019-11-06 16:11:48,709 valid 000 1.969690e-02 -0.040910
2019-11-06 16:11:58,159 valid 050 2.044836e-02 -0.551144
2019-11-06 16:12:06,464 validation loss; R2: 2.053986e-02 -0.667487
2019-11-06 16:12:06,529 epoch 123 lr 1.000000e-05
2019-11-06 16:12:07,309 train 000 1.830680e-02 -0.481094
2019-11-06 16:12:17,064 train 050 1.968822e-02 -1.034560
2019-11-06 16:12:26,855 train 100 1.963791e-02 -0.790664
2019-11-06 16:12:36,644 train 150 1.966821e-02 -0.782644
2019-11-06 16:12:46,442 train 200 1.988319e-02 -0.771162
2019-11-06 16:12:56,258 train 250 1.980589e-02 -0.743753
2019-11-06 16:13:06,079 train 300 1.977196e-02 -0.734430
2019-11-06 16:13:15,921 train 350 1.969720e-02 -0.719068
2019-11-06 16:13:25,760 train 400 1.971802e-02 -0.726932
2019-11-06 16:13:35,590 train 450 1.971532e-02 -0.705767
2019-11-06 16:13:45,431 train 500 1.974536e-02 -0.697856
2019-11-06 16:13:55,253 train 550 1.971513e-02 -0.702634
2019-11-06 16:14:05,080 train 600 1.969972e-02 -0.717860
2019-11-06 16:14:14,911 train 650 1.971697e-02 -0.727948
2019-11-06 16:14:24,737 train 700 1.971050e-02 -0.714896
2019-11-06 16:14:34,565 train 750 1.971865e-02 -0.792511
2019-11-06 16:14:44,409 train 800 1.972451e-02 -0.779253
2019-11-06 16:14:54,231 train 850 1.968151e-02 -0.870571
2019-11-06 16:14:57,169 training loss; R2: 1.966433e-02 -0.881606
2019-11-06 16:14:57,867 valid 000 2.185369e-02 -1.116515
2019-11-06 16:15:07,195 valid 050 2.115894e-02 -0.727322
2019-11-06 16:15:15,565 validation loss; R2: 2.121642e-02 -0.695406
2019-11-06 16:15:15,646 epoch 124 lr 1.000000e-05
2019-11-06 16:15:16,419 train 000 1.945428e-02 -1.839546
2019-11-06 16:15:26,173 train 050 1.963636e-02 -0.877464
2019-11-06 16:15:35,956 train 100 1.967693e-02 -0.835977
2019-11-06 16:15:45,745 train 150 1.971516e-02 -0.898540
2019-11-06 16:15:55,546 train 200 1.981410e-02 -0.843193
2019-11-06 16:16:05,342 train 250 1.982997e-02 -0.853587
2019-11-06 16:16:15,142 train 300 1.984857e-02 -0.847995
2019-11-06 16:16:24,957 train 350 1.988512e-02 -0.816347
2019-11-06 16:16:34,799 train 400 1.982048e-02 -0.856675
2019-11-06 16:16:44,623 train 450 1.975564e-02 -0.875267
2019-11-06 16:16:54,442 train 500 1.972638e-02 -0.847078
2019-11-06 16:17:04,270 train 550 1.970931e-02 -0.858022
2019-11-06 16:17:14,092 train 600 1.969123e-02 -0.828316
2019-11-06 16:17:23,923 train 650 1.966531e-02 -0.809625
2019-11-06 16:17:33,749 train 700 1.966622e-02 -0.800653
2019-11-06 16:17:43,578 train 750 1.966353e-02 -0.782548
2019-11-06 16:17:53,414 train 800 1.963091e-02 -0.778323
2019-11-06 16:18:03,241 train 850 1.964187e-02 -0.776366
2019-11-06 16:18:06,180 training loss; R2: 1.964839e-02 -0.774402
2019-11-06 16:18:06,768 valid 000 2.123681e-02 -0.915044
2019-11-06 16:18:16,213 valid 050 2.061880e-02 -0.546568
2019-11-06 16:18:24,578 validation loss; R2: 2.072049e-02 -0.606129
2019-11-06 16:18:24,644 epoch 125 lr 1.000000e-05
2019-11-06 16:18:25,404 train 000 2.159273e-02 -0.175620
2019-11-06 16:18:35,169 train 050 1.974506e-02 -1.049454
2019-11-06 16:18:44,934 train 100 1.964622e-02 -0.817881
2019-11-06 16:18:54,708 train 150 1.970807e-02 -0.730392
2019-11-06 16:19:04,494 train 200 1.972109e-02 -0.728164
2019-11-06 16:19:14,273 train 250 1.970179e-02 -0.733018
2019-11-06 16:19:24,074 train 300 1.968835e-02 -0.712167
2019-11-06 16:19:33,883 train 350 1.963886e-02 -0.709686
2019-11-06 16:19:43,700 train 400 1.967422e-02 -0.680946
2019-11-06 16:19:53,514 train 450 1.967292e-02 -1.069274
2019-11-06 16:20:03,326 train 500 1.969067e-02 -1.013024
2019-11-06 16:20:13,141 train 550 1.967236e-02 -0.983634
2019-11-06 16:20:22,962 train 600 1.965340e-02 -0.959333
2019-11-06 16:20:32,771 train 650 1.965032e-02 -0.932911
2019-11-06 16:20:42,599 train 700 1.963696e-02 -0.954411
2019-11-06 16:20:52,438 train 750 1.966417e-02 -0.946573
2019-11-06 16:21:02,243 train 800 1.964529e-02 -0.946061
2019-11-06 16:21:12,058 train 850 1.964549e-02 -0.927889
2019-11-06 16:21:14,992 training loss; R2: 1.964516e-02 -0.925972
2019-11-06 16:21:15,624 valid 000 2.436772e-02 -0.273730
2019-11-06 16:21:25,066 valid 050 2.153043e-02 -0.889065
2019-11-06 16:21:33,376 validation loss; R2: 2.118370e-02 -0.817780
2019-11-06 16:21:33,440 epoch 126 lr 1.000000e-05
2019-11-06 16:21:34,207 train 000 1.886806e-02 -0.054807
2019-11-06 16:21:43,947 train 050 1.962282e-02 -0.680877
2019-11-06 16:21:53,717 train 100 1.978278e-02 -0.795119
2019-11-06 16:22:03,483 train 150 1.967886e-02 -0.789605
2019-11-06 16:22:13,243 train 200 1.958366e-02 -0.788032
2019-11-06 16:22:23,028 train 250 1.962536e-02 -0.777050
2019-11-06 16:22:32,817 train 300 1.959841e-02 -0.743910
2019-11-06 16:22:42,604 train 350 1.956553e-02 -0.737108
2019-11-06 16:22:52,395 train 400 1.957912e-02 -0.769892
2019-11-06 16:23:02,182 train 450 1.963935e-02 -0.762754
2019-11-06 16:23:11,969 train 500 1.961350e-02 -0.742747
2019-11-06 16:23:21,769 train 550 1.960961e-02 -0.755156
2019-11-06 16:23:31,558 train 600 1.961580e-02 -0.738451
2019-11-06 16:23:41,356 train 650 1.962171e-02 -0.727620
2019-11-06 16:23:51,147 train 700 1.960725e-02 -0.713382
2019-11-06 16:24:00,942 train 750 1.961213e-02 -0.712705
2019-11-06 16:24:10,737 train 800 1.959174e-02 -0.737269
2019-11-06 16:24:20,535 train 850 1.959394e-02 -0.733968
2019-11-06 16:24:23,461 training loss; R2: 1.958044e-02 -0.736316
2019-11-06 16:24:24,059 valid 000 2.054326e-02 -0.683985
2019-11-06 16:24:33,481 valid 050 2.088220e-02 -0.454825
2019-11-06 16:24:41,805 validation loss; R2: 2.082505e-02 -0.549017
2019-11-06 16:24:41,874 epoch 127 lr 1.000000e-05
2019-11-06 16:24:42,689 train 000 2.161283e-02 -0.385513
2019-11-06 16:24:52,432 train 050 1.941493e-02 -0.581205
2019-11-06 16:25:02,197 train 100 1.968381e-02 -0.661874
2019-11-06 16:25:11,953 train 150 1.957464e-02 -0.685772
2019-11-06 16:25:21,722 train 200 1.956842e-02 -0.649954
2019-11-06 16:25:31,507 train 250 1.952152e-02 -0.593458
2019-11-06 16:25:41,302 train 300 1.964092e-02 -0.614661
2019-11-06 16:25:51,085 train 350 1.961319e-02 -0.772126
2019-11-06 16:26:00,870 train 400 1.964478e-02 -0.739628
2019-11-06 16:26:10,666 train 450 1.963697e-02 -0.726228
2019-11-06 16:26:20,461 train 500 1.966488e-02 -0.712373
2019-11-06 16:26:30,255 train 550 1.968972e-02 -0.699932
2019-11-06 16:26:40,059 train 600 1.966275e-02 -0.695183
2019-11-06 16:26:49,852 train 650 1.969465e-02 -0.699467
2019-11-06 16:26:59,653 train 700 1.967685e-02 -0.704225
2019-11-06 16:27:09,461 train 750 1.969841e-02 -0.710082
2019-11-06 16:27:19,266 train 800 1.966401e-02 -0.715402
2019-11-06 16:27:29,084 train 850 1.967054e-02 -0.718623
2019-11-06 16:27:32,054 training loss; R2: 1.966144e-02 -0.731438
2019-11-06 16:27:32,707 valid 000 1.783513e-02 -0.946128
2019-11-06 16:27:42,138 valid 050 2.104887e-02 -0.891571
2019-11-06 16:27:50,505 validation loss; R2: 2.098122e-02 -0.710010
2019-11-06 16:27:50,587 epoch 128 lr 1.000000e-05
2019-11-06 16:27:51,357 train 000 2.041946e-02 -0.660716
2019-11-06 16:28:01,090 train 050 1.959901e-02 -1.153985
2019-11-06 16:28:10,850 train 100 1.987448e-02 -0.913962
2019-11-06 16:28:20,613 train 150 1.980335e-02 -0.767404
2019-11-06 16:28:30,381 train 200 1.979424e-02 -0.728902
2019-11-06 16:28:40,153 train 250 1.974593e-02 -0.747830
2019-11-06 16:28:49,931 train 300 1.972713e-02 -0.753202
2019-11-06 16:28:59,732 train 350 1.968802e-02 -0.798912
2019-11-06 16:29:09,528 train 400 1.969682e-02 -0.787347
2019-11-06 16:29:19,306 train 450 1.966388e-02 -0.800610
2019-11-06 16:29:29,097 train 500 1.964993e-02 -0.771731
2019-11-06 16:29:38,896 train 550 1.970278e-02 -0.771337
2019-11-06 16:29:48,683 train 600 1.967040e-02 -9.308028
2019-11-06 16:29:58,475 train 650 1.966662e-02 -8.644868
2019-11-06 16:30:08,276 train 700 1.968581e-02 -8.059473
2019-11-06 16:30:18,071 train 750 1.968188e-02 -7.561359
2019-11-06 16:30:27,865 train 800 1.967127e-02 -7.128887
2019-11-06 16:30:37,667 train 850 1.967267e-02 -6.756154
2019-11-06 16:30:40,598 training loss; R2: 1.966664e-02 -6.651264
2019-11-06 16:30:41,301 valid 000 1.986062e-02 -0.773888
2019-11-06 16:30:50,646 valid 050 2.071722e-02 -0.633836
2019-11-06 16:30:58,991 validation loss; R2: 2.063718e-02 -0.669328
2019-11-06 16:30:59,060 epoch 129 lr 1.000000e-05
2019-11-06 16:30:59,790 train 000 1.821668e-02 -1.661748
2019-11-06 16:31:09,526 train 050 1.975728e-02 -0.670366
2019-11-06 16:31:19,317 train 100 1.990488e-02 -0.599224
2019-11-06 16:31:29,085 train 150 1.974508e-02 -0.694018
2019-11-06 16:31:38,879 train 200 1.973559e-02 -0.769601
2019-11-06 16:31:48,672 train 250 1.962242e-02 -0.735614
2019-11-06 16:31:58,484 train 300 1.960505e-02 -0.727302
2019-11-06 16:32:08,288 train 350 1.955902e-02 -0.708515
2019-11-06 16:32:18,100 train 400 1.954945e-02 -0.697406
2019-11-06 16:32:27,917 train 450 1.953907e-02 -0.678771
2019-11-06 16:32:37,724 train 500 1.956244e-02 -0.687100
2019-11-06 16:32:47,567 train 550 1.955830e-02 -0.680635
2019-11-06 16:32:57,389 train 600 1.961028e-02 -0.704839
2019-11-06 16:33:07,200 train 650 1.959785e-02 -0.825792
2019-11-06 16:33:17,011 train 700 1.958077e-02 -0.831996
2019-11-06 16:33:26,816 train 750 1.955894e-02 -0.819200
2019-11-06 16:33:36,628 train 800 1.953779e-02 -0.810036
2019-11-06 16:33:46,440 train 850 1.954910e-02 -0.802872
2019-11-06 16:33:49,410 training loss; R2: 1.955448e-02 -0.800694
2019-11-06 16:33:50,045 valid 000 2.008622e-02 -0.445714
2019-11-06 16:33:59,481 valid 050 2.143488e-02 -1.357581
2019-11-06 16:34:07,841 validation loss; R2: 2.125152e-02 -1.097366
2019-11-06 16:34:07,922 epoch 130 lr 1.000000e-05
2019-11-06 16:34:08,761 train 000 2.028640e-02 -0.427441
2019-11-06 16:34:18,907 train 050 1.944848e-02 -0.753277
2019-11-06 16:34:29,072 train 100 1.959233e-02 -0.611652
2019-11-06 16:34:39,226 train 150 1.959854e-02 -0.566288
2019-11-06 16:34:49,378 train 200 1.948537e-02 -0.578012
2019-11-06 16:34:59,530 train 250 1.951516e-02 -0.568604
2019-11-06 16:35:09,691 train 300 1.952438e-02 -0.607030
2019-11-06 16:35:19,854 train 350 1.948776e-02 -0.634277
2019-11-06 16:35:30,030 train 400 1.946422e-02 -0.621458
2019-11-06 16:35:40,220 train 450 1.949258e-02 -0.655025
2019-11-06 16:35:50,392 train 500 1.950350e-02 -0.699913
2019-11-06 16:36:00,594 train 550 1.952713e-02 -0.705055
2019-11-06 16:36:10,747 train 600 1.954988e-02 -0.690190
2019-11-06 16:36:20,931 train 650 1.954248e-02 -0.791580
2019-11-06 16:36:31,110 train 700 1.951840e-02 -1.180135
2019-11-06 16:36:41,284 train 750 1.951401e-02 -1.156793
2019-11-06 16:36:51,467 train 800 1.955096e-02 -1.121051
2019-11-06 16:37:01,640 train 850 1.954261e-02 -1.096726
2019-11-06 16:37:04,679 training loss; R2: 1.953375e-02 -1.096503
2019-11-06 16:37:05,389 valid 000 2.359473e-02 -6.272581
2019-11-06 16:37:14,786 valid 050 2.258511e-02 -1.183375
2019-11-06 16:37:23,208 validation loss; R2: 2.259735e-02 -1.087722
2019-11-06 16:37:23,277 epoch 131 lr 1.000000e-05
2019-11-06 16:37:24,036 train 000 1.950200e-02 -0.316606
2019-11-06 16:37:34,144 train 050 1.929288e-02 -0.598339
2019-11-06 16:37:44,291 train 100 1.970503e-02 -24.835690
2019-11-06 16:37:54,416 train 150 1.975039e-02 -16.814453
2019-11-06 16:38:04,535 train 200 1.978373e-02 -17.367542
2019-11-06 16:38:14,654 train 250 1.974671e-02 -14.060566
2019-11-06 16:38:24,779 train 300 1.969778e-02 -11.896117
2019-11-06 16:38:34,904 train 350 1.972842e-02 -10.290535
2019-11-06 16:38:45,056 train 400 1.971256e-02 -9.071995
2019-11-06 16:38:55,190 train 450 1.967737e-02 -8.143558
2019-11-06 16:39:05,335 train 500 1.968942e-02 -7.382699
2019-11-06 16:39:15,481 train 550 1.962758e-02 -6.780470
2019-11-06 16:39:25,630 train 600 1.958931e-02 -6.267049
2019-11-06 16:39:35,802 train 650 1.962143e-02 -5.843297
2019-11-06 16:39:45,958 train 700 1.960495e-02 -5.487095
2019-11-06 16:39:56,111 train 750 1.961078e-02 -5.171433
2019-11-06 16:40:06,266 train 800 1.962512e-02 -4.895763
2019-11-06 16:40:16,408 train 850 1.960389e-02 -4.654100
2019-11-06 16:40:19,446 training loss; R2: 1.959122e-02 -4.591395
2019-11-06 16:40:20,138 valid 000 2.161431e-02 -0.253368
2019-11-06 16:40:29,478 valid 050 2.146705e-02 -1.104885
2019-11-06 16:40:37,872 validation loss; R2: 2.136820e-02 -1.086574
2019-11-06 16:40:37,939 epoch 132 lr 1.000000e-05
2019-11-06 16:40:38,738 train 000 1.860599e-02 -0.667996
2019-11-06 16:40:48,835 train 050 1.918494e-02 -0.873631
2019-11-06 16:40:58,965 train 100 1.933325e-02 -0.851227
2019-11-06 16:41:09,088 train 150 1.936203e-02 -0.795230
2019-11-06 16:41:19,193 train 200 1.945069e-02 -0.745270
2019-11-06 16:41:29,309 train 250 1.943805e-02 -0.711206
2019-11-06 16:41:39,443 train 300 1.943534e-02 -0.662716
2019-11-06 16:41:49,568 train 350 1.941263e-02 -0.686054
2019-11-06 16:41:59,705 train 400 1.944790e-02 -0.684403
2019-11-06 16:42:09,847 train 450 1.943497e-02 -0.665841
2019-11-06 16:42:20,002 train 500 1.945303e-02 -0.668508
2019-11-06 16:42:30,163 train 550 1.949015e-02 -0.666367
2019-11-06 16:42:40,315 train 600 1.950448e-02 -0.665978
2019-11-06 16:42:50,473 train 650 1.951486e-02 -0.669320
2019-11-06 16:43:00,659 train 700 1.949656e-02 -0.670339
2019-11-06 16:43:10,855 train 750 1.948424e-02 -0.668802
2019-11-06 16:43:20,800 train 800 1.948014e-02 -0.688521
2019-11-06 16:43:30,633 train 850 1.949682e-02 -0.690850
2019-11-06 16:43:33,577 training loss; R2: 1.948649e-02 -0.687837
2019-11-06 16:43:34,167 valid 000 1.846485e-02 -0.379673
2019-11-06 16:43:43,612 valid 050 2.138837e-02 -1.098693
2019-11-06 16:43:51,952 validation loss; R2: 2.125867e-02 -0.977244
2019-11-06 16:43:52,021 epoch 133 lr 1.000000e-05
2019-11-06 16:43:52,793 train 000 1.798515e-02 -0.482424
2019-11-06 16:44:02,579 train 050 1.918712e-02 -0.717109
2019-11-06 16:44:12,399 train 100 1.942072e-02 -0.551906
2019-11-06 16:44:22,229 train 150 1.933709e-02 -0.564224
2019-11-06 16:44:32,027 train 200 1.946232e-02 -0.548532
2019-11-06 16:44:41,841 train 250 1.947004e-02 -0.586422
2019-11-06 16:44:51,658 train 300 1.943994e-02 -0.612210
2019-11-06 16:45:01,479 train 350 1.936120e-02 -0.616957
2019-11-06 16:45:11,295 train 400 1.939218e-02 -0.635215
2019-11-06 16:45:21,112 train 450 1.942308e-02 -0.619346
2019-11-06 16:45:30,932 train 500 1.945086e-02 -0.668417
2019-11-06 16:45:40,751 train 550 1.945332e-02 -0.668274
2019-11-06 16:45:50,568 train 600 1.950114e-02 -0.713958
2019-11-06 16:46:00,395 train 650 1.949784e-02 -0.721182
2019-11-06 16:46:10,227 train 700 1.949046e-02 -0.722256
2019-11-06 16:46:20,056 train 750 1.949843e-02 -0.716982
2019-11-06 16:46:29,873 train 800 1.952246e-02 -0.706270
2019-11-06 16:46:39,693 train 850 1.952691e-02 -0.696723
2019-11-06 16:46:42,625 training loss; R2: 1.952673e-02 -0.691039
2019-11-06 16:46:43,240 valid 000 2.089064e-02 -0.084331
2019-11-06 16:46:52,673 valid 050 2.081867e-02 -0.637588
2019-11-06 16:47:00,985 validation loss; R2: 2.119603e-02 -0.652578
2019-11-06 16:47:01,049 epoch 134 lr 1.000000e-05
2019-11-06 16:47:01,783 train 000 1.795614e-02 -0.116724
2019-11-06 16:47:11,535 train 050 1.958443e-02 -0.693344
2019-11-06 16:47:21,291 train 100 1.957977e-02 -0.808821
2019-11-06 16:47:31,059 train 150 1.953579e-02 -0.740904
2019-11-06 16:47:40,840 train 200 1.957086e-02 -0.699054
2019-11-06 16:47:50,638 train 250 1.955817e-02 -0.686539
2019-11-06 16:48:00,442 train 300 1.954817e-02 -0.663864
2019-11-06 16:48:10,246 train 350 1.953733e-02 -0.658400
2019-11-06 16:48:20,052 train 400 1.949651e-02 -0.668780
2019-11-06 16:48:29,863 train 450 1.947027e-02 -0.668345
2019-11-06 16:48:39,682 train 500 1.949371e-02 -0.655718
2019-11-06 16:48:49,499 train 550 1.947737e-02 -0.648039
2019-11-06 16:48:59,315 train 600 1.947925e-02 -0.628337
2019-11-06 16:49:09,445 train 650 1.943116e-02 -0.701135
2019-11-06 16:49:19,613 train 700 1.943161e-02 -0.702229
2019-11-06 16:49:29,768 train 750 1.942672e-02 -0.690351
2019-11-06 16:49:39,933 train 800 1.940839e-02 -0.699579
2019-11-06 16:49:50,117 train 850 1.943204e-02 -0.698831
2019-11-06 16:49:53,148 training loss; R2: 1.943338e-02 -0.708392
2019-11-06 16:49:53,783 valid 000 1.886802e-02 -0.335122
2019-11-06 16:50:03,217 valid 050 2.081201e-02 -1.079404
2019-11-06 16:50:11,568 validation loss; R2: 2.111602e-02 -0.807655
2019-11-06 16:50:11,628 epoch 135 lr 1.000000e-05
2019-11-06 16:50:12,434 train 000 2.241312e-02 -0.209101
2019-11-06 16:50:22,559 train 050 1.995543e-02 -0.662683
2019-11-06 16:50:32,697 train 100 1.984687e-02 -0.759443
2019-11-06 16:50:42,857 train 150 1.965052e-02 -0.786172
2019-11-06 16:50:52,990 train 200 1.965940e-02 -0.805361
2019-11-06 16:51:03,151 train 250 1.958087e-02 -0.769199
2019-11-06 16:51:13,151 train 300 1.958102e-02 -0.763656
2019-11-06 16:51:22,952 train 350 1.960910e-02 -0.759545
2019-11-06 16:51:32,744 train 400 1.959885e-02 -0.722662
2019-11-06 16:51:42,542 train 450 1.956470e-02 -0.713240
2019-11-06 16:51:52,330 train 500 1.954148e-02 -0.745129
2019-11-06 16:52:02,131 train 550 1.953072e-02 -0.722809
2019-11-06 16:52:11,921 train 600 1.953560e-02 -0.736816
2019-11-06 16:52:21,714 train 650 1.952702e-02 -0.778786
2019-11-06 16:52:31,505 train 700 1.950987e-02 -0.784931
2019-11-06 16:52:41,295 train 750 1.946282e-02 -0.775472
2019-11-06 16:52:51,091 train 800 1.945948e-02 -0.765622
2019-11-06 16:53:00,885 train 850 1.946774e-02 -0.755860
2019-11-06 16:53:03,807 training loss; R2: 1.948712e-02 -0.747855
2019-11-06 16:53:04,506 valid 000 2.313383e-02 -1.432140
2019-11-06 16:53:13,890 valid 050 2.098271e-02 -0.690976
2019-11-06 16:53:22,330 validation loss; R2: 2.088136e-02 -0.653128
2019-11-06 16:53:22,397 epoch 136 lr 1.000000e-05
2019-11-06 16:53:23,206 train 000 2.330505e-02 -0.993010
2019-11-06 16:53:32,949 train 050 1.975104e-02 -0.581808
2019-11-06 16:53:42,726 train 100 1.969537e-02 -0.606453
2019-11-06 16:53:52,516 train 150 1.962492e-02 -0.564081
2019-11-06 16:54:02,311 train 200 1.943364e-02 -0.590705
2019-11-06 16:54:12,079 train 250 1.951800e-02 -0.580797
2019-11-06 16:54:21,908 train 300 1.954291e-02 -0.571380
2019-11-06 16:54:31,722 train 350 1.951232e-02 -0.585873
2019-11-06 16:54:41,547 train 400 1.956387e-02 -0.588512
2019-11-06 16:54:51,356 train 450 1.954118e-02 -0.583953
2019-11-06 16:55:01,180 train 500 1.954506e-02 -0.586559
2019-11-06 16:55:11,011 train 550 1.952465e-02 -0.594346
2019-11-06 16:55:20,819 train 600 1.951924e-02 -0.606325
2019-11-06 16:55:30,635 train 650 1.956803e-02 -0.614391
2019-11-06 16:55:40,448 train 700 1.956460e-02 -0.614451
2019-11-06 16:55:50,258 train 750 1.955904e-02 -0.727807
2019-11-06 16:56:00,064 train 800 1.956724e-02 -0.815840
2019-11-06 16:56:09,871 train 850 1.952800e-02 -0.804479
2019-11-06 16:56:12,806 training loss; R2: 1.952742e-02 -0.807710
2019-11-06 16:56:13,450 valid 000 2.501557e-02 -1.247756
2019-11-06 16:56:22,914 valid 050 2.136765e-02 -0.748544
2019-11-06 16:56:31,281 validation loss; R2: 2.166223e-02 -0.675374
2019-11-06 16:56:31,355 epoch 137 lr 1.000000e-05
2019-11-06 16:56:32,139 train 000 1.701711e-02 -0.882915
2019-11-06 16:56:42,188 train 050 1.950759e-02 -0.587316
2019-11-06 16:56:52,372 train 100 1.965412e-02 -0.744162
2019-11-06 16:57:02,238 train 150 1.940639e-02 -0.763546
2019-11-06 16:57:11,998 train 200 1.939288e-02 -0.768438
2019-11-06 16:57:21,763 train 250 1.940260e-02 -0.835458
2019-11-06 16:57:31,563 train 300 1.939471e-02 -0.808630
2019-11-06 16:57:41,360 train 350 1.940166e-02 -0.822140
2019-11-06 16:57:51,147 train 400 1.936403e-02 -0.786067
2019-11-06 16:58:00,942 train 450 1.934119e-02 -0.768409
2019-11-06 16:58:10,747 train 500 1.931164e-02 -0.782094
2019-11-06 16:58:20,575 train 550 1.930727e-02 -0.784540
2019-11-06 16:58:30,390 train 600 1.931203e-02 -0.769161
2019-11-06 16:58:40,201 train 650 1.930826e-02 -0.763311
2019-11-06 16:58:50,012 train 700 1.930899e-02 -0.761399
2019-11-06 16:58:59,839 train 750 1.934878e-02 -0.770971
2019-11-06 16:59:09,655 train 800 1.933803e-02 -0.881010
2019-11-06 16:59:19,441 train 850 1.938523e-02 -0.858186
2019-11-06 16:59:22,369 training loss; R2: 1.939343e-02 -0.852890
2019-11-06 16:59:23,023 valid 000 1.943058e-02 -0.706552
2019-11-06 16:59:32,458 valid 050 2.051393e-02 -0.825652
2019-11-06 16:59:40,771 validation loss; R2: 2.082115e-02 -0.687618
2019-11-06 16:59:40,837 epoch 138 lr 1.000000e-05
2019-11-06 16:59:41,563 train 000 1.741743e-02 -0.463367
2019-11-06 16:59:51,286 train 050 1.902985e-02 -0.762341
2019-11-06 17:00:01,044 train 100 1.935884e-02 -0.695737
2019-11-06 17:00:10,808 train 150 1.945148e-02 -0.632539
2019-11-06 17:00:20,567 train 200 1.954804e-02 -0.715797
2019-11-06 17:00:30,323 train 250 1.956338e-02 -1.137819
2019-11-06 17:00:40,077 train 300 1.952375e-02 -1.069137
2019-11-06 17:00:49,830 train 350 1.943910e-02 -1.085984
2019-11-06 17:00:59,627 train 400 1.947056e-02 -1.115505
2019-11-06 17:01:09,449 train 450 1.949571e-02 -1.086381
2019-11-06 17:01:19,227 train 500 1.944237e-02 -1.051848
2019-11-06 17:01:29,022 train 550 1.941625e-02 -1.030443
2019-11-06 17:01:38,817 train 600 1.942984e-02 -1.035650
2019-11-06 17:01:48,605 train 650 1.938632e-02 -1.034469
2019-11-06 17:01:58,406 train 700 1.937858e-02 -1.004128
2019-11-06 17:02:08,196 train 750 1.937431e-02 -0.972834
2019-11-06 17:02:17,984 train 800 1.938609e-02 -0.966242
2019-11-06 17:02:27,774 train 850 1.938705e-02 -0.953949
2019-11-06 17:02:30,697 training loss; R2: 1.938905e-02 -0.954553
2019-11-06 17:02:31,339 valid 000 1.821977e-02 -0.458262
2019-11-06 17:02:40,786 valid 050 2.115589e-02 -1.038026
2019-11-06 17:02:49,150 validation loss; R2: 2.114554e-02 -0.981018
2019-11-06 17:02:49,210 epoch 139 lr 1.000000e-05
2019-11-06 17:02:50,020 train 000 1.987247e-02 -1.134518
2019-11-06 17:02:59,759 train 050 1.993053e-02 -0.572506
2019-11-06 17:03:09,519 train 100 1.959885e-02 -0.730457
2019-11-06 17:03:19,267 train 150 1.954912e-02 -0.765417
2019-11-06 17:03:29,019 train 200 1.955679e-02 -0.717485
2019-11-06 17:03:38,783 train 250 1.956082e-02 -0.757705
2019-11-06 17:03:48,532 train 300 1.946047e-02 -0.748166
2019-11-06 17:03:58,291 train 350 1.951522e-02 -0.770111
2019-11-06 17:04:08,049 train 400 1.947581e-02 -0.742087
2019-11-06 17:04:17,816 train 450 1.941574e-02 -0.762046
2019-11-06 17:04:27,591 train 500 1.941210e-02 -0.733471
2019-11-06 17:04:37,378 train 550 1.940186e-02 -0.729133
2019-11-06 17:04:47,170 train 600 1.940510e-02 -0.707582
2019-11-06 17:04:56,955 train 650 1.937677e-02 -0.694509
2019-11-06 17:05:06,735 train 700 1.938979e-02 -0.687512
2019-11-06 17:05:16,511 train 750 1.941112e-02 -0.701555
2019-11-06 17:05:26,304 train 800 1.940764e-02 -0.698589
2019-11-06 17:05:36,092 train 850 1.940240e-02 -0.714285
2019-11-06 17:05:39,048 training loss; R2: 1.941700e-02 -0.711994
2019-11-06 17:05:39,704 valid 000 2.275507e-02 -0.014693
2019-11-06 17:05:49,136 valid 050 2.190663e-02 -1.026309
2019-11-06 17:05:57,491 validation loss; R2: 2.167996e-02 -1.131360
2019-11-06 17:05:57,575 epoch 140 lr 1.000000e-05
2019-11-06 17:05:58,379 train 000 1.847329e-02 -0.497855
2019-11-06 17:06:08,111 train 050 1.938238e-02 -0.494841
2019-11-06 17:06:17,874 train 100 1.896255e-02 -0.590116
2019-11-06 17:06:27,632 train 150 1.904923e-02 -0.642510
2019-11-06 17:06:37,399 train 200 1.912690e-02 -0.658140
2019-11-06 17:06:47,180 train 250 1.922660e-02 -0.667774
2019-11-06 17:06:56,969 train 300 1.919319e-02 -0.683356
2019-11-06 17:07:06,747 train 350 1.923943e-02 -0.684412
2019-11-06 17:07:16,528 train 400 1.925686e-02 -0.718829
2019-11-06 17:07:26,307 train 450 1.924085e-02 -0.720675
2019-11-06 17:07:36,085 train 500 1.921796e-02 -0.699202
2019-11-06 17:07:45,868 train 550 1.924365e-02 -0.678219
2019-11-06 17:07:55,646 train 600 1.923963e-02 -0.694793
2019-11-06 17:08:05,428 train 650 1.928907e-02 -0.708041
2019-11-06 17:08:15,208 train 700 1.928679e-02 -0.710456
2019-11-06 17:08:24,984 train 750 1.932156e-02 -0.707193
2019-11-06 17:08:34,768 train 800 1.936260e-02 -0.707804
2019-11-06 17:08:44,541 train 850 1.936557e-02 -0.703093
2019-11-06 17:08:47,457 training loss; R2: 1.938881e-02 -0.779731
2019-11-06 17:08:48,139 valid 000 1.971277e-02 -0.355354
2019-11-06 17:08:57,549 valid 050 2.100682e-02 -0.917057
2019-11-06 17:09:05,881 validation loss; R2: 2.119545e-02 -0.745410
2019-11-06 17:09:05,955 epoch 141 lr 1.000000e-05
2019-11-06 17:09:06,707 train 000 1.925216e-02 0.047161
2019-11-06 17:09:16,433 train 050 1.921781e-02 -0.812329
2019-11-06 17:09:26,180 train 100 1.948181e-02 -0.746526
2019-11-06 17:09:35,943 train 150 1.925390e-02 -0.746416
2019-11-06 17:09:45,696 train 200 1.934765e-02 -0.748611
2019-11-06 17:09:55,452 train 250 1.932439e-02 -0.786169
2019-11-06 17:10:05,211 train 300 1.938612e-02 -0.732674
2019-11-06 17:10:15,001 train 350 1.934616e-02 -0.758196
2019-11-06 17:10:24,800 train 400 1.930486e-02 -0.735173
2019-11-06 17:10:34,597 train 450 1.935237e-02 -0.738812
2019-11-06 17:10:44,380 train 500 1.935923e-02 -0.740361
2019-11-06 17:10:54,156 train 550 1.935985e-02 -0.717025
2019-11-06 17:11:03,938 train 600 1.937664e-02 -0.712332
2019-11-06 17:11:13,733 train 650 1.938413e-02 -0.704946
2019-11-06 17:11:23,521 train 700 1.938017e-02 -0.715618
2019-11-06 17:11:33,332 train 750 1.937258e-02 -0.718970
2019-11-06 17:11:43,144 train 800 1.937779e-02 -0.817336
2019-11-06 17:11:52,956 train 850 1.936732e-02 -0.829064
2019-11-06 17:11:55,892 training loss; R2: 1.935615e-02 -0.833123
2019-11-06 17:11:56,566 valid 000 2.191758e-02 -0.099175
2019-11-06 17:12:05,995 valid 050 2.222790e-02 -0.579552
2019-11-06 17:12:14,411 validation loss; R2: 2.209851e-02 -0.783339
2019-11-06 17:12:14,477 epoch 142 lr 1.000000e-05
2019-11-06 17:12:15,216 train 000 1.894187e-02 -0.493048
2019-11-06 17:12:24,979 train 050 1.920580e-02 -0.488221
2019-11-06 17:12:34,771 train 100 1.935372e-02 -0.492410
2019-11-06 17:12:44,549 train 150 1.931065e-02 -0.758662
2019-11-06 17:12:54,337 train 200 1.932451e-02 -0.726351
2019-11-06 17:13:04,119 train 250 1.935799e-02 -0.782984
2019-11-06 17:13:13,893 train 300 1.935732e-02 -0.837151
2019-11-06 17:13:23,689 train 350 1.934107e-02 -0.807013
2019-11-06 17:13:33,482 train 400 1.935945e-02 -0.830578
2019-11-06 17:13:43,273 train 450 1.936408e-02 -0.805782
2019-11-06 17:13:53,058 train 500 1.931898e-02 -0.804037
2019-11-06 17:14:02,850 train 550 1.926295e-02 -0.792805
2019-11-06 17:14:12,648 train 600 1.925184e-02 -0.775960
2019-11-06 17:14:22,435 train 650 1.926267e-02 -0.794063
2019-11-06 17:14:32,231 train 700 1.929131e-02 -0.772375
2019-11-06 17:14:42,019 train 750 1.929198e-02 -0.768702
2019-11-06 17:14:51,796 train 800 1.931507e-02 -0.774639
2019-11-06 17:15:01,578 train 850 1.930178e-02 -0.762299
2019-11-06 17:15:04,503 training loss; R2: 1.930908e-02 -0.759101
2019-11-06 17:15:05,199 valid 000 2.435700e-02 -0.389131
2019-11-06 17:15:14,629 valid 050 2.151764e-02 -0.874253
2019-11-06 17:15:22,939 validation loss; R2: 2.110827e-02 -0.727032
2019-11-06 17:15:23,004 epoch 143 lr 1.000000e-05
2019-11-06 17:15:23,792 train 000 1.847837e-02 -0.555370
2019-11-06 17:15:33,539 train 050 1.922464e-02 -0.783700
2019-11-06 17:15:43,300 train 100 1.922185e-02 -0.812552
2019-11-06 17:15:53,054 train 150 1.918599e-02 -0.758600
2019-11-06 17:16:02,815 train 200 1.922345e-02 -0.717953
2019-11-06 17:16:12,589 train 250 1.924592e-02 -0.708331
2019-11-06 17:16:22,370 train 300 1.931286e-02 -0.701996
2019-11-06 17:16:32,154 train 350 1.936953e-02 -0.707781
2019-11-06 17:16:41,931 train 400 1.933804e-02 -0.693033
2019-11-06 17:16:51,713 train 450 1.932172e-02 -0.889550
2019-11-06 17:17:01,489 train 500 1.934005e-02 -0.879818
2019-11-06 17:17:11,277 train 550 1.934738e-02 -0.874046
2019-11-06 17:17:21,075 train 600 1.939077e-02 -0.848423
2019-11-06 17:17:30,856 train 650 1.939897e-02 -0.816056
2019-11-06 17:17:40,644 train 700 1.939038e-02 -0.816175
2019-11-06 17:17:50,419 train 750 1.938199e-02 -0.804865
2019-11-06 17:18:00,209 train 800 1.936864e-02 -0.797866
2019-11-06 17:18:09,986 train 850 1.936777e-02 -0.805257
2019-11-06 17:18:12,941 training loss; R2: 1.937312e-02 -0.796770
2019-11-06 17:18:13,638 valid 000 2.167206e-02 -0.996289
2019-11-06 17:18:22,999 valid 050 2.203467e-02 -0.787105
2019-11-06 17:18:31,361 validation loss; R2: 2.195220e-02 -0.698691
2019-11-06 17:18:31,448 epoch 144 lr 1.000000e-05
2019-11-06 17:18:32,239 train 000 2.226766e-02 -0.407769
2019-11-06 17:18:42,002 train 050 1.933269e-02 -0.745173
2019-11-06 17:18:51,788 train 100 1.927507e-02 -0.829582
2019-11-06 17:19:01,583 train 150 1.937795e-02 -0.789989
2019-11-06 17:19:11,375 train 200 1.944095e-02 -0.815354
2019-11-06 17:19:21,158 train 250 1.940111e-02 -0.752452
2019-11-06 17:19:30,967 train 300 1.945184e-02 -0.742283
2019-11-06 17:19:40,783 train 350 1.942979e-02 -0.743605
2019-11-06 17:19:50,605 train 400 1.943236e-02 -0.732369
2019-11-06 17:20:00,419 train 450 1.941167e-02 -0.712811
2019-11-06 17:20:10,237 train 500 1.944132e-02 -0.708646
2019-11-06 17:20:20,054 train 550 1.940529e-02 -0.731783
2019-11-06 17:20:29,867 train 600 1.942439e-02 -0.736450
2019-11-06 17:20:39,676 train 650 1.939831e-02 -0.738354
2019-11-06 17:20:49,483 train 700 1.936816e-02 -0.728541
2019-11-06 17:20:59,296 train 750 1.935672e-02 -0.748536
2019-11-06 17:21:09,108 train 800 1.933592e-02 -0.732288
2019-11-06 17:21:18,926 train 850 1.933853e-02 -0.748813
2019-11-06 17:21:21,875 training loss; R2: 1.933077e-02 -0.749310
2019-11-06 17:21:22,574 valid 000 1.958205e-02 -0.452526
2019-11-06 17:21:32,085 valid 050 2.058871e-02 -0.651852
2019-11-06 17:21:40,492 validation loss; R2: 2.082096e-02 -0.773968
2019-11-06 17:21:40,569 epoch 145 lr 1.000000e-05
2019-11-06 17:21:41,341 train 000 1.683857e-02 -0.016589
2019-11-06 17:21:51,128 train 050 1.910629e-02 -0.647935
2019-11-06 17:22:00,950 train 100 1.914592e-02 -0.571024
2019-11-06 17:22:10,764 train 150 1.936399e-02 -0.621950
2019-11-06 17:22:20,578 train 200 1.946462e-02 -0.665447
2019-11-06 17:22:30,403 train 250 1.946400e-02 -0.646718
2019-11-06 17:22:40,232 train 300 1.949158e-02 -0.631323
2019-11-06 17:22:50,088 train 350 1.946615e-02 -0.648097
2019-11-06 17:22:59,953 train 400 1.941996e-02 -0.648892
2019-11-06 17:23:09,807 train 450 1.939894e-02 -0.677390
2019-11-06 17:23:19,637 train 500 1.938340e-02 -0.680691
2019-11-06 17:23:29,488 train 550 1.936177e-02 -1.421475
2019-11-06 17:23:39,341 train 600 1.940139e-02 -1.351111
2019-11-06 17:23:49,200 train 650 1.935375e-02 -1.293241
2019-11-06 17:23:59,050 train 700 1.932239e-02 -1.232125
2019-11-06 17:24:08,885 train 750 1.931360e-02 -1.199126
2019-11-06 17:24:18,746 train 800 1.930282e-02 -1.180256
2019-11-06 17:24:28,608 train 850 1.932847e-02 -1.148462
2019-11-06 17:24:31,582 training loss; R2: 1.933396e-02 -1.141447
2019-11-06 17:24:32,267 valid 000 2.364904e-02 -0.129017
2019-11-06 17:24:41,677 valid 050 2.141737e-02 -0.951424
2019-11-06 17:24:50,013 validation loss; R2: 2.102192e-02 -0.834910
2019-11-06 17:24:50,084 epoch 146 lr 1.000000e-05
2019-11-06 17:24:50,836 train 000 2.115068e-02 -0.167699
2019-11-06 17:25:00,644 train 050 1.949877e-02 -2.314144
2019-11-06 17:25:10,475 train 100 1.948548e-02 -1.386546
2019-11-06 17:25:20,336 train 150 1.936997e-02 -1.208827
2019-11-06 17:25:30,174 train 200 1.934698e-02 -1.049934
2019-11-06 17:25:40,011 train 250 1.937344e-02 -0.982265
2019-11-06 17:25:49,828 train 300 1.944267e-02 -0.911129
2019-11-06 17:25:59,687 train 350 1.945007e-02 -0.873724
2019-11-06 17:26:09,563 train 400 1.941993e-02 -0.831082
2019-11-06 17:26:19,429 train 450 1.937560e-02 -0.825968
2019-11-06 17:26:29,287 train 500 1.935265e-02 -0.852179
2019-11-06 17:26:39,150 train 550 1.937878e-02 -0.830811
2019-11-06 17:26:49,022 train 600 1.937493e-02 -0.835150
2019-11-06 17:26:58,865 train 650 1.939549e-02 -0.871980
2019-11-06 17:27:08,725 train 700 1.938990e-02 -0.859708
2019-11-06 17:27:18,593 train 750 1.939038e-02 -0.833264
2019-11-06 17:27:28,393 train 800 1.937724e-02 -0.816696
2019-11-06 17:27:38,186 train 850 1.935295e-02 -0.831761
2019-11-06 17:27:41,109 training loss; R2: 1.934762e-02 -3.623617
2019-11-06 17:27:41,766 valid 000 1.973451e-02 -1.892925
2019-11-06 17:27:51,207 valid 050 2.064132e-02 -1.074971
2019-11-06 17:27:59,545 validation loss; R2: 2.064036e-02 -0.921838
2019-11-06 17:27:59,605 epoch 147 lr 1.000000e-05
2019-11-06 17:28:00,344 train 000 2.128380e-02 -0.364375
2019-11-06 17:28:10,078 train 050 1.907776e-02 -0.800855
2019-11-06 17:28:19,837 train 100 1.907651e-02 -0.815823
2019-11-06 17:28:29,608 train 150 1.923078e-02 -0.725473
2019-11-06 17:28:39,364 train 200 1.929657e-02 -0.697655
2019-11-06 17:28:49,131 train 250 1.943780e-02 -0.692150
2019-11-06 17:28:58,895 train 300 1.951348e-02 -0.697936
2019-11-06 17:29:08,690 train 350 1.945316e-02 -0.691514
2019-11-06 17:29:18,481 train 400 1.943842e-02 -0.702761
2019-11-06 17:29:28,277 train 450 1.939903e-02 -0.698290
2019-11-06 17:29:38,086 train 500 1.938245e-02 -0.719751
2019-11-06 17:29:47,879 train 550 1.933374e-02 -0.722709
2019-11-06 17:29:57,679 train 600 1.932998e-02 -0.716499
2019-11-06 17:30:07,474 train 650 1.932424e-02 -0.741475
2019-11-06 17:30:17,268 train 700 1.930521e-02 -0.729621
2019-11-06 17:30:27,067 train 750 1.927807e-02 -0.748522
2019-11-06 17:30:36,881 train 800 1.927142e-02 -0.738993
2019-11-06 17:30:46,668 train 850 1.925531e-02 -0.728563
2019-11-06 17:30:49,595 training loss; R2: 1.925553e-02 -0.724287
2019-11-06 17:30:50,278 valid 000 2.145443e-02 -0.767928
2019-11-06 17:30:59,659 valid 050 2.133492e-02 -1.273195
2019-11-06 17:31:07,969 validation loss; R2: 2.131700e-02 -1.012821
2019-11-06 17:31:08,034 epoch 148 lr 1.000000e-05
2019-11-06 17:31:08,800 train 000 1.712625e-02 -0.526943
2019-11-06 17:31:18,550 train 050 1.918569e-02 -0.541432
2019-11-06 17:31:28,305 train 100 1.936111e-02 -0.670665
2019-11-06 17:31:38,063 train 150 1.922572e-02 -0.989411
2019-11-06 17:31:47,819 train 200 1.930257e-02 -0.886584
2019-11-06 17:31:57,576 train 250 1.934897e-02 -0.993010
2019-11-06 17:32:07,350 train 300 1.933325e-02 -0.939248
2019-11-06 17:32:17,139 train 350 1.931092e-02 -0.899090
2019-11-06 17:32:26,919 train 400 1.933661e-02 -0.885253
2019-11-06 17:32:36,699 train 450 1.933873e-02 -0.853118
2019-11-06 17:32:46,470 train 500 1.933768e-02 -0.825642
2019-11-06 17:32:56,239 train 550 1.931640e-02 -0.791303
2019-11-06 17:33:06,016 train 600 1.934289e-02 -0.777419
2019-11-06 17:33:15,779 train 650 1.935845e-02 -0.767463
2019-11-06 17:33:25,549 train 700 1.935985e-02 -0.769038
2019-11-06 17:33:35,323 train 750 1.935210e-02 -0.768878
2019-11-06 17:33:45,096 train 800 1.935530e-02 -0.751518
2019-11-06 17:33:54,872 train 850 1.934567e-02 -0.757719
2019-11-06 17:33:57,794 training loss; R2: 1.935586e-02 -0.755201
2019-11-06 17:33:58,420 valid 000 2.180680e-02 -0.019578
2019-11-06 17:34:07,829 valid 050 2.177530e-02 -1.124437
2019-11-06 17:34:16,134 validation loss; R2: 2.188463e-02 -1.037324
2019-11-06 17:34:16,198 epoch 149 lr 1.000000e-05
2019-11-06 17:34:16,956 train 000 1.827476e-02 -0.131652
2019-11-06 17:34:26,689 train 050 1.945584e-02 -0.556176
2019-11-06 17:34:36,414 train 100 1.953878e-02 -0.612062
2019-11-06 17:34:46,168 train 150 1.947370e-02 -0.713654
2019-11-06 17:34:55,930 train 200 1.933775e-02 -0.723754
2019-11-06 17:35:05,735 train 250 1.935545e-02 -0.672818
2019-11-06 17:35:15,533 train 300 1.940371e-02 -0.699479
2019-11-06 17:35:25,327 train 350 1.937991e-02 -0.689065
2019-11-06 17:35:35,129 train 400 1.930392e-02 -0.687016
2019-11-06 17:35:44,931 train 450 1.930440e-02 -0.668221
2019-11-06 17:35:54,738 train 500 1.930499e-02 -0.667490
2019-11-06 17:36:04,533 train 550 1.928192e-02 -0.672113
2019-11-06 17:36:14,335 train 600 1.927497e-02 -0.695262
2019-11-06 17:36:24,137 train 650 1.926343e-02 -0.702017
2019-11-06 17:36:33,942 train 700 1.928877e-02 -0.718647
2019-11-06 17:36:43,733 train 750 1.929249e-02 -0.721308
2019-11-06 17:36:53,540 train 800 1.929234e-02 -0.724012
2019-11-06 17:37:03,334 train 850 1.927797e-02 -0.713742
2019-11-06 17:37:06,263 training loss; R2: 1.929261e-02 -0.717935
2019-11-06 17:37:06,928 valid 000 2.032254e-02 -0.968019
2019-11-06 17:37:16,322 valid 050 2.098717e-02 -0.689333
2019-11-06 17:37:24,644 validation loss; R2: 2.119455e-02 -6.553305
2019-11-06 17:37:24,709 epoch 150 lr 1.000000e-05
2019-11-06 17:37:25,500 train 000 1.943723e-02 -0.368828
2019-11-06 17:37:35,232 train 050 1.921733e-02 -0.688334
2019-11-06 17:37:44,983 train 100 1.903347e-02 -0.894229
2019-11-06 17:37:54,752 train 150 1.898410e-02 -2.600782
2019-11-06 17:38:04,507 train 200 1.909337e-02 -2.084660
2019-11-06 17:38:14,300 train 250 1.917759e-02 -1.806166
2019-11-06 17:38:24,103 train 300 1.920519e-02 -1.645327
2019-11-06 17:38:33,889 train 350 1.922967e-02 -1.500669
2019-11-06 17:38:43,678 train 400 1.923549e-02 -1.407078
2019-11-06 17:38:53,472 train 450 1.922740e-02 -1.368471
2019-11-06 17:39:03,272 train 500 1.920629e-02 -1.325856
2019-11-06 17:39:13,073 train 550 1.919132e-02 -1.265359
2019-11-06 17:39:22,881 train 600 1.922054e-02 -1.266463
2019-11-06 17:39:32,682 train 650 1.926443e-02 -1.219131
2019-11-06 17:39:42,485 train 700 1.928009e-02 -1.166957
2019-11-06 17:39:52,283 train 750 1.928533e-02 -1.126283
2019-11-06 17:40:02,136 train 800 1.928603e-02 -1.099066
2019-11-06 17:40:11,947 train 850 1.926555e-02 -1.887958
2019-11-06 17:40:14,878 training loss; R2: 1.926815e-02 -1.863840
2019-11-06 17:40:15,580 valid 000 2.135685e-02 -0.066229
2019-11-06 17:40:24,943 valid 050 2.021153e-02 -1.005300
2019-11-06 17:40:33,282 validation loss; R2: 2.024752e-02 -0.889067
2019-11-06 17:40:33,356 epoch 151 lr 1.000000e-05
2019-11-06 17:40:34,094 train 000 1.870492e-02 -0.285144
2019-11-06 17:40:43,832 train 050 1.922733e-02 -0.706054
2019-11-06 17:40:53,588 train 100 1.919682e-02 -0.519012
2019-11-06 17:41:03,344 train 150 1.907273e-02 -0.555565
2019-11-06 17:41:13,118 train 200 1.909802e-02 -0.532796
2019-11-06 17:41:22,921 train 250 1.914874e-02 -0.560392
2019-11-06 17:41:32,715 train 300 1.911954e-02 -0.595239
2019-11-06 17:41:42,506 train 350 1.913250e-02 -0.634575
2019-11-06 17:41:52,300 train 400 1.908152e-02 -0.646687
2019-11-06 17:42:02,083 train 450 1.909054e-02 -0.650391
2019-11-06 17:42:11,862 train 500 1.912897e-02 -0.663407
2019-11-06 17:42:21,655 train 550 1.914847e-02 -0.689674
2019-11-06 17:42:31,452 train 600 1.917101e-02 -0.676378
2019-11-06 17:42:41,253 train 650 1.918230e-02 -0.660830
2019-11-06 17:42:51,052 train 700 1.919285e-02 -0.653486
2019-11-06 17:43:00,849 train 750 1.919482e-02 -0.656677
2019-11-06 17:43:10,650 train 800 1.915895e-02 -0.659464
2019-11-06 17:43:20,453 train 850 1.915731e-02 -0.661537
2019-11-06 17:43:23,378 training loss; R2: 1.916313e-02 -0.659092
2019-11-06 17:43:23,979 valid 000 1.929077e-02 -0.565833
2019-11-06 17:43:33,420 valid 050 2.208890e-02 -1.185851
2019-11-06 17:43:41,728 validation loss; R2: 2.167507e-02 -1.037996
2019-11-06 17:43:41,786 epoch 152 lr 1.000000e-05
2019-11-06 17:43:42,539 train 000 1.956601e-02 -0.158826
2019-11-06 17:43:52,304 train 050 1.900307e-02 -0.694753
2019-11-06 17:44:02,092 train 100 1.902103e-02 -0.748356
2019-11-06 17:44:11,881 train 150 1.902379e-02 -0.789772
2019-11-06 17:44:21,666 train 200 1.923554e-02 -0.852945
2019-11-06 17:44:31,452 train 250 1.922585e-02 -0.856157
2019-11-06 17:44:41,246 train 300 1.925658e-02 -0.825230
2019-11-06 17:44:51,061 train 350 1.920133e-02 -0.793206
2019-11-06 17:45:00,881 train 400 1.919619e-02 -0.764375
2019-11-06 17:45:10,698 train 450 1.921956e-02 -0.765501
2019-11-06 17:45:20,515 train 500 1.921400e-02 -0.754147
2019-11-06 17:45:30,334 train 550 1.918344e-02 -0.734595
2019-11-06 17:45:40,148 train 600 1.918772e-02 -0.724688
2019-11-06 17:45:49,955 train 650 1.919098e-02 -0.720079
2019-11-06 17:45:59,763 train 700 1.918940e-02 -0.713491
2019-11-06 17:46:09,571 train 750 1.919435e-02 -0.725897
2019-11-06 17:46:19,380 train 800 1.921596e-02 -0.740466
2019-11-06 17:46:29,185 train 850 1.922251e-02 -0.758137
2019-11-06 17:46:32,140 training loss; R2: 1.923405e-02 -0.758782
2019-11-06 17:46:32,776 valid 000 2.173625e-02 -7.430557
2019-11-06 17:46:42,183 valid 050 2.144495e-02 -0.900667
2019-11-06 17:46:50,498 validation loss; R2: 2.118129e-02 -0.833419
2019-11-06 17:46:50,582 epoch 153 lr 1.000000e-05
2019-11-06 17:46:51,409 train 000 1.688665e-02 -1.537818
2019-11-06 17:47:01,557 train 050 1.885517e-02 -0.502981
2019-11-06 17:47:11,702 train 100 1.918382e-02 -0.587704
2019-11-06 17:47:21,850 train 150 1.917086e-02 -0.569033
2019-11-06 17:47:31,987 train 200 1.924358e-02 -0.667322
2019-11-06 17:47:42,152 train 250 1.920014e-02 -0.697232
2019-11-06 17:47:52,336 train 300 1.920977e-02 -0.688940
2019-11-06 17:48:02,522 train 350 1.922053e-02 -0.671960
2019-11-06 17:48:12,718 train 400 1.919865e-02 -0.674178
2019-11-06 17:48:22,903 train 450 1.918913e-02 -0.685526
2019-11-06 17:48:33,087 train 500 1.919154e-02 -0.686307
2019-11-06 17:48:42,951 train 550 1.919657e-02 -0.670605
2019-11-06 17:48:52,758 train 600 1.917918e-02 -3.238815
2019-11-06 17:49:02,564 train 650 1.922183e-02 -3.050173
2019-11-06 17:49:12,366 train 700 1.922323e-02 -2.874871
2019-11-06 17:49:22,169 train 750 1.921368e-02 -2.741239
2019-11-06 17:49:31,963 train 800 1.918859e-02 -2.614585
2019-11-06 17:49:41,764 train 850 1.918254e-02 -2.502293
2019-11-06 17:49:44,689 training loss; R2: 1.917606e-02 -2.464506
2019-11-06 17:49:45,288 valid 000 1.854704e-02 -0.029061
2019-11-06 17:49:54,666 valid 050 2.053556e-02 -0.608097
2019-11-06 17:50:02,968 validation loss; R2: 2.074733e-02 -0.753582
2019-11-06 17:50:03,059 epoch 154 lr 1.000000e-05
2019-11-06 17:50:03,798 train 000 2.147868e-02 -0.227808
2019-11-06 17:50:13,561 train 050 1.874672e-02 -0.680811
2019-11-06 17:50:23,353 train 100 1.885949e-02 -0.644573
2019-11-06 17:50:33,144 train 150 1.884461e-02 -0.626845
2019-11-06 17:50:42,927 train 200 1.895335e-02 -0.615906
2019-11-06 17:50:52,721 train 250 1.905227e-02 -0.571450
2019-11-06 17:51:02,538 train 300 1.909216e-02 -0.586999
2019-11-06 17:51:12,361 train 350 1.912769e-02 -0.613509
2019-11-06 17:51:22,196 train 400 1.915825e-02 -0.595416
2019-11-06 17:51:32,019 train 450 1.916753e-02 -0.616361
2019-11-06 17:51:41,830 train 500 1.912562e-02 -0.637084
2019-11-06 17:51:51,649 train 550 1.918121e-02 -0.643865
2019-11-06 17:52:01,489 train 600 1.917139e-02 -0.648174
2019-11-06 17:52:11,308 train 650 1.920135e-02 -0.635517
2019-11-06 17:52:21,133 train 700 1.920947e-02 -0.643471
2019-11-06 17:52:30,939 train 750 1.918277e-02 -0.633623
2019-11-06 17:52:40,752 train 800 1.917061e-02 -0.630614
2019-11-06 17:52:50,575 train 850 1.915234e-02 -0.628463
2019-11-06 17:52:53,511 training loss; R2: 1.916013e-02 -0.633933
2019-11-06 17:52:54,144 valid 000 1.915777e-02 -0.808573
2019-11-06 17:53:03,532 valid 050 2.095012e-02 -0.707601
2019-11-06 17:53:11,887 validation loss; R2: 2.081002e-02 -1.764037
2019-11-06 17:53:11,953 epoch 155 lr 1.000000e-05
2019-11-06 17:53:12,719 train 000 1.733332e-02 -0.462796
2019-11-06 17:53:22,479 train 050 1.885095e-02 -0.689162
2019-11-06 17:53:32,263 train 100 1.900195e-02 -0.569195
2019-11-06 17:53:42,051 train 150 1.895960e-02 -0.654726
2019-11-06 17:53:51,841 train 200 1.916822e-02 -0.630517
2019-11-06 17:54:01,641 train 250 1.906792e-02 -0.620057
2019-11-06 17:54:11,458 train 300 1.912305e-02 -0.686332
2019-11-06 17:54:21,276 train 350 1.917727e-02 -0.660875
2019-11-06 17:54:31,083 train 400 1.920123e-02 -0.667139
2019-11-06 17:54:40,895 train 450 1.923070e-02 -0.650178
2019-11-06 17:54:50,703 train 500 1.920429e-02 -0.677631
2019-11-06 17:55:00,511 train 550 1.916669e-02 -0.688930
2019-11-06 17:55:10,327 train 600 1.916126e-02 -0.689712
2019-11-06 17:55:20,163 train 650 1.919185e-02 -0.681923
2019-11-06 17:55:29,981 train 700 1.917901e-02 -0.677997
2019-11-06 17:55:39,810 train 750 1.916852e-02 -0.697366
2019-11-06 17:55:49,636 train 800 1.915697e-02 -0.705247
2019-11-06 17:55:59,473 train 850 1.918111e-02 -0.722970
2019-11-06 17:56:02,453 training loss; R2: 1.918706e-02 -0.733384
2019-11-06 17:56:03,152 valid 000 2.182073e-02 -0.086802
2019-11-06 17:56:12,597 valid 050 2.241011e-02 -1.019346
2019-11-06 17:56:20,948 validation loss; R2: 2.213755e-02 -1.107492
2019-11-06 17:56:21,018 epoch 156 lr 1.000000e-05
2019-11-06 17:56:21,767 train 000 1.575536e-02 -0.907567
2019-11-06 17:56:31,917 train 050 1.947691e-02 -0.629225
2019-11-06 17:56:42,086 train 100 1.948341e-02 -0.584922
2019-11-06 17:56:52,267 train 150 1.937267e-02 -0.667247
2019-11-06 17:57:02,412 train 200 1.931597e-02 -1.004248
2019-11-06 17:57:12,577 train 250 1.927399e-02 -1.278828
2019-11-06 17:57:22,733 train 300 1.930274e-02 -1.170997
2019-11-06 17:57:32,890 train 350 1.926524e-02 -1.088759
2019-11-06 17:57:43,054 train 400 1.924564e-02 -1.058057
2019-11-06 17:57:53,230 train 450 1.925340e-02 -1.046432
2019-11-06 17:58:03,411 train 500 1.923102e-02 -0.992646
2019-11-06 17:58:13,594 train 550 1.920035e-02 -0.958605
2019-11-06 17:58:23,776 train 600 1.923597e-02 -0.957622
2019-11-06 17:58:33,971 train 650 1.921881e-02 -0.936745
2019-11-06 17:58:44,120 train 700 1.923183e-02 -0.911254
2019-11-06 17:58:54,253 train 750 1.924101e-02 -0.886843
2019-11-06 17:59:04,382 train 800 1.925860e-02 -0.868460
2019-11-06 17:59:14,511 train 850 1.924985e-02 -0.841416
2019-11-06 17:59:17,530 training loss; R2: 1.923665e-02 -0.837869
2019-11-06 17:59:18,178 valid 000 1.859826e-02 -1.228765
2019-11-06 17:59:27,601 valid 050 2.091719e-02 -0.671145
2019-11-06 17:59:35,930 validation loss; R2: 2.120978e-02 -0.795948
2019-11-06 17:59:36,000 epoch 157 lr 1.000000e-05
2019-11-06 17:59:36,749 train 000 1.917840e-02 -0.178128
2019-11-06 17:59:46,817 train 050 1.887099e-02 -0.590230
2019-11-06 17:59:56,917 train 100 1.900736e-02 -0.603853
2019-11-06 18:00:07,037 train 150 1.903395e-02 -0.593990
2019-11-06 18:00:17,144 train 200 1.915767e-02 -0.654432
2019-11-06 18:00:27,248 train 250 1.918005e-02 -0.679114
2019-11-06 18:00:37,370 train 300 1.919771e-02 -0.664138
2019-11-06 18:00:47,514 train 350 1.919461e-02 -0.636635
2019-11-06 18:00:57,650 train 400 1.920753e-02 -0.611829
2019-11-06 18:01:07,771 train 450 1.920480e-02 -0.629713
2019-11-06 18:01:17,903 train 500 1.920699e-02 -0.625744
2019-11-06 18:01:28,041 train 550 1.919296e-02 -0.721168
2019-11-06 18:01:38,169 train 600 1.922799e-02 -0.707174
2019-11-06 18:01:48,303 train 650 1.921478e-02 -0.719898
2019-11-06 18:01:58,442 train 700 1.920844e-02 -0.735121
2019-11-06 18:02:08,565 train 750 1.918509e-02 -0.750691
2019-11-06 18:02:18,701 train 800 1.918932e-02 -0.755567
2019-11-06 18:02:28,828 train 850 1.919916e-02 -0.735147
2019-11-06 18:02:31,861 training loss; R2: 1.919322e-02 -0.733561
2019-11-06 18:02:32,548 valid 000 1.879533e-02 -0.345834
2019-11-06 18:02:41,904 valid 050 2.146034e-02 -1.035016
2019-11-06 18:02:50,230 validation loss; R2: 2.126191e-02 -1.008631
2019-11-06 18:02:50,298 epoch 158 lr 1.000000e-05
2019-11-06 18:02:51,073 train 000 1.650465e-02 -1.406923
2019-11-06 18:03:01,161 train 050 1.911860e-02 -0.507398
2019-11-06 18:03:11,272 train 100 1.919798e-02 -0.557600
2019-11-06 18:03:21,361 train 150 1.913351e-02 -0.604819
2019-11-06 18:03:31,474 train 200 1.921458e-02 -0.615155
2019-11-06 18:03:41,626 train 250 1.918678e-02 -0.631172
2019-11-06 18:03:51,776 train 300 1.914661e-02 -0.643336
2019-11-06 18:04:01,923 train 350 1.914461e-02 -0.678076
2019-11-06 18:04:12,060 train 400 1.914015e-02 -0.683631
2019-11-06 18:04:22,191 train 450 1.911776e-02 -0.738141
2019-11-06 18:04:32,343 train 500 1.910965e-02 -0.720705
2019-11-06 18:04:42,472 train 550 1.908993e-02 -0.724326
2019-11-06 18:04:52,606 train 600 1.909431e-02 -0.726828
2019-11-06 18:05:02,757 train 650 1.909358e-02 -0.775567
2019-11-06 18:05:12,889 train 700 1.910582e-02 -0.780018
2019-11-06 18:05:23,021 train 750 1.909076e-02 -0.784245
2019-11-06 18:05:33,141 train 800 1.907794e-02 -0.799114
2019-11-06 18:05:43,277 train 850 1.908808e-02 -0.798142
2019-11-06 18:05:46,306 training loss; R2: 1.910000e-02 -0.794834
2019-11-06 18:05:46,879 valid 000 2.301691e-02 -0.377786
2019-11-06 18:05:56,338 valid 050 2.221452e-02 -0.989886
2019-11-06 18:06:04,678 validation loss; R2: 2.218357e-02 -0.996038
2019-11-06 18:06:04,746 epoch 159 lr 1.000000e-05
2019-11-06 18:06:05,570 train 000 2.196020e-02 -0.782146
2019-11-06 18:06:15,658 train 050 1.943701e-02 -0.665421
2019-11-06 18:06:25,763 train 100 1.945735e-02 -0.811794
2019-11-06 18:06:35,868 train 150 1.926955e-02 -1.002457
2019-11-06 18:06:45,926 train 200 1.911124e-02 -0.941576
2019-11-06 18:06:55,747 train 250 1.915001e-02 -0.889979
2019-11-06 18:07:05,582 train 300 1.910899e-02 -0.855316
2019-11-06 18:07:15,401 train 350 1.912211e-02 -0.827397
2019-11-06 18:07:25,235 train 400 1.909454e-02 -0.793915
2019-11-06 18:07:35,057 train 450 1.908955e-02 -0.809026
2019-11-06 18:07:44,879 train 500 1.906480e-02 -0.797806
2019-11-06 18:07:54,684 train 550 1.908840e-02 -0.796350
2019-11-06 18:08:04,508 train 600 1.908675e-02 -0.785317
2019-11-06 18:08:14,324 train 650 1.913314e-02 -0.771836
2019-11-06 18:08:24,138 train 700 1.914391e-02 -0.782586
2019-11-06 18:08:33,958 train 750 1.914388e-02 -0.766071
2019-11-06 18:08:43,778 train 800 1.916109e-02 -0.757826
2019-11-06 18:08:53,598 train 850 1.914112e-02 -0.752068
2019-11-06 18:08:56,530 training loss; R2: 1.913725e-02 -0.751452
2019-11-06 18:08:57,224 valid 000 1.835911e-02 -0.991363
2019-11-06 18:09:06,632 valid 050 2.128642e-02 -1.022927
2019-11-06 18:09:14,976 validation loss; R2: 2.111046e-02 -1.018111
2019-11-06 18:09:15,042 epoch 160 lr 1.000000e-05
2019-11-06 18:09:15,818 train 000 1.708707e-02 -1.227598
2019-11-06 18:09:25,576 train 050 1.927438e-02 -0.640336
2019-11-06 18:09:35,375 train 100 1.939921e-02 -0.742527
2019-11-06 18:09:45,192 train 150 1.929731e-02 -0.962308
2019-11-06 18:09:55,017 train 200 1.938632e-02 -0.872120
2019-11-06 18:10:04,829 train 250 1.938368e-02 -0.799512
2019-11-06 18:10:14,655 train 300 1.925889e-02 -0.760490
2019-11-06 18:10:24,469 train 350 1.921821e-02 -0.777238
2019-11-06 18:10:34,284 train 400 1.918246e-02 -0.798160
2019-11-06 18:10:44,102 train 450 1.921695e-02 -0.810379
2019-11-06 18:10:53,901 train 500 1.917620e-02 -0.855287
2019-11-06 18:11:03,702 train 550 1.916687e-02 -0.837914
2019-11-06 18:11:13,497 train 600 1.914877e-02 -0.842383
2019-11-06 18:11:23,638 train 650 1.918044e-02 -0.819798
2019-11-06 18:11:33,788 train 700 1.915766e-02 -0.793562
2019-11-06 18:11:43,951 train 750 1.913484e-02 -0.789746
2019-11-06 18:11:54,097 train 800 1.914017e-02 -0.770014
2019-11-06 18:12:04,270 train 850 1.914361e-02 -0.765201
2019-11-06 18:12:07,311 training loss; R2: 1.913903e-02 -0.761137
2019-11-06 18:12:07,963 valid 000 2.365127e-02 -0.190586
2019-11-06 18:12:17,375 valid 050 2.148044e-02 -0.984811
2019-11-06 18:12:25,690 validation loss; R2: 2.121702e-02 -1.158102
2019-11-06 18:12:25,773 epoch 161 lr 1.000000e-05
2019-11-06 18:12:26,592 train 000 1.550513e-02 -0.406850
2019-11-06 18:12:36,338 train 050 1.870597e-02 -0.768594
2019-11-06 18:12:46,118 train 100 1.910978e-02 -0.858816
2019-11-06 18:12:55,907 train 150 1.905674e-02 -2.257047
2019-11-06 18:13:05,676 train 200 1.901393e-02 -1.959996
2019-11-06 18:13:15,458 train 250 1.906301e-02 -1.716476
2019-11-06 18:13:25,240 train 300 1.901829e-02 -1.523332
2019-11-06 18:13:35,007 train 350 1.899414e-02 -1.385252
2019-11-06 18:13:44,780 train 400 1.900901e-02 -1.281657
2019-11-06 18:13:54,551 train 450 1.907174e-02 -1.237970
2019-11-06 18:14:04,332 train 500 1.903486e-02 -1.196253
2019-11-06 18:14:14,105 train 550 1.899781e-02 -1.174444
2019-11-06 18:14:23,859 train 600 1.898059e-02 -1.145946
2019-11-06 18:14:33,622 train 650 1.896824e-02 -1.110285
2019-11-06 18:14:43,395 train 700 1.898242e-02 -1.162476
2019-11-06 18:14:53,152 train 750 1.897425e-02 -1.116053
2019-11-06 18:15:02,926 train 800 1.898656e-02 -1.077568
2019-11-06 18:15:12,694 train 850 1.900441e-02 -1.132036
2019-11-06 18:15:15,617 training loss; R2: 1.903142e-02 -1.121693
2019-11-06 18:15:16,325 valid 000 2.123562e-02 -0.817124
2019-11-06 18:15:25,675 valid 050 2.109983e-02 -1.641617
2019-11-06 18:15:34,093 validation loss; R2: 2.097974e-02 -1.380621
2019-11-06 18:15:34,158 epoch 162 lr 1.000000e-05
2019-11-06 18:15:34,901 train 000 1.942564e-02 -0.302484
2019-11-06 18:15:44,639 train 050 1.865127e-02 -0.869702
2019-11-06 18:15:54,388 train 100 1.869255e-02 -0.821648
2019-11-06 18:16:04,166 train 150 1.879102e-02 -0.928035
2019-11-06 18:16:13,949 train 200 1.881533e-02 -0.847814
2019-11-06 18:16:23,732 train 250 1.882061e-02 -0.822334
2019-11-06 18:16:33,522 train 300 1.891794e-02 -0.793906
2019-11-06 18:16:43,316 train 350 1.893232e-02 -0.771269
2019-11-06 18:16:53,115 train 400 1.892056e-02 -0.789027
2019-11-06 18:17:02,919 train 450 1.894490e-02 -0.796966
2019-11-06 18:17:12,714 train 500 1.895703e-02 -0.812823
2019-11-06 18:17:22,508 train 550 1.899165e-02 -0.778296
2019-11-06 18:17:32,295 train 600 1.901657e-02 -0.773688
2019-11-06 18:17:42,085 train 650 1.900047e-02 -0.752335
2019-11-06 18:17:51,895 train 700 1.900147e-02 -0.731315
2019-11-06 18:18:01,715 train 750 1.900959e-02 -0.726073
2019-11-06 18:18:11,528 train 800 1.902218e-02 -0.716048
2019-11-06 18:18:21,335 train 850 1.905797e-02 -0.716866
2019-11-06 18:18:24,263 training loss; R2: 1.906542e-02 -0.716376
2019-11-06 18:18:24,941 valid 000 1.878439e-02 -6.416011
2019-11-06 18:18:34,375 valid 050 2.107358e-02 -1.216487
2019-11-06 18:18:42,684 validation loss; R2: 2.115175e-02 -2.009369
2019-11-06 18:18:42,752 epoch 163 lr 1.000000e-05
2019-11-06 18:18:43,483 train 000 2.346883e-02 -0.004562
2019-11-06 18:18:53,246 train 050 1.910130e-02 -0.832100
2019-11-06 18:19:03,030 train 100 1.901888e-02 -0.646448
2019-11-06 18:19:12,812 train 150 1.890308e-02 -0.729607
2019-11-06 18:19:22,601 train 200 1.897281e-02 -0.679581
2019-11-06 18:19:32,397 train 250 1.900559e-02 -0.719194
2019-11-06 18:19:42,191 train 300 1.907199e-02 -0.733159
2019-11-06 18:19:51,981 train 350 1.909695e-02 -0.711848
2019-11-06 18:20:01,780 train 400 1.910871e-02 -0.705492
2019-11-06 18:20:11,571 train 450 1.908397e-02 -0.687269
2019-11-06 18:20:21,371 train 500 1.906974e-02 -0.667752
2019-11-06 18:20:31,170 train 550 1.910837e-02 -0.684891
2019-11-06 18:20:40,974 train 600 1.906840e-02 -0.680024
2019-11-06 18:20:51,132 train 650 1.906458e-02 -0.679675
2019-11-06 18:21:01,293 train 700 1.906619e-02 -0.673099
2019-11-06 18:21:11,441 train 750 1.903138e-02 -2.632991
2019-11-06 18:21:21,596 train 800 1.900407e-02 -2.571639
2019-11-06 18:21:31,758 train 850 1.901670e-02 -2.444199
2019-11-06 18:21:34,805 training loss; R2: 1.902520e-02 -2.420017
2019-11-06 18:21:35,449 valid 000 2.226350e-02 -0.951206
2019-11-06 18:21:44,923 valid 050 2.023795e-02 -0.723043
2019-11-06 18:21:53,245 validation loss; R2: 2.049665e-02 -1.825811
2019-11-06 18:21:53,324 epoch 164 lr 1.000000e-05
2019-11-06 18:21:54,122 train 000 1.871737e-02 -0.497686
2019-11-06 18:22:04,231 train 050 1.913492e-02 -0.770891
2019-11-06 18:22:14,367 train 100 1.899672e-02 -0.720259
2019-11-06 18:22:24,523 train 150 1.908341e-02 -0.816163
2019-11-06 18:22:34,473 train 200 1.897949e-02 -0.802890
2019-11-06 18:22:44,244 train 250 1.905323e-02 -0.985348
2019-11-06 18:22:54,017 train 300 1.909295e-02 -0.929087
2019-11-06 18:23:03,773 train 350 1.909839e-02 -0.891225
2019-11-06 18:23:13,543 train 400 1.907994e-02 -0.865123
2019-11-06 18:23:23,301 train 450 1.903565e-02 -17.957033
2019-11-06 18:23:33,058 train 500 1.905523e-02 -16.258711
2019-11-06 18:23:42,820 train 550 1.905315e-02 -14.839570
2019-11-06 18:23:52,575 train 600 1.902556e-02 -14.136066
2019-11-06 18:24:02,334 train 650 1.902962e-02 -13.110234
2019-11-06 18:24:12,093 train 700 1.900017e-02 -12.231931
2019-11-06 18:24:21,844 train 750 1.901003e-02 -11.469982
2019-11-06 18:24:31,604 train 800 1.900821e-02 -10.792802
2019-11-06 18:24:41,364 train 850 1.903028e-02 -10.197699
2019-11-06 18:24:44,279 training loss; R2: 1.903826e-02 -10.035818
2019-11-06 18:24:44,960 valid 000 1.795281e-02 -0.891717
2019-11-06 18:24:54,342 valid 050 1.978519e-02 -0.831461
2019-11-06 18:25:02,712 validation loss; R2: 1.981571e-02 -0.712244
2019-11-06 18:25:02,779 epoch 165 lr 1.000000e-05
2019-11-06 18:25:03,566 train 000 1.714092e-02 -0.167147
2019-11-06 18:25:13,256 train 050 1.927788e-02 -0.977087
2019-11-06 18:25:22,960 train 100 1.930388e-02 -0.909537
2019-11-06 18:25:32,689 train 150 1.922946e-02 -0.770616
2019-11-06 18:25:42,429 train 200 1.928196e-02 -0.713097
2019-11-06 18:25:52,179 train 250 1.927504e-02 -0.676214
2019-11-06 18:26:01,940 train 300 1.921837e-02 -0.700983
2019-11-06 18:26:11,697 train 350 1.915931e-02 -0.748862
2019-11-06 18:26:21,459 train 400 1.911288e-02 -0.748580
2019-11-06 18:26:31,215 train 450 1.913663e-02 -0.778545
2019-11-06 18:26:40,974 train 500 1.911220e-02 -0.826343
2019-11-06 18:26:50,736 train 550 1.910153e-02 -0.817486
2019-11-06 18:27:00,507 train 600 1.911480e-02 -0.803592
2019-11-06 18:27:10,314 train 650 1.911508e-02 -0.785418
2019-11-06 18:27:20,120 train 700 1.911226e-02 -0.770312
2019-11-06 18:27:29,923 train 750 1.911134e-02 -0.767865
2019-11-06 18:27:39,733 train 800 1.907725e-02 -0.755361
2019-11-06 18:27:49,528 train 850 1.908068e-02 -0.748529
2019-11-06 18:27:52,451 training loss; R2: 1.907975e-02 -0.752333
2019-11-06 18:27:53,127 valid 000 2.051099e-02 -1.467289
2019-11-06 18:28:02,525 valid 050 2.111724e-02 -0.677642
2019-11-06 18:28:10,886 validation loss; R2: 2.082684e-02 -0.731418
2019-11-06 18:28:10,952 epoch 166 lr 1.000000e-05
2019-11-06 18:28:11,738 train 000 1.701882e-02 -0.474156
2019-11-06 18:28:21,482 train 050 1.919054e-02 -0.533212
2019-11-06 18:28:31,241 train 100 1.909921e-02 -0.547156
2019-11-06 18:28:41,030 train 150 1.902682e-02 -0.556880
2019-11-06 18:28:50,838 train 200 1.892683e-02 -0.570094
2019-11-06 18:29:00,636 train 250 1.897994e-02 -0.626473
2019-11-06 18:29:10,432 train 300 1.907703e-02 -0.641702
2019-11-06 18:29:20,228 train 350 1.905923e-02 -0.634920
2019-11-06 18:29:30,037 train 400 1.904097e-02 -0.623348
2019-11-06 18:29:39,855 train 450 1.896742e-02 -0.653374
2019-11-06 18:29:49,661 train 500 1.900519e-02 -0.668838
2019-11-06 18:29:59,471 train 550 1.901325e-02 -0.667174
2019-11-06 18:30:09,267 train 600 1.900982e-02 -0.684151
2019-11-06 18:30:19,058 train 650 1.899710e-02 -0.681363
2019-11-06 18:30:28,858 train 700 1.900876e-02 -0.677038
2019-11-06 18:30:38,656 train 750 1.899354e-02 -0.676014
2019-11-06 18:30:48,450 train 800 1.897817e-02 -0.683035
2019-11-06 18:30:58,223 train 850 1.899309e-02 -0.678708
2019-11-06 18:31:01,142 training loss; R2: 1.899137e-02 -0.677837
2019-11-06 18:31:01,834 valid 000 1.887465e-02 -0.254256
2019-11-06 18:31:11,209 valid 050 2.089807e-02 -1.132686
2019-11-06 18:31:19,592 validation loss; R2: 2.088586e-02 -0.928343
2019-11-06 18:31:19,662 epoch 167 lr 1.000000e-05
2019-11-06 18:31:20,408 train 000 2.118099e-02 -0.050232
2019-11-06 18:31:30,136 train 050 1.879022e-02 -35.646244
2019-11-06 18:31:39,857 train 100 1.885457e-02 -18.327678
2019-11-06 18:31:49,610 train 150 1.894243e-02 -12.526359
2019-11-06 18:31:59,368 train 200 1.888536e-02 -9.514769
2019-11-06 18:32:09,125 train 250 1.896152e-02 -7.790265
2019-11-06 18:32:18,890 train 300 1.901744e-02 -6.602917
2019-11-06 18:32:28,644 train 350 1.903916e-02 -5.939447
2019-11-06 18:32:38,409 train 400 1.907655e-02 -5.262133
2019-11-06 18:32:48,175 train 450 1.907353e-02 -4.786954
2019-11-06 18:32:57,935 train 500 1.908246e-02 -4.379175
2019-11-06 18:33:07,709 train 550 1.910046e-02 -4.192245
2019-11-06 18:33:17,484 train 600 1.908472e-02 -8.861301
2019-11-06 18:33:27,252 train 650 1.908649e-02 -8.231262
2019-11-06 18:33:37,024 train 700 1.908696e-02 -7.707170
2019-11-06 18:33:46,795 train 750 1.907599e-02 -7.230172
2019-11-06 18:33:56,578 train 800 1.905976e-02 -6.888714
2019-11-06 18:34:06,366 train 850 1.903978e-02 -6.522417
2019-11-06 18:34:09,290 training loss; R2: 1.903805e-02 -6.419379
2019-11-06 18:34:09,920 valid 000 2.268194e-02 -0.611250
2019-11-06 18:34:19,366 valid 050 2.137871e-02 -1.014188
2019-11-06 18:34:27,700 validation loss; R2: 2.116073e-02 -1.018095
2019-11-06 18:34:27,766 epoch 168 lr 1.000000e-05
2019-11-06 18:34:28,539 train 000 2.016980e-02 -0.169280
2019-11-06 18:34:38,271 train 050 1.915610e-02 -0.559531
2019-11-06 18:34:48,022 train 100 1.907089e-02 -0.531809
2019-11-06 18:34:57,779 train 150 1.892954e-02 -0.483574
2019-11-06 18:35:07,530 train 200 1.894635e-02 -0.472945
2019-11-06 18:35:17,286 train 250 1.896831e-02 -0.512715
2019-11-06 18:35:27,042 train 300 1.897980e-02 -0.528620
2019-11-06 18:35:36,818 train 350 1.903568e-02 -0.563759
2019-11-06 18:35:46,575 train 400 1.898790e-02 -0.583229
2019-11-06 18:35:56,337 train 450 1.898203e-02 -0.621595
2019-11-06 18:36:06,106 train 500 1.903532e-02 -0.626399
2019-11-06 18:36:15,868 train 550 1.900312e-02 -0.611433
2019-11-06 18:36:25,642 train 600 1.903273e-02 -0.611747
2019-11-06 18:36:35,419 train 650 1.903927e-02 -0.628897
2019-11-06 18:36:45,190 train 700 1.905759e-02 -0.645694
2019-11-06 18:36:54,981 train 750 1.904766e-02 -0.647428
2019-11-06 18:37:04,771 train 800 1.902045e-02 -0.648980
2019-11-06 18:37:14,556 train 850 1.900548e-02 -0.648523
2019-11-06 18:37:17,481 training loss; R2: 1.901775e-02 -0.646271
2019-11-06 18:37:18,145 valid 000 2.375317e-02 -0.517140
2019-11-06 18:37:27,535 valid 050 2.176755e-02 -0.847574
2019-11-06 18:37:35,867 validation loss; R2: 2.140105e-02 -0.847331
2019-11-06 18:37:35,937 epoch 169 lr 1.000000e-05
2019-11-06 18:37:36,671 train 000 1.778964e-02 -0.843429
2019-11-06 18:37:46,405 train 050 1.846316e-02 -0.646557
2019-11-06 18:37:56,125 train 100 1.858867e-02 -0.714649
2019-11-06 18:38:05,870 train 150 1.873424e-02 -0.718584
2019-11-06 18:38:15,625 train 200 1.886604e-02 -0.721708
2019-11-06 18:38:25,364 train 250 1.892726e-02 -0.661597
2019-11-06 18:38:35,122 train 300 1.901742e-02 -0.639743
2019-11-06 18:38:44,870 train 350 1.902967e-02 -0.625054
2019-11-06 18:38:54,626 train 400 1.906510e-02 -0.635062
2019-11-06 18:39:04,394 train 450 1.904731e-02 -0.648469
2019-11-06 18:39:14,172 train 500 1.903960e-02 -0.654182
2019-11-06 18:39:23,941 train 550 1.900936e-02 -0.634218
2019-11-06 18:39:33,711 train 600 1.903194e-02 -0.656938
2019-11-06 18:39:43,496 train 650 1.902536e-02 -0.665391
2019-11-06 18:39:53,277 train 700 1.902638e-02 -0.650309
2019-11-06 18:40:03,063 train 750 1.905980e-02 -0.653096
2019-11-06 18:40:12,843 train 800 1.901974e-02 -0.653289
2019-11-06 18:40:22,625 train 850 1.903757e-02 -0.652102
2019-11-06 18:40:25,551 training loss; R2: 1.904543e-02 -0.647051
2019-11-06 18:40:26,164 valid 000 2.089135e-02 0.063759
2019-11-06 18:40:35,643 valid 050 2.037103e-02 -0.781664
2019-11-06 18:40:43,970 validation loss; R2: 2.044069e-02 -0.833797
2019-11-06 18:40:44,037 epoch 170 lr 1.000000e-05
2019-11-06 18:40:44,767 train 000 1.756831e-02 -0.521409
2019-11-06 18:40:54,503 train 050 1.935172e-02 -0.613371
2019-11-06 18:41:04,231 train 100 1.925208e-02 -0.625758
2019-11-06 18:41:13,989 train 150 1.917810e-02 -0.742609
2019-11-06 18:41:23,764 train 200 1.922478e-02 -0.729204
2019-11-06 18:41:33,537 train 250 1.906089e-02 -0.663494
2019-11-06 18:41:43,308 train 300 1.902427e-02 -0.800763
2019-11-06 18:41:53,075 train 350 1.902569e-02 -0.821296
2019-11-06 18:42:02,839 train 400 1.899723e-02 -0.846654
2019-11-06 18:42:12,611 train 450 1.898460e-02 -0.812957
2019-11-06 18:42:22,386 train 500 1.898618e-02 -0.875018
2019-11-06 18:42:32,165 train 550 1.898004e-02 -0.893379
2019-11-06 18:42:41,958 train 600 1.893863e-02 -0.866035
2019-11-06 18:42:51,764 train 650 1.896644e-02 -0.848900
2019-11-06 18:43:01,572 train 700 1.894558e-02 -0.824705
2019-11-06 18:43:11,392 train 750 1.893958e-02 -0.812825
2019-11-06 18:43:21,206 train 800 1.897463e-02 -0.808922
2019-11-06 18:43:31,013 train 850 1.900461e-02 -0.779832
2019-11-06 18:43:33,945 training loss; R2: 1.901166e-02 -0.783039
2019-11-06 18:43:34,562 valid 000 2.200838e-02 -1.835981
2019-11-06 18:43:44,010 valid 050 2.028782e-02 -0.864033
2019-11-06 18:43:52,342 validation loss; R2: 2.024176e-02 -1.010439
2019-11-06 18:43:52,407 epoch 171 lr 1.000000e-05
2019-11-06 18:43:53,161 train 000 2.042596e-02 -0.923953
2019-11-06 18:44:02,892 train 050 1.882611e-02 -0.448699
2019-11-06 18:44:12,652 train 100 1.880336e-02 -0.533499
2019-11-06 18:44:22,431 train 150 1.901623e-02 -0.532217
2019-11-06 18:44:32,207 train 200 1.903278e-02 -0.552261
2019-11-06 18:44:41,971 train 250 1.901103e-02 -0.564254
2019-11-06 18:44:51,743 train 300 1.897666e-02 -0.559535
2019-11-06 18:45:01,515 train 350 1.895070e-02 -0.631981
2019-11-06 18:45:11,284 train 400 1.899492e-02 -0.641133
2019-11-06 18:45:21,052 train 450 1.890242e-02 -0.631528
2019-11-06 18:45:30,844 train 500 1.891587e-02 -0.627001
2019-11-06 18:45:40,631 train 550 1.890991e-02 -0.639018
2019-11-06 18:45:50,431 train 600 1.892275e-02 -0.623960
2019-11-06 18:46:00,220 train 650 1.893869e-02 -0.731047
2019-11-06 18:46:10,022 train 700 1.895543e-02 -0.739190
2019-11-06 18:46:19,822 train 750 1.896045e-02 -0.757617
2019-11-06 18:46:29,636 train 800 1.896786e-02 -0.755426
2019-11-06 18:46:39,441 train 850 1.895809e-02 -0.751622
2019-11-06 18:46:42,372 training loss; R2: 1.894686e-02 -0.748942
2019-11-06 18:46:43,064 valid 000 1.853463e-02 -0.773004
2019-11-06 18:46:52,427 valid 050 1.970447e-02 -0.744485
2019-11-06 18:47:00,755 validation loss; R2: 1.972361e-02 -0.755223
2019-11-06 18:47:00,821 epoch 172 lr 1.000000e-05
2019-11-06 18:47:01,561 train 000 1.763476e-02 -0.364604
2019-11-06 18:47:11,290 train 050 1.874046e-02 -0.619926
2019-11-06 18:47:21,045 train 100 1.889280e-02 -0.623398
2019-11-06 18:47:30,805 train 150 1.912974e-02 -0.701255
2019-11-06 18:47:40,566 train 200 1.902916e-02 -0.655143
2019-11-06 18:47:50,337 train 250 1.901914e-02 -0.645816
2019-11-06 18:48:00,107 train 300 1.902156e-02 -0.647833
2019-11-06 18:48:09,879 train 350 1.897085e-02 -0.674030
2019-11-06 18:48:19,652 train 400 1.898408e-02 -0.685469
2019-11-06 18:48:29,425 train 450 1.897194e-02 -0.683390
2019-11-06 18:48:39,205 train 500 1.893708e-02 -1.170879
2019-11-06 18:48:48,993 train 550 1.889674e-02 -1.128182
2019-11-06 18:48:58,793 train 600 1.892202e-02 -1.077821
2019-11-06 18:49:08,583 train 650 1.890594e-02 -1.067119
2019-11-06 18:49:18,384 train 700 1.889962e-02 -1.055996
2019-11-06 18:49:28,188 train 750 1.890184e-02 -1.032585
2019-11-06 18:49:37,981 train 800 1.888670e-02 -1.006764
2019-11-06 18:49:47,775 train 850 1.890917e-02 -0.977017
2019-11-06 18:49:50,699 training loss; R2: 1.891094e-02 -0.970502
2019-11-06 18:49:51,319 valid 000 2.426163e-02 -0.969099
2019-11-06 18:50:00,751 valid 050 2.242382e-02 -1.135789
2019-11-06 18:50:09,130 validation loss; R2: 2.223030e-02 -1.096306
2019-11-06 18:50:09,196 epoch 173 lr 1.000000e-05
2019-11-06 18:50:10,005 train 000 1.766004e-02 -0.276786
2019-11-06 18:50:19,738 train 050 1.863545e-02 -0.835221
2019-11-06 18:50:29,476 train 100 1.864979e-02 -0.939771
2019-11-06 18:50:39,244 train 150 1.880453e-02 -0.814452
2019-11-06 18:50:49,027 train 200 1.875838e-02 -0.748654
2019-11-06 18:50:58,805 train 250 1.883193e-02 -0.778304
2019-11-06 18:51:08,570 train 300 1.880517e-02 -0.989264
2019-11-06 18:51:18,347 train 350 1.885195e-02 -1.017387
2019-11-06 18:51:28,129 train 400 1.884459e-02 -0.973642
2019-11-06 18:51:37,905 train 450 1.888324e-02 -0.978991
2019-11-06 18:51:47,682 train 500 1.887930e-02 -1.022468
2019-11-06 18:51:57,491 train 550 1.890998e-02 -0.980077
2019-11-06 18:52:07,297 train 600 1.891779e-02 -0.961249
2019-11-06 18:52:17,104 train 650 1.889964e-02 -0.937529
2019-11-06 18:52:26,917 train 700 1.890208e-02 -0.958506
2019-11-06 18:52:36,726 train 750 1.890623e-02 -0.939877
2019-11-06 18:52:46,522 train 800 1.888884e-02 -0.918626
2019-11-06 18:52:56,345 train 850 1.889604e-02 -0.896394
2019-11-06 18:52:59,273 training loss; R2: 1.892002e-02 -0.900311
2019-11-06 18:52:59,918 valid 000 2.145380e-02 -0.086077
2019-11-06 18:53:09,357 valid 050 2.070483e-02 -1.080839
2019-11-06 18:53:17,679 validation loss; R2: 2.065981e-02 -6.040808
2019-11-06 18:53:17,745 epoch 174 lr 1.000000e-05
2019-11-06 18:53:18,538 train 000 1.702060e-02 -0.452093
2019-11-06 18:53:28,283 train 050 1.908129e-02 -0.506282
2019-11-06 18:53:38,050 train 100 1.891721e-02 -0.542602
2019-11-06 18:53:47,845 train 150 1.888144e-02 -0.665006
2019-11-06 18:53:57,640 train 200 1.899202e-02 -0.650103
2019-11-06 18:54:07,459 train 250 1.893983e-02 -0.688881
2019-11-06 18:54:17,534 train 300 1.894389e-02 -0.849429
2019-11-06 18:54:27,681 train 350 1.890238e-02 -0.839468
2019-11-06 18:54:37,835 train 400 1.889716e-02 -0.800914
2019-11-06 18:54:47,985 train 450 1.888226e-02 -0.810473
2019-11-06 18:54:58,156 train 500 1.892361e-02 -0.786423
2019-11-06 18:55:08,309 train 550 1.891790e-02 -0.764249
2019-11-06 18:55:18,451 train 600 1.895748e-02 -0.769922
2019-11-06 18:55:28,623 train 650 1.900664e-02 -0.782822
2019-11-06 18:55:38,789 train 700 1.900158e-02 -0.789138
2019-11-06 18:55:48,959 train 750 1.900044e-02 -0.779711
2019-11-06 18:55:59,134 train 800 1.901729e-02 -0.768144
2019-11-06 18:56:09,296 train 850 1.901366e-02 -0.758450
2019-11-06 18:56:12,330 training loss; R2: 1.901554e-02 -0.755714
2019-11-06 18:56:13,014 valid 000 1.807216e-02 -0.852842
2019-11-06 18:56:22,377 valid 050 2.040190e-02 -0.841327
2019-11-06 18:56:30,769 validation loss; R2: 2.045005e-02 -0.800482
2019-11-06 18:56:30,835 epoch 175 lr 1.000000e-05
2019-11-06 18:56:31,653 train 000 1.709985e-02 -0.383875
2019-11-06 18:56:41,775 train 050 1.859232e-02 -0.645580
2019-11-06 18:56:51,915 train 100 1.887840e-02 -0.664176
2019-11-06 18:57:02,059 train 150 1.873237e-02 -0.631807
2019-11-06 18:57:12,213 train 200 1.872922e-02 -0.683350
2019-11-06 18:57:22,354 train 250 1.874969e-02 -0.648574
2019-11-06 18:57:32,516 train 300 1.883099e-02 -0.665368
2019-11-06 18:57:42,679 train 350 1.882038e-02 -0.670698
2019-11-06 18:57:52,836 train 400 1.882928e-02 -0.674897
2019-11-06 18:58:02,996 train 450 1.885729e-02 -0.668095
2019-11-06 18:58:13,158 train 500 1.887352e-02 -0.676873
2019-11-06 18:58:23,325 train 550 1.887941e-02 -0.685621
2019-11-06 18:58:33,503 train 600 1.891563e-02 -0.689259
2019-11-06 18:58:43,664 train 650 1.891688e-02 -0.697474
2019-11-06 18:58:53,823 train 700 1.891258e-02 -0.695957
2019-11-06 18:59:03,992 train 750 1.891119e-02 -0.684311
2019-11-06 18:59:14,178 train 800 1.889715e-02 -0.709112
2019-11-06 18:59:24,361 train 850 1.893046e-02 -0.696233
2019-11-06 18:59:27,406 training loss; R2: 1.892061e-02 -0.706701
2019-11-06 18:59:28,096 valid 000 2.212138e-02 -0.663052
2019-11-06 18:59:37,465 valid 050 1.961312e-02 -0.837609
2019-11-06 18:59:45,820 validation loss; R2: 2.000724e-02 -0.824063
2019-11-06 18:59:45,888 epoch 176 lr 1.000000e-05
2019-11-06 18:59:46,655 train 000 1.775344e-02 -0.396956
2019-11-06 18:59:56,770 train 050 1.875653e-02 -0.637346
2019-11-06 19:00:06,925 train 100 1.888089e-02 -0.577937
2019-11-06 19:00:16,870 train 150 1.878246e-02 -0.628469
2019-11-06 19:00:26,637 train 200 1.877067e-02 -0.637593
2019-11-06 19:00:36,412 train 250 1.889313e-02 -0.659694
2019-11-06 19:00:46,197 train 300 1.892924e-02 -0.630734
2019-11-06 19:00:55,977 train 350 1.900564e-02 -0.644897
2019-11-06 19:01:05,764 train 400 1.898924e-02 -0.645819
2019-11-06 19:01:15,567 train 450 1.902821e-02 -0.678478
2019-11-06 19:01:25,358 train 500 1.902187e-02 -0.698254
2019-11-06 19:01:35,149 train 550 1.896254e-02 -0.678591
2019-11-06 19:01:44,965 train 600 1.895306e-02 -0.689281
2019-11-06 19:01:54,769 train 650 1.895354e-02 -0.688158
2019-11-06 19:02:04,579 train 700 1.894661e-02 -0.694650
2019-11-06 19:02:14,392 train 750 1.894115e-02 -0.686334
2019-11-06 19:02:24,206 train 800 1.892237e-02 -0.682356
2019-11-06 19:02:34,014 train 850 1.890549e-02 -0.685710
2019-11-06 19:02:36,979 training loss; R2: 1.892318e-02 -0.680804
2019-11-06 19:02:37,597 valid 000 2.310451e-02 -0.769691
2019-11-06 19:02:47,041 valid 050 2.128987e-02 -1.009829
2019-11-06 19:02:55,357 validation loss; R2: 2.113867e-02 -0.973307
2019-11-06 19:02:55,436 epoch 177 lr 1.000000e-05
2019-11-06 19:02:56,167 train 000 2.004212e-02 -0.577787
2019-11-06 19:03:05,897 train 050 1.932048e-02 -0.878164
2019-11-06 19:03:15,646 train 100 1.927178e-02 -0.746869
2019-11-06 19:03:25,411 train 150 1.919513e-02 -0.736047
2019-11-06 19:03:35,164 train 200 1.908255e-02 -0.759137
2019-11-06 19:03:44,949 train 250 1.908157e-02 -0.739282
2019-11-06 19:03:54,733 train 300 1.901781e-02 -0.755893
2019-11-06 19:04:04,515 train 350 1.898208e-02 -0.780860
2019-11-06 19:04:14,300 train 400 1.897492e-02 -0.866698
2019-11-06 19:04:24,101 train 450 1.892499e-02 -0.837173
2019-11-06 19:04:33,904 train 500 1.889838e-02 -0.832478
2019-11-06 19:04:43,720 train 550 1.887015e-02 -0.829118
2019-11-06 19:04:53,538 train 600 1.886769e-02 -0.839419
2019-11-06 19:05:03,296 train 650 1.884990e-02 -0.829709
2019-11-06 19:05:13,055 train 700 1.889959e-02 -0.817559
2019-11-06 19:05:22,816 train 750 1.886923e-02 -0.828372
2019-11-06 19:05:32,571 train 800 1.886360e-02 -0.813705
2019-11-06 19:05:42,333 train 850 1.885715e-02 -0.797619
2019-11-06 19:05:45,251 training loss; R2: 1.887503e-02 -0.797241
2019-11-06 19:05:45,842 valid 000 2.003949e-02 -0.229755
2019-11-06 19:05:55,312 valid 050 2.034751e-02 -0.961807
2019-11-06 19:06:03,635 validation loss; R2: 2.025304e-02 -0.870691
2019-11-06 19:06:03,694 epoch 178 lr 1.000000e-05
2019-11-06 19:06:04,472 train 000 2.302534e-02 -2.450313
2019-11-06 19:06:14,174 train 050 1.923781e-02 -0.559964
2019-11-06 19:06:23,856 train 100 1.899176e-02 -0.655152
2019-11-06 19:06:33,576 train 150 1.872933e-02 -0.571938
2019-11-06 19:06:43,288 train 200 1.878361e-02 -0.558860
2019-11-06 19:06:53,014 train 250 1.885519e-02 -0.603340
2019-11-06 19:07:02,727 train 300 1.887209e-02 -0.579062
2019-11-06 19:07:12,455 train 350 1.884977e-02 -0.642292
2019-11-06 19:07:22,180 train 400 1.885194e-02 -0.622634
2019-11-06 19:07:31,912 train 450 1.884744e-02 -0.632160
2019-11-06 19:07:41,657 train 500 1.884576e-02 -0.633835
2019-11-06 19:07:51,401 train 550 1.884598e-02 -0.644413
2019-11-06 19:08:01,150 train 600 1.887803e-02 -0.638525
2019-11-06 19:08:10,906 train 650 1.889964e-02 -0.645172
2019-11-06 19:08:20,657 train 700 1.886649e-02 -0.672753
2019-11-06 19:08:30,407 train 750 1.887510e-02 -0.686076
2019-11-06 19:08:40,154 train 800 1.888306e-02 -0.697180
2019-11-06 19:08:49,910 train 850 1.888047e-02 -0.698176
2019-11-06 19:08:52,822 training loss; R2: 1.887417e-02 -0.697380
2019-11-06 19:08:53,457 valid 000 2.001439e-02 -1.402051
2019-11-06 19:09:02,856 valid 050 2.081937e-02 -0.858025
2019-11-06 19:09:11,257 validation loss; R2: 2.067919e-02 -0.774200
2019-11-06 19:09:11,323 epoch 179 lr 1.000000e-05
2019-11-06 19:09:12,163 train 000 1.550260e-02 -1.231374
2019-11-06 19:09:21,843 train 050 1.859263e-02 -0.681912
2019-11-06 19:09:31,532 train 100 1.904775e-02 -0.643330
2019-11-06 19:09:41,251 train 150 1.901763e-02 -0.614935
2019-11-06 19:09:50,968 train 200 1.889674e-02 -0.622818
2019-11-06 19:10:00,684 train 250 1.889893e-02 -0.664816
2019-11-06 19:10:10,413 train 300 1.898471e-02 -0.703367
2019-11-06 19:10:20,144 train 350 1.898413e-02 -0.694986
2019-11-06 19:10:29,885 train 400 1.896623e-02 -0.718498
2019-11-06 19:10:39,622 train 450 1.893839e-02 -0.721271
2019-11-06 19:10:49,369 train 500 1.896372e-02 -0.735632
2019-11-06 19:10:59,125 train 550 1.895850e-02 -0.724513
2019-11-06 19:11:08,879 train 600 1.892483e-02 -0.705321
2019-11-06 19:11:18,625 train 650 1.891942e-02 -0.689251
2019-11-06 19:11:28,376 train 700 1.889354e-02 -0.682144
2019-11-06 19:11:38,132 train 750 1.888960e-02 -0.682309
2019-11-06 19:11:47,889 train 800 1.888822e-02 -0.694788
2019-11-06 19:11:57,642 train 850 1.887005e-02 -0.696463
2019-11-06 19:12:00,558 training loss; R2: 1.887596e-02 -0.698690
2019-11-06 19:12:01,206 valid 000 2.358214e-02 -0.093709
2019-11-06 19:12:10,616 valid 050 2.056818e-02 -0.724040
2019-11-06 19:12:18,937 validation loss; R2: 2.067882e-02 -0.849352
2019-11-06 19:12:19,002 epoch 180 lr 1.000000e-05
2019-11-06 19:12:19,735 train 000 1.931758e-02 -0.000959
2019-11-06 19:12:29,435 train 050 1.840802e-02 -0.705371
2019-11-06 19:12:39,128 train 100 1.858518e-02 -0.622884
2019-11-06 19:12:48,855 train 150 1.857310e-02 -0.653011
2019-11-06 19:12:58,583 train 200 1.858573e-02 -0.631458
2019-11-06 19:13:08,312 train 250 1.859153e-02 -0.649056
2019-11-06 19:13:18,041 train 300 1.864427e-02 -0.670161
2019-11-06 19:13:27,798 train 350 1.869665e-02 -0.653584
2019-11-06 19:13:37,571 train 400 1.871001e-02 -0.694623
2019-11-06 19:13:47,362 train 450 1.871152e-02 -0.696698
2019-11-06 19:13:57,167 train 500 1.871018e-02 -0.790557
2019-11-06 19:14:06,965 train 550 1.874020e-02 -0.893609
2019-11-06 19:14:16,769 train 600 1.874471e-02 -0.882607
2019-11-06 19:14:26,573 train 650 1.876432e-02 -0.854929
2019-11-06 19:14:36,378 train 700 1.883691e-02 -0.839778
2019-11-06 19:14:46,174 train 750 1.880902e-02 -0.823147
2019-11-06 19:14:55,976 train 800 1.883494e-02 -0.807229
2019-11-06 19:15:05,779 train 850 1.883283e-02 -0.808892
2019-11-06 19:15:08,710 training loss; R2: 1.882791e-02 -0.807062
2019-11-06 19:15:09,391 valid 000 1.735405e-02 -1.278604
2019-11-06 19:15:18,793 valid 050 2.032270e-02 -0.971340
2019-11-06 19:15:27,109 validation loss; R2: 1.995312e-02 -1.180077
2019-11-06 19:15:27,178 epoch 181 lr 1.000000e-05
2019-11-06 19:15:27,911 train 000 2.052047e-02 -0.467260
2019-11-06 19:15:37,658 train 050 1.839879e-02 -0.580003
2019-11-06 19:15:47,439 train 100 1.887598e-02 -0.530398
2019-11-06 19:15:57,228 train 150 1.887433e-02 -0.512036
2019-11-06 19:16:07,009 train 200 1.877829e-02 -0.588695
2019-11-06 19:16:16,790 train 250 1.886594e-02 -0.628513
2019-11-06 19:16:26,568 train 300 1.883602e-02 -0.620816
2019-11-06 19:16:36,331 train 350 1.881738e-02 -0.652038
2019-11-06 19:16:46,105 train 400 1.878555e-02 -0.646838
2019-11-06 19:16:55,888 train 450 1.881981e-02 -0.687936
2019-11-06 19:17:05,668 train 500 1.881592e-02 -0.689132
2019-11-06 19:17:15,441 train 550 1.878029e-02 -0.707874
2019-11-06 19:17:25,207 train 600 1.879950e-02 -0.691327
2019-11-06 19:17:34,970 train 650 1.881268e-02 -0.686343
2019-11-06 19:17:44,737 train 700 1.880257e-02 -0.688305
2019-11-06 19:17:54,493 train 750 1.881452e-02 -0.696742
2019-11-06 19:18:04,254 train 800 1.882602e-02 -0.690054
2019-11-06 19:18:14,004 train 850 1.880318e-02 -0.718313
2019-11-06 19:18:16,963 training loss; R2: 1.880914e-02 -0.714835
2019-11-06 19:18:17,594 valid 000 1.770787e-02 -0.207153
2019-11-06 19:18:27,041 valid 050 2.014741e-02 -0.899866
2019-11-06 19:18:35,360 validation loss; R2: 2.016964e-02 -1.015455
2019-11-06 19:18:35,435 epoch 182 lr 1.000000e-05
2019-11-06 19:18:36,209 train 000 2.030852e-02 -0.080626
2019-11-06 19:18:45,980 train 050 1.868262e-02 -0.818459
2019-11-06 19:18:55,739 train 100 1.874178e-02 -0.645671
2019-11-06 19:19:05,515 train 150 1.872214e-02 -0.642533
2019-11-06 19:19:15,277 train 200 1.868409e-02 -0.625766
2019-11-06 19:19:25,045 train 250 1.874927e-02 -0.677842
2019-11-06 19:19:34,816 train 300 1.871284e-02 -0.687066
2019-11-06 19:19:44,592 train 350 1.873144e-02 -0.749830
2019-11-06 19:19:54,373 train 400 1.871919e-02 -0.772087
2019-11-06 19:20:04,149 train 450 1.871645e-02 -0.753385
2019-11-06 19:20:13,946 train 500 1.872391e-02 -0.757083
2019-11-06 19:20:23,738 train 550 1.873203e-02 -0.758243
2019-11-06 19:20:33,530 train 600 1.872436e-02 -0.745846
2019-11-06 19:20:43,313 train 650 1.874117e-02 -0.733537
2019-11-06 19:20:53,112 train 700 1.873147e-02 -0.712990
2019-11-06 19:21:02,922 train 750 1.874310e-02 -0.713532
2019-11-06 19:21:12,714 train 800 1.874686e-02 -0.705086
2019-11-06 19:21:22,515 train 850 1.876208e-02 -0.709065
2019-11-06 19:21:25,443 training loss; R2: 1.876194e-02 -0.709142
2019-11-06 19:21:26,130 valid 000 1.975152e-02 -0.112422
2019-11-06 19:21:35,607 valid 050 2.018580e-02 -1.059620
2019-11-06 19:21:43,939 validation loss; R2: 2.010914e-02 -0.837432
2019-11-06 19:21:44,007 epoch 183 lr 1.000000e-05
2019-11-06 19:21:44,834 train 000 1.918273e-02 -0.202020
2019-11-06 19:21:54,587 train 050 1.898566e-02 -0.823056
2019-11-06 19:22:04,341 train 100 1.894741e-02 -0.965645
2019-11-06 19:22:14,117 train 150 1.879805e-02 -0.959922
2019-11-06 19:22:23,907 train 200 1.882010e-02 -0.980932
2019-11-06 19:22:33,680 train 250 1.888382e-02 -0.949898
2019-11-06 19:22:43,472 train 300 1.884844e-02 -0.956380
2019-11-06 19:22:53,262 train 350 1.886621e-02 -0.923335
2019-11-06 19:23:03,061 train 400 1.892547e-02 -0.882880
2019-11-06 19:23:12,868 train 450 1.893705e-02 -0.853144
2019-11-06 19:23:22,665 train 500 1.890700e-02 -0.886056
2019-11-06 19:23:32,492 train 550 1.888066e-02 -3.448315
2019-11-06 19:23:42,306 train 600 1.887465e-02 -3.229809
2019-11-06 19:23:52,146 train 650 1.887698e-02 -3.032437
2019-11-06 19:24:01,974 train 700 1.887266e-02 -2.886541
2019-11-06 19:24:11,800 train 750 1.885808e-02 -2.739670
2019-11-06 19:24:21,635 train 800 1.884379e-02 -2.603124
2019-11-06 19:24:31,447 train 850 1.885313e-02 -2.478093
2019-11-06 19:24:34,382 training loss; R2: 1.886793e-02 -2.456185
2019-11-06 19:24:35,073 valid 000 1.948890e-02 -0.341327
2019-11-06 19:24:44,476 valid 050 2.021857e-02 -1.435764
2019-11-06 19:24:52,786 validation loss; R2: 2.048664e-02 -1.330701
2019-11-06 19:24:52,855 epoch 184 lr 1.000000e-05
2019-11-06 19:24:53,615 train 000 1.902208e-02 -6.294287
2019-11-06 19:25:03,361 train 050 1.832450e-02 -0.819483
2019-11-06 19:25:13,124 train 100 1.848264e-02 -0.720295
2019-11-06 19:25:22,896 train 150 1.860617e-02 -0.710288
2019-11-06 19:25:32,669 train 200 1.867326e-02 -0.685986
2019-11-06 19:25:42,443 train 250 1.871932e-02 -0.699612
2019-11-06 19:25:52,227 train 300 1.867721e-02 -0.703814
2019-11-06 19:26:02,010 train 350 1.872410e-02 -3.914737
2019-11-06 19:26:11,804 train 400 1.876164e-02 -3.535270
2019-11-06 19:26:21,605 train 450 1.875182e-02 -3.251699
2019-11-06 19:26:31,408 train 500 1.877791e-02 -2.987413
2019-11-06 19:26:41,212 train 550 1.878758e-02 -2.780843
2019-11-06 19:26:51,022 train 600 1.882392e-02 -2.627534
2019-11-06 19:27:00,832 train 650 1.880002e-02 -2.487561
2019-11-06 19:27:10,637 train 700 1.881164e-02 -2.374482
2019-11-06 19:27:20,442 train 750 1.880326e-02 -2.251588
2019-11-06 19:27:30,244 train 800 1.880856e-02 -2.153934
2019-11-06 19:27:40,047 train 850 1.879861e-02 -2.113214
2019-11-06 19:27:42,974 training loss; R2: 1.878788e-02 -2.082691
2019-11-06 19:27:43,639 valid 000 1.896055e-02 -0.479096
2019-11-06 19:27:53,064 valid 050 2.047956e-02 -0.972674
2019-11-06 19:28:01,375 validation loss; R2: 2.065260e-02 -1.050676
2019-11-06 19:28:01,440 epoch 185 lr 1.000000e-05
2019-11-06 19:28:02,208 train 000 1.592643e-02 -0.354270
2019-11-06 19:28:11,964 train 050 1.921101e-02 -0.573080
2019-11-06 19:28:21,738 train 100 1.891665e-02 -0.690890
2019-11-06 19:28:31,519 train 150 1.901557e-02 -0.600460
2019-11-06 19:28:41,304 train 200 1.896525e-02 -0.638407
2019-11-06 19:28:51,083 train 250 1.885496e-02 -0.657333
2019-11-06 19:29:00,894 train 300 1.878283e-02 -0.632156
2019-11-06 19:29:10,690 train 350 1.875241e-02 -0.631594
2019-11-06 19:29:20,486 train 400 1.873897e-02 -0.653429
2019-11-06 19:29:30,276 train 450 1.867684e-02 -0.656832
2019-11-06 19:29:40,092 train 500 1.874315e-02 -0.651870
2019-11-06 19:29:49,899 train 550 1.870621e-02 -0.655582
2019-11-06 19:29:59,724 train 600 1.874212e-02 -0.649505
2019-11-06 19:30:09,559 train 650 1.873959e-02 -0.665016
2019-11-06 19:30:19,362 train 700 1.875869e-02 -0.672552
2019-11-06 19:30:29,182 train 750 1.878930e-02 -0.677809
2019-11-06 19:30:38,994 train 800 1.880080e-02 -0.681981
2019-11-06 19:30:48,815 train 850 1.880434e-02 -0.682946
2019-11-06 19:30:51,761 training loss; R2: 1.880437e-02 -0.691460
2019-11-06 19:30:52,387 valid 000 1.686579e-02 -0.750487
2019-11-06 19:31:01,872 valid 050 2.099632e-02 -1.030996
2019-11-06 19:31:10,192 validation loss; R2: 2.102015e-02 -0.922522
2019-11-06 19:31:10,258 epoch 186 lr 1.000000e-05
2019-11-06 19:31:11,021 train 000 2.024901e-02 -0.403815
2019-11-06 19:31:20,772 train 050 1.902097e-02 -0.775937
2019-11-06 19:31:30,530 train 100 1.914915e-02 -0.837437
2019-11-06 19:31:40,307 train 150 1.910185e-02 -0.855384
2019-11-06 19:31:50,089 train 200 1.899282e-02 -0.794974
2019-11-06 19:31:59,875 train 250 1.901375e-02 -0.887788
2019-11-06 19:32:09,642 train 300 1.891279e-02 -0.884143
2019-11-06 19:32:19,431 train 350 1.888158e-02 -0.850251
2019-11-06 19:32:29,210 train 400 1.889338e-02 -0.824430
2019-11-06 19:32:38,987 train 450 1.892354e-02 -0.778660
2019-11-06 19:32:48,761 train 500 1.892400e-02 -0.740738
2019-11-06 19:32:58,549 train 550 1.891983e-02 -0.735182
2019-11-06 19:33:08,336 train 600 1.887917e-02 -0.751658
2019-11-06 19:33:18,120 train 650 1.883452e-02 -0.743719
2019-11-06 19:33:27,908 train 700 1.881565e-02 -0.754723
2019-11-06 19:33:37,707 train 750 1.881589e-02 -0.750429
2019-11-06 19:33:47,502 train 800 1.882922e-02 -0.744582
2019-11-06 19:33:57,301 train 850 1.882158e-02 -0.738285
2019-11-06 19:34:00,224 training loss; R2: 1.882939e-02 -0.734757
2019-11-06 19:34:00,872 valid 000 2.134022e-02 -0.715080
2019-11-06 19:34:10,356 valid 050 2.111138e-02 -1.296100
2019-11-06 19:34:18,647 validation loss; R2: 2.140239e-02 -1.291104
2019-11-06 19:34:18,712 epoch 187 lr 1.000000e-05
2019-11-06 19:34:19,480 train 000 1.802349e-02 -0.205682
2019-11-06 19:34:29,218 train 050 1.866214e-02 -1.397075
2019-11-06 19:34:38,965 train 100 1.842956e-02 -1.133337
2019-11-06 19:34:48,725 train 150 1.854026e-02 -0.983616
2019-11-06 19:34:58,498 train 200 1.862480e-02 -0.930088
2019-11-06 19:35:08,250 train 250 1.859622e-02 -0.892919
2019-11-06 19:35:18,015 train 300 1.856242e-02 -0.870666
2019-11-06 19:35:27,768 train 350 1.859811e-02 -0.829129
2019-11-06 19:35:37,525 train 400 1.863169e-02 -0.820447
2019-11-06 19:35:47,303 train 450 1.866507e-02 -0.788581
2019-11-06 19:35:57,116 train 500 1.873018e-02 -0.766988
2019-11-06 19:36:06,909 train 550 1.874774e-02 -0.752624
2019-11-06 19:36:16,708 train 600 1.874860e-02 -0.761280
2019-11-06 19:36:26,541 train 650 1.875748e-02 -0.750252
2019-11-06 19:36:36,368 train 700 1.874890e-02 -1.054636
2019-11-06 19:36:46,206 train 750 1.873706e-02 -1.037292
2019-11-06 19:36:56,042 train 800 1.873618e-02 -1.018036
2019-11-06 19:37:05,882 train 850 1.875378e-02 -0.999432
2019-11-06 19:37:08,826 training loss; R2: 1.875985e-02 -0.987262
2019-11-06 19:37:09,443 valid 000 1.912196e-02 -1.470780
2019-11-06 19:37:18,856 valid 050 1.968587e-02 -1.122533
2019-11-06 19:37:27,229 validation loss; R2: 1.981095e-02 -0.903835
2019-11-06 19:37:27,296 epoch 188 lr 1.000000e-05
2019-11-06 19:37:28,044 train 000 1.772711e-02 -1.561904
2019-11-06 19:37:37,806 train 050 1.865892e-02 -0.845306
2019-11-06 19:37:47,568 train 100 1.854931e-02 -0.699368
2019-11-06 19:37:57,356 train 150 1.868523e-02 -0.699940
2019-11-06 19:38:07,157 train 200 1.883339e-02 -0.673779
2019-11-06 19:38:16,949 train 250 1.878896e-02 -0.693271
2019-11-06 19:38:26,732 train 300 1.883994e-02 -0.720752
2019-11-06 19:38:36,530 train 350 1.879808e-02 -0.719798
2019-11-06 19:38:46,331 train 400 1.882603e-02 -0.695347
2019-11-06 19:38:56,133 train 450 1.885535e-02 -0.701249
2019-11-06 19:39:05,942 train 500 1.882806e-02 -0.726859
2019-11-06 19:39:15,759 train 550 1.885434e-02 -0.706247
2019-11-06 19:39:25,568 train 600 1.885385e-02 -0.700593
2019-11-06 19:39:35,386 train 650 1.885326e-02 -0.693347
2019-11-06 19:39:45,209 train 700 1.887292e-02 -0.689011
2019-11-06 19:39:55,027 train 750 1.887969e-02 -0.679313
2019-11-06 19:40:04,847 train 800 1.887394e-02 -0.683122
2019-11-06 19:40:14,663 train 850 1.886442e-02 -0.702933
2019-11-06 19:40:17,595 training loss; R2: 1.885954e-02 -0.701983
2019-11-06 19:40:18,218 valid 000 2.477640e-02 -1.669035
2019-11-06 19:40:27,632 valid 050 2.098471e-02 -0.630274
2019-11-06 19:40:35,945 validation loss; R2: 2.085314e-02 -1.003647
2019-11-06 19:40:36,011 epoch 189 lr 1.000000e-05
2019-11-06 19:40:36,776 train 000 1.966401e-02 0.026794
2019-11-06 19:40:46,539 train 050 1.885503e-02 -0.549001
2019-11-06 19:40:56,328 train 100 1.871717e-02 -0.651957
2019-11-06 19:41:06,127 train 150 1.863047e-02 -0.602132
2019-11-06 19:41:15,917 train 200 1.873061e-02 -0.634322
2019-11-06 19:41:25,713 train 250 1.882107e-02 -0.619857
2019-11-06 19:41:35,513 train 300 1.876158e-02 -0.659334
2019-11-06 19:41:45,305 train 350 1.878188e-02 -0.678297
2019-11-06 19:41:55,109 train 400 1.876452e-02 -0.696207
2019-11-06 19:42:04,927 train 450 1.876356e-02 -0.712125
2019-11-06 19:42:14,747 train 500 1.872616e-02 -0.706575
2019-11-06 19:42:24,574 train 550 1.872679e-02 -0.747605
2019-11-06 19:42:34,386 train 600 1.872307e-02 -0.744075
2019-11-06 19:42:44,208 train 650 1.875753e-02 -0.896892
2019-11-06 19:42:54,029 train 700 1.876716e-02 -0.883005
2019-11-06 19:43:03,848 train 750 1.874464e-02 -0.872308
2019-11-06 19:43:13,668 train 800 1.874855e-02 -0.859936
2019-11-06 19:43:23,482 train 850 1.875006e-02 -0.844396
2019-11-06 19:43:26,417 training loss; R2: 1.873203e-02 -0.840966
2019-11-06 19:43:27,028 valid 000 1.889954e-02 -0.403655
2019-11-06 19:43:36,421 valid 050 2.043640e-02 -1.068110
2019-11-06 19:43:44,744 validation loss; R2: 2.061635e-02 -1.196871
2019-11-06 19:43:44,810 epoch 190 lr 1.000000e-05
2019-11-06 19:43:45,554 train 000 2.040277e-02 -0.250267
2019-11-06 19:43:55,297 train 050 1.903830e-02 -0.681580
2019-11-06 19:44:05,071 train 100 1.867284e-02 -0.584773
2019-11-06 19:44:14,870 train 150 1.869583e-02 -0.615737
2019-11-06 19:44:24,669 train 200 1.862427e-02 -0.679330
2019-11-06 19:44:34,474 train 250 1.873132e-02 -0.665118
2019-11-06 19:44:44,280 train 300 1.874608e-02 -0.693669
2019-11-06 19:44:54,091 train 350 1.874454e-02 -0.749020
2019-11-06 19:45:03,907 train 400 1.867213e-02 -0.739721
2019-11-06 19:45:13,740 train 450 1.867528e-02 -0.730745
2019-11-06 19:45:23,564 train 500 1.866217e-02 -0.743982
2019-11-06 19:45:33,393 train 550 1.867040e-02 -0.739656
2019-11-06 19:45:43,218 train 600 1.865426e-02 -0.728826
2019-11-06 19:45:53,051 train 650 1.867622e-02 -0.711332
2019-11-06 19:46:02,862 train 700 1.869585e-02 -0.700596
2019-11-06 19:46:12,681 train 750 1.868708e-02 -0.687317
2019-11-06 19:46:22,514 train 800 1.867462e-02 -0.698235
2019-11-06 19:46:32,350 train 850 1.867258e-02 -0.692400
2019-11-06 19:46:35,286 training loss; R2: 1.867405e-02 -0.688542
2019-11-06 19:46:35,962 valid 000 1.671067e-02 -1.666994
2019-11-06 19:46:45,392 valid 050 2.061746e-02 -1.217092
2019-11-06 19:46:53,736 validation loss; R2: 2.072570e-02 -1.296347
2019-11-06 19:46:53,803 epoch 191 lr 1.000000e-05
2019-11-06 19:46:54,583 train 000 1.958258e-02 0.041574
2019-11-06 19:47:04,338 train 050 1.895987e-02 -0.759776
2019-11-06 19:47:14,105 train 100 1.875530e-02 -0.716370
2019-11-06 19:47:23,876 train 150 1.883064e-02 -0.753895
2019-11-06 19:47:33,641 train 200 1.890094e-02 -0.722313
2019-11-06 19:47:43,404 train 250 1.887526e-02 -0.701849
2019-11-06 19:47:53,187 train 300 1.880806e-02 -0.689738
2019-11-06 19:48:02,953 train 350 1.880141e-02 -0.657894
2019-11-06 19:48:12,723 train 400 1.878533e-02 -0.644575
2019-11-06 19:48:22,506 train 450 1.882723e-02 -0.643594
2019-11-06 19:48:32,295 train 500 1.883880e-02 -0.683195
2019-11-06 19:48:42,094 train 550 1.880762e-02 -0.785633
2019-11-06 19:48:51,883 train 600 1.877584e-02 -0.765693
2019-11-06 19:49:01,666 train 650 1.877306e-02 -0.756608
2019-11-06 19:49:11,459 train 700 1.878598e-02 -0.745702
2019-11-06 19:49:21,246 train 750 1.877206e-02 -0.741424
2019-11-06 19:49:31,055 train 800 1.878564e-02 -0.721211
2019-11-06 19:49:40,848 train 850 1.877453e-02 -0.705701
2019-11-06 19:49:43,773 training loss; R2: 1.875890e-02 -0.705821
2019-11-06 19:49:44,403 valid 000 2.171938e-02 -1.027521
2019-11-06 19:49:53,826 valid 050 2.051829e-02 -0.908548
2019-11-06 19:50:02,145 validation loss; R2: 2.035821e-02 -0.923322
2019-11-06 19:50:02,217 epoch 192 lr 1.000000e-05
2019-11-06 19:50:02,971 train 000 2.122920e-02 -0.709782
2019-11-06 19:50:12,712 train 050 1.879859e-02 -0.660635
2019-11-06 19:50:22,448 train 100 1.867815e-02 -0.667131
2019-11-06 19:50:32,211 train 150 1.866843e-02 -0.731825
2019-11-06 19:50:41,965 train 200 1.869181e-02 -0.700500
2019-11-06 19:50:51,721 train 250 1.872093e-02 -0.721616
2019-11-06 19:51:01,475 train 300 1.868867e-02 -0.720237
2019-11-06 19:51:11,246 train 350 1.871838e-02 -0.787729
2019-11-06 19:51:21,022 train 400 1.870992e-02 -0.770969
2019-11-06 19:51:30,826 train 450 1.867979e-02 -0.800752
2019-11-06 19:51:40,613 train 500 1.869213e-02 -0.782864
2019-11-06 19:51:50,411 train 550 1.866054e-02 -0.772661
2019-11-06 19:52:00,209 train 600 1.868943e-02 -35.521762
2019-11-06 19:52:09,998 train 650 1.868350e-02 -32.858839
2019-11-06 19:52:19,801 train 700 1.867895e-02 -30.561377
2019-11-06 19:52:29,601 train 750 1.871266e-02 -28.570848
2019-11-06 19:52:39,404 train 800 1.871973e-02 -26.830924
2019-11-06 19:52:49,217 train 850 1.871909e-02 -25.297438
2019-11-06 19:52:52,149 training loss; R2: 1.873184e-02 -24.876830
2019-11-06 19:52:52,837 valid 000 2.154789e-02 -0.021205
2019-11-06 19:53:02,195 valid 050 2.062435e-02 -0.732589
2019-11-06 19:53:10,503 validation loss; R2: 2.063881e-02 -0.881818
2019-11-06 19:53:10,569 epoch 193 lr 1.000000e-05
2019-11-06 19:53:11,289 train 000 1.801989e-02 -0.007533
2019-11-06 19:53:21,035 train 050 1.839613e-02 -0.761204
2019-11-06 19:53:30,809 train 100 1.869380e-02 -0.759835
2019-11-06 19:53:40,588 train 150 1.875173e-02 -10.160450
2019-11-06 19:53:50,358 train 200 1.868800e-02 -7.785415
2019-11-06 19:54:00,139 train 250 1.867308e-02 -6.377450
2019-11-06 19:54:09,919 train 300 1.869965e-02 -5.413111
2019-11-06 19:54:19,703 train 350 1.870942e-02 -4.717514
2019-11-06 19:54:29,482 train 400 1.868418e-02 -4.380321
2019-11-06 19:54:39,273 train 450 1.870433e-02 -3.969800
2019-11-06 19:54:49,070 train 500 1.874525e-02 -3.635223
2019-11-06 19:54:58,869 train 550 1.878518e-02 -3.395444
2019-11-06 19:55:08,671 train 600 1.876877e-02 -3.172632
2019-11-06 19:55:18,463 train 650 1.878046e-02 -2.971922
2019-11-06 19:55:28,247 train 700 1.876037e-02 -2.829295
2019-11-06 19:55:38,041 train 750 1.876952e-02 -2.689759
2019-11-06 19:55:47,829 train 800 1.877798e-02 -2.560595
2019-11-06 19:55:57,617 train 850 1.877947e-02 -2.458770
2019-11-06 19:56:00,542 training loss; R2: 1.877068e-02 -2.422263
2019-11-06 19:56:01,131 valid 000 1.984118e-02 -71.069371
2019-11-06 19:56:10,613 valid 050 2.028426e-02 -2.401039
2019-11-06 19:56:18,925 validation loss; R2: 2.029327e-02 -1.743279
2019-11-06 19:56:18,991 epoch 194 lr 1.000000e-05
2019-11-06 19:56:19,731 train 000 1.669038e-02 -0.773110
2019-11-06 19:56:29,491 train 050 1.872688e-02 -0.880523
2019-11-06 19:56:39,232 train 100 1.858819e-02 -0.751801
2019-11-06 19:56:48,982 train 150 1.861608e-02 -0.747200
2019-11-06 19:56:58,733 train 200 1.866515e-02 -1.604289
2019-11-06 19:57:08,484 train 250 1.869527e-02 -1.399740
2019-11-06 19:57:18,235 train 300 1.866637e-02 -1.292408
2019-11-06 19:57:27,994 train 350 1.871773e-02 -1.258394
2019-11-06 19:57:37,748 train 400 1.873645e-02 -1.208027
2019-11-06 19:57:47,542 train 450 1.873686e-02 -1.135883
2019-11-06 19:57:57,351 train 500 1.874009e-02 -1.076264
2019-11-06 19:58:07,156 train 550 1.874223e-02 -1.034299
2019-11-06 19:58:16,964 train 600 1.875316e-02 -1.021227
2019-11-06 19:58:26,766 train 650 1.874104e-02 -1.058329
2019-11-06 19:58:36,573 train 700 1.873161e-02 -1.057833
2019-11-06 19:58:46,368 train 750 1.872936e-02 -1.044462
2019-11-06 19:58:56,169 train 800 1.874935e-02 -1.038249
2019-11-06 19:59:05,968 train 850 1.874487e-02 -1.012024
2019-11-06 19:59:08,891 training loss; R2: 1.872779e-02 -1.005385
2019-11-06 19:59:09,531 valid 000 2.026492e-02 -0.373420
2019-11-06 19:59:18,969 valid 050 2.044769e-02 -0.764377
2019-11-06 19:59:27,258 validation loss; R2: 2.063807e-02 -0.863926
2019-11-06 19:59:27,323 epoch 195 lr 1.000000e-05
2019-11-06 19:59:28,068 train 000 2.213995e-02 -1.559788
2019-11-06 19:59:37,799 train 050 1.875836e-02 -1.232274
2019-11-06 19:59:47,515 train 100 1.869743e-02 -1.005481
2019-11-06 19:59:57,279 train 150 1.874461e-02 -0.964459
2019-11-06 20:00:07,030 train 200 1.868622e-02 -0.831393
2019-11-06 20:00:16,797 train 250 1.868300e-02 -0.834054
2019-11-06 20:00:26,554 train 300 1.874438e-02 -0.772368
2019-11-06 20:00:36,306 train 350 1.876237e-02 -0.745107
2019-11-06 20:00:46,038 train 400 1.883055e-02 -0.734826
2019-11-06 20:00:55,776 train 450 1.884578e-02 -0.760352
2019-11-06 20:01:05,532 train 500 1.880343e-02 -0.738220
2019-11-06 20:01:15,283 train 550 1.883631e-02 -0.732943
2019-11-06 20:01:25,033 train 600 1.884818e-02 -0.726036
2019-11-06 20:01:34,791 train 650 1.883460e-02 -0.749637
2019-11-06 20:01:44,547 train 700 1.880328e-02 -0.760004
2019-11-06 20:01:54,300 train 750 1.881437e-02 -0.750091
2019-11-06 20:02:04,063 train 800 1.880540e-02 -0.765003
2019-11-06 20:02:13,812 train 850 1.879830e-02 -0.761420
2019-11-06 20:02:16,725 training loss; R2: 1.879955e-02 -0.757659
2019-11-06 20:02:17,412 valid 000 1.901974e-02 -0.174426
2019-11-06 20:02:26,785 valid 050 1.937321e-02 -0.645161
2019-11-06 20:02:35,178 validation loss; R2: 1.961037e-02 -0.808680
2019-11-06 20:02:35,245 epoch 196 lr 1.000000e-05
2019-11-06 20:02:36,032 train 000 1.898073e-02 -0.076738
2019-11-06 20:02:45,725 train 050 1.868985e-02 -1.268970
2019-11-06 20:02:55,410 train 100 1.871773e-02 -1.033146
2019-11-06 20:03:05,116 train 150 1.869497e-02 -7.016487
2019-11-06 20:03:14,844 train 200 1.868295e-02 -5.696944
2019-11-06 20:03:24,589 train 250 1.869550e-02 -4.697836
2019-11-06 20:03:34,356 train 300 1.875653e-02 -4.022670
2019-11-06 20:03:44,106 train 350 1.880160e-02 -3.513350
2019-11-06 20:03:53,853 train 400 1.880626e-02 -3.146309
2019-11-06 20:04:03,612 train 450 1.872861e-02 -2.854406
2019-11-06 20:04:13,361 train 500 1.871541e-02 -2.649223
2019-11-06 20:04:23,150 train 550 1.870479e-02 -2.484952
2019-11-06 20:04:32,951 train 600 1.871490e-02 -2.336843
2019-11-06 20:04:42,744 train 650 1.873121e-02 -2.196951
2019-11-06 20:04:52,558 train 700 1.873216e-02 -2.104668
2019-11-06 20:05:02,365 train 750 1.872539e-02 -2.013177
2019-11-06 20:05:12,164 train 800 1.871512e-02 -1.924101
2019-11-06 20:05:21,969 train 850 1.870608e-02 -1.855740
2019-11-06 20:05:24,900 training loss; R2: 1.870485e-02 -1.836256
2019-11-06 20:05:25,608 valid 000 2.665929e-02 -1.094628
2019-11-06 20:05:34,961 valid 050 2.089350e-02 -0.905546
2019-11-06 20:05:43,299 validation loss; R2: 2.051634e-02 -0.872237
2019-11-06 20:05:43,368 epoch 197 lr 1.000000e-05
2019-11-06 20:05:44,118 train 000 1.916700e-02 -1.134023
2019-11-06 20:05:53,845 train 050 1.889482e-02 -0.687285
2019-11-06 20:06:03,585 train 100 1.887667e-02 -0.631405
2019-11-06 20:06:13,330 train 150 1.877882e-02 -0.638173
2019-11-06 20:06:23,089 train 200 1.876399e-02 -0.691231
2019-11-06 20:06:32,850 train 250 1.878280e-02 -0.674008
2019-11-06 20:06:42,600 train 300 1.876803e-02 -0.721769
2019-11-06 20:06:52,346 train 350 1.866702e-02 -0.730651
2019-11-06 20:07:02,100 train 400 1.868269e-02 -0.764355
2019-11-06 20:07:11,872 train 450 1.870235e-02 -0.771232
2019-11-06 20:07:21,670 train 500 1.874235e-02 -0.794858
2019-11-06 20:07:31,467 train 550 1.869280e-02 -0.840011
2019-11-06 20:07:41,260 train 600 1.867604e-02 -0.808361
2019-11-06 20:07:51,031 train 650 1.865610e-02 -0.811932
2019-11-06 20:08:00,825 train 700 1.863412e-02 -0.810319
2019-11-06 20:08:10,610 train 750 1.865225e-02 -0.792996
2019-11-06 20:08:20,395 train 800 1.862109e-02 -0.789994
2019-11-06 20:08:30,196 train 850 1.863769e-02 -0.784785
2019-11-06 20:08:33,121 training loss; R2: 1.863401e-02 -0.784652
2019-11-06 20:08:33,814 valid 000 1.781291e-02 0.007234
2019-11-06 20:08:43,127 valid 050 1.946127e-02 -1.236470
2019-11-06 20:08:51,540 validation loss; R2: 1.961473e-02 -1.268056
2019-11-06 20:08:51,606 epoch 198 lr 1.000000e-05
2019-11-06 20:08:52,411 train 000 1.799291e-02 -0.556646
2019-11-06 20:09:02,127 train 050 1.888210e-02 -0.539944
2019-11-06 20:09:11,888 train 100 1.882116e-02 -0.612071
2019-11-06 20:09:21,638 train 150 1.879199e-02 -0.899702
2019-11-06 20:09:31,394 train 200 1.874141e-02 -0.807368
2019-11-06 20:09:41,138 train 250 1.868188e-02 -0.775396
2019-11-06 20:09:50,887 train 300 1.866090e-02 -0.735014
2019-11-06 20:10:00,641 train 350 1.874796e-02 -0.728668
2019-11-06 20:10:10,393 train 400 1.875666e-02 -0.753803
2019-11-06 20:10:20,149 train 450 1.871446e-02 -0.758382
2019-11-06 20:10:29,907 train 500 1.870840e-02 -0.740452
2019-11-06 20:10:39,711 train 550 1.869082e-02 -0.742035
2019-11-06 20:10:49,488 train 600 1.867656e-02 -0.754510
2019-11-06 20:10:59,276 train 650 1.867126e-02 -0.731487
2019-11-06 20:11:09,052 train 700 1.866891e-02 -0.724276
2019-11-06 20:11:18,845 train 750 1.865004e-02 -0.737150
2019-11-06 20:11:28,635 train 800 1.865218e-02 -0.728447
2019-11-06 20:11:38,429 train 850 1.867612e-02 -0.723330
2019-11-06 20:11:41,354 training loss; R2: 1.865393e-02 -0.732630
2019-11-06 20:11:42,031 valid 000 2.206458e-02 -0.623390
2019-11-06 20:11:51,462 valid 050 2.106607e-02 -0.894323
2019-11-06 20:11:59,780 validation loss; R2: 2.084460e-02 -1.133627
2019-11-06 20:11:59,845 epoch 199 lr 1.000000e-05
2019-11-06 20:12:00,543 train 000 1.731945e-02 -0.999915
2019-11-06 20:12:10,268 train 050 1.833965e-02 -0.803735
2019-11-06 20:12:20,004 train 100 1.856885e-02 -0.795352
2019-11-06 20:12:29,752 train 150 1.858897e-02 -0.735288
2019-11-06 20:12:39,496 train 200 1.867467e-02 -0.745877
2019-11-06 20:12:49,243 train 250 1.865300e-02 -0.704833
2019-11-06 20:12:58,988 train 300 1.867480e-02 -0.742728
2019-11-06 20:13:08,740 train 350 1.869585e-02 -0.731694
2019-11-06 20:13:18,482 train 400 1.867072e-02 -0.715524
2019-11-06 20:13:28,258 train 450 1.865898e-02 -0.689958
2019-11-06 20:13:38,036 train 500 1.865767e-02 -12.812144
2019-11-06 20:13:47,818 train 550 1.870260e-02 -11.717867
2019-11-06 20:13:57,596 train 600 1.868034e-02 -10.802550
2019-11-06 20:14:07,369 train 650 1.866221e-02 -10.040886
2019-11-06 20:14:17,157 train 700 1.866431e-02 -9.375512
2019-11-06 20:14:26,935 train 750 1.864740e-02 -8.782423
2019-11-06 20:14:36,714 train 800 1.867806e-02 -8.281297
2019-11-06 20:14:46,500 train 850 1.869749e-02 -7.862833
2019-11-06 20:14:49,444 training loss; R2: 1.870573e-02 -7.745423
2019-11-06 20:14:50,088 valid 000 1.860537e-02 -0.855100
2019-11-06 20:14:59,525 valid 050 1.976013e-02 -1.013374
2019-11-06 20:15:07,850 validation loss; R2: 1.999074e-02 -0.980480
2019-11-06 20:15:07,915 epoch 200 lr 1.000000e-05
2019-11-06 20:15:08,689 train 000 1.730024e-02 -1.095355
2019-11-06 20:15:18,448 train 050 1.845176e-02 -1.039004
2019-11-06 20:15:28,206 train 100 1.857774e-02 -0.853007
2019-11-06 20:15:37,967 train 150 1.839925e-02 -0.846949
2019-11-06 20:15:47,753 train 200 1.838010e-02 -0.840699
2019-11-06 20:15:57,588 train 250 1.842591e-02 -0.836216
2019-11-06 20:16:07,373 train 300 1.851070e-02 -0.780601
2019-11-06 20:16:17,131 train 350 1.857681e-02 -0.760394
2019-11-06 20:16:26,880 train 400 1.858094e-02 -0.746767
2019-11-06 20:16:36,632 train 450 1.854840e-02 -0.746249
2019-11-06 20:16:46,408 train 500 1.856418e-02 -0.759626
2019-11-06 20:16:56,191 train 550 1.856415e-02 -0.767374
2019-11-06 20:17:05,965 train 600 1.855420e-02 -0.760226
2019-11-06 20:17:15,743 train 650 1.856600e-02 -0.770850
2019-11-06 20:17:25,517 train 700 1.859266e-02 -0.758807
2019-11-06 20:17:35,292 train 750 1.857767e-02 -0.748850
2019-11-06 20:17:45,069 train 800 1.859879e-02 -0.751366
2019-11-06 20:17:54,845 train 850 1.858726e-02 -0.746937
2019-11-06 20:17:57,771 training loss; R2: 1.859405e-02 -1.034863
2019-11-06 20:17:58,398 valid 000 1.939193e-02 -0.098140
2019-11-06 20:18:07,845 valid 050 1.994992e-02 -2.808156
2019-11-06 20:18:16,147 validation loss; R2: 1.974797e-02 -1.803756
2019-11-06 20:18:16,212 epoch 201 lr 1.000000e-05
2019-11-06 20:18:17,026 train 000 1.898783e-02 -1.010462
2019-11-06 20:18:26,754 train 050 1.894380e-02 -0.611047
2019-11-06 20:18:36,495 train 100 1.891796e-02 -0.659826
2019-11-06 20:18:46,233 train 150 1.873344e-02 -0.637684
2019-11-06 20:18:55,976 train 200 1.861076e-02 -0.665285
2019-11-06 20:19:05,739 train 250 1.866601e-02 -0.676562
2019-11-06 20:19:15,487 train 300 1.863018e-02 -0.684735
2019-11-06 20:19:25,233 train 350 1.859782e-02 -0.683237
2019-11-06 20:19:34,979 train 400 1.861820e-02 -0.692606
2019-11-06 20:19:44,727 train 450 1.859505e-02 -0.667128
2019-11-06 20:19:54,490 train 500 1.864167e-02 -0.658595
2019-11-06 20:20:04,242 train 550 1.864634e-02 -0.670602
2019-11-06 20:20:13,994 train 600 1.862440e-02 -0.648897
2019-11-06 20:20:23,744 train 650 1.863110e-02 -0.703482
2019-11-06 20:20:33,500 train 700 1.864864e-02 -0.713443
2019-11-06 20:20:43,249 train 750 1.864137e-02 -0.723198
2019-11-06 20:20:53,007 train 800 1.863061e-02 -0.718380
2019-11-06 20:21:02,758 train 850 1.862939e-02 -0.724580
2019-11-06 20:21:05,672 training loss; R2: 1.861587e-02 -0.733964
2019-11-06 20:21:06,298 valid 000 2.156118e-02 0.101054
2019-11-06 20:21:15,722 valid 050 1.954759e-02 -0.880878
2019-11-06 20:21:24,117 validation loss; R2: 1.960120e-02 -1.019333
2019-11-06 20:21:24,182 epoch 202 lr 1.000000e-05
2019-11-06 20:21:24,933 train 000 1.719621e-02 0.005776
2019-11-06 20:21:34,619 train 050 1.843360e-02 -0.723111
2019-11-06 20:21:44,302 train 100 1.867512e-02 -0.961536
2019-11-06 20:21:54,028 train 150 1.869877e-02 -0.878001
2019-11-06 20:22:03,739 train 200 1.866748e-02 -0.812545
2019-11-06 20:22:13,457 train 250 1.860981e-02 -0.785634
2019-11-06 20:22:23,180 train 300 1.871068e-02 -0.789375
2019-11-06 20:22:32,888 train 350 1.868992e-02 -0.768026
2019-11-06 20:22:42,620 train 400 1.869017e-02 -0.757955
2019-11-06 20:22:52,382 train 450 1.874506e-02 -0.742846
2019-11-06 20:23:02,144 train 500 1.877710e-02 -0.717100
2019-11-06 20:23:11,910 train 550 1.873603e-02 -0.771741
2019-11-06 20:23:21,679 train 600 1.874256e-02 -0.769562
2019-11-06 20:23:31,440 train 650 1.872654e-02 -0.746399
2019-11-06 20:23:41,207 train 700 1.871831e-02 -0.725497
2019-11-06 20:23:50,971 train 750 1.872339e-02 -0.728518
2019-11-06 20:24:00,725 train 800 1.871512e-02 -0.718517
2019-11-06 20:24:10,490 train 850 1.870123e-02 -0.727763
2019-11-06 20:24:13,406 training loss; R2: 1.868845e-02 -0.723949
2019-11-06 20:24:14,052 valid 000 1.921760e-02 -1.064332
2019-11-06 20:24:23,503 valid 050 1.946778e-02 -1.086657
2019-11-06 20:24:31,845 validation loss; R2: 1.954144e-02 -1.167473
2019-11-06 20:24:31,911 epoch 203 lr 1.000000e-05
2019-11-06 20:24:32,644 train 000 1.829906e-02 -0.510176
2019-11-06 20:24:42,331 train 050 1.834090e-02 -0.652386
2019-11-06 20:24:52,024 train 100 1.843559e-02 -0.598638
2019-11-06 20:25:01,754 train 150 1.849653e-02 -0.562049
2019-11-06 20:25:11,470 train 200 1.839543e-02 -0.651253
2019-11-06 20:25:21,195 train 250 1.843485e-02 -0.648006
2019-11-06 20:25:30,922 train 300 1.845980e-02 -0.641030
2019-11-06 20:25:40,658 train 350 1.853284e-02 -0.618504
2019-11-06 20:25:50,413 train 400 1.851798e-02 -0.611729
2019-11-06 20:26:00,157 train 450 1.854101e-02 -0.615269
2019-11-06 20:26:09,925 train 500 1.856557e-02 -0.621574
2019-11-06 20:26:19,716 train 550 1.851557e-02 -0.630161
2019-11-06 20:26:29,515 train 600 1.853933e-02 -0.617845
2019-11-06 20:26:39,289 train 650 1.856388e-02 -0.621408
2019-11-06 20:26:49,058 train 700 1.855560e-02 -0.618987
2019-11-06 20:26:58,833 train 750 1.854580e-02 -0.615728
2019-11-06 20:27:08,610 train 800 1.856190e-02 -0.636952
2019-11-06 20:27:18,384 train 850 1.859055e-02 -0.629530
2019-11-06 20:27:21,312 training loss; R2: 1.859361e-02 -0.631999
2019-11-06 20:27:21,953 valid 000 1.859147e-02 0.000248
2019-11-06 20:27:31,329 valid 050 2.065820e-02 -1.063542
2019-11-06 20:27:39,634 validation loss; R2: 2.087793e-02 -9.074065
2019-11-06 20:27:39,707 epoch 204 lr 1.000000e-05
2019-11-06 20:27:40,438 train 000 1.759137e-02 -0.260408
2019-11-06 20:27:50,169 train 050 1.863538e-02 -0.797902
2019-11-06 20:28:00,100 train 100 1.866389e-02 -0.829216
2019-11-06 20:28:10,235 train 150 1.860280e-02 -0.914714
2019-11-06 20:28:20,358 train 200 1.857491e-02 -0.806042
2019-11-06 20:28:30,463 train 250 1.855769e-02 -0.756787
2019-11-06 20:28:40,565 train 300 1.862810e-02 -0.744390
2019-11-06 20:28:50,668 train 350 1.858980e-02 -0.725102
2019-11-06 20:29:00,768 train 400 1.860102e-02 -0.871296
2019-11-06 20:29:10,878 train 450 1.865318e-02 -0.829284
2019-11-06 20:29:20,985 train 500 1.865489e-02 -0.820982
2019-11-06 20:29:31,096 train 550 1.865060e-02 -0.802366
2019-11-06 20:29:41,211 train 600 1.865877e-02 -0.880996
2019-11-06 20:29:51,346 train 650 1.866978e-02 -0.899546
2019-11-06 20:30:01,354 train 700 1.867618e-02 -0.883651
2019-11-06 20:30:11,174 train 750 1.866383e-02 -0.862381
2019-11-06 20:30:20,993 train 800 1.864145e-02 -0.855790
2019-11-06 20:30:30,801 train 850 1.862895e-02 -0.858208
2019-11-06 20:30:33,737 training loss; R2: 1.862905e-02 -0.852618
2019-11-06 20:30:34,371 valid 000 1.814321e-02 -0.228923
2019-11-06 20:30:43,794 valid 050 2.023244e-02 -1.338397
2019-11-06 20:30:52,189 validation loss; R2: 2.071275e-02 -2.319866
2019-11-06 20:30:52,255 epoch 205 lr 1.000000e-05
2019-11-06 20:30:53,003 train 000 1.984581e-02 0.061473
2019-11-06 20:31:02,751 train 050 1.857254e-02 -0.642669
2019-11-06 20:31:12,522 train 100 1.865883e-02 -0.738016
2019-11-06 20:31:22,307 train 150 1.861237e-02 -0.659430
2019-11-06 20:31:32,098 train 200 1.858513e-02 -0.664979
2019-11-06 20:31:41,881 train 250 1.856418e-02 -0.653098
2019-11-06 20:31:51,664 train 300 1.863928e-02 -0.710762
2019-11-06 20:32:01,447 train 350 1.859279e-02 -0.713267
2019-11-06 20:32:11,273 train 400 1.865068e-02 -0.708757
2019-11-06 20:32:21,108 train 450 1.860927e-02 -0.700544
2019-11-06 20:32:30,950 train 500 1.861371e-02 -0.706944
2019-11-06 20:32:40,768 train 550 1.861065e-02 -0.690130
2019-11-06 20:32:50,607 train 600 1.862567e-02 -0.682439
2019-11-06 20:33:00,417 train 650 1.862477e-02 -0.658510
2019-11-06 20:33:10,239 train 700 1.862369e-02 -0.663174
2019-11-06 20:33:20,060 train 750 1.861429e-02 -0.665168
2019-11-06 20:33:29,873 train 800 1.860611e-02 -0.667893
2019-11-06 20:33:39,686 train 850 1.858450e-02 -0.668636
2019-11-06 20:33:42,618 training loss; R2: 1.858620e-02 -0.670699
2019-11-06 20:33:43,272 valid 000 2.318060e-02 -0.653049
2019-11-06 20:33:52,691 valid 050 2.152381e-02 -13.774658
2019-11-06 20:34:00,974 validation loss; R2: 2.136302e-02 -7.774036
2019-11-06 20:34:01,040 epoch 206 lr 1.000000e-05
2019-11-06 20:34:01,803 train 000 1.918426e-02 -0.574733
2019-11-06 20:34:11,531 train 050 1.905579e-02 -0.703564
2019-11-06 20:34:21,264 train 100 1.869588e-02 -0.675630
2019-11-06 20:34:31,024 train 150 1.865554e-02 -0.663678
2019-11-06 20:34:40,767 train 200 1.867256e-02 -0.632236
2019-11-06 20:34:50,525 train 250 1.856582e-02 -0.615695
2019-11-06 20:35:00,300 train 300 1.857327e-02 -0.638054
2019-11-06 20:35:10,080 train 350 1.857716e-02 -0.884814
2019-11-06 20:35:19,856 train 400 1.860785e-02 -0.869029
2019-11-06 20:35:29,634 train 450 1.857887e-02 -0.864390
2019-11-06 20:35:39,417 train 500 1.858696e-02 -0.840720
2019-11-06 20:35:49,190 train 550 1.857161e-02 -0.945693
2019-11-06 20:35:58,981 train 600 1.855083e-02 -0.923426
2019-11-06 20:36:08,778 train 650 1.855166e-02 -0.902851
2019-11-06 20:36:18,564 train 700 1.856703e-02 -0.897845
2019-11-06 20:36:28,347 train 750 1.856025e-02 -0.864001
2019-11-06 20:36:38,128 train 800 1.857674e-02 -0.850231
2019-11-06 20:36:47,905 train 850 1.856846e-02 -0.826515
2019-11-06 20:36:50,859 training loss; R2: 1.856664e-02 -0.824916
2019-11-06 20:36:51,535 valid 000 2.047437e-02 -0.438093
2019-11-06 20:37:00,953 valid 050 2.003369e-02 -0.769635
2019-11-06 20:37:09,278 validation loss; R2: 2.013974e-02 -0.903901
2019-11-06 20:37:09,353 epoch 207 lr 1.000000e-05
2019-11-06 20:37:10,114 train 000 1.876509e-02 -0.141850
2019-11-06 20:37:20,257 train 050 1.855768e-02 -0.616046
2019-11-06 20:37:30,371 train 100 1.847124e-02 -0.611012
2019-11-06 20:37:40,305 train 150 1.855496e-02 -0.675645
2019-11-06 20:37:50,073 train 200 1.876629e-02 -0.634555
2019-11-06 20:37:59,844 train 250 1.866527e-02 -0.758451
2019-11-06 20:38:09,633 train 300 1.860014e-02 -0.706787
2019-11-06 20:38:19,425 train 350 1.864316e-02 -0.672727
2019-11-06 20:38:29,215 train 400 1.865813e-02 -0.684196
2019-11-06 20:38:39,007 train 450 1.864638e-02 -0.695622
2019-11-06 20:38:48,810 train 500 1.864485e-02 -0.700478
2019-11-06 20:38:58,610 train 550 1.861482e-02 -0.698029
2019-11-06 20:39:08,401 train 600 1.861361e-02 -0.701309
2019-11-06 20:39:18,211 train 650 1.860155e-02 -0.694072
2019-11-06 20:39:28,006 train 700 1.860395e-02 -0.692233
2019-11-06 20:39:37,799 train 750 1.859721e-02 -0.679078
2019-11-06 20:39:47,585 train 800 1.859108e-02 -0.694043
2019-11-06 20:39:57,379 train 850 1.859124e-02 -0.687062
2019-11-06 20:40:00,325 training loss; R2: 1.858880e-02 -0.686993
2019-11-06 20:40:01,004 valid 000 2.699475e-02 -1.097688
2019-11-06 20:40:10,391 valid 050 2.171986e-02 -1.171476
2019-11-06 20:40:18,724 validation loss; R2: 2.162654e-02 -1.100997
2019-11-06 20:40:18,797 epoch 208 lr 1.000000e-05
2019-11-06 20:40:19,577 train 000 1.771106e-02 -2.809037
2019-11-06 20:40:29,301 train 050 1.885683e-02 -0.837489
2019-11-06 20:40:39,052 train 100 1.863493e-02 -0.920367
2019-11-06 20:40:48,808 train 150 1.855768e-02 -0.781567
2019-11-06 20:40:58,569 train 200 1.867597e-02 -0.761877
2019-11-06 20:41:08,353 train 250 1.864035e-02 -0.745186
2019-11-06 20:41:18,138 train 300 1.858153e-02 -0.734641
2019-11-06 20:41:27,917 train 350 1.859570e-02 -0.741288
2019-11-06 20:41:37,693 train 400 1.859650e-02 -0.735870
2019-11-06 20:41:47,477 train 450 1.862051e-02 -0.847814
2019-11-06 20:41:57,247 train 500 1.861496e-02 -0.816102
2019-11-06 20:42:07,020 train 550 1.863847e-02 -0.789853
2019-11-06 20:42:16,796 train 600 1.864290e-02 -0.829084
2019-11-06 20:42:26,573 train 650 1.863289e-02 -0.843897
2019-11-06 20:42:36,350 train 700 1.862602e-02 -1.211457
2019-11-06 20:42:46,125 train 750 1.863756e-02 -1.192256
2019-11-06 20:42:55,909 train 800 1.864087e-02 -1.168969
2019-11-06 20:43:05,676 train 850 1.862390e-02 -1.141009
2019-11-06 20:43:08,596 training loss; R2: 1.862075e-02 -1.134046
2019-11-06 20:43:09,213 valid 000 1.705452e-02 -0.910927
2019-11-06 20:43:18,682 valid 050 1.943264e-02 -0.905569
2019-11-06 20:43:27,019 validation loss; R2: 1.973393e-02 -0.971758
2019-11-06 20:43:27,084 epoch 209 lr 1.000000e-05
2019-11-06 20:43:27,841 train 000 1.677210e-02 -0.297701
2019-11-06 20:43:37,575 train 050 1.880771e-02 -0.901772
2019-11-06 20:43:47,343 train 100 1.857662e-02 -0.781362
2019-11-06 20:43:57,124 train 150 1.846602e-02 -0.762673
2019-11-06 20:44:06,932 train 200 1.854695e-02 -0.742749
2019-11-06 20:44:16,732 train 250 1.856019e-02 -0.731666
2019-11-06 20:44:26,531 train 300 1.851362e-02 -0.695337
2019-11-06 20:44:36,342 train 350 1.852258e-02 -0.692633
2019-11-06 20:44:46,145 train 400 1.852832e-02 -0.694237
2019-11-06 20:44:55,956 train 450 1.851330e-02 -0.694937
2019-11-06 20:45:05,763 train 500 1.849844e-02 -0.739252
2019-11-06 20:45:15,551 train 550 1.850485e-02 -0.742555
2019-11-06 20:45:25,362 train 600 1.852024e-02 -0.725541
2019-11-06 20:45:35,164 train 650 1.852431e-02 -0.720847
2019-11-06 20:45:44,968 train 700 1.852313e-02 -0.704267
2019-11-06 20:45:54,756 train 750 1.855740e-02 -0.691526
2019-11-06 20:46:04,542 train 800 1.854998e-02 -0.715609
2019-11-06 20:46:14,324 train 850 1.857810e-02 -0.715834
2019-11-06 20:46:17,243 training loss; R2: 1.859901e-02 -0.710246
2019-11-06 20:46:17,952 valid 000 1.864829e-02 -0.928301
2019-11-06 20:46:27,280 valid 050 2.039984e-02 -0.900487
2019-11-06 20:46:35,734 validation loss; R2: 2.012439e-02 -0.908124
2019-11-06 20:46:35,798 epoch 210 lr 1.000000e-05
2019-11-06 20:46:36,595 train 000 1.827610e-02 -0.305672
2019-11-06 20:46:46,321 train 050 1.868132e-02 -1.068067
2019-11-06 20:46:56,042 train 100 1.867080e-02 -0.875375
2019-11-06 20:47:05,773 train 150 1.856727e-02 -0.733581
2019-11-06 20:47:15,509 train 200 1.839711e-02 -0.687661
2019-11-06 20:47:25,266 train 250 1.835311e-02 -0.683336
2019-11-06 20:47:35,038 train 300 1.833919e-02 -0.692987
2019-11-06 20:47:44,804 train 350 1.842061e-02 -0.667744
2019-11-06 20:47:54,571 train 400 1.846166e-02 -0.668262
2019-11-06 20:48:04,342 train 450 1.853009e-02 -0.659655
2019-11-06 20:48:14,113 train 500 1.850795e-02 -0.662752
2019-11-06 20:48:23,895 train 550 1.852436e-02 -0.674200
2019-11-06 20:48:33,675 train 600 1.852706e-02 -0.683123
2019-11-06 20:48:43,448 train 650 1.854628e-02 -0.668011
2019-11-06 20:48:53,243 train 700 1.857312e-02 -0.670883
2019-11-06 20:49:03,057 train 750 1.859962e-02 -0.673797
2019-11-06 20:49:12,861 train 800 1.858800e-02 -0.667348
2019-11-06 20:49:22,664 train 850 1.857808e-02 -0.676230
2019-11-06 20:49:25,597 training loss; R2: 1.856322e-02 -0.674124
2019-11-06 20:49:26,232 valid 000 1.619109e-02 -1.956730
2019-11-06 20:49:35,669 valid 050 1.995919e-02 -1.107017
2019-11-06 20:49:43,984 validation loss; R2: 1.995355e-02 -1.043384
2019-11-06 20:49:44,056 epoch 211 lr 1.000000e-05
2019-11-06 20:49:44,778 train 000 1.608210e-02 -0.006764
2019-11-06 20:49:54,529 train 050 1.879465e-02 -0.786443
2019-11-06 20:50:04,306 train 100 1.877359e-02 -0.693409
2019-11-06 20:50:14,091 train 150 1.852663e-02 -0.640148
2019-11-06 20:50:23,911 train 200 1.858259e-02 -0.686604
2019-11-06 20:50:33,722 train 250 1.857303e-02 -0.673934
2019-11-06 20:50:43,543 train 300 1.860032e-02 -0.700477
2019-11-06 20:50:53,380 train 350 1.862247e-02 -0.672896
2019-11-06 20:51:03,207 train 400 1.863930e-02 -0.674752
2019-11-06 20:51:13,034 train 450 1.856124e-02 -0.673950
2019-11-06 20:51:22,849 train 500 1.856560e-02 -0.776541
2019-11-06 20:51:32,663 train 550 1.857095e-02 -0.815297
2019-11-06 20:51:42,478 train 600 1.855128e-02 -0.794832
2019-11-06 20:51:52,291 train 650 1.853696e-02 -0.796680
2019-11-06 20:52:02,116 train 700 1.856823e-02 -0.795754
2019-11-06 20:52:11,920 train 750 1.859550e-02 -0.791308
2019-11-06 20:52:21,739 train 800 1.859974e-02 -0.775684
2019-11-06 20:52:31,552 train 850 1.858647e-02 -0.755309
2019-11-06 20:52:34,487 training loss; R2: 1.858509e-02 -0.756046
2019-11-06 20:52:35,129 valid 000 2.168453e-02 -1.095144
2019-11-06 20:52:44,486 valid 050 2.036208e-02 -1.111006
2019-11-06 20:52:52,780 validation loss; R2: 2.033821e-02 -1.053599
2019-11-06 20:52:52,848 epoch 212 lr 1.000000e-05
2019-11-06 20:52:53,624 train 000 1.532916e-02 -0.167172
2019-11-06 20:53:03,376 train 050 1.841497e-02 -0.866325
2019-11-06 20:53:13,102 train 100 1.831511e-02 -0.814448
2019-11-06 20:53:22,856 train 150 1.838629e-02 -0.732275
2019-11-06 20:53:32,608 train 200 1.840084e-02 -0.710728
2019-11-06 20:53:42,396 train 250 1.843530e-02 -0.961468
2019-11-06 20:53:52,175 train 300 1.842242e-02 -0.910332
2019-11-06 20:54:01,975 train 350 1.853028e-02 -0.892112
2019-11-06 20:54:11,789 train 400 1.854783e-02 -0.859597
2019-11-06 20:54:21,589 train 450 1.857960e-02 -0.848851
2019-11-06 20:54:31,362 train 500 1.857336e-02 -0.829318
2019-11-06 20:54:41,142 train 550 1.854364e-02 -0.805805
2019-11-06 20:54:50,921 train 600 1.852724e-02 -0.780209
2019-11-06 20:55:00,702 train 650 1.854959e-02 -0.793792
2019-11-06 20:55:10,488 train 700 1.854940e-02 -0.784707
2019-11-06 20:55:20,272 train 750 1.855170e-02 -0.788079
2019-11-06 20:55:30,089 train 800 1.852640e-02 -0.792145
2019-11-06 20:55:39,881 train 850 1.852357e-02 -0.793981
2019-11-06 20:55:42,808 training loss; R2: 1.852216e-02 -0.847644
2019-11-06 20:55:43,495 valid 000 2.153922e-02 -0.532540
2019-11-06 20:55:52,891 valid 050 2.032793e-02 -1.367375
2019-11-06 20:56:01,222 validation loss; R2: 2.024983e-02 -1.081646
2019-11-06 20:56:01,301 epoch 213 lr 1.000000e-05
2019-11-06 20:56:02,092 train 000 1.750384e-02 -0.034619
2019-11-06 20:56:12,201 train 050 1.876803e-02 -0.634760
2019-11-06 20:56:22,355 train 100 1.870461e-02 -0.725397
2019-11-06 20:56:32,508 train 150 1.867324e-02 -0.692963
2019-11-06 20:56:42,639 train 200 1.869664e-02 -0.667394
2019-11-06 20:56:52,800 train 250 1.861710e-02 -0.770822
2019-11-06 20:57:02,966 train 300 1.862976e-02 -0.750744
2019-11-06 20:57:13,124 train 350 1.856531e-02 -0.725975
2019-11-06 20:57:23,284 train 400 1.856792e-02 -0.751748
2019-11-06 20:57:33,447 train 450 1.852997e-02 -0.764071
2019-11-06 20:57:43,619 train 500 1.855874e-02 -0.758093
2019-11-06 20:57:53,790 train 550 1.857825e-02 -0.749512
2019-11-06 20:58:03,589 train 600 1.856796e-02 -0.726111
2019-11-06 20:58:13,404 train 650 1.858887e-02 -0.728424
2019-11-06 20:58:23,220 train 700 1.858704e-02 -0.761217
2019-11-06 20:58:33,036 train 750 1.856500e-02 -0.755388
2019-11-06 20:58:42,875 train 800 1.857988e-02 -0.752526
2019-11-06 20:58:52,701 train 850 1.855944e-02 -0.752274
2019-11-06 20:58:55,637 training loss; R2: 1.855037e-02 -0.749519
2019-11-06 20:58:56,315 valid 000 1.609084e-02 -1.083833
2019-11-06 20:59:05,730 valid 050 2.004493e-02 -1.437061
2019-11-06 20:59:14,056 validation loss; R2: 1.993916e-02 -2.440539
2019-11-06 20:59:14,120 epoch 214 lr 1.000000e-05
2019-11-06 20:59:14,864 train 000 1.781962e-02 -0.419092
2019-11-06 20:59:24,614 train 050 1.878105e-02 -0.744559
2019-11-06 20:59:34,348 train 100 1.847145e-02 -0.725595
2019-11-06 20:59:44,128 train 150 1.850734e-02 -0.678005
2019-11-06 20:59:53,894 train 200 1.851075e-02 -0.597157
2019-11-06 21:00:03,700 train 250 1.852677e-02 -0.623173
2019-11-06 21:00:13,502 train 300 1.849867e-02 -0.669051
2019-11-06 21:00:23,305 train 350 1.849377e-02 -0.655263
2019-11-06 21:00:33,123 train 400 1.854420e-02 -0.769102
2019-11-06 21:00:42,934 train 450 1.858481e-02 -0.766905
2019-11-06 21:00:52,742 train 500 1.855525e-02 -0.763879
2019-11-06 21:01:02,552 train 550 1.854275e-02 -0.772322
2019-11-06 21:01:12,363 train 600 1.854568e-02 -0.778243
2019-11-06 21:01:22,173 train 650 1.855878e-02 -0.773577
2019-11-06 21:01:31,992 train 700 1.856403e-02 -0.749360
2019-11-06 21:01:41,806 train 750 1.855567e-02 -0.746507
2019-11-06 21:01:51,610 train 800 1.854926e-02 -0.757864
2019-11-06 21:02:01,415 train 850 1.856604e-02 -0.773035
2019-11-06 21:02:04,352 training loss; R2: 1.855183e-02 -0.768776
2019-11-06 21:02:04,934 valid 000 1.697449e-02 -0.160563
2019-11-06 21:02:14,369 valid 050 2.048710e-02 -0.888352
2019-11-06 21:02:22,686 validation loss; R2: 2.077476e-02 -1.003706
2019-11-06 21:02:22,755 epoch 215 lr 1.000000e-05
2019-11-06 21:02:23,536 train 000 2.152442e-02 -0.527863
2019-11-06 21:02:33,284 train 050 1.831169e-02 -0.820160
2019-11-06 21:02:43,030 train 100 1.840909e-02 -0.792832
2019-11-06 21:02:52,778 train 150 1.832596e-02 -0.730107
2019-11-06 21:03:02,557 train 200 1.839771e-02 -0.691566
2019-11-06 21:03:12,340 train 250 1.849341e-02 -0.730605
2019-11-06 21:03:22,125 train 300 1.848098e-02 -0.751375
2019-11-06 21:03:31,913 train 350 1.838375e-02 -0.894790
2019-11-06 21:03:41,705 train 400 1.841071e-02 -0.882049
2019-11-06 21:03:51,523 train 450 1.847487e-02 -0.856929
2019-11-06 21:04:01,321 train 500 1.846666e-02 -0.849016
2019-11-06 21:04:11,134 train 550 1.848596e-02 -0.835184
2019-11-06 21:04:20,934 train 600 1.848319e-02 -0.817326
2019-11-06 21:04:30,739 train 650 1.852350e-02 -0.798389
2019-11-06 21:04:40,540 train 700 1.852208e-02 -0.792230
2019-11-06 21:04:50,333 train 750 1.852560e-02 -0.781529
2019-11-06 21:05:00,133 train 800 1.851125e-02 -0.779752
2019-11-06 21:05:09,938 train 850 1.852433e-02 -0.769633
2019-11-06 21:05:12,875 training loss; R2: 1.851970e-02 -0.760854
2019-11-06 21:05:13,550 valid 000 2.411922e-02 -1.428534
2019-11-06 21:05:22,930 valid 050 2.106458e-02 -0.992608
2019-11-06 21:05:31,250 validation loss; R2: 2.077722e-02 -2.356887
2019-11-06 21:05:31,315 epoch 216 lr 1.000000e-05
2019-11-06 21:05:32,080 train 000 1.596129e-02 -1.207464
2019-11-06 21:05:41,804 train 050 1.893157e-02 -0.824516
2019-11-06 21:05:51,524 train 100 1.874737e-02 -0.962349
2019-11-06 21:06:01,269 train 150 1.873482e-02 -0.917529
2019-11-06 21:06:11,015 train 200 1.865703e-02 -0.864774
2019-11-06 21:06:20,790 train 250 1.864569e-02 -0.819452
2019-11-06 21:06:30,571 train 300 1.861627e-02 -0.791333
2019-11-06 21:06:40,344 train 350 1.860395e-02 -0.776872
2019-11-06 21:06:50,130 train 400 1.857136e-02 -0.800372
2019-11-06 21:06:59,914 train 450 1.857260e-02 -0.810757
2019-11-06 21:07:09,698 train 500 1.858291e-02 -0.807954
2019-11-06 21:07:19,478 train 550 1.858329e-02 -0.802424
2019-11-06 21:07:29,237 train 600 1.858756e-02 -0.781864
2019-11-06 21:07:38,984 train 650 1.862344e-02 -0.841234
2019-11-06 21:07:48,727 train 700 1.862205e-02 -0.812456
2019-11-06 21:07:58,477 train 750 1.860610e-02 -0.797444
2019-11-06 21:08:08,224 train 800 1.857861e-02 -0.794875
2019-11-06 21:08:17,974 train 850 1.860687e-02 -0.807348
2019-11-06 21:08:20,883 training loss; R2: 1.860741e-02 -0.810354
2019-11-06 21:08:21,498 valid 000 1.718869e-02 -1.536748
2019-11-06 21:08:30,918 valid 050 2.031924e-02 -0.636655
2019-11-06 21:08:39,250 validation loss; R2: 2.016460e-02 -0.870022
2019-11-06 21:08:39,315 epoch 217 lr 1.000000e-05
2019-11-06 21:08:40,037 train 000 1.728523e-02 -1.207761
2019-11-06 21:08:49,729 train 050 1.843451e-02 -0.490913
2019-11-06 21:08:59,417 train 100 1.859542e-02 -0.644156
2019-11-06 21:09:09,127 train 150 1.857395e-02 -0.641625
2019-11-06 21:09:18,853 train 200 1.857680e-02 -0.605027
2019-11-06 21:09:28,601 train 250 1.863335e-02 -0.610939
2019-11-06 21:09:38,353 train 300 1.854510e-02 -0.620303
2019-11-06 21:09:48,104 train 350 1.852845e-02 -0.602394
2019-11-06 21:09:57,864 train 400 1.853008e-02 -0.626705
2019-11-06 21:10:07,617 train 450 1.852054e-02 -0.624017
2019-11-06 21:10:17,367 train 500 1.851534e-02 -0.602153
2019-11-06 21:10:27,121 train 550 1.851272e-02 -0.599190
2019-11-06 21:10:36,876 train 600 1.850866e-02 -0.623695
2019-11-06 21:10:46,628 train 650 1.849596e-02 -0.639266
2019-11-06 21:10:56,399 train 700 1.848451e-02 -0.653777
2019-11-06 21:11:06,199 train 750 1.848405e-02 -0.663721
2019-11-06 21:11:16,002 train 800 1.848671e-02 -0.666892
2019-11-06 21:11:25,818 train 850 1.849542e-02 -0.669368
2019-11-06 21:11:28,749 training loss; R2: 1.849631e-02 -0.666788
2019-11-06 21:11:29,340 valid 000 2.059083e-02 -0.097445
2019-11-06 21:11:38,834 valid 050 1.899779e-02 -1.244825
2019-11-06 21:11:47,186 validation loss; R2: 1.885875e-02 -1.105155
2019-11-06 21:11:47,252 epoch 218 lr 1.000000e-05
2019-11-06 21:11:48,026 train 000 1.824895e-02 -0.229637
2019-11-06 21:11:57,776 train 050 1.825171e-02 -0.713987
2019-11-06 21:12:07,541 train 100 1.862598e-02 -0.794094
2019-11-06 21:12:17,315 train 150 1.858286e-02 -0.775391
2019-11-06 21:12:27,102 train 200 1.844215e-02 -0.739896
2019-11-06 21:12:36,894 train 250 1.848653e-02 -0.747438
2019-11-06 21:12:46,678 train 300 1.849145e-02 -0.744642
2019-11-06 21:12:56,479 train 350 1.854186e-02 -0.763226
2019-11-06 21:13:06,255 train 400 1.854472e-02 -0.740925
2019-11-06 21:13:16,040 train 450 1.856715e-02 -0.732136
2019-11-06 21:13:25,824 train 500 1.858715e-02 -0.731366
2019-11-06 21:13:35,615 train 550 1.856424e-02 -0.738114
2019-11-06 21:13:45,394 train 600 1.856146e-02 -0.719683
2019-11-06 21:13:55,176 train 650 1.853687e-02 -17.707039
2019-11-06 21:14:04,967 train 700 1.852394e-02 -16.479560
2019-11-06 21:14:14,757 train 750 1.851494e-02 -15.419195
2019-11-06 21:14:24,535 train 800 1.851362e-02 -14.494441
2019-11-06 21:14:34,308 train 850 1.850607e-02 -13.676593
2019-11-06 21:14:37,227 training loss; R2: 1.850849e-02 -13.450432
2019-11-06 21:14:37,919 valid 000 2.180740e-02 -1.433862
2019-11-06 21:14:47,297 valid 050 2.040171e-02 -1.591885
2019-11-06 21:14:55,694 validation loss; R2: 2.018999e-02 -2.139544
2019-11-06 21:14:55,759 epoch 219 lr 1.000000e-05
2019-11-06 21:14:56,538 train 000 1.753611e-02 0.008813
2019-11-06 21:15:06,256 train 050 1.829948e-02 -0.536506
2019-11-06 21:15:15,951 train 100 1.833680e-02 -0.773976
2019-11-06 21:15:25,668 train 150 1.834478e-02 -0.808664
2019-11-06 21:15:35,401 train 200 1.838877e-02 -0.826193
2019-11-06 21:15:45,129 train 250 1.841018e-02 -0.764062
2019-11-06 21:15:54,881 train 300 1.846239e-02 -0.792747
2019-11-06 21:16:04,640 train 350 1.852585e-02 -0.787303
2019-11-06 21:16:14,407 train 400 1.843312e-02 -0.982811
2019-11-06 21:16:24,172 train 450 1.846326e-02 -0.971355
2019-11-06 21:16:33,939 train 500 1.843524e-02 -0.944252
2019-11-06 21:16:43,695 train 550 1.847415e-02 -0.914676
2019-11-06 21:16:53,448 train 600 1.846577e-02 -0.887707
2019-11-06 21:17:03,233 train 650 1.846415e-02 -0.870568
2019-11-06 21:17:13,020 train 700 1.844670e-02 -0.851660
2019-11-06 21:17:22,794 train 750 1.846523e-02 -0.839749
2019-11-06 21:17:32,569 train 800 1.846318e-02 -0.830538
2019-11-06 21:17:42,344 train 850 1.847027e-02 -0.815402
2019-11-06 21:17:45,260 training loss; R2: 1.847380e-02 -0.814418
2019-11-06 21:17:45,942 valid 000 1.966840e-02 -0.360392
2019-11-06 21:17:55,304 valid 050 1.898846e-02 -0.716798
2019-11-06 21:18:03,679 validation loss; R2: 1.914622e-02 -0.801553
2019-11-06 21:18:03,745 epoch 220 lr 1.000000e-05
2019-11-06 21:18:04,513 train 000 1.711658e-02 -0.784719
2019-11-06 21:18:14,230 train 050 1.872432e-02 -0.845262
2019-11-06 21:18:23,966 train 100 1.868153e-02 -0.716723
2019-11-06 21:18:33,704 train 150 1.858927e-02 -0.742256
2019-11-06 21:18:43,448 train 200 1.866200e-02 -0.761597
2019-11-06 21:18:53,208 train 250 1.858831e-02 -0.753470
2019-11-06 21:19:02,949 train 300 1.855720e-02 -0.728659
2019-11-06 21:19:12,707 train 350 1.858370e-02 -0.722195
2019-11-06 21:19:22,468 train 400 1.856803e-02 -0.738899
2019-11-06 21:19:32,240 train 450 1.853817e-02 -0.720113
2019-11-06 21:19:42,009 train 500 1.852707e-02 -0.721652
2019-11-06 21:19:51,790 train 550 1.848831e-02 -0.725334
2019-11-06 21:20:01,559 train 600 1.848783e-02 -0.754845
2019-11-06 21:20:11,325 train 650 1.848340e-02 -0.735648
2019-11-06 21:20:21,092 train 700 1.850066e-02 -0.720698
2019-11-06 21:20:30,853 train 750 1.849436e-02 -0.719952
2019-11-06 21:20:40,623 train 800 1.848444e-02 -0.710829
2019-11-06 21:20:50,396 train 850 1.847667e-02 -0.781495
2019-11-06 21:20:53,321 training loss; R2: 1.846842e-02 -0.780110
2019-11-06 21:20:53,998 valid 000 2.170546e-02 -0.302134
2019-11-06 21:21:03,370 valid 050 1.993354e-02 -1.024888
2019-11-06 21:21:11,730 validation loss; R2: 2.012742e-02 -0.976264
2019-11-06 21:21:11,796 epoch 221 lr 1.000000e-05
2019-11-06 21:21:12,574 train 000 1.926998e-02 -0.275757
2019-11-06 21:21:22,288 train 050 1.854539e-02 -1.003689
2019-11-06 21:21:32,007 train 100 1.871959e-02 -0.898737
2019-11-06 21:21:41,751 train 150 1.861402e-02 -0.860718
2019-11-06 21:21:51,493 train 200 1.849398e-02 -0.776253
2019-11-06 21:22:01,230 train 250 1.841780e-02 -0.784338
2019-11-06 21:22:10,973 train 300 1.841833e-02 -0.735815
2019-11-06 21:22:20,733 train 350 1.838562e-02 -0.735306
2019-11-06 21:22:30,483 train 400 1.836946e-02 -0.750964
2019-11-06 21:22:40,232 train 450 1.838643e-02 -0.786745
2019-11-06 21:22:49,994 train 500 1.842096e-02 -0.773358
2019-11-06 21:22:59,754 train 550 1.840178e-02 -0.762934
2019-11-06 21:23:09,500 train 600 1.836730e-02 -0.759970
2019-11-06 21:23:19,256 train 650 1.837761e-02 -0.805727
2019-11-06 21:23:29,018 train 700 1.838387e-02 -1.049537
2019-11-06 21:23:38,778 train 750 1.842868e-02 -1.023696
2019-11-06 21:23:48,548 train 800 1.841912e-02 -1.008002
2019-11-06 21:23:58,334 train 850 1.840067e-02 -1.014382
2019-11-06 21:24:01,250 training loss; R2: 1.840534e-02 -1.010149
2019-11-06 21:24:01,875 valid 000 2.115941e-02 -0.175238
2019-11-06 21:24:11,292 valid 050 1.868527e-02 -0.674928
2019-11-06 21:24:19,611 validation loss; R2: 1.851218e-02 -0.731695
2019-11-06 21:24:19,678 epoch 222 lr 1.000000e-05
2019-11-06 21:24:20,481 train 000 1.722743e-02 -0.382054
2019-11-06 21:24:30,228 train 050 1.827922e-02 -381.912671
2019-11-06 21:24:39,985 train 100 1.844943e-02 -193.144503
2019-11-06 21:24:49,760 train 150 1.851816e-02 -129.403904
2019-11-06 21:24:59,555 train 200 1.852466e-02 -97.405860
2019-11-06 21:25:09,345 train 250 1.854292e-02 -78.103955
2019-11-06 21:25:19,133 train 300 1.846754e-02 -86.070102
2019-11-06 21:25:28,917 train 350 1.842944e-02 -73.885000
2019-11-06 21:25:38,701 train 400 1.837849e-02 -64.740502
2019-11-06 21:25:48,488 train 450 1.841789e-02 -57.645250
2019-11-06 21:25:58,287 train 500 1.840364e-02 -51.967884
2019-11-06 21:26:08,092 train 550 1.841901e-02 -47.325887
2019-11-06 21:26:17,881 train 600 1.841985e-02 -43.452124
2019-11-06 21:26:27,677 train 650 1.846384e-02 -40.163401
2019-11-06 21:26:37,492 train 700 1.847466e-02 -37.344013
2019-11-06 21:26:47,280 train 750 1.846430e-02 -34.906165
2019-11-06 21:26:57,068 train 800 1.846371e-02 -32.771654
2019-11-06 21:27:06,863 train 850 1.846011e-02 -30.910940
2019-11-06 21:27:09,793 training loss; R2: 1.846320e-02 -30.397746
2019-11-06 21:27:10,481 valid 000 2.210674e-02 -0.661681
2019-11-06 21:27:19,896 valid 050 1.992851e-02 -0.883701
2019-11-06 21:27:28,298 validation loss; R2: 1.983484e-02 -0.994284
2019-11-06 21:27:28,364 epoch 223 lr 1.000000e-05
2019-11-06 21:27:29,119 train 000 1.978999e-02 -1.610247
2019-11-06 21:27:38,839 train 050 1.854292e-02 -0.447909
2019-11-06 21:27:48,595 train 100 1.858540e-02 -0.608004
2019-11-06 21:27:58,339 train 150 1.866077e-02 -0.656751
2019-11-06 21:28:08,097 train 200 1.855653e-02 -0.653876
2019-11-06 21:28:17,848 train 250 1.848683e-02 -0.691664
2019-11-06 21:28:27,599 train 300 1.850945e-02 -0.719987
2019-11-06 21:28:37,365 train 350 1.857414e-02 -1.390799
2019-11-06 21:28:47,122 train 400 1.856669e-02 -1.266168
2019-11-06 21:28:56,886 train 450 1.853517e-02 -1.189757
2019-11-06 21:29:06,650 train 500 1.852809e-02 -1.128621
2019-11-06 21:29:16,405 train 550 1.848687e-02 -1.114818
2019-11-06 21:29:26,168 train 600 1.849994e-02 -1.533678
2019-11-06 21:29:35,931 train 650 1.850522e-02 -1.471443
2019-11-06 21:29:45,685 train 700 1.850386e-02 -1.660878
2019-11-06 21:29:55,438 train 750 1.852587e-02 -1.594016
2019-11-06 21:30:05,202 train 800 1.852475e-02 -1.533593
2019-11-06 21:30:14,956 train 850 1.851165e-02 -1.483975
2019-11-06 21:30:17,879 training loss; R2: 1.851642e-02 -1.467174
2019-11-06 21:30:18,584 valid 000 2.310085e-02 -0.021190
2019-11-06 21:30:27,948 valid 050 1.996803e-02 -1.048767
2019-11-06 21:30:36,264 validation loss; R2: 2.000478e-02 -1.180728
2019-11-06 21:30:36,331 epoch 224 lr 1.000000e-05
2019-11-06 21:30:37,130 train 000 1.769982e-02 0.042853
2019-11-06 21:30:46,852 train 050 1.851920e-02 -0.722142
2019-11-06 21:30:56,593 train 100 1.834819e-02 -0.616211
2019-11-06 21:31:06,343 train 150 1.826313e-02 -0.631039
2019-11-06 21:31:16,097 train 200 1.829869e-02 -0.732145
2019-11-06 21:31:25,852 train 250 1.823598e-02 -0.692831
2019-11-06 21:31:35,606 train 300 1.825761e-02 -0.675139
2019-11-06 21:31:45,360 train 350 1.829088e-02 -0.656145
2019-11-06 21:31:55,113 train 400 1.831097e-02 -0.699807
2019-11-06 21:32:04,872 train 450 1.833557e-02 -0.684988
2019-11-06 21:32:14,630 train 500 1.837070e-02 -0.705270
2019-11-06 21:32:24,387 train 550 1.838421e-02 -0.708122
2019-11-06 21:32:34,146 train 600 1.840716e-02 -0.690026
2019-11-06 21:32:43,913 train 650 1.843009e-02 -0.680776
2019-11-06 21:32:53,672 train 700 1.843544e-02 -0.706979
2019-11-06 21:33:03,430 train 750 1.844007e-02 -0.697547
2019-11-06 21:33:13,193 train 800 1.848757e-02 -0.686289
2019-11-06 21:33:22,960 train 850 1.847619e-02 -0.684803
2019-11-06 21:33:25,876 training loss; R2: 1.847930e-02 -0.680922
2019-11-06 21:33:26,503 valid 000 2.053731e-02 -2.334601
2019-11-06 21:33:35,965 valid 050 2.015262e-02 -1.370205
2019-11-06 21:33:44,318 validation loss; R2: 1.991798e-02 -1.202305
2019-11-06 21:33:44,386 epoch 225 lr 1.000000e-05
2019-11-06 21:33:45,194 train 000 1.843040e-02 -7.826309
2019-11-06 21:33:54,917 train 050 1.840613e-02 -0.690272
2019-11-06 21:34:04,643 train 100 1.839107e-02 -0.604831
2019-11-06 21:34:14,417 train 150 1.841666e-02 -0.586369
2019-11-06 21:34:24,202 train 200 1.840370e-02 -0.625987
2019-11-06 21:34:33,971 train 250 1.845012e-02 -0.605416
2019-11-06 21:34:43,751 train 300 1.841250e-02 -0.626871
2019-11-06 21:34:53,534 train 350 1.835546e-02 -60.643834
2019-11-06 21:35:03,303 train 400 1.840752e-02 -53.140674
2019-11-06 21:35:13,064 train 450 1.841763e-02 -47.307386
2019-11-06 21:35:22,843 train 500 1.844958e-02 -42.675460
2019-11-06 21:35:32,627 train 550 1.843573e-02 -38.867972
2019-11-06 21:35:42,405 train 600 1.844022e-02 -35.685276
2019-11-06 21:35:52,182 train 650 1.844558e-02 -32.990605
2019-11-06 21:36:01,963 train 700 1.845291e-02 -30.695016
2019-11-06 21:36:11,752 train 750 1.844198e-02 -28.698563
2019-11-06 21:36:21,539 train 800 1.844706e-02 -26.981270
2019-11-06 21:36:31,311 train 850 1.847035e-02 -25.433993
2019-11-06 21:36:34,232 training loss; R2: 1.846795e-02 -25.007046
2019-11-06 21:36:34,816 valid 000 2.289278e-02 -0.171100
2019-11-06 21:36:44,297 valid 050 1.997835e-02 -0.651686
2019-11-06 21:36:52,624 validation loss; R2: 1.968255e-02 -0.663009
2019-11-06 21:36:52,690 epoch 226 lr 1.000000e-05
2019-11-06 21:36:53,451 train 000 2.018027e-02 -0.750649
2019-11-06 21:37:03,176 train 050 1.855122e-02 -0.617505
2019-11-06 21:37:12,914 train 100 1.837560e-02 -0.637577
2019-11-06 21:37:22,660 train 150 1.827633e-02 -0.990249
2019-11-06 21:37:32,414 train 200 1.834233e-02 -0.962846
2019-11-06 21:37:42,162 train 250 1.836891e-02 -0.896289
2019-11-06 21:37:51,919 train 300 1.839547e-02 -0.899164
2019-11-06 21:38:01,678 train 350 1.834806e-02 -0.909012
2019-11-06 21:38:11,440 train 400 1.836806e-02 -0.903508
2019-11-06 21:38:21,210 train 450 1.835626e-02 -0.899233
2019-11-06 21:38:30,973 train 500 1.837011e-02 -1.025317
2019-11-06 21:38:40,740 train 550 1.832764e-02 -0.973345
2019-11-06 21:38:50,521 train 600 1.833105e-02 -0.939852
2019-11-06 21:39:00,307 train 650 1.832151e-02 -0.900965
2019-11-06 21:39:10,095 train 700 1.834475e-02 -0.871747
2019-11-06 21:39:19,870 train 750 1.838486e-02 -0.860038
2019-11-06 21:39:29,648 train 800 1.839551e-02 -0.870197
2019-11-06 21:39:39,419 train 850 1.841666e-02 -0.871666
2019-11-06 21:39:42,340 training loss; R2: 1.841605e-02 -0.864781
2019-11-06 21:39:43,036 valid 000 1.897398e-02 -3.151264
2019-11-06 21:39:52,401 valid 050 1.993550e-02 -0.844447
2019-11-06 21:40:00,969 validation loss; R2: 1.995341e-02 -0.752600
2019-11-06 21:40:01,055 epoch 227 lr 1.000000e-05
2019-11-06 21:40:01,891 train 000 1.723493e-02 -0.118583
2019-11-06 21:40:11,975 train 050 1.827265e-02 -1.515612
2019-11-06 21:40:22,087 train 100 1.836973e-02 -1.297835
2019-11-06 21:40:32,192 train 150 1.841513e-02 -1.161535
2019-11-06 21:40:42,297 train 200 1.833963e-02 -1.064291
2019-11-06 21:40:52,401 train 250 1.845177e-02 -0.996863
2019-11-06 21:41:02,524 train 300 1.842388e-02 -0.906288
2019-11-06 21:41:12,643 train 350 1.841489e-02 -0.868550
2019-11-06 21:41:22,740 train 400 1.839053e-02 -0.828565
2019-11-06 21:41:32,863 train 450 1.837429e-02 -0.833402
2019-11-06 21:41:42,998 train 500 1.838920e-02 -0.798244
2019-11-06 21:41:53,125 train 550 1.836437e-02 -0.788303
2019-11-06 21:42:03,252 train 600 1.835336e-02 -0.785553
2019-11-06 21:42:13,373 train 650 1.833353e-02 -0.780824
2019-11-06 21:42:23,489 train 700 1.833893e-02 -0.804620
2019-11-06 21:42:33,617 train 750 1.835154e-02 -0.797916
2019-11-06 21:42:43,740 train 800 1.836163e-02 -0.785820
2019-11-06 21:42:53,890 train 850 1.836872e-02 -0.774833
2019-11-06 21:42:56,919 training loss; R2: 1.837091e-02 -0.772717
2019-11-06 21:42:57,616 valid 000 2.074448e-02 -2.538102
2019-11-06 21:43:07,019 valid 050 2.061305e-02 -0.837884
2019-11-06 21:43:15,368 validation loss; R2: 2.075487e-02 -0.965102
2019-11-06 21:43:15,435 epoch 228 lr 1.000000e-05
2019-11-06 21:43:16,210 train 000 1.862969e-02 -0.349237
2019-11-06 21:43:26,318 train 050 1.862703e-02 -1.202853
2019-11-06 21:43:36,468 train 100 1.838287e-02 -0.984116
2019-11-06 21:43:46,609 train 150 1.843311e-02 -0.890090
2019-11-06 21:43:56,752 train 200 1.856613e-02 -0.842929
2019-11-06 21:44:06,899 train 250 1.859481e-02 -0.822083
2019-11-06 21:44:17,033 train 300 1.860117e-02 -0.842064
2019-11-06 21:44:27,183 train 350 1.852666e-02 -0.817240
2019-11-06 21:44:37,119 train 400 1.847046e-02 -0.799566
2019-11-06 21:44:46,878 train 450 1.847182e-02 -0.843056
2019-11-06 21:44:56,654 train 500 1.848536e-02 -0.898035
2019-11-06 21:45:06,396 train 550 1.847160e-02 -0.859239
2019-11-06 21:45:16,146 train 600 1.847056e-02 -0.853102
2019-11-06 21:45:25,878 train 650 1.847023e-02 -0.826371
2019-11-06 21:45:35,617 train 700 1.847877e-02 -0.814342
2019-11-06 21:45:45,368 train 750 1.850664e-02 -0.800202
2019-11-06 21:45:55,114 train 800 1.850501e-02 -0.800526
2019-11-06 21:46:04,882 train 850 1.846984e-02 -0.785965
2019-11-06 21:46:07,800 training loss; R2: 1.845402e-02 -0.780719
2019-11-06 21:46:08,499 valid 000 2.136874e-02 -0.436785
2019-11-06 21:46:17,835 valid 050 1.923984e-02 -1.778924
2019-11-06 21:46:26,165 validation loss; R2: 1.929688e-02 -1.513436
2019-11-06 21:46:26,233 epoch 229 lr 1.000000e-05
2019-11-06 21:46:27,000 train 000 2.019746e-02 -0.169720
2019-11-06 21:46:36,712 train 050 1.808145e-02 -0.554767
2019-11-06 21:46:46,431 train 100 1.818570e-02 -0.600665
2019-11-06 21:46:56,146 train 150 1.811333e-02 -0.551775
2019-11-06 21:47:05,866 train 200 1.812387e-02 -0.720814
2019-11-06 21:47:15,597 train 250 1.820532e-02 -0.690379
2019-11-06 21:47:25,331 train 300 1.823399e-02 -0.692584
2019-11-06 21:47:35,064 train 350 1.825820e-02 -0.696216
2019-11-06 21:47:44,797 train 400 1.827215e-02 -0.704188
2019-11-06 21:47:54,532 train 450 1.830794e-02 -0.826635
2019-11-06 21:48:04,278 train 500 1.832604e-02 -0.827591
2019-11-06 21:48:14,033 train 550 1.836168e-02 -0.816256
2019-11-06 21:48:23,796 train 600 1.838831e-02 -0.825350
2019-11-06 21:48:33,613 train 650 1.840731e-02 -0.829375
2019-11-06 21:48:43,431 train 700 1.838705e-02 -0.816578
2019-11-06 21:48:53,275 train 750 1.839608e-02 -0.800172
2019-11-06 21:49:03,108 train 800 1.839523e-02 -0.791282
2019-11-06 21:49:12,941 train 850 1.838589e-02 -0.790858
2019-11-06 21:49:15,876 training loss; R2: 1.838397e-02 -0.789815
2019-11-06 21:49:16,537 valid 000 2.087753e-02 -0.372674
2019-11-06 21:49:25,952 valid 050 2.050022e-02 -1.023808
2019-11-06 21:49:34,259 validation loss; R2: 2.057642e-02 -0.951498
2019-11-06 21:49:34,325 epoch 230 lr 1.000000e-05
2019-11-06 21:49:35,087 train 000 1.957427e-02 -1.063910
2019-11-06 21:49:44,840 train 050 1.827164e-02 -0.642667
2019-11-06 21:49:54,595 train 100 1.842894e-02 -0.755041
2019-11-06 21:50:04,360 train 150 1.841186e-02 -0.704583
2019-11-06 21:50:14,140 train 200 1.839811e-02 -0.667206
2019-11-06 21:50:23,914 train 250 1.840214e-02 -0.690725
2019-11-06 21:50:33,676 train 300 1.843398e-02 -0.702225
2019-11-06 21:50:43,452 train 350 1.847904e-02 -0.701841
2019-11-06 21:50:53,233 train 400 1.847519e-02 -0.683710
2019-11-06 21:51:03,004 train 450 1.842867e-02 -0.666428
2019-11-06 21:51:12,823 train 500 1.845241e-02 -0.650794
2019-11-06 21:51:22,638 train 550 1.839031e-02 -0.673541
2019-11-06 21:51:32,446 train 600 1.840762e-02 -0.685217
2019-11-06 21:51:42,244 train 650 1.845892e-02 -0.682520
2019-11-06 21:51:52,039 train 700 1.845600e-02 -0.665291
2019-11-06 21:52:01,831 train 750 1.844883e-02 -0.653796
2019-11-06 21:52:11,632 train 800 1.842743e-02 -0.657410
2019-11-06 21:52:21,436 train 850 1.844567e-02 -0.683328
2019-11-06 21:52:24,363 training loss; R2: 1.842105e-02 -0.692441
2019-11-06 21:52:24,957 valid 000 2.057038e-02 -2.082701
2019-11-06 21:52:34,422 valid 050 2.047964e-02 -0.690150
2019-11-06 21:52:42,756 validation loss; R2: 2.019593e-02 -0.840623
2019-11-06 21:52:42,823 epoch 231 lr 1.000000e-05
2019-11-06 21:52:43,602 train 000 1.850543e-02 -0.049884
2019-11-06 21:52:53,335 train 050 1.864457e-02 -0.974281
2019-11-06 21:53:03,079 train 100 1.872289e-02 -1.011890
2019-11-06 21:53:12,854 train 150 1.849574e-02 -0.963636
2019-11-06 21:53:22,620 train 200 1.838193e-02 -0.923125
2019-11-06 21:53:32,380 train 250 1.835701e-02 -1.157180
2019-11-06 21:53:42,146 train 300 1.835039e-02 -1.069368
2019-11-06 21:53:51,914 train 350 1.830226e-02 -1.036210
2019-11-06 21:54:01,690 train 400 1.835950e-02 -0.983921
2019-11-06 21:54:11,463 train 450 1.838190e-02 -0.949836
2019-11-06 21:54:21,238 train 500 1.838957e-02 -0.915096
2019-11-06 21:54:31,026 train 550 1.836224e-02 -0.896865
2019-11-06 21:54:40,818 train 600 1.834902e-02 -0.870689
2019-11-06 21:54:50,625 train 650 1.835790e-02 -0.853905
2019-11-06 21:55:00,423 train 700 1.836345e-02 -0.845799
2019-11-06 21:55:10,217 train 750 1.835000e-02 -0.848196
2019-11-06 21:55:20,005 train 800 1.837700e-02 -0.843071
2019-11-06 21:55:29,794 train 850 1.838076e-02 -0.822351
2019-11-06 21:55:32,748 training loss; R2: 1.838122e-02 -0.818158
2019-11-06 21:55:33,400 valid 000 1.817799e-02 0.013778
2019-11-06 21:55:42,829 valid 050 2.025008e-02 -1.015461
2019-11-06 21:55:51,141 validation loss; R2: 2.044778e-02 -1.188150
2019-11-06 21:55:51,223 epoch 232 lr 1.000000e-05
2019-11-06 21:55:52,006 train 000 1.768189e-02 -0.431621
2019-11-06 21:56:01,912 train 050 1.803197e-02 -0.791826
2019-11-06 21:56:11,641 train 100 1.827814e-02 -0.762371
2019-11-06 21:56:21,367 train 150 1.838784e-02 -0.725542
2019-11-06 21:56:31,086 train 200 1.831138e-02 -0.727551
2019-11-06 21:56:40,807 train 250 1.838158e-02 -0.696744
2019-11-06 21:56:50,533 train 300 1.836398e-02 -0.661597
2019-11-06 21:57:00,254 train 350 1.833800e-02 -0.671675
2019-11-06 21:57:09,983 train 400 1.833792e-02 -0.662413
2019-11-06 21:57:19,709 train 450 1.835719e-02 -0.665086
2019-11-06 21:57:29,438 train 500 1.835621e-02 -0.729788
2019-11-06 21:57:39,170 train 550 1.837851e-02 -0.716115
2019-11-06 21:57:48,940 train 600 1.838595e-02 -0.716389
2019-11-06 21:57:58,720 train 650 1.840467e-02 -0.700791
2019-11-06 21:58:08,505 train 700 1.840440e-02 -0.714463
2019-11-06 21:58:18,297 train 750 1.840661e-02 -0.721181
2019-11-06 21:58:28,076 train 800 1.840614e-02 -0.722214
2019-11-06 21:58:37,857 train 850 1.842017e-02 -0.716605
2019-11-06 21:58:40,779 training loss; R2: 1.841519e-02 -0.710414
2019-11-06 21:58:41,429 valid 000 2.011457e-02 0.002460
2019-11-06 21:58:50,833 valid 050 1.943310e-02 -2.462360
2019-11-06 21:58:59,164 validation loss; R2: 1.936650e-02 -1.845049
2019-11-06 21:58:59,232 epoch 233 lr 1.000000e-05
2019-11-06 21:59:00,028 train 000 1.712946e-02 -0.147346
2019-11-06 21:59:09,751 train 050 1.869356e-02 -0.606935
2019-11-06 21:59:19,481 train 100 1.855806e-02 -0.585725
2019-11-06 21:59:29,227 train 150 1.851083e-02 -0.573116
2019-11-06 21:59:38,983 train 200 1.843115e-02 -2.060982
2019-11-06 21:59:48,757 train 250 1.840911e-02 -1.763050
2019-11-06 21:59:58,544 train 300 1.844094e-02 -1.547272
2019-11-06 22:00:08,321 train 350 1.844000e-02 -5.367429
2019-11-06 22:00:18,113 train 400 1.836505e-02 -4.803635
2019-11-06 22:00:27,904 train 450 1.842815e-02 -4.329597
2019-11-06 22:00:37,684 train 500 1.844162e-02 -4.009878
2019-11-06 22:00:47,495 train 550 1.845642e-02 -3.745347
2019-11-06 22:00:57,313 train 600 1.848275e-02 -3.531843
2019-11-06 22:01:07,121 train 650 1.846267e-02 -3.316934
2019-11-06 22:01:16,935 train 700 1.847210e-02 -3.117744
2019-11-06 22:01:26,719 train 750 1.845305e-02 -2.954436
2019-11-06 22:01:36,517 train 800 1.845973e-02 -2.824083
2019-11-06 22:01:46,321 train 850 1.845464e-02 -2.693787
2019-11-06 22:01:49,250 training loss; R2: 1.845319e-02 -2.655522
2019-11-06 22:01:49,930 valid 000 1.859871e-02 -1.056825
2019-11-06 22:01:59,304 valid 050 1.867206e-02 -0.807072
2019-11-06 22:02:07,661 validation loss; R2: 1.881641e-02 -0.830371
2019-11-06 22:02:07,727 epoch 234 lr 1.000000e-05
2019-11-06 22:02:08,454 train 000 2.017290e-02 0.054184
2019-11-06 22:02:18,196 train 050 1.819981e-02 -0.605433
2019-11-06 22:02:27,929 train 100 1.815029e-02 -0.555151
2019-11-06 22:02:37,686 train 150 1.818740e-02 -0.626705
2019-11-06 22:02:47,442 train 200 1.824338e-02 -0.581161
2019-11-06 22:02:57,220 train 250 1.826810e-02 -0.589853
2019-11-06 22:03:06,989 train 300 1.828113e-02 -0.604120
2019-11-06 22:03:16,758 train 350 1.825957e-02 -0.629641
2019-11-06 22:03:26,534 train 400 1.826137e-02 -0.654157
2019-11-06 22:03:36,303 train 450 1.829298e-02 -0.648739
2019-11-06 22:03:46,096 train 500 1.832908e-02 -0.632385
2019-11-06 22:03:55,890 train 550 1.830359e-02 -0.646132
2019-11-06 22:04:05,676 train 600 1.826731e-02 -0.682363
2019-11-06 22:04:15,448 train 650 1.830895e-02 -0.684766
2019-11-06 22:04:25,198 train 700 1.832211e-02 -0.682470
2019-11-06 22:04:34,948 train 750 1.834308e-02 -0.674919
2019-11-06 22:04:44,704 train 800 1.835954e-02 -0.699157
2019-11-06 22:04:54,463 train 850 1.838662e-02 -0.705154
2019-11-06 22:04:57,382 training loss; R2: 1.837722e-02 -0.705451
2019-11-06 22:04:58,003 valid 000 1.928025e-02 -0.184508
2019-11-06 22:05:07,415 valid 050 2.022712e-02 -1.085092
2019-11-06 22:05:15,778 validation loss; R2: 2.062366e-02 -1.090626
2019-11-06 22:05:15,844 epoch 235 lr 1.000000e-05
2019-11-06 22:05:16,620 train 000 1.688366e-02 -0.265911
2019-11-06 22:05:26,328 train 050 1.845390e-02 -0.745799
2019-11-06 22:05:36,048 train 100 1.847527e-02 -0.766215
2019-11-06 22:05:45,770 train 150 1.843803e-02 -0.689520
2019-11-06 22:05:55,496 train 200 1.831328e-02 -0.647630
2019-11-06 22:06:05,271 train 250 1.836183e-02 -0.647923
2019-11-06 22:06:15,040 train 300 1.835117e-02 -0.611797
2019-11-06 22:06:24,813 train 350 1.833212e-02 -0.666940
2019-11-06 22:06:34,581 train 400 1.831375e-02 -0.762773
2019-11-06 22:06:44,379 train 450 1.829224e-02 -0.749663
2019-11-06 22:06:54,154 train 500 1.826795e-02 -0.743809
2019-11-06 22:07:03,923 train 550 1.826481e-02 -0.720111
2019-11-06 22:07:13,691 train 600 1.826244e-02 -0.708195
2019-11-06 22:07:23,479 train 650 1.825243e-02 -0.712817
2019-11-06 22:07:33,264 train 700 1.823416e-02 -0.702692
2019-11-06 22:07:43,068 train 750 1.823756e-02 -0.697257
2019-11-06 22:07:52,867 train 800 1.826637e-02 -0.699621
2019-11-06 22:08:02,623 train 850 1.828107e-02 -0.693292
2019-11-06 22:08:05,570 training loss; R2: 1.829092e-02 -0.700532
2019-11-06 22:08:06,265 valid 000 2.266292e-02 -0.315637
2019-11-06 22:08:15,733 valid 050 2.051230e-02 -1.232097
2019-11-06 22:08:24,104 validation loss; R2: 2.047774e-02 -1.172009
2019-11-06 22:08:24,182 epoch 236 lr 1.000000e-05
2019-11-06 22:08:24,978 train 000 2.207464e-02 0.066409
2019-11-06 22:08:34,730 train 050 1.872716e-02 -0.689408
2019-11-06 22:08:44,526 train 100 1.861838e-02 -0.686006
2019-11-06 22:08:54,324 train 150 1.850946e-02 -0.880857
2019-11-06 22:09:04,118 train 200 1.844218e-02 -0.784976
2019-11-06 22:09:13,900 train 250 1.838175e-02 -0.734632
2019-11-06 22:09:23,679 train 300 1.833359e-02 -0.792982
2019-11-06 22:09:33,457 train 350 1.836204e-02 -0.781707
2019-11-06 22:09:43,227 train 400 1.833420e-02 -0.773391
2019-11-06 22:09:53,018 train 450 1.833619e-02 -0.761126
2019-11-06 22:10:02,814 train 500 1.831910e-02 -0.765632
2019-11-06 22:10:12,597 train 550 1.831232e-02 -0.755508
2019-11-06 22:10:22,386 train 600 1.833140e-02 -0.760780
2019-11-06 22:10:32,179 train 650 1.835033e-02 -0.754973
2019-11-06 22:10:42,001 train 700 1.836493e-02 -0.747299
2019-11-06 22:10:51,804 train 750 1.835032e-02 -0.741948
2019-11-06 22:11:01,590 train 800 1.835016e-02 -0.730945
2019-11-06 22:11:11,377 train 850 1.833841e-02 -0.730341
2019-11-06 22:11:14,303 training loss; R2: 1.834688e-02 -0.723618
2019-11-06 22:11:14,994 valid 000 1.851065e-02 -1.008752
2019-11-06 22:11:24,405 valid 050 1.912735e-02 -1.117301
2019-11-06 22:11:32,713 validation loss; R2: 1.898712e-02 -2.285396
2019-11-06 22:11:32,780 epoch 237 lr 1.000000e-05
2019-11-06 22:11:33,545 train 000 1.883416e-02 -1.348173
2019-11-06 22:11:43,293 train 050 1.851736e-02 -0.814225
2019-11-06 22:11:53,062 train 100 1.840120e-02 -0.692992
2019-11-06 22:12:02,821 train 150 1.834032e-02 -0.772354
2019-11-06 22:12:12,596 train 200 1.835307e-02 -0.726702
2019-11-06 22:12:22,351 train 250 1.832421e-02 -0.705271
2019-11-06 22:12:32,131 train 300 1.837968e-02 -1.171669
2019-11-06 22:12:41,907 train 350 1.838705e-02 -1.153252
2019-11-06 22:12:51,679 train 400 1.839729e-02 -1.086549
2019-11-06 22:13:01,453 train 450 1.837915e-02 -1.237343
2019-11-06 22:13:11,553 train 500 1.836561e-02 -1.204408
2019-11-06 22:13:21,693 train 550 1.835314e-02 -1.133683
2019-11-06 22:13:31,834 train 600 1.838783e-02 -1.092884
2019-11-06 22:13:41,978 train 650 1.837043e-02 -1.078854
2019-11-06 22:13:52,133 train 700 1.837884e-02 -1.040143
2019-11-06 22:14:02,275 train 750 1.834179e-02 -1.031113
2019-11-06 22:14:12,439 train 800 1.832505e-02 -1.017491
2019-11-06 22:14:22,615 train 850 1.831254e-02 -0.989853
2019-11-06 22:14:25,652 training loss; R2: 1.831001e-02 -0.986223
2019-11-06 22:14:26,303 valid 000 2.625847e-02 -1.374319
2019-11-06 22:14:35,729 valid 050 2.109021e-02 -1.566252
2019-11-06 22:14:44,078 validation loss; R2: 2.067917e-02 -1.260467
2019-11-06 22:14:44,151 epoch 238 lr 1.000000e-05
2019-11-06 22:14:44,911 train 000 2.328998e-02 -0.024559
2019-11-06 22:14:55,044 train 050 1.839759e-02 -0.498278
2019-11-06 22:15:05,194 train 100 1.838097e-02 -0.591064
2019-11-06 22:15:15,343 train 150 1.838264e-02 -0.686582
2019-11-06 22:15:25,459 train 200 1.839555e-02 -0.694572
2019-11-06 22:15:35,615 train 250 1.845149e-02 -0.688541
2019-11-06 22:15:45,716 train 300 1.836626e-02 -0.642982
2019-11-06 22:15:55,823 train 350 1.836264e-02 -0.629984
2019-11-06 22:16:05,945 train 400 1.836393e-02 -0.626237
2019-11-06 22:16:16,064 train 450 1.836737e-02 -0.678466
2019-11-06 22:16:26,177 train 500 1.842451e-02 -0.674285
2019-11-06 22:16:36,279 train 550 1.838083e-02 -0.655110
2019-11-06 22:16:46,388 train 600 1.835432e-02 -0.686579
2019-11-06 22:16:56,495 train 650 1.833823e-02 -0.735758
2019-11-06 22:17:06,618 train 700 1.837262e-02 -0.748450
2019-11-06 22:17:16,743 train 750 1.837127e-02 -0.755354
2019-11-06 22:17:26,869 train 800 1.836044e-02 -0.756446
2019-11-06 22:17:37,014 train 850 1.837480e-02 -0.745159
2019-11-06 22:17:40,038 training loss; R2: 1.836268e-02 -0.745481
2019-11-06 22:17:40,670 valid 000 1.700789e-02 -1.847063
2019-11-06 22:17:50,088 valid 050 1.831974e-02 -0.791547
2019-11-06 22:17:58,442 validation loss; R2: 1.883846e-02 -0.843855
2019-11-06 22:17:58,511 epoch 239 lr 1.000000e-05
2019-11-06 22:17:59,309 train 000 2.139811e-02 -0.023108
2019-11-06 22:18:09,429 train 050 1.898112e-02 -0.845573
2019-11-06 22:18:19,216 train 100 1.860917e-02 -0.783130
2019-11-06 22:18:28,991 train 150 1.854824e-02 -0.684141
2019-11-06 22:18:38,784 train 200 1.845859e-02 -0.722950
2019-11-06 22:18:48,574 train 250 1.841150e-02 -0.662533
2019-11-06 22:18:58,365 train 300 1.846428e-02 -0.701342
2019-11-06 22:19:08,171 train 350 1.842395e-02 -0.699737
2019-11-06 22:19:17,968 train 400 1.843366e-02 -0.699627
2019-11-06 22:19:27,767 train 450 1.836840e-02 -0.688717
2019-11-06 22:19:37,575 train 500 1.840019e-02 -0.702912
2019-11-06 22:19:47,387 train 550 1.838491e-02 -0.724361
2019-11-06 22:19:57,198 train 600 1.840062e-02 -0.726188
2019-11-06 22:20:07,013 train 650 1.838868e-02 -0.748452
2019-11-06 22:20:16,818 train 700 1.835906e-02 -0.747778
2019-11-06 22:20:26,623 train 750 1.838879e-02 -0.757154
2019-11-06 22:20:36,431 train 800 1.837956e-02 -0.749523
2019-11-06 22:20:46,259 train 850 1.836887e-02 -0.758130
2019-11-06 22:20:49,192 training loss; R2: 1.836521e-02 -0.759197
2019-11-06 22:20:49,832 valid 000 2.028506e-02 -0.049290
2019-11-06 22:20:59,239 valid 050 1.977213e-02 -0.933617
2019-11-06 22:21:07,713 validation loss; R2: 1.985003e-02 -1.012237
2019-11-06 22:21:07,777 epoch 240 lr 1.000000e-05
2019-11-06 22:21:08,560 train 000 1.862156e-02 -0.039241
2019-11-06 22:21:18,328 train 050 1.857748e-02 -0.681224
2019-11-06 22:21:28,115 train 100 1.835008e-02 -0.673007
2019-11-06 22:21:37,900 train 150 1.834447e-02 -0.714226
2019-11-06 22:21:47,696 train 200 1.830504e-02 -0.762276
2019-11-06 22:21:57,490 train 250 1.824158e-02 -0.729091
2019-11-06 22:22:07,279 train 300 1.829598e-02 -0.707546
2019-11-06 22:22:17,088 train 350 1.839865e-02 -0.674524
2019-11-06 22:22:26,872 train 400 1.835774e-02 -0.693915
2019-11-06 22:22:36,668 train 450 1.838465e-02 -0.727868
2019-11-06 22:22:46,491 train 500 1.838942e-02 -0.743432
2019-11-06 22:22:56,319 train 550 1.840111e-02 -0.738651
2019-11-06 22:23:06,139 train 600 1.841456e-02 -0.716543
2019-11-06 22:23:15,963 train 650 1.843419e-02 -0.722119
2019-11-06 22:23:25,779 train 700 1.846060e-02 -0.733486
2019-11-06 22:23:35,607 train 750 1.844039e-02 -0.741911
2019-11-06 22:23:45,431 train 800 1.843973e-02 -0.777397
2019-11-06 22:23:55,257 train 850 1.841243e-02 -0.790246
2019-11-06 22:23:58,231 training loss; R2: 1.841270e-02 -0.782879
2019-11-06 22:23:58,880 valid 000 1.789700e-02 -1.042167
2019-11-06 22:24:08,328 valid 050 1.976184e-02 -1.151201
2019-11-06 22:24:16,646 validation loss; R2: 1.984265e-02 -1.182010
2019-11-06 22:24:16,724 epoch 241 lr 1.000000e-05
2019-11-06 22:24:17,514 train 000 1.704874e-02 -0.269719
2019-11-06 22:24:27,290 train 050 1.849583e-02 -0.760881
2019-11-06 22:24:37,083 train 100 1.830218e-02 -0.754497
2019-11-06 22:24:46,884 train 150 1.824424e-02 -0.722017
2019-11-06 22:24:56,674 train 200 1.825290e-02 -0.647012
2019-11-06 22:25:06,473 train 250 1.824992e-02 -0.763202
2019-11-06 22:25:16,283 train 300 1.821380e-02 -0.734943
2019-11-06 22:25:26,075 train 350 1.820738e-02 -0.763547
2019-11-06 22:25:35,870 train 400 1.820907e-02 -0.756490
2019-11-06 22:25:45,682 train 450 1.824011e-02 -0.750208
2019-11-06 22:25:55,483 train 500 1.828688e-02 -0.739529
2019-11-06 22:26:05,313 train 550 1.835780e-02 -0.743242
2019-11-06 22:26:15,115 train 600 1.836653e-02 -0.725936
2019-11-06 22:26:24,903 train 650 1.837397e-02 -0.720010
2019-11-06 22:26:34,697 train 700 1.837447e-02 -0.721171
2019-11-06 22:26:44,509 train 750 1.837753e-02 -0.735962
2019-11-06 22:26:54,303 train 800 1.837425e-02 -0.748202
2019-11-06 22:27:04,091 train 850 1.837419e-02 -0.746553
2019-11-06 22:27:07,017 training loss; R2: 1.838520e-02 -0.749585
2019-11-06 22:27:07,644 valid 000 1.707679e-02 -1.457875
2019-11-06 22:27:17,093 valid 050 1.880346e-02 -1.227440
2019-11-06 22:27:25,421 validation loss; R2: 1.889383e-02 -1.042723
2019-11-06 22:27:25,488 epoch 242 lr 1.000000e-05
2019-11-06 22:27:26,267 train 000 2.345735e-02 -0.560964
2019-11-06 22:27:36,002 train 050 1.884021e-02 -0.773057
2019-11-06 22:27:45,747 train 100 1.860771e-02 -0.792634
2019-11-06 22:27:55,500 train 150 1.858107e-02 -0.849141
2019-11-06 22:28:05,252 train 200 1.844455e-02 -0.804264
2019-11-06 22:28:15,020 train 250 1.840403e-02 -0.760803
2019-11-06 22:28:24,775 train 300 1.834413e-02 -0.800860
2019-11-06 22:28:34,532 train 350 1.836813e-02 -0.758508
2019-11-06 22:28:44,293 train 400 1.836564e-02 -0.719176
2019-11-06 22:28:54,078 train 450 1.836256e-02 -0.739754
2019-11-06 22:29:03,854 train 500 1.833776e-02 -0.728517
2019-11-06 22:29:13,651 train 550 1.833885e-02 -0.739570
2019-11-06 22:29:23,449 train 600 1.835375e-02 -0.732419
2019-11-06 22:29:33,258 train 650 1.835899e-02 -0.725115
2019-11-06 22:29:43,059 train 700 1.836614e-02 -0.722229
2019-11-06 22:29:52,871 train 750 1.832846e-02 -0.726952
2019-11-06 22:30:02,682 train 800 1.832566e-02 -0.727726
2019-11-06 22:30:12,485 train 850 1.831867e-02 -0.721452
2019-11-06 22:30:15,414 training loss; R2: 1.831614e-02 -0.717633
2019-11-06 22:30:16,055 valid 000 1.915215e-02 -0.280361
2019-11-06 22:30:25,479 valid 050 1.901474e-02 -0.768433
2019-11-06 22:30:33,863 validation loss; R2: 1.913456e-02 -1.076865
2019-11-06 22:30:33,929 epoch 243 lr 1.000000e-05
2019-11-06 22:30:34,739 train 000 1.921123e-02 -0.157869
2019-11-06 22:30:44,488 train 050 1.826551e-02 -0.469771
2019-11-06 22:30:54,264 train 100 1.865538e-02 -0.617716
2019-11-06 22:31:04,054 train 150 1.843439e-02 -0.594730
2019-11-06 22:31:13,838 train 200 1.836406e-02 -0.628155
2019-11-06 22:31:23,617 train 250 1.836703e-02 -0.700627
2019-11-06 22:31:33,401 train 300 1.834444e-02 -0.703571
2019-11-06 22:31:43,186 train 350 1.833653e-02 -0.702069
2019-11-06 22:31:52,971 train 400 1.835903e-02 -0.681037
2019-11-06 22:32:02,734 train 450 1.841259e-02 -0.685000
2019-11-06 22:32:12,510 train 500 1.840572e-02 -0.681547
2019-11-06 22:32:22,291 train 550 1.838546e-02 -0.658217
2019-11-06 22:32:32,076 train 600 1.835198e-02 -0.662472
2019-11-06 22:32:41,887 train 650 1.836563e-02 -0.678594
2019-11-06 22:32:51,713 train 700 1.834856e-02 -0.675852
2019-11-06 22:33:01,543 train 750 1.834452e-02 -0.688463
2019-11-06 22:33:11,368 train 800 1.834070e-02 -0.687905
2019-11-06 22:33:21,202 train 850 1.831686e-02 -0.789508
2019-11-06 22:33:24,140 training loss; R2: 1.832355e-02 -0.791724
2019-11-06 22:33:24,779 valid 000 1.686146e-02 -0.445205
2019-11-06 22:33:34,183 valid 050 2.002794e-02 -0.938213
2019-11-06 22:33:42,498 validation loss; R2: 2.012546e-02 -0.863319
2019-11-06 22:33:42,562 epoch 244 lr 1.000000e-05
2019-11-06 22:33:43,314 train 000 1.533034e-02 -1.156675
2019-11-06 22:33:53,066 train 050 1.851624e-02 -0.693257
2019-11-06 22:34:02,837 train 100 1.826608e-02 -0.634728
2019-11-06 22:34:12,618 train 150 1.827760e-02 -0.634648
2019-11-06 22:34:22,405 train 200 1.833745e-02 -0.687289
2019-11-06 22:34:32,211 train 250 1.830068e-02 -0.671425
2019-11-06 22:34:41,999 train 300 1.836832e-02 -0.711731
2019-11-06 22:34:51,798 train 350 1.842859e-02 -0.676274
2019-11-06 22:35:01,576 train 400 1.840675e-02 -0.668227
2019-11-06 22:35:11,363 train 450 1.833175e-02 -0.702451
2019-11-06 22:35:21,153 train 500 1.835619e-02 -0.715657
2019-11-06 22:35:30,955 train 550 1.832804e-02 -0.712612
2019-11-06 22:35:40,756 train 600 1.831490e-02 -0.706293
2019-11-06 22:35:50,576 train 650 1.825996e-02 -0.703010
2019-11-06 22:36:00,391 train 700 1.824581e-02 -0.698627
2019-11-06 22:36:10,204 train 750 1.824115e-02 -0.683217
2019-11-06 22:36:20,013 train 800 1.825575e-02 -0.696646
2019-11-06 22:36:29,817 train 850 1.825358e-02 -0.694834
2019-11-06 22:36:32,753 training loss; R2: 1.826056e-02 -0.694004
2019-11-06 22:36:33,418 valid 000 2.031576e-02 -1.049356
2019-11-06 22:36:42,913 valid 050 1.793591e-02 -16.845677
2019-11-06 22:36:51,251 validation loss; R2: 1.811804e-02 -9.436646
2019-11-06 22:36:51,318 epoch 245 lr 1.000000e-05
2019-11-06 22:36:52,048 train 000 1.831523e-02 0.026441
2019-11-06 22:37:01,798 train 050 1.830228e-02 -0.653909
2019-11-06 22:37:11,596 train 100 1.829471e-02 -0.857628
2019-11-06 22:37:21,707 train 150 1.828472e-02 -0.784469
2019-11-06 22:37:31,636 train 200 1.828405e-02 -0.777127
2019-11-06 22:37:41,425 train 250 1.822953e-02 -0.785431
2019-11-06 22:37:51,213 train 300 1.832273e-02 -0.784270
2019-11-06 22:38:01,000 train 350 1.827299e-02 -0.797040
2019-11-06 22:38:10,818 train 400 1.821908e-02 -0.797729
2019-11-06 22:38:20,641 train 450 1.822123e-02 -0.759178
2019-11-06 22:38:30,426 train 500 1.824375e-02 -0.762566
2019-11-06 22:38:40,200 train 550 1.826036e-02 -0.762153
2019-11-06 22:38:49,976 train 600 1.828807e-02 -0.750334
2019-11-06 22:38:59,752 train 650 1.829041e-02 -0.736309
2019-11-06 22:39:09,519 train 700 1.830400e-02 -0.745428
2019-11-06 22:39:19,302 train 750 1.829476e-02 -0.743233
2019-11-06 22:39:29,091 train 800 1.829302e-02 -0.727554
2019-11-06 22:39:38,870 train 850 1.831370e-02 -0.722282
2019-11-06 22:39:41,796 training loss; R2: 1.832343e-02 -0.719360
2019-11-06 22:39:42,411 valid 000 1.892672e-02 -0.919105
2019-11-06 22:39:51,852 valid 050 1.783115e-02 -1.081631
2019-11-06 22:40:00,164 validation loss; R2: 1.783828e-02 -0.909840
2019-11-06 22:40:00,223 epoch 246 lr 1.000000e-05
2019-11-06 22:40:00,986 train 000 2.129953e-02 -0.615008
2019-11-06 22:40:10,710 train 050 1.832029e-02 -0.553217
2019-11-06 22:40:20,452 train 100 1.816166e-02 -0.815029
2019-11-06 22:40:30,200 train 150 1.818034e-02 -1.245689
2019-11-06 22:40:39,955 train 200 1.808679e-02 -1.097265
2019-11-06 22:40:49,704 train 250 1.806805e-02 -1.020974
2019-11-06 22:40:59,458 train 300 1.817321e-02 -0.968280
2019-11-06 22:41:09,210 train 350 1.820564e-02 -0.911301
2019-11-06 22:41:18,967 train 400 1.823224e-02 -0.881378
2019-11-06 22:41:28,715 train 450 1.823589e-02 -0.863674
2019-11-06 22:41:38,478 train 500 1.823596e-02 -0.874402
2019-11-06 22:41:48,258 train 550 1.822563e-02 -0.860190
2019-11-06 22:41:58,030 train 600 1.823306e-02 -0.855941
2019-11-06 22:42:07,818 train 650 1.829926e-02 -8.161606
2019-11-06 22:42:17,610 train 700 1.830963e-02 -7.620460
2019-11-06 22:42:27,385 train 750 1.829988e-02 -7.173819
2019-11-06 22:42:37,169 train 800 1.832448e-02 -6.758492
2019-11-06 22:42:46,944 train 850 1.834446e-02 -6.395931
2019-11-06 22:42:49,868 training loss; R2: 1.835105e-02 -6.308360
2019-11-06 22:42:50,447 valid 000 1.663329e-02 -0.581474
2019-11-06 22:42:59,959 valid 050 1.976946e-02 -0.830444
2019-11-06 22:43:08,266 validation loss; R2: 1.985183e-02 -0.853435
2019-11-06 22:43:08,331 epoch 247 lr 1.000000e-05
2019-11-06 22:43:09,100 train 000 1.686806e-02 -0.393156
2019-11-06 22:43:18,829 train 050 1.824191e-02 -0.667697
2019-11-06 22:43:28,550 train 100 1.829313e-02 -0.667236
2019-11-06 22:43:38,303 train 150 1.847212e-02 -0.705893
2019-11-06 22:43:48,054 train 200 1.852698e-02 -0.686926
2019-11-06 22:43:57,825 train 250 1.844571e-02 -0.733621
2019-11-06 22:44:07,574 train 300 1.838728e-02 -0.724522
2019-11-06 22:44:17,321 train 350 1.842706e-02 -1.565522
2019-11-06 22:44:27,069 train 400 1.847294e-02 -1.475133
2019-11-06 22:44:36,815 train 450 1.846839e-02 -1.387793
2019-11-06 22:44:46,594 train 500 1.844447e-02 -1.325168
2019-11-06 22:44:56,369 train 550 1.841940e-02 -1.267877
2019-11-06 22:45:06,151 train 600 1.841450e-02 -1.213745
2019-11-06 22:45:15,924 train 650 1.835880e-02 -1.202862
2019-11-06 22:45:25,695 train 700 1.832704e-02 -1.191877
2019-11-06 22:45:35,466 train 750 1.831529e-02 -1.159143
2019-11-06 22:45:45,238 train 800 1.829653e-02 -1.126523
2019-11-06 22:45:55,012 train 850 1.829586e-02 -1.096618
2019-11-06 22:45:57,935 training loss; R2: 1.829940e-02 -1.086271
2019-11-06 22:45:58,607 valid 000 2.292036e-02 0.051529
2019-11-06 22:46:07,978 valid 050 1.954965e-02 -0.929947
2019-11-06 22:46:16,279 validation loss; R2: 1.940300e-02 -0.955584
2019-11-06 22:46:16,351 epoch 248 lr 1.000000e-05
2019-11-06 22:46:17,106 train 000 1.624919e-02 -0.084803
2019-11-06 22:46:26,839 train 050 1.795935e-02 -0.581204
2019-11-06 22:46:36,582 train 100 1.814724e-02 -0.631175
2019-11-06 22:46:46,329 train 150 1.825290e-02 -0.627592
2019-11-06 22:46:56,076 train 200 1.824025e-02 -2.348580
2019-11-06 22:47:05,830 train 250 1.824047e-02 -1.995893
2019-11-06 22:47:15,584 train 300 1.823722e-02 -1.794764
2019-11-06 22:47:25,339 train 350 1.827280e-02 -1.638597
2019-11-06 22:47:35,086 train 400 1.828412e-02 -1.545951
2019-11-06 22:47:44,856 train 450 1.830351e-02 -1.424167
2019-11-06 22:47:54,629 train 500 1.829306e-02 -1.345146
2019-11-06 22:48:04,408 train 550 1.830135e-02 -1.277856
2019-11-06 22:48:14,174 train 600 1.829323e-02 -1.221149
2019-11-06 22:48:23,959 train 650 1.830282e-02 -1.171361
2019-11-06 22:48:33,744 train 700 1.828580e-02 -1.160338
2019-11-06 22:48:43,538 train 750 1.831180e-02 -1.131935
2019-11-06 22:48:53,317 train 800 1.834097e-02 -1.110140
2019-11-06 22:49:03,082 train 850 1.831898e-02 -1.080498
2019-11-06 22:49:05,998 training loss; R2: 1.832098e-02 -1.074569
2019-11-06 22:49:06,673 valid 000 1.911541e-02 -1.218157
2019-11-06 22:49:16,088 valid 050 2.022851e-02 -0.979602
2019-11-06 22:49:24,453 validation loss; R2: 2.000266e-02 -1.217614
2019-11-06 22:49:24,521 epoch 249 lr 1.000000e-05
2019-11-06 22:49:25,269 train 000 1.999549e-02 -0.503488
2019-11-06 22:49:35,015 train 050 1.795357e-02 -0.740332
2019-11-06 22:49:44,751 train 100 1.820741e-02 -0.732354
2019-11-06 22:49:54,502 train 150 1.828849e-02 -0.783967
2019-11-06 22:50:04,256 train 200 1.826578e-02 -0.686234
2019-11-06 22:50:14,011 train 250 1.819784e-02 -0.735623
2019-11-06 22:50:23,765 train 300 1.821619e-02 -0.779300
2019-11-06 22:50:33,517 train 350 1.826855e-02 -0.744171
2019-11-06 22:50:43,288 train 400 1.829628e-02 -0.746527
2019-11-06 22:50:53,123 train 450 1.830153e-02 -0.730774
2019-11-06 22:51:03,283 train 500 1.831012e-02 -0.745394
2019-11-06 22:51:13,457 train 550 1.829597e-02 -0.747577
2019-11-06 22:51:23,628 train 600 1.827135e-02 -0.736436
2019-11-06 22:51:33,796 train 650 1.824348e-02 -0.730573
2019-11-06 22:51:43,969 train 700 1.822588e-02 -0.720509
2019-11-06 22:51:54,129 train 750 1.824115e-02 -0.705413
2019-11-06 22:52:04,293 train 800 1.824587e-02 -0.703559
2019-11-06 22:52:14,457 train 850 1.827943e-02 -0.715499
2019-11-06 22:52:17,489 training loss; R2: 1.827477e-02 -0.712801
2019-11-06 22:52:18,175 valid 000 2.175845e-02 -0.621427
2019-11-06 22:52:27,582 valid 050 1.927007e-02 -1.089114
2019-11-06 22:52:35,903 validation loss; R2: 1.961052e-02 -1.353748
2019-11-06 22:52:35,981 epoch 250 lr 1.000000e-05
2019-11-06 22:52:36,718 train 000 1.842662e-02 -0.611696
2019-11-06 22:52:46,454 train 050 1.830341e-02 -0.563419
2019-11-06 22:52:56,191 train 100 1.851271e-02 -0.627429
2019-11-06 22:53:05,934 train 150 1.850049e-02 -0.706137
2019-11-06 22:53:15,690 train 200 1.851317e-02 -0.642381
2019-11-06 22:53:25,445 train 250 1.842370e-02 -0.659444
2019-11-06 22:53:35,200 train 300 1.836574e-02 -0.638590
2019-11-06 22:53:44,953 train 350 1.836649e-02 -0.646936
2019-11-06 22:53:54,710 train 400 1.831272e-02 -0.640878
2019-11-06 22:54:04,501 train 450 1.831356e-02 -0.649454
2019-11-06 22:54:14,310 train 500 1.828134e-02 -0.739955
2019-11-06 22:54:24,116 train 550 1.828508e-02 -0.708958
2019-11-06 22:54:33,916 train 600 1.828824e-02 -0.740336
2019-11-06 22:54:43,724 train 650 1.828729e-02 -0.751749
2019-11-06 22:54:53,528 train 700 1.827945e-02 -0.747691
2019-11-06 22:55:03,334 train 750 1.827525e-02 -0.752589
2019-11-06 22:55:13,127 train 800 1.828825e-02 -0.742006
2019-11-06 22:55:22,921 train 850 1.830228e-02 -0.747638
2019-11-06 22:55:25,851 training loss; R2: 1.829233e-02 -0.745223
2019-11-06 22:55:26,476 valid 000 2.171477e-02 -0.493027
2019-11-06 22:55:35,919 valid 050 1.916373e-02 -1.055178
2019-11-06 22:55:44,261 validation loss; R2: 1.906869e-02 -0.966629
2019-11-06 22:55:44,327 epoch 251 lr 1.000000e-05
2019-11-06 22:55:45,115 train 000 1.892214e-02 -0.802449
2019-11-06 22:55:54,866 train 050 1.842962e-02 -0.731861
2019-11-06 22:56:04,626 train 100 1.825950e-02 -0.592584
2019-11-06 22:56:14,403 train 150 1.839129e-02 -0.728301
2019-11-06 22:56:24,184 train 200 1.831597e-02 -0.790579
2019-11-06 22:56:33,965 train 250 1.835399e-02 -0.780377
2019-11-06 22:56:43,746 train 300 1.832702e-02 -0.753589
2019-11-06 22:56:53,534 train 350 1.831360e-02 -0.756524
2019-11-06 22:57:03,347 train 400 1.830354e-02 -0.742751
2019-11-06 22:57:13,139 train 450 1.826957e-02 -0.748456
2019-11-06 22:57:22,951 train 500 1.828828e-02 -0.743740
2019-11-06 22:57:32,755 train 550 1.827154e-02 -0.789426
2019-11-06 22:57:42,562 train 600 1.827104e-02 -0.809461
2019-11-06 22:57:52,367 train 650 1.827429e-02 -0.805894
2019-11-06 22:58:02,155 train 700 1.825103e-02 -0.825623
2019-11-06 22:58:11,949 train 750 1.824411e-02 -0.812976
2019-11-06 22:58:21,749 train 800 1.820889e-02 -0.815098
2019-11-06 22:58:31,559 train 850 1.821452e-02 -0.804722
2019-11-06 22:58:34,495 training loss; R2: 1.821594e-02 -0.798104
2019-11-06 22:58:35,185 valid 000 1.913946e-02 -0.021457
2019-11-06 22:58:44,573 valid 050 1.919257e-02 -1.394068
2019-11-06 22:58:52,953 validation loss; R2: 1.926283e-02 -1.231583
2019-11-06 22:58:53,035 epoch 252 lr 1.000000e-05
2019-11-06 22:58:53,836 train 000 1.973713e-02 -0.324820
2019-11-06 22:59:03,596 train 050 1.865040e-02 -0.620689
2019-11-06 22:59:13,369 train 100 1.850624e-02 -0.740364
2019-11-06 22:59:23,167 train 150 1.827473e-02 -0.762618
2019-11-06 22:59:33,263 train 200 1.828765e-02 -0.772351
2019-11-06 22:59:43,425 train 250 1.828158e-02 -0.755685
2019-11-06 22:59:53,327 train 300 1.833883e-02 -0.738891
2019-11-06 23:00:03,103 train 350 1.836375e-02 -0.739348
2019-11-06 23:00:12,860 train 400 1.833508e-02 -0.731714
2019-11-06 23:00:22,639 train 450 1.827644e-02 -0.724023
2019-11-06 23:00:32,428 train 500 1.827583e-02 -0.826864
2019-11-06 23:00:42,210 train 550 1.828290e-02 -0.830818
2019-11-06 23:00:51,980 train 600 1.827999e-02 -0.845824
2019-11-06 23:01:01,765 train 650 1.830938e-02 -0.833634
2019-11-06 23:01:11,545 train 700 1.828366e-02 -0.819755
2019-11-06 23:01:21,355 train 750 1.827518e-02 -0.814695
2019-11-06 23:01:31,161 train 800 1.827120e-02 -0.800760
2019-11-06 23:01:40,984 train 850 1.826508e-02 -0.811373
2019-11-06 23:01:43,932 training loss; R2: 1.827752e-02 -0.809737
2019-11-06 23:01:44,536 valid 000 1.790032e-02 -0.472264
2019-11-06 23:01:53,978 valid 050 1.882300e-02 -1.127492
2019-11-06 23:02:02,419 validation loss; R2: 1.888349e-02 -0.994325
2019-11-06 23:02:02,508 epoch 253 lr 1.000000e-05
2019-11-06 23:02:03,337 train 000 1.749912e-02 -2.117191
2019-11-06 23:02:13,422 train 050 1.822861e-02 -0.542011
2019-11-06 23:02:23,528 train 100 1.819535e-02 -0.548551
2019-11-06 23:02:33,648 train 150 1.817882e-02 -0.609900
2019-11-06 23:02:43,770 train 200 1.811999e-02 -0.603142
2019-11-06 23:02:53,894 train 250 1.825761e-02 -0.618554
2019-11-06 23:03:04,014 train 300 1.835354e-02 -0.594260
2019-11-06 23:03:14,135 train 350 1.836364e-02 -0.608168
2019-11-06 23:03:24,261 train 400 1.828697e-02 -0.600094
2019-11-06 23:03:34,424 train 450 1.828408e-02 -0.648624
2019-11-06 23:03:44,611 train 500 1.828957e-02 -0.637152
2019-11-06 23:03:54,787 train 550 1.828120e-02 -0.651216
2019-11-06 23:04:04,958 train 600 1.826361e-02 -0.657789
2019-11-06 23:04:15,141 train 650 1.825593e-02 -0.660755
2019-11-06 23:04:25,306 train 700 1.822907e-02 -0.649915
2019-11-06 23:04:35,480 train 750 1.822070e-02 -0.655805
2019-11-06 23:04:45,653 train 800 1.820578e-02 -0.647295
2019-11-06 23:04:55,814 train 850 1.819680e-02 -0.641913
2019-11-06 23:04:58,856 training loss; R2: 1.820269e-02 -0.644256
2019-11-06 23:04:59,546 valid 000 1.897929e-02 -1.613397
2019-11-06 23:05:08,946 valid 050 1.907346e-02 -1.283394
2019-11-06 23:05:17,275 validation loss; R2: 1.944135e-02 -1.093704
2019-11-06 23:05:17,343 epoch 254 lr 1.000000e-05
2019-11-06 23:05:18,092 train 000 2.033297e-02 -7.609595
2019-11-06 23:05:28,199 train 050 1.816535e-02 -1.428807
2019-11-06 23:05:38,338 train 100 1.820003e-02 -1.102806
2019-11-06 23:05:48,484 train 150 1.821030e-02 -0.925302
2019-11-06 23:05:58,641 train 200 1.823231e-02 -0.941105
2019-11-06 23:06:08,782 train 250 1.815728e-02 -0.897456
2019-11-06 23:06:18,936 train 300 1.817688e-02 -0.858523
2019-11-06 23:06:29,099 train 350 1.821109e-02 -0.808144
2019-11-06 23:06:39,248 train 400 1.823372e-02 -0.830485
2019-11-06 23:06:49,384 train 450 1.822340e-02 -0.795389
2019-11-06 23:06:59,540 train 500 1.823507e-02 -0.784258
2019-11-06 23:07:09,721 train 550 1.822186e-02 -0.794725
2019-11-06 23:07:19,885 train 600 1.822651e-02 -0.773367
2019-11-06 23:07:30,069 train 650 1.819775e-02 -0.766666
2019-11-06 23:07:40,251 train 700 1.821019e-02 -0.762966
2019-11-06 23:07:50,423 train 750 1.819179e-02 -0.773629
2019-11-06 23:08:00,591 train 800 1.817615e-02 -0.787392
2019-11-06 23:08:10,760 train 850 1.818554e-02 -0.772965
2019-11-06 23:08:13,800 training loss; R2: 1.817907e-02 -0.768745
2019-11-06 23:08:14,424 valid 000 1.857455e-02 -0.326669
2019-11-06 23:08:23,862 valid 050 1.914880e-02 -1.367281
2019-11-06 23:08:32,197 validation loss; R2: 1.894148e-02 -1.227075
2019-11-06 23:08:32,262 epoch 255 lr 1.000000e-05
2019-11-06 23:08:33,049 train 000 1.781562e-02 -0.170471
2019-11-06 23:08:43,153 train 050 1.826298e-02 -0.931874
2019-11-06 23:08:53,175 train 100 1.831001e-02 -0.829344
2019-11-06 23:09:02,930 train 150 1.841622e-02 -0.815399
2019-11-06 23:09:12,678 train 200 1.836929e-02 -0.775375
2019-11-06 23:09:22,439 train 250 1.838429e-02 -0.761409
2019-11-06 23:09:32,202 train 300 1.837382e-02 -0.761105
2019-11-06 23:09:41,983 train 350 1.830584e-02 -0.774666
2019-11-06 23:09:51,763 train 400 1.833987e-02 -0.766902
2019-11-06 23:10:01,559 train 450 1.833631e-02 -0.868758
2019-11-06 23:10:11,353 train 500 1.832918e-02 -0.850178
2019-11-06 23:10:21,157 train 550 1.829314e-02 -0.878667
2019-11-06 23:10:30,967 train 600 1.827314e-02 -0.871825
2019-11-06 23:10:40,770 train 650 1.828819e-02 -0.857455
2019-11-06 23:10:50,576 train 700 1.828591e-02 -0.851223
2019-11-06 23:11:00,368 train 750 1.826101e-02 -0.948977
2019-11-06 23:11:10,181 train 800 1.825980e-02 -0.946762
2019-11-06 23:11:19,987 train 850 1.824814e-02 -0.935378
2019-11-06 23:11:22,919 training loss; R2: 1.824514e-02 -0.927996
2019-11-06 23:11:23,618 valid 000 2.096500e-02 -0.239304
2019-11-06 23:11:33,039 valid 050 1.931848e-02 -1.170672
2019-11-06 23:11:41,423 validation loss; R2: 1.976889e-02 -1.040255
2019-11-06 23:11:41,488 epoch 256 lr 1.000000e-05
2019-11-06 23:11:42,270 train 000 2.048178e-02 -0.203273
2019-11-06 23:11:52,000 train 050 1.810856e-02 -0.675741
2019-11-06 23:12:01,742 train 100 1.797531e-02 -1.251443
2019-11-06 23:12:11,498 train 150 1.799516e-02 -1.050516
2019-11-06 23:12:21,257 train 200 1.805162e-02 -0.998109
2019-11-06 23:12:31,019 train 250 1.805254e-02 -0.920374
2019-11-06 23:12:40,781 train 300 1.806567e-02 -0.879024
2019-11-06 23:12:50,553 train 350 1.809303e-02 -0.899099
2019-11-06 23:13:00,321 train 400 1.810929e-02 -0.855215
2019-11-06 23:13:10,109 train 450 1.814350e-02 -0.831496
2019-11-06 23:13:19,907 train 500 1.814934e-02 -0.803078
2019-11-06 23:13:29,707 train 550 1.814490e-02 -0.809496
2019-11-06 23:13:39,503 train 600 1.812886e-02 -0.810075
2019-11-06 23:13:49,311 train 650 1.814829e-02 -0.787850
2019-11-06 23:13:59,111 train 700 1.818369e-02 -0.779960
2019-11-06 23:14:08,919 train 750 1.818559e-02 -0.756438
2019-11-06 23:14:18,730 train 800 1.819902e-02 -0.758581
2019-11-06 23:14:28,536 train 850 1.820177e-02 -0.747313
2019-11-06 23:14:31,466 training loss; R2: 1.820080e-02 -0.748591
2019-11-06 23:14:32,083 valid 000 1.903699e-02 -1.040183
2019-11-06 23:14:41,539 valid 050 1.909250e-02 -1.245263
2019-11-06 23:14:49,838 validation loss; R2: 1.892008e-02 -1.105094
2019-11-06 23:14:49,907 epoch 257 lr 1.000000e-05
2019-11-06 23:14:50,680 train 000 2.089062e-02 -2.095598
2019-11-06 23:15:00,439 train 050 1.828614e-02 -0.827912
2019-11-06 23:15:10,254 train 100 1.850816e-02 -0.782586
2019-11-06 23:15:20,064 train 150 1.818214e-02 -1.001703
2019-11-06 23:15:29,836 train 200 1.831062e-02 -1.091265
2019-11-06 23:15:39,638 train 250 1.824480e-02 -0.956128
2019-11-06 23:15:49,463 train 300 1.828056e-02 -0.905399
2019-11-06 23:15:59,295 train 350 1.824353e-02 -0.905273
2019-11-06 23:16:09,147 train 400 1.823894e-02 -0.863244
2019-11-06 23:16:18,988 train 450 1.823443e-02 -0.870012
2019-11-06 23:16:28,831 train 500 1.825862e-02 -0.860536
2019-11-06 23:16:38,680 train 550 1.827319e-02 -0.846510
2019-11-06 23:16:48,534 train 600 1.828994e-02 -0.822152
2019-11-06 23:16:58,370 train 650 1.828252e-02 -0.796140
2019-11-06 23:17:08,212 train 700 1.827656e-02 -0.804549
2019-11-06 23:17:18,039 train 750 1.825905e-02 -0.800963
2019-11-06 23:17:27,870 train 800 1.823695e-02 -0.787890
2019-11-06 23:17:37,720 train 850 1.823530e-02 -0.788218
2019-11-06 23:17:40,659 training loss; R2: 1.823949e-02 -0.785347
2019-11-06 23:17:41,350 valid 000 2.054471e-02 -1.095743
2019-11-06 23:17:50,757 valid 050 2.068521e-02 -1.377611
2019-11-06 23:17:59,071 validation loss; R2: 2.044941e-02 -1.323205
2019-11-06 23:17:59,137 epoch 258 lr 1.000000e-05
2019-11-06 23:17:59,911 train 000 1.869736e-02 -0.169612
2019-11-06 23:18:09,667 train 050 1.845912e-02 -0.801511
2019-11-06 23:18:19,468 train 100 1.826982e-02 -0.750480
2019-11-06 23:18:29,221 train 150 1.809883e-02 -0.684645
2019-11-06 23:18:38,987 train 200 1.820317e-02 -0.754808
2019-11-06 23:18:48,760 train 250 1.818971e-02 -0.788660
2019-11-06 23:18:58,525 train 300 1.819024e-02 -0.775972
2019-11-06 23:19:08,283 train 350 1.819359e-02 -0.731163
2019-11-06 23:19:18,050 train 400 1.818673e-02 -0.708862
2019-11-06 23:19:27,838 train 450 1.820986e-02 -0.736106
2019-11-06 23:19:37,633 train 500 1.818215e-02 -0.739401
2019-11-06 23:19:47,438 train 550 1.818949e-02 -0.731572
2019-11-06 23:19:57,219 train 600 1.822031e-02 -0.742509
2019-11-06 23:20:07,012 train 650 1.821265e-02 -0.875978
2019-11-06 23:20:16,802 train 700 1.823824e-02 -0.861933
2019-11-06 23:20:26,590 train 750 1.824365e-02 -0.853867
2019-11-06 23:20:36,375 train 800 1.823579e-02 -0.838891
2019-11-06 23:20:46,167 train 850 1.823688e-02 -0.839024
2019-11-06 23:20:49,091 training loss; R2: 1.823437e-02 -0.840617
2019-11-06 23:20:49,742 valid 000 2.271755e-02 -0.503879
2019-11-06 23:20:59,184 valid 050 1.997108e-02 -1.338245
2019-11-06 23:21:07,505 validation loss; R2: 2.024052e-02 -1.159563
2019-11-06 23:21:07,582 epoch 259 lr 1.000000e-05
2019-11-06 23:21:08,356 train 000 2.092970e-02 -0.869790
2019-11-06 23:21:18,096 train 050 1.829693e-02 -0.565617
2019-11-06 23:21:27,816 train 100 1.817392e-02 -0.509056
2019-11-06 23:21:37,573 train 150 1.830492e-02 -0.579998
2019-11-06 23:21:47,325 train 200 1.829826e-02 -0.641943
2019-11-06 23:21:57,086 train 250 1.825632e-02 -0.677478
2019-11-06 23:22:06,838 train 300 1.821283e-02 -0.653469
2019-11-06 23:22:16,593 train 350 1.821439e-02 -0.654214
2019-11-06 23:22:26,366 train 400 1.825428e-02 -0.641644
2019-11-06 23:22:36,140 train 450 1.827890e-02 -0.639626
2019-11-06 23:22:45,920 train 500 1.830889e-02 -0.646837
2019-11-06 23:22:55,711 train 550 1.827437e-02 -0.660279
2019-11-06 23:23:05,495 train 600 1.824402e-02 -0.660675
2019-11-06 23:23:15,281 train 650 1.821302e-02 -0.681512
2019-11-06 23:23:25,069 train 700 1.822293e-02 -0.668275
2019-11-06 23:23:34,848 train 750 1.821695e-02 -0.665378
2019-11-06 23:23:44,634 train 800 1.818692e-02 -0.659143
2019-11-06 23:23:54,439 train 850 1.818208e-02 -0.661925
2019-11-06 23:23:57,369 training loss; R2: 1.817233e-02 -0.659365
2019-11-06 23:23:57,990 valid 000 1.828390e-02 0.062895
2019-11-06 23:24:07,420 valid 050 1.797906e-02 -1.074475
2019-11-06 23:24:15,801 validation loss; R2: 1.825049e-02 -0.890534
2019-11-06 23:24:15,865 epoch 260 lr 1.000000e-05
2019-11-06 23:24:16,665 train 000 2.098908e-02 -0.135107
2019-11-06 23:24:26,378 train 050 1.877430e-02 -0.987883
2019-11-06 23:24:36,089 train 100 1.854931e-02 -0.911998
2019-11-06 23:24:45,815 train 150 1.850129e-02 -2.485593
2019-11-06 23:24:55,537 train 200 1.841492e-02 -2.053295
2019-11-06 23:25:05,270 train 250 1.832086e-02 -1.751309
2019-11-06 23:25:15,007 train 300 1.822372e-02 -1.574256
2019-11-06 23:25:24,736 train 350 1.825165e-02 -1.444765
2019-11-06 23:25:34,481 train 400 1.827106e-02 -1.345661
2019-11-06 23:25:44,244 train 450 1.826817e-02 -1.284475
2019-11-06 23:25:54,016 train 500 1.825886e-02 -1.214321
2019-11-06 23:26:03,789 train 550 1.823756e-02 -1.172348
2019-11-06 23:26:13,558 train 600 1.820701e-02 -1.141040
2019-11-06 23:26:23,331 train 650 1.822606e-02 -1.109845
2019-11-06 23:26:33,110 train 700 1.822479e-02 -1.086056
2019-11-06 23:26:42,888 train 750 1.823199e-02 -1.058219
2019-11-06 23:26:52,664 train 800 1.821426e-02 -1.031430
2019-11-06 23:27:02,442 train 850 1.818046e-02 -1.013382
2019-11-06 23:27:05,364 training loss; R2: 1.817577e-02 -1.002279
2019-11-06 23:27:06,044 valid 000 1.964385e-02 -0.661637
2019-11-06 23:27:15,350 valid 050 1.995971e-02 -0.887788
2019-11-06 23:27:23,703 validation loss; R2: 1.991625e-02 -1.004922
2019-11-06 23:27:23,771 epoch 261 lr 1.000000e-05
2019-11-06 23:27:24,547 train 000 1.508707e-02 -0.171647
2019-11-06 23:27:34,274 train 050 1.840445e-02 -0.531607
2019-11-06 23:27:44,014 train 100 1.841783e-02 -0.580148
2019-11-06 23:27:53,765 train 150 1.839433e-02 -0.737663
2019-11-06 23:28:03,518 train 200 1.834638e-02 -0.797903
2019-11-06 23:28:13,286 train 250 1.838807e-02 -0.785955
2019-11-06 23:28:23,072 train 300 1.837774e-02 -0.786929
2019-11-06 23:28:32,886 train 350 1.832079e-02 -0.860160
2019-11-06 23:28:42,684 train 400 1.830648e-02 -0.866655
2019-11-06 23:28:52,505 train 450 1.824654e-02 -0.848478
2019-11-06 23:29:02,311 train 500 1.828043e-02 -0.815190
2019-11-06 23:29:12,115 train 550 1.827544e-02 -0.817965
2019-11-06 23:29:21,931 train 600 1.827557e-02 -0.797583
2019-11-06 23:29:31,741 train 650 1.824206e-02 -0.782950
2019-11-06 23:29:41,543 train 700 1.826193e-02 -0.787021
2019-11-06 23:29:51,356 train 750 1.826547e-02 -0.803372
2019-11-06 23:30:01,174 train 800 1.827288e-02 -0.811385
2019-11-06 23:30:10,981 train 850 1.824490e-02 -0.792580
2019-11-06 23:30:13,914 training loss; R2: 1.824475e-02 -0.783846
2019-11-06 23:30:14,612 valid 000 2.060739e-02 -0.497520
2019-11-06 23:30:23,947 valid 050 1.889574e-02 -0.838499
2019-11-06 23:30:32,323 validation loss; R2: 1.887400e-02 -0.927836
2019-11-06 23:30:32,389 epoch 262 lr 1.000000e-05
2019-11-06 23:30:33,170 train 000 1.704746e-02 -0.086658
2019-11-06 23:30:42,917 train 050 1.821771e-02 -0.672742
2019-11-06 23:30:52,644 train 100 1.821152e-02 -1.060948
2019-11-06 23:31:02,380 train 150 1.822631e-02 -0.910211
2019-11-06 23:31:12,118 train 200 1.835855e-02 -0.840222
2019-11-06 23:31:21,855 train 250 1.833700e-02 -0.764458
2019-11-06 23:31:31,603 train 300 1.824898e-02 -0.727556
2019-11-06 23:31:41,343 train 350 1.821611e-02 -0.708294
2019-11-06 23:31:51,083 train 400 1.816635e-02 -0.709630
2019-11-06 23:32:00,834 train 450 1.817187e-02 -0.715018
2019-11-06 23:32:10,605 train 500 1.818240e-02 -0.699302
2019-11-06 23:32:20,387 train 550 1.818352e-02 -0.685770
2019-11-06 23:32:30,172 train 600 1.821489e-02 -0.667481
2019-11-06 23:32:39,941 train 650 1.820132e-02 -0.672368
2019-11-06 23:32:49,726 train 700 1.819785e-02 -0.670279
2019-11-06 23:32:59,520 train 750 1.822566e-02 -0.658017
2019-11-06 23:33:09,295 train 800 1.821911e-02 -0.659855
2019-11-06 23:33:19,078 train 850 1.816093e-02 -0.654860
2019-11-06 23:33:22,010 training loss; R2: 1.815888e-02 -0.662515
2019-11-06 23:33:22,593 valid 000 1.805238e-02 -0.506998
2019-11-06 23:33:32,097 valid 050 1.821525e-02 -1.061566
2019-11-06 23:33:40,446 validation loss; R2: 1.820833e-02 -1.009919
2019-11-06 23:33:40,513 epoch 263 lr 1.000000e-05
2019-11-06 23:33:41,263 train 000 1.744841e-02 -0.344782
2019-11-06 23:33:50,996 train 050 1.831808e-02 -0.732859
2019-11-06 23:34:00,704 train 100 1.816903e-02 -0.841752
2019-11-06 23:34:10,444 train 150 1.808932e-02 -0.762785
2019-11-06 23:34:20,183 train 200 1.802972e-02 -0.753175
2019-11-06 23:34:29,926 train 250 1.814064e-02 -0.810266
2019-11-06 23:34:39,673 train 300 1.814963e-02 -76.729702
2019-11-06 23:34:49,422 train 350 1.816030e-02 -65.921284
2019-11-06 23:34:59,170 train 400 1.814836e-02 -57.816880
2019-11-06 23:35:08,921 train 450 1.818672e-02 -51.497962
2019-11-06 23:35:18,682 train 500 1.819376e-02 -46.452068
2019-11-06 23:35:28,455 train 550 1.821782e-02 -42.310435
2019-11-06 23:35:38,230 train 600 1.822664e-02 -38.835063
2019-11-06 23:35:48,005 train 650 1.818862e-02 -35.900067
2019-11-06 23:35:57,791 train 700 1.818032e-02 -33.374207
2019-11-06 23:36:07,567 train 750 1.819072e-02 -31.178567
2019-11-06 23:36:17,342 train 800 1.817210e-02 -29.278517
2019-11-06 23:36:27,122 train 850 1.816021e-02 -27.618748
2019-11-06 23:36:30,039 training loss; R2: 1.814928e-02 -29.434954
2019-11-06 23:36:30,664 valid 000 1.792679e-02 -0.112695
2019-11-06 23:36:40,074 valid 050 1.864885e-02 -1.016155
2019-11-06 23:36:48,381 validation loss; R2: 1.850095e-02 -1.007071
2019-11-06 23:36:48,446 epoch 264 lr 1.000000e-05
2019-11-06 23:36:49,220 train 000 1.561114e-02 -1.155237
2019-11-06 23:36:58,937 train 050 1.808186e-02 -0.876643
2019-11-06 23:37:08,668 train 100 1.803214e-02 -0.713892
2019-11-06 23:37:18,452 train 150 1.795581e-02 -0.697051
2019-11-06 23:37:28,488 train 200 1.792535e-02 -0.754814
2019-11-06 23:37:38,624 train 250 1.789429e-02 -0.744024
2019-11-06 23:37:48,754 train 300 1.795449e-02 -0.761631
2019-11-06 23:37:58,887 train 350 1.799447e-02 -0.737513
2019-11-06 23:38:09,016 train 400 1.802530e-02 -0.752229
2019-11-06 23:38:19,150 train 450 1.804406e-02 -0.745476
2019-11-06 23:38:29,313 train 500 1.804354e-02 -0.729540
2019-11-06 23:38:39,473 train 550 1.808677e-02 -0.722117
2019-11-06 23:38:49,640 train 600 1.810555e-02 -0.718295
2019-11-06 23:38:59,797 train 650 1.812509e-02 -0.715691
2019-11-06 23:39:09,972 train 700 1.814813e-02 -0.716911
2019-11-06 23:39:20,123 train 750 1.815142e-02 -0.702294
2019-11-06 23:39:30,290 train 800 1.814396e-02 -0.731557
2019-11-06 23:39:40,485 train 850 1.813503e-02 -0.753184
2019-11-06 23:39:43,520 training loss; R2: 1.814245e-02 -0.747980
2019-11-06 23:39:44,213 valid 000 2.162051e-02 -0.290715
2019-11-06 23:39:53,609 valid 050 1.967035e-02 -1.259549
2019-11-06 23:40:01,974 validation loss; R2: 1.964320e-02 -1.290980
2019-11-06 23:40:02,036 epoch 265 lr 1.000000e-05
2019-11-06 23:40:02,830 train 000 2.047833e-02 -0.060274
2019-11-06 23:40:12,903 train 050 1.805969e-02 -0.661823
2019-11-06 23:40:22,999 train 100 1.808573e-02 -0.609316
2019-11-06 23:40:33,119 train 150 1.811189e-02 -0.565372
2019-11-06 23:40:43,231 train 200 1.799548e-02 -0.759733
2019-11-06 23:40:53,338 train 250 1.803001e-02 -0.719731
2019-11-06 23:41:03,467 train 300 1.802033e-02 -0.702539
2019-11-06 23:41:13,590 train 350 1.809756e-02 -0.677904
2019-11-06 23:41:23,710 train 400 1.808765e-02 -0.670210
2019-11-06 23:41:33,824 train 450 1.811861e-02 -0.658335
2019-11-06 23:41:43,680 train 500 1.814554e-02 -0.701998
2019-11-06 23:41:53,405 train 550 1.816447e-02 -0.678922
2019-11-06 23:42:03,134 train 600 1.816387e-02 -0.675664
2019-11-06 23:42:12,854 train 650 1.814742e-02 -0.684698
2019-11-06 23:42:22,598 train 700 1.813892e-02 -1.112696
2019-11-06 23:42:32,350 train 750 1.815257e-02 -1.095859
2019-11-06 23:42:42,095 train 800 1.815974e-02 -1.080560
2019-11-06 23:42:51,857 train 850 1.816133e-02 -1.059590
2019-11-06 23:42:54,775 training loss; R2: 1.815803e-02 -1.047385
2019-11-06 23:42:55,464 valid 000 1.812401e-02 -6.832872
2019-11-06 23:43:04,859 valid 050 2.024649e-02 -1.394926
2019-11-06 23:43:13,186 validation loss; R2: 2.054101e-02 -1.260752
2019-11-06 23:43:13,250 epoch 266 lr 1.000000e-05
2019-11-06 23:43:13,998 train 000 1.962895e-02 -0.484878
2019-11-06 23:43:23,726 train 050 1.845980e-02 -0.793116
2019-11-06 23:43:33,474 train 100 1.827045e-02 -1.600744
2019-11-06 23:43:43,222 train 150 1.814198e-02 -1.284500
2019-11-06 23:43:52,960 train 200 1.822249e-02 -1.531169
2019-11-06 23:44:02,714 train 250 1.820955e-02 -1.856806
2019-11-06 23:44:12,490 train 300 1.816200e-02 -1.702718
2019-11-06 23:44:22,266 train 350 1.816912e-02 -1.573850
2019-11-06 23:44:32,046 train 400 1.815713e-02 -1.462697
2019-11-06 23:44:41,826 train 450 1.821507e-02 -1.364867
2019-11-06 23:44:51,616 train 500 1.824543e-02 -1.311109
2019-11-06 23:45:01,418 train 550 1.821304e-02 -1.250614
2019-11-06 23:45:11,223 train 600 1.820690e-02 -1.190010
2019-11-06 23:45:21,017 train 650 1.822626e-02 -1.150063
2019-11-06 23:45:30,805 train 700 1.820563e-02 -1.118480
2019-11-06 23:45:40,609 train 750 1.819165e-02 -1.099619
2019-11-06 23:45:50,406 train 800 1.818971e-02 -1.072835
2019-11-06 23:46:00,201 train 850 1.816812e-02 -1.032144
2019-11-06 23:46:03,126 training loss; R2: 1.815171e-02 -1.027986
2019-11-06 23:46:03,702 valid 000 1.989271e-02 0.028852
2019-11-06 23:46:13,136 valid 050 1.901994e-02 -1.079485
2019-11-06 23:46:21,412 validation loss; R2: 1.916281e-02 -1.198879
2019-11-06 23:46:21,479 epoch 267 lr 1.000000e-05
2019-11-06 23:46:22,265 train 000 1.946307e-02 -1.738275
2019-11-06 23:46:32,006 train 050 1.792761e-02 -0.577981
2019-11-06 23:46:41,782 train 100 1.810738e-02 -0.619088
2019-11-06 23:46:51,546 train 150 1.807143e-02 -0.641495
2019-11-06 23:47:01,318 train 200 1.806019e-02 -0.589225
2019-11-06 23:47:11,093 train 250 1.805890e-02 -0.716251
2019-11-06 23:47:20,876 train 300 1.803701e-02 -0.683472
2019-11-06 23:47:30,678 train 350 1.801479e-02 -0.709131
2019-11-06 23:47:40,457 train 400 1.806325e-02 -0.717614
2019-11-06 23:47:50,244 train 450 1.808714e-02 -0.695825
2019-11-06 23:48:00,027 train 500 1.812860e-02 -0.702678
2019-11-06 23:48:09,812 train 550 1.811710e-02 -0.708997
2019-11-06 23:48:19,611 train 600 1.813122e-02 -0.990544
2019-11-06 23:48:29,409 train 650 1.811787e-02 -0.956276
2019-11-06 23:48:39,203 train 700 1.813015e-02 -0.959004
2019-11-06 23:48:48,999 train 750 1.812932e-02 -0.937710
2019-11-06 23:48:58,806 train 800 1.813172e-02 -0.915153
2019-11-06 23:49:08,606 train 850 1.813588e-02 -0.922060
2019-11-06 23:49:11,533 training loss; R2: 1.813609e-02 -0.917326
2019-11-06 23:49:12,235 valid 000 1.847824e-02 -0.568840
2019-11-06 23:49:21,616 valid 050 1.945247e-02 -3.670570
2019-11-06 23:49:30,025 validation loss; R2: 1.925427e-02 -2.324571
2019-11-06 23:49:30,092 epoch 268 lr 1.000000e-05
2019-11-06 23:49:30,890 train 000 1.807448e-02 -0.347672
2019-11-06 23:49:40,611 train 050 1.831761e-02 -1.379104
2019-11-06 23:49:50,340 train 100 1.819043e-02 -0.895552
2019-11-06 23:50:00,090 train 150 1.820416e-02 -0.719092
2019-11-06 23:50:09,872 train 200 1.816421e-02 -0.720466
2019-11-06 23:50:20,027 train 250 1.817528e-02 -0.719451
2019-11-06 23:50:30,199 train 300 1.817085e-02 -0.749154
2019-11-06 23:50:40,370 train 350 1.820016e-02 -0.787822
2019-11-06 23:50:50,534 train 400 1.820359e-02 -0.766058
2019-11-06 23:51:00,686 train 450 1.819413e-02 -0.757846
2019-11-06 23:51:10,843 train 500 1.820822e-02 -0.756999
2019-11-06 23:51:20,985 train 550 1.816295e-02 -0.764013
2019-11-06 23:51:30,881 train 600 1.814489e-02 -0.908766
2019-11-06 23:51:40,651 train 650 1.817836e-02 -0.994388
2019-11-06 23:51:50,437 train 700 1.817464e-02 -0.965953
2019-11-06 23:52:00,247 train 750 1.816265e-02 -0.945026
2019-11-06 23:52:10,051 train 800 1.815312e-02 -1.225667
2019-11-06 23:52:19,860 train 850 1.816319e-02 -1.203582
2019-11-06 23:52:22,792 training loss; R2: 1.816241e-02 -1.206169
2019-11-06 23:52:23,468 valid 000 2.125751e-02 -1.084122
2019-11-06 23:52:32,873 valid 050 1.915184e-02 -0.998565
2019-11-06 23:52:41,214 validation loss; R2: 1.926155e-02 -0.971600
2019-11-06 23:52:41,279 epoch 269 lr 1.000000e-05
2019-11-06 23:52:42,070 train 000 2.042640e-02 -0.755891
2019-11-06 23:52:51,803 train 050 1.805245e-02 -0.575711
2019-11-06 23:53:01,557 train 100 1.813752e-02 -0.646647
2019-11-06 23:53:11,324 train 150 1.824925e-02 -0.608383
2019-11-06 23:53:21,080 train 200 1.826733e-02 -0.655302
2019-11-06 23:53:30,832 train 250 1.812237e-02 -0.720804
2019-11-06 23:53:40,592 train 300 1.808705e-02 -0.771863
2019-11-06 23:53:50,354 train 350 1.803581e-02 -0.771997
2019-11-06 23:54:00,134 train 400 1.804845e-02 -0.789302
2019-11-06 23:54:09,921 train 450 1.809915e-02 -0.814189
2019-11-06 23:54:19,718 train 500 1.810353e-02 -0.799039
2019-11-06 23:54:29,515 train 550 1.811002e-02 -0.789397
2019-11-06 23:54:39,308 train 600 1.812912e-02 -0.762506
2019-11-06 23:54:49,101 train 650 1.816004e-02 -0.741697
2019-11-06 23:54:58,870 train 700 1.814351e-02 -0.730702
2019-11-06 23:55:08,654 train 750 1.813684e-02 -0.726143
2019-11-06 23:55:18,478 train 800 1.815384e-02 -0.721389
2019-11-06 23:55:28,300 train 850 1.816383e-02 -0.715845
2019-11-06 23:55:31,236 training loss; R2: 1.817182e-02 -0.738415
2019-11-06 23:55:31,891 valid 000 1.832599e-02 -1.492833
2019-11-06 23:55:41,379 valid 050 1.873341e-02 -1.287674
2019-11-06 23:55:49,736 validation loss; R2: 1.914611e-02 -1.255085
2019-11-06 23:55:49,806 epoch 270 lr 1.000000e-05
2019-11-06 23:55:50,581 train 000 2.082155e-02 -0.832630
2019-11-06 23:56:00,333 train 050 1.819589e-02 -0.602342
2019-11-06 23:56:10,092 train 100 1.826028e-02 -0.605440
2019-11-06 23:56:19,882 train 150 1.807665e-02 -0.659498
2019-11-06 23:56:29,694 train 200 1.810815e-02 -0.680809
2019-11-06 23:56:39,509 train 250 1.808044e-02 -0.674196
2019-11-06 23:56:49,347 train 300 1.804771e-02 -0.633274
2019-11-06 23:56:59,180 train 350 1.809725e-02 -0.868177
2019-11-06 23:57:09,009 train 400 1.805756e-02 -0.835245
2019-11-06 23:57:18,813 train 450 1.806068e-02 -0.836263
2019-11-06 23:57:28,613 train 500 1.809600e-02 -0.806149
2019-11-06 23:57:38,407 train 550 1.806534e-02 -0.791132
2019-11-06 23:57:48,213 train 600 1.808139e-02 -0.781593
2019-11-06 23:57:58,013 train 650 1.805628e-02 -0.765390
2019-11-06 23:58:07,798 train 700 1.804448e-02 -1.382977
2019-11-06 23:58:17,600 train 750 1.805045e-02 -1.336401
2019-11-06 23:58:27,402 train 800 1.804888e-02 -1.291519
2019-11-06 23:58:37,199 train 850 1.805379e-02 -1.267328
2019-11-06 23:58:40,132 training loss; R2: 1.805736e-02 -1.272559
2019-11-06 23:58:40,830 valid 000 2.012747e-02 -0.707134
2019-11-06 23:58:50,180 valid 050 1.935358e-02 -1.353283
2019-11-06 23:58:58,494 validation loss; R2: 1.901860e-02 -1.028962
2019-11-06 23:58:58,557 epoch 271 lr 1.000000e-05
2019-11-06 23:58:59,312 train 000 1.542255e-02 0.011070
2019-11-06 23:59:09,033 train 050 1.811469e-02 -0.584129
2019-11-06 23:59:18,764 train 100 1.812776e-02 -0.655826
2019-11-06 23:59:28,504 train 150 1.804366e-02 -0.671797
2019-11-06 23:59:38,268 train 200 1.808418e-02 -0.725537
2019-11-06 23:59:48,035 train 250 1.800314e-02 -0.740493
2019-11-06 23:59:57,808 train 300 1.810218e-02 -0.808836
2019-11-07 00:00:07,577 train 350 1.811722e-02 -0.831137
2019-11-07 00:00:17,365 train 400 1.812158e-02 -0.815930
2019-11-07 00:00:27,135 train 450 1.810118e-02 -0.799781
2019-11-07 00:00:36,900 train 500 1.809805e-02 -0.783673
2019-11-07 00:00:46,667 train 550 1.810736e-02 -0.775843
2019-11-07 00:00:56,436 train 600 1.810422e-02 -0.780616
2019-11-07 00:01:06,210 train 650 1.812814e-02 -0.793509
2019-11-07 00:01:15,991 train 700 1.814031e-02 -0.778089
2019-11-07 00:01:25,757 train 750 1.811344e-02 -0.768860
2019-11-07 00:01:35,535 train 800 1.812938e-02 -0.761130
2019-11-07 00:01:45,312 train 850 1.814947e-02 -0.744849
2019-11-07 00:01:48,232 training loss; R2: 1.815508e-02 -0.746904
2019-11-07 00:01:48,925 valid 000 1.765163e-02 -0.061085
2019-11-07 00:01:58,302 valid 050 1.827954e-02 -1.048583
2019-11-07 00:02:06,663 validation loss; R2: 1.826678e-02 -1.082670
2019-11-07 00:02:06,729 epoch 272 lr 1.000000e-05
2019-11-07 00:02:07,514 train 000 1.627067e-02 -0.202284
2019-11-07 00:02:17,234 train 050 1.841519e-02 -0.649839
2019-11-07 00:02:26,970 train 100 1.806828e-02 -0.700058
2019-11-07 00:02:36,730 train 150 1.828307e-02 -0.743110
2019-11-07 00:02:46,505 train 200 1.823752e-02 -0.745875
2019-11-07 00:02:56,262 train 250 1.821048e-02 -0.753549
2019-11-07 00:03:06,040 train 300 1.817122e-02 -0.740340
2019-11-07 00:03:15,825 train 350 1.814903e-02 -0.780532
2019-11-07 00:03:25,591 train 400 1.814898e-02 -0.756600
2019-11-07 00:03:35,358 train 450 1.816979e-02 -0.750460
2019-11-07 00:03:45,130 train 500 1.815695e-02 -0.737400
2019-11-07 00:03:54,906 train 550 1.815539e-02 -0.730036
2019-11-07 00:04:04,718 train 600 1.816036e-02 -0.729756
2019-11-07 00:04:14,516 train 650 1.819515e-02 -2.346353
2019-11-07 00:04:24,292 train 700 1.821097e-02 -2.226236
2019-11-07 00:04:34,080 train 750 1.821344e-02 -2.179522
2019-11-07 00:04:43,863 train 800 1.818994e-02 -2.077717
2019-11-07 00:04:53,707 train 850 1.816146e-02 -1.986158
2019-11-07 00:04:56,664 training loss; R2: 1.814859e-02 -1.967175
2019-11-07 00:04:57,285 valid 000 1.877987e-02 -0.420079
2019-11-07 00:05:06,765 valid 050 1.885701e-02 -1.015604
2019-11-07 00:05:15,119 validation loss; R2: 1.878615e-02 -0.897708
2019-11-07 00:05:15,200 epoch 273 lr 1.000000e-05
2019-11-07 00:05:16,039 train 000 1.778508e-02 -0.742571
2019-11-07 00:05:26,150 train 050 1.780186e-02 -0.852884
2019-11-07 00:05:36,302 train 100 1.789228e-02 -0.791944
2019-11-07 00:05:46,453 train 150 1.817388e-02 -0.854320
2019-11-07 00:05:56,626 train 200 1.811338e-02 -0.773389
2019-11-07 00:06:06,795 train 250 1.820084e-02 -0.747761
2019-11-07 00:06:16,964 train 300 1.819024e-02 -0.700449
2019-11-07 00:06:27,128 train 350 1.816818e-02 -0.712014
2019-11-07 00:06:37,301 train 400 1.817776e-02 -0.710004
2019-11-07 00:06:47,462 train 450 1.816996e-02 -0.775179
2019-11-07 00:06:57,619 train 500 1.816530e-02 -0.800825
2019-11-07 00:07:07,780 train 550 1.813326e-02 -0.793375
2019-11-07 00:07:17,946 train 600 1.810929e-02 -0.809541
2019-11-07 00:07:27,759 train 650 1.813523e-02 -0.788734
2019-11-07 00:07:37,595 train 700 1.814676e-02 -0.781177
2019-11-07 00:07:47,426 train 750 1.813710e-02 -0.801602
2019-11-07 00:07:57,259 train 800 1.810993e-02 -0.799411
2019-11-07 00:08:07,079 train 850 1.809653e-02 -0.793616
2019-11-07 00:08:10,015 training loss; R2: 1.808442e-02 -0.793886
2019-11-07 00:08:10,637 valid 000 1.665162e-02 0.027758
2019-11-07 00:08:20,052 valid 050 1.790474e-02 -1.236051
2019-11-07 00:08:28,357 validation loss; R2: 1.785948e-02 -0.992159
2019-11-07 00:08:28,423 epoch 274 lr 1.000000e-05
2019-11-07 00:08:29,185 train 000 1.633907e-02 -0.373595
2019-11-07 00:08:38,940 train 050 1.744035e-02 -0.457530
2019-11-07 00:08:48,715 train 100 1.784687e-02 -0.753458
2019-11-07 00:08:58,530 train 150 1.784776e-02 -0.783339
2019-11-07 00:09:08,350 train 200 1.796375e-02 -0.788785
2019-11-07 00:09:18,178 train 250 1.794854e-02 -0.800405
2019-11-07 00:09:28,008 train 300 1.800485e-02 -0.778971
2019-11-07 00:09:37,866 train 350 1.804459e-02 -0.762739
2019-11-07 00:09:47,688 train 400 1.802733e-02 -0.783417
2019-11-07 00:09:57,513 train 450 1.802653e-02 -0.775666
2019-11-07 00:10:07,343 train 500 1.801497e-02 -0.757924
2019-11-07 00:10:17,161 train 550 1.799929e-02 -0.734175
2019-11-07 00:10:26,982 train 600 1.803681e-02 -0.718738
2019-11-07 00:10:36,806 train 650 1.803785e-02 -0.767626
2019-11-07 00:10:46,622 train 700 1.806366e-02 -0.841192
2019-11-07 00:10:56,443 train 750 1.806144e-02 -0.835756
2019-11-07 00:11:06,267 train 800 1.805461e-02 -0.883928
2019-11-07 00:11:16,098 train 850 1.804754e-02 -0.863842
2019-11-07 00:11:19,033 training loss; R2: 1.805536e-02 -0.860539
2019-11-07 00:11:19,704 valid 000 2.447274e-02 -0.507355
2019-11-07 00:11:29,061 valid 050 2.029056e-02 -1.048256
2019-11-07 00:11:37,453 validation loss; R2: 2.032805e-02 -1.202846
2019-11-07 00:11:37,518 epoch 275 lr 1.000000e-05
2019-11-07 00:11:38,300 train 000 1.847161e-02 -0.018025
2019-11-07 00:11:48,044 train 050 1.831616e-02 -0.636027
2019-11-07 00:11:57,837 train 100 1.806526e-02 -0.634767
2019-11-07 00:12:07,632 train 150 1.795478e-02 -0.684657
2019-11-07 00:12:17,437 train 200 1.805562e-02 -0.698520
2019-11-07 00:12:27,259 train 250 1.802275e-02 -0.694682
2019-11-07 00:12:37,098 train 300 1.799603e-02 -0.718185
2019-11-07 00:12:46,932 train 350 1.802921e-02 -0.695260
2019-11-07 00:12:56,765 train 400 1.799918e-02 -0.713973
2019-11-07 00:13:06,609 train 450 1.802860e-02 -0.698809
2019-11-07 00:13:16,458 train 500 1.802540e-02 -0.686087
2019-11-07 00:13:26,308 train 550 1.805103e-02 -0.695208
2019-11-07 00:13:36,166 train 600 1.808888e-02 -0.722125
2019-11-07 00:13:46,005 train 650 1.808738e-02 -0.703922
2019-11-07 00:13:55,842 train 700 1.812561e-02 -0.703938
2019-11-07 00:14:05,686 train 750 1.816503e-02 -0.695355
2019-11-07 00:14:15,527 train 800 1.815159e-02 -0.686340
2019-11-07 00:14:25,368 train 850 1.814011e-02 -0.688611
2019-11-07 00:14:28,308 training loss; R2: 1.813092e-02 -0.688485
2019-11-07 00:14:28,935 valid 000 2.125785e-02 -0.639983
2019-11-07 00:14:38,355 valid 050 1.999324e-02 -1.691634
2019-11-07 00:14:46,674 validation loss; R2: 2.018768e-02 -1.488544
2019-11-07 00:14:46,740 epoch 276 lr 1.000000e-05
2019-11-07 00:14:47,483 train 000 1.556450e-02 -0.598873
2019-11-07 00:14:57,240 train 050 1.786124e-02 -0.680049
2019-11-07 00:15:07,001 train 100 1.802603e-02 -0.719689
2019-11-07 00:15:16,803 train 150 1.805605e-02 -0.716631
2019-11-07 00:15:26,621 train 200 1.805646e-02 -0.841060
2019-11-07 00:15:36,436 train 250 1.797157e-02 -0.847658
2019-11-07 00:15:46,230 train 300 1.797694e-02 -0.847796
2019-11-07 00:15:56,027 train 350 1.804254e-02 -0.818081
2019-11-07 00:16:05,828 train 400 1.808667e-02 -0.798671
2019-11-07 00:16:15,630 train 450 1.814308e-02 -0.790458
2019-11-07 00:16:25,432 train 500 1.808986e-02 -0.764429
2019-11-07 00:16:35,227 train 550 1.808476e-02 -1.539312
2019-11-07 00:16:45,023 train 600 1.809342e-02 -1.482901
2019-11-07 00:16:54,832 train 650 1.807458e-02 -1.431241
2019-11-07 00:17:04,630 train 700 1.809284e-02 -1.369465
2019-11-07 00:17:14,441 train 750 1.810571e-02 -1.318128
2019-11-07 00:17:24,254 train 800 1.813068e-02 -1.273736
2019-11-07 00:17:34,057 train 850 1.812298e-02 -1.233229
2019-11-07 00:17:36,990 training loss; R2: 1.812029e-02 -1.222355
2019-11-07 00:17:37,582 valid 000 1.714579e-02 0.005434
2019-11-07 00:17:47,043 valid 050 1.856884e-02 -0.765220
2019-11-07 00:17:55,384 validation loss; R2: 1.837286e-02 -0.958751
2019-11-07 00:17:55,451 epoch 277 lr 1.000000e-05
2019-11-07 00:17:56,235 train 000 1.922636e-02 -0.375146
2019-11-07 00:18:05,969 train 050 1.847011e-02 -0.760877
2019-11-07 00:18:15,726 train 100 1.812486e-02 -0.724681
2019-11-07 00:18:25,511 train 150 1.802536e-02 -0.811039
2019-11-07 00:18:35,298 train 200 1.807493e-02 -0.778407
2019-11-07 00:18:45,084 train 250 1.817222e-02 -0.760172
2019-11-07 00:18:54,858 train 300 1.814066e-02 -0.794294
2019-11-07 00:19:04,649 train 350 1.805110e-02 -0.762037
2019-11-07 00:19:14,437 train 400 1.801450e-02 -0.734622
2019-11-07 00:19:24,227 train 450 1.802975e-02 -0.771072
2019-11-07 00:19:34,017 train 500 1.802781e-02 -0.792096
2019-11-07 00:19:43,809 train 550 1.805811e-02 -0.797432
2019-11-07 00:19:53,601 train 600 1.808216e-02 -0.781954
2019-11-07 00:20:03,384 train 650 1.808082e-02 -0.755251
2019-11-07 00:20:13,145 train 700 1.812779e-02 -0.742206
2019-11-07 00:20:22,911 train 750 1.813635e-02 -0.796762
2019-11-07 00:20:32,683 train 800 1.812681e-02 -0.791632
2019-11-07 00:20:42,443 train 850 1.813934e-02 -0.776306
2019-11-07 00:20:45,361 training loss; R2: 1.811795e-02 -0.773325
2019-11-07 00:20:46,040 valid 000 1.940888e-02 -2.958478
2019-11-07 00:20:55,460 valid 050 1.909262e-02 -1.076790
2019-11-07 00:21:03,853 validation loss; R2: 1.907783e-02 -0.931284
2019-11-07 00:21:03,919 epoch 278 lr 1.000000e-05
2019-11-07 00:21:04,696 train 000 1.707637e-02 -1.486158
2019-11-07 00:21:14,437 train 050 1.834350e-02 -0.747711
2019-11-07 00:21:24,184 train 100 1.821225e-02 -0.820246
2019-11-07 00:21:33,939 train 150 1.831367e-02 -0.851240
2019-11-07 00:21:43,687 train 200 1.835155e-02 -0.821732
2019-11-07 00:21:53,449 train 250 1.839352e-02 -0.808083
2019-11-07 00:22:03,223 train 300 1.835821e-02 -0.823916
2019-11-07 00:22:12,992 train 350 1.832886e-02 -0.797696
2019-11-07 00:22:22,766 train 400 1.828933e-02 -0.802856
2019-11-07 00:22:32,540 train 450 1.827239e-02 -0.795563
2019-11-07 00:22:42,318 train 500 1.821644e-02 -0.772592
2019-11-07 00:22:52,090 train 550 1.817089e-02 -0.750598
2019-11-07 00:23:01,879 train 600 1.813025e-02 -0.733176
2019-11-07 00:23:11,651 train 650 1.811289e-02 -0.728064
2019-11-07 00:23:21,446 train 700 1.806865e-02 -0.714555
2019-11-07 00:23:31,230 train 750 1.806328e-02 -0.699861
2019-11-07 00:23:41,034 train 800 1.808327e-02 -0.708383
2019-11-07 00:23:50,839 train 850 1.806380e-02 -0.710906
2019-11-07 00:23:53,761 training loss; R2: 1.805622e-02 -0.715811
2019-11-07 00:23:54,380 valid 000 1.992418e-02 0.045649
2019-11-07 00:24:03,830 valid 050 1.981600e-02 -0.874400
2019-11-07 00:24:12,164 validation loss; R2: 1.934820e-02 -2.517113
2019-11-07 00:24:12,249 epoch 279 lr 1.000000e-05
2019-11-07 00:24:13,071 train 000 1.718800e-02 -0.404940
2019-11-07 00:24:22,815 train 050 1.799301e-02 -2.527138
2019-11-07 00:24:32,597 train 100 1.801817e-02 -1.599614
2019-11-07 00:24:42,379 train 150 1.798430e-02 -1.300086
2019-11-07 00:24:52,181 train 200 1.804109e-02 -1.159990
2019-11-07 00:25:01,976 train 250 1.798943e-02 -1.104667
2019-11-07 00:25:11,769 train 300 1.800963e-02 -1.052761
2019-11-07 00:25:21,559 train 350 1.806242e-02 -1.036811
2019-11-07 00:25:31,343 train 400 1.805781e-02 -0.996309
2019-11-07 00:25:41,137 train 450 1.809140e-02 -0.968692
2019-11-07 00:25:50,920 train 500 1.806400e-02 -0.938884
2019-11-07 00:26:00,710 train 550 1.805245e-02 -0.924316
2019-11-07 00:26:10,497 train 600 1.812097e-02 -0.920005
2019-11-07 00:26:20,298 train 650 1.811159e-02 -0.890480
2019-11-07 00:26:30,094 train 700 1.809592e-02 -0.873287
2019-11-07 00:26:39,892 train 750 1.806970e-02 -0.867582
2019-11-07 00:26:49,683 train 800 1.809121e-02 -0.883911
2019-11-07 00:26:59,480 train 850 1.809120e-02 -0.875966
2019-11-07 00:27:02,404 training loss; R2: 1.807673e-02 -0.962029
2019-11-07 00:27:02,988 valid 000 1.529851e-02 -3.544264
2019-11-07 00:27:12,425 valid 050 1.843302e-02 -0.884177
2019-11-07 00:27:20,789 validation loss; R2: 1.838784e-02 -0.969174
2019-11-07 00:27:20,857 epoch 280 lr 1.000000e-05
2019-11-07 00:27:21,626 train 000 1.766768e-02 -0.287351
2019-11-07 00:27:31,341 train 050 1.828388e-02 -0.531839
2019-11-07 00:27:41,072 train 100 1.807451e-02 -0.617185
2019-11-07 00:27:50,833 train 150 1.811377e-02 -0.625424
2019-11-07 00:28:00,616 train 200 1.813010e-02 -0.627898
2019-11-07 00:28:10,415 train 250 1.817860e-02 -0.837348
2019-11-07 00:28:20,220 train 300 1.811142e-02 -0.827049
2019-11-07 00:28:30,021 train 350 1.806093e-02 -0.838977
2019-11-07 00:28:39,824 train 400 1.804970e-02 -0.874148
2019-11-07 00:28:49,632 train 450 1.806119e-02 -0.865797
2019-11-07 00:28:59,424 train 500 1.804503e-02 -0.831900
2019-11-07 00:29:09,196 train 550 1.807288e-02 -0.809358
2019-11-07 00:29:18,982 train 600 1.805881e-02 -0.811131
2019-11-07 00:29:28,741 train 650 1.802749e-02 -0.790157
2019-11-07 00:29:38,500 train 700 1.801377e-02 -0.793618
2019-11-07 00:29:48,269 train 750 1.802404e-02 -0.770919
2019-11-07 00:29:58,051 train 800 1.802517e-02 -0.768903
2019-11-07 00:30:07,819 train 850 1.800499e-02 -0.767218
2019-11-07 00:30:10,746 training loss; R2: 1.800598e-02 -0.766687
2019-11-07 00:30:11,330 valid 000 1.752230e-02 -0.375611
2019-11-07 00:30:20,841 valid 050 1.977262e-02 -0.999672
2019-11-07 00:30:29,212 validation loss; R2: 1.983906e-02 -1.310179
2019-11-07 00:30:29,279 epoch 281 lr 1.000000e-05
2019-11-07 00:30:30,056 train 000 1.619920e-02 -1.474974
2019-11-07 00:30:39,787 train 050 1.794005e-02 -0.628094
2019-11-07 00:30:49,534 train 100 1.812297e-02 -0.640618
2019-11-07 00:30:59,301 train 150 1.811328e-02 -0.668994
2019-11-07 00:31:09,062 train 200 1.802463e-02 -0.691205
2019-11-07 00:31:18,830 train 250 1.806043e-02 -0.688346
2019-11-07 00:31:28,590 train 300 1.798854e-02 -0.683285
2019-11-07 00:31:38,360 train 350 1.800286e-02 -0.699801
2019-11-07 00:31:48,114 train 400 1.805155e-02 -0.693548
2019-11-07 00:31:57,883 train 450 1.812592e-02 -0.679533
2019-11-07 00:32:07,660 train 500 1.811470e-02 -0.687629
2019-11-07 00:32:17,438 train 550 1.807021e-02 -0.683898
2019-11-07 00:32:27,221 train 600 1.803316e-02 -0.687057
2019-11-07 00:32:37,000 train 650 1.804108e-02 -0.688386
2019-11-07 00:32:46,782 train 700 1.805737e-02 -0.697538
2019-11-07 00:32:56,570 train 750 1.805552e-02 -0.706976
2019-11-07 00:33:06,356 train 800 1.803450e-02 -0.707768
2019-11-07 00:33:16,128 train 850 1.805250e-02 -0.693171
2019-11-07 00:33:19,056 training loss; R2: 1.805397e-02 -0.688427
2019-11-07 00:33:19,699 valid 000 1.723234e-02 -1.545628
2019-11-07 00:33:29,116 valid 050 1.811608e-02 -0.889028
2019-11-07 00:33:37,502 validation loss; R2: 1.836031e-02 -0.872832
2019-11-07 00:33:37,570 epoch 282 lr 1.000000e-05
2019-11-07 00:33:38,355 train 000 2.176390e-02 -5.483055
2019-11-07 00:33:48,088 train 050 1.770274e-02 -0.802470
2019-11-07 00:33:57,866 train 100 1.778828e-02 -0.913978
2019-11-07 00:34:07,644 train 150 1.791764e-02 -0.819895
2019-11-07 00:34:17,415 train 200 1.792034e-02 -0.788571
2019-11-07 00:34:27,168 train 250 1.798058e-02 -0.820292
2019-11-07 00:34:36,943 train 300 1.797913e-02 -0.852580
2019-11-07 00:34:46,699 train 350 1.801897e-02 -0.871239
2019-11-07 00:34:56,447 train 400 1.806792e-02 -0.871259
2019-11-07 00:35:06,200 train 450 1.805575e-02 -0.843747
2019-11-07 00:35:15,957 train 500 1.802894e-02 -0.826704
2019-11-07 00:35:25,710 train 550 1.802593e-02 -0.808841
2019-11-07 00:35:35,461 train 600 1.802077e-02 -0.790672
2019-11-07 00:35:45,213 train 650 1.797420e-02 -0.784120
2019-11-07 00:35:54,962 train 700 1.799173e-02 -0.786262
2019-11-07 00:36:04,724 train 750 1.799693e-02 -0.772593
2019-11-07 00:36:14,483 train 800 1.799960e-02 -1.010753
2019-11-07 00:36:24,243 train 850 1.803004e-02 -0.990970
2019-11-07 00:36:27,163 training loss; R2: 1.803183e-02 -0.978411
2019-11-07 00:36:27,813 valid 000 2.208954e-02 -0.443129
2019-11-07 00:36:37,206 valid 050 1.923120e-02 -1.080115
2019-11-07 00:36:45,474 validation loss; R2: 1.908077e-02 -0.957485
2019-11-07 00:36:45,540 epoch 283 lr 1.000000e-05
2019-11-07 00:36:46,262 train 000 1.832349e-02 -1.094291
2019-11-07 00:36:55,977 train 050 1.794858e-02 -0.837259
2019-11-07 00:37:05,721 train 100 1.819414e-02 -0.803090
2019-11-07 00:37:15,489 train 150 1.818764e-02 -0.758835
2019-11-07 00:37:25,250 train 200 1.805249e-02 -0.681868
2019-11-07 00:37:35,011 train 250 1.805084e-02 -0.782403
2019-11-07 00:37:44,780 train 300 1.803391e-02 -0.784092
2019-11-07 00:37:54,555 train 350 1.804460e-02 -0.761316
2019-11-07 00:38:04,341 train 400 1.807466e-02 -0.759848
2019-11-07 00:38:14,099 train 450 1.810607e-02 -0.760769
2019-11-07 00:38:23,856 train 500 1.809798e-02 -0.752426
2019-11-07 00:38:33,645 train 550 1.809671e-02 -0.750252
2019-11-07 00:38:43,421 train 600 1.811970e-02 -0.740161
2019-11-07 00:38:53,197 train 650 1.811561e-02 -0.739283
2019-11-07 00:39:02,977 train 700 1.811375e-02 -0.732551
2019-11-07 00:39:12,750 train 750 1.810239e-02 -0.722935
2019-11-07 00:39:22,523 train 800 1.812852e-02 -0.719753
2019-11-07 00:39:32,299 train 850 1.808895e-02 -0.728028
2019-11-07 00:39:35,225 training loss; R2: 1.809297e-02 -0.723181
2019-11-07 00:39:35,911 valid 000 1.931143e-02 -2.036368
2019-11-07 00:39:45,315 valid 050 1.801889e-02 -2.787224
2019-11-07 00:39:53,660 validation loss; R2: 1.835237e-02 -3.308634
2019-11-07 00:39:53,727 epoch 284 lr 1.000000e-05
2019-11-07 00:39:54,497 train 000 1.898438e-02 -0.474835
2019-11-07 00:40:04,234 train 050 1.842756e-02 -0.461126
2019-11-07 00:40:13,988 train 100 1.828006e-02 -0.638291
2019-11-07 00:40:23,756 train 150 1.817169e-02 -0.680235
2019-11-07 00:40:33,527 train 200 1.806287e-02 -0.710038
2019-11-07 00:40:43,306 train 250 1.798073e-02 -0.712358
2019-11-07 00:40:53,075 train 300 1.797408e-02 -0.792883
2019-11-07 00:41:02,843 train 350 1.802868e-02 -0.743856
2019-11-07 00:41:12,611 train 400 1.801396e-02 -0.739185
2019-11-07 00:41:22,383 train 450 1.801086e-02 -0.728979
2019-11-07 00:41:32,164 train 500 1.801604e-02 -0.717274
2019-11-07 00:41:41,939 train 550 1.806071e-02 -0.739719
2019-11-07 00:41:51,727 train 600 1.805231e-02 -0.758901
2019-11-07 00:42:01,509 train 650 1.806202e-02 -0.741682
2019-11-07 00:42:11,307 train 700 1.808199e-02 -0.737041
2019-11-07 00:42:21,077 train 750 1.807573e-02 -0.758960
2019-11-07 00:42:30,867 train 800 1.805980e-02 -1.241800
2019-11-07 00:42:40,668 train 850 1.804560e-02 -1.202006
2019-11-07 00:42:43,593 training loss; R2: 1.806151e-02 -1.199221
2019-11-07 00:42:44,295 valid 000 1.721967e-02 -1.347956
2019-11-07 00:42:53,735 valid 050 1.824960e-02 -0.920102
2019-11-07 00:43:02,063 validation loss; R2: 1.817284e-02 -0.862025
2019-11-07 00:43:02,127 epoch 285 lr 1.000000e-05
2019-11-07 00:43:02,890 train 000 1.625927e-02 -0.066699
2019-11-07 00:43:12,623 train 050 1.832263e-02 -0.597542
2019-11-07 00:43:22,368 train 100 1.815204e-02 -0.738767
2019-11-07 00:43:32,113 train 150 1.811209e-02 -0.714992
2019-11-07 00:43:41,861 train 200 1.812096e-02 -0.683068
2019-11-07 00:43:51,615 train 250 1.792695e-02 -0.754961
2019-11-07 00:44:01,376 train 300 1.795776e-02 -0.716836
2019-11-07 00:44:11,135 train 350 1.796742e-02 -0.716583
2019-11-07 00:44:20,912 train 400 1.794704e-02 -0.723372
2019-11-07 00:44:30,680 train 450 1.793131e-02 -0.727623
2019-11-07 00:44:40,439 train 500 1.792210e-02 -0.754688
2019-11-07 00:44:50,178 train 550 1.789857e-02 -0.757359
2019-11-07 00:44:59,910 train 600 1.791048e-02 -0.758825
2019-11-07 00:45:09,646 train 650 1.793259e-02 -3.075419
2019-11-07 00:45:19,393 train 700 1.792441e-02 -2.927535
2019-11-07 00:45:29,123 train 750 1.792104e-02 -2.789684
2019-11-07 00:45:38,859 train 800 1.793126e-02 -2.661813
2019-11-07 00:45:48,595 train 850 1.793327e-02 -2.534106
2019-11-07 00:45:51,501 training loss; R2: 1.792137e-02 -2.501464
2019-11-07 00:45:52,165 valid 000 1.725519e-02 -3.433782
2019-11-07 00:46:01,569 valid 050 1.790019e-02 -0.870152
2019-11-07 00:46:09,885 validation loss; R2: 1.819880e-02 -0.900776
2019-11-07 00:46:09,952 epoch 286 lr 1.000000e-05
2019-11-07 00:46:10,698 train 000 1.579446e-02 -0.040984
2019-11-07 00:46:20,390 train 050 1.838970e-02 -0.553382
2019-11-07 00:46:30,072 train 100 1.836298e-02 -0.664461
2019-11-07 00:46:39,789 train 150 1.821908e-02 -0.638572
2019-11-07 00:46:49,504 train 200 1.818951e-02 -0.660849
2019-11-07 00:46:59,224 train 250 1.810317e-02 -0.650535
2019-11-07 00:47:08,974 train 300 1.807251e-02 -0.646906
2019-11-07 00:47:18,733 train 350 1.805664e-02 -0.622289
2019-11-07 00:47:28,497 train 400 1.801315e-02 -0.694022
2019-11-07 00:47:38,255 train 450 1.798918e-02 -0.691058
2019-11-07 00:47:48,028 train 500 1.799879e-02 -0.712477
2019-11-07 00:47:57,804 train 550 1.806721e-02 -0.704653
2019-11-07 00:48:07,581 train 600 1.804497e-02 -0.687453
2019-11-07 00:48:17,356 train 650 1.804121e-02 -0.703390
2019-11-07 00:48:27,128 train 700 1.803287e-02 -0.703694
2019-11-07 00:48:36,905 train 750 1.801481e-02 -0.721116
2019-11-07 00:48:46,678 train 800 1.801665e-02 -0.715867
2019-11-07 00:48:56,788 train 850 1.803722e-02 -0.722808
2019-11-07 00:48:59,816 training loss; R2: 1.803257e-02 -0.726403
2019-11-07 00:49:00,478 valid 000 2.107650e-02 -0.834778
2019-11-07 00:49:09,870 valid 050 1.877584e-02 -0.647099
2019-11-07 00:49:18,202 validation loss; R2: 1.895389e-02 -0.920586
2019-11-07 00:49:18,269 epoch 287 lr 1.000000e-05
2019-11-07 00:49:19,036 train 000 1.585456e-02 -0.080391
2019-11-07 00:49:29,140 train 050 1.749580e-02 -0.912728
2019-11-07 00:49:39,281 train 100 1.781307e-02 -0.725044
2019-11-07 00:49:49,421 train 150 1.787200e-02 -0.622766
2019-11-07 00:49:59,575 train 200 1.794740e-02 -0.662162
2019-11-07 00:50:09,391 train 250 1.798110e-02 -0.741739
2019-11-07 00:50:19,166 train 300 1.800811e-02 -0.705372
2019-11-07 00:50:28,972 train 350 1.801342e-02 -0.718505
2019-11-07 00:50:38,780 train 400 1.797773e-02 -0.709071
2019-11-07 00:50:48,592 train 450 1.799018e-02 -0.703701
2019-11-07 00:50:58,402 train 500 1.802802e-02 -0.700141
2019-11-07 00:51:08,211 train 550 1.804819e-02 -0.706026
2019-11-07 00:51:18,019 train 600 1.802523e-02 -0.704114
2019-11-07 00:51:27,841 train 650 1.803232e-02 -0.746631
2019-11-07 00:51:37,660 train 700 1.802781e-02 -0.729867
2019-11-07 00:51:47,474 train 750 1.806221e-02 -0.726123
2019-11-07 00:51:57,287 train 800 1.806570e-02 -0.724688
2019-11-07 00:52:07,102 train 850 1.806954e-02 -0.721936
2019-11-07 00:52:10,036 training loss; R2: 1.806307e-02 -0.723680
2019-11-07 00:52:10,745 valid 000 1.388774e-02 -1.100627
2019-11-07 00:52:20,109 valid 050 1.797902e-02 -0.955328
2019-11-07 00:52:28,414 validation loss; R2: 1.820815e-02 -0.963625
2019-11-07 00:52:28,488 epoch 288 lr 1.000000e-05
2019-11-07 00:52:29,281 train 000 1.708486e-02 -0.894833
2019-11-07 00:52:39,033 train 050 1.837274e-02 -0.791705
2019-11-07 00:52:48,802 train 100 1.813721e-02 -0.844429
2019-11-07 00:52:58,582 train 150 1.813074e-02 -0.779520
2019-11-07 00:53:08,375 train 200 1.815621e-02 -0.742477
2019-11-07 00:53:18,173 train 250 1.811013e-02 -0.771483
2019-11-07 00:53:27,975 train 300 1.806765e-02 -0.777857
2019-11-07 00:53:37,777 train 350 1.807335e-02 -1.098163
2019-11-07 00:53:47,589 train 400 1.805260e-02 -1.038524
2019-11-07 00:53:57,410 train 450 1.804905e-02 -1.032058
2019-11-07 00:54:07,230 train 500 1.806999e-02 -1.018343
2019-11-07 00:54:17,046 train 550 1.804763e-02 -0.977359
2019-11-07 00:54:26,850 train 600 1.805603e-02 -0.939127
2019-11-07 00:54:36,648 train 650 1.802727e-02 -0.953946
2019-11-07 00:54:46,443 train 700 1.802628e-02 -0.946992
2019-11-07 00:54:56,242 train 750 1.799498e-02 -0.938859
2019-11-07 00:55:06,036 train 800 1.798954e-02 -0.921831
2019-11-07 00:55:15,835 train 850 1.800924e-02 -0.902754
2019-11-07 00:55:18,802 training loss; R2: 1.800252e-02 -0.896316
2019-11-07 00:55:19,487 valid 000 2.066053e-02 -0.442567
2019-11-07 00:55:28,885 valid 050 1.922781e-02 -1.171870
2019-11-07 00:55:37,211 validation loss; R2: 1.950792e-02 -1.216283
2019-11-07 00:55:37,284 epoch 289 lr 1.000000e-05
2019-11-07 00:55:38,057 train 000 1.892161e-02 -0.200149
2019-11-07 00:55:47,844 train 050 1.820812e-02 -0.830490
2019-11-07 00:55:57,639 train 100 1.810766e-02 -0.750931
2019-11-07 00:56:07,476 train 150 1.818679e-02 -0.810691
2019-11-07 00:56:17,307 train 200 1.808413e-02 -0.717386
2019-11-07 00:56:27,148 train 250 1.805637e-02 -0.681011
2019-11-07 00:56:36,965 train 300 1.803673e-02 -0.690551
2019-11-07 00:56:46,765 train 350 1.805047e-02 -0.692280
2019-11-07 00:56:56,599 train 400 1.807075e-02 -0.686414
2019-11-07 00:57:06,428 train 450 1.804149e-02 -0.694033
2019-11-07 00:57:16,257 train 500 1.799444e-02 -0.706114
2019-11-07 00:57:26,116 train 550 1.797209e-02 -0.745059
2019-11-07 00:57:35,957 train 600 1.801680e-02 -0.744471
2019-11-07 00:57:45,803 train 650 1.805020e-02 -0.889515
2019-11-07 00:57:55,641 train 700 1.805657e-02 -0.902274
2019-11-07 00:58:05,500 train 750 1.806667e-02 -0.893468
2019-11-07 00:58:15,351 train 800 1.807041e-02 -0.882060
2019-11-07 00:58:25,209 train 850 1.807250e-02 -0.925029
2019-11-07 00:58:28,178 training loss; R2: 1.807318e-02 -0.916230
2019-11-07 00:58:28,886 valid 000 2.059313e-02 -0.085993
2019-11-07 00:58:38,306 valid 050 1.882164e-02 -0.921896
2019-11-07 00:58:46,625 validation loss; R2: 1.860445e-02 -1.067529
2019-11-07 00:58:46,696 epoch 290 lr 1.000000e-05
2019-11-07 00:58:47,485 train 000 1.508357e-02 -0.351176
2019-11-07 00:58:57,275 train 050 1.789609e-02 -0.864553
2019-11-07 00:59:07,130 train 100 1.799253e-02 -0.807707
2019-11-07 00:59:16,969 train 150 1.793387e-02 -0.891844
2019-11-07 00:59:26,816 train 200 1.798315e-02 -0.879174
2019-11-07 00:59:36,648 train 250 1.799059e-02 -0.812089
2019-11-07 00:59:46,484 train 300 1.801691e-02 -0.761505
2019-11-07 00:59:56,315 train 350 1.799688e-02 -0.756127
2019-11-07 01:00:06,151 train 400 1.798520e-02 -0.727861
2019-11-07 01:00:15,984 train 450 1.800312e-02 -0.704220
2019-11-07 01:00:25,813 train 500 1.801846e-02 -0.696347
2019-11-07 01:00:35,615 train 550 1.803936e-02 -0.714171
2019-11-07 01:00:45,417 train 600 1.803434e-02 -0.733561
2019-11-07 01:00:55,220 train 650 1.802773e-02 -0.733162
2019-11-07 01:01:05,019 train 700 1.800227e-02 -0.736085
2019-11-07 01:01:14,821 train 750 1.798199e-02 -0.725945
2019-11-07 01:01:24,641 train 800 1.798959e-02 -0.726506
2019-11-07 01:01:34,449 train 850 1.797825e-02 -0.712731
2019-11-07 01:01:37,379 training loss; R2: 1.796533e-02 -0.748554
2019-11-07 01:01:38,008 valid 000 1.857187e-02 -0.156919
2019-11-07 01:01:47,463 valid 050 1.821177e-02 -1.447017
2019-11-07 01:01:55,775 validation loss; R2: 1.840629e-02 -1.038865
2019-11-07 01:01:55,840 epoch 291 lr 1.000000e-05
2019-11-07 01:01:56,601 train 000 1.481691e-02 -0.293509
2019-11-07 01:02:06,384 train 050 1.790270e-02 -0.606407
2019-11-07 01:02:16,186 train 100 1.781408e-02 -0.632907
2019-11-07 01:02:26,014 train 150 1.795231e-02 -0.635317
2019-11-07 01:02:35,847 train 200 1.795554e-02 -0.657750
2019-11-07 01:02:45,650 train 250 1.800516e-02 -0.637340
2019-11-07 01:02:55,459 train 300 1.794336e-02 -0.666279
2019-11-07 01:03:05,237 train 350 1.803380e-02 -0.671595
2019-11-07 01:03:15,045 train 400 1.806708e-02 -0.661064
2019-11-07 01:03:24,841 train 450 1.804027e-02 -0.692884
2019-11-07 01:03:34,635 train 500 1.801292e-02 -0.707365
2019-11-07 01:03:44,424 train 550 1.802292e-02 -0.716082
2019-11-07 01:03:54,219 train 600 1.799928e-02 -2.091807
2019-11-07 01:04:04,005 train 650 1.803101e-02 -1.980134
2019-11-07 01:04:13,792 train 700 1.805107e-02 -1.901227
2019-11-07 01:04:23,586 train 750 1.805304e-02 -1.828450
2019-11-07 01:04:33,370 train 800 1.802899e-02 -1.746028
2019-11-07 01:04:43,167 train 850 1.805556e-02 -1.664488
2019-11-07 01:04:46,099 training loss; R2: 1.805078e-02 -1.648081
2019-11-07 01:04:46,746 valid 000 1.578627e-02 -0.510146
2019-11-07 01:04:56,174 valid 050 1.928141e-02 -1.075753
2019-11-07 01:05:04,469 validation loss; R2: 1.926278e-02 -1.096567
2019-11-07 01:05:04,535 epoch 292 lr 1.000000e-05
2019-11-07 01:05:05,266 train 000 2.023393e-02 -0.354849
2019-11-07 01:05:15,000 train 050 1.794940e-02 -0.651537
2019-11-07 01:05:24,734 train 100 1.786077e-02 -0.660444
2019-11-07 01:05:34,499 train 150 1.794753e-02 -0.763397
2019-11-07 01:05:44,255 train 200 1.792098e-02 -0.828166
2019-11-07 01:05:54,020 train 250 1.796898e-02 -0.874190
2019-11-07 01:06:03,783 train 300 1.794530e-02 -0.837812
2019-11-07 01:06:13,550 train 350 1.793925e-02 -0.822125
2019-11-07 01:06:23,320 train 400 1.789956e-02 -0.834400
2019-11-07 01:06:33,090 train 450 1.792942e-02 -0.823138
2019-11-07 01:06:42,856 train 500 1.788453e-02 -0.832667
2019-11-07 01:06:52,648 train 550 1.786924e-02 -0.812598
2019-11-07 01:07:02,451 train 600 1.789930e-02 -0.829183
2019-11-07 01:07:12,240 train 650 1.791358e-02 -0.812324
2019-11-07 01:07:22,032 train 700 1.791599e-02 -0.811953
2019-11-07 01:07:31,820 train 750 1.788067e-02 -0.824416
2019-11-07 01:07:41,624 train 800 1.788328e-02 -0.824156
2019-11-07 01:07:51,436 train 850 1.791409e-02 -0.821864
2019-11-07 01:07:54,371 training loss; R2: 1.791289e-02 -0.814053
2019-11-07 01:07:55,072 valid 000 2.176916e-02 -3.517693
2019-11-07 01:08:04,448 valid 050 1.951409e-02 -2.113023
2019-11-07 01:08:12,811 validation loss; R2: 1.970486e-02 -2.251061
2019-11-07 01:08:12,884 epoch 293 lr 1.000000e-05
2019-11-07 01:08:13,659 train 000 1.898544e-02 -0.457808
2019-11-07 01:08:23,394 train 050 1.778570e-02 -0.978599
2019-11-07 01:08:33,153 train 100 1.783354e-02 -2.059848
2019-11-07 01:08:42,942 train 150 1.787230e-02 -10.560467
2019-11-07 01:08:52,738 train 200 1.784300e-02 -8.109549
2019-11-07 01:09:02,561 train 250 1.784828e-02 -6.584382
2019-11-07 01:09:12,375 train 300 1.790796e-02 -5.605008
2019-11-07 01:09:22,152 train 350 1.787055e-02 -4.930795
2019-11-07 01:09:31,912 train 400 1.790977e-02 -4.384514
2019-11-07 01:09:41,706 train 450 1.791786e-02 -4.062791
2019-11-07 01:09:51,526 train 500 1.793353e-02 -3.734114
2019-11-07 01:10:01,339 train 550 1.794786e-02 -3.485613
2019-11-07 01:10:11,155 train 600 1.798761e-02 -3.248695
2019-11-07 01:10:20,967 train 650 1.800689e-02 -3.060887
2019-11-07 01:10:30,779 train 700 1.800988e-02 -2.890613
2019-11-07 01:10:40,598 train 750 1.797635e-02 -2.741863
2019-11-07 01:10:50,418 train 800 1.798425e-02 -2.616553
2019-11-07 01:11:00,249 train 850 1.799209e-02 -2.998610
2019-11-07 01:11:03,246 training loss; R2: 1.799776e-02 -2.955851
2019-11-07 01:11:03,931 valid 000 1.606320e-02 -0.400741
2019-11-07 01:11:13,356 valid 050 1.878799e-02 -1.780456
2019-11-07 01:11:21,702 validation loss; R2: 1.884208e-02 -1.277127
2019-11-07 01:11:21,770 epoch 294 lr 1.000000e-05
2019-11-07 01:11:22,515 train 000 2.113182e-02 -0.001352
2019-11-07 01:11:32,637 train 050 1.777178e-02 -36.211297
2019-11-07 01:11:42,766 train 100 1.773970e-02 -18.558560
2019-11-07 01:11:52,923 train 150 1.779179e-02 -12.672009
2019-11-07 01:12:03,078 train 200 1.784901e-02 -9.671872
2019-11-07 01:12:13,245 train 250 1.784615e-02 -8.047107
2019-11-07 01:12:23,405 train 300 1.776481e-02 -6.890093
2019-11-07 01:12:33,562 train 350 1.776909e-02 -6.023026
2019-11-07 01:12:43,728 train 400 1.783384e-02 -5.358579
2019-11-07 01:12:53,885 train 450 1.785669e-02 -4.942356
2019-11-07 01:13:04,074 train 500 1.791310e-02 -4.497349
2019-11-07 01:13:14,246 train 550 1.789482e-02 -4.169707
2019-11-07 01:13:24,419 train 600 1.791022e-02 -3.890909
2019-11-07 01:13:34,588 train 650 1.791347e-02 -3.651592
2019-11-07 01:13:44,759 train 700 1.790945e-02 -3.429449
2019-11-07 01:13:54,942 train 750 1.792740e-02 -3.257247
2019-11-07 01:14:05,128 train 800 1.793425e-02 -3.107947
2019-11-07 01:14:15,316 train 850 1.795218e-02 -2.951021
2019-11-07 01:14:18,337 training loss; R2: 1.795652e-02 -2.909795
2019-11-07 01:14:18,974 valid 000 1.718812e-02 -1.999746
2019-11-07 01:14:28,418 valid 050 1.859447e-02 -1.686687
2019-11-07 01:14:36,768 validation loss; R2: 1.862726e-02 -1.275305
2019-11-07 01:14:36,834 epoch 295 lr 1.000000e-05
2019-11-07 01:14:37,584 train 000 1.479061e-02 -0.631392
2019-11-07 01:14:47,724 train 050 1.767212e-02 -0.879558
2019-11-07 01:14:57,886 train 100 1.781678e-02 -0.773799
2019-11-07 01:15:08,040 train 150 1.773288e-02 -0.714705
2019-11-07 01:15:18,203 train 200 1.771508e-02 -0.739397
2019-11-07 01:15:28,384 train 250 1.770304e-02 -0.710913
2019-11-07 01:15:38,549 train 300 1.772809e-02 -0.710614
2019-11-07 01:15:48,722 train 350 1.776463e-02 -0.703284
2019-11-07 01:15:58,913 train 400 1.782290e-02 -0.688023
2019-11-07 01:16:09,070 train 450 1.784105e-02 -0.651794
2019-11-07 01:16:19,248 train 500 1.783330e-02 -0.641012
2019-11-07 01:16:29,437 train 550 1.790787e-02 -0.723975
2019-11-07 01:16:39,621 train 600 1.792747e-02 -0.835283
2019-11-07 01:16:49,819 train 650 1.791684e-02 -0.816411
2019-11-07 01:16:59,683 train 700 1.791176e-02 -0.828729
2019-11-07 01:17:09,489 train 750 1.792064e-02 -0.839332
2019-11-07 01:17:19,296 train 800 1.793215e-02 -0.824759
2019-11-07 01:17:29,111 train 850 1.792295e-02 -0.806551
2019-11-07 01:17:32,044 training loss; R2: 1.792933e-02 -0.797501
2019-11-07 01:17:32,728 valid 000 1.788846e-02 -2.043303
2019-11-07 01:17:42,160 valid 050 1.931854e-02 -1.120368
2019-11-07 01:17:50,497 validation loss; R2: 1.940070e-02 -1.054722
2019-11-07 01:17:50,562 epoch 296 lr 1.000000e-05
2019-11-07 01:17:51,330 train 000 1.860880e-02 -0.678696
2019-11-07 01:18:01,085 train 050 1.786603e-02 -2.516628
2019-11-07 01:18:10,844 train 100 1.805673e-02 -1.608613
2019-11-07 01:18:20,629 train 150 1.804702e-02 -1.348436
2019-11-07 01:18:30,422 train 200 1.793730e-02 -1.154164
2019-11-07 01:18:40,217 train 250 1.787850e-02 -1.043293
2019-11-07 01:18:50,014 train 300 1.785404e-02 -0.965048
2019-11-07 01:18:59,817 train 350 1.785876e-02 -0.916622
2019-11-07 01:19:09,614 train 400 1.787482e-02 -0.895884
2019-11-07 01:19:19,413 train 450 1.787756e-02 -0.867958
2019-11-07 01:19:29,213 train 500 1.788554e-02 -0.854213
2019-11-07 01:19:39,018 train 550 1.791098e-02 -0.832575
2019-11-07 01:19:48,827 train 600 1.790265e-02 -0.813602
2019-11-07 01:19:58,629 train 650 1.792904e-02 -0.828714
2019-11-07 01:20:08,453 train 700 1.790891e-02 -0.819932
2019-11-07 01:20:18,257 train 750 1.788692e-02 -0.816500
2019-11-07 01:20:28,053 train 800 1.793104e-02 -0.827218
2019-11-07 01:20:37,837 train 850 1.793699e-02 -0.806191
2019-11-07 01:20:40,763 training loss; R2: 1.792941e-02 -0.806124
2019-11-07 01:20:41,409 valid 000 1.576712e-02 -1.459784
2019-11-07 01:20:50,785 valid 050 1.853330e-02 -1.171767
2019-11-07 01:20:59,112 validation loss; R2: 1.858570e-02 -1.142968
2019-11-07 01:20:59,177 epoch 297 lr 1.000000e-05
2019-11-07 01:20:59,945 train 000 1.777348e-02 -0.461046
2019-11-07 01:21:09,670 train 050 1.836545e-02 -0.751965
2019-11-07 01:21:19,405 train 100 1.805721e-02 -0.839935
2019-11-07 01:21:29,172 train 150 1.812159e-02 -0.774305
2019-11-07 01:21:38,959 train 200 1.802271e-02 -0.729380
2019-11-07 01:21:48,742 train 250 1.808897e-02 -0.686654
2019-11-07 01:21:58,528 train 300 1.803371e-02 -0.697069
2019-11-07 01:22:08,309 train 350 1.804126e-02 -0.699587
2019-11-07 01:22:18,089 train 400 1.802386e-02 -0.703065
2019-11-07 01:22:27,876 train 450 1.803902e-02 -0.710247
2019-11-07 01:22:37,658 train 500 1.798665e-02 -0.689774
2019-11-07 01:22:47,439 train 550 1.799717e-02 -0.677392
2019-11-07 01:22:57,218 train 600 1.803082e-02 -0.686092
2019-11-07 01:23:06,993 train 650 1.805010e-02 -0.671977
2019-11-07 01:23:16,775 train 700 1.802597e-02 -0.670606
2019-11-07 01:23:26,565 train 750 1.802912e-02 -0.690689
2019-11-07 01:23:36,356 train 800 1.802058e-02 -0.695382
2019-11-07 01:23:46,139 train 850 1.800791e-02 -0.693973
2019-11-07 01:23:49,060 training loss; R2: 1.800505e-02 -0.687460
2019-11-07 01:23:49,691 valid 000 1.909018e-02 -0.587361
2019-11-07 01:23:59,125 valid 050 1.838855e-02 -0.991208
2019-11-07 01:24:07,480 validation loss; R2: 1.839777e-02 -0.883058
2019-11-07 01:24:07,545 epoch 298 lr 1.000000e-05
2019-11-07 01:24:08,287 train 000 2.036101e-02 -0.479412
2019-11-07 01:24:18,028 train 050 1.776101e-02 -0.734682
2019-11-07 01:24:27,759 train 100 1.781201e-02 -0.731750
2019-11-07 01:24:37,526 train 150 1.786684e-02 -0.755686
2019-11-07 01:24:47,288 train 200 1.791966e-02 -0.719978
2019-11-07 01:24:57,054 train 250 1.777864e-02 -0.664930
2019-11-07 01:25:06,825 train 300 1.781261e-02 -0.708479
2019-11-07 01:25:16,595 train 350 1.785891e-02 -0.721470
2019-11-07 01:25:26,363 train 400 1.781509e-02 -0.702988
2019-11-07 01:25:36,147 train 450 1.781696e-02 -0.695129
2019-11-07 01:25:45,919 train 500 1.782757e-02 -0.703236
2019-11-07 01:25:55,709 train 550 1.785893e-02 -0.708812
2019-11-07 01:26:05,494 train 600 1.790356e-02 -0.702604
2019-11-07 01:26:15,277 train 650 1.791616e-02 -0.682391
2019-11-07 01:26:25,064 train 700 1.792508e-02 -0.681236
2019-11-07 01:26:34,855 train 750 1.789660e-02 -0.677776
2019-11-07 01:26:44,648 train 800 1.793491e-02 -0.674891
2019-11-07 01:26:54,443 train 850 1.794534e-02 -0.669308
2019-11-07 01:26:57,378 training loss; R2: 1.795015e-02 -0.674573
2019-11-07 01:26:57,999 valid 000 1.911383e-02 -0.367991
2019-11-07 01:27:07,470 valid 050 1.925908e-02 -1.534092
2019-11-07 01:27:15,812 validation loss; R2: 1.919182e-02 -1.430310
2019-11-07 01:27:15,877 epoch 299 lr 1.000000e-05
2019-11-07 01:27:16,600 train 000 1.511597e-02 -1.029740
2019-11-07 01:27:26,342 train 050 1.794496e-02 -0.654577
2019-11-07 01:27:36,085 train 100 1.774026e-02 -0.732533
2019-11-07 01:27:45,831 train 150 1.769777e-02 -0.767455
2019-11-07 01:27:55,573 train 200 1.779630e-02 -0.727386
2019-11-07 01:28:05,303 train 250 1.774241e-02 -0.742212
2019-11-07 01:28:15,054 train 300 1.773694e-02 -0.709842
2019-11-07 01:28:24,814 train 350 1.770269e-02 -0.733033
2019-11-07 01:28:34,558 train 400 1.775503e-02 -0.746560
2019-11-07 01:28:44,302 train 450 1.778668e-02 -0.748333
2019-11-07 01:28:54,061 train 500 1.781866e-02 -0.768157
2019-11-07 01:29:03,789 train 550 1.780822e-02 -0.758274
2019-11-07 01:29:13,541 train 600 1.781655e-02 -0.748588
2019-11-07 01:29:23,340 train 650 1.782062e-02 -0.732228
2019-11-07 01:29:33,069 train 700 1.784426e-02 -0.732224
2019-11-07 01:29:42,809 train 750 1.785222e-02 -0.740777
2019-11-07 01:29:52,595 train 800 1.786031e-02 -0.738885
2019-11-07 01:30:02,337 train 850 1.783972e-02 -0.737415
2019-11-07 01:30:05,252 training loss; R2: 1.785673e-02 -0.744910
2019-11-07 01:30:05,882 valid 000 1.607773e-02 -0.211720
2019-11-07 01:30:15,274 valid 050 1.805325e-02 -1.051898
2019-11-07 01:30:23,619 validation loss; R2: 1.790325e-02 -0.837584
2019-11-07 01:30:23,703 epoch 300 lr 1.000000e-05
2019-11-07 01:30:24,495 train 000 1.877234e-02 -0.957374
2019-11-07 01:30:34,257 train 050 1.778161e-02 -0.647844
2019-11-07 01:30:44,046 train 100 1.774980e-02 -0.635830
2019-11-07 01:30:53,834 train 150 1.785393e-02 -0.641154
2019-11-07 01:31:03,653 train 200 1.791555e-02 -0.650441
2019-11-07 01:31:13,452 train 250 1.788679e-02 -0.614424
2019-11-07 01:31:23,253 train 300 1.793965e-02 -0.610708
2019-11-07 01:31:33,066 train 350 1.790882e-02 -0.623472
2019-11-07 01:31:42,883 train 400 1.789649e-02 -0.608948
2019-11-07 01:31:52,691 train 450 1.787069e-02 -0.625865
2019-11-07 01:32:02,512 train 500 1.787194e-02 -0.638808
2019-11-07 01:32:12,316 train 550 1.791851e-02 -0.663902
2019-11-07 01:32:22,133 train 600 1.793206e-02 -0.683115
2019-11-07 01:32:31,925 train 650 1.791713e-02 -0.683458
2019-11-07 01:32:41,716 train 700 1.789282e-02 -0.707365
2019-11-07 01:32:51,519 train 750 1.790415e-02 -0.765150
2019-11-07 01:33:01,314 train 800 1.789516e-02 -0.761044
2019-11-07 01:33:11,119 train 850 1.786979e-02 -0.752969
2019-11-07 01:33:14,041 training loss; R2: 1.786806e-02 -0.748404
2019-11-07 01:33:14,743 valid 000 1.918323e-02 -3.153936
2019-11-07 01:33:24,084 valid 050 1.803115e-02 -1.045486
2019-11-07 01:33:32,485 validation loss; R2: 1.813584e-02 -1.480253
2019-11-07 01:33:32,551 epoch 301 lr 1.000000e-05
2019-11-07 01:33:33,330 train 000 1.525804e-02 -0.077001
2019-11-07 01:33:43,045 train 050 1.781748e-02 -0.562195
2019-11-07 01:33:52,765 train 100 1.784345e-02 -0.667053
2019-11-07 01:34:02,518 train 150 1.780215e-02 -0.647103
2019-11-07 01:34:12,267 train 200 1.783443e-02 -0.676255
2019-11-07 01:34:22,017 train 250 1.783824e-02 -0.629057
2019-11-07 01:34:31,768 train 300 1.786861e-02 -0.673787
2019-11-07 01:34:41,525 train 350 1.789935e-02 -0.669705
2019-11-07 01:34:51,281 train 400 1.789377e-02 -0.685081
2019-11-07 01:35:01,066 train 450 1.788004e-02 -0.679792
2019-11-07 01:35:10,857 train 500 1.784521e-02 -0.710355
2019-11-07 01:35:20,649 train 550 1.784879e-02 -0.714624
2019-11-07 01:35:30,422 train 600 1.787385e-02 -0.759056
2019-11-07 01:35:40,202 train 650 1.787964e-02 -0.727034
2019-11-07 01:35:49,982 train 700 1.785309e-02 -0.739874
2019-11-07 01:35:59,758 train 750 1.785783e-02 -0.745305
2019-11-07 01:36:09,553 train 800 1.786213e-02 -0.750539
2019-11-07 01:36:19,328 train 850 1.785765e-02 -0.744013
2019-11-07 01:36:22,247 training loss; R2: 1.786137e-02 -0.747488
2019-11-07 01:36:22,928 valid 000 1.952463e-02 -0.501205
2019-11-07 01:36:32,302 valid 050 1.852998e-02 -1.223925
2019-11-07 01:36:40,669 validation loss; R2: 1.868240e-02 -1.385998
2019-11-07 01:36:40,737 epoch 302 lr 1.000000e-05
2019-11-07 01:36:41,530 train 000 2.134960e-02 -0.015319
2019-11-07 01:36:51,240 train 050 1.778346e-02 -0.548652
2019-11-07 01:37:00,979 train 100 1.802853e-02 -0.845520
2019-11-07 01:37:10,734 train 150 1.799578e-02 -0.742939
2019-11-07 01:37:20,480 train 200 1.788675e-02 -0.721478
2019-11-07 01:37:30,230 train 250 1.788628e-02 -0.725375
2019-11-07 01:37:39,989 train 300 1.789482e-02 -0.708747
2019-11-07 01:37:49,735 train 350 1.786709e-02 -0.682000
2019-11-07 01:37:59,491 train 400 1.787955e-02 -0.680556
2019-11-07 01:38:09,258 train 450 1.787630e-02 -0.664118
2019-11-07 01:38:19,015 train 500 1.786498e-02 -0.662932
2019-11-07 01:38:28,784 train 550 1.786829e-02 -0.645651
2019-11-07 01:38:38,559 train 600 1.784427e-02 -0.656624
2019-11-07 01:38:48,347 train 650 1.783425e-02 -0.653931
2019-11-07 01:38:58,132 train 700 1.781762e-02 -0.641038
2019-11-07 01:39:07,921 train 750 1.782855e-02 -0.633595
2019-11-07 01:39:17,708 train 800 1.780235e-02 -0.651644
2019-11-07 01:39:27,489 train 850 1.781032e-02 -0.680854
2019-11-07 01:39:30,419 training loss; R2: 1.780583e-02 -0.679646
2019-11-07 01:39:31,052 valid 000 1.511200e-02 -1.369064
2019-11-07 01:39:40,521 valid 050 1.817028e-02 -1.127682
2019-11-07 01:39:48,846 validation loss; R2: 1.801170e-02 -0.896950
2019-11-07 01:39:48,911 epoch 303 lr 1.000000e-05
2019-11-07 01:39:49,658 train 000 1.585920e-02 -1.703168
2019-11-07 01:39:59,390 train 050 1.720311e-02 -0.569877
2019-11-07 01:40:09,144 train 100 1.784076e-02 -0.730522
2019-11-07 01:40:18,906 train 150 1.793511e-02 -0.719919
2019-11-07 01:40:28,652 train 200 1.798893e-02 -0.733903
2019-11-07 01:40:38,413 train 250 1.799000e-02 -0.985956
2019-11-07 01:40:48,167 train 300 1.797326e-02 -0.961322
2019-11-07 01:40:57,927 train 350 1.805446e-02 -0.932410
2019-11-07 01:41:07,686 train 400 1.801105e-02 -0.912032
2019-11-07 01:41:17,444 train 450 1.803824e-02 -0.910159
2019-11-07 01:41:27,196 train 500 1.798492e-02 -0.879228
2019-11-07 01:41:36,982 train 550 1.796118e-02 -0.853016
2019-11-07 01:41:46,762 train 600 1.791270e-02 -0.843413
2019-11-07 01:41:56,538 train 650 1.793843e-02 -0.854340
2019-11-07 01:42:06,331 train 700 1.793851e-02 -0.836878
2019-11-07 01:42:16,138 train 750 1.793423e-02 -0.830697
2019-11-07 01:42:25,934 train 800 1.794045e-02 -0.824800
2019-11-07 01:42:35,742 train 850 1.793164e-02 -0.802657
2019-11-07 01:42:38,667 training loss; R2: 1.792532e-02 -0.800311
2019-11-07 01:42:39,273 valid 000 1.694883e-02 -0.666574
2019-11-07 01:42:48,763 valid 050 1.831811e-02 -1.305833
2019-11-07 01:42:57,110 validation loss; R2: 1.820795e-02 -1.345299
2019-11-07 01:42:57,189 epoch 304 lr 1.000000e-05
2019-11-07 01:42:58,004 train 000 1.826941e-02 -0.119189
2019-11-07 01:43:07,749 train 050 1.807743e-02 -0.965368
2019-11-07 01:43:17,514 train 100 1.807609e-02 -0.803550
2019-11-07 01:43:27,294 train 150 1.809184e-02 -0.801739
2019-11-07 01:43:37,046 train 200 1.810885e-02 -0.827239
2019-11-07 01:43:46,793 train 250 1.812013e-02 -0.801244
2019-11-07 01:43:56,542 train 300 1.801330e-02 -0.742325
2019-11-07 01:44:06,308 train 350 1.798185e-02 -0.753986
2019-11-07 01:44:16,098 train 400 1.794885e-02 -0.720351
2019-11-07 01:44:25,890 train 450 1.796945e-02 -0.727479
2019-11-07 01:44:35,688 train 500 1.799598e-02 -0.746634
2019-11-07 01:44:45,475 train 550 1.798148e-02 -0.771626
2019-11-07 01:44:55,275 train 600 1.797963e-02 -0.779847
2019-11-07 01:45:05,088 train 650 1.798449e-02 -0.757624
2019-11-07 01:45:14,905 train 700 1.797138e-02 -0.775791
2019-11-07 01:45:24,709 train 750 1.797187e-02 -0.764794
2019-11-07 01:45:34,523 train 800 1.796763e-02 -0.771885
2019-11-07 01:45:44,344 train 850 1.794733e-02 -0.770490
2019-11-07 01:45:47,271 training loss; R2: 1.794484e-02 -0.773440
2019-11-07 01:45:47,966 valid 000 1.803283e-02 -1.583279
2019-11-07 01:45:57,365 valid 050 1.894502e-02 -0.805756
2019-11-07 01:46:05,695 validation loss; R2: 1.881275e-02 -8.804160
2019-11-07 01:46:05,762 epoch 305 lr 1.000000e-05
2019-11-07 01:46:06,564 train 000 1.811358e-02 -0.110811
2019-11-07 01:46:16,297 train 050 1.756397e-02 -0.666626
2019-11-07 01:46:26,047 train 100 1.767408e-02 -0.678546
2019-11-07 01:46:35,805 train 150 1.779182e-02 -0.816068
2019-11-07 01:46:45,574 train 200 1.777719e-02 -0.862081
2019-11-07 01:46:55,343 train 250 1.776890e-02 -0.869826
2019-11-07 01:47:05,118 train 300 1.778697e-02 -0.813778
2019-11-07 01:47:14,890 train 350 1.783302e-02 -0.794997
2019-11-07 01:47:24,665 train 400 1.787199e-02 -0.779893
2019-11-07 01:47:34,434 train 450 1.782341e-02 -0.802426
2019-11-07 01:47:44,199 train 500 1.783963e-02 -0.799768
2019-11-07 01:47:53,979 train 550 1.788601e-02 -0.785781
2019-11-07 01:48:03,778 train 600 1.789558e-02 -0.794866
2019-11-07 01:48:13,578 train 650 1.788240e-02 -0.784032
2019-11-07 01:48:23,369 train 700 1.789057e-02 -0.785816
2019-11-07 01:48:33,151 train 750 1.789914e-02 -0.775853
2019-11-07 01:48:42,935 train 800 1.792583e-02 -0.771561
2019-11-07 01:48:52,721 train 850 1.793922e-02 -0.766982
2019-11-07 01:48:55,646 training loss; R2: 1.793188e-02 -0.761314
2019-11-07 01:48:56,271 valid 000 1.912709e-02 -0.296968
2019-11-07 01:49:05,728 valid 050 1.789341e-02 -0.970227
2019-11-07 01:49:14,050 validation loss; R2: 1.783513e-02 -0.975923
2019-11-07 01:49:14,116 epoch 306 lr 1.000000e-05
2019-11-07 01:49:14,891 train 000 2.003329e-02 -0.158050
2019-11-07 01:49:24,635 train 050 1.740858e-02 -0.562083
2019-11-07 01:49:34,401 train 100 1.764981e-02 -0.828432
2019-11-07 01:49:44,167 train 150 1.778688e-02 -0.709932
2019-11-07 01:49:53,939 train 200 1.785599e-02 -0.672678
2019-11-07 01:50:03,715 train 250 1.781688e-02 -0.659949
2019-11-07 01:50:13,491 train 300 1.787493e-02 -0.655058
2019-11-07 01:50:23,265 train 350 1.785103e-02 -0.676367
2019-11-07 01:50:33,035 train 400 1.783589e-02 -0.697353
2019-11-07 01:50:42,814 train 450 1.783582e-02 -0.690797
2019-11-07 01:50:52,588 train 500 1.786708e-02 -0.686863
2019-11-07 01:51:02,371 train 550 1.793838e-02 -0.668999
2019-11-07 01:51:12,192 train 600 1.791918e-02 -0.667893
2019-11-07 01:51:22,012 train 650 1.793939e-02 -0.673236
2019-11-07 01:51:31,831 train 700 1.795935e-02 -0.678617
2019-11-07 01:51:41,656 train 750 1.794664e-02 -0.683246
2019-11-07 01:51:51,480 train 800 1.795710e-02 -0.679939
2019-11-07 01:52:01,296 train 850 1.794657e-02 -0.671512
2019-11-07 01:52:04,249 training loss; R2: 1.794066e-02 -0.669403
2019-11-07 01:52:04,891 valid 000 2.291687e-02 -2.908783
2019-11-07 01:52:14,298 valid 050 2.005205e-02 -1.332586
2019-11-07 01:52:22,684 validation loss; R2: 2.002955e-02 -1.163945
2019-11-07 01:52:22,766 epoch 307 lr 1.000000e-05
2019-11-07 01:52:23,548 train 000 2.044420e-02 -0.084200
2019-11-07 01:52:33,316 train 050 1.757960e-02 -0.870048
2019-11-07 01:52:43,084 train 100 1.773392e-02 -0.788474
2019-11-07 01:52:52,861 train 150 1.776998e-02 -0.676983
2019-11-07 01:53:02,651 train 200 1.776917e-02 -0.739219
2019-11-07 01:53:12,443 train 250 1.782432e-02 -0.739191
2019-11-07 01:53:22,236 train 300 1.783123e-02 -0.777566
2019-11-07 01:53:32,025 train 350 1.787172e-02 -0.813359
2019-11-07 01:53:41,808 train 400 1.791302e-02 -0.786355
2019-11-07 01:53:51,605 train 450 1.787092e-02 -0.765628
2019-11-07 01:54:01,407 train 500 1.784042e-02 -0.750705
2019-11-07 01:54:11,216 train 550 1.781157e-02 -0.740462
2019-11-07 01:54:21,032 train 600 1.784120e-02 -0.743312
2019-11-07 01:54:30,846 train 650 1.782046e-02 -0.750003
2019-11-07 01:54:40,672 train 700 1.783234e-02 -0.747691
2019-11-07 01:54:50,492 train 750 1.784704e-02 -0.772396
2019-11-07 01:55:00,315 train 800 1.790757e-02 -0.764750
2019-11-07 01:55:10,133 train 850 1.791670e-02 -0.748567
2019-11-07 01:55:13,064 training loss; R2: 1.790698e-02 -0.747079
2019-11-07 01:55:13,748 valid 000 1.729474e-02 -2.270519
2019-11-07 01:55:23,128 valid 050 1.778123e-02 -0.797145
2019-11-07 01:55:31,431 validation loss; R2: 1.773874e-02 -0.974812
2019-11-07 01:55:31,500 epoch 308 lr 1.000000e-05
2019-11-07 01:55:32,274 train 000 1.549291e-02 -0.643841
2019-11-07 01:55:42,029 train 050 1.796484e-02 -0.886275
2019-11-07 01:55:51,809 train 100 1.803402e-02 -0.697319
2019-11-07 01:56:01,594 train 150 1.814685e-02 -0.709593
2019-11-07 01:56:11,373 train 200 1.804663e-02 -0.723437
2019-11-07 01:56:21,157 train 250 1.798682e-02 -0.683732
2019-11-07 01:56:30,949 train 300 1.788215e-02 -0.711596
2019-11-07 01:56:40,742 train 350 1.787547e-02 -0.743892
2019-11-07 01:56:50,529 train 400 1.791354e-02 -0.743400
2019-11-07 01:57:00,329 train 450 1.791514e-02 -0.738669
2019-11-07 01:57:10,169 train 500 1.791468e-02 -0.738065
2019-11-07 01:57:19,976 train 550 1.792120e-02 -0.719767
2019-11-07 01:57:29,807 train 600 1.788872e-02 -0.710492
2019-11-07 01:57:39,637 train 650 1.787481e-02 -0.715274
2019-11-07 01:57:49,468 train 700 1.787677e-02 -0.721851
2019-11-07 01:57:59,296 train 750 1.784942e-02 -0.764872
2019-11-07 01:58:09,130 train 800 1.781840e-02 -0.760902
2019-11-07 01:58:18,962 train 850 1.783199e-02 -0.750897
2019-11-07 01:58:21,901 training loss; R2: 1.783806e-02 -0.748486
2019-11-07 01:58:22,597 valid 000 2.335881e-02 -0.184141
2019-11-07 01:58:32,008 valid 050 1.905127e-02 -0.914235
2019-11-07 01:58:40,305 validation loss; R2: 1.878042e-02 -1.146431
2019-11-07 01:58:40,375 epoch 309 lr 1.000000e-05
2019-11-07 01:58:41,111 train 000 1.540289e-02 -0.296160
2019-11-07 01:58:50,912 train 050 1.789202e-02 -1.120390
2019-11-07 01:59:00,707 train 100 1.800242e-02 -0.882724
2019-11-07 01:59:10,491 train 150 1.801659e-02 -0.857646
2019-11-07 01:59:20,276 train 200 1.795671e-02 -6.753597
2019-11-07 01:59:30,067 train 250 1.795030e-02 -5.525035
2019-11-07 01:59:39,851 train 300 1.793617e-02 -4.747572
2019-11-07 01:59:49,656 train 350 1.795150e-02 -4.178697
2019-11-07 01:59:59,468 train 400 1.791561e-02 -3.746074
2019-11-07 02:00:09,256 train 450 1.790821e-02 -3.403041
2019-11-07 02:00:18,999 train 500 1.788030e-02 -3.144010
2019-11-07 02:00:28,752 train 550 1.790049e-02 -2.916222
2019-11-07 02:00:38,504 train 600 1.788860e-02 -2.724678
2019-11-07 02:00:48,254 train 650 1.785473e-02 -2.570205
2019-11-07 02:00:58,007 train 700 1.786379e-02 -2.436975
2019-11-07 02:01:07,756 train 750 1.787943e-02 -2.314040
2019-11-07 02:01:17,502 train 800 1.787591e-02 -2.230390
2019-11-07 02:01:27,248 train 850 1.788082e-02 -2.151100
2019-11-07 02:01:30,164 training loss; R2: 1.788902e-02 -2.136150
2019-11-07 02:01:30,841 valid 000 1.413956e-02 -0.319123
2019-11-07 02:01:40,192 valid 050 1.873227e-02 -1.614683
2019-11-07 02:01:48,712 validation loss; R2: 1.864522e-02 -2.723553
2019-11-07 02:01:48,785 epoch 310 lr 1.000000e-05
2019-11-07 02:01:49,520 train 000 2.133469e-02 -1.516008
2019-11-07 02:01:59,238 train 050 1.832914e-02 -0.671530
2019-11-07 02:02:08,956 train 100 1.806144e-02 -0.761170
2019-11-07 02:02:18,700 train 150 1.807572e-02 -0.714434
2019-11-07 02:02:28,439 train 200 1.796066e-02 -0.646551
2019-11-07 02:02:38,182 train 250 1.800089e-02 -0.684042
2019-11-07 02:02:47,915 train 300 1.793546e-02 -0.657590
2019-11-07 02:02:57,625 train 350 1.788443e-02 -0.665550
2019-11-07 02:03:07,348 train 400 1.785120e-02 -0.680521
2019-11-07 02:03:17,095 train 450 1.784801e-02 -0.658586
2019-11-07 02:03:26,840 train 500 1.783809e-02 -0.656231
2019-11-07 02:03:36,589 train 550 1.785137e-02 -0.640625
2019-11-07 02:03:46,329 train 600 1.782747e-02 -0.634971
2019-11-07 02:03:56,071 train 650 1.786663e-02 -0.621204
2019-11-07 02:04:05,818 train 700 1.785311e-02 -0.619214
2019-11-07 02:04:15,564 train 750 1.786308e-02 -0.621139
2019-11-07 02:04:25,317 train 800 1.785449e-02 -0.634986
2019-11-07 02:04:35,073 train 850 1.785171e-02 -0.644549
2019-11-07 02:04:37,986 training loss; R2: 1.785136e-02 -0.646125
2019-11-07 02:04:38,607 valid 000 1.983997e-02 -1.846289
2019-11-07 02:04:48,083 valid 050 1.942204e-02 -0.985146
2019-11-07 02:04:56,423 validation loss; R2: 1.922893e-02 -1.221990
2019-11-07 02:04:56,488 epoch 311 lr 1.000000e-05
2019-11-07 02:04:57,273 train 000 1.353352e-02 -0.587445
2019-11-07 02:05:06,988 train 050 1.790612e-02 -0.941364
2019-11-07 02:05:16,714 train 100 1.784207e-02 -0.844240
2019-11-07 02:05:26,436 train 150 1.774433e-02 -0.818810
2019-11-07 02:05:36,172 train 200 1.782634e-02 -0.759933
2019-11-07 02:05:45,906 train 250 1.787079e-02 -0.725816
2019-11-07 02:05:55,636 train 300 1.787387e-02 -0.715001
2019-11-07 02:06:05,368 train 350 1.789813e-02 -0.689843
2019-11-07 02:06:15,104 train 400 1.787082e-02 -0.677698
2019-11-07 02:06:24,846 train 450 1.788619e-02 -0.679583
2019-11-07 02:06:34,601 train 500 1.791356e-02 -0.682618
2019-11-07 02:06:44,348 train 550 1.792874e-02 -0.679009
2019-11-07 02:06:54,100 train 600 1.791116e-02 -0.683796
2019-11-07 02:07:03,847 train 650 1.792253e-02 -0.705749
2019-11-07 02:07:13,609 train 700 1.794305e-02 -0.704623
2019-11-07 02:07:23,362 train 750 1.794468e-02 -0.998592
2019-11-07 02:07:33,124 train 800 1.793332e-02 -0.970588
2019-11-07 02:07:42,891 train 850 1.793164e-02 -0.958359
2019-11-07 02:07:45,805 training loss; R2: 1.793093e-02 -0.959659
2019-11-07 02:07:46,439 valid 000 2.048622e-02 0.056106
2019-11-07 02:07:55,859 valid 050 1.873650e-02 -1.147004
2019-11-07 02:08:04,177 validation loss; R2: 1.881027e-02 -1.099003
2019-11-07 02:08:04,240 epoch 312 lr 1.000000e-05
2019-11-07 02:08:04,944 train 000 1.792107e-02 -0.132453
2019-11-07 02:08:14,632 train 050 1.763015e-02 -0.483306
2019-11-07 02:08:24,328 train 100 1.785094e-02 -0.696564
2019-11-07 02:08:34,056 train 150 1.790032e-02 -0.684927
2019-11-07 02:08:43,783 train 200 1.796324e-02 -0.718806
2019-11-07 02:08:53,499 train 250 1.787854e-02 -0.888462
2019-11-07 02:09:03,225 train 300 1.795866e-02 -0.851949
2019-11-07 02:09:12,954 train 350 1.792562e-02 -0.828279
2019-11-07 02:09:22,674 train 400 1.792638e-02 -0.777340
2019-11-07 02:09:32,430 train 450 1.795774e-02 -0.765813
2019-11-07 02:09:42,192 train 500 1.792632e-02 -0.746579
2019-11-07 02:09:51,948 train 550 1.791973e-02 -0.739226
2019-11-07 02:10:01,709 train 600 1.791177e-02 -0.732435
2019-11-07 02:10:11,467 train 650 1.786431e-02 -0.728715
2019-11-07 02:10:21,229 train 700 1.786569e-02 -0.723030
2019-11-07 02:10:30,985 train 750 1.787279e-02 -0.718641
2019-11-07 02:10:40,738 train 800 1.785581e-02 -0.730927
2019-11-07 02:10:50,489 train 850 1.784801e-02 -0.721545
2019-11-07 02:10:53,398 training loss; R2: 1.784825e-02 -0.723295
2019-11-07 02:10:54,103 valid 000 2.076514e-02 0.024839
2019-11-07 02:11:03,451 valid 050 1.828145e-02 -1.266870
2019-11-07 02:11:11,822 validation loss; R2: 1.836863e-02 -1.204406
2019-11-07 02:11:11,889 epoch 313 lr 1.000000e-05
2019-11-07 02:11:12,672 train 000 1.845142e-02 -1.191645
2019-11-07 02:11:22,382 train 050 1.766836e-02 -0.922300
2019-11-07 02:11:32,104 train 100 1.769696e-02 -0.844111
2019-11-07 02:11:41,828 train 150 1.774180e-02 -0.863110
2019-11-07 02:11:51,548 train 200 1.787258e-02 -0.809476
2019-11-07 02:12:01,274 train 250 1.787212e-02 -0.896935
2019-11-07 02:12:11,008 train 300 1.798297e-02 -0.918156
2019-11-07 02:12:20,764 train 350 1.797045e-02 -0.920472
2019-11-07 02:12:30,517 train 400 1.793621e-02 -0.864716
2019-11-07 02:12:40,267 train 450 1.794160e-02 -0.834545
2019-11-07 02:12:50,022 train 500 1.796497e-02 -0.820673
2019-11-07 02:12:59,766 train 550 1.794508e-02 -0.814943
2019-11-07 02:13:09,520 train 600 1.794414e-02 -0.829868
2019-11-07 02:13:19,272 train 650 1.792529e-02 -0.837769
2019-11-07 02:13:29,022 train 700 1.793122e-02 -0.817816
2019-11-07 02:13:38,766 train 750 1.791831e-02 -0.803165
2019-11-07 02:13:48,511 train 800 1.792030e-02 -0.801052
2019-11-07 02:13:58,253 train 850 1.788084e-02 -0.797963
2019-11-07 02:14:01,161 training loss; R2: 1.787132e-02 -0.790404
2019-11-07 02:14:01,828 valid 000 2.320237e-02 -1.163955
2019-11-07 02:14:11,276 valid 050 1.986827e-02 -1.250121
2019-11-07 02:14:19,626 validation loss; R2: 1.992845e-02 -1.153671
2019-11-07 02:14:19,691 epoch 314 lr 1.000000e-05
2019-11-07 02:14:20,427 train 000 1.922960e-02 -0.231864
2019-11-07 02:14:30,115 train 050 1.759343e-02 -0.673065
2019-11-07 02:14:39,807 train 100 1.758004e-02 -0.786317
2019-11-07 02:14:49,535 train 150 1.780038e-02 -0.749025
2019-11-07 02:14:59,269 train 200 1.781680e-02 -0.726182
2019-11-07 02:15:09,020 train 250 1.778341e-02 -0.702650
2019-11-07 02:15:18,771 train 300 1.786596e-02 -0.708949
2019-11-07 02:15:28,509 train 350 1.785893e-02 -1.616277
2019-11-07 02:15:38,266 train 400 1.786834e-02 -2.131613
2019-11-07 02:15:48,013 train 450 1.788427e-02 -1.952313
2019-11-07 02:15:57,769 train 500 1.790426e-02 -1.821621
2019-11-07 02:16:07,590 train 550 1.790280e-02 -1.734682
2019-11-07 02:16:17,764 train 600 1.788556e-02 -1.660836
2019-11-07 02:16:27,927 train 650 1.785527e-02 -1.585825
2019-11-07 02:16:38,084 train 700 1.786893e-02 -1.525311
2019-11-07 02:16:48,236 train 750 1.786032e-02 -1.475012
2019-11-07 02:16:58,381 train 800 1.785205e-02 -1.423764
2019-11-07 02:17:08,548 train 850 1.782951e-02 -1.367570
2019-11-07 02:17:11,584 training loss; R2: 1.782589e-02 -1.356648
2019-11-07 02:17:12,298 valid 000 1.989023e-02 -0.677591
2019-11-07 02:17:21,666 valid 050 1.990494e-02 -1.447306
2019-11-07 02:17:30,122 validation loss; R2: 1.975605e-02 -1.325935
2019-11-07 02:17:30,192 epoch 315 lr 1.000000e-05
2019-11-07 02:17:30,959 train 000 1.883232e-02 -0.083507
2019-11-07 02:17:41,093 train 050 1.783929e-02 -0.672894
2019-11-07 02:17:51,251 train 100 1.802167e-02 -0.759961
2019-11-07 02:18:01,373 train 150 1.792199e-02 -0.859735
2019-11-07 02:18:11,501 train 200 1.790342e-02 -0.762295
2019-11-07 02:18:21,625 train 250 1.784112e-02 -0.771602
2019-11-07 02:18:31,790 train 300 1.789649e-02 -0.758241
2019-11-07 02:18:41,956 train 350 1.792587e-02 -0.783846
2019-11-07 02:18:52,112 train 400 1.797393e-02 -0.751893
2019-11-07 02:19:02,262 train 450 1.800671e-02 -0.735962
2019-11-07 02:19:12,414 train 500 1.795967e-02 -0.734259
2019-11-07 02:19:22,582 train 550 1.798600e-02 -0.731576
2019-11-07 02:19:32,741 train 600 1.801181e-02 -0.735292
2019-11-07 02:19:42,898 train 650 1.798188e-02 -0.734242
2019-11-07 02:19:53,051 train 700 1.797553e-02 -0.730473
2019-11-07 02:20:03,207 train 750 1.795796e-02 -0.731272
2019-11-07 02:20:13,358 train 800 1.794413e-02 -0.719718
2019-11-07 02:20:23,516 train 850 1.791611e-02 -0.704942
2019-11-07 02:20:26,547 training loss; R2: 1.792099e-02 -0.713743
2019-11-07 02:20:27,182 valid 000 2.309485e-02 -0.537864
2019-11-07 02:20:36,575 valid 050 1.925454e-02 -1.091257
2019-11-07 02:20:45,020 validation loss; R2: 1.927640e-02 -1.104424
2019-11-07 02:20:45,088 epoch 316 lr 1.000000e-05
2019-11-07 02:20:45,906 train 000 1.580075e-02 -0.942789
2019-11-07 02:20:55,985 train 050 1.778075e-02 -0.660487
2019-11-07 02:21:06,095 train 100 1.776948e-02 -0.703808
2019-11-07 02:21:16,196 train 150 1.772212e-02 -0.717382
2019-11-07 02:21:26,306 train 200 1.777482e-02 -0.688034
2019-11-07 02:21:36,402 train 250 1.779323e-02 -0.668110
2019-11-07 02:21:46,524 train 300 1.779408e-02 -0.706169
2019-11-07 02:21:56,630 train 350 1.780987e-02 -0.679558
2019-11-07 02:22:06,738 train 400 1.788362e-02 -0.684993
2019-11-07 02:22:16,856 train 450 1.786070e-02 -0.674667
2019-11-07 02:22:26,951 train 500 1.784679e-02 -0.676524
2019-11-07 02:22:37,064 train 550 1.780396e-02 -0.693063
2019-11-07 02:22:47,196 train 600 1.781909e-02 -0.704885
2019-11-07 02:22:57,341 train 650 1.782520e-02 -0.691302
2019-11-07 02:23:07,467 train 700 1.783160e-02 -0.677626
2019-11-07 02:23:17,608 train 750 1.782949e-02 -0.691711
2019-11-07 02:23:27,751 train 800 1.784943e-02 -0.693355
2019-11-07 02:23:37,886 train 850 1.784874e-02 -0.698190
2019-11-07 02:23:40,917 training loss; R2: 1.785377e-02 -0.694391
2019-11-07 02:23:41,553 valid 000 1.572753e-02 -3.613086
2019-11-07 02:23:50,940 valid 050 1.803963e-02 -1.215193
2019-11-07 02:23:59,406 validation loss; R2: 1.812821e-02 -1.186670
2019-11-07 02:23:59,472 epoch 317 lr 1.000000e-05
2019-11-07 02:24:00,247 train 000 1.678437e-02 -0.545785
2019-11-07 02:24:10,342 train 050 1.753933e-02 -0.656244
2019-11-07 02:24:20,455 train 100 1.771433e-02 -0.755052
2019-11-07 02:24:30,555 train 150 1.772336e-02 -0.744820
2019-11-07 02:24:40,679 train 200 1.781532e-02 -0.880417
2019-11-07 02:24:50,798 train 250 1.777418e-02 -0.882763
2019-11-07 02:25:00,915 train 300 1.779152e-02 -0.827002
2019-11-07 02:25:11,038 train 350 1.774264e-02 -0.803601
2019-11-07 02:25:21,164 train 400 1.773853e-02 -0.799154
2019-11-07 02:25:31,285 train 450 1.775609e-02 -0.815474
2019-11-07 02:25:41,402 train 500 1.771631e-02 -0.783671
2019-11-07 02:25:51,518 train 550 1.771459e-02 -0.776003
2019-11-07 02:26:01,663 train 600 1.772951e-02 -0.751819
2019-11-07 02:26:11,807 train 650 1.771950e-02 -0.754929
2019-11-07 02:26:21,961 train 700 1.771885e-02 -0.879663
2019-11-07 02:26:32,104 train 750 1.773541e-02 -0.852631
2019-11-07 02:26:42,257 train 800 1.775483e-02 -0.840160
2019-11-07 02:26:52,409 train 850 1.773377e-02 -0.874665
2019-11-07 02:26:55,442 training loss; R2: 1.774367e-02 -0.866601
2019-11-07 02:26:56,078 valid 000 1.855933e-02 -2.121000
2019-11-07 02:27:05,490 valid 050 1.829773e-02 -1.077967
2019-11-07 02:27:13,900 validation loss; R2: 1.835369e-02 -1.201031
2019-11-07 02:27:13,968 epoch 318 lr 1.000000e-05
2019-11-07 02:27:14,732 train 000 2.143435e-02 -0.052223
2019-11-07 02:27:24,810 train 050 1.784570e-02 -0.543603
2019-11-07 02:27:34,616 train 100 1.782242e-02 -0.650891
2019-11-07 02:27:44,368 train 150 1.799561e-02 -0.597300
2019-11-07 02:27:54,121 train 200 1.792295e-02 -0.674893
2019-11-07 02:28:03,879 train 250 1.791116e-02 -1.062845
2019-11-07 02:28:13,639 train 300 1.784396e-02 -1.010030
2019-11-07 02:28:23,393 train 350 1.779267e-02 -0.998856
2019-11-07 02:28:33,169 train 400 1.783182e-02 -0.958204
2019-11-07 02:28:42,956 train 450 1.777829e-02 -0.913972
2019-11-07 02:28:52,734 train 500 1.780284e-02 -0.895466
2019-11-07 02:29:02,513 train 550 1.783846e-02 -0.869178
2019-11-07 02:29:12,305 train 600 1.785529e-02 -0.866925
2019-11-07 02:29:22,085 train 650 1.783744e-02 -0.885119
2019-11-07 02:29:31,873 train 700 1.782328e-02 -0.867764
2019-11-07 02:29:41,663 train 750 1.782099e-02 -0.949491
2019-11-07 02:29:51,450 train 800 1.783123e-02 -0.928194
2019-11-07 02:30:01,236 train 850 1.782521e-02 -0.926477
2019-11-07 02:30:04,161 training loss; R2: 1.781608e-02 -0.922275
2019-11-07 02:30:04,788 valid 000 1.956190e-02 0.105050
2019-11-07 02:30:14,188 valid 050 1.767526e-02 -0.930636
2019-11-07 02:30:22,503 validation loss; R2: 1.770705e-02 -0.972109
2019-11-07 02:30:22,567 epoch 319 lr 1.000000e-05
2019-11-07 02:30:23,295 train 000 1.826399e-02 -0.274400
2019-11-07 02:30:33,022 train 050 1.790917e-02 -0.836542
2019-11-07 02:30:42,745 train 100 1.774623e-02 -1.871350
2019-11-07 02:30:52,502 train 150 1.783520e-02 -1.619105
2019-11-07 02:31:02,279 train 200 1.774258e-02 -1.570600
2019-11-07 02:31:12,048 train 250 1.773650e-02 -1.386491
2019-11-07 02:31:21,870 train 300 1.780240e-02 -1.319345
2019-11-07 02:31:31,677 train 350 1.777239e-02 -1.235148
2019-11-07 02:31:41,494 train 400 1.777913e-02 -1.219307
2019-11-07 02:31:51,314 train 450 1.775766e-02 -1.149139
2019-11-07 02:32:01,132 train 500 1.772079e-02 -1.119442
2019-11-07 02:32:10,949 train 550 1.772010e-02 -1.083381
2019-11-07 02:32:20,772 train 600 1.773694e-02 -1.030115
2019-11-07 02:32:30,591 train 650 1.772955e-02 -0.985507
2019-11-07 02:32:40,415 train 700 1.772334e-02 -0.962368
2019-11-07 02:32:50,228 train 750 1.771878e-02 -0.938485
2019-11-07 02:33:00,044 train 800 1.772406e-02 -0.918618
2019-11-07 02:33:09,879 train 850 1.773730e-02 -0.900499
2019-11-07 02:33:12,810 training loss; R2: 1.773518e-02 -0.904857
2019-11-07 02:33:13,502 valid 000 1.794755e-02 -0.004794
2019-11-07 02:33:22,850 valid 050 1.795738e-02 -1.520973
2019-11-07 02:33:31,206 validation loss; R2: 1.815042e-02 -1.264473
2019-11-07 02:33:31,273 epoch 320 lr 1.000000e-05
2019-11-07 02:33:32,055 train 000 2.078156e-02 -0.333759
2019-11-07 02:33:41,783 train 050 1.765944e-02 -0.816386
2019-11-07 02:33:51,509 train 100 1.773322e-02 -0.709529
2019-11-07 02:34:01,243 train 150 1.778001e-02 -0.731871
2019-11-07 02:34:10,982 train 200 1.789354e-02 -0.742655
2019-11-07 02:34:20,721 train 250 1.793249e-02 -0.749963
2019-11-07 02:34:30,480 train 300 1.788379e-02 -0.724409
2019-11-07 02:34:40,240 train 350 1.787053e-02 -0.761312
2019-11-07 02:34:50,000 train 400 1.788103e-02 -0.728215
2019-11-07 02:34:59,773 train 450 1.788592e-02 -0.736706
2019-11-07 02:35:09,556 train 500 1.790270e-02 -0.743791
2019-11-07 02:35:19,320 train 550 1.790335e-02 -0.743542
2019-11-07 02:35:29,088 train 600 1.790166e-02 -0.751365
2019-11-07 02:35:38,864 train 650 1.789816e-02 -0.751559
2019-11-07 02:35:48,663 train 700 1.790276e-02 -0.744474
2019-11-07 02:35:58,467 train 750 1.791159e-02 -0.734383
2019-11-07 02:36:08,276 train 800 1.788484e-02 -0.722782
2019-11-07 02:36:18,093 train 850 1.789839e-02 -0.722740
2019-11-07 02:36:21,056 training loss; R2: 1.790205e-02 -0.717124
2019-11-07 02:36:21,701 valid 000 1.818827e-02 0.079468
2019-11-07 02:36:31,132 valid 050 1.842291e-02 -0.962266
2019-11-07 02:36:39,432 validation loss; R2: 1.824635e-02 -1.010231
2019-11-07 02:36:39,514 epoch 321 lr 1.000000e-05
2019-11-07 02:36:40,261 train 000 2.025255e-02 -1.024785
2019-11-07 02:36:50,393 train 050 1.803652e-02 -0.543219
2019-11-07 02:37:00,536 train 100 1.798849e-02 -0.812357
2019-11-07 02:37:10,689 train 150 1.811119e-02 -0.769652
2019-11-07 02:37:20,844 train 200 1.802056e-02 -0.736008
2019-11-07 02:37:31,000 train 250 1.799671e-02 -0.749847
2019-11-07 02:37:41,172 train 300 1.797160e-02 -0.739652
2019-11-07 02:37:51,346 train 350 1.792425e-02 -0.697094
2019-11-07 02:38:01,339 train 400 1.788075e-02 -0.719765
2019-11-07 02:38:11,149 train 450 1.783832e-02 -0.708555
2019-11-07 02:38:20,956 train 500 1.786746e-02 -0.722311
2019-11-07 02:38:30,761 train 550 1.784207e-02 -0.713438
2019-11-07 02:38:40,595 train 600 1.785283e-02 -0.700470
2019-11-07 02:38:50,405 train 650 1.785940e-02 -0.712199
2019-11-07 02:39:00,231 train 700 1.787347e-02 -0.720283
2019-11-07 02:39:10,046 train 750 1.787471e-02 -0.711955
2019-11-07 02:39:19,852 train 800 1.786862e-02 -0.705024
2019-11-07 02:39:29,661 train 850 1.787555e-02 -0.707130
2019-11-07 02:39:32,595 training loss; R2: 1.786148e-02 -0.702059
2019-11-07 02:39:33,232 valid 000 1.786310e-02 -1.590766
2019-11-07 02:39:42,668 valid 050 1.887309e-02 -1.005817
2019-11-07 02:39:50,994 validation loss; R2: 1.884004e-02 -0.914726
2019-11-07 02:39:51,062 epoch 322 lr 1.000000e-05
2019-11-07 02:39:51,817 train 000 2.270473e-02 -0.832170
2019-11-07 02:40:01,593 train 050 1.793894e-02 -0.716270
2019-11-07 02:40:11,392 train 100 1.807359e-02 -0.685181
2019-11-07 02:40:21,183 train 150 1.788667e-02 -0.687398
2019-11-07 02:40:30,995 train 200 1.786728e-02 -0.655956
2019-11-07 02:40:40,812 train 250 1.789319e-02 -0.719441
2019-11-07 02:40:50,638 train 300 1.784060e-02 -0.693036
2019-11-07 02:41:00,463 train 350 1.788436e-02 -0.716255
2019-11-07 02:41:10,286 train 400 1.782404e-02 -0.700133
2019-11-07 02:41:20,095 train 450 1.787181e-02 -0.708600
2019-11-07 02:41:29,901 train 500 1.790555e-02 -0.684884
2019-11-07 02:41:39,716 train 550 1.788279e-02 -0.694445
2019-11-07 02:41:49,529 train 600 1.791244e-02 -0.690098
2019-11-07 02:41:59,354 train 650 1.790044e-02 -0.698387
2019-11-07 02:42:09,220 train 700 1.787955e-02 -0.686077
2019-11-07 02:42:19,069 train 750 1.784484e-02 -0.706628
2019-11-07 02:42:28,935 train 800 1.785864e-02 -0.687497
2019-11-07 02:42:38,786 train 850 1.786480e-02 -0.741869
2019-11-07 02:42:41,720 training loss; R2: 1.786738e-02 -0.738407
2019-11-07 02:42:42,318 valid 000 1.765942e-02 -0.084843
2019-11-07 02:42:51,725 valid 050 1.838131e-02 -1.014491
2019-11-07 02:43:00,088 validation loss; R2: 1.835652e-02 -1.212608
2019-11-07 02:43:00,152 epoch 323 lr 1.000000e-05
2019-11-07 02:43:00,955 train 000 1.596940e-02 -2.524755
2019-11-07 02:43:10,692 train 050 1.778249e-02 -0.501607
2019-11-07 02:43:20,427 train 100 1.795685e-02 -0.507752
2019-11-07 02:43:30,190 train 150 1.791522e-02 -0.584423
2019-11-07 02:43:39,939 train 200 1.786994e-02 -0.593751
2019-11-07 02:43:49,731 train 250 1.786847e-02 -0.654117
2019-11-07 02:43:59,520 train 300 1.784510e-02 -0.649069
2019-11-07 02:44:09,313 train 350 1.778186e-02 -0.679222
2019-11-07 02:44:19,099 train 400 1.775746e-02 -0.676642
2019-11-07 02:44:28,881 train 450 1.777556e-02 -0.673913
2019-11-07 02:44:38,678 train 500 1.771536e-02 -0.664206
2019-11-07 02:44:48,475 train 550 1.770913e-02 -1.313229
2019-11-07 02:44:58,279 train 600 1.773948e-02 -1.272946
2019-11-07 02:45:08,090 train 650 1.775350e-02 -1.223526
2019-11-07 02:45:17,872 train 700 1.773829e-02 -1.212154
2019-11-07 02:45:27,659 train 750 1.774750e-02 -1.181434
2019-11-07 02:45:37,444 train 800 1.776255e-02 -1.146093
2019-11-07 02:45:47,229 train 850 1.777414e-02 -1.137194
2019-11-07 02:45:50,156 training loss; R2: 1.777475e-02 -1.134729
2019-11-07 02:45:50,804 valid 000 1.695863e-02 -0.922409
2019-11-07 02:46:00,198 valid 050 1.814971e-02 -0.605255
2019-11-07 02:46:08,498 validation loss; R2: 1.802600e-02 -0.806007
2019-11-07 02:46:08,566 epoch 324 lr 1.000000e-05
2019-11-07 02:46:09,288 train 000 1.752227e-02 -0.189368
2019-11-07 02:46:19,036 train 050 1.775537e-02 -1.199561
2019-11-07 02:46:28,803 train 100 1.793078e-02 -1.542658
2019-11-07 02:46:38,582 train 150 1.792088e-02 -1.275401
2019-11-07 02:46:48,363 train 200 1.790126e-02 -1.138024
2019-11-07 02:46:58,140 train 250 1.778288e-02 -1.087203
2019-11-07 02:47:07,906 train 300 1.782296e-02 -0.985717
2019-11-07 02:47:17,695 train 350 1.780007e-02 -0.953030
2019-11-07 02:47:27,481 train 400 1.780039e-02 -0.951768
2019-11-07 02:47:37,284 train 450 1.778356e-02 -0.926028
2019-11-07 02:47:47,070 train 500 1.776597e-02 -0.902180
2019-11-07 02:47:56,857 train 550 1.780487e-02 -0.897425
2019-11-07 02:48:06,632 train 600 1.781898e-02 -0.874698
2019-11-07 02:48:16,417 train 650 1.782759e-02 -0.869162
2019-11-07 02:48:26,208 train 700 1.783300e-02 -0.843308
2019-11-07 02:48:35,992 train 750 1.781731e-02 -0.869327
2019-11-07 02:48:45,781 train 800 1.781250e-02 -0.863267
2019-11-07 02:48:55,572 train 850 1.781560e-02 -0.848855
2019-11-07 02:48:58,502 training loss; R2: 1.783270e-02 -0.847423
2019-11-07 02:48:59,146 valid 000 2.062081e-02 -0.445356
2019-11-07 02:49:08,581 valid 050 1.828312e-02 -0.923517
2019-11-07 02:49:16,921 validation loss; R2: 1.816139e-02 -1.050153
2019-11-07 02:49:16,997 epoch 325 lr 1.000000e-05
2019-11-07 02:49:17,801 train 000 1.803684e-02 -0.232068
2019-11-07 02:49:27,561 train 050 1.799195e-02 -0.606242
2019-11-07 02:49:37,323 train 100 1.786909e-02 -0.853019
2019-11-07 02:49:47,116 train 150 1.781186e-02 -0.761921
2019-11-07 02:49:56,927 train 200 1.774770e-02 -0.712413
2019-11-07 02:50:06,735 train 250 1.777745e-02 -0.931812
2019-11-07 02:50:16,537 train 300 1.780226e-02 -0.929031
2019-11-07 02:50:26,348 train 350 1.775199e-02 -0.909973
2019-11-07 02:50:36,163 train 400 1.776588e-02 -0.862846
2019-11-07 02:50:45,980 train 450 1.776978e-02 -0.848211
2019-11-07 02:50:55,790 train 500 1.770835e-02 -0.834723
2019-11-07 02:51:05,602 train 550 1.772352e-02 -0.832547
2019-11-07 02:51:15,402 train 600 1.772939e-02 -0.812371
2019-11-07 02:51:25,209 train 650 1.780154e-02 -0.792823
2019-11-07 02:51:35,011 train 700 1.778695e-02 -0.790412
2019-11-07 02:51:44,818 train 750 1.779167e-02 -0.774458
2019-11-07 02:51:54,626 train 800 1.779374e-02 -0.782163
2019-11-07 02:52:04,426 train 850 1.779478e-02 -0.808225
2019-11-07 02:52:07,375 training loss; R2: 1.779678e-02 -0.803074
2019-11-07 02:52:08,018 valid 000 1.952076e-02 -0.127213
2019-11-07 02:52:17,450 valid 050 1.888667e-02 -0.944160
2019-11-07 02:52:25,782 validation loss; R2: 1.873439e-02 -0.949426
2019-11-07 02:52:25,850 epoch 326 lr 1.000000e-05
2019-11-07 02:52:26,630 train 000 1.697708e-02 -0.201322
2019-11-07 02:52:36,408 train 050 1.789406e-02 -5.923946
2019-11-07 02:52:46,201 train 100 1.796813e-02 -3.254217
2019-11-07 02:52:56,007 train 150 1.787371e-02 -2.406620
2019-11-07 02:53:05,830 train 200 1.784839e-02 -2.003693
2019-11-07 02:53:15,644 train 250 1.781342e-02 -1.795762
2019-11-07 02:53:25,476 train 300 1.785942e-02 -1.610647
2019-11-07 02:53:35,288 train 350 1.782957e-02 -1.467567
2019-11-07 02:53:45,132 train 400 1.781932e-02 -1.362587
2019-11-07 02:53:54,962 train 450 1.781279e-02 -1.289627
2019-11-07 02:54:04,776 train 500 1.781404e-02 -1.303849
2019-11-07 02:54:14,586 train 550 1.779762e-02 -1.261942
2019-11-07 02:54:24,394 train 600 1.780482e-02 -1.250605
2019-11-07 02:54:34,199 train 650 1.782850e-02 -1.202681
2019-11-07 02:54:44,024 train 700 1.786575e-02 -1.161114
2019-11-07 02:54:53,845 train 750 1.785896e-02 -1.120929
2019-11-07 02:55:03,667 train 800 1.787416e-02 -1.093964
2019-11-07 02:55:13,477 train 850 1.788110e-02 -1.087927
2019-11-07 02:55:16,408 training loss; R2: 1.786147e-02 -1.080116
2019-11-07 02:55:17,062 valid 000 2.229637e-02 -0.717757
2019-11-07 02:55:26,474 valid 050 1.933444e-02 -1.064240
2019-11-07 02:55:34,790 validation loss; R2: 1.947190e-02 -1.078870
2019-11-07 02:55:34,856 epoch 327 lr 1.000000e-05
2019-11-07 02:55:35,621 train 000 1.485126e-02 -1.037024
2019-11-07 02:55:45,384 train 050 1.763866e-02 -0.782550
2019-11-07 02:55:55,157 train 100 1.749074e-02 -0.746139
2019-11-07 02:56:04,998 train 150 1.761044e-02 -0.750303
2019-11-07 02:56:14,847 train 200 1.771137e-02 -0.762650
2019-11-07 02:56:24,701 train 250 1.776102e-02 -0.762086
2019-11-07 02:56:34,558 train 300 1.775656e-02 -0.738673
2019-11-07 02:56:44,411 train 350 1.776709e-02 -0.728126
2019-11-07 02:56:54,266 train 400 1.774620e-02 -0.744170
2019-11-07 02:57:04,131 train 450 1.772936e-02 -0.740151
2019-11-07 02:57:13,986 train 500 1.773783e-02 -0.733528
2019-11-07 02:57:23,837 train 550 1.775068e-02 -0.714365
2019-11-07 02:57:33,690 train 600 1.777305e-02 -0.728014
2019-11-07 02:57:43,558 train 650 1.778051e-02 -0.721515
2019-11-07 02:57:53,427 train 700 1.777338e-02 -0.728638
2019-11-07 02:58:03,248 train 750 1.778424e-02 -0.726872
2019-11-07 02:58:13,069 train 800 1.779741e-02 -0.719798
2019-11-07 02:58:22,883 train 850 1.780472e-02 -0.717915
2019-11-07 02:58:25,817 training loss; R2: 1.779493e-02 -0.718512
2019-11-07 02:58:26,530 valid 000 1.855090e-02 -0.209632
2019-11-07 02:58:35,918 valid 050 1.852371e-02 -1.455789
2019-11-07 02:58:44,323 validation loss; R2: 1.817984e-02 -1.259489
2019-11-07 02:58:44,404 epoch 328 lr 1.000000e-05
2019-11-07 02:58:45,291 train 000 1.515554e-02 -1.191544
2019-11-07 02:58:55,039 train 050 1.791375e-02 -0.825568
2019-11-07 02:59:04,855 train 100 1.802483e-02 -0.724165
2019-11-07 02:59:14,689 train 150 1.787908e-02 -0.714022
2019-11-07 02:59:24,533 train 200 1.785343e-02 -0.757112
2019-11-07 02:59:34,387 train 250 1.787518e-02 -0.761007
2019-11-07 02:59:44,238 train 300 1.785018e-02 -0.699085
2019-11-07 02:59:54,109 train 350 1.781638e-02 -0.682765
2019-11-07 03:00:03,963 train 400 1.782363e-02 -0.670077
2019-11-07 03:00:13,828 train 450 1.780988e-02 -0.662884
2019-11-07 03:00:23,695 train 500 1.782165e-02 -0.685756
2019-11-07 03:00:33,548 train 550 1.780315e-02 -0.685110
2019-11-07 03:00:43,391 train 600 1.780737e-02 -0.686314
2019-11-07 03:00:53,165 train 650 1.779339e-02 -0.677925
2019-11-07 03:01:02,907 train 700 1.779394e-02 -0.691305
2019-11-07 03:01:12,645 train 750 1.777784e-02 -0.708537
2019-11-07 03:01:22,389 train 800 1.777345e-02 -0.719127
2019-11-07 03:01:32,144 train 850 1.776833e-02 -0.702857
2019-11-07 03:01:35,057 training loss; R2: 1.776798e-02 -0.707059
2019-11-07 03:01:35,744 valid 000 2.142316e-02 -2.528693
2019-11-07 03:01:45,133 valid 050 1.879351e-02 -0.919769
2019-11-07 03:01:53,562 validation loss; R2: 1.871036e-02 -1.117968
2019-11-07 03:01:53,628 epoch 329 lr 1.000000e-05
2019-11-07 03:01:54,408 train 000 2.121547e-02 -1.177568
2019-11-07 03:02:04,097 train 050 1.805840e-02 -0.529242
2019-11-07 03:02:13,793 train 100 1.776373e-02 -0.714794
2019-11-07 03:02:23,514 train 150 1.775693e-02 -0.718350
2019-11-07 03:02:33,263 train 200 1.773817e-02 -0.751749
2019-11-07 03:02:43,010 train 250 1.776525e-02 -0.752862
2019-11-07 03:02:52,757 train 300 1.780831e-02 -0.694131
2019-11-07 03:03:02,502 train 350 1.784459e-02 -0.878282
2019-11-07 03:03:12,256 train 400 1.781290e-02 -0.835101
2019-11-07 03:03:22,005 train 450 1.787997e-02 -0.865619
2019-11-07 03:03:31,757 train 500 1.785483e-02 -0.855674
2019-11-07 03:03:41,518 train 550 1.786925e-02 -0.848101
2019-11-07 03:03:51,281 train 600 1.788019e-02 -0.833967
2019-11-07 03:04:01,037 train 650 1.784143e-02 -0.890611
2019-11-07 03:04:10,785 train 700 1.780595e-02 -0.883214
2019-11-07 03:04:20,528 train 750 1.780562e-02 -0.879757
2019-11-07 03:04:30,282 train 800 1.780837e-02 -0.873208
2019-11-07 03:04:40,034 train 850 1.780547e-02 -17.332476
2019-11-07 03:04:42,944 training loss; R2: 1.780464e-02 -17.044344
2019-11-07 03:04:43,622 valid 000 1.701646e-02 -2.053172
2019-11-07 03:04:52,978 valid 050 1.926963e-02 -1.140954
2019-11-07 03:05:01,376 validation loss; R2: 1.898350e-02 -1.139966
2019-11-07 03:05:01,441 epoch 330 lr 1.000000e-05
2019-11-07 03:05:02,162 train 000 1.669874e-02 -0.441233
2019-11-07 03:05:11,857 train 050 1.717551e-02 -1.095381
2019-11-07 03:05:21,541 train 100 1.758368e-02 -2.883816
2019-11-07 03:05:31,266 train 150 1.761944e-02 -2.139501
2019-11-07 03:05:41,086 train 200 1.771727e-02 -1.786972
2019-11-07 03:05:50,926 train 250 1.774359e-02 -1.566578
2019-11-07 03:06:00,770 train 300 1.775962e-02 -1.436309
2019-11-07 03:06:10,615 train 350 1.778293e-02 -1.339843
2019-11-07 03:06:20,485 train 400 1.779885e-02 -1.248803
2019-11-07 03:06:30,350 train 450 1.777799e-02 -1.182204
2019-11-07 03:06:40,131 train 500 1.776609e-02 -1.137908
2019-11-07 03:06:49,921 train 550 1.772439e-02 -1.100450
2019-11-07 03:06:59,703 train 600 1.776779e-02 -1.057069
2019-11-07 03:07:09,491 train 650 1.775263e-02 -1.028042
2019-11-07 03:07:19,276 train 700 1.775065e-02 -1.001090
2019-11-07 03:07:29,054 train 750 1.773438e-02 -0.998947
2019-11-07 03:07:38,849 train 800 1.773653e-02 -0.978628
2019-11-07 03:07:48,639 train 850 1.775494e-02 -0.956471
2019-11-07 03:07:51,565 training loss; R2: 1.776337e-02 -0.951178
2019-11-07 03:07:52,212 valid 000 1.908343e-02 -0.646879
2019-11-07 03:08:01,632 valid 050 1.822033e-02 -1.084681
2019-11-07 03:08:10,007 validation loss; R2: 1.796615e-02 -1.219724
2019-11-07 03:08:10,075 epoch 331 lr 1.000000e-05
2019-11-07 03:08:10,811 train 000 1.561102e-02 0.070952
2019-11-07 03:08:20,536 train 050 1.810321e-02 -0.475975
2019-11-07 03:08:30,273 train 100 1.785335e-02 -0.690134
2019-11-07 03:08:40,033 train 150 1.790512e-02 -0.742937
2019-11-07 03:08:49,803 train 200 1.789493e-02 -0.673666
2019-11-07 03:08:59,580 train 250 1.790154e-02 -0.672926
2019-11-07 03:09:09,354 train 300 1.785209e-02 -0.661154
2019-11-07 03:09:19,126 train 350 1.785925e-02 -0.684304
2019-11-07 03:09:28,931 train 400 1.779426e-02 -0.681990
2019-11-07 03:09:38,713 train 450 1.778261e-02 -0.692241
2019-11-07 03:09:48,496 train 500 1.776269e-02 -0.680496
2019-11-07 03:09:58,277 train 550 1.779314e-02 -0.708472
2019-11-07 03:10:08,066 train 600 1.783495e-02 -0.718031
2019-11-07 03:10:17,868 train 650 1.782463e-02 -0.736819
2019-11-07 03:10:27,656 train 700 1.784171e-02 -0.724910
2019-11-07 03:10:37,434 train 750 1.786522e-02 -0.715354
2019-11-07 03:10:47,214 train 800 1.784503e-02 -0.723907
2019-11-07 03:10:57,011 train 850 1.783710e-02 -0.724715
2019-11-07 03:10:59,937 training loss; R2: 1.783311e-02 -0.720481
2019-11-07 03:11:00,578 valid 000 1.594413e-02 -0.375954
2019-11-07 03:11:09,997 valid 050 1.866294e-02 -0.949333
2019-11-07 03:11:18,421 validation loss; R2: 1.874580e-02 -0.880762
2019-11-07 03:11:18,487 epoch 332 lr 1.000000e-05
2019-11-07 03:11:19,279 train 000 1.959181e-02 -0.619550
2019-11-07 03:11:28,998 train 050 1.770293e-02 -0.975734
2019-11-07 03:11:38,746 train 100 1.782448e-02 -0.871891
2019-11-07 03:11:48,512 train 150 1.771352e-02 -0.795812
2019-11-07 03:11:58,278 train 200 1.772352e-02 -0.804379
2019-11-07 03:12:08,050 train 250 1.778475e-02 -0.769258
2019-11-07 03:12:17,827 train 300 1.770227e-02 -0.756149
2019-11-07 03:12:27,602 train 350 1.772971e-02 -0.777945
2019-11-07 03:12:37,376 train 400 1.773048e-02 -0.762331
2019-11-07 03:12:47,152 train 450 1.774602e-02 -0.740098
2019-11-07 03:12:56,934 train 500 1.771925e-02 -0.747460
2019-11-07 03:13:06,717 train 550 1.772565e-02 -0.759962
2019-11-07 03:13:16,500 train 600 1.774335e-02 -0.765503
2019-11-07 03:13:26,277 train 650 1.773208e-02 -0.769945
2019-11-07 03:13:36,035 train 700 1.773798e-02 -0.757558
2019-11-07 03:13:45,794 train 750 1.775348e-02 -0.758529
2019-11-07 03:13:55,548 train 800 1.776048e-02 -0.785593
2019-11-07 03:14:05,299 train 850 1.774233e-02 -0.781962
2019-11-07 03:14:08,215 training loss; R2: 1.773988e-02 -0.779634
2019-11-07 03:14:08,831 valid 000 1.829954e-02 -0.120970
2019-11-07 03:14:18,267 valid 050 1.776774e-02 -1.186593
2019-11-07 03:14:26,567 validation loss; R2: 1.818029e-02 -1.003522
2019-11-07 03:14:26,632 epoch 333 lr 1.000000e-05
2019-11-07 03:14:27,449 train 000 1.898742e-02 -0.331049
2019-11-07 03:14:37,169 train 050 1.792521e-02 -1.087721
2019-11-07 03:14:46,933 train 100 1.802483e-02 -1.033808
2019-11-07 03:14:56,701 train 150 1.791844e-02 -0.851275
2019-11-07 03:15:06,476 train 200 1.799805e-02 -0.864694
2019-11-07 03:15:16,243 train 250 1.791387e-02 -0.847115
2019-11-07 03:15:25,999 train 300 1.785741e-02 -0.862822
2019-11-07 03:15:35,744 train 350 1.780990e-02 -0.853468
2019-11-07 03:15:45,494 train 400 1.778006e-02 -0.818890
2019-11-07 03:15:55,248 train 450 1.777409e-02 -0.806213
2019-11-07 03:16:05,003 train 500 1.778847e-02 -0.867546
2019-11-07 03:16:14,776 train 550 1.779135e-02 -0.845185
2019-11-07 03:16:24,535 train 600 1.777061e-02 -0.833719
2019-11-07 03:16:34,297 train 650 1.775713e-02 -0.845789
2019-11-07 03:16:44,047 train 700 1.775643e-02 -0.822492
2019-11-07 03:16:53,811 train 750 1.775987e-02 -0.789444
2019-11-07 03:17:03,569 train 800 1.776982e-02 -0.781244
2019-11-07 03:17:13,332 train 850 1.775962e-02 -0.783100
2019-11-07 03:17:16,295 training loss; R2: 1.776478e-02 -0.791943
2019-11-07 03:17:16,932 valid 000 1.807002e-02 -0.248834
2019-11-07 03:17:26,327 valid 050 1.793092e-02 -0.999019
2019-11-07 03:17:34,650 validation loss; R2: 1.786307e-02 -0.981413
2019-11-07 03:17:34,731 epoch 334 lr 1.000000e-05
2019-11-07 03:17:35,522 train 000 1.796916e-02 -0.588984
2019-11-07 03:17:45,640 train 050 1.739699e-02 -0.639455
2019-11-07 03:17:55,804 train 100 1.770972e-02 -0.629752
2019-11-07 03:18:05,973 train 150 1.766843e-02 -0.653338
2019-11-07 03:18:16,155 train 200 1.765740e-02 -0.705790
2019-11-07 03:18:26,321 train 250 1.768063e-02 -0.667331
2019-11-07 03:18:36,488 train 300 1.773013e-02 -0.689252
2019-11-07 03:18:46,676 train 350 1.771978e-02 -0.675229
2019-11-07 03:18:56,842 train 400 1.774514e-02 -0.897762
2019-11-07 03:19:07,037 train 450 1.772129e-02 -0.883733
2019-11-07 03:19:17,197 train 500 1.769105e-02 -0.915732
2019-11-07 03:19:27,377 train 550 1.770906e-02 -0.913570
2019-11-07 03:19:37,563 train 600 1.773558e-02 -0.899418
2019-11-07 03:19:47,524 train 650 1.775085e-02 -0.867207
2019-11-07 03:19:57,333 train 700 1.774710e-02 -0.861879
2019-11-07 03:20:07,165 train 750 1.773403e-02 -0.838465
2019-11-07 03:20:17,005 train 800 1.775774e-02 -0.834185
2019-11-07 03:20:26,860 train 850 1.776227e-02 -2.459530
2019-11-07 03:20:29,799 training loss; R2: 1.774525e-02 -2.430158
2019-11-07 03:20:30,397 valid 000 1.729829e-02 -0.019413
2019-11-07 03:20:39,850 valid 050 1.818898e-02 -0.995840
2019-11-07 03:20:48,163 validation loss; R2: 1.807840e-02 -1.099244
2019-11-07 03:20:48,231 epoch 335 lr 1.000000e-05
2019-11-07 03:20:48,986 train 000 1.888067e-02 -0.743381
2019-11-07 03:20:58,748 train 050 1.787745e-02 -0.599523
2019-11-07 03:21:08,538 train 100 1.803521e-02 -0.707203
2019-11-07 03:21:18,354 train 150 1.802483e-02 -0.688572
2019-11-07 03:21:28,163 train 200 1.787462e-02 -0.688143
2019-11-07 03:21:37,992 train 250 1.787308e-02 -0.704986
2019-11-07 03:21:47,816 train 300 1.782269e-02 -0.683974
2019-11-07 03:21:57,664 train 350 1.780814e-02 -0.642695
2019-11-07 03:22:07,473 train 400 1.786046e-02 -0.640914
2019-11-07 03:22:17,296 train 450 1.785113e-02 -0.649447
2019-11-07 03:22:27,112 train 500 1.782947e-02 -0.642225
2019-11-07 03:22:36,922 train 550 1.780869e-02 -0.639947
2019-11-07 03:22:46,732 train 600 1.779013e-02 -0.680039
2019-11-07 03:22:56,560 train 650 1.781123e-02 -0.682652
2019-11-07 03:23:06,372 train 700 1.782034e-02 -0.688333
2019-11-07 03:23:16,176 train 750 1.783944e-02 -0.702454
2019-11-07 03:23:25,991 train 800 1.783532e-02 -0.715968
2019-11-07 03:23:35,807 train 850 1.783813e-02 -0.707950
2019-11-07 03:23:38,743 training loss; R2: 1.784117e-02 -0.714337
2019-11-07 03:23:39,366 valid 000 1.836079e-02 -0.147473
2019-11-07 03:23:48,799 valid 050 1.947029e-02 -1.226161
2019-11-07 03:23:57,118 validation loss; R2: 1.899072e-02 -1.217474
2019-11-07 03:23:57,184 epoch 336 lr 1.000000e-05
2019-11-07 03:23:57,946 train 000 1.600226e-02 -0.900742
2019-11-07 03:24:07,730 train 050 1.796619e-02 -0.934335
2019-11-07 03:24:17,528 train 100 1.780276e-02 -0.829777
2019-11-07 03:24:27,330 train 150 1.778953e-02 -0.777316
2019-11-07 03:24:37,143 train 200 1.778144e-02 -0.772636
2019-11-07 03:24:46,994 train 250 1.779532e-02 -0.742412
2019-11-07 03:24:56,846 train 300 1.787240e-02 -0.702402
2019-11-07 03:25:06,687 train 350 1.789374e-02 -0.698877
2019-11-07 03:25:16,535 train 400 1.792376e-02 -0.700462
2019-11-07 03:25:26,387 train 450 1.791583e-02 -0.675913
2019-11-07 03:25:36,235 train 500 1.791804e-02 -0.682536
2019-11-07 03:25:46,084 train 550 1.789010e-02 -0.691797
2019-11-07 03:25:55,931 train 600 1.786231e-02 -0.672750
2019-11-07 03:26:05,788 train 650 1.789250e-02 -1.060528
2019-11-07 03:26:15,641 train 700 1.785777e-02 -1.024934
2019-11-07 03:26:25,460 train 750 1.786836e-02 -0.991487
2019-11-07 03:26:35,279 train 800 1.785257e-02 -0.992488
2019-11-07 03:26:45,097 train 850 1.783441e-02 -0.998472
2019-11-07 03:26:48,041 training loss; R2: 1.784041e-02 -0.994264
2019-11-07 03:26:48,626 valid 000 1.887270e-02 -0.200796
2019-11-07 03:26:58,061 valid 050 1.763320e-02 -0.687903
2019-11-07 03:27:06,362 validation loss; R2: 1.762549e-02 -0.738678
2019-11-07 03:27:06,428 epoch 337 lr 1.000000e-05
2019-11-07 03:27:07,202 train 000 1.894651e-02 -0.059511
2019-11-07 03:27:16,986 train 050 1.752786e-02 -0.534244
2019-11-07 03:27:26,776 train 100 1.755714e-02 -0.686414
2019-11-07 03:27:36,570 train 150 1.766361e-02 -0.763560
2019-11-07 03:27:46,350 train 200 1.778972e-02 -0.794244
2019-11-07 03:27:56,140 train 250 1.777355e-02 -0.756420
2019-11-07 03:28:05,927 train 300 1.774532e-02 -0.710232
2019-11-07 03:28:15,713 train 350 1.776361e-02 -0.731605
2019-11-07 03:28:25,489 train 400 1.772147e-02 -0.734901
2019-11-07 03:28:35,287 train 450 1.774992e-02 -0.722043
2019-11-07 03:28:45,069 train 500 1.779838e-02 -0.756285
2019-11-07 03:28:54,849 train 550 1.778427e-02 -0.757837
2019-11-07 03:29:04,638 train 600 1.778110e-02 -0.760338
2019-11-07 03:29:14,418 train 650 1.776690e-02 -0.770784
2019-11-07 03:29:24,203 train 700 1.776424e-02 -0.759342
2019-11-07 03:29:33,998 train 750 1.774009e-02 -0.763028
2019-11-07 03:29:43,791 train 800 1.773462e-02 -0.746282
2019-11-07 03:29:53,581 train 850 1.773132e-02 -0.749706
2019-11-07 03:29:56,503 training loss; R2: 1.773103e-02 -0.756322
2019-11-07 03:29:57,102 valid 000 2.096684e-02 -0.185090
2019-11-07 03:30:06,540 valid 050 1.838831e-02 -4.262811
2019-11-07 03:30:14,851 validation loss; R2: 1.824708e-02 -2.909149
2019-11-07 03:30:14,918 epoch 338 lr 1.000000e-05
2019-11-07 03:30:15,718 train 000 1.993613e-02 -0.828013
2019-11-07 03:30:25,468 train 050 1.807333e-02 -0.739854
2019-11-07 03:30:35,252 train 100 1.782796e-02 -0.741052
2019-11-07 03:30:45,047 train 150 1.775897e-02 -0.705984
2019-11-07 03:30:54,832 train 200 1.775157e-02 -0.693355
2019-11-07 03:31:04,620 train 250 1.770313e-02 -0.685803
2019-11-07 03:31:14,398 train 300 1.775791e-02 -0.662473
2019-11-07 03:31:24,187 train 350 1.772875e-02 -0.686340
2019-11-07 03:31:33,975 train 400 1.770259e-02 -1.005137
2019-11-07 03:31:43,765 train 450 1.774709e-02 -0.959618
2019-11-07 03:31:53,566 train 500 1.777276e-02 -0.930473
2019-11-07 03:32:03,361 train 550 1.774693e-02 -0.929104
2019-11-07 03:32:13,148 train 600 1.776523e-02 -0.892818
2019-11-07 03:32:22,943 train 650 1.777381e-02 -0.863543
2019-11-07 03:32:32,743 train 700 1.780123e-02 -0.870037
2019-11-07 03:32:42,528 train 750 1.778219e-02 -0.869330
2019-11-07 03:32:52,315 train 800 1.778540e-02 -0.855880
2019-11-07 03:33:02,124 train 850 1.778956e-02 -0.871360
2019-11-07 03:33:05,054 training loss; R2: 1.777642e-02 -0.863666
2019-11-07 03:33:05,690 valid 000 1.785809e-02 -0.289182
2019-11-07 03:33:15,173 valid 050 1.891739e-02 -1.141104
2019-11-07 03:33:23,514 validation loss; R2: 1.938726e-02 -1.295436
2019-11-07 03:33:23,578 epoch 339 lr 1.000000e-05
2019-11-07 03:33:24,300 train 000 2.063810e-02 -2.461011
2019-11-07 03:33:34,067 train 050 1.795921e-02 -0.736153
2019-11-07 03:33:43,866 train 100 1.783108e-02 -0.680553
2019-11-07 03:33:53,683 train 150 1.789179e-02 -0.651896
2019-11-07 03:34:03,495 train 200 1.780065e-02 -0.656606
2019-11-07 03:34:13,307 train 250 1.772882e-02 -0.701797
2019-11-07 03:34:23,124 train 300 1.773388e-02 -0.727190
2019-11-07 03:34:32,951 train 350 1.776691e-02 -0.707429
2019-11-07 03:34:42,755 train 400 1.775621e-02 -0.683016
2019-11-07 03:34:52,569 train 450 1.779036e-02 -0.659644
2019-11-07 03:35:02,374 train 500 1.778478e-02 -0.658026
2019-11-07 03:35:12,171 train 550 1.777517e-02 -0.675666
2019-11-07 03:35:21,988 train 600 1.777072e-02 -0.675795
2019-11-07 03:35:31,804 train 650 1.775149e-02 -0.680948
2019-11-07 03:35:41,620 train 700 1.775676e-02 -0.687548
2019-11-07 03:35:51,441 train 750 1.776462e-02 -0.702034
2019-11-07 03:36:01,281 train 800 1.777645e-02 -0.770258
2019-11-07 03:36:11,121 train 850 1.775593e-02 -0.767798
2019-11-07 03:36:14,092 training loss; R2: 1.776192e-02 -0.764591
2019-11-07 03:36:14,723 valid 000 1.774969e-02 0.074091
2019-11-07 03:36:24,165 valid 050 1.839668e-02 -0.864989
2019-11-07 03:36:32,472 validation loss; R2: 1.832758e-02 -0.942515
2019-11-07 03:36:32,559 epoch 340 lr 1.000000e-05
2019-11-07 03:36:33,368 train 000 1.633024e-02 -0.297884
2019-11-07 03:36:43,139 train 050 1.774496e-02 -1.082475
2019-11-07 03:36:52,939 train 100 1.771786e-02 -0.821130
2019-11-07 03:37:02,761 train 150 1.770638e-02 -0.769782
2019-11-07 03:37:12,566 train 200 1.769060e-02 -0.760111
2019-11-07 03:37:22,353 train 250 1.771280e-02 -0.745911
2019-11-07 03:37:32,148 train 300 1.760563e-02 -0.735099
2019-11-07 03:37:41,940 train 350 1.759508e-02 -0.749500
2019-11-07 03:37:51,743 train 400 1.760967e-02 -0.744909
2019-11-07 03:38:01,541 train 450 1.765175e-02 -0.739210
2019-11-07 03:38:11,343 train 500 1.762069e-02 -0.740000
2019-11-07 03:38:21,143 train 550 1.759599e-02 -0.721926
2019-11-07 03:38:30,949 train 600 1.763788e-02 -0.992933
2019-11-07 03:38:40,766 train 650 1.766878e-02 -0.985668
2019-11-07 03:38:50,569 train 700 1.764487e-02 -0.973084
2019-11-07 03:39:00,362 train 750 1.763380e-02 -0.965759
2019-11-07 03:39:10,190 train 800 1.764670e-02 -1.403204
2019-11-07 03:39:19,986 train 850 1.765698e-02 -1.368908
2019-11-07 03:39:22,914 training loss; R2: 1.765372e-02 -1.361425
2019-11-07 03:39:23,624 valid 000 1.786816e-02 -0.327183
2019-11-07 03:39:33,005 valid 050 1.862978e-02 -1.335625
2019-11-07 03:39:41,329 validation loss; R2: 1.879087e-02 -2.212937
2019-11-07 03:39:41,394 epoch 341 lr 1.000000e-05
2019-11-07 03:39:42,194 train 000 1.754034e-02 -0.622527
2019-11-07 03:39:51,917 train 050 1.787740e-02 -0.639594
2019-11-07 03:40:01,674 train 100 1.782327e-02 -0.675405
2019-11-07 03:40:11,456 train 150 1.775514e-02 -0.680085
2019-11-07 03:40:21,229 train 200 1.775010e-02 -0.662399
2019-11-07 03:40:31,010 train 250 1.779910e-02 -0.631765
2019-11-07 03:40:40,788 train 300 1.773973e-02 -0.760760
2019-11-07 03:40:50,561 train 350 1.774346e-02 -0.748885
2019-11-07 03:41:00,345 train 400 1.771682e-02 -0.718568
2019-11-07 03:41:10,120 train 450 1.774844e-02 -0.713847
2019-11-07 03:41:19,906 train 500 1.773979e-02 -0.735579
2019-11-07 03:41:29,695 train 550 1.774510e-02 -0.737146
2019-11-07 03:41:39,477 train 600 1.771218e-02 -0.735131
2019-11-07 03:41:49,267 train 650 1.771042e-02 -0.837480
2019-11-07 03:41:59,060 train 700 1.769857e-02 -0.837775
2019-11-07 03:42:08,843 train 750 1.771992e-02 -0.819833
2019-11-07 03:42:18,636 train 800 1.769626e-02 -0.811218
2019-11-07 03:42:28,424 train 850 1.768500e-02 -0.818578
2019-11-07 03:42:31,402 training loss; R2: 1.769304e-02 -0.812358
2019-11-07 03:42:32,052 valid 000 1.943839e-02 -0.648796
2019-11-07 03:42:41,466 valid 050 1.905758e-02 -0.931848
2019-11-07 03:42:49,822 validation loss; R2: 1.895307e-02 -1.053384
2019-11-07 03:42:49,904 epoch 342 lr 1.000000e-05
2019-11-07 03:42:50,707 train 000 1.785833e-02 -0.701835
2019-11-07 03:43:00,437 train 050 1.766275e-02 -1.652655
2019-11-07 03:43:10,206 train 100 1.779535e-02 -1.167249
2019-11-07 03:43:19,991 train 150 1.788469e-02 -1.079441
2019-11-07 03:43:29,790 train 200 1.785202e-02 -0.951934
2019-11-07 03:43:39,579 train 250 1.774397e-02 -0.910959
2019-11-07 03:43:49,372 train 300 1.778048e-02 -0.994790
2019-11-07 03:43:59,162 train 350 1.777098e-02 -0.943570
2019-11-07 03:44:08,936 train 400 1.772891e-02 -0.913529
2019-11-07 03:44:18,727 train 450 1.773701e-02 -0.882048
2019-11-07 03:44:28,495 train 500 1.773839e-02 -0.855033
2019-11-07 03:44:38,267 train 550 1.772872e-02 -1.424206
2019-11-07 03:44:48,035 train 600 1.774024e-02 -1.347488
2019-11-07 03:44:57,829 train 650 1.773060e-02 -1.296524
2019-11-07 03:45:07,620 train 700 1.773970e-02 -1.258490
2019-11-07 03:45:17,403 train 750 1.771210e-02 -1.235179
2019-11-07 03:45:27,194 train 800 1.771979e-02 -1.206876
2019-11-07 03:45:36,991 train 850 1.774238e-02 -1.218507
2019-11-07 03:45:39,961 training loss; R2: 1.774080e-02 -1.203761
2019-11-07 03:45:40,590 valid 000 1.978277e-02 -0.518676
2019-11-07 03:45:50,019 valid 050 1.940852e-02 -1.597057
2019-11-07 03:45:58,358 validation loss; R2: 1.930115e-02 -2.383811
2019-11-07 03:45:58,439 epoch 343 lr 1.000000e-05
2019-11-07 03:45:59,266 train 000 2.052012e-02 0.005503
2019-11-07 03:46:08,993 train 050 1.792888e-02 -1.348515
2019-11-07 03:46:18,734 train 100 1.783202e-02 -1.016889
2019-11-07 03:46:28,521 train 150 1.768958e-02 -0.949141
2019-11-07 03:46:38,323 train 200 1.771464e-02 -0.894336
2019-11-07 03:46:48,095 train 250 1.775522e-02 -0.852522
2019-11-07 03:46:57,868 train 300 1.769088e-02 -0.824020
2019-11-07 03:47:07,642 train 350 1.768347e-02 -0.799680
2019-11-07 03:47:17,421 train 400 1.766049e-02 -0.804042
2019-11-07 03:47:27,204 train 450 1.771057e-02 -0.768537
2019-11-07 03:47:36,991 train 500 1.772779e-02 -0.780377
2019-11-07 03:47:46,761 train 550 1.769855e-02 -0.770428
2019-11-07 03:47:56,541 train 600 1.774155e-02 -0.767899
2019-11-07 03:48:06,322 train 650 1.777760e-02 -0.756578
2019-11-07 03:48:16,105 train 700 1.775866e-02 -0.793246
2019-11-07 03:48:25,885 train 750 1.776870e-02 -0.774189
2019-11-07 03:48:35,677 train 800 1.777789e-02 -0.810860
2019-11-07 03:48:45,460 train 850 1.775684e-02 -0.821582
2019-11-07 03:48:48,392 training loss; R2: 1.775499e-02 -0.817588
2019-11-07 03:48:49,086 valid 000 1.923907e-02 -1.108612
2019-11-07 03:48:58,443 valid 050 1.944233e-02 -0.857493
2019-11-07 03:49:06,876 validation loss; R2: 1.919929e-02 -0.996315
2019-11-07 03:49:06,943 epoch 344 lr 1.000000e-05
2019-11-07 03:49:07,714 train 000 1.954156e-02 0.004017
2019-11-07 03:49:17,451 train 050 1.779677e-02 -0.729632
2019-11-07 03:49:27,226 train 100 1.782917e-02 -0.821863
2019-11-07 03:49:37,022 train 150 1.786556e-02 -0.796516
2019-11-07 03:49:46,816 train 200 1.779751e-02 -0.771554
2019-11-07 03:49:56,612 train 250 1.780355e-02 -0.757649
2019-11-07 03:50:06,429 train 300 1.780162e-02 -2.043307
2019-11-07 03:50:16,217 train 350 1.780768e-02 -1.845210
2019-11-07 03:50:26,018 train 400 1.774070e-02 -1.699523
2019-11-07 03:50:35,813 train 450 1.780752e-02 -1.600661
2019-11-07 03:50:45,619 train 500 1.777655e-02 -1.500732
2019-11-07 03:50:55,427 train 550 1.778454e-02 -1.407842
2019-11-07 03:51:05,238 train 600 1.776822e-02 -1.346314
2019-11-07 03:51:15,072 train 650 1.774854e-02 -1.295975
2019-11-07 03:51:24,896 train 700 1.774176e-02 -1.265377
2019-11-07 03:51:34,741 train 750 1.773035e-02 -1.223173
2019-11-07 03:51:44,550 train 800 1.772046e-02 -1.192036
2019-11-07 03:51:54,333 train 850 1.773750e-02 -1.170894
2019-11-07 03:51:57,260 training loss; R2: 1.773162e-02 -1.166342
2019-11-07 03:51:57,942 valid 000 2.022064e-02 -0.965882
2019-11-07 03:52:07,311 valid 050 1.859726e-02 -1.503161
2019-11-07 03:52:15,665 validation loss; R2: 1.863339e-02 -1.337234
2019-11-07 03:52:15,730 epoch 345 lr 1.000000e-05
2019-11-07 03:52:16,513 train 000 1.748000e-02 -0.424482
2019-11-07 03:52:26,250 train 050 1.752215e-02 -0.737879
2019-11-07 03:52:36,006 train 100 1.754446e-02 -0.729145
2019-11-07 03:52:45,766 train 150 1.757427e-02 -0.753876
2019-11-07 03:52:55,528 train 200 1.758630e-02 -0.781801
2019-11-07 03:53:05,550 train 250 1.760663e-02 -0.816531
2019-11-07 03:53:15,674 train 300 1.761193e-02 -0.796293
2019-11-07 03:53:25,789 train 350 1.763489e-02 -0.793627
2019-11-07 03:53:35,916 train 400 1.760175e-02 -0.761260
2019-11-07 03:53:46,043 train 450 1.761984e-02 -0.754236
2019-11-07 03:53:56,153 train 500 1.759997e-02 -0.733664
2019-11-07 03:54:06,277 train 550 1.757321e-02 -0.730462
2019-11-07 03:54:16,417 train 600 1.762041e-02 -0.730474
2019-11-07 03:54:26,532 train 650 1.762135e-02 -0.712468
2019-11-07 03:54:36,676 train 700 1.761964e-02 -0.719788
2019-11-07 03:54:46,796 train 750 1.763659e-02 -0.720381
2019-11-07 03:54:56,919 train 800 1.764080e-02 -0.719455
2019-11-07 03:55:07,075 train 850 1.764835e-02 -0.730920
2019-11-07 03:55:10,116 training loss; R2: 1.764001e-02 -0.730363
2019-11-07 03:55:10,738 valid 000 1.665444e-02 -1.471491
2019-11-07 03:55:20,222 valid 050 1.794996e-02 -1.578858
2019-11-07 03:55:28,584 validation loss; R2: 1.804473e-02 -1.728980
2019-11-07 03:55:28,656 epoch 346 lr 1.000000e-05
2019-11-07 03:55:29,436 train 000 1.736233e-02 -0.937551
2019-11-07 03:55:39,546 train 050 1.773663e-02 -0.846003
2019-11-07 03:55:49,621 train 100 1.792295e-02 -1.205553
2019-11-07 03:55:59,389 train 150 1.778759e-02 -1.188460
2019-11-07 03:56:09,156 train 200 1.778015e-02 -1.099315
2019-11-07 03:56:18,926 train 250 1.788454e-02 -1.008945
2019-11-07 03:56:28,700 train 300 1.785689e-02 -0.937256
2019-11-07 03:56:38,466 train 350 1.787384e-02 -0.955936
2019-11-07 03:56:48,236 train 400 1.789757e-02 -0.948924
2019-11-07 03:56:58,031 train 450 1.786922e-02 -0.932614
2019-11-07 03:57:07,808 train 500 1.784611e-02 -0.911747
2019-11-07 03:57:17,582 train 550 1.783907e-02 -0.901889
2019-11-07 03:57:27,364 train 600 1.787147e-02 -0.907665
2019-11-07 03:57:37,141 train 650 1.782746e-02 -0.889269
2019-11-07 03:57:46,917 train 700 1.781046e-02 -0.967606
2019-11-07 03:57:56,698 train 750 1.781430e-02 -0.966971
2019-11-07 03:58:06,484 train 800 1.777068e-02 -0.948361
2019-11-07 03:58:16,266 train 850 1.777268e-02 -0.940888
2019-11-07 03:58:19,191 training loss; R2: 1.775835e-02 -0.942858
2019-11-07 03:58:19,831 valid 000 1.830423e-02 -0.527750
2019-11-07 03:58:29,276 valid 050 1.817624e-02 -0.982494
2019-11-07 03:58:37,648 validation loss; R2: 1.814757e-02 -0.905664
2019-11-07 03:58:37,713 epoch 347 lr 1.000000e-05
2019-11-07 03:58:38,475 train 000 1.938243e-02 -0.119638
2019-11-07 03:58:48,196 train 050 1.807997e-02 -1.047088
2019-11-07 03:58:57,942 train 100 1.770060e-02 -0.910574
2019-11-07 03:59:07,705 train 150 1.781299e-02 -0.773116
2019-11-07 03:59:17,465 train 200 1.775088e-02 -0.756608
2019-11-07 03:59:27,222 train 250 1.774497e-02 -0.747254
2019-11-07 03:59:36,980 train 300 1.775412e-02 -0.719705
2019-11-07 03:59:46,748 train 350 1.778371e-02 -0.716288
2019-11-07 03:59:56,516 train 400 1.787105e-02 -0.714975
2019-11-07 04:00:06,288 train 450 1.783815e-02 -0.730324
2019-11-07 04:00:16,063 train 500 1.786175e-02 -0.744556
2019-11-07 04:00:25,822 train 550 1.785497e-02 -0.730313
2019-11-07 04:00:35,605 train 600 1.781811e-02 -0.745225
2019-11-07 04:00:45,386 train 650 1.779898e-02 -0.769235
2019-11-07 04:00:55,153 train 700 1.778701e-02 -0.756286
2019-11-07 04:01:04,937 train 750 1.778109e-02 -0.759891
2019-11-07 04:01:14,716 train 800 1.777004e-02 -0.766036
2019-11-07 04:01:24,504 train 850 1.777146e-02 -0.762869
2019-11-07 04:01:27,430 training loss; R2: 1.776781e-02 -0.760071
2019-11-07 04:01:28,082 valid 000 2.080570e-02 -1.282186
2019-11-07 04:01:37,473 valid 050 1.786080e-02 -1.202790
2019-11-07 04:01:45,795 validation loss; R2: 1.800109e-02 -1.090752
2019-11-07 04:01:45,860 epoch 348 lr 1.000000e-05
2019-11-07 04:01:46,596 train 000 1.755008e-02 -0.907686
2019-11-07 04:01:56,324 train 050 1.766797e-02 -1.126147
2019-11-07 04:02:06,048 train 100 1.773496e-02 -0.899351
2019-11-07 04:02:15,803 train 150 1.767181e-02 -0.857440
2019-11-07 04:02:25,563 train 200 1.763849e-02 -0.820894
2019-11-07 04:02:35,323 train 250 1.752977e-02 -0.797588
2019-11-07 04:02:45,080 train 300 1.749244e-02 -0.763794
2019-11-07 04:02:54,854 train 350 1.760026e-02 -1.979583
2019-11-07 04:03:04,630 train 400 1.767389e-02 -1.813182
2019-11-07 04:03:14,415 train 450 1.767289e-02 -1.694338
2019-11-07 04:03:24,181 train 500 1.772519e-02 -1.596514
2019-11-07 04:03:34,159 train 550 1.772438e-02 -1.515441
2019-11-07 04:03:44,124 train 600 1.771893e-02 -1.468394
2019-11-07 04:03:53,893 train 650 1.772191e-02 -1.411192
2019-11-07 04:04:03,666 train 700 1.774127e-02 -1.342189
2019-11-07 04:04:13,456 train 750 1.771507e-02 -1.291594
2019-11-07 04:04:23,271 train 800 1.771913e-02 -1.263715
2019-11-07 04:04:33,067 train 850 1.770459e-02 -1.224228
2019-11-07 04:04:35,991 training loss; R2: 1.770753e-02 -1.214599
2019-11-07 04:04:36,627 valid 000 1.563134e-02 -5.155853
2019-11-07 04:04:46,099 valid 050 1.806079e-02 -0.872714
2019-11-07 04:04:54,422 validation loss; R2: 1.820842e-02 -1.024893
2019-11-07 04:04:54,487 epoch 349 lr 1.000000e-05
2019-11-07 04:04:55,261 train 000 1.969833e-02 -0.896127
2019-11-07 04:05:04,993 train 050 1.784290e-02 -0.554487
2019-11-07 04:05:14,749 train 100 1.766296e-02 -0.689173
2019-11-07 04:05:24,508 train 150 1.771747e-02 -0.659664
2019-11-07 04:05:34,261 train 200 1.780355e-02 -0.662065
2019-11-07 04:05:44,027 train 250 1.776559e-02 -0.664251
2019-11-07 04:05:53,803 train 300 1.772838e-02 -0.664982
2019-11-07 04:06:03,577 train 350 1.764250e-02 -0.668049
2019-11-07 04:06:13,357 train 400 1.761776e-02 -0.649934
2019-11-07 04:06:23,144 train 450 1.765505e-02 -0.641774
2019-11-07 04:06:32,920 train 500 1.766343e-02 -0.680128
2019-11-07 04:06:42,701 train 550 1.770767e-02 -0.720915
2019-11-07 04:06:52,499 train 600 1.772037e-02 -0.728128
2019-11-07 04:07:02,265 train 650 1.770114e-02 -0.708614
2019-11-07 04:07:12,043 train 700 1.769029e-02 -0.710247
2019-11-07 04:07:21,843 train 750 1.770990e-02 -0.699477
2019-11-07 04:07:31,639 train 800 1.771452e-02 -0.711342
2019-11-07 04:07:41,435 train 850 1.772872e-02 -0.704503
2019-11-07 04:07:44,360 training loss; R2: 1.772840e-02 -0.703750
2019-11-07 04:07:44,984 valid 000 1.863965e-02 -0.128050
2019-11-07 04:07:54,421 valid 050 1.815438e-02 -1.187602
2019-11-07 04:08:02,817 validation loss; R2: 1.820750e-02 -1.178474
2019-11-07 04:08:02,883 epoch 350 lr 1.000000e-05
2019-11-07 04:08:03,645 train 000 1.485182e-02 -0.369341
2019-11-07 04:08:13,394 train 050 1.747976e-02 -0.559195
2019-11-07 04:08:23,162 train 100 1.751403e-02 -0.628553
2019-11-07 04:08:32,921 train 150 1.760101e-02 -0.625381
2019-11-07 04:08:42,697 train 200 1.757250e-02 -0.603270
2019-11-07 04:08:52,485 train 250 1.761684e-02 -0.642043
2019-11-07 04:09:02,257 train 300 1.764574e-02 -0.989798
2019-11-07 04:09:12,031 train 350 1.762440e-02 -0.953594
2019-11-07 04:09:21,818 train 400 1.763344e-02 -0.914863
2019-11-07 04:09:31,583 train 450 1.763508e-02 -0.938884
2019-11-07 04:09:41,361 train 500 1.766033e-02 -0.913626
2019-11-07 04:09:51,156 train 550 1.766935e-02 -0.896105
2019-11-07 04:10:00,952 train 600 1.770279e-02 -0.865080
2019-11-07 04:10:10,756 train 650 1.768327e-02 -0.856523
2019-11-07 04:10:20,553 train 700 1.768171e-02 -0.834727
2019-11-07 04:10:30,355 train 750 1.767575e-02 -0.821326
2019-11-07 04:10:40,151 train 800 1.769737e-02 -0.821646
2019-11-07 04:10:49,951 train 850 1.770454e-02 -0.818387
2019-11-07 04:10:52,884 training loss; R2: 1.769765e-02 -0.815238
2019-11-07 04:10:53,505 valid 000 1.974485e-02 -1.373908
2019-11-07 04:11:02,952 valid 050 1.896576e-02 -1.604205
2019-11-07 04:11:11,262 validation loss; R2: 1.901301e-02 -1.332825
2019-11-07 04:11:11,332 epoch 351 lr 1.000000e-05
2019-11-07 04:11:12,127 train 000 1.788853e-02 -0.675408
2019-11-07 04:11:22,238 train 050 1.759624e-02 -0.757519
2019-11-07 04:11:32,365 train 100 1.780877e-02 -0.792388
2019-11-07 04:11:42,496 train 150 1.780919e-02 -0.765552
2019-11-07 04:11:52,610 train 200 1.775283e-02 -0.695861
2019-11-07 04:12:02,728 train 250 1.782114e-02 -0.697497
2019-11-07 04:12:12,831 train 300 1.776510e-02 -0.705331
2019-11-07 04:12:22,949 train 350 1.776940e-02 -0.697600
2019-11-07 04:12:33,076 train 400 1.776120e-02 -0.664445
2019-11-07 04:12:43,180 train 450 1.775772e-02 -0.649707
2019-11-07 04:12:53,306 train 500 1.771724e-02 -0.681545
2019-11-07 04:13:03,440 train 550 1.771817e-02 -0.673863
2019-11-07 04:13:13,561 train 600 1.773010e-02 -0.658770
2019-11-07 04:13:23,706 train 650 1.771376e-02 -0.662179
2019-11-07 04:13:33,857 train 700 1.771097e-02 -0.665285
2019-11-07 04:13:44,006 train 750 1.770052e-02 -0.663713
2019-11-07 04:13:54,157 train 800 1.770405e-02 -0.663425
2019-11-07 04:14:04,301 train 850 1.771500e-02 -0.669744
2019-11-07 04:14:07,341 training loss; R2: 1.772312e-02 -0.674439
2019-11-07 04:14:08,011 valid 000 1.700241e-02 -0.581451
2019-11-07 04:14:17,434 valid 050 1.874723e-02 -1.167547
2019-11-07 04:14:25,766 validation loss; R2: 1.898415e-02 -1.026692
2019-11-07 04:14:25,853 epoch 352 lr 1.000000e-05
2019-11-07 04:14:26,653 train 000 1.555704e-02 -0.168353
2019-11-07 04:14:36,605 train 050 1.731089e-02 -0.627789
2019-11-07 04:14:46,754 train 100 1.749143e-02 -0.789356
2019-11-07 04:14:56,894 train 150 1.744378e-02 -0.744527
2019-11-07 04:15:07,042 train 200 1.755121e-02 -0.734973
2019-11-07 04:15:17,169 train 250 1.751845e-02 -0.682232
2019-11-07 04:15:27,319 train 300 1.763335e-02 -0.720117
2019-11-07 04:15:37,455 train 350 1.765011e-02 -0.689079
2019-11-07 04:15:47,587 train 400 1.764393e-02 -0.762002
2019-11-07 04:15:57,710 train 450 1.763606e-02 -0.755488
2019-11-07 04:16:07,840 train 500 1.761316e-02 -0.722371
2019-11-07 04:16:17,987 train 550 1.758483e-02 -0.734576
2019-11-07 04:16:28,135 train 600 1.757829e-02 -0.715216
2019-11-07 04:16:38,290 train 650 1.759937e-02 -0.703909
2019-11-07 04:16:48,461 train 700 1.761951e-02 -0.699310
2019-11-07 04:16:58,620 train 750 1.761404e-02 -0.700261
2019-11-07 04:17:08,782 train 800 1.761943e-02 -0.708820
2019-11-07 04:17:18,943 train 850 1.763476e-02 -0.710055
2019-11-07 04:17:21,974 training loss; R2: 1.763983e-02 -0.710079
2019-11-07 04:17:22,678 valid 000 1.679248e-02 -0.511680
2019-11-07 04:17:32,071 valid 050 1.786068e-02 -1.223392
2019-11-07 04:17:40,542 validation loss; R2: 1.788849e-02 -1.465865
2019-11-07 04:17:40,610 epoch 353 lr 1.000000e-05
2019-11-07 04:17:41,391 train 000 1.631780e-02 0.022045
2019-11-07 04:17:51,481 train 050 1.709432e-02 -0.662391
2019-11-07 04:18:01,333 train 100 1.722454e-02 -0.744707
2019-11-07 04:18:11,117 train 150 1.733686e-02 -0.725149
2019-11-07 04:18:20,912 train 200 1.734577e-02 -0.710497
2019-11-07 04:18:30,704 train 250 1.741436e-02 -0.717195
2019-11-07 04:18:40,492 train 300 1.746094e-02 -0.705207
2019-11-07 04:18:50,286 train 350 1.750918e-02 -0.693621
2019-11-07 04:19:00,087 train 400 1.752051e-02 -0.719381
2019-11-07 04:19:09,895 train 450 1.755072e-02 -0.754988
2019-11-07 04:19:19,715 train 500 1.757130e-02 -0.774190
2019-11-07 04:19:29,569 train 550 1.761554e-02 -0.757161
2019-11-07 04:19:39,385 train 600 1.765630e-02 -0.759436
2019-11-07 04:19:49,215 train 650 1.767731e-02 -0.736666
2019-11-07 04:19:59,037 train 700 1.768062e-02 -0.718228
2019-11-07 04:20:08,865 train 750 1.768049e-02 -0.968731
2019-11-07 04:20:18,684 train 800 1.768405e-02 -0.955005
2019-11-07 04:20:28,525 train 850 1.767135e-02 -0.966122
2019-11-07 04:20:31,474 training loss; R2: 1.766936e-02 -0.962863
2019-11-07 04:20:32,194 valid 000 1.670607e-02 -0.512853
2019-11-07 04:20:41,580 valid 050 1.873038e-02 -1.297592
2019-11-07 04:20:49,925 validation loss; R2: 1.866914e-02 -1.205664
2019-11-07 04:20:49,991 epoch 354 lr 1.000000e-05
2019-11-07 04:20:50,780 train 000 1.444276e-02 -0.378028
2019-11-07 04:21:00,560 train 050 1.757005e-02 -0.929333
2019-11-07 04:21:10,350 train 100 1.732428e-02 -236.022496
2019-11-07 04:21:20,138 train 150 1.737321e-02 -158.103261
2019-11-07 04:21:29,938 train 200 1.744624e-02 -118.971831
2019-11-07 04:21:39,740 train 250 1.746131e-02 -95.422784
2019-11-07 04:21:49,535 train 300 1.750032e-02 -79.651610
2019-11-07 04:21:59,368 train 350 1.755520e-02 -68.434023
2019-11-07 04:22:09,185 train 400 1.757597e-02 -59.973215
2019-11-07 04:22:19,005 train 450 1.761645e-02 -53.415571
2019-11-07 04:22:28,821 train 500 1.762983e-02 -48.149192
2019-11-07 04:22:38,652 train 550 1.763846e-02 -43.834430
2019-11-07 04:22:48,476 train 600 1.761426e-02 -40.252109
2019-11-07 04:22:58,301 train 650 1.761658e-02 -37.198305
2019-11-07 04:23:08,484 train 700 1.762501e-02 -34.598861
2019-11-07 04:23:18,661 train 750 1.763905e-02 -32.375855
2019-11-07 04:23:28,846 train 800 1.762881e-02 -30.387658
2019-11-07 04:23:38,708 train 850 1.764278e-02 -28.648071
2019-11-07 04:23:41,630 training loss; R2: 1.765385e-02 -28.163113
2019-11-07 04:23:42,320 valid 000 1.510800e-02 -0.554480
2019-11-07 04:23:51,693 valid 050 1.848201e-02 -1.281371
2019-11-07 04:24:00,022 validation loss; R2: 1.867984e-02 -1.107960
2019-11-07 04:24:00,088 epoch 355 lr 1.000000e-05
2019-11-07 04:24:00,816 train 000 1.734261e-02 -0.853594
2019-11-07 04:24:10,549 train 050 1.796073e-02 -0.621659
2019-11-07 04:24:20,275 train 100 1.768174e-02 -0.760726
2019-11-07 04:24:30,003 train 150 1.772341e-02 -0.728580
2019-11-07 04:24:39,712 train 200 1.770930e-02 -0.809082
2019-11-07 04:24:49,436 train 250 1.769007e-02 -0.769634
2019-11-07 04:24:59,151 train 300 1.765839e-02 -0.757559
2019-11-07 04:25:08,903 train 350 1.766963e-02 -0.722579
2019-11-07 04:25:18,648 train 400 1.770042e-02 -0.747487
2019-11-07 04:25:28,397 train 450 1.773549e-02 -0.742173
2019-11-07 04:25:38,140 train 500 1.769062e-02 -0.734770
2019-11-07 04:25:47,886 train 550 1.768870e-02 -0.720409
2019-11-07 04:25:57,634 train 600 1.765451e-02 -0.730598
2019-11-07 04:26:07,379 train 650 1.764480e-02 -0.736779
2019-11-07 04:26:17,123 train 700 1.764499e-02 -0.741532
2019-11-07 04:26:26,872 train 750 1.762722e-02 -0.724620
2019-11-07 04:26:36,622 train 800 1.760294e-02 -0.722732
2019-11-07 04:26:46,384 train 850 1.760290e-02 -0.731304
2019-11-07 04:26:49,295 training loss; R2: 1.760085e-02 -0.729903
2019-11-07 04:26:49,928 valid 000 1.962523e-02 -0.353492
2019-11-07 04:26:59,350 valid 050 1.886058e-02 -1.392237
2019-11-07 04:27:07,662 validation loss; R2: 1.895543e-02 -1.215593
2019-11-07 04:27:07,728 epoch 356 lr 1.000000e-05
2019-11-07 04:27:08,466 train 000 1.669179e-02 -0.713215
2019-11-07 04:27:18,179 train 050 1.720014e-02 -0.783506
2019-11-07 04:27:27,871 train 100 1.750211e-02 -0.633644
2019-11-07 04:27:37,601 train 150 1.752572e-02 -0.650738
2019-11-07 04:27:47,324 train 200 1.762428e-02 -0.629424
2019-11-07 04:27:57,066 train 250 1.762780e-02 -0.618066
2019-11-07 04:28:06,832 train 300 1.762685e-02 -0.609993
2019-11-07 04:28:16,618 train 350 1.759672e-02 -0.604522
2019-11-07 04:28:26,412 train 400 1.757845e-02 -0.607823
2019-11-07 04:28:36,197 train 450 1.755722e-02 -0.651163
2019-11-07 04:28:45,979 train 500 1.755694e-02 -0.662745
2019-11-07 04:28:55,796 train 550 1.760200e-02 -0.679148
2019-11-07 04:29:05,595 train 600 1.760057e-02 -0.764137
2019-11-07 04:29:15,393 train 650 1.763589e-02 -0.773778
2019-11-07 04:29:25,186 train 700 1.761245e-02 -0.770750
2019-11-07 04:29:34,980 train 750 1.758631e-02 -0.806846
2019-11-07 04:29:44,772 train 800 1.759765e-02 -0.796174
2019-11-07 04:29:54,558 train 850 1.759336e-02 -0.791530
2019-11-07 04:29:57,485 training loss; R2: 1.760261e-02 -0.791802
2019-11-07 04:29:58,120 valid 000 1.917597e-02 -8.572704
2019-11-07 04:30:07,534 valid 050 1.807133e-02 -1.309670
2019-11-07 04:30:15,854 validation loss; R2: 1.806472e-02 -1.201175
2019-11-07 04:30:15,919 epoch 357 lr 1.000000e-05
2019-11-07 04:30:16,701 train 000 1.830362e-02 -1.132939
2019-11-07 04:30:26,420 train 050 1.746381e-02 -0.600584
2019-11-07 04:30:36,146 train 100 1.748696e-02 -0.696377
2019-11-07 04:30:45,906 train 150 1.761589e-02 -0.678926
2019-11-07 04:30:55,665 train 200 1.761794e-02 -0.669364
2019-11-07 04:31:05,431 train 250 1.755247e-02 -0.611438
2019-11-07 04:31:15,200 train 300 1.757665e-02 -4.776749
2019-11-07 04:31:24,984 train 350 1.762270e-02 -4.191739
2019-11-07 04:31:34,773 train 400 1.761210e-02 -3.977725
2019-11-07 04:31:44,549 train 450 1.762443e-02 -3.626559
2019-11-07 04:31:54,329 train 500 1.764342e-02 -3.338052
2019-11-07 04:32:04,114 train 550 1.763193e-02 -3.094889
2019-11-07 04:32:13,908 train 600 1.766110e-02 -2.890496
2019-11-07 04:32:23,698 train 650 1.764619e-02 -2.719000
2019-11-07 04:32:33,481 train 700 1.761328e-02 -2.570545
2019-11-07 04:32:43,269 train 750 1.761443e-02 -2.436955
2019-11-07 04:32:53,054 train 800 1.762062e-02 -2.387597
2019-11-07 04:33:02,863 train 850 1.761506e-02 -2.297939
2019-11-07 04:33:05,793 training loss; R2: 1.761952e-02 -2.281384
2019-11-07 04:33:06,446 valid 000 2.062766e-02 -0.009325
2019-11-07 04:33:15,894 valid 050 1.864950e-02 -5.164308
2019-11-07 04:33:24,252 validation loss; R2: 1.834464e-02 -3.181899
2019-11-07 04:33:24,319 epoch 358 lr 1.000000e-05
2019-11-07 04:33:25,090 train 000 1.947388e-02 -0.134918
2019-11-07 04:33:34,825 train 050 1.797260e-02 -0.548483
2019-11-07 04:33:44,586 train 100 1.793269e-02 -0.546270
2019-11-07 04:33:54,339 train 150 1.772311e-02 -0.580300
2019-11-07 04:34:04,077 train 200 1.768615e-02 -0.616882
2019-11-07 04:34:13,843 train 250 1.761500e-02 -0.628622
2019-11-07 04:34:23,591 train 300 1.756936e-02 -0.672745
2019-11-07 04:34:33,339 train 350 1.758337e-02 -0.674894
2019-11-07 04:34:43,105 train 400 1.756097e-02 -0.675828
2019-11-07 04:34:52,887 train 450 1.755228e-02 -0.669843
2019-11-07 04:35:02,663 train 500 1.754011e-02 -0.664433
2019-11-07 04:35:12,435 train 550 1.761180e-02 -0.707283
2019-11-07 04:35:22,516 train 600 1.762063e-02 -0.739593
2019-11-07 04:35:32,657 train 650 1.763469e-02 -0.727510
2019-11-07 04:35:42,808 train 700 1.764658e-02 -0.731751
2019-11-07 04:35:52,984 train 750 1.765054e-02 -0.737830
2019-11-07 04:36:03,135 train 800 1.766396e-02 -0.925732
2019-11-07 04:36:13,291 train 850 1.764657e-02 -0.917697
2019-11-07 04:36:16,329 training loss; R2: 1.766058e-02 -0.909872
2019-11-07 04:36:17,017 valid 000 1.619628e-02 -0.222020
2019-11-07 04:36:26,381 valid 050 1.811252e-02 -1.226336
2019-11-07 04:36:34,706 validation loss; R2: 1.822510e-02 -0.986035
2019-11-07 04:36:34,775 epoch 359 lr 1.000000e-05
2019-11-07 04:36:35,596 train 000 1.687990e-02 -0.118067
2019-11-07 04:36:45,705 train 050 1.791300e-02 -0.653291
2019-11-07 04:36:55,809 train 100 1.780313e-02 -0.743246
2019-11-07 04:37:05,934 train 150 1.774496e-02 -0.800818
2019-11-07 04:37:16,064 train 200 1.764059e-02 -0.727476
2019-11-07 04:37:26,184 train 250 1.763397e-02 -0.780881
2019-11-07 04:37:36,307 train 300 1.758763e-02 -0.767390
2019-11-07 04:37:46,423 train 350 1.756850e-02 -0.792605
2019-11-07 04:37:56,543 train 400 1.760221e-02 -0.813214
2019-11-07 04:38:06,669 train 450 1.763508e-02 -0.797483
2019-11-07 04:38:16,788 train 500 1.762183e-02 -0.788363
2019-11-07 04:38:26,928 train 550 1.764198e-02 -0.783006
2019-11-07 04:38:37,074 train 600 1.763874e-02 -0.768114
2019-11-07 04:38:47,232 train 650 1.763122e-02 -0.760006
2019-11-07 04:38:57,375 train 700 1.763940e-02 -0.782154
2019-11-07 04:39:07,515 train 750 1.762814e-02 -0.771310
2019-11-07 04:39:17,656 train 800 1.762561e-02 -0.780229
2019-11-07 04:39:27,775 train 850 1.763577e-02 -0.779986
2019-11-07 04:39:30,804 training loss; R2: 1.762334e-02 -0.776108
2019-11-07 04:39:31,500 valid 000 1.638023e-02 0.014335
2019-11-07 04:39:40,880 valid 050 1.819387e-02 -1.169762
2019-11-07 04:39:49,236 validation loss; R2: 1.826998e-02 -1.123898
2019-11-07 04:39:49,303 epoch 360 lr 1.000000e-05
2019-11-07 04:39:50,058 train 000 1.688148e-02 -1.162163
2019-11-07 04:40:00,107 train 050 1.770021e-02 -0.778329
2019-11-07 04:40:09,889 train 100 1.761516e-02 -0.841807
2019-11-07 04:40:19,667 train 150 1.754756e-02 -0.807072
2019-11-07 04:40:29,457 train 200 1.751080e-02 -0.741264
2019-11-07 04:40:39,238 train 250 1.761677e-02 -0.753134
2019-11-07 04:40:49,044 train 300 1.767783e-02 -0.746908
2019-11-07 04:40:58,841 train 350 1.771555e-02 -0.740048
2019-11-07 04:41:08,662 train 400 1.768043e-02 -0.731554
2019-11-07 04:41:18,486 train 450 1.773142e-02 -0.716027
2019-11-07 04:41:28,297 train 500 1.773519e-02 -0.695886
2019-11-07 04:41:38,118 train 550 1.768414e-02 -0.725491
2019-11-07 04:41:47,930 train 600 1.765294e-02 -0.732693
2019-11-07 04:41:57,741 train 650 1.762506e-02 -0.739308
2019-11-07 04:42:07,548 train 700 1.764301e-02 -0.735862
2019-11-07 04:42:17,351 train 750 1.763995e-02 -0.717874
2019-11-07 04:42:27,167 train 800 1.766938e-02 -0.709289
2019-11-07 04:42:36,978 train 850 1.768691e-02 -0.726963
2019-11-07 04:42:39,906 training loss; R2: 1.767776e-02 -0.723528
2019-11-07 04:42:40,563 valid 000 1.802526e-02 -0.372644
2019-11-07 04:42:49,977 valid 050 1.873212e-02 -1.295561
2019-11-07 04:42:58,285 validation loss; R2: 1.885637e-02 -1.279556
2019-11-07 04:42:58,361 epoch 361 lr 1.000000e-05
2019-11-07 04:42:59,134 train 000 1.960839e-02 -0.627179
2019-11-07 04:43:08,881 train 050 1.739958e-02 -0.674762
2019-11-07 04:43:18,651 train 100 1.757589e-02 -0.763103
2019-11-07 04:43:28,429 train 150 1.749430e-02 -0.677972
2019-11-07 04:43:38,214 train 200 1.761774e-02 -0.702369
2019-11-07 04:43:48,010 train 250 1.760225e-02 -1.826022
2019-11-07 04:43:57,801 train 300 1.760073e-02 -1.608303
2019-11-07 04:44:07,615 train 350 1.764708e-02 -1.465516
2019-11-07 04:44:17,432 train 400 1.765115e-02 -1.340464
2019-11-07 04:44:27,237 train 450 1.763524e-02 -1.268736
2019-11-07 04:44:37,035 train 500 1.760707e-02 -1.207104
2019-11-07 04:44:46,833 train 550 1.762165e-02 -42.440846
2019-11-07 04:44:56,621 train 600 1.762288e-02 -38.957477
2019-11-07 04:45:06,434 train 650 1.763136e-02 -36.077142
2019-11-07 04:45:16,245 train 700 1.761160e-02 -33.553101
2019-11-07 04:45:26,041 train 750 1.763059e-02 -31.353283
2019-11-07 04:45:35,844 train 800 1.763832e-02 -29.485585
2019-11-07 04:45:45,633 train 850 1.762651e-02 -27.789244
2019-11-07 04:45:48,559 training loss; R2: 1.761218e-02 -27.325025
2019-11-07 04:45:49,221 valid 000 1.828402e-02 -1.206790
2019-11-07 04:45:58,648 valid 050 1.794148e-02 -1.429162
2019-11-07 04:46:07,083 validation loss; R2: 1.795627e-02 -1.373766
2019-11-07 04:46:07,151 epoch 362 lr 1.000000e-05
2019-11-07 04:46:07,956 train 000 1.523617e-02 0.062769
2019-11-07 04:46:17,693 train 050 1.728538e-02 -0.683652
2019-11-07 04:46:27,432 train 100 1.754810e-02 -0.923788
2019-11-07 04:46:37,189 train 150 1.752430e-02 -0.991447
2019-11-07 04:46:46,947 train 200 1.751214e-02 -0.945913
2019-11-07 04:46:56,703 train 250 1.756013e-02 -0.903091
2019-11-07 04:47:06,481 train 300 1.753619e-02 -0.830990
2019-11-07 04:47:16,279 train 350 1.761036e-02 -0.822558
2019-11-07 04:47:26,066 train 400 1.763061e-02 -0.806931
2019-11-07 04:47:35,845 train 450 1.769607e-02 -0.794313
2019-11-07 04:47:45,627 train 500 1.766820e-02 -0.779566
2019-11-07 04:47:55,431 train 550 1.770259e-02 -0.766490
2019-11-07 04:48:05,233 train 600 1.769926e-02 -0.754905
2019-11-07 04:48:15,031 train 650 1.769952e-02 -0.745702
2019-11-07 04:48:24,817 train 700 1.768185e-02 -0.745172
2019-11-07 04:48:34,620 train 750 1.769369e-02 -0.766494
2019-11-07 04:48:44,417 train 800 1.766956e-02 -0.780532
2019-11-07 04:48:54,216 train 850 1.767391e-02 -0.765978
2019-11-07 04:48:57,149 training loss; R2: 1.767230e-02 -0.764367
2019-11-07 04:48:57,760 valid 000 1.945360e-02 -0.002266
2019-11-07 04:49:07,166 valid 050 1.815584e-02 -0.910537
2019-11-07 04:49:15,524 validation loss; R2: 1.811263e-02 -0.983797
2019-11-07 04:49:15,591 epoch 363 lr 1.000000e-05
2019-11-07 04:49:16,366 train 000 1.770133e-02 -0.292151
2019-11-07 04:49:26,119 train 050 1.784244e-02 -0.503494
2019-11-07 04:49:35,880 train 100 1.757940e-02 -0.667609
2019-11-07 04:49:45,667 train 150 1.751083e-02 -0.867875
2019-11-07 04:49:55,458 train 200 1.753595e-02 -0.918850
2019-11-07 04:50:05,254 train 250 1.753423e-02 -0.877049
2019-11-07 04:50:15,043 train 300 1.755903e-02 -0.813037
2019-11-07 04:50:24,833 train 350 1.755034e-02 -0.759552
2019-11-07 04:50:34,623 train 400 1.754259e-02 -0.728494
2019-11-07 04:50:44,429 train 450 1.754787e-02 -0.717343
2019-11-07 04:50:54,230 train 500 1.756059e-02 -0.720163
2019-11-07 04:51:04,033 train 550 1.761091e-02 -0.711519
2019-11-07 04:51:13,827 train 600 1.759480e-02 -0.710254
2019-11-07 04:51:23,641 train 650 1.758720e-02 -0.708325
2019-11-07 04:51:33,434 train 700 1.755914e-02 -1.570305
2019-11-07 04:51:43,232 train 750 1.758089e-02 -1.528717
2019-11-07 04:51:53,027 train 800 1.755769e-02 -1.476200
2019-11-07 04:52:02,826 train 850 1.755641e-02 -1.435358
2019-11-07 04:52:05,756 training loss; R2: 1.756334e-02 -1.428111
2019-11-07 04:52:06,449 valid 000 1.587646e-02 -9.248670
2019-11-07 04:52:15,828 valid 050 1.836186e-02 -1.006023
2019-11-07 04:52:24,302 validation loss; R2: 1.838968e-02 -0.954561
2019-11-07 04:52:24,368 epoch 364 lr 1.000000e-05
2019-11-07 04:52:25,177 train 000 1.555857e-02 -0.135493
2019-11-07 04:52:34,901 train 050 1.794166e-02 -0.958506
2019-11-07 04:52:44,648 train 100 1.779879e-02 -0.943505
2019-11-07 04:52:54,413 train 150 1.776975e-02 -0.836623
2019-11-07 04:53:04,181 train 200 1.763658e-02 -0.789485
2019-11-07 04:53:13,967 train 250 1.763243e-02 -0.758561
2019-11-07 04:53:23,771 train 300 1.763204e-02 -0.756646
2019-11-07 04:53:33,870 train 350 1.767007e-02 -0.735193
2019-11-07 04:53:44,026 train 400 1.764096e-02 -0.717545
2019-11-07 04:53:54,195 train 450 1.760632e-02 -0.704674
2019-11-07 04:54:04,350 train 500 1.759872e-02 -0.688557
2019-11-07 04:54:14,532 train 550 1.758808e-02 -0.700389
2019-11-07 04:54:24,706 train 600 1.761297e-02 -0.686038
2019-11-07 04:54:34,883 train 650 1.763156e-02 -0.689467
2019-11-07 04:54:45,034 train 700 1.764988e-02 -0.699181
2019-11-07 04:54:55,188 train 750 1.764765e-02 -0.695894
2019-11-07 04:55:05,351 train 800 1.763992e-02 -0.703037
2019-11-07 04:55:15,505 train 850 1.761792e-02 -0.712020
2019-11-07 04:55:18,534 training loss; R2: 1.760334e-02 -0.713633
2019-11-07 04:55:19,230 valid 000 2.030608e-02 -1.364950
2019-11-07 04:55:28,599 valid 050 1.782703e-02 -1.349706
2019-11-07 04:55:36,926 validation loss; R2: 1.781876e-02 -1.250908
2019-11-07 04:55:36,993 epoch 365 lr 1.000000e-05
2019-11-07 04:55:37,797 train 000 1.800089e-02 -0.600879
2019-11-07 04:55:47,892 train 050 1.799167e-02 -0.568914
2019-11-07 04:55:58,000 train 100 1.774985e-02 -0.683633
2019-11-07 04:56:08,149 train 150 1.765334e-02 -0.681124
2019-11-07 04:56:18,291 train 200 1.778088e-02 -0.684070
2019-11-07 04:56:28,435 train 250 1.780510e-02 -0.668677
2019-11-07 04:56:38,580 train 300 1.777770e-02 -0.720501
2019-11-07 04:56:48,746 train 350 1.778933e-02 -0.712263
2019-11-07 04:56:58,920 train 400 1.775073e-02 -0.729676
2019-11-07 04:57:09,078 train 450 1.771027e-02 -0.746596
2019-11-07 04:57:19,246 train 500 1.771401e-02 -0.731412
2019-11-07 04:57:29,405 train 550 1.769257e-02 -0.712091
2019-11-07 04:57:39,569 train 600 1.766184e-02 -0.699893
2019-11-07 04:57:49,748 train 650 1.764407e-02 -0.717799
2019-11-07 04:57:59,912 train 700 1.765103e-02 -0.719162
2019-11-07 04:58:10,085 train 750 1.763792e-02 -0.731866
2019-11-07 04:58:20,031 train 800 1.763436e-02 -0.737911
2019-11-07 04:58:29,769 train 850 1.760445e-02 -0.734740
2019-11-07 04:58:32,684 training loss; R2: 1.759708e-02 -0.743153
2019-11-07 04:58:33,385 valid 000 2.128798e-02 -1.242476
2019-11-07 04:58:42,740 valid 050 1.761388e-02 -1.021625
2019-11-07 04:58:51,088 validation loss; R2: 1.771594e-02 -1.265070
2019-11-07 04:58:51,154 epoch 366 lr 1.000000e-05
2019-11-07 04:58:51,937 train 000 1.651475e-02 0.048451
2019-11-07 04:59:01,657 train 050 1.713671e-02 -0.554356
2019-11-07 04:59:11,394 train 100 1.738659e-02 -0.502314
2019-11-07 04:59:21,156 train 150 1.742362e-02 -0.513511
2019-11-07 04:59:30,901 train 200 1.745562e-02 -0.523314
2019-11-07 04:59:40,662 train 250 1.752268e-02 -0.555060
2019-11-07 04:59:50,451 train 300 1.760500e-02 -0.609954
2019-11-07 05:00:00,234 train 350 1.759954e-02 -0.637845
2019-11-07 05:00:10,002 train 400 1.759842e-02 -0.624601
2019-11-07 05:00:19,781 train 450 1.761366e-02 -0.682039
2019-11-07 05:00:29,560 train 500 1.763167e-02 -0.683105
2019-11-07 05:00:39,344 train 550 1.765040e-02 -0.704249
2019-11-07 05:00:49,124 train 600 1.762977e-02 -0.703763
2019-11-07 05:00:58,895 train 650 1.764619e-02 -0.782956
2019-11-07 05:01:08,671 train 700 1.766772e-02 -0.783177
2019-11-07 05:01:18,452 train 750 1.767278e-02 -0.799190
2019-11-07 05:01:28,234 train 800 1.766808e-02 -0.810686
2019-11-07 05:01:38,011 train 850 1.767933e-02 -0.810392
2019-11-07 05:01:40,933 training loss; R2: 1.767091e-02 -0.808207
2019-11-07 05:01:41,640 valid 000 1.846108e-02 -0.949222
2019-11-07 05:01:51,052 valid 050 1.821531e-02 -0.776146
2019-11-07 05:01:59,389 validation loss; R2: 1.848122e-02 -1.000696
2019-11-07 05:01:59,453 epoch 367 lr 1.000000e-05
2019-11-07 05:02:00,186 train 000 1.896893e-02 -0.606069
2019-11-07 05:02:09,918 train 050 1.780263e-02 -0.843503
2019-11-07 05:02:19,638 train 100 1.791348e-02 -0.752731
2019-11-07 05:02:29,379 train 150 1.795385e-02 -0.708102
2019-11-07 05:02:39,135 train 200 1.789481e-02 -0.668237
2019-11-07 05:02:48,898 train 250 1.782826e-02 -0.802403
2019-11-07 05:02:58,675 train 300 1.773001e-02 -0.782301
2019-11-07 05:03:08,445 train 350 1.773152e-02 -0.792221
2019-11-07 05:03:18,211 train 400 1.765964e-02 -0.772458
2019-11-07 05:03:27,981 train 450 1.762236e-02 -0.766213
2019-11-07 05:03:37,772 train 500 1.764081e-02 -0.751247
2019-11-07 05:03:47,540 train 550 1.762455e-02 -0.751067
2019-11-07 05:03:57,314 train 600 1.760713e-02 -0.761587
2019-11-07 05:04:07,087 train 650 1.766129e-02 -0.803952
2019-11-07 05:04:16,882 train 700 1.769561e-02 -0.806188
2019-11-07 05:04:27,029 train 750 1.767629e-02 -0.801791
2019-11-07 05:04:37,185 train 800 1.769672e-02 -0.779344
2019-11-07 05:04:47,242 train 850 1.770801e-02 -0.780189
2019-11-07 05:04:50,165 training loss; R2: 1.772299e-02 -0.774914
2019-11-07 05:04:50,758 valid 000 1.979580e-02 -0.973238
2019-11-07 05:05:00,183 valid 050 1.811715e-02 -0.908441
2019-11-07 05:05:08,510 validation loss; R2: 1.792581e-02 -0.960153
2019-11-07 05:05:08,575 epoch 368 lr 1.000000e-05
2019-11-07 05:05:09,336 train 000 1.822739e-02 -1.389472
2019-11-07 05:05:19,053 train 050 1.760434e-02 -0.498510
2019-11-07 05:05:28,808 train 100 1.743885e-02 -0.660252
2019-11-07 05:05:38,608 train 150 1.753011e-02 -0.723292
2019-11-07 05:05:48,403 train 200 1.759240e-02 -0.693269
2019-11-07 05:05:58,215 train 250 1.754364e-02 -0.656484
2019-11-07 05:06:08,030 train 300 1.755540e-02 -0.669877
2019-11-07 05:06:17,834 train 350 1.758879e-02 -0.636536
2019-11-07 05:06:27,648 train 400 1.757165e-02 -0.636740
2019-11-07 05:06:37,453 train 450 1.753905e-02 -0.658264
2019-11-07 05:06:47,269 train 500 1.758035e-02 -0.657492
2019-11-07 05:06:57,078 train 550 1.754602e-02 -0.658812
2019-11-07 05:07:06,876 train 600 1.759101e-02 -0.648496
2019-11-07 05:07:16,672 train 650 1.764144e-02 -0.652922
2019-11-07 05:07:26,460 train 700 1.762563e-02 -0.660551
2019-11-07 05:07:36,246 train 750 1.761614e-02 -0.651165
2019-11-07 05:07:46,035 train 800 1.761790e-02 -0.668566
2019-11-07 05:07:55,809 train 850 1.760843e-02 -0.711114
2019-11-07 05:07:58,759 training loss; R2: 1.762318e-02 -0.707434
2019-11-07 05:07:59,405 valid 000 1.493569e-02 -1.602002
2019-11-07 05:08:08,794 valid 050 1.744696e-02 -1.579526
2019-11-07 05:08:17,150 validation loss; R2: 1.765802e-02 -1.315849
2019-11-07 05:08:17,229 epoch 369 lr 1.000000e-05
2019-11-07 05:08:18,001 train 000 1.748591e-02 -0.098939
2019-11-07 05:08:28,136 train 050 1.750440e-02 -0.678672
2019-11-07 05:08:38,272 train 100 1.777193e-02 -0.653268
2019-11-07 05:08:48,422 train 150 1.768974e-02 -0.707990
2019-11-07 05:08:58,568 train 200 1.767881e-02 -0.722223
2019-11-07 05:09:08,729 train 250 1.767031e-02 -0.748806
2019-11-07 05:09:18,861 train 300 1.771285e-02 -0.735862
2019-11-07 05:09:28,677 train 350 1.768555e-02 -0.718813
2019-11-07 05:09:38,493 train 400 1.765946e-02 -0.724543
2019-11-07 05:09:48,308 train 450 1.760515e-02 -0.741303
2019-11-07 05:09:58,112 train 500 1.757912e-02 -0.734485
2019-11-07 05:10:07,939 train 550 1.761852e-02 -0.720169
2019-11-07 05:10:17,738 train 600 1.762372e-02 -0.723199
2019-11-07 05:10:27,562 train 650 1.764573e-02 -0.715122
2019-11-07 05:10:37,368 train 700 1.763951e-02 -0.714617
2019-11-07 05:10:47,162 train 750 1.762037e-02 -0.698848
2019-11-07 05:10:56,958 train 800 1.759624e-02 -0.699823
2019-11-07 05:11:06,759 train 850 1.761527e-02 -0.718664
2019-11-07 05:11:09,688 training loss; R2: 1.761128e-02 -0.717441
2019-11-07 05:11:10,378 valid 000 2.156121e-02 -0.474377
2019-11-07 05:11:19,786 valid 050 1.833806e-02 -1.104376
2019-11-07 05:11:28,112 validation loss; R2: 1.850498e-02 -0.967936
2019-11-07 05:11:28,177 epoch 370 lr 1.000000e-05
2019-11-07 05:11:28,951 train 000 2.051298e-02 -0.035203
2019-11-07 05:11:38,685 train 050 1.774406e-02 -0.666058
2019-11-07 05:11:48,429 train 100 1.764779e-02 -1.029245
2019-11-07 05:11:58,176 train 150 1.782795e-02 -0.871608
2019-11-07 05:12:07,933 train 200 1.777842e-02 -0.922048
2019-11-07 05:12:17,709 train 250 1.765835e-02 -0.872022
2019-11-07 05:12:27,482 train 300 1.763167e-02 -0.839144
2019-11-07 05:12:37,270 train 350 1.765404e-02 -0.799803
2019-11-07 05:12:47,055 train 400 1.765399e-02 -0.809314
2019-11-07 05:12:56,824 train 450 1.765385e-02 -0.798072
2019-11-07 05:13:06,615 train 500 1.766893e-02 -0.768744
2019-11-07 05:13:16,417 train 550 1.769425e-02 -0.746480
2019-11-07 05:13:26,208 train 600 1.766988e-02 -0.766987
2019-11-07 05:13:35,989 train 650 1.765391e-02 -0.980181
2019-11-07 05:13:45,775 train 700 1.764583e-02 -0.969814
2019-11-07 05:13:55,569 train 750 1.763894e-02 -0.945022
2019-11-07 05:14:05,352 train 800 1.765767e-02 -0.935149
2019-11-07 05:14:15,141 train 850 1.764168e-02 -0.933975
2019-11-07 05:14:18,096 training loss; R2: 1.764895e-02 -0.926404
2019-11-07 05:14:18,727 valid 000 1.702330e-02 0.075009
2019-11-07 05:14:28,153 valid 050 1.800298e-02 -1.102549
2019-11-07 05:14:36,444 validation loss; R2: 1.809021e-02 -1.050754
2019-11-07 05:14:36,522 epoch 371 lr 1.000000e-05
2019-11-07 05:14:37,297 train 000 1.757661e-02 -0.670360
2019-11-07 05:14:47,415 train 050 1.759166e-02 -1.027639
2019-11-07 05:14:57,554 train 100 1.760726e-02 -0.775222
2019-11-07 05:15:07,714 train 150 1.750986e-02 -0.745428
2019-11-07 05:15:17,879 train 200 1.751015e-02 -0.748730
2019-11-07 05:15:28,053 train 250 1.756406e-02 -0.712430
2019-11-07 05:15:38,235 train 300 1.755207e-02 -0.657646
2019-11-07 05:15:48,400 train 350 1.751792e-02 -0.645088
2019-11-07 05:15:58,262 train 400 1.753530e-02 -0.654955
2019-11-07 05:16:08,064 train 450 1.751541e-02 -0.690871
2019-11-07 05:16:17,876 train 500 1.753625e-02 -0.711910
2019-11-07 05:16:27,678 train 550 1.755336e-02 -0.737527
2019-11-07 05:16:37,480 train 600 1.757149e-02 -0.708232
2019-11-07 05:16:47,267 train 650 1.757755e-02 -0.700885
2019-11-07 05:16:57,059 train 700 1.755143e-02 -0.681430
2019-11-07 05:17:06,879 train 750 1.754892e-02 -0.713163
2019-11-07 05:17:16,684 train 800 1.756939e-02 -0.733432
2019-11-07 05:17:26,488 train 850 1.758636e-02 -0.743024
2019-11-07 05:17:29,440 training loss; R2: 1.759066e-02 -0.745895
2019-11-07 05:17:30,055 valid 000 1.881465e-02 -0.182931
2019-11-07 05:17:39,498 valid 050 1.784465e-02 -1.150437
2019-11-07 05:17:47,841 validation loss; R2: 1.786486e-02 -1.119252
2019-11-07 05:17:47,911 epoch 372 lr 1.000000e-05
2019-11-07 05:17:48,718 train 000 1.896919e-02 -0.241565
2019-11-07 05:17:58,853 train 050 1.777973e-02 -0.911950
2019-11-07 05:18:09,001 train 100 1.755752e-02 -0.898016
2019-11-07 05:18:19,168 train 150 1.746438e-02 -0.916483
2019-11-07 05:18:29,326 train 200 1.742998e-02 -1.078502
2019-11-07 05:18:39,502 train 250 1.742005e-02 -0.972959
2019-11-07 05:18:49,678 train 300 1.739951e-02 -0.898720
2019-11-07 05:18:59,871 train 350 1.739855e-02 -0.907601
2019-11-07 05:19:10,054 train 400 1.741610e-02 -0.888309
2019-11-07 05:19:20,225 train 450 1.749682e-02 -0.882071
2019-11-07 05:19:30,390 train 500 1.751192e-02 -0.860660
2019-11-07 05:19:40,558 train 550 1.747314e-02 -0.839927
2019-11-07 05:19:50,733 train 600 1.747127e-02 -0.824070
2019-11-07 05:20:00,922 train 650 1.748108e-02 -0.805295
2019-11-07 05:20:11,106 train 700 1.751201e-02 -0.799993
2019-11-07 05:20:21,280 train 750 1.755208e-02 -0.795304
2019-11-07 05:20:31,442 train 800 1.755974e-02 -0.783671
2019-11-07 05:20:41,615 train 850 1.756004e-02 -0.772847
2019-11-07 05:20:44,660 training loss; R2: 1.757637e-02 -0.771279
2019-11-07 05:20:45,364 valid 000 2.078644e-02 -0.987046
2019-11-07 05:20:54,738 valid 050 1.777032e-02 -0.780713
2019-11-07 05:21:03,116 validation loss; R2: 1.757374e-02 -0.829147
2019-11-07 05:21:03,196 epoch 373 lr 1.000000e-05
2019-11-07 05:21:03,972 train 000 1.554117e-02 -0.223682
2019-11-07 05:21:13,686 train 050 1.698368e-02 -0.538902
2019-11-07 05:21:23,416 train 100 1.723010e-02 -11.466955
2019-11-07 05:21:33,164 train 150 1.725973e-02 -8.030617
2019-11-07 05:21:42,915 train 200 1.738900e-02 -6.162488
2019-11-07 05:21:52,725 train 250 1.749114e-02 -5.146825
2019-11-07 05:22:02,487 train 300 1.749345e-02 -4.448839
2019-11-07 05:22:12,314 train 350 1.753345e-02 -3.903161
2019-11-07 05:22:22,130 train 400 1.755110e-02 -3.500819
2019-11-07 05:22:31,938 train 450 1.754905e-02 -3.182501
2019-11-07 05:22:41,749 train 500 1.754556e-02 -2.954283
2019-11-07 05:22:51,556 train 550 1.753494e-02 -2.756020
2019-11-07 05:23:01,372 train 600 1.753521e-02 -2.574519
2019-11-07 05:23:11,184 train 650 1.752312e-02 -2.425119
2019-11-07 05:23:20,984 train 700 1.753995e-02 -2.290610
2019-11-07 05:23:30,787 train 750 1.752903e-02 -2.166188
2019-11-07 05:23:40,600 train 800 1.751945e-02 -2.068332
2019-11-07 05:23:50,405 train 850 1.753085e-02 -2.000690
2019-11-07 05:23:53,343 training loss; R2: 1.753323e-02 -1.975600
2019-11-07 05:23:53,951 valid 000 1.975530e-02 -0.031377
2019-11-07 05:24:03,367 valid 050 1.851862e-02 -1.753268
2019-11-07 05:24:11,801 validation loss; R2: 1.859003e-02 -1.384672
2019-11-07 05:24:11,866 epoch 374 lr 1.000000e-05
2019-11-07 05:24:12,637 train 000 1.688562e-02 -1.365772
2019-11-07 05:24:22,388 train 050 1.747073e-02 -0.562139
2019-11-07 05:24:32,157 train 100 1.758529e-02 -0.618216
2019-11-07 05:24:41,935 train 150 1.753241e-02 -0.599213
2019-11-07 05:24:51,684 train 200 1.763088e-02 -0.786756
2019-11-07 05:25:01,466 train 250 1.769173e-02 -0.799445
2019-11-07 05:25:11,248 train 300 1.771877e-02 -0.781282
2019-11-07 05:25:21,031 train 350 1.767351e-02 -0.761602
2019-11-07 05:25:30,815 train 400 1.767073e-02 -0.750822
2019-11-07 05:25:40,596 train 450 1.765427e-02 -0.734861
2019-11-07 05:25:50,389 train 500 1.763420e-02 -0.724917
2019-11-07 05:26:00,170 train 550 1.761637e-02 -0.726931
2019-11-07 05:26:09,959 train 600 1.764067e-02 -0.787637
2019-11-07 05:26:19,749 train 650 1.763962e-02 -0.791942
2019-11-07 05:26:29,515 train 700 1.762103e-02 -0.812983
2019-11-07 05:26:39,283 train 750 1.763294e-02 -1.362015
2019-11-07 05:26:49,050 train 800 1.762407e-02 -1.307025
2019-11-07 05:26:58,820 train 850 1.762490e-02 -1.271545
2019-11-07 05:27:01,781 training loss; R2: 1.762187e-02 -1.261065
2019-11-07 05:27:02,411 valid 000 1.724835e-02 -2.070415
2019-11-07 05:27:11,812 valid 050 1.805723e-02 -1.031032
2019-11-07 05:27:20,132 validation loss; R2: 1.826011e-02 -1.053021
2019-11-07 05:27:20,213 epoch 375 lr 1.000000e-05
2019-11-07 05:27:21,016 train 000 1.843463e-02 -0.172039
2019-11-07 05:27:30,728 train 050 1.754998e-02 -0.591427
2019-11-07 05:27:40,454 train 100 1.745347e-02 -0.623315
2019-11-07 05:27:50,210 train 150 1.762295e-02 -1.294921
2019-11-07 05:27:59,975 train 200 1.761316e-02 -1.166645
2019-11-07 05:28:09,741 train 250 1.763700e-02 -1.069193
2019-11-07 05:28:19,506 train 300 1.764832e-02 -1.013378
2019-11-07 05:28:29,271 train 350 1.761765e-02 -0.971533
2019-11-07 05:28:39,031 train 400 1.760819e-02 -0.939391
2019-11-07 05:28:48,815 train 450 1.759613e-02 -1.105499
2019-11-07 05:28:58,590 train 500 1.758287e-02 -1.066134
2019-11-07 05:29:08,356 train 550 1.762698e-02 -1.034553
2019-11-07 05:29:18,132 train 600 1.764710e-02 -0.986625
2019-11-07 05:29:27,902 train 650 1.765066e-02 -0.958618
2019-11-07 05:29:37,678 train 700 1.765388e-02 -0.936724
2019-11-07 05:29:47,458 train 750 1.764609e-02 -4.848541
2019-11-07 05:29:57,236 train 800 1.763943e-02 -4.586640
2019-11-07 05:30:07,009 train 850 1.764648e-02 -4.363124
2019-11-07 05:30:09,932 training loss; R2: 1.766314e-02 -4.297379
2019-11-07 05:30:10,621 valid 000 1.770056e-02 0.016687
2019-11-07 05:30:20,013 valid 050 1.875427e-02 -1.487506
2019-11-07 05:30:28,385 validation loss; R2: 1.880201e-02 -1.551988
2019-11-07 05:30:28,466 epoch 376 lr 1.000000e-05
2019-11-07 05:30:29,252 train 000 1.827040e-02 -0.866658
2019-11-07 05:30:38,975 train 050 1.717126e-02 -1.079705
2019-11-07 05:30:48,705 train 100 1.723572e-02 -0.834112
2019-11-07 05:30:58,460 train 150 1.729161e-02 -0.715696
2019-11-07 05:31:08,219 train 200 1.740732e-02 -0.668397
2019-11-07 05:31:17,974 train 250 1.746698e-02 -0.672562
2019-11-07 05:31:27,739 train 300 1.748322e-02 -0.656441
2019-11-07 05:31:37,502 train 350 1.750168e-02 -0.680861
2019-11-07 05:31:47,257 train 400 1.755048e-02 -0.643267
2019-11-07 05:31:57,026 train 450 1.761679e-02 -0.647167
2019-11-07 05:32:06,811 train 500 1.762606e-02 -1.064140
2019-11-07 05:32:16,610 train 550 1.761448e-02 -1.065341
2019-11-07 05:32:26,413 train 600 1.759706e-02 -1.040304
2019-11-07 05:32:36,208 train 650 1.760324e-02 -1.107419
2019-11-07 05:32:46,014 train 700 1.762342e-02 -1.072735
2019-11-07 05:32:55,818 train 750 1.760663e-02 -1.047275
2019-11-07 05:33:05,627 train 800 1.760821e-02 -1.024036
2019-11-07 05:33:15,414 train 850 1.761502e-02 -1.003270
2019-11-07 05:33:18,330 training loss; R2: 1.760835e-02 -0.998424
2019-11-07 05:33:18,955 valid 000 1.461973e-02 -0.285197
2019-11-07 05:33:28,378 valid 050 1.831504e-02 -1.238688
2019-11-07 05:33:36,666 validation loss; R2: 1.836137e-02 -1.303249
2019-11-07 05:33:36,733 epoch 377 lr 1.000000e-05
2019-11-07 05:33:37,497 train 000 1.711285e-02 -1.557498
2019-11-07 05:33:47,231 train 050 1.783618e-02 -0.577849
2019-11-07 05:33:56,997 train 100 1.763404e-02 -0.582476
2019-11-07 05:34:06,769 train 150 1.756198e-02 -0.620722
2019-11-07 05:34:16,551 train 200 1.756868e-02 -0.705821
2019-11-07 05:34:26,355 train 250 1.757846e-02 -0.701655
2019-11-07 05:34:36,129 train 300 1.760329e-02 -0.705020
2019-11-07 05:34:45,912 train 350 1.760670e-02 -0.716482
2019-11-07 05:34:55,698 train 400 1.752970e-02 -0.723385
2019-11-07 05:35:05,485 train 450 1.756415e-02 -0.756750
2019-11-07 05:35:15,274 train 500 1.755489e-02 -0.740250
2019-11-07 05:35:25,049 train 550 1.750117e-02 -0.754137
2019-11-07 05:35:34,827 train 600 1.756469e-02 -0.769087
2019-11-07 05:35:44,619 train 650 1.758585e-02 -0.752520
2019-11-07 05:35:54,403 train 700 1.757289e-02 -0.735183
2019-11-07 05:36:04,181 train 750 1.759169e-02 -0.724725
2019-11-07 05:36:13,976 train 800 1.759872e-02 -0.716484
2019-11-07 05:36:23,757 train 850 1.758434e-02 -0.725037
2019-11-07 05:36:26,705 training loss; R2: 1.758853e-02 -0.728999
2019-11-07 05:36:27,343 valid 000 1.871237e-02 -0.070441
2019-11-07 05:36:36,786 valid 050 1.728791e-02 -0.766529
2019-11-07 05:36:45,119 validation loss; R2: 1.708926e-02 -0.865240
2019-11-07 05:36:45,197 epoch 378 lr 1.000000e-05
2019-11-07 05:36:45,990 train 000 1.660351e-02 -0.160767
2019-11-07 05:36:55,716 train 050 1.779157e-02 -0.715634
2019-11-07 05:37:05,771 train 100 1.749195e-02 -0.761901
2019-11-07 05:37:15,892 train 150 1.749872e-02 -0.703582
2019-11-07 05:37:26,011 train 200 1.757310e-02 -0.726765
2019-11-07 05:37:36,136 train 250 1.758313e-02 -7.366318
2019-11-07 05:37:46,286 train 300 1.758667e-02 -6.245683
2019-11-07 05:37:56,449 train 350 1.758475e-02 -5.421001
2019-11-07 05:38:06,611 train 400 1.761379e-02 -4.866823
2019-11-07 05:38:16,764 train 450 1.757554e-02 -4.416005
2019-11-07 05:38:26,923 train 500 1.756686e-02 -4.029804
2019-11-07 05:38:37,097 train 550 1.754018e-02 -3.731964
2019-11-07 05:38:47,269 train 600 1.752843e-02 -3.503598
2019-11-07 05:38:57,445 train 650 1.751331e-02 -3.291709
2019-11-07 05:39:07,634 train 700 1.749231e-02 -3.309020
2019-11-07 05:39:17,810 train 750 1.748465e-02 -3.139440
2019-11-07 05:39:27,962 train 800 1.747548e-02 -3.029950
2019-11-07 05:39:38,150 train 850 1.746609e-02 -2.887322
2019-11-07 05:39:41,198 training loss; R2: 1.747437e-02 -2.847413
2019-11-07 05:39:41,872 valid 000 1.651391e-02 -0.574231
2019-11-07 05:39:51,312 valid 050 1.774473e-02 -3.304428
2019-11-07 05:39:59,633 validation loss; R2: 1.766212e-02 -2.150047
2019-11-07 05:39:59,713 epoch 379 lr 1.000000e-05
2019-11-07 05:40:00,520 train 000 1.390012e-02 -0.474929
2019-11-07 05:40:10,262 train 050 1.768475e-02 -0.795075
2019-11-07 05:40:20,001 train 100 1.754499e-02 -0.639676
2019-11-07 05:40:29,746 train 150 1.769264e-02 -0.709454
2019-11-07 05:40:39,507 train 200 1.755631e-02 -0.671219
2019-11-07 05:40:49,287 train 250 1.757348e-02 -0.697093
2019-11-07 05:40:59,057 train 300 1.759785e-02 -0.731720
2019-11-07 05:41:08,831 train 350 1.755843e-02 -0.706575
2019-11-07 05:41:18,597 train 400 1.759399e-02 -0.716034
2019-11-07 05:41:28,365 train 450 1.759051e-02 -0.704977
2019-11-07 05:41:38,129 train 500 1.762151e-02 -0.695994
2019-11-07 05:41:47,912 train 550 1.762920e-02 -0.685722
2019-11-07 05:41:57,688 train 600 1.765147e-02 -0.697804
2019-11-07 05:42:07,470 train 650 1.764045e-02 -0.711853
2019-11-07 05:42:17,257 train 700 1.760219e-02 -0.707361
2019-11-07 05:42:27,039 train 750 1.760252e-02 -0.700190
2019-11-07 05:42:36,821 train 800 1.758336e-02 -0.716501
2019-11-07 05:42:46,606 train 850 1.758369e-02 -0.730711
2019-11-07 05:42:49,529 training loss; R2: 1.757955e-02 -0.725597
2019-11-07 05:42:50,177 valid 000 2.007961e-02 -0.389992
2019-11-07 05:42:59,556 valid 050 1.801221e-02 -1.449843
2019-11-07 05:43:07,870 validation loss; R2: 1.800190e-02 -1.215844
2019-11-07 05:43:07,936 epoch 380 lr 1.000000e-05
2019-11-07 05:43:08,710 train 000 1.631793e-02 -4.554124
2019-11-07 05:43:18,453 train 050 1.776557e-02 -0.572761
2019-11-07 05:43:28,180 train 100 1.770022e-02 -1.001947
2019-11-07 05:43:37,942 train 150 1.783451e-02 -0.897121
2019-11-07 05:43:47,704 train 200 1.778900e-02 -0.815624
2019-11-07 05:43:57,473 train 250 1.770722e-02 -0.797840
2019-11-07 05:44:07,236 train 300 1.768991e-02 -0.769810
2019-11-07 05:44:17,011 train 350 1.771941e-02 -0.762512
2019-11-07 05:44:26,771 train 400 1.769777e-02 -0.733384
2019-11-07 05:44:36,547 train 450 1.768587e-02 -0.703531
2019-11-07 05:44:46,325 train 500 1.767792e-02 -0.725295
2019-11-07 05:44:56,125 train 550 1.766774e-02 -0.745416
2019-11-07 05:45:05,925 train 600 1.767015e-02 -0.755039
2019-11-07 05:45:15,696 train 650 1.764651e-02 -0.778192
2019-11-07 05:45:25,461 train 700 1.761385e-02 -0.773379
2019-11-07 05:45:35,235 train 750 1.760220e-02 -0.764321
2019-11-07 05:45:45,011 train 800 1.758571e-02 -0.769571
2019-11-07 05:45:54,778 train 850 1.756802e-02 -0.781439
2019-11-07 05:45:57,696 training loss; R2: 1.756553e-02 -0.779875
2019-11-07 05:45:58,348 valid 000 2.207823e-02 -0.729081
2019-11-07 05:46:07,767 valid 050 1.735793e-02 -1.064179
2019-11-07 05:46:16,076 validation loss; R2: 1.768786e-02 -1.102797
2019-11-07 05:46:16,148 epoch 381 lr 1.000000e-05
2019-11-07 05:46:16,920 train 000 1.633726e-02 -1.347993
2019-11-07 05:46:26,630 train 050 1.728972e-02 -0.963670
2019-11-07 05:46:36,365 train 100 1.743049e-02 -0.813345
2019-11-07 05:46:46,156 train 150 1.752795e-02 -0.804546
2019-11-07 05:46:55,945 train 200 1.751878e-02 -0.773520
2019-11-07 05:47:05,729 train 250 1.755191e-02 -0.842621
2019-11-07 05:47:15,467 train 300 1.756278e-02 -0.861857
2019-11-07 05:47:25,209 train 350 1.759135e-02 -0.816632
2019-11-07 05:47:34,949 train 400 1.763446e-02 -0.818157
2019-11-07 05:47:44,689 train 450 1.759557e-02 -0.789100
2019-11-07 05:47:54,446 train 500 1.758863e-02 -0.783473
2019-11-07 05:48:04,183 train 550 1.757579e-02 -0.772361
2019-11-07 05:48:13,921 train 600 1.757883e-02 -0.747878
2019-11-07 05:48:23,661 train 650 1.758850e-02 -0.749556
2019-11-07 05:48:33,404 train 700 1.758925e-02 -0.773078
2019-11-07 05:48:43,157 train 750 1.760409e-02 -0.766855
2019-11-07 05:48:52,912 train 800 1.756730e-02 -0.741446
2019-11-07 05:49:02,665 train 850 1.754844e-02 -0.738295
2019-11-07 05:49:05,577 training loss; R2: 1.755272e-02 -0.736314
2019-11-07 05:49:06,236 valid 000 2.175365e-02 -0.994085
2019-11-07 05:49:15,693 valid 050 1.929318e-02 -1.241353
2019-11-07 05:49:24,039 validation loss; R2: 1.939143e-02 -1.276134
2019-11-07 05:49:24,105 epoch 382 lr 1.000000e-05
2019-11-07 05:49:24,840 train 000 1.672084e-02 -0.493944
2019-11-07 05:49:34,532 train 050 1.736244e-02 -1.006954
2019-11-07 05:49:44,220 train 100 1.752833e-02 -0.880455
2019-11-07 05:49:53,961 train 150 1.744816e-02 -0.755496
2019-11-07 05:50:03,690 train 200 1.749021e-02 -0.735216
2019-11-07 05:50:13,422 train 250 1.748333e-02 -0.712430
2019-11-07 05:50:23,146 train 300 1.748297e-02 -0.806062
2019-11-07 05:50:32,875 train 350 1.755264e-02 -0.799293
2019-11-07 05:50:42,619 train 400 1.754190e-02 -0.790585
2019-11-07 05:50:52,404 train 450 1.759246e-02 -0.785975
2019-11-07 05:51:02,176 train 500 1.758178e-02 -0.796196
2019-11-07 05:51:11,945 train 550 1.758599e-02 -0.810954
2019-11-07 05:51:21,722 train 600 1.756681e-02 -0.802235
2019-11-07 05:51:31,506 train 650 1.755930e-02 -0.811309
2019-11-07 05:51:41,287 train 700 1.756955e-02 -0.803466
2019-11-07 05:51:51,091 train 750 1.760007e-02 -0.796326
2019-11-07 05:52:00,870 train 800 1.757644e-02 -0.780191
2019-11-07 05:52:10,666 train 850 1.757074e-02 -0.798034
2019-11-07 05:52:13,606 training loss; R2: 1.756254e-02 -0.797696
2019-11-07 05:52:14,223 valid 000 1.681989e-02 -0.475078
2019-11-07 05:52:23,642 valid 050 1.949681e-02 -1.472632
2019-11-07 05:52:31,961 validation loss; R2: 1.920370e-02 -1.591972
2019-11-07 05:52:32,028 epoch 383 lr 1.000000e-05
2019-11-07 05:52:32,760 train 000 1.740639e-02 0.021507
2019-11-07 05:52:42,477 train 050 1.782470e-02 -0.668168
2019-11-07 05:52:52,215 train 100 1.767593e-02 -0.775523
2019-11-07 05:53:01,990 train 150 1.758852e-02 -0.759582
2019-11-07 05:53:11,760 train 200 1.766560e-02 -1.201242
2019-11-07 05:53:21,523 train 250 1.750973e-02 -1.103013
2019-11-07 05:53:31,291 train 300 1.757229e-02 -1.186153
2019-11-07 05:53:41,062 train 350 1.758913e-02 -1.131741
2019-11-07 05:53:50,842 train 400 1.755444e-02 -1.171830
2019-11-07 05:54:00,608 train 450 1.750535e-02 -1.135926
2019-11-07 05:54:10,388 train 500 1.751917e-02 -1.084824
2019-11-07 05:54:20,167 train 550 1.749268e-02 -1.051942
2019-11-07 05:54:29,953 train 600 1.747740e-02 -1.038444
2019-11-07 05:54:39,735 train 650 1.746691e-02 -1.016824
2019-11-07 05:54:49,540 train 700 1.748910e-02 -1.391230
2019-11-07 05:54:59,326 train 750 1.751047e-02 -1.353543
2019-11-07 05:55:09,341 train 800 1.751530e-02 -1.318124
2019-11-07 05:55:19,516 train 850 1.750824e-02 -1.276729
2019-11-07 05:55:22,552 training loss; R2: 1.750842e-02 -1.276774
2019-11-07 05:55:23,241 valid 000 1.653473e-02 -1.452610
2019-11-07 05:55:32,640 valid 050 1.824941e-02 -1.299057
2019-11-07 05:55:40,958 validation loss; R2: 1.820741e-02 -1.405700
2019-11-07 05:55:41,028 epoch 384 lr 1.000000e-05
2019-11-07 05:55:41,820 train 000 1.981620e-02 -0.105935
2019-11-07 05:55:51,929 train 050 1.781998e-02 -0.920166
2019-11-07 05:56:02,057 train 100 1.753854e-02 -0.914887
2019-11-07 05:56:12,191 train 150 1.743785e-02 -1.035690
2019-11-07 05:56:22,341 train 200 1.748937e-02 -0.980161
2019-11-07 05:56:32,495 train 250 1.742060e-02 -0.896321
2019-11-07 05:56:42,634 train 300 1.742857e-02 -0.885905
2019-11-07 05:56:52,770 train 350 1.743158e-02 -0.869674
2019-11-07 05:57:02,921 train 400 1.748514e-02 -0.853517
2019-11-07 05:57:13,057 train 450 1.747237e-02 -0.903182
2019-11-07 05:57:23,188 train 500 1.746836e-02 -0.911497
2019-11-07 05:57:33,330 train 550 1.750271e-02 -0.888533
2019-11-07 05:57:43,471 train 600 1.744269e-02 -0.866577
2019-11-07 05:57:53,598 train 650 1.746631e-02 -0.859174
2019-11-07 05:58:03,750 train 700 1.748739e-02 -0.887468
2019-11-07 05:58:13,867 train 750 1.751173e-02 -0.891737
2019-11-07 05:58:24,000 train 800 1.750258e-02 -0.887085
2019-11-07 05:58:34,142 train 850 1.750162e-02 -0.885071
2019-11-07 05:58:37,163 training loss; R2: 1.750938e-02 -0.876922
2019-11-07 05:58:37,877 valid 000 1.693610e-02 -2.261419
2019-11-07 05:58:47,211 valid 050 1.860598e-02 -1.644614
2019-11-07 05:58:55,589 validation loss; R2: 1.866290e-02 -2.495723
2019-11-07 05:58:55,679 epoch 385 lr 1.000000e-05
2019-11-07 05:58:56,472 train 000 1.637791e-02 -1.290622
2019-11-07 05:59:06,182 train 050 1.739124e-02 -0.557416
2019-11-07 05:59:15,897 train 100 1.730839e-02 -0.885451
2019-11-07 05:59:25,629 train 150 1.740137e-02 -0.862427
2019-11-07 05:59:35,359 train 200 1.751007e-02 -0.893078
2019-11-07 05:59:45,106 train 250 1.754931e-02 -0.843702
2019-11-07 05:59:54,862 train 300 1.751088e-02 -0.841200
2019-11-07 06:00:04,612 train 350 1.749842e-02 -0.841116
2019-11-07 06:00:14,373 train 400 1.751623e-02 -0.831430
2019-11-07 06:00:24,131 train 450 1.754218e-02 -0.798823
2019-11-07 06:00:33,885 train 500 1.753960e-02 -0.782151
2019-11-07 06:00:43,643 train 550 1.752370e-02 -0.875183
2019-11-07 06:00:53,419 train 600 1.750640e-02 -0.868723
2019-11-07 06:01:03,188 train 650 1.753646e-02 -0.863138
2019-11-07 06:01:12,941 train 700 1.752654e-02 -0.855424
2019-11-07 06:01:22,694 train 750 1.752766e-02 -0.848754
2019-11-07 06:01:32,446 train 800 1.755814e-02 -0.832671
2019-11-07 06:01:42,208 train 850 1.755546e-02 -0.805003
2019-11-07 06:01:45,167 training loss; R2: 1.756157e-02 -0.808976
2019-11-07 06:01:45,788 valid 000 1.716259e-02 -4.379219
2019-11-07 06:01:55,220 valid 050 1.890981e-02 -1.133451
2019-11-07 06:02:03,528 validation loss; R2: 1.866336e-02 -2.942220
2019-11-07 06:02:03,596 epoch 386 lr 1.000000e-05
2019-11-07 06:02:04,383 train 000 1.752109e-02 0.051449
2019-11-07 06:02:14,158 train 050 1.720363e-02 -0.556263
2019-11-07 06:02:23,961 train 100 1.749746e-02 -0.727964
2019-11-07 06:02:33,812 train 150 1.743430e-02 -0.800344
2019-11-07 06:02:43,640 train 200 1.743560e-02 -0.802735
2019-11-07 06:02:53,465 train 250 1.751452e-02 -22.684392
2019-11-07 06:03:03,288 train 300 1.752785e-02 -19.019828
2019-11-07 06:03:13,073 train 350 1.757606e-02 -16.386311
2019-11-07 06:03:22,878 train 400 1.754216e-02 -14.466318
2019-11-07 06:03:32,680 train 450 1.758974e-02 -12.958880
2019-11-07 06:03:42,477 train 500 1.761826e-02 -11.723010
2019-11-07 06:03:52,290 train 550 1.756540e-02 -10.727772
2019-11-07 06:04:02,079 train 600 1.756985e-02 -9.960934
2019-11-07 06:04:11,871 train 650 1.757682e-02 -9.234652
2019-11-07 06:04:21,657 train 700 1.755769e-02 -8.617898
2019-11-07 06:04:31,433 train 750 1.754078e-02 -8.086775
2019-11-07 06:04:41,218 train 800 1.754515e-02 -7.650655
2019-11-07 06:04:51,022 train 850 1.755075e-02 -7.236293
2019-11-07 06:04:53,957 training loss; R2: 1.756017e-02 -7.120028
2019-11-07 06:04:54,671 valid 000 1.558338e-02 -1.087333
2019-11-07 06:05:04,068 valid 050 1.776245e-02 -1.835463
2019-11-07 06:05:12,410 validation loss; R2: 1.807881e-02 -2.374126
2019-11-07 06:05:12,475 epoch 387 lr 1.000000e-05
2019-11-07 06:05:13,247 train 000 1.635188e-02 -0.067456
2019-11-07 06:05:23,015 train 050 1.761699e-02 -0.681788
2019-11-07 06:05:32,793 train 100 1.768443e-02 -0.775424
2019-11-07 06:05:42,561 train 150 1.774109e-02 -0.699785
2019-11-07 06:05:52,336 train 200 1.768019e-02 -0.654479
2019-11-07 06:06:02,110 train 250 1.766233e-02 -0.622543
2019-11-07 06:06:11,885 train 300 1.771559e-02 -0.680837
2019-11-07 06:06:21,695 train 350 1.767197e-02 -0.664381
2019-11-07 06:06:31,511 train 400 1.762501e-02 -0.670288
2019-11-07 06:06:41,321 train 450 1.764109e-02 -0.709870
2019-11-07 06:06:51,110 train 500 1.762063e-02 -0.912221
2019-11-07 06:07:00,888 train 550 1.761688e-02 -0.891238
2019-11-07 06:07:10,654 train 600 1.759748e-02 -0.873323
2019-11-07 06:07:20,438 train 650 1.759783e-02 -0.850447
2019-11-07 06:07:30,227 train 700 1.760214e-02 -0.829113
2019-11-07 06:07:40,017 train 750 1.761158e-02 -0.809701
2019-11-07 06:07:49,812 train 800 1.760711e-02 -0.805497
2019-11-07 06:07:59,616 train 850 1.760455e-02 -0.811449
2019-11-07 06:08:02,575 training loss; R2: 1.761506e-02 -0.812080
2019-11-07 06:08:03,263 valid 000 2.274442e-02 -0.367649
2019-11-07 06:08:12,656 valid 050 1.842941e-02 -1.434730
2019-11-07 06:08:20,995 validation loss; R2: 1.853229e-02 -1.229676
2019-11-07 06:08:21,061 epoch 388 lr 1.000000e-05
2019-11-07 06:08:21,825 train 000 1.525873e-02 -0.655719
2019-11-07 06:08:31,972 train 050 1.724841e-02 -0.822332
2019-11-07 06:08:42,124 train 100 1.727353e-02 -0.766996
2019-11-07 06:08:52,256 train 150 1.739138e-02 -0.747382
2019-11-07 06:09:02,386 train 200 1.741743e-02 -0.735353
2019-11-07 06:09:12,519 train 250 1.743703e-02 -0.777613
2019-11-07 06:09:22,658 train 300 1.742946e-02 -0.780956
2019-11-07 06:09:32,783 train 350 1.744112e-02 -0.745025
2019-11-07 06:09:42,916 train 400 1.744191e-02 -0.788203
2019-11-07 06:09:53,053 train 450 1.745428e-02 -1.071469
2019-11-07 06:10:03,190 train 500 1.745595e-02 -1.050852
2019-11-07 06:10:13,330 train 550 1.743435e-02 -1.005988
2019-11-07 06:10:23,475 train 600 1.745293e-02 -1.405331
2019-11-07 06:10:33,623 train 650 1.747725e-02 -1.334709
2019-11-07 06:10:43,760 train 700 1.749677e-02 -1.289727
2019-11-07 06:10:53,896 train 750 1.748991e-02 -1.306225
2019-11-07 06:11:04,032 train 800 1.749600e-02 -1.265058
2019-11-07 06:11:14,161 train 850 1.753546e-02 -1.266122
2019-11-07 06:11:17,191 training loss; R2: 1.753158e-02 -1.258443
2019-11-07 06:11:17,878 valid 000 2.009511e-02 -0.192878
2019-11-07 06:11:27,245 valid 050 1.926219e-02 -1.153584
2019-11-07 06:11:35,589 validation loss; R2: 1.937378e-02 -1.281458
2019-11-07 06:11:35,665 epoch 389 lr 1.000000e-05
2019-11-07 06:11:36,391 train 000 1.729216e-02 -1.574425
2019-11-07 06:11:46,125 train 050 1.801375e-02 -0.614061
2019-11-07 06:11:55,863 train 100 1.778726e-02 -0.636821
2019-11-07 06:12:05,612 train 150 1.762321e-02 -0.685476
2019-11-07 06:12:15,373 train 200 1.758222e-02 -0.677398
2019-11-07 06:12:25,126 train 250 1.761278e-02 -0.689910
2019-11-07 06:12:34,889 train 300 1.760432e-02 -0.704142
2019-11-07 06:12:44,668 train 350 1.759270e-02 -0.727310
2019-11-07 06:12:54,433 train 400 1.763459e-02 -0.726913
2019-11-07 06:13:04,234 train 450 1.760895e-02 -0.709383
2019-11-07 06:13:14,052 train 500 1.758993e-02 -0.690995
2019-11-07 06:13:23,866 train 550 1.756145e-02 -0.722529
2019-11-07 06:13:33,672 train 600 1.754171e-02 -0.716946
2019-11-07 06:13:43,467 train 650 1.752347e-02 -0.713043
2019-11-07 06:13:53,242 train 700 1.751781e-02 -0.717938
2019-11-07 06:14:03,038 train 750 1.753384e-02 -0.703452
2019-11-07 06:14:12,841 train 800 1.750413e-02 -0.711960
2019-11-07 06:14:22,662 train 850 1.749325e-02 -0.711309
2019-11-07 06:14:25,628 training loss; R2: 1.750329e-02 -0.715158
2019-11-07 06:14:26,277 valid 000 1.832221e-02 -1.718851
2019-11-07 06:14:35,703 valid 050 1.698912e-02 -1.225690
2019-11-07 06:14:43,981 validation loss; R2: 1.690148e-02 -1.082146
2019-11-07 06:14:44,060 epoch 390 lr 1.000000e-05
2019-11-07 06:14:44,855 train 000 1.997194e-02 -0.670803
2019-11-07 06:14:54,628 train 050 1.744126e-02 -1.041676
2019-11-07 06:15:04,446 train 100 1.761157e-02 -0.909885
2019-11-07 06:15:14,267 train 150 1.769300e-02 -0.808416
2019-11-07 06:15:24,077 train 200 1.762999e-02 -0.770332
2019-11-07 06:15:33,882 train 250 1.763059e-02 -11.421513
2019-11-07 06:15:43,703 train 300 1.761050e-02 -9.673275
2019-11-07 06:15:53,523 train 350 1.758921e-02 -8.405763
2019-11-07 06:16:03,335 train 400 1.753533e-02 -7.425332
2019-11-07 06:16:13,142 train 450 1.755161e-02 -6.674277
2019-11-07 06:16:22,960 train 500 1.754587e-02 -6.076086
2019-11-07 06:16:32,765 train 550 1.751762e-02 -5.591227
2019-11-07 06:16:42,560 train 600 1.751549e-02 -5.192031
2019-11-07 06:16:52,370 train 650 1.750302e-02 -4.841843
2019-11-07 06:17:02,176 train 700 1.748315e-02 -4.540605
2019-11-07 06:17:11,980 train 750 1.749700e-02 -4.310462
2019-11-07 06:17:21,795 train 800 1.752006e-02 -4.086533
2019-11-07 06:17:31,612 train 850 1.752771e-02 -3.896688
2019-11-07 06:17:34,571 training loss; R2: 1.753759e-02 -3.837677
2019-11-07 06:17:35,175 valid 000 1.947509e-02 -2.746440
2019-11-07 06:17:44,638 valid 050 1.833885e-02 -1.021465
2019-11-07 06:17:53,148 validation loss; R2: 1.808449e-02 -0.963520
2019-11-07 06:17:53,229 epoch 391 lr 1.000000e-05
2019-11-07 06:17:54,059 train 000 1.670079e-02 -2.509492
2019-11-07 06:18:03,799 train 050 1.778587e-02 -0.799700
2019-11-07 06:18:13,560 train 100 1.772291e-02 -0.982522
2019-11-07 06:18:23,318 train 150 1.759272e-02 -0.945195
2019-11-07 06:18:33,069 train 200 1.756740e-02 -0.961962
2019-11-07 06:18:42,826 train 250 1.762310e-02 -0.901604
2019-11-07 06:18:52,590 train 300 1.761808e-02 -0.879987
2019-11-07 06:19:02,349 train 350 1.762820e-02 -4.293447
2019-11-07 06:19:12,107 train 400 1.762600e-02 -3.845119
2019-11-07 06:19:21,876 train 450 1.760833e-02 -3.482545
2019-11-07 06:19:31,638 train 500 1.755008e-02 -3.198702
2019-11-07 06:19:41,411 train 550 1.755010e-02 -2.965751
2019-11-07 06:19:51,178 train 600 1.754558e-02 -2.761342
2019-11-07 06:20:00,936 train 650 1.754029e-02 -2.602468
2019-11-07 06:20:10,727 train 700 1.752699e-02 -22.623367
2019-11-07 06:20:20,500 train 750 1.753377e-02 -21.163601
2019-11-07 06:20:30,279 train 800 1.753457e-02 -19.892272
2019-11-07 06:20:40,068 train 850 1.753293e-02 -18.797980
2019-11-07 06:20:43,001 training loss; R2: 1.751804e-02 -18.493528
2019-11-07 06:20:43,690 valid 000 1.715089e-02 -2.556652
2019-11-07 06:20:53,071 valid 050 1.786359e-02 -15.219095
2019-11-07 06:21:01,393 validation loss; R2: 1.808243e-02 -8.564188
2019-11-07 06:21:01,458 epoch 392 lr 1.000000e-05
2019-11-07 06:21:02,201 train 000 1.709871e-02 -2.412994
2019-11-07 06:21:11,943 train 050 1.780015e-02 -0.652380
2019-11-07 06:21:21,690 train 100 1.774672e-02 -0.831233
2019-11-07 06:21:31,437 train 150 1.773592e-02 -0.772010
2019-11-07 06:21:41,431 train 200 1.765853e-02 -0.699726
2019-11-07 06:21:51,551 train 250 1.760507e-02 -0.733542
2019-11-07 06:22:01,675 train 300 1.761114e-02 -0.736819
2019-11-07 06:22:11,816 train 350 1.760022e-02 -0.706401
2019-11-07 06:22:21,952 train 400 1.756041e-02 -0.736125
2019-11-07 06:22:32,084 train 450 1.750985e-02 -0.765697
2019-11-07 06:22:41,901 train 500 1.754127e-02 -0.765602
2019-11-07 06:22:51,681 train 550 1.753006e-02 -0.759224
2019-11-07 06:23:01,452 train 600 1.748803e-02 -0.761338
2019-11-07 06:23:11,233 train 650 1.748392e-02 -0.764942
2019-11-07 06:23:21,000 train 700 1.749152e-02 -0.780862
2019-11-07 06:23:30,782 train 750 1.750464e-02 -0.795302
2019-11-07 06:23:40,554 train 800 1.748091e-02 -0.788958
2019-11-07 06:23:50,344 train 850 1.747695e-02 -0.770705
2019-11-07 06:23:53,267 training loss; R2: 1.748720e-02 -0.772817
2019-11-07 06:23:53,952 valid 000 1.647578e-02 -0.596671
2019-11-07 06:24:03,338 valid 050 1.836320e-02 -1.070772
2019-11-07 06:24:11,742 validation loss; R2: 1.839457e-02 -1.405073
2019-11-07 06:24:11,807 epoch 393 lr 1.000000e-05
2019-11-07 06:24:12,548 train 000 1.720823e-02 -0.054315
2019-11-07 06:24:22,304 train 050 1.728394e-02 -0.605188
2019-11-07 06:24:32,067 train 100 1.735835e-02 -0.795863
2019-11-07 06:24:41,846 train 150 1.753623e-02 -0.723941
2019-11-07 06:24:51,623 train 200 1.757214e-02 -0.708998
2019-11-07 06:25:01,380 train 250 1.755270e-02 -1.013991
2019-11-07 06:25:11,142 train 300 1.755253e-02 -0.985070
2019-11-07 06:25:20,909 train 350 1.754327e-02 -0.946317
2019-11-07 06:25:30,680 train 400 1.757556e-02 -0.906626
2019-11-07 06:25:40,453 train 450 1.760186e-02 -0.913517
2019-11-07 06:25:50,226 train 500 1.761659e-02 -0.889609
2019-11-07 06:25:59,989 train 550 1.762143e-02 -0.874585
2019-11-07 06:26:09,766 train 600 1.760982e-02 -0.871901
2019-11-07 06:26:19,557 train 650 1.761461e-02 -0.858227
2019-11-07 06:26:29,346 train 700 1.760617e-02 -0.844889
2019-11-07 06:26:39,123 train 750 1.761854e-02 -0.831971
2019-11-07 06:26:48,903 train 800 1.762135e-02 -0.824977
2019-11-07 06:26:58,685 train 850 1.761817e-02 -0.831598
2019-11-07 06:27:01,613 training loss; R2: 1.760479e-02 -0.836862
2019-11-07 06:27:02,202 valid 000 1.863807e-02 -2.007154
2019-11-07 06:27:11,670 valid 050 1.805427e-02 -1.106790
2019-11-07 06:27:20,025 validation loss; R2: 1.801280e-02 -1.183610
2019-11-07 06:27:20,089 epoch 394 lr 1.000000e-05
2019-11-07 06:27:20,809 train 000 1.943211e-02 -0.001454
2019-11-07 06:27:30,571 train 050 1.725429e-02 -1.082164
2019-11-07 06:27:40,326 train 100 1.738615e-02 -0.855669
2019-11-07 06:27:50,102 train 150 1.725437e-02 -0.896826
2019-11-07 06:27:59,871 train 200 1.746228e-02 -1.790020
2019-11-07 06:28:09,653 train 250 1.742655e-02 -1.552134
2019-11-07 06:28:19,447 train 300 1.746801e-02 -1.385101
2019-11-07 06:28:29,234 train 350 1.749366e-02 -1.275211
2019-11-07 06:28:39,035 train 400 1.743690e-02 -1.215113
2019-11-07 06:28:48,837 train 450 1.746190e-02 -1.143942
2019-11-07 06:28:58,634 train 500 1.747533e-02 -1.095494
2019-11-07 06:29:08,451 train 550 1.743595e-02 -1.060599
2019-11-07 06:29:18,266 train 600 1.743351e-02 -1.033066
2019-11-07 06:29:28,085 train 650 1.746209e-02 -1.000064
2019-11-07 06:29:37,905 train 700 1.746757e-02 -0.982803
2019-11-07 06:29:47,726 train 750 1.745174e-02 -0.971673
2019-11-07 06:29:57,538 train 800 1.745108e-02 -0.948634
2019-11-07 06:30:07,353 train 850 1.747705e-02 -0.954076
2019-11-07 06:30:10,283 training loss; R2: 1.747432e-02 -0.958675
2019-11-07 06:30:10,908 valid 000 1.889854e-02 -1.480952
2019-11-07 06:30:20,360 valid 050 1.790571e-02 -1.344223
2019-11-07 06:30:28,704 validation loss; R2: 1.806196e-02 -1.108628
2019-11-07 06:30:28,769 epoch 395 lr 1.000000e-05
2019-11-07 06:30:29,549 train 000 1.939375e-02 -0.025267
2019-11-07 06:30:39,265 train 050 1.751890e-02 -0.763744
2019-11-07 06:30:48,980 train 100 1.738268e-02 -0.735837
2019-11-07 06:30:58,722 train 150 1.735890e-02 -0.843604
2019-11-07 06:31:08,471 train 200 1.740414e-02 -0.846085
2019-11-07 06:31:18,217 train 250 1.747124e-02 -0.858323
2019-11-07 06:31:27,965 train 300 1.742603e-02 -0.808526
2019-11-07 06:31:37,730 train 350 1.752936e-02 -0.788650
2019-11-07 06:31:47,488 train 400 1.755295e-02 -0.762751
2019-11-07 06:31:57,258 train 450 1.753605e-02 -0.742927
2019-11-07 06:32:07,056 train 500 1.754222e-02 -0.821811
2019-11-07 06:32:16,838 train 550 1.755587e-02 -0.822372
2019-11-07 06:32:26,624 train 600 1.758339e-02 -0.814123
2019-11-07 06:32:36,412 train 650 1.760758e-02 -0.808372
2019-11-07 06:32:46,194 train 700 1.757096e-02 -1.257951
2019-11-07 06:32:55,979 train 750 1.755685e-02 -1.208473
2019-11-07 06:33:05,759 train 800 1.756036e-02 -1.162778
2019-11-07 06:33:15,543 train 850 1.754432e-02 -1.143680
2019-11-07 06:33:18,463 training loss; R2: 1.753971e-02 -1.140250
2019-11-07 06:33:19,113 valid 000 1.427867e-02 -0.503595
2019-11-07 06:33:28,520 valid 050 1.674974e-02 -0.830735
2019-11-07 06:33:36,876 validation loss; R2: 1.704758e-02 -1.071070
2019-11-07 06:33:36,942 epoch 396 lr 1.000000e-05
2019-11-07 06:33:37,705 train 000 1.614521e-02 -0.009082
2019-11-07 06:33:47,441 train 050 1.758430e-02 -0.662341
2019-11-07 06:33:57,198 train 100 1.760931e-02 -0.600916
2019-11-07 06:34:06,955 train 150 1.767510e-02 -0.579487
2019-11-07 06:34:16,730 train 200 1.764943e-02 -0.602944
2019-11-07 06:34:26,482 train 250 1.765180e-02 -0.618948
2019-11-07 06:34:36,247 train 300 1.765898e-02 -0.620651
2019-11-07 06:34:46,011 train 350 1.763695e-02 -0.688194
2019-11-07 06:34:55,796 train 400 1.756995e-02 -0.787646
2019-11-07 06:35:05,575 train 450 1.754473e-02 -0.772937
2019-11-07 06:35:15,369 train 500 1.758300e-02 -0.778379
2019-11-07 06:35:25,163 train 550 1.756501e-02 -0.772122
2019-11-07 06:35:34,962 train 600 1.756308e-02 -0.766947
2019-11-07 06:35:44,739 train 650 1.758026e-02 -0.741990
2019-11-07 06:35:54,517 train 700 1.756031e-02 -0.747741
2019-11-07 06:36:04,314 train 750 1.754127e-02 -0.738693
2019-11-07 06:36:14,097 train 800 1.754596e-02 -0.748397
2019-11-07 06:36:23,889 train 850 1.754307e-02 -0.740295
2019-11-07 06:36:26,846 training loss; R2: 1.753967e-02 -0.739487
2019-11-07 06:36:27,497 valid 000 1.722472e-02 -0.670417
2019-11-07 06:36:36,914 valid 050 1.790264e-02 -0.947955
2019-11-07 06:36:45,234 validation loss; R2: 1.810271e-02 -1.026962
2019-11-07 06:36:45,315 epoch 397 lr 1.000000e-05
2019-11-07 06:36:46,112 train 000 1.724195e-02 -0.177625
2019-11-07 06:36:56,231 train 050 1.746069e-02 -0.969135
2019-11-07 06:37:06,345 train 100 1.741348e-02 -0.808553
2019-11-07 06:37:16,498 train 150 1.742251e-02 -0.871648
2019-11-07 06:37:26,633 train 200 1.744101e-02 -0.793778
2019-11-07 06:37:36,794 train 250 1.744434e-02 -0.728172
2019-11-07 06:37:46,957 train 300 1.747474e-02 -0.763395
2019-11-07 06:37:57,080 train 350 1.750893e-02 -0.736256
2019-11-07 06:38:07,225 train 400 1.750685e-02 -0.755378
2019-11-07 06:38:17,071 train 450 1.754949e-02 -0.759529
2019-11-07 06:38:26,910 train 500 1.757158e-02 -0.750857
2019-11-07 06:38:36,715 train 550 1.756558e-02 -0.760552
2019-11-07 06:38:46,528 train 600 1.757730e-02 -0.742815
2019-11-07 06:38:56,357 train 650 1.756057e-02 -0.736188
2019-11-07 06:39:06,194 train 700 1.753315e-02 -0.738540
2019-11-07 06:39:16,025 train 750 1.746680e-02 -0.738903
2019-11-07 06:39:25,850 train 800 1.747271e-02 -0.753705
2019-11-07 06:39:35,674 train 850 1.746705e-02 -0.749677
2019-11-07 06:39:38,615 training loss; R2: 1.745344e-02 -0.747130
2019-11-07 06:39:39,264 valid 000 2.121168e-02 -0.040912
2019-11-07 06:39:48,676 valid 050 1.833652e-02 -18.036082
2019-11-07 06:39:56,994 validation loss; R2: 1.847574e-02 -10.026752
2019-11-07 06:39:57,064 epoch 398 lr 1.000000e-05
2019-11-07 06:39:57,839 train 000 1.758024e-02 -0.459346
2019-11-07 06:40:07,605 train 050 1.753424e-02 -0.574556
2019-11-07 06:40:17,377 train 100 1.735240e-02 -0.732685
2019-11-07 06:40:27,181 train 150 1.746434e-02 -0.793538
2019-11-07 06:40:37,010 train 200 1.759019e-02 -0.778519
2019-11-07 06:40:46,830 train 250 1.763438e-02 -0.748878
2019-11-07 06:40:56,659 train 300 1.758300e-02 -0.723598
2019-11-07 06:41:06,496 train 350 1.755107e-02 -0.757477
2019-11-07 06:41:16,330 train 400 1.752064e-02 -0.766777
2019-11-07 06:41:26,154 train 450 1.752667e-02 -0.776291
2019-11-07 06:41:35,986 train 500 1.751152e-02 -0.776878
2019-11-07 06:41:45,816 train 550 1.748631e-02 -0.794096
2019-11-07 06:41:55,659 train 600 1.749397e-02 -0.793115
2019-11-07 06:42:05,510 train 650 1.748222e-02 -0.805874
2019-11-07 06:42:15,364 train 700 1.747173e-02 -0.808291
2019-11-07 06:42:25,224 train 750 1.746431e-02 -0.790225
2019-11-07 06:42:35,084 train 800 1.747427e-02 -0.784408
2019-11-07 06:42:44,935 train 850 1.747159e-02 -0.779038
2019-11-07 06:42:47,873 training loss; R2: 1.747103e-02 -0.773609
2019-11-07 06:42:48,573 valid 000 1.838637e-02 -1.068660
2019-11-07 06:42:57,930 valid 050 1.826953e-02 -0.846508
2019-11-07 06:43:06,252 validation loss; R2: 1.835952e-02 -1.110442
2019-11-07 06:43:06,317 epoch 399 lr 1.000000e-05
2019-11-07 06:43:07,054 train 000 2.061738e-02 -0.864436
2019-11-07 06:43:16,814 train 050 1.753536e-02 -1.509450
2019-11-07 06:43:26,577 train 100 1.765695e-02 -1.091370
2019-11-07 06:43:36,360 train 150 1.755057e-02 -0.904809
2019-11-07 06:43:46,149 train 200 1.757538e-02 -0.848362
2019-11-07 06:43:55,939 train 250 1.760823e-02 -0.862599
2019-11-07 06:44:05,722 train 300 1.764087e-02 -0.826171
2019-11-07 06:44:15,514 train 350 1.766959e-02 -0.832257
2019-11-07 06:44:25,308 train 400 1.769849e-02 -0.830736
2019-11-07 06:44:35,087 train 450 1.770006e-02 -0.805739
2019-11-07 06:44:44,877 train 500 1.770133e-02 -0.789221
2019-11-07 06:44:54,670 train 550 1.767253e-02 -0.792604
2019-11-07 06:45:04,467 train 600 1.762410e-02 -0.764120
2019-11-07 06:45:14,266 train 650 1.761978e-02 -0.748098
2019-11-07 06:45:24,084 train 700 1.758313e-02 -0.731609
2019-11-07 06:45:33,893 train 750 1.755775e-02 -0.741753
2019-11-07 06:45:43,702 train 800 1.751644e-02 -0.744323
2019-11-07 06:45:53,514 train 850 1.751188e-02 -0.732037
2019-11-07 06:45:56,450 training loss; R2: 1.750250e-02 -0.731075
2019-11-07 06:45:57,151 valid 000 1.599648e-02 -0.107301
2019-11-07 06:46:06,496 valid 050 1.855037e-02 -3.342733
2019-11-07 06:46:14,895 validation loss; R2: 1.818799e-02 -2.376958
2019-11-07 06:46:14,961 epoch 400 lr 1.000000e-05
2019-11-07 06:46:15,742 train 000 1.700998e-02 -0.685421
2019-11-07 06:46:25,486 train 050 1.718503e-02 -0.776825
2019-11-07 06:46:35,220 train 100 1.745088e-02 -0.779852
2019-11-07 06:46:44,986 train 150 1.752966e-02 -0.759029
2019-11-07 06:46:54,745 train 200 1.752747e-02 -0.765435
2019-11-07 06:47:04,509 train 250 1.745757e-02 -0.883493
2019-11-07 06:47:14,274 train 300 1.748161e-02 -0.818924
2019-11-07 06:47:24,044 train 350 1.748126e-02 -0.919101
2019-11-07 06:47:33,812 train 400 1.751188e-02 -0.896460
2019-11-07 06:47:43,595 train 450 1.753401e-02 -0.858267
2019-11-07 06:47:53,386 train 500 1.755100e-02 -0.859029
2019-11-07 06:48:03,168 train 550 1.751420e-02 -0.835312
2019-11-07 06:48:12,971 train 600 1.751418e-02 -0.810256
2019-11-07 06:48:22,771 train 650 1.752463e-02 -0.780875
2019-11-07 06:48:32,570 train 700 1.752658e-02 -0.774902
2019-11-07 06:48:42,343 train 750 1.753196e-02 -0.791275
2019-11-07 06:48:52,133 train 800 1.753546e-02 -0.782133
2019-11-07 06:49:01,941 train 850 1.752142e-02 -0.783547
2019-11-07 06:49:04,873 training loss; R2: 1.751000e-02 -0.780499
2019-11-07 06:49:05,548 valid 000 1.874047e-02 -0.530108
2019-11-07 06:49:14,981 valid 050 1.810360e-02 -1.180285
2019-11-07 06:49:23,306 validation loss; R2: 1.799731e-02 -1.096171
2019-11-07 06:49:23,373 epoch 401 lr 1.000000e-05
2019-11-07 06:49:24,114 train 000 1.347500e-02 -0.463407
2019-11-07 06:49:33,851 train 050 1.741022e-02 -0.866517
2019-11-07 06:49:43,623 train 100 1.740214e-02 -0.720559
2019-11-07 06:49:53,405 train 150 1.745483e-02 -0.713120
2019-11-07 06:50:03,176 train 200 1.752397e-02 -0.757919
2019-11-07 06:50:12,947 train 250 1.748238e-02 -0.760004
2019-11-07 06:50:22,717 train 300 1.742057e-02 -0.749697
2019-11-07 06:50:32,506 train 350 1.743991e-02 -0.771131
2019-11-07 06:50:42,314 train 400 1.739589e-02 -0.784552
2019-11-07 06:50:52,101 train 450 1.742431e-02 -1.221243
2019-11-07 06:51:01,914 train 500 1.745045e-02 -1.180985
2019-11-07 06:51:11,709 train 550 1.741524e-02 -1.152532
2019-11-07 06:51:21,503 train 600 1.742182e-02 -1.121109
2019-11-07 06:51:31,299 train 650 1.744810e-02 -1.078514
2019-11-07 06:51:41,100 train 700 1.747329e-02 -1.039648
2019-11-07 06:51:50,868 train 750 1.749749e-02 -1.019453
2019-11-07 06:52:00,635 train 800 1.750390e-02 -1.007114
2019-11-07 06:52:10,419 train 850 1.748469e-02 -0.992657
2019-11-07 06:52:13,336 training loss; R2: 1.748827e-02 -0.985343
2019-11-07 06:52:14,013 valid 000 1.603528e-02 -0.792803
2019-11-07 06:52:23,423 valid 050 1.833159e-02 -1.228246
2019-11-07 06:52:31,754 validation loss; R2: 1.833463e-02 -1.298574
2019-11-07 06:52:31,821 epoch 402 lr 1.000000e-05
2019-11-07 06:52:32,548 train 000 1.585270e-02 -1.140023
2019-11-07 06:52:42,250 train 050 1.734376e-02 -0.658442
2019-11-07 06:52:51,939 train 100 1.733459e-02 -0.606695
2019-11-07 06:53:01,669 train 150 1.738879e-02 -0.651523
2019-11-07 06:53:11,439 train 200 1.739910e-02 -0.615462
2019-11-07 06:53:21,208 train 250 1.746217e-02 -0.631605
2019-11-07 06:53:30,978 train 300 1.741176e-02 -0.697841
2019-11-07 06:53:40,774 train 350 1.744641e-02 -0.681020
2019-11-07 06:53:50,601 train 400 1.739151e-02 -0.668680
2019-11-07 06:54:00,444 train 450 1.742688e-02 -0.696576
2019-11-07 06:54:10,279 train 500 1.744978e-02 -0.706872
2019-11-07 06:54:20,110 train 550 1.745340e-02 -0.687730
2019-11-07 06:54:29,942 train 600 1.747720e-02 -1.109758
2019-11-07 06:54:39,766 train 650 1.747972e-02 -1.081195
2019-11-07 06:54:49,596 train 700 1.749718e-02 -1.045722
2019-11-07 06:54:59,430 train 750 1.749733e-02 -1.019995
2019-11-07 06:55:09,262 train 800 1.748778e-02 -0.998599
2019-11-07 06:55:19,097 train 850 1.748050e-02 -0.969404
2019-11-07 06:55:22,029 training loss; R2: 1.747638e-02 -0.960246
2019-11-07 06:55:22,735 valid 000 1.439498e-02 -1.131336
2019-11-07 06:55:32,098 valid 050 1.744555e-02 -1.213609
2019-11-07 06:55:40,493 validation loss; R2: 1.750926e-02 -1.119653
2019-11-07 06:55:40,558 epoch 403 lr 1.000000e-05
2019-11-07 06:55:41,353 train 000 1.611118e-02 -0.310385
2019-11-07 06:55:51,129 train 050 1.738331e-02 -0.809137
2019-11-07 06:56:00,928 train 100 1.747486e-02 -0.701557
2019-11-07 06:56:10,720 train 150 1.745167e-02 -0.664198
2019-11-07 06:56:20,515 train 200 1.742425e-02 -0.603353
2019-11-07 06:56:30,316 train 250 1.738682e-02 -0.653691
2019-11-07 06:56:40,126 train 300 1.755317e-02 -0.643842
2019-11-07 06:56:49,927 train 350 1.752328e-02 -0.663328
2019-11-07 06:56:59,697 train 400 1.753312e-02 -0.637096
2019-11-07 06:57:09,452 train 450 1.751537e-02 -0.637347
2019-11-07 06:57:19,209 train 500 1.752400e-02 -0.646061
2019-11-07 06:57:28,972 train 550 1.754670e-02 -0.640006
2019-11-07 06:57:38,743 train 600 1.756079e-02 -0.639484
2019-11-07 06:57:48,518 train 650 1.758027e-02 -0.636496
2019-11-07 06:57:58,279 train 700 1.759284e-02 -0.651281
2019-11-07 06:58:08,038 train 750 1.756411e-02 -0.643718
2019-11-07 06:58:17,800 train 800 1.757404e-02 -0.649498
2019-11-07 06:58:27,553 train 850 1.754050e-02 -0.655337
2019-11-07 06:58:30,469 training loss; R2: 1.755109e-02 -0.652542
2019-11-07 06:58:31,056 valid 000 1.829609e-02 -1.339842
2019-11-07 06:58:40,493 valid 050 1.817107e-02 -1.213096
2019-11-07 06:58:48,836 validation loss; R2: 1.834445e-02 -1.255726
2019-11-07 06:58:48,902 epoch 404 lr 1.000000e-05
2019-11-07 06:58:49,688 train 000 1.661946e-02 -0.135057
2019-11-07 06:58:59,385 train 050 1.715590e-02 -0.766759
2019-11-07 06:59:09,076 train 100 1.737621e-02 -0.691384
2019-11-07 06:59:18,797 train 150 1.738815e-02 -0.655054
2019-11-07 06:59:28,523 train 200 1.724921e-02 -0.684731
2019-11-07 06:59:38,255 train 250 1.724225e-02 -0.645106
2019-11-07 06:59:48,054 train 300 1.720831e-02 -0.657584
2019-11-07 06:59:57,859 train 350 1.721636e-02 -0.634707
2019-11-07 07:00:07,670 train 400 1.725308e-02 -0.637251
2019-11-07 07:00:17,497 train 450 1.728987e-02 -0.628958
2019-11-07 07:00:27,305 train 500 1.730073e-02 -0.653530
2019-11-07 07:00:37,108 train 550 1.731973e-02 -0.650401
2019-11-07 07:00:46,914 train 600 1.731865e-02 -0.676194
2019-11-07 07:00:56,728 train 650 1.731843e-02 -0.713151
2019-11-07 07:01:06,527 train 700 1.733163e-02 -0.751456
2019-11-07 07:01:16,333 train 750 1.733829e-02 -0.734007
2019-11-07 07:01:26,147 train 800 1.736791e-02 -0.815165
2019-11-07 07:01:35,962 train 850 1.737018e-02 -0.805537
2019-11-07 07:01:38,895 training loss; R2: 1.737292e-02 -0.801767
2019-11-07 07:01:39,541 valid 000 2.054757e-02 -1.836647
2019-11-07 07:01:48,964 valid 050 1.788366e-02 -0.972835
2019-11-07 07:01:57,298 validation loss; R2: 1.797714e-02 -1.132300
2019-11-07 07:01:57,364 epoch 405 lr 1.000000e-05
2019-11-07 07:01:58,141 train 000 1.881566e-02 -0.192982
2019-11-07 07:02:07,873 train 050 1.740456e-02 -0.729018
2019-11-07 07:02:17,620 train 100 1.745511e-02 -1.070532
2019-11-07 07:02:27,390 train 150 1.734551e-02 -1.022442
2019-11-07 07:02:37,186 train 200 1.741950e-02 -0.933484
2019-11-07 07:02:46,950 train 250 1.741573e-02 -0.887273
2019-11-07 07:02:56,718 train 300 1.743180e-02 -0.831496
2019-11-07 07:03:06,535 train 350 1.743290e-02 -0.846520
2019-11-07 07:03:16,359 train 400 1.740929e-02 -0.842133
2019-11-07 07:03:26,191 train 450 1.741497e-02 -0.820074
2019-11-07 07:03:36,023 train 500 1.741459e-02 -0.832979
2019-11-07 07:03:45,847 train 550 1.743727e-02 -0.795237
2019-11-07 07:03:55,680 train 600 1.742620e-02 -0.776740
2019-11-07 07:04:05,509 train 650 1.743343e-02 -0.757458
2019-11-07 07:04:15,347 train 700 1.742860e-02 -0.747630
2019-11-07 07:04:25,184 train 750 1.742483e-02 -0.740440
2019-11-07 07:04:35,021 train 800 1.742959e-02 -0.745988
2019-11-07 07:04:44,868 train 850 1.740537e-02 -0.763196
2019-11-07 07:04:47,845 training loss; R2: 1.740435e-02 -0.761158
2019-11-07 07:04:48,496 valid 000 1.608922e-02 -0.473143
2019-11-07 07:04:57,927 valid 050 1.872148e-02 -0.694558
2019-11-07 07:05:06,238 validation loss; R2: 1.857346e-02 -1.050306
2019-11-07 07:05:06,321 epoch 406 lr 1.000000e-05
2019-11-07 07:05:07,117 train 000 1.943449e-02 -0.313692
2019-11-07 07:05:16,884 train 050 1.721987e-02 -0.676633
2019-11-07 07:05:26,667 train 100 1.745407e-02 -0.807446
2019-11-07 07:05:36,466 train 150 1.750438e-02 -0.803285
2019-11-07 07:05:46,260 train 200 1.747853e-02 -0.787226
2019-11-07 07:05:56,067 train 250 1.753927e-02 -0.763730
2019-11-07 07:06:05,885 train 300 1.756020e-02 -0.728848
2019-11-07 07:06:15,717 train 350 1.756668e-02 -0.721482
2019-11-07 07:06:25,549 train 400 1.753354e-02 -0.749348
2019-11-07 07:06:35,373 train 450 1.756738e-02 -0.745915
2019-11-07 07:06:45,197 train 500 1.755184e-02 -0.719477
2019-11-07 07:06:55,017 train 550 1.752544e-02 -0.735944
2019-11-07 07:07:04,842 train 600 1.753344e-02 -0.737897
2019-11-07 07:07:14,648 train 650 1.753626e-02 -0.735736
2019-11-07 07:07:24,417 train 700 1.754811e-02 -0.717854
2019-11-07 07:07:34,193 train 750 1.752559e-02 -0.814297
2019-11-07 07:07:44,231 train 800 1.750332e-02 -0.815285
2019-11-07 07:07:54,404 train 850 1.749260e-02 -0.812574
2019-11-07 07:07:57,449 training loss; R2: 1.750140e-02 -0.812755
2019-11-07 07:07:58,144 valid 000 1.621596e-02 -14.684260
2019-11-07 07:08:07,576 valid 050 1.788715e-02 -1.934308
2019-11-07 07:08:15,895 validation loss; R2: 1.819150e-02 -1.584128
2019-11-07 07:08:15,975 epoch 407 lr 1.000000e-05
2019-11-07 07:08:16,758 train 000 1.391510e-02 -1.231167
2019-11-07 07:08:26,479 train 050 1.749384e-02 -0.635760
2019-11-07 07:08:36,220 train 100 1.745730e-02 -0.725143
2019-11-07 07:08:45,980 train 150 1.753400e-02 -0.635507
2019-11-07 07:08:55,745 train 200 1.754033e-02 -0.721841
2019-11-07 07:09:05,505 train 250 1.748073e-02 -0.719043
2019-11-07 07:09:15,293 train 300 1.744506e-02 -0.833286
2019-11-07 07:09:25,075 train 350 1.743294e-02 -0.809665
2019-11-07 07:09:34,868 train 400 1.740679e-02 -0.784073
2019-11-07 07:09:44,650 train 450 1.737228e-02 -0.784513
2019-11-07 07:09:54,428 train 500 1.737166e-02 -0.781336
2019-11-07 07:10:04,230 train 550 1.740643e-02 -0.789796
2019-11-07 07:10:14,021 train 600 1.741096e-02 -0.773055
2019-11-07 07:10:23,807 train 650 1.744073e-02 -0.775367
2019-11-07 07:10:33,599 train 700 1.743810e-02 -0.763424
2019-11-07 07:10:43,393 train 750 1.744685e-02 -0.771535
2019-11-07 07:10:53,195 train 800 1.744833e-02 -0.766714
2019-11-07 07:11:02,944 train 850 1.743970e-02 -0.788101
2019-11-07 07:11:05,859 training loss; R2: 1.743217e-02 -0.783564
2019-11-07 07:11:06,461 valid 000 1.660528e-02 -0.070749
2019-11-07 07:11:15,891 valid 050 1.723597e-02 -0.775764
2019-11-07 07:11:24,318 validation loss; R2: 1.718754e-02 -0.888762
2019-11-07 07:11:24,385 epoch 408 lr 1.000000e-05
2019-11-07 07:11:25,148 train 000 1.770655e-02 -0.229192
2019-11-07 07:11:34,845 train 050 1.758174e-02 -0.814260
2019-11-07 07:11:44,534 train 100 1.742634e-02 -0.779256
2019-11-07 07:11:54,251 train 150 1.749885e-02 -0.671724
2019-11-07 07:12:03,992 train 200 1.756972e-02 -0.685860
2019-11-07 07:12:13,772 train 250 1.756587e-02 -0.741103
2019-11-07 07:12:23,534 train 300 1.751849e-02 -0.738912
2019-11-07 07:12:33,321 train 350 1.750680e-02 -0.760722
2019-11-07 07:12:43,095 train 400 1.747257e-02 -0.841397
2019-11-07 07:12:52,884 train 450 1.750179e-02 -0.835636
2019-11-07 07:13:02,678 train 500 1.749369e-02 -0.833511
2019-11-07 07:13:12,463 train 550 1.750135e-02 -0.944502
2019-11-07 07:13:22,254 train 600 1.748679e-02 -0.926443
2019-11-07 07:13:32,051 train 650 1.746876e-02 -0.893343
2019-11-07 07:13:41,843 train 700 1.749215e-02 -0.875482
2019-11-07 07:13:51,648 train 750 1.746999e-02 -0.861333
2019-11-07 07:14:01,452 train 800 1.746757e-02 -0.867424
2019-11-07 07:14:11,255 train 850 1.748981e-02 -0.860599
2019-11-07 07:14:14,185 training loss; R2: 1.750202e-02 -0.849237
2019-11-07 07:14:14,815 valid 000 1.835487e-02 -3.954896
2019-11-07 07:14:24,249 valid 050 1.727756e-02 -0.972058
2019-11-07 07:14:32,603 validation loss; R2: 1.731201e-02 -0.952818
2019-11-07 07:14:32,671 epoch 409 lr 1.000000e-05
2019-11-07 07:14:33,452 train 000 1.974061e-02 -0.294524
2019-11-07 07:14:43,186 train 050 1.738579e-02 -1.072767
2019-11-07 07:14:52,940 train 100 1.732629e-02 -1.132873
2019-11-07 07:15:02,706 train 150 1.738296e-02 -1.525143
2019-11-07 07:15:12,487 train 200 1.727291e-02 -1.285153
2019-11-07 07:15:22,284 train 250 1.735680e-02 -1.224993
2019-11-07 07:15:32,070 train 300 1.732435e-02 -1.108910
2019-11-07 07:15:41,860 train 350 1.728622e-02 -1.029375
2019-11-07 07:15:51,655 train 400 1.734783e-02 -0.998059
2019-11-07 07:16:01,458 train 450 1.732516e-02 -0.964477
2019-11-07 07:16:11,263 train 500 1.733294e-02 -0.972552
2019-11-07 07:16:21,077 train 550 1.729522e-02 -0.953204
2019-11-07 07:16:30,874 train 600 1.732011e-02 -0.925265
2019-11-07 07:16:40,681 train 650 1.735097e-02 -0.917117
2019-11-07 07:16:50,494 train 700 1.738791e-02 -0.906485
2019-11-07 07:17:00,294 train 750 1.739439e-02 -0.879951
2019-11-07 07:17:10,095 train 800 1.741310e-02 -0.878651
2019-11-07 07:17:19,894 train 850 1.741748e-02 -0.858314
2019-11-07 07:17:22,846 training loss; R2: 1.742055e-02 -0.859824
2019-11-07 07:17:23,543 valid 000 1.955060e-02 0.007921
2019-11-07 07:17:32,924 valid 050 1.827647e-02 -1.461515
2019-11-07 07:17:41,257 validation loss; R2: 1.806593e-02 -1.543104
2019-11-07 07:17:41,336 epoch 410 lr 1.000000e-05
2019-11-07 07:17:42,105 train 000 1.786429e-02 -0.170934
2019-11-07 07:17:51,830 train 050 1.740464e-02 -0.900295
2019-11-07 07:18:01,567 train 100 1.754479e-02 -0.826209
2019-11-07 07:18:11,323 train 150 1.760241e-02 -0.733711
2019-11-07 07:18:21,085 train 200 1.747556e-02 -0.717687
2019-11-07 07:18:30,873 train 250 1.747194e-02 -0.715482
2019-11-07 07:18:40,647 train 300 1.745823e-02 -0.695395
2019-11-07 07:18:50,418 train 350 1.745894e-02 -0.726692
2019-11-07 07:19:00,201 train 400 1.744787e-02 -0.777282
2019-11-07 07:19:09,987 train 450 1.746143e-02 -0.756040
2019-11-07 07:19:19,774 train 500 1.742032e-02 -0.782468
2019-11-07 07:19:29,565 train 550 1.742219e-02 -0.775624
2019-11-07 07:19:39,361 train 600 1.742990e-02 -0.759792
2019-11-07 07:19:49,153 train 650 1.745979e-02 -0.768059
2019-11-07 07:19:58,944 train 700 1.744068e-02 -9.990282
2019-11-07 07:20:08,741 train 750 1.743883e-02 -9.380417
2019-11-07 07:20:18,530 train 800 1.744149e-02 -8.846559
2019-11-07 07:20:28,332 train 850 1.743152e-02 -8.377189
2019-11-07 07:20:31,260 training loss; R2: 1.742562e-02 -8.248317
2019-11-07 07:20:31,898 valid 000 2.295181e-02 -0.198838
2019-11-07 07:20:41,320 valid 050 1.800386e-02 -1.642805
2019-11-07 07:20:49,655 validation loss; R2: 1.825630e-02 -1.397871
2019-11-07 07:20:49,732 epoch 411 lr 1.000000e-05
2019-11-07 07:20:50,496 train 000 1.682064e-02 -75.587612
2019-11-07 07:21:00,225 train 050 1.743205e-02 -2.276566
2019-11-07 07:21:09,981 train 100 1.759916e-02 -1.471783
2019-11-07 07:21:19,753 train 150 1.756492e-02 -1.170550
2019-11-07 07:21:29,593 train 200 1.756001e-02 -1.027788
2019-11-07 07:21:39,390 train 250 1.750950e-02 -24.389193
2019-11-07 07:21:49,214 train 300 1.743646e-02 -20.495275
2019-11-07 07:21:59,019 train 350 1.740932e-02 -17.655451
2019-11-07 07:22:08,819 train 400 1.746560e-02 -15.536442
2019-11-07 07:22:18,601 train 450 1.743107e-02 -13.896290
2019-11-07 07:22:28,380 train 500 1.743165e-02 -12.575594
2019-11-07 07:22:38,163 train 550 1.744060e-02 -11.486062
2019-11-07 07:22:47,954 train 600 1.744345e-02 -10.571154
2019-11-07 07:22:57,741 train 650 1.745715e-02 -9.822680
2019-11-07 07:23:07,527 train 700 1.745150e-02 -9.172475
2019-11-07 07:23:17,321 train 750 1.744821e-02 -8.595689
2019-11-07 07:23:27,114 train 800 1.745208e-02 -8.112662
2019-11-07 07:23:36,895 train 850 1.743618e-02 -7.664884
2019-11-07 07:23:39,819 training loss; R2: 1.742788e-02 -7.545437
2019-11-07 07:23:40,503 valid 000 1.688897e-02 -1.410694
2019-11-07 07:23:49,899 valid 050 1.763657e-02 -1.422684
2019-11-07 07:23:58,221 validation loss; R2: 1.768409e-02 -1.241263
2019-11-07 07:23:58,287 epoch 412 lr 1.000000e-05
2019-11-07 07:23:59,067 train 000 1.485151e-02 -0.067815
2019-11-07 07:24:08,785 train 050 1.748294e-02 -0.566590
2019-11-07 07:24:18,524 train 100 1.746327e-02 -0.555771
2019-11-07 07:24:28,283 train 150 1.743352e-02 -1.121879
2019-11-07 07:24:38,047 train 200 1.736239e-02 -0.985596
2019-11-07 07:24:47,818 train 250 1.746090e-02 -0.958412
2019-11-07 07:24:57,596 train 300 1.742277e-02 -5.931333
2019-11-07 07:25:07,380 train 350 1.748890e-02 -5.181229
2019-11-07 07:25:17,167 train 400 1.746145e-02 -4.660183
2019-11-07 07:25:26,949 train 450 1.745905e-02 -4.234328
2019-11-07 07:25:36,736 train 500 1.743165e-02 -3.911165
2019-11-07 07:25:46,545 train 550 1.743054e-02 -3.618539
2019-11-07 07:25:56,303 train 600 1.742336e-02 -3.383415
2019-11-07 07:26:06,069 train 650 1.742785e-02 -3.188441
2019-11-07 07:26:15,823 train 700 1.743631e-02 -3.032166
2019-11-07 07:26:25,578 train 750 1.743126e-02 -3.000554
2019-11-07 07:26:35,335 train 800 1.742395e-02 -2.885195
2019-11-07 07:26:45,099 train 850 1.743803e-02 -2.752245
2019-11-07 07:26:48,020 training loss; R2: 1.743659e-02 -2.724415
2019-11-07 07:26:48,597 valid 000 2.228050e-02 -0.209954
2019-11-07 07:26:58,073 valid 050 1.843484e-02 -1.156367
2019-11-07 07:27:06,439 validation loss; R2: 1.841738e-02 -1.059632
2019-11-07 07:27:06,501 epoch 413 lr 1.000000e-05
2019-11-07 07:27:07,256 train 000 1.913043e-02 -0.520830
2019-11-07 07:27:16,985 train 050 1.755076e-02 -0.647382
2019-11-07 07:27:26,734 train 100 1.751026e-02 -0.617640
2019-11-07 07:27:36,528 train 150 1.745567e-02 -0.710613
2019-11-07 07:27:46,328 train 200 1.743700e-02 -0.784582
2019-11-07 07:27:56,113 train 250 1.744665e-02 -0.769194
2019-11-07 07:28:05,890 train 300 1.741179e-02 -0.847999
2019-11-07 07:28:16,043 train 350 1.741564e-02 -0.799983
2019-11-07 07:28:26,183 train 400 1.739750e-02 -0.816740
2019-11-07 07:28:36,344 train 450 1.743997e-02 -0.843575
2019-11-07 07:28:46,495 train 500 1.748246e-02 -0.815036
2019-11-07 07:28:56,660 train 550 1.745836e-02 -0.798384
2019-11-07 07:29:06,490 train 600 1.744943e-02 -0.783598
2019-11-07 07:29:16,296 train 650 1.745939e-02 -0.770478
2019-11-07 07:29:26,457 train 700 1.745410e-02 -0.747237
2019-11-07 07:29:36,334 train 750 1.744804e-02 -0.761879
2019-11-07 07:29:46,122 train 800 1.745707e-02 -0.756204
2019-11-07 07:29:55,925 train 850 1.743888e-02 -0.754584
2019-11-07 07:29:58,846 training loss; R2: 1.744491e-02 -0.755033
2019-11-07 07:29:59,489 valid 000 1.947558e-02 -0.620603
2019-11-07 07:30:08,892 valid 050 1.754331e-02 -1.952080
2019-11-07 07:30:17,169 validation loss; R2: 1.744722e-02 -1.840296
2019-11-07 07:30:17,235 epoch 414 lr 1.000000e-05
2019-11-07 07:30:17,951 train 000 1.298652e-02 -1.073781
2019-11-07 07:30:27,678 train 050 1.741121e-02 -0.444026
2019-11-07 07:30:37,425 train 100 1.742999e-02 -0.650276
2019-11-07 07:30:47,190 train 150 1.749952e-02 -0.620778
2019-11-07 07:30:56,998 train 200 1.747515e-02 -0.620394
2019-11-07 07:31:06,797 train 250 1.744124e-02 -0.672498
2019-11-07 07:31:16,604 train 300 1.746326e-02 -0.681269
2019-11-07 07:31:26,392 train 350 1.744392e-02 -0.708617
2019-11-07 07:31:36,186 train 400 1.741785e-02 -1.212854
2019-11-07 07:31:45,977 train 450 1.738734e-02 -1.175545
2019-11-07 07:31:55,779 train 500 1.737880e-02 -1.115673
2019-11-07 07:32:05,589 train 550 1.741402e-02 -1.089163
2019-11-07 07:32:15,414 train 600 1.742769e-02 -1.055581
2019-11-07 07:32:25,245 train 650 1.745199e-02 -1.036241
2019-11-07 07:32:35,069 train 700 1.744114e-02 -1.010126
2019-11-07 07:32:44,890 train 750 1.745578e-02 -0.994333
2019-11-07 07:32:54,698 train 800 1.744539e-02 -0.987027
2019-11-07 07:33:04,502 train 850 1.744673e-02 -0.958142
2019-11-07 07:33:07,436 training loss; R2: 1.744761e-02 -0.952597
2019-11-07 07:33:08,129 valid 000 1.602765e-02 -1.611470
2019-11-07 07:33:17,443 valid 050 1.788040e-02 -1.198410
2019-11-07 07:33:25,934 validation loss; R2: 1.765165e-02 -1.096870
2019-11-07 07:33:26,000 epoch 415 lr 1.000000e-05
2019-11-07 07:33:26,797 train 000 1.554616e-02 -0.260217
2019-11-07 07:33:36,536 train 050 1.708496e-02 -0.554506
2019-11-07 07:33:46,281 train 100 1.712297e-02 -0.577595
2019-11-07 07:33:56,063 train 150 1.719102e-02 -0.654982
2019-11-07 07:34:05,849 train 200 1.730086e-02 -0.612738
2019-11-07 07:34:15,650 train 250 1.742757e-02 -0.598588
2019-11-07 07:34:25,443 train 300 1.740854e-02 -0.628237
2019-11-07 07:34:35,239 train 350 1.739503e-02 -0.623239
2019-11-07 07:34:45,026 train 400 1.733192e-02 -0.628046
2019-11-07 07:34:54,817 train 450 1.733626e-02 -0.664070
2019-11-07 07:35:04,630 train 500 1.732707e-02 -0.668723
2019-11-07 07:35:14,437 train 550 1.735970e-02 -0.681913
2019-11-07 07:35:24,244 train 600 1.737770e-02 -0.694061
2019-11-07 07:35:34,045 train 650 1.735541e-02 -0.689926
2019-11-07 07:35:43,849 train 700 1.737109e-02 -0.678333
2019-11-07 07:35:53,644 train 750 1.737236e-02 -0.681901
2019-11-07 07:36:03,432 train 800 1.738280e-02 -0.707358
2019-11-07 07:36:13,230 train 850 1.738462e-02 -0.707839
2019-11-07 07:36:16,157 training loss; R2: 1.738477e-02 -0.708312
2019-11-07 07:36:16,809 valid 000 1.882575e-02 -0.735220
2019-11-07 07:36:26,242 valid 050 1.851552e-02 -1.199165
2019-11-07 07:36:34,621 validation loss; R2: 1.878777e-02 -1.544829
2019-11-07 07:36:34,689 epoch 416 lr 1.000000e-05
2019-11-07 07:36:35,472 train 000 1.912861e-02 0.046626
2019-11-07 07:36:45,212 train 050 1.771866e-02 -0.857767
2019-11-07 07:36:54,969 train 100 1.733904e-02 -0.897858
2019-11-07 07:37:04,753 train 150 1.744269e-02 -0.797132
2019-11-07 07:37:14,545 train 200 1.750536e-02 -0.945272
2019-11-07 07:37:24,339 train 250 1.751113e-02 -0.876650
2019-11-07 07:37:34,127 train 300 1.743885e-02 -0.847011
2019-11-07 07:37:43,922 train 350 1.742251e-02 -0.817697
2019-11-07 07:37:53,713 train 400 1.737382e-02 -1.082363
2019-11-07 07:38:03,506 train 450 1.737340e-02 -1.186772
2019-11-07 07:38:13,311 train 500 1.734081e-02 -1.151113
2019-11-07 07:38:23,112 train 550 1.740638e-02 -1.151012
2019-11-07 07:38:32,899 train 600 1.742850e-02 -1.137758
2019-11-07 07:38:42,685 train 650 1.742608e-02 -1.106015
2019-11-07 07:38:52,477 train 700 1.743882e-02 -1.073854
2019-11-07 07:39:02,261 train 750 1.744314e-02 -1.081260
2019-11-07 07:39:12,046 train 800 1.743230e-02 -1.045740
2019-11-07 07:39:21,836 train 850 1.743461e-02 -1.015405
2019-11-07 07:39:24,767 training loss; R2: 1.743740e-02 -1.020553
2019-11-07 07:39:25,445 valid 000 1.853839e-02 -0.265305
2019-11-07 07:39:34,826 valid 050 1.720044e-02 -0.863059
2019-11-07 07:39:43,152 validation loss; R2: 1.718115e-02 -0.915991
2019-11-07 07:39:43,219 epoch 417 lr 1.000000e-05
2019-11-07 07:39:43,983 train 000 1.729452e-02 -0.298027
2019-11-07 07:39:53,710 train 050 1.724262e-02 -0.668643
2019-11-07 07:40:03,426 train 100 1.734428e-02 -0.676578
2019-11-07 07:40:13,189 train 150 1.749860e-02 -0.643006
2019-11-07 07:40:22,969 train 200 1.740587e-02 -0.710958
2019-11-07 07:40:32,748 train 250 1.739851e-02 -0.724020
2019-11-07 07:40:42,527 train 300 1.740241e-02 -0.742366
2019-11-07 07:40:52,313 train 350 1.744755e-02 -0.685160
2019-11-07 07:41:02,082 train 400 1.747814e-02 -0.679444
2019-11-07 07:41:11,857 train 450 1.747067e-02 -0.791924
2019-11-07 07:41:21,650 train 500 1.745956e-02 -0.817697
2019-11-07 07:41:31,422 train 550 1.748231e-02 -0.826929
2019-11-07 07:41:41,204 train 600 1.747644e-02 -0.824827
2019-11-07 07:41:50,994 train 650 1.745426e-02 -0.819825
2019-11-07 07:42:00,778 train 700 1.744456e-02 -0.793823
2019-11-07 07:42:10,564 train 750 1.746749e-02 -0.782253
2019-11-07 07:42:20,342 train 800 1.747366e-02 -0.759345
2019-11-07 07:42:30,123 train 850 1.749187e-02 -0.772668
2019-11-07 07:42:33,046 training loss; R2: 1.747717e-02 -0.766370
2019-11-07 07:42:33,728 valid 000 1.747922e-02 -1.143532
2019-11-07 07:42:43,168 valid 050 1.825115e-02 -1.294693
2019-11-07 07:42:51,541 validation loss; R2: 1.832869e-02 -1.188322
2019-11-07 07:42:51,608 epoch 418 lr 1.000000e-05
2019-11-07 07:42:52,403 train 000 1.688692e-02 -0.049458
2019-11-07 07:43:02,150 train 050 1.754330e-02 -0.664739
2019-11-07 07:43:11,906 train 100 1.753605e-02 -0.722753
2019-11-07 07:43:21,703 train 150 1.760590e-02 -0.746881
2019-11-07 07:43:31,500 train 200 1.747782e-02 -0.674335
2019-11-07 07:43:41,307 train 250 1.740673e-02 -0.661431
2019-11-07 07:43:51,113 train 300 1.741731e-02 -0.679728
2019-11-07 07:44:00,922 train 350 1.739924e-02 -0.727570
2019-11-07 07:44:10,741 train 400 1.740949e-02 -0.729835
2019-11-07 07:44:20,525 train 450 1.741154e-02 -0.786770
2019-11-07 07:44:30,314 train 500 1.742017e-02 -0.812770
2019-11-07 07:44:40,120 train 550 1.744197e-02 -0.805251
2019-11-07 07:44:49,922 train 600 1.743445e-02 -0.788689
2019-11-07 07:44:59,723 train 650 1.741477e-02 -0.779543
2019-11-07 07:45:09,523 train 700 1.740616e-02 -0.782587
2019-11-07 07:45:19,334 train 750 1.740259e-02 -1.019063
2019-11-07 07:45:29,147 train 800 1.742216e-02 -0.984225
2019-11-07 07:45:38,952 train 850 1.743343e-02 -0.983074
2019-11-07 07:45:41,877 training loss; R2: 1.743266e-02 -0.975965
2019-11-07 07:45:42,523 valid 000 1.604708e-02 -0.128428
2019-11-07 07:45:51,913 valid 050 1.765259e-02 -1.146865
2019-11-07 07:46:00,355 validation loss; R2: 1.763562e-02 -1.491077
2019-11-07 07:46:00,415 epoch 419 lr 1.000000e-05
2019-11-07 07:46:01,180 train 000 1.569932e-02 0.057884
2019-11-07 07:46:10,920 train 050 1.722735e-02 -2.192076
2019-11-07 07:46:20,683 train 100 1.710835e-02 -1.410427
2019-11-07 07:46:30,479 train 150 1.719152e-02 -1.288792
2019-11-07 07:46:40,271 train 200 1.723471e-02 -1.140572
2019-11-07 07:46:50,071 train 250 1.732991e-02 -1.048567
2019-11-07 07:46:59,858 train 300 1.735537e-02 -0.994409
2019-11-07 07:47:09,663 train 350 1.735441e-02 -0.978704
2019-11-07 07:47:19,459 train 400 1.736935e-02 -0.992024
2019-11-07 07:47:29,245 train 450 1.740725e-02 -0.956203
2019-11-07 07:47:39,029 train 500 1.737750e-02 -0.945114
2019-11-07 07:47:48,824 train 550 1.738380e-02 -0.906672
2019-11-07 07:47:58,608 train 600 1.739110e-02 -0.889422
2019-11-07 07:48:08,400 train 650 1.737438e-02 -0.869661
2019-11-07 07:48:18,182 train 700 1.737891e-02 -0.916204
2019-11-07 07:48:27,984 train 750 1.738258e-02 -0.884735
2019-11-07 07:48:37,773 train 800 1.740631e-02 -0.885928
2019-11-07 07:48:47,561 train 850 1.740338e-02 -0.880784
2019-11-07 07:48:50,514 training loss; R2: 1.739455e-02 -0.879841
2019-11-07 07:48:51,212 valid 000 2.083327e-02 -0.458062
2019-11-07 07:49:00,621 valid 050 1.845856e-02 -19.217116
2019-11-07 07:49:08,943 validation loss; R2: 1.844171e-02 -12.258481
2019-11-07 07:49:09,020 epoch 420 lr 1.000000e-05
2019-11-07 07:49:09,799 train 000 2.162268e-02 -0.230459
2019-11-07 07:49:19,538 train 050 1.753977e-02 -0.866304
2019-11-07 07:49:29,286 train 100 1.750239e-02 -0.800903
2019-11-07 07:49:39,028 train 150 1.751019e-02 -0.963355
2019-11-07 07:49:48,816 train 200 1.758384e-02 -0.935390
2019-11-07 07:49:58,598 train 250 1.757421e-02 -0.875582
2019-11-07 07:50:08,374 train 300 1.757132e-02 -0.852782
2019-11-07 07:50:18,157 train 350 1.752987e-02 -0.825436
2019-11-07 07:50:27,944 train 400 1.744581e-02 -0.815864
2019-11-07 07:50:37,727 train 450 1.742754e-02 -0.833235
2019-11-07 07:50:47,500 train 500 1.743737e-02 -0.798320
2019-11-07 07:50:57,286 train 550 1.742683e-02 -0.840233
2019-11-07 07:51:07,077 train 600 1.744000e-02 -0.820622
2019-11-07 07:51:16,857 train 650 1.744613e-02 -0.809299
2019-11-07 07:51:26,653 train 700 1.746431e-02 -0.813531
2019-11-07 07:51:36,437 train 750 1.748553e-02 -0.807833
2019-11-07 07:51:46,220 train 800 1.746628e-02 -0.795039
2019-11-07 07:51:55,995 train 850 1.745983e-02 -0.794464
2019-11-07 07:51:58,948 training loss; R2: 1.745404e-02 -0.790712
2019-11-07 07:51:59,623 valid 000 1.828440e-02 -4.305263
2019-11-07 07:52:09,051 valid 050 1.904192e-02 -1.074163
2019-11-07 07:52:17,464 validation loss; R2: 1.891014e-02 -0.966766
2019-11-07 07:52:17,545 epoch 421 lr 1.000000e-05
2019-11-07 07:52:18,373 train 000 1.924605e-02 -0.470455
2019-11-07 07:52:28,095 train 050 1.775024e-02 -0.608810
2019-11-07 07:52:37,857 train 100 1.750945e-02 -0.585656
2019-11-07 07:52:47,636 train 150 1.753546e-02 -0.667358
2019-11-07 07:52:57,416 train 200 1.764493e-02 -0.743746
2019-11-07 07:53:07,209 train 250 1.757045e-02 -0.725625
2019-11-07 07:53:17,019 train 300 1.758114e-02 -0.718362
2019-11-07 07:53:26,820 train 350 1.752009e-02 -0.694304
2019-11-07 07:53:36,613 train 400 1.750021e-02 -0.702503
2019-11-07 07:53:46,404 train 450 1.743719e-02 -0.706905
2019-11-07 07:53:56,195 train 500 1.738491e-02 -0.722105
2019-11-07 07:54:05,979 train 550 1.731626e-02 -0.735115
2019-11-07 07:54:15,769 train 600 1.733138e-02 -0.737949
2019-11-07 07:54:25,551 train 650 1.732417e-02 -0.716938
2019-11-07 07:54:35,329 train 700 1.731876e-02 -0.722465
2019-11-07 07:54:45,102 train 750 1.736069e-02 -0.717628
2019-11-07 07:54:54,886 train 800 1.738921e-02 -0.710862
2019-11-07 07:55:04,667 train 850 1.740438e-02 -0.728270
2019-11-07 07:55:07,593 training loss; R2: 1.739879e-02 -0.730505
2019-11-07 07:55:08,286 valid 000 1.586339e-02 -15.755801
2019-11-07 07:55:17,717 valid 050 1.717058e-02 -1.160423
2019-11-07 07:55:26,039 validation loss; R2: 1.727867e-02 -1.095341
2019-11-07 07:55:26,105 epoch 422 lr 1.000000e-05
2019-11-07 07:55:26,840 train 000 1.774831e-02 -0.238684
2019-11-07 07:55:36,605 train 050 1.744568e-02 -0.735941
2019-11-07 07:55:46,383 train 100 1.720939e-02 -0.946905
2019-11-07 07:55:56,168 train 150 1.723549e-02 -0.872047
2019-11-07 07:56:05,960 train 200 1.729574e-02 -0.797744
2019-11-07 07:56:15,758 train 250 1.732819e-02 -0.759831
2019-11-07 07:56:25,578 train 300 1.731918e-02 -0.774242
2019-11-07 07:56:35,393 train 350 1.739439e-02 -0.759888
2019-11-07 07:56:45,220 train 400 1.740576e-02 -0.767851
2019-11-07 07:56:55,043 train 450 1.737808e-02 -0.790134
2019-11-07 07:57:04,868 train 500 1.739346e-02 -0.778429
2019-11-07 07:57:14,683 train 550 1.735874e-02 -0.768082
2019-11-07 07:57:24,506 train 600 1.734712e-02 -0.743439
2019-11-07 07:57:34,307 train 650 1.736283e-02 -0.787289
2019-11-07 07:57:44,115 train 700 1.733992e-02 -1.596806
2019-11-07 07:57:53,911 train 750 1.734560e-02 -1.542380
2019-11-07 07:58:03,719 train 800 1.734644e-02 -1.494448
2019-11-07 07:58:13,511 train 850 1.735830e-02 -1.441535
2019-11-07 07:58:16,437 training loss; R2: 1.735260e-02 -1.433057
2019-11-07 07:58:17,106 valid 000 1.488504e-02 -0.908544
2019-11-07 07:58:26,504 valid 050 1.738937e-02 -3.073831
2019-11-07 07:58:34,864 validation loss; R2: 1.726313e-02 -2.051969
2019-11-07 07:58:34,931 epoch 423 lr 1.000000e-05
2019-11-07 07:58:35,692 train 000 1.769516e-02 -0.607579
2019-11-07 07:58:45,452 train 050 1.729433e-02 -0.836490
2019-11-07 07:58:55,214 train 100 1.745449e-02 -0.823524
2019-11-07 07:59:04,977 train 150 1.740355e-02 -0.719992
2019-11-07 07:59:14,773 train 200 1.731061e-02 -0.685480
2019-11-07 07:59:24,846 train 250 1.732376e-02 -0.849198
2019-11-07 07:59:35,032 train 300 1.735835e-02 -0.808275
2019-11-07 07:59:45,232 train 350 1.736021e-02 -0.776384
2019-11-07 07:59:55,429 train 400 1.736909e-02 -0.795304
2019-11-07 08:00:05,610 train 450 1.737903e-02 -0.780713
2019-11-07 08:00:15,788 train 500 1.739543e-02 -0.818719
2019-11-07 08:00:25,967 train 550 1.739033e-02 -0.805384
2019-11-07 08:00:36,158 train 600 1.740037e-02 -0.800884
2019-11-07 08:00:46,342 train 650 1.739646e-02 -0.799336
2019-11-07 08:00:56,511 train 700 1.736982e-02 -0.782903
2019-11-07 08:01:06,697 train 750 1.736946e-02 -0.789538
2019-11-07 08:01:16,868 train 800 1.738044e-02 -0.842468
2019-11-07 08:01:27,042 train 850 1.737640e-02 -0.824020
2019-11-07 08:01:30,092 training loss; R2: 1.738552e-02 -0.813374
2019-11-07 08:01:30,737 valid 000 2.109840e-02 -0.289525
2019-11-07 08:01:40,192 valid 050 1.808906e-02 -1.333313
2019-11-07 08:01:48,573 validation loss; R2: 1.801927e-02 -1.337361
2019-11-07 08:01:48,647 epoch 424 lr 1.000000e-05
2019-11-07 08:01:49,391 train 000 2.075678e-02 0.095724
2019-11-07 08:01:59,124 train 050 1.746860e-02 -0.587698
2019-11-07 08:02:08,861 train 100 1.726581e-02 -0.715669
2019-11-07 08:02:18,644 train 150 1.731024e-02 -1.038050
2019-11-07 08:02:28,427 train 200 1.730856e-02 -0.976412
2019-11-07 08:02:38,243 train 250 1.732337e-02 -0.936609
2019-11-07 08:02:48,051 train 300 1.745960e-02 -0.915561
2019-11-07 08:02:57,857 train 350 1.745959e-02 -0.883040
2019-11-07 08:03:07,673 train 400 1.746120e-02 -0.845191
2019-11-07 08:03:17,498 train 450 1.744276e-02 -3.696184
2019-11-07 08:03:27,307 train 500 1.745870e-02 -3.409134
2019-11-07 08:03:37,115 train 550 1.746262e-02 -3.179219
2019-11-07 08:03:46,923 train 600 1.746693e-02 -2.986159
2019-11-07 08:03:56,727 train 650 1.747391e-02 -2.809220
2019-11-07 08:04:06,534 train 700 1.746693e-02 -2.652519
2019-11-07 08:04:16,349 train 750 1.746487e-02 -2.522921
2019-11-07 08:04:26,160 train 800 1.744958e-02 -2.392316
2019-11-07 08:04:35,962 train 850 1.742535e-02 -2.304836
2019-11-07 08:04:38,886 training loss; R2: 1.741889e-02 -2.277556
2019-11-07 08:04:39,488 valid 000 1.825878e-02 -4.327354
2019-11-07 08:04:48,975 valid 050 1.737309e-02 -1.119705
2019-11-07 08:04:57,354 validation loss; R2: 1.757982e-02 -1.078494
2019-11-07 08:04:57,414 epoch 425 lr 1.000000e-05
2019-11-07 08:04:58,197 train 000 1.906764e-02 -0.168365
2019-11-07 08:05:07,939 train 050 1.741442e-02 -1.120068
2019-11-07 08:05:17,693 train 100 1.742567e-02 -0.873020
2019-11-07 08:05:27,466 train 150 1.746073e-02 -0.844822
2019-11-07 08:05:37,270 train 200 1.742278e-02 -0.831630
2019-11-07 08:05:47,088 train 250 1.736504e-02 -0.848884
2019-11-07 08:05:56,896 train 300 1.740780e-02 -0.829400
2019-11-07 08:06:06,709 train 350 1.738182e-02 -0.803077
2019-11-07 08:06:16,525 train 400 1.733218e-02 -0.815472
2019-11-07 08:06:26,336 train 450 1.734711e-02 -0.794859
2019-11-07 08:06:36,151 train 500 1.736131e-02 -0.826747
2019-11-07 08:06:45,963 train 550 1.735368e-02 -0.833713
2019-11-07 08:06:55,775 train 600 1.736859e-02 -0.830776
2019-11-07 08:07:05,595 train 650 1.738491e-02 -0.825558
2019-11-07 08:07:15,422 train 700 1.739857e-02 -0.804109
2019-11-07 08:07:25,248 train 750 1.737952e-02 -0.790211
2019-11-07 08:07:35,060 train 800 1.736056e-02 -0.793655
2019-11-07 08:07:44,889 train 850 1.735677e-02 -0.790042
2019-11-07 08:07:47,820 training loss; R2: 1.736116e-02 -0.794785
2019-11-07 08:07:48,441 valid 000 1.648513e-02 -0.634137
2019-11-07 08:07:57,837 valid 050 1.849250e-02 -1.517305
2019-11-07 08:08:06,155 validation loss; R2: 1.841915e-02 -1.563974
2019-11-07 08:08:06,220 epoch 426 lr 1.000000e-05
2019-11-07 08:08:06,956 train 000 1.806618e-02 -1.262007
2019-11-07 08:08:16,721 train 050 1.744391e-02 -0.757499
2019-11-07 08:08:26,503 train 100 1.733959e-02 -0.840620
2019-11-07 08:08:36,295 train 150 1.721329e-02 -0.788031
2019-11-07 08:08:46,104 train 200 1.724041e-02 -0.759444
2019-11-07 08:08:55,918 train 250 1.719658e-02 -0.740101
2019-11-07 08:09:05,745 train 300 1.726217e-02 -0.787626
2019-11-07 08:09:15,558 train 350 1.728529e-02 -0.820328
2019-11-07 08:09:25,378 train 400 1.728285e-02 -0.840763
2019-11-07 08:09:35,201 train 450 1.731981e-02 -0.806085
2019-11-07 08:09:45,024 train 500 1.729055e-02 -0.798919
2019-11-07 08:09:54,846 train 550 1.729521e-02 -0.799896
2019-11-07 08:10:04,673 train 600 1.732077e-02 -0.774771
2019-11-07 08:10:14,501 train 650 1.730833e-02 -0.776206
2019-11-07 08:10:24,319 train 700 1.730434e-02 -0.766005
2019-11-07 08:10:34,139 train 750 1.729490e-02 -0.820955
2019-11-07 08:10:43,959 train 800 1.729236e-02 -0.827809
2019-11-07 08:10:53,778 train 850 1.732321e-02 -0.814933
2019-11-07 08:10:56,709 training loss; R2: 1.732886e-02 -0.821400
2019-11-07 08:10:57,331 valid 000 1.681708e-02 -0.080608
2019-11-07 08:11:06,778 valid 050 1.772497e-02 -0.949987
2019-11-07 08:11:15,097 validation loss; R2: 1.789948e-02 -1.028955
2019-11-07 08:11:15,163 epoch 427 lr 1.000000e-05
2019-11-07 08:11:15,894 train 000 1.370811e-02 -0.432179
2019-11-07 08:11:25,676 train 050 1.684231e-02 -0.620290
2019-11-07 08:11:35,441 train 100 1.718494e-02 -0.746193
2019-11-07 08:11:45,201 train 150 1.729157e-02 -0.751329
2019-11-07 08:11:54,986 train 200 1.723310e-02 -0.746981
2019-11-07 08:12:04,773 train 250 1.738242e-02 -0.808518
2019-11-07 08:12:14,552 train 300 1.736286e-02 -0.800801
2019-11-07 08:12:24,348 train 350 1.735160e-02 -0.761898
2019-11-07 08:12:34,138 train 400 1.740503e-02 -0.749934
2019-11-07 08:12:43,933 train 450 1.744980e-02 -0.736299
2019-11-07 08:12:53,728 train 500 1.748367e-02 -0.713025
2019-11-07 08:13:03,510 train 550 1.752377e-02 -0.715715
2019-11-07 08:13:13,299 train 600 1.750160e-02 -0.999484
2019-11-07 08:13:23,087 train 650 1.746511e-02 -0.982971
2019-11-07 08:13:32,887 train 700 1.745804e-02 -0.948370
2019-11-07 08:13:42,673 train 750 1.747449e-02 -1.005886
2019-11-07 08:13:52,455 train 800 1.748121e-02 -1.005417
2019-11-07 08:14:02,231 train 850 1.747742e-02 -0.990438
2019-11-07 08:14:05,185 training loss; R2: 1.746062e-02 -0.983608
2019-11-07 08:14:05,819 valid 000 1.907206e-02 -1.348390
2019-11-07 08:14:15,232 valid 050 1.776060e-02 -2.043796
2019-11-07 08:14:23,533 validation loss; R2: 1.798249e-02 -1.535476
2019-11-07 08:14:23,612 epoch 428 lr 1.000000e-05
2019-11-07 08:14:24,398 train 000 1.566738e-02 -3.983469
2019-11-07 08:14:34,241 train 050 1.697614e-02 -1.020520
2019-11-07 08:14:44,024 train 100 1.694074e-02 -0.768583
2019-11-07 08:14:53,843 train 150 1.698802e-02 -0.792284
2019-11-07 08:15:03,651 train 200 1.712265e-02 -0.773190
2019-11-07 08:15:13,458 train 250 1.720976e-02 -0.764853
2019-11-07 08:15:23,259 train 300 1.724842e-02 -0.765003
2019-11-07 08:15:33,073 train 350 1.728348e-02 -0.758644
2019-11-07 08:15:42,866 train 400 1.728885e-02 -0.739729
2019-11-07 08:15:52,687 train 450 1.729642e-02 -0.763601
2019-11-07 08:16:02,502 train 500 1.734386e-02 -0.798939
2019-11-07 08:16:12,314 train 550 1.735035e-02 -0.781563
2019-11-07 08:16:22,119 train 600 1.736344e-02 -0.782667
2019-11-07 08:16:31,946 train 650 1.733918e-02 -0.781404
2019-11-07 08:16:41,754 train 700 1.734829e-02 -0.772053
2019-11-07 08:16:51,574 train 750 1.735322e-02 -0.773856
2019-11-07 08:17:01,392 train 800 1.736521e-02 -0.771003
2019-11-07 08:17:11,203 train 850 1.737114e-02 -0.767563
2019-11-07 08:17:14,133 training loss; R2: 1.736289e-02 -0.761206
2019-11-07 08:17:14,835 valid 000 1.596462e-02 -5.466039
2019-11-07 08:17:24,179 valid 050 1.699115e-02 -1.020653
2019-11-07 08:17:32,492 validation loss; R2: 1.691939e-02 -0.972089
2019-11-07 08:17:32,569 epoch 429 lr 1.000000e-05
2019-11-07 08:17:33,290 train 000 1.921546e-02 -0.192400
2019-11-07 08:17:43,042 train 050 1.757793e-02 -0.724800
2019-11-07 08:17:52,796 train 100 1.763163e-02 -0.627499
2019-11-07 08:18:02,572 train 150 1.753878e-02 -0.631485
2019-11-07 08:18:12,339 train 200 1.751563e-02 -0.630394
2019-11-07 08:18:22,116 train 250 1.745025e-02 -0.633530
2019-11-07 08:18:31,908 train 300 1.740845e-02 -1.546860
2019-11-07 08:18:41,695 train 350 1.738249e-02 -1.447699
2019-11-07 08:18:51,473 train 400 1.736053e-02 -1.466232
2019-11-07 08:19:01,249 train 450 1.736271e-02 -1.388001
2019-11-07 08:19:11,024 train 500 1.734491e-02 -1.349290
2019-11-07 08:19:20,797 train 550 1.737455e-02 -1.294116
2019-11-07 08:19:30,574 train 600 1.741418e-02 -1.241376
2019-11-07 08:19:40,355 train 650 1.743044e-02 -1.214719
2019-11-07 08:19:50,145 train 700 1.743795e-02 -1.177149
2019-11-07 08:19:59,962 train 750 1.742951e-02 -1.132055
2019-11-07 08:20:09,776 train 800 1.742379e-02 -1.100296
2019-11-07 08:20:19,585 train 850 1.742241e-02 -1.094248
2019-11-07 08:20:22,517 training loss; R2: 1.742806e-02 -1.090690
2019-11-07 08:20:23,106 valid 000 1.692647e-02 -1.114998
2019-11-07 08:20:32,585 valid 050 1.743763e-02 -1.185862
2019-11-07 08:20:40,910 validation loss; R2: 1.721560e-02 -1.153954
2019-11-07 08:20:40,974 epoch 430 lr 1.000000e-05
2019-11-07 08:20:41,727 train 000 1.691442e-02 -2.176282
2019-11-07 08:20:51,510 train 050 1.785354e-02 -0.585527
2019-11-07 08:21:01,316 train 100 1.758288e-02 -0.747149
2019-11-07 08:21:11,142 train 150 1.761302e-02 -0.748451
2019-11-07 08:21:20,984 train 200 1.749601e-02 -0.757788
2019-11-07 08:21:30,825 train 250 1.746680e-02 -0.772444
2019-11-07 08:21:40,687 train 300 1.748132e-02 -0.772551
2019-11-07 08:21:50,510 train 350 1.742846e-02 -0.777932
2019-11-07 08:22:00,322 train 400 1.744077e-02 -0.772981
2019-11-07 08:22:10,157 train 450 1.744325e-02 -0.760009
2019-11-07 08:22:19,983 train 500 1.744407e-02 -0.766005
2019-11-07 08:22:29,746 train 550 1.740415e-02 -0.752645
2019-11-07 08:22:39,502 train 600 1.736244e-02 -0.755804
2019-11-07 08:22:49,257 train 650 1.735706e-02 -0.743046
2019-11-07 08:22:59,023 train 700 1.734510e-02 -0.756877
2019-11-07 08:23:08,771 train 750 1.738432e-02 -0.738406
2019-11-07 08:23:18,542 train 800 1.741488e-02 -0.733525
2019-11-07 08:23:28,297 train 850 1.740122e-02 -0.729812
2019-11-07 08:23:31,245 training loss; R2: 1.740526e-02 -0.722980
2019-11-07 08:23:31,888 valid 000 1.756876e-02 -0.594157
2019-11-07 08:23:41,299 valid 050 1.755246e-02 -1.185550
2019-11-07 08:23:49,606 validation loss; R2: 1.753402e-02 -1.210963
2019-11-07 08:23:49,673 epoch 431 lr 1.000000e-05
2019-11-07 08:23:50,455 train 000 1.948290e-02 -0.453417
2019-11-07 08:24:00,255 train 050 1.750922e-02 -0.833629
2019-11-07 08:24:10,031 train 100 1.717137e-02 -0.762395
2019-11-07 08:24:19,852 train 150 1.731909e-02 -0.709209
2019-11-07 08:24:29,673 train 200 1.743294e-02 -0.738923
2019-11-07 08:24:39,490 train 250 1.743938e-02 -0.670987
2019-11-07 08:24:49,306 train 300 1.742477e-02 -0.660737
2019-11-07 08:24:59,133 train 350 1.739572e-02 -0.692012
2019-11-07 08:25:08,956 train 400 1.738114e-02 -0.682594
2019-11-07 08:25:18,772 train 450 1.734395e-02 -0.686022
2019-11-07 08:25:28,603 train 500 1.731085e-02 -0.678784
2019-11-07 08:25:38,425 train 550 1.731119e-02 -0.800337
2019-11-07 08:25:48,275 train 600 1.732793e-02 -0.794973
2019-11-07 08:25:58,143 train 650 1.730414e-02 -0.787556
2019-11-07 08:26:08,008 train 700 1.733688e-02 -0.776644
2019-11-07 08:26:17,858 train 750 1.737737e-02 -0.773675
2019-11-07 08:26:27,713 train 800 1.738952e-02 -0.779523
2019-11-07 08:26:37,576 train 850 1.738145e-02 -0.797371
2019-11-07 08:26:40,504 training loss; R2: 1.738439e-02 -0.791638
2019-11-07 08:26:41,223 valid 000 1.943261e-02 -0.018638
2019-11-07 08:26:50,606 valid 050 1.745032e-02 -1.163255
2019-11-07 08:26:58,977 validation loss; R2: 1.763009e-02 -1.159708
2019-11-07 08:26:59,056 epoch 432 lr 1.000000e-05
2019-11-07 08:26:59,841 train 000 1.897847e-02 -0.212310
2019-11-07 08:27:09,607 train 050 1.739955e-02 -0.763881
2019-11-07 08:27:19,341 train 100 1.736332e-02 -0.746319
2019-11-07 08:27:29,124 train 150 1.740378e-02 -0.676758
2019-11-07 08:27:38,891 train 200 1.737415e-02 -0.731129
2019-11-07 08:27:48,659 train 250 1.744846e-02 -0.763305
2019-11-07 08:27:58,437 train 300 1.739040e-02 -0.759835
2019-11-07 08:28:08,211 train 350 1.740972e-02 -0.769594
2019-11-07 08:28:18,002 train 400 1.742336e-02 -0.746204
2019-11-07 08:28:27,776 train 450 1.739572e-02 -0.744333
2019-11-07 08:28:37,551 train 500 1.738827e-02 -0.752224
2019-11-07 08:28:47,329 train 550 1.737609e-02 -0.732207
2019-11-07 08:28:57,101 train 600 1.739633e-02 -0.743844
2019-11-07 08:29:06,877 train 650 1.738799e-02 -0.736555
2019-11-07 08:29:16,651 train 700 1.738608e-02 -0.733621
2019-11-07 08:29:26,434 train 750 1.740575e-02 -0.727771
2019-11-07 08:29:36,207 train 800 1.739315e-02 -0.727940
2019-11-07 08:29:45,976 train 850 1.739965e-02 -0.735394
2019-11-07 08:29:48,896 training loss; R2: 1.739530e-02 -0.737582
2019-11-07 08:29:49,613 valid 000 1.870610e-02 -0.737467
2019-11-07 08:29:58,975 valid 050 1.798433e-02 -1.199418
2019-11-07 08:30:07,405 validation loss; R2: 1.777935e-02 -1.268496
2019-11-07 08:30:07,469 epoch 433 lr 1.000000e-05
2019-11-07 08:30:08,246 train 000 1.759572e-02 -0.093593
2019-11-07 08:30:17,966 train 050 1.745929e-02 -0.471753
2019-11-07 08:30:27,715 train 100 1.756835e-02 -0.529562
2019-11-07 08:30:37,496 train 150 1.743635e-02 -0.687872
2019-11-07 08:30:47,271 train 200 1.738900e-02 -0.638686
2019-11-07 08:30:57,043 train 250 1.733354e-02 -0.674577
2019-11-07 08:31:06,815 train 300 1.729654e-02 -0.664449
2019-11-07 08:31:16,604 train 350 1.733358e-02 -0.678357
2019-11-07 08:31:26,389 train 400 1.733584e-02 -0.668935
2019-11-07 08:31:36,189 train 450 1.733170e-02 -0.697504
2019-11-07 08:31:45,969 train 500 1.733771e-02 -0.710307
2019-11-07 08:31:55,751 train 550 1.734927e-02 -0.707741
2019-11-07 08:32:05,526 train 600 1.737285e-02 -0.711415
2019-11-07 08:32:15,291 train 650 1.736825e-02 -0.715036
2019-11-07 08:32:25,088 train 700 1.738321e-02 -0.748916
2019-11-07 08:32:34,877 train 750 1.738654e-02 -0.735164
2019-11-07 08:32:44,676 train 800 1.740108e-02 -0.754535
2019-11-07 08:32:54,472 train 850 1.740498e-02 -0.739118
2019-11-07 08:32:57,398 training loss; R2: 1.739732e-02 -0.737343
2019-11-07 08:32:58,052 valid 000 1.910715e-02 -0.888968
2019-11-07 08:33:07,454 valid 050 1.729683e-02 -1.120618
2019-11-07 08:33:15,814 validation loss; R2: 1.740324e-02 -1.262482
2019-11-07 08:33:15,880 epoch 434 lr 1.000000e-05
2019-11-07 08:33:16,658 train 000 1.460021e-02 -1.429916
2019-11-07 08:33:26,397 train 050 1.656794e-02 -0.746110
2019-11-07 08:33:36,167 train 100 1.690433e-02 -0.636257
2019-11-07 08:33:45,951 train 150 1.710386e-02 -0.674863
2019-11-07 08:33:55,736 train 200 1.718443e-02 -0.663728
2019-11-07 08:34:05,525 train 250 1.725105e-02 -0.648846
2019-11-07 08:34:15,305 train 300 1.723308e-02 -0.639951
2019-11-07 08:34:25,083 train 350 1.727584e-02 -0.653839
2019-11-07 08:34:34,851 train 400 1.726078e-02 -0.665179
2019-11-07 08:34:44,619 train 450 1.724892e-02 -0.674615
2019-11-07 08:34:54,388 train 500 1.726151e-02 -0.682939
2019-11-07 08:35:04,161 train 550 1.730173e-02 -0.701293
2019-11-07 08:35:13,924 train 600 1.730941e-02 -0.710141
2019-11-07 08:35:23,703 train 650 1.730323e-02 -0.762990
2019-11-07 08:35:33,481 train 700 1.732670e-02 -0.754835
2019-11-07 08:35:43,247 train 750 1.731312e-02 -0.743533
2019-11-07 08:35:53,029 train 800 1.732300e-02 -0.741846
2019-11-07 08:36:02,807 train 850 1.732068e-02 -0.736166
2019-11-07 08:36:05,728 training loss; R2: 1.732251e-02 -0.733140
2019-11-07 08:36:06,423 valid 000 2.051508e-02 -1.091788
2019-11-07 08:36:15,861 valid 050 1.842503e-02 -1.047689
2019-11-07 08:36:24,204 validation loss; R2: 1.827364e-02 -1.255291
2019-11-07 08:36:24,272 epoch 435 lr 1.000000e-05
2019-11-07 08:36:25,032 train 000 1.812818e-02 -0.236929
2019-11-07 08:36:34,783 train 050 1.728529e-02 -0.934001
2019-11-07 08:36:44,555 train 100 1.765021e-02 -0.852075
2019-11-07 08:36:54,340 train 150 1.750830e-02 -0.825926
2019-11-07 08:37:04,123 train 200 1.752805e-02 -0.810890
2019-11-07 08:37:13,904 train 250 1.752426e-02 -0.759946
2019-11-07 08:37:23,685 train 300 1.750267e-02 -0.712229
2019-11-07 08:37:33,482 train 350 1.743573e-02 -0.723905
2019-11-07 08:37:43,269 train 400 1.735680e-02 -0.735762
2019-11-07 08:37:53,052 train 450 1.735430e-02 -0.720099
2019-11-07 08:38:02,840 train 500 1.734766e-02 -0.730342
2019-11-07 08:38:12,620 train 550 1.735346e-02 -0.740846
2019-11-07 08:38:22,414 train 600 1.735761e-02 -0.721342
2019-11-07 08:38:32,257 train 650 1.734523e-02 -0.757048
2019-11-07 08:38:42,072 train 700 1.735299e-02 -0.761163
2019-11-07 08:38:51,894 train 750 1.734885e-02 -0.748328
2019-11-07 08:39:01,709 train 800 1.734204e-02 -0.747966
2019-11-07 08:39:11,562 train 850 1.733909e-02 -0.738929
2019-11-07 08:39:14,538 training loss; R2: 1.734387e-02 -0.751539
2019-11-07 08:39:15,258 valid 000 1.691360e-02 -0.800240
2019-11-07 08:39:24,661 valid 050 1.793041e-02 -1.502387
2019-11-07 08:39:33,005 validation loss; R2: 1.791069e-02 -1.233785
2019-11-07 08:39:33,090 epoch 436 lr 1.000000e-05
2019-11-07 08:39:33,991 train 000 1.846659e-02 -0.218077
2019-11-07 08:39:43,703 train 050 1.739252e-02 -0.581923
2019-11-07 08:39:53,477 train 100 1.738731e-02 -0.621387
2019-11-07 08:40:03,283 train 150 1.732953e-02 -0.652767
2019-11-07 08:40:13,076 train 200 1.732201e-02 -0.725214
2019-11-07 08:40:23,078 train 250 1.740051e-02 -0.747548
2019-11-07 08:40:33,208 train 300 1.742846e-02 -0.744552
2019-11-07 08:40:43,005 train 350 1.744723e-02 -0.725035
2019-11-07 08:40:52,798 train 400 1.743985e-02 -0.712171
2019-11-07 08:41:02,597 train 450 1.741172e-02 -0.707136
2019-11-07 08:41:12,398 train 500 1.738890e-02 -0.714364
2019-11-07 08:41:22,198 train 550 1.738154e-02 -0.709057
2019-11-07 08:41:31,999 train 600 1.738219e-02 -0.733478
2019-11-07 08:41:41,790 train 650 1.735260e-02 -0.789837
2019-11-07 08:41:51,609 train 700 1.736233e-02 -0.800475
2019-11-07 08:42:01,432 train 750 1.737007e-02 -0.791023
2019-11-07 08:42:11,273 train 800 1.734759e-02 -0.788738
2019-11-07 08:42:21,099 train 850 1.731285e-02 -0.819412
2019-11-07 08:42:24,041 training loss; R2: 1.731787e-02 -0.816197
2019-11-07 08:42:24,722 valid 000 1.883802e-02 -2.927370
2019-11-07 08:42:34,089 valid 050 1.733218e-02 -1.080445
2019-11-07 08:42:42,406 validation loss; R2: 1.742429e-02 -1.004473
2019-11-07 08:42:42,476 epoch 437 lr 1.000000e-05
2019-11-07 08:42:43,235 train 000 1.461219e-02 -0.448136
2019-11-07 08:42:53,005 train 050 1.736259e-02 -0.910544
2019-11-07 08:43:02,808 train 100 1.738473e-02 -0.906225
2019-11-07 08:43:12,604 train 150 1.741606e-02 -0.858376
2019-11-07 08:43:22,422 train 200 1.732785e-02 -0.807090
2019-11-07 08:43:32,219 train 250 1.727550e-02 -0.812087
2019-11-07 08:43:42,025 train 300 1.728596e-02 -0.793166
2019-11-07 08:43:51,831 train 350 1.728925e-02 -0.777290
2019-11-07 08:44:01,633 train 400 1.729764e-02 -0.777080
2019-11-07 08:44:11,424 train 450 1.726762e-02 -0.772762
2019-11-07 08:44:21,219 train 500 1.725200e-02 -0.802740
2019-11-07 08:44:31,020 train 550 1.726305e-02 -0.818957
2019-11-07 08:44:40,825 train 600 1.726592e-02 -0.804715
2019-11-07 08:44:50,641 train 650 1.728454e-02 -0.806670
2019-11-07 08:45:00,457 train 700 1.727709e-02 -0.790244
2019-11-07 08:45:10,276 train 750 1.730442e-02 -0.767457
2019-11-07 08:45:20,106 train 800 1.731577e-02 -0.784954
2019-11-07 08:45:29,930 train 850 1.732692e-02 -0.794894
2019-11-07 08:45:32,868 training loss; R2: 1.732236e-02 -0.792405
2019-11-07 08:45:33,533 valid 000 1.627615e-02 -9.454338
2019-11-07 08:45:42,968 valid 050 1.663978e-02 -1.443155
2019-11-07 08:45:51,320 validation loss; R2: 1.675219e-02 -1.201388
2019-11-07 08:45:51,384 epoch 438 lr 1.000000e-05
2019-11-07 08:45:52,158 train 000 1.831891e-02 -0.842571
2019-11-07 08:46:01,909 train 050 1.717882e-02 -0.595723
2019-11-07 08:46:11,675 train 100 1.714836e-02 -0.614371
2019-11-07 08:46:21,452 train 150 1.738897e-02 -0.592662
2019-11-07 08:46:31,230 train 200 1.734730e-02 -0.587935
2019-11-07 08:46:41,017 train 250 1.732273e-02 -0.604460
2019-11-07 08:46:50,804 train 300 1.731202e-02 -0.641846
2019-11-07 08:47:00,614 train 350 1.733883e-02 -0.605993
2019-11-07 08:47:10,407 train 400 1.726351e-02 -0.646734
2019-11-07 08:47:20,188 train 450 1.724628e-02 -0.652774
2019-11-07 08:47:29,996 train 500 1.721547e-02 -0.655615
2019-11-07 08:47:39,802 train 550 1.722077e-02 -0.660836
2019-11-07 08:47:49,611 train 600 1.725667e-02 -0.774518
2019-11-07 08:47:59,412 train 650 1.726879e-02 -0.788318
2019-11-07 08:48:09,222 train 700 1.727242e-02 -0.783999
2019-11-07 08:48:19,029 train 750 1.729054e-02 -0.765975
2019-11-07 08:48:28,844 train 800 1.728827e-02 -0.763973
2019-11-07 08:48:38,667 train 850 1.730389e-02 -0.750408
2019-11-07 08:48:41,611 training loss; R2: 1.729771e-02 -0.754823
2019-11-07 08:48:42,267 valid 000 1.775263e-02 -5.366645
2019-11-07 08:48:51,689 valid 050 1.757594e-02 -1.502604
2019-11-07 08:49:00,012 validation loss; R2: 1.775379e-02 -1.233794
2019-11-07 08:49:00,097 epoch 439 lr 1.000000e-05
2019-11-07 08:49:00,884 train 000 1.779433e-02 -0.251053
2019-11-07 08:49:11,054 train 050 1.783030e-02 -0.664470
2019-11-07 08:49:21,246 train 100 1.748443e-02 -0.616664
2019-11-07 08:49:31,438 train 150 1.752272e-02 -0.778773
2019-11-07 08:49:41,608 train 200 1.737925e-02 -0.730655
2019-11-07 08:49:51,782 train 250 1.734135e-02 -0.704201
2019-11-07 08:50:01,935 train 300 1.729345e-02 -0.706613
2019-11-07 08:50:12,109 train 350 1.727783e-02 -0.709949
2019-11-07 08:50:22,289 train 400 1.722340e-02 -0.743704
2019-11-07 08:50:32,460 train 450 1.723765e-02 -0.748012
2019-11-07 08:50:42,610 train 500 1.720955e-02 -0.789313
2019-11-07 08:50:52,793 train 550 1.722297e-02 -0.800185
2019-11-07 08:51:02,976 train 600 1.724837e-02 -0.775936
2019-11-07 08:51:13,157 train 650 1.726538e-02 -0.787926
2019-11-07 08:51:23,367 train 700 1.728825e-02 -0.766620
2019-11-07 08:51:33,568 train 750 1.730038e-02 -0.775215
2019-11-07 08:51:43,770 train 800 1.731889e-02 -0.781237
2019-11-07 08:51:53,687 train 850 1.732389e-02 -0.784491
2019-11-07 08:51:56,618 training loss; R2: 1.731719e-02 -0.781138
2019-11-07 08:51:57,313 valid 000 2.034719e-02 -0.230913
2019-11-07 08:52:06,741 valid 050 1.743653e-02 -1.271528
2019-11-07 08:52:15,041 validation loss; R2: 1.725367e-02 -1.071982
2019-11-07 08:52:15,107 epoch 440 lr 1.000000e-05
2019-11-07 08:52:15,883 train 000 1.444914e-02 -0.444282
2019-11-07 08:52:25,646 train 050 1.774812e-02 -0.988425
2019-11-07 08:52:35,408 train 100 1.765575e-02 -0.803814
2019-11-07 08:52:45,195 train 150 1.748504e-02 -0.777708
2019-11-07 08:52:54,961 train 200 1.748385e-02 -0.819693
2019-11-07 08:53:04,741 train 250 1.753877e-02 -0.803387
2019-11-07 08:53:14,529 train 300 1.753999e-02 -0.795560
2019-11-07 08:53:24,311 train 350 1.752011e-02 -0.752908
2019-11-07 08:53:34,091 train 400 1.750201e-02 -0.766296
2019-11-07 08:53:43,884 train 450 1.747401e-02 -0.792096
2019-11-07 08:53:53,666 train 500 1.742731e-02 -0.806064
2019-11-07 08:54:03,473 train 550 1.740465e-02 -0.777129
2019-11-07 08:54:13,279 train 600 1.736707e-02 -0.777813
2019-11-07 08:54:23,087 train 650 1.735202e-02 -0.769335
2019-11-07 08:54:32,919 train 700 1.733141e-02 -0.758316
2019-11-07 08:54:42,727 train 750 1.732378e-02 -0.747162
2019-11-07 08:54:52,560 train 800 1.733562e-02 -0.742653
2019-11-07 08:55:02,384 train 850 1.732081e-02 -0.760566
2019-11-07 08:55:05,318 training loss; R2: 1.732390e-02 -0.763793
2019-11-07 08:55:05,917 valid 000 1.471103e-02 -1.580889
2019-11-07 08:55:15,385 valid 050 1.768171e-02 -1.152462
2019-11-07 08:55:23,734 validation loss; R2: 1.770301e-02 -1.078040
2019-11-07 08:55:23,800 epoch 441 lr 1.000000e-05
2019-11-07 08:55:24,590 train 000 1.583341e-02 -0.709460
2019-11-07 08:55:34,339 train 050 1.706238e-02 -0.566069
2019-11-07 08:55:44,114 train 100 1.706577e-02 -0.638356
2019-11-07 08:55:53,893 train 150 1.705426e-02 -0.724787
2019-11-07 08:56:03,675 train 200 1.707433e-02 -0.733549
2019-11-07 08:56:13,464 train 250 1.704793e-02 -0.752629
2019-11-07 08:56:23,243 train 300 1.712510e-02 -0.697546
2019-11-07 08:56:33,033 train 350 1.715425e-02 -0.710420
2019-11-07 08:56:42,830 train 400 1.719638e-02 -0.705513
2019-11-07 08:56:52,665 train 450 1.717789e-02 -0.714365
2019-11-07 08:57:02,486 train 500 1.720130e-02 -0.711738
2019-11-07 08:57:12,326 train 550 1.723512e-02 -0.732078
2019-11-07 08:57:22,118 train 600 1.725681e-02 -0.725476
2019-11-07 08:57:31,901 train 650 1.723996e-02 -0.729361
2019-11-07 08:57:41,695 train 700 1.725690e-02 -0.732107
2019-11-07 08:57:51,493 train 750 1.725011e-02 -0.728102
2019-11-07 08:58:01,295 train 800 1.727984e-02 -0.716722
2019-11-07 08:58:11,112 train 850 1.731319e-02 -0.708388
2019-11-07 08:58:14,075 training loss; R2: 1.732201e-02 -0.708024
2019-11-07 08:58:14,722 valid 000 1.828923e-02 -1.816519
2019-11-07 08:58:24,144 valid 050 1.796973e-02 -1.587607
2019-11-07 08:58:32,450 validation loss; R2: 1.773557e-02 -1.196807
2019-11-07 08:58:32,514 epoch 442 lr 1.000000e-05
2019-11-07 08:58:33,294 train 000 1.765885e-02 -0.698905
2019-11-07 08:58:43,082 train 050 1.702680e-02 -0.704892
2019-11-07 08:58:52,849 train 100 1.724171e-02 -0.806282
2019-11-07 08:59:02,628 train 150 1.730132e-02 -0.738194
2019-11-07 08:59:12,417 train 200 1.729338e-02 -0.730677
2019-11-07 08:59:22,193 train 250 1.740047e-02 -0.728439
2019-11-07 08:59:31,967 train 300 1.739910e-02 -0.708119
2019-11-07 08:59:41,772 train 350 1.737031e-02 -0.678280
2019-11-07 08:59:51,585 train 400 1.742414e-02 -0.680636
2019-11-07 09:00:01,395 train 450 1.740750e-02 -0.691451
2019-11-07 09:00:11,196 train 500 1.740267e-02 -0.715312
2019-11-07 09:00:20,994 train 550 1.740416e-02 -0.727653
2019-11-07 09:00:30,796 train 600 1.737769e-02 -0.760128
2019-11-07 09:00:40,619 train 650 1.741336e-02 -0.754972
2019-11-07 09:00:50,449 train 700 1.738528e-02 -0.750552
2019-11-07 09:01:00,281 train 750 1.740563e-02 -0.743323
2019-11-07 09:01:10,112 train 800 1.738832e-02 -0.752776
2019-11-07 09:01:19,957 train 850 1.736089e-02 -0.760945
2019-11-07 09:01:22,895 training loss; R2: 1.735372e-02 -0.756570
2019-11-07 09:01:23,518 valid 000 1.658846e-02 -0.935596
2019-11-07 09:01:33,054 valid 050 1.757287e-02 -0.874256
2019-11-07 09:01:41,382 validation loss; R2: 1.756991e-02 -0.951427
2019-11-07 09:01:41,447 epoch 443 lr 1.000000e-05
2019-11-07 09:01:42,260 train 000 1.664751e-02 -1.057785
2019-11-07 09:01:52,010 train 050 1.723498e-02 -0.941933
2019-11-07 09:02:01,764 train 100 1.709498e-02 -0.808881
2019-11-07 09:02:11,533 train 150 1.708225e-02 -0.765355
2019-11-07 09:02:21,303 train 200 1.718605e-02 -0.759113
2019-11-07 09:02:31,077 train 250 1.729597e-02 -0.745455
2019-11-07 09:02:40,861 train 300 1.735006e-02 -0.784002
2019-11-07 09:02:50,657 train 350 1.738135e-02 -0.782112
2019-11-07 09:03:00,449 train 400 1.735261e-02 -0.769199
2019-11-07 09:03:10,283 train 450 1.736876e-02 -0.768009
2019-11-07 09:03:20,083 train 500 1.738656e-02 -0.845995
2019-11-07 09:03:29,883 train 550 1.739606e-02 -0.898395
2019-11-07 09:03:39,690 train 600 1.739016e-02 -0.886689
2019-11-07 09:03:49,803 train 650 1.739643e-02 -0.862583
2019-11-07 09:03:59,971 train 700 1.738492e-02 -0.867682
2019-11-07 09:04:09,889 train 750 1.738218e-02 -0.847819
2019-11-07 09:04:19,696 train 800 1.737307e-02 -0.834722
2019-11-07 09:04:29,509 train 850 1.738697e-02 -0.823623
2019-11-07 09:04:32,446 training loss; R2: 1.737944e-02 -0.821211
2019-11-07 09:04:33,097 valid 000 1.707520e-02 -0.472057
2019-11-07 09:04:42,584 valid 050 1.740936e-02 -1.218037
2019-11-07 09:04:50,930 validation loss; R2: 1.751040e-02 -1.357846
2019-11-07 09:04:50,993 epoch 444 lr 1.000000e-05
2019-11-07 09:04:51,753 train 000 1.601322e-02 -0.663917
2019-11-07 09:05:01,485 train 050 1.730351e-02 -0.797263
2019-11-07 09:05:11,243 train 100 1.739092e-02 -0.854498
2019-11-07 09:05:21,010 train 150 1.743374e-02 -0.854289
2019-11-07 09:05:30,779 train 200 1.741025e-02 -0.784743
2019-11-07 09:05:40,599 train 250 1.738056e-02 -0.767760
2019-11-07 09:05:50,421 train 300 1.735145e-02 -0.751592
2019-11-07 09:06:00,231 train 350 1.732900e-02 -0.723549
2019-11-07 09:06:10,028 train 400 1.728501e-02 -0.818187
2019-11-07 09:06:19,820 train 450 1.728395e-02 -0.789781
2019-11-07 09:06:29,624 train 500 1.728136e-02 -0.788405
2019-11-07 09:06:39,417 train 550 1.731953e-02 -0.769966
2019-11-07 09:06:49,218 train 600 1.734102e-02 -0.759438
2019-11-07 09:06:59,020 train 650 1.736264e-02 -0.787430
2019-11-07 09:07:08,833 train 700 1.737233e-02 -0.823302
2019-11-07 09:07:18,637 train 750 1.736153e-02 -0.804230
2019-11-07 09:07:28,445 train 800 1.734090e-02 -0.788527
2019-11-07 09:07:38,266 train 850 1.734730e-02 -0.788947
2019-11-07 09:07:41,200 training loss; R2: 1.734636e-02 -0.784955
2019-11-07 09:07:41,787 valid 000 1.426768e-02 -1.023892
2019-11-07 09:07:51,252 valid 050 1.617673e-02 -0.946481
2019-11-07 09:07:59,674 validation loss; R2: 1.621923e-02 -0.940501
2019-11-07 09:07:59,739 epoch 445 lr 1.000000e-05
2019-11-07 09:08:00,530 train 000 1.766764e-02 -0.507267
2019-11-07 09:08:10,264 train 050 1.773605e-02 -0.528584
2019-11-07 09:08:20,009 train 100 1.756144e-02 -0.628892
2019-11-07 09:08:29,766 train 150 1.743109e-02 -0.639852
2019-11-07 09:08:39,525 train 200 1.733919e-02 -0.638362
2019-11-07 09:08:49,296 train 250 1.734306e-02 -0.643543
2019-11-07 09:08:59,082 train 300 1.730344e-02 -0.695852
2019-11-07 09:09:08,864 train 350 1.729779e-02 -0.694738
2019-11-07 09:09:18,661 train 400 1.732223e-02 -0.717072
2019-11-07 09:09:28,452 train 450 1.730415e-02 -0.704538
2019-11-07 09:09:38,246 train 500 1.732829e-02 -0.737986
2019-11-07 09:09:48,041 train 550 1.729418e-02 -0.747707
2019-11-07 09:09:57,842 train 600 1.727344e-02 -0.766004
2019-11-07 09:10:07,646 train 650 1.729486e-02 -0.746869
2019-11-07 09:10:17,451 train 700 1.730134e-02 -0.743058
2019-11-07 09:10:27,283 train 750 1.733184e-02 -0.734407
2019-11-07 09:10:37,090 train 800 1.732896e-02 -0.724626
2019-11-07 09:10:46,889 train 850 1.733346e-02 -0.722689
2019-11-07 09:10:49,822 training loss; R2: 1.733102e-02 -0.719353
2019-11-07 09:10:50,495 valid 000 1.699787e-02 -1.338094
2019-11-07 09:10:59,892 valid 050 1.619098e-02 -1.145401
2019-11-07 09:11:08,281 validation loss; R2: 1.658941e-02 -1.168523
2019-11-07 09:11:08,346 epoch 446 lr 1.000000e-05
2019-11-07 09:11:09,131 train 000 1.770545e-02 -0.229088
2019-11-07 09:11:18,873 train 050 1.724404e-02 -0.777042
2019-11-07 09:11:28,632 train 100 1.747363e-02 -0.916460
2019-11-07 09:11:38,410 train 150 1.735995e-02 -1.045877
2019-11-07 09:11:48,185 train 200 1.743039e-02 -1.011876
2019-11-07 09:11:57,961 train 250 1.741880e-02 -0.970462
2019-11-07 09:12:07,748 train 300 1.738844e-02 -0.912710
2019-11-07 09:12:17,542 train 350 1.738457e-02 -0.870989
2019-11-07 09:12:27,338 train 400 1.740460e-02 -0.870746
2019-11-07 09:12:37,141 train 450 1.736276e-02 -0.859121
2019-11-07 09:12:46,941 train 500 1.733848e-02 -0.813585
2019-11-07 09:12:56,738 train 550 1.733352e-02 -0.831217
2019-11-07 09:13:06,545 train 600 1.733566e-02 -0.824152
2019-11-07 09:13:16,352 train 650 1.733632e-02 -0.814252
2019-11-07 09:13:26,156 train 700 1.731618e-02 -0.807389
2019-11-07 09:13:35,978 train 750 1.731551e-02 -0.787764
2019-11-07 09:13:45,782 train 800 1.729234e-02 -0.795630
2019-11-07 09:13:55,582 train 850 1.730465e-02 -0.780411
2019-11-07 09:13:58,509 training loss; R2: 1.730771e-02 -0.777559
2019-11-07 09:13:59,129 valid 000 1.636371e-02 -0.158967
2019-11-07 09:14:08,515 valid 050 1.680050e-02 -1.059994
2019-11-07 09:14:16,867 validation loss; R2: 1.701235e-02 -1.155307
2019-11-07 09:14:16,933 epoch 447 lr 1.000000e-05
2019-11-07 09:14:17,720 train 000 1.917242e-02 -0.500368
2019-11-07 09:14:27,447 train 050 1.779381e-02 -0.921153
2019-11-07 09:14:37,205 train 100 1.758897e-02 -0.686477
2019-11-07 09:14:46,977 train 150 1.767955e-02 -0.659974
2019-11-07 09:14:56,747 train 200 1.761631e-02 -0.672693
2019-11-07 09:15:06,543 train 250 1.747776e-02 -0.717553
2019-11-07 09:15:16,538 train 300 1.741050e-02 -0.683740
2019-11-07 09:15:26,732 train 350 1.737723e-02 -0.659573
2019-11-07 09:15:36,934 train 400 1.740335e-02 -0.681585
2019-11-07 09:15:47,126 train 450 1.735295e-02 -0.667387
2019-11-07 09:15:57,327 train 500 1.734658e-02 -0.694444
2019-11-07 09:16:07,515 train 550 1.735323e-02 -0.691136
2019-11-07 09:16:17,736 train 600 1.732093e-02 -0.703914
2019-11-07 09:16:27,933 train 650 1.734594e-02 -0.691278
2019-11-07 09:16:38,157 train 700 1.736550e-02 -0.697494
2019-11-07 09:16:48,362 train 750 1.735830e-02 -0.687311
2019-11-07 09:16:58,577 train 800 1.735344e-02 -0.688153
2019-11-07 09:17:08,788 train 850 1.737081e-02 -0.683589
2019-11-07 09:17:11,833 training loss; R2: 1.737925e-02 -0.686919
2019-11-07 09:17:12,470 valid 000 1.549930e-02 -0.232852
2019-11-07 09:17:21,874 valid 050 1.689180e-02 -0.897662
2019-11-07 09:17:30,180 validation loss; R2: 1.703830e-02 -1.246494
2019-11-07 09:17:30,247 epoch 448 lr 1.000000e-05
2019-11-07 09:17:30,994 train 000 1.685317e-02 -0.337068
2019-11-07 09:17:41,116 train 050 1.732272e-02 -0.731106
2019-11-07 09:17:51,063 train 100 1.726403e-02 -0.847389
2019-11-07 09:18:00,835 train 150 1.719057e-02 -0.760747
2019-11-07 09:18:10,606 train 200 1.718396e-02 -0.712173
2019-11-07 09:18:20,379 train 250 1.724392e-02 -0.731449
2019-11-07 09:18:30,160 train 300 1.727860e-02 -0.733902
2019-11-07 09:18:39,951 train 350 1.729659e-02 -0.706414
2019-11-07 09:18:49,752 train 400 1.735459e-02 -0.763609
2019-11-07 09:18:59,569 train 450 1.734171e-02 -0.749893
2019-11-07 09:19:09,367 train 500 1.732665e-02 -0.750489
2019-11-07 09:19:19,172 train 550 1.735868e-02 -0.749817
2019-11-07 09:19:28,978 train 600 1.740153e-02 -0.755184
2019-11-07 09:19:38,781 train 650 1.742296e-02 -0.752890
2019-11-07 09:19:48,600 train 700 1.739790e-02 -0.765443
2019-11-07 09:19:58,407 train 750 1.738736e-02 -0.774894
2019-11-07 09:20:08,209 train 800 1.739531e-02 -0.761980
2019-11-07 09:20:18,014 train 850 1.737200e-02 -0.759234
2019-11-07 09:20:20,944 training loss; R2: 1.736747e-02 -0.759436
2019-11-07 09:20:21,562 valid 000 1.509574e-02 -2.405545
2019-11-07 09:20:31,024 valid 050 1.715380e-02 -1.192163
2019-11-07 09:20:39,343 validation loss; R2: 1.704961e-02 -1.171827
2019-11-07 09:20:39,410 epoch 449 lr 1.000000e-05
2019-11-07 09:20:40,185 train 000 1.841211e-02 -0.904102
2019-11-07 09:20:49,914 train 050 1.718079e-02 -0.602921
2019-11-07 09:20:59,679 train 100 1.724937e-02 -0.663342
2019-11-07 09:21:09,458 train 150 1.726176e-02 -0.759614
2019-11-07 09:21:19,244 train 200 1.725542e-02 -0.806569
2019-11-07 09:21:29,028 train 250 1.717365e-02 -0.793065
2019-11-07 09:21:38,819 train 300 1.716807e-02 -0.964910
2019-11-07 09:21:48,618 train 350 1.723882e-02 -0.926176
2019-11-07 09:21:58,422 train 400 1.724925e-02 -0.916616
2019-11-07 09:22:08,229 train 450 1.723925e-02 -0.865487
2019-11-07 09:22:18,031 train 500 1.722902e-02 -0.852036
2019-11-07 09:22:27,831 train 550 1.725418e-02 -0.848006
2019-11-07 09:22:37,634 train 600 1.723596e-02 -0.840368
2019-11-07 09:22:47,441 train 650 1.724071e-02 -0.822621
2019-11-07 09:22:57,250 train 700 1.725802e-02 -0.805089
2019-11-07 09:23:07,055 train 750 1.723560e-02 -0.827132
2019-11-07 09:23:16,861 train 800 1.725234e-02 -0.809036
2019-11-07 09:23:26,681 train 850 1.724429e-02 -0.794204
2019-11-07 09:23:29,611 training loss; R2: 1.723376e-02 -0.793191
2019-11-07 09:23:30,282 valid 000 1.605050e-02 -1.420081
2019-11-07 09:23:39,649 valid 050 1.711283e-02 -0.966586
2019-11-07 09:23:47,978 validation loss; R2: 1.702983e-02 -0.809449
2019-11-07 09:23:48,049 epoch 450 lr 1.000000e-05
2019-11-07 09:23:48,763 train 000 1.696021e-02 -1.498754
2019-11-07 09:23:58,497 train 050 1.731065e-02 -0.723964
2019-11-07 09:24:08,260 train 100 1.731095e-02 -0.717764
2019-11-07 09:24:18,041 train 150 1.735313e-02 -0.783165
2019-11-07 09:24:27,824 train 200 1.731715e-02 -0.744995
2019-11-07 09:24:37,607 train 250 1.735855e-02 -0.760998
2019-11-07 09:24:47,382 train 300 1.733882e-02 -0.755405
2019-11-07 09:24:57,189 train 350 1.728733e-02 -0.741204
2019-11-07 09:25:07,004 train 400 1.733667e-02 -1.372934
2019-11-07 09:25:16,812 train 450 1.737041e-02 -1.291711
2019-11-07 09:25:26,617 train 500 1.732329e-02 -1.235855
2019-11-07 09:25:36,423 train 550 1.733404e-02 -1.205514
2019-11-07 09:25:46,223 train 600 1.729756e-02 -1.153108
2019-11-07 09:25:56,036 train 650 1.728416e-02 -1.108177
2019-11-07 09:26:05,834 train 700 1.726465e-02 -1.067026
2019-11-07 09:26:15,643 train 750 1.725516e-02 -1.064966
2019-11-07 09:26:25,457 train 800 1.727050e-02 -1.075734
2019-11-07 09:26:35,278 train 850 1.727326e-02 -1.069979
2019-11-07 09:26:38,213 training loss; R2: 1.727955e-02 -1.061571
2019-11-07 09:26:38,881 valid 000 1.861013e-02 -0.185048
2019-11-07 09:26:48,239 valid 050 1.780676e-02 -1.615885
2019-11-07 09:26:56,687 validation loss; R2: 1.785390e-02 -2.555150
2019-11-07 09:26:56,756 epoch 451 lr 1.000000e-05
2019-11-07 09:26:57,572 train 000 1.882599e-02 -0.434309
2019-11-07 09:27:07,328 train 050 1.741964e-02 -1.026461
2019-11-07 09:27:17,098 train 100 1.739287e-02 -0.794925
2019-11-07 09:27:26,892 train 150 1.739544e-02 -0.822301
2019-11-07 09:27:36,666 train 200 1.748048e-02 -0.758346
2019-11-07 09:27:46,461 train 250 1.743496e-02 -0.709496
2019-11-07 09:27:56,246 train 300 1.742661e-02 -0.744394
2019-11-07 09:28:06,042 train 350 1.742485e-02 -0.740903
2019-11-07 09:28:15,826 train 400 1.741624e-02 -0.773399
2019-11-07 09:28:25,620 train 450 1.739517e-02 -0.781810
2019-11-07 09:28:35,427 train 500 1.738130e-02 -49.758150
2019-11-07 09:28:45,240 train 550 1.736054e-02 -45.288291
2019-11-07 09:28:55,046 train 600 1.735791e-02 -41.587452
2019-11-07 09:29:04,865 train 650 1.735234e-02 -38.474732
2019-11-07 09:29:14,671 train 700 1.734096e-02 -35.783079
2019-11-07 09:29:24,486 train 750 1.732768e-02 -33.440845
2019-11-07 09:29:34,317 train 800 1.731410e-02 -31.406547
2019-11-07 09:29:44,128 train 850 1.730180e-02 -29.611582
2019-11-07 09:29:47,060 training loss; R2: 1.730636e-02 -29.117182
2019-11-07 09:29:47,757 valid 000 1.289224e-02 -0.851761
2019-11-07 09:29:57,144 valid 050 1.698124e-02 -0.966752
2019-11-07 09:30:05,474 validation loss; R2: 1.706333e-02 -1.119335
2019-11-07 09:30:05,540 epoch 452 lr 1.000000e-05
2019-11-07 09:30:06,323 train 000 1.871122e-02 -0.915874
2019-11-07 09:30:16,059 train 050 1.687340e-02 -0.840020
2019-11-07 09:30:25,820 train 100 1.692426e-02 -0.755187
2019-11-07 09:30:35,571 train 150 1.709708e-02 -0.799893
2019-11-07 09:30:45,330 train 200 1.715624e-02 -0.776793
2019-11-07 09:30:55,118 train 250 1.726113e-02 -0.804903
2019-11-07 09:31:04,912 train 300 1.728281e-02 -0.871490
2019-11-07 09:31:14,693 train 350 1.728017e-02 -0.942404
2019-11-07 09:31:24,495 train 400 1.726902e-02 -0.897947
2019-11-07 09:31:34,297 train 450 1.730345e-02 -0.859784
2019-11-07 09:31:44,094 train 500 1.727760e-02 -0.981846
2019-11-07 09:31:53,901 train 550 1.732028e-02 -0.965463
2019-11-07 09:32:03,702 train 600 1.731167e-02 -0.940648
2019-11-07 09:32:13,512 train 650 1.731005e-02 -0.908365
2019-11-07 09:32:23,329 train 700 1.729369e-02 -0.904684
2019-11-07 09:32:33,145 train 750 1.727445e-02 -0.911795
2019-11-07 09:32:42,942 train 800 1.728556e-02 -0.898386
2019-11-07 09:32:52,769 train 850 1.729991e-02 -0.890137
2019-11-07 09:32:55,733 training loss; R2: 1.730340e-02 -0.889794
2019-11-07 09:32:56,385 valid 000 1.819001e-02 -0.587300
2019-11-07 09:33:05,811 valid 050 1.789484e-02 -1.477123
2019-11-07 09:33:14,131 validation loss; R2: 1.807172e-02 -1.571780
2019-11-07 09:33:14,203 epoch 453 lr 1.000000e-05
2019-11-07 09:33:14,974 train 000 1.765844e-02 -0.620056
2019-11-07 09:33:24,750 train 050 1.730974e-02 -0.809158
2019-11-07 09:33:34,531 train 100 1.745875e-02 -1.251122
2019-11-07 09:33:44,580 train 150 1.736115e-02 -1.047874
2019-11-07 09:33:54,723 train 200 1.736653e-02 -0.915461
2019-11-07 09:34:04,884 train 250 1.729054e-02 -0.873732
2019-11-07 09:34:15,053 train 300 1.730113e-02 -0.820221
2019-11-07 09:34:25,229 train 350 1.732045e-02 -0.797403
2019-11-07 09:34:35,374 train 400 1.730444e-02 -0.788378
2019-11-07 09:34:45,559 train 450 1.728719e-02 -0.796261
2019-11-07 09:34:55,731 train 500 1.729333e-02 -0.773729
2019-11-07 09:35:05,896 train 550 1.728749e-02 -0.771074
2019-11-07 09:35:16,054 train 600 1.726179e-02 -3.429147
2019-11-07 09:35:26,228 train 650 1.726233e-02 -3.217665
2019-11-07 09:35:36,403 train 700 1.728845e-02 -3.473421
2019-11-07 09:35:46,571 train 750 1.727635e-02 -3.283100
2019-11-07 09:35:56,731 train 800 1.732437e-02 -3.122526
2019-11-07 09:36:06,908 train 850 1.731741e-02 -2.984093
2019-11-07 09:36:09,943 training loss; R2: 1.732858e-02 -2.946315
2019-11-07 09:36:10,549 valid 000 1.743383e-02 -0.009141
2019-11-07 09:36:19,990 valid 050 1.701306e-02 -1.275206
2019-11-07 09:36:28,309 validation loss; R2: 1.699535e-02 -1.143136
2019-11-07 09:36:28,376 epoch 454 lr 1.000000e-05
2019-11-07 09:36:29,116 train 000 2.027414e-02 -0.276637
2019-11-07 09:36:39,208 train 050 1.740815e-02 -0.949355
2019-11-07 09:36:49,333 train 100 1.719686e-02 -0.900641
2019-11-07 09:36:59,476 train 150 1.727994e-02 -1.009914
2019-11-07 09:37:09,618 train 200 1.743194e-02 -1.106324
2019-11-07 09:37:19,758 train 250 1.740175e-02 -1.026460
2019-11-07 09:37:29,919 train 300 1.737892e-02 -0.963251
2019-11-07 09:37:40,073 train 350 1.736999e-02 -0.995345
2019-11-07 09:37:50,231 train 400 1.739555e-02 -0.974097
2019-11-07 09:38:00,390 train 450 1.739213e-02 -0.948528
2019-11-07 09:38:10,554 train 500 1.735884e-02 -0.931832
2019-11-07 09:38:20,712 train 550 1.733343e-02 -0.909618
2019-11-07 09:38:30,896 train 600 1.734030e-02 -0.880299
2019-11-07 09:38:41,060 train 650 1.733279e-02 -0.904342
2019-11-07 09:38:51,226 train 700 1.733001e-02 -0.898731
2019-11-07 09:39:01,387 train 750 1.732833e-02 -0.882887
2019-11-07 09:39:11,558 train 800 1.733581e-02 -0.952652
2019-11-07 09:39:21,512 train 850 1.732281e-02 -0.929888
2019-11-07 09:39:24,453 training loss; R2: 1.732344e-02 -0.923119
2019-11-07 09:39:25,054 valid 000 1.852350e-02 -0.631889
2019-11-07 09:39:34,561 valid 050 1.709723e-02 -1.261145
2019-11-07 09:39:42,877 validation loss; R2: 1.737084e-02 -1.486245
2019-11-07 09:39:42,944 epoch 455 lr 1.000000e-05
2019-11-07 09:39:43,738 train 000 1.519675e-02 -0.621804
2019-11-07 09:39:53,547 train 050 1.679464e-02 -0.859787
2019-11-07 09:40:03,380 train 100 1.693693e-02 -0.865259
2019-11-07 09:40:13,227 train 150 1.709825e-02 -1.213794
2019-11-07 09:40:23,067 train 200 1.714762e-02 -1.152995
2019-11-07 09:40:32,927 train 250 1.714412e-02 -1.070151
2019-11-07 09:40:42,793 train 300 1.717252e-02 -0.998786
2019-11-07 09:40:52,647 train 350 1.720180e-02 -0.932918
2019-11-07 09:41:02,494 train 400 1.727187e-02 -0.906071
2019-11-07 09:41:12,347 train 450 1.726167e-02 -0.875219
2019-11-07 09:41:22,227 train 500 1.728909e-02 -0.878165
2019-11-07 09:41:32,145 train 550 1.731856e-02 -0.922804
2019-11-07 09:41:42,011 train 600 1.733436e-02 -0.997693
2019-11-07 09:41:51,869 train 650 1.734725e-02 -0.985033
2019-11-07 09:42:01,713 train 700 1.733129e-02 -0.969275
2019-11-07 09:42:11,566 train 750 1.731186e-02 -0.952057
2019-11-07 09:42:21,441 train 800 1.731809e-02 -0.919699
2019-11-07 09:42:31,320 train 850 1.733503e-02 -0.906073
2019-11-07 09:42:34,259 training loss; R2: 1.732791e-02 -0.900990
2019-11-07 09:42:34,935 valid 000 1.545307e-02 -0.594534
2019-11-07 09:42:44,382 valid 050 1.731193e-02 -1.296700
2019-11-07 09:42:52,728 validation loss; R2: 1.730713e-02 -1.499240
2019-11-07 09:42:52,795 epoch 456 lr 1.000000e-05
2019-11-07 09:42:53,572 train 000 1.704179e-02 -0.021649
2019-11-07 09:43:03,365 train 050 1.730021e-02 -19.477482
2019-11-07 09:43:13,201 train 100 1.735858e-02 -10.241600
2019-11-07 09:43:23,044 train 150 1.729606e-02 -7.098780
2019-11-07 09:43:32,893 train 200 1.733865e-02 -5.465075
2019-11-07 09:43:42,763 train 250 1.740223e-02 -4.516284
2019-11-07 09:43:52,649 train 300 1.743108e-02 -3.893938
2019-11-07 09:44:02,532 train 350 1.748615e-02 -3.423832
2019-11-07 09:44:12,428 train 400 1.746171e-02 -3.496253
2019-11-07 09:44:22,289 train 450 1.745220e-02 -3.208472
2019-11-07 09:44:32,162 train 500 1.745561e-02 -2.974334
2019-11-07 09:44:42,029 train 550 1.745009e-02 -2.782454
2019-11-07 09:44:51,913 train 600 1.742518e-02 -2.601174
2019-11-07 09:45:01,801 train 650 1.738742e-02 -2.573413
2019-11-07 09:45:11,689 train 700 1.740294e-02 -2.440906
2019-11-07 09:45:21,565 train 750 1.739815e-02 -2.339793
2019-11-07 09:45:31,450 train 800 1.736920e-02 -2.226945
2019-11-07 09:45:41,320 train 850 1.737729e-02 -2.157007
2019-11-07 09:45:44,307 training loss; R2: 1.737986e-02 -2.140934
2019-11-07 09:45:45,004 valid 000 1.563398e-02 0.121254
2019-11-07 09:45:54,406 valid 050 1.645997e-02 -1.041419
2019-11-07 09:46:02,705 validation loss; R2: 1.666353e-02 -1.060545
2019-11-07 09:46:02,771 epoch 457 lr 1.000000e-05
2019-11-07 09:46:03,542 train 000 1.730172e-02 0.019561
2019-11-07 09:46:13,308 train 050 1.743329e-02 -0.523889
2019-11-07 09:46:23,114 train 100 1.738532e-02 -0.577636
2019-11-07 09:46:32,923 train 150 1.744800e-02 -0.641217
2019-11-07 09:46:42,761 train 200 1.739951e-02 -0.774869
2019-11-07 09:46:52,596 train 250 1.741205e-02 -0.749665
2019-11-07 09:47:02,435 train 300 1.742114e-02 -0.741450
2019-11-07 09:47:12,264 train 350 1.738741e-02 -0.727779
2019-11-07 09:47:22,112 train 400 1.736224e-02 -0.768342
2019-11-07 09:47:31,957 train 450 1.736993e-02 -0.806753
2019-11-07 09:47:41,804 train 500 1.733376e-02 -0.790870
2019-11-07 09:47:51,648 train 550 1.731096e-02 -0.801146
2019-11-07 09:48:01,479 train 600 1.730932e-02 -0.788635
2019-11-07 09:48:11,325 train 650 1.731054e-02 -0.793462
2019-11-07 09:48:21,128 train 700 1.729838e-02 -0.797932
2019-11-07 09:48:30,942 train 750 1.731583e-02 -0.780088
2019-11-07 09:48:40,755 train 800 1.731155e-02 -0.780180
2019-11-07 09:48:50,570 train 850 1.728963e-02 -0.782697
2019-11-07 09:48:53,493 training loss; R2: 1.729779e-02 -0.777902
2019-11-07 09:48:54,122 valid 000 1.730946e-02 -0.101543
2019-11-07 09:49:03,571 valid 050 1.722037e-02 -0.956445
2019-11-07 09:49:11,876 validation loss; R2: 1.700683e-02 -0.825586
2019-11-07 09:49:11,943 epoch 458 lr 1.000000e-05
2019-11-07 09:49:12,719 train 000 1.680724e-02 -2.682452
2019-11-07 09:49:22,450 train 050 1.743094e-02 -0.975439
2019-11-07 09:49:32,218 train 100 1.722342e-02 -0.974922
2019-11-07 09:49:41,974 train 150 1.730483e-02 -0.962503
2019-11-07 09:49:51,762 train 200 1.741557e-02 -0.898558
2019-11-07 09:50:01,549 train 250 1.735386e-02 -0.854906
2019-11-07 09:50:11,339 train 300 1.738185e-02 -5.804509
2019-11-07 09:50:21,140 train 350 1.735124e-02 -5.073124
2019-11-07 09:50:30,927 train 400 1.737154e-02 -4.538424
2019-11-07 09:50:40,720 train 450 1.733694e-02 -4.153991
2019-11-07 09:50:50,517 train 500 1.735146e-02 -3.805093
2019-11-07 09:51:00,310 train 550 1.736823e-02 -3.500550
2019-11-07 09:51:10,094 train 600 1.738160e-02 -3.272497
2019-11-07 09:51:19,907 train 650 1.737960e-02 -3.071036
2019-11-07 09:51:29,717 train 700 1.734821e-02 -2.901614
2019-11-07 09:51:39,523 train 750 1.733475e-02 -2.825149
2019-11-07 09:51:49,332 train 800 1.734162e-02 -2.691937
2019-11-07 09:51:59,140 train 850 1.733168e-02 -2.587540
2019-11-07 09:52:02,120 training loss; R2: 1.732147e-02 -2.551132
2019-11-07 09:52:02,825 valid 000 1.684641e-02 -0.806814
2019-11-07 09:52:12,198 valid 050 1.825504e-02 -1.309967
2019-11-07 09:52:20,569 validation loss; R2: 1.798930e-02 -1.382368
2019-11-07 09:52:20,637 epoch 459 lr 1.000000e-05
2019-11-07 09:52:21,429 train 000 1.640335e-02 -1.355877
2019-11-07 09:52:31,553 train 050 1.730944e-02 -0.907173
2019-11-07 09:52:41,677 train 100 1.725573e-02 -0.736272
2019-11-07 09:52:51,783 train 150 1.731039e-02 -0.773708
2019-11-07 09:53:01,918 train 200 1.740118e-02 -0.776534
2019-11-07 09:53:12,070 train 250 1.739286e-02 -0.751038
2019-11-07 09:53:22,204 train 300 1.733004e-02 -0.857398
2019-11-07 09:53:32,343 train 350 1.729978e-02 -0.839665
2019-11-07 09:53:42,487 train 400 1.728128e-02 -0.813277
2019-11-07 09:53:52,637 train 450 1.728731e-02 -0.910440
2019-11-07 09:54:02,774 train 500 1.727405e-02 -0.882528
2019-11-07 09:54:12,916 train 550 1.728381e-02 -0.889722
2019-11-07 09:54:23,071 train 600 1.729761e-02 -1.112864
2019-11-07 09:54:33,252 train 650 1.729517e-02 -1.132370
2019-11-07 09:54:43,401 train 700 1.728167e-02 -1.102476
2019-11-07 09:54:53,236 train 750 1.727942e-02 -1.071391
2019-11-07 09:55:03,021 train 800 1.728967e-02 -1.052433
2019-11-07 09:55:12,815 train 850 1.729579e-02 -1.055211
2019-11-07 09:55:15,742 training loss; R2: 1.729880e-02 -1.050116
2019-11-07 09:55:16,373 valid 000 2.032196e-02 -0.763468
2019-11-07 09:55:25,836 valid 050 1.706116e-02 -1.184858
2019-11-07 09:55:34,158 validation loss; R2: 1.725515e-02 -1.104440
2019-11-07 09:55:34,223 epoch 460 lr 1.000000e-05
2019-11-07 09:55:34,985 train 000 1.608061e-02 -0.333602
2019-11-07 09:55:44,705 train 050 1.695233e-02 -0.882628
2019-11-07 09:55:54,458 train 100 1.715676e-02 -0.833734
2019-11-07 09:56:04,240 train 150 1.730112e-02 -0.772384
2019-11-07 09:56:14,023 train 200 1.720473e-02 -0.694829
2019-11-07 09:56:23,806 train 250 1.719366e-02 -0.653636
2019-11-07 09:56:33,585 train 300 1.719691e-02 -0.742394
2019-11-07 09:56:43,391 train 350 1.721649e-02 -0.733655
2019-11-07 09:56:53,167 train 400 1.723194e-02 -0.710916
2019-11-07 09:57:02,964 train 450 1.724229e-02 -0.733390
2019-11-07 09:57:12,814 train 500 1.723510e-02 -0.714887
2019-11-07 09:57:22,671 train 550 1.722045e-02 -0.721979
2019-11-07 09:57:32,528 train 600 1.723600e-02 -0.701430
2019-11-07 09:57:42,389 train 650 1.726874e-02 -0.712819
2019-11-07 09:57:52,251 train 700 1.727705e-02 -0.727282
2019-11-07 09:58:02,124 train 750 1.728380e-02 -0.728256
2019-11-07 09:58:12,018 train 800 1.728523e-02 -0.724850
2019-11-07 09:58:21,885 train 850 1.727881e-02 -0.704864
2019-11-07 09:58:24,862 training loss; R2: 1.727787e-02 -0.713333
2019-11-07 09:58:25,477 valid 000 1.981467e-02 0.007215
2019-11-07 09:58:34,966 valid 050 1.696759e-02 -1.071330
2019-11-07 09:58:43,322 validation loss; R2: 1.679468e-02 -1.184213
2019-11-07 09:58:43,403 epoch 461 lr 1.000000e-05
2019-11-07 09:58:44,257 train 000 1.672801e-02 -1.130958
2019-11-07 09:58:54,052 train 050 1.760644e-02 -0.589483
2019-11-07 09:59:03,884 train 100 1.760129e-02 -0.700075
2019-11-07 09:59:13,716 train 150 1.759423e-02 -0.663801
2019-11-07 09:59:23,541 train 200 1.750934e-02 -0.624171
2019-11-07 09:59:33,359 train 250 1.750564e-02 -0.604272
2019-11-07 09:59:43,204 train 300 1.743358e-02 -0.645892
2019-11-07 09:59:53,048 train 350 1.742137e-02 -0.661282
2019-11-07 10:00:02,899 train 400 1.740554e-02 -0.698093
2019-11-07 10:00:12,753 train 450 1.739179e-02 -0.733312
2019-11-07 10:00:22,579 train 500 1.738009e-02 -0.745700
2019-11-07 10:00:32,418 train 550 1.733450e-02 -0.738484
2019-11-07 10:00:42,265 train 600 1.731103e-02 -0.723285
2019-11-07 10:00:52,099 train 650 1.727592e-02 -0.735468
2019-11-07 10:01:01,933 train 700 1.728083e-02 -0.723596
2019-11-07 10:01:11,772 train 750 1.727157e-02 -0.712343
2019-11-07 10:01:21,604 train 800 1.727950e-02 -0.732066
2019-11-07 10:01:31,435 train 850 1.727820e-02 -0.725439
2019-11-07 10:01:34,379 training loss; R2: 1.727783e-02 -0.724158
2019-11-07 10:01:35,097 valid 000 1.866675e-02 0.132118
2019-11-07 10:01:44,453 valid 050 1.791281e-02 -0.990765
2019-11-07 10:01:52,954 validation loss; R2: 1.796861e-02 -1.039376
2019-11-07 10:01:53,017 epoch 462 lr 1.000000e-05
2019-11-07 10:01:53,807 train 000 2.021686e-02 -1.690045
2019-11-07 10:02:03,568 train 050 1.758412e-02 -0.669672
2019-11-07 10:02:13,361 train 100 1.763425e-02 -0.680057
2019-11-07 10:02:23,152 train 150 1.753676e-02 -0.619549
2019-11-07 10:02:32,970 train 200 1.749559e-02 -0.688474
2019-11-07 10:02:42,800 train 250 1.743530e-02 -0.679936
2019-11-07 10:02:52,634 train 300 1.744644e-02 -0.694378
2019-11-07 10:03:02,459 train 350 1.741376e-02 -0.714690
2019-11-07 10:03:12,270 train 400 1.744517e-02 -0.713719
2019-11-07 10:03:22,089 train 450 1.743693e-02 -0.716370
2019-11-07 10:03:31,913 train 500 1.742430e-02 -0.782394
2019-11-07 10:03:41,735 train 550 1.741746e-02 -0.779364
2019-11-07 10:03:51,534 train 600 1.739666e-02 -0.767818
2019-11-07 10:04:01,354 train 650 1.739269e-02 -0.788726
2019-11-07 10:04:11,196 train 700 1.736040e-02 -0.790138
2019-11-07 10:04:21,039 train 750 1.733573e-02 -0.781034
2019-11-07 10:04:30,881 train 800 1.735030e-02 -0.770504
2019-11-07 10:04:40,744 train 850 1.735414e-02 -0.857471
2019-11-07 10:04:43,690 training loss; R2: 1.735890e-02 -0.849465
2019-11-07 10:04:44,374 valid 000 1.635278e-02 -1.521324
2019-11-07 10:04:53,817 valid 050 1.697494e-02 -1.565033
2019-11-07 10:05:02,168 validation loss; R2: 1.716685e-02 -1.516417
2019-11-07 10:05:02,235 epoch 463 lr 1.000000e-05
2019-11-07 10:05:03,003 train 000 1.493336e-02 -0.808262
2019-11-07 10:05:12,728 train 050 1.674839e-02 -0.655368
2019-11-07 10:05:22,493 train 100 1.680953e-02 -0.575196
2019-11-07 10:05:32,314 train 150 1.701767e-02 -0.582170
2019-11-07 10:05:42,095 train 200 1.714716e-02 -0.608230
2019-11-07 10:05:51,877 train 250 1.713494e-02 -0.631278
2019-11-07 10:06:01,669 train 300 1.709408e-02 -0.641471
2019-11-07 10:06:11,455 train 350 1.719312e-02 -0.653273
2019-11-07 10:06:21,237 train 400 1.724137e-02 -0.980094
2019-11-07 10:06:31,036 train 450 1.723742e-02 -0.932654
2019-11-07 10:06:40,841 train 500 1.721682e-02 -0.926258
2019-11-07 10:06:50,655 train 550 1.721433e-02 -0.902588
2019-11-07 10:07:00,475 train 600 1.721864e-02 -0.867928
2019-11-07 10:07:10,280 train 650 1.721348e-02 -0.848229
2019-11-07 10:07:20,218 train 700 1.723344e-02 -0.826384
2019-11-07 10:07:30,413 train 750 1.725696e-02 -0.807833
2019-11-07 10:07:40,601 train 800 1.726358e-02 -0.807524
2019-11-07 10:07:50,783 train 850 1.728108e-02 -0.811422
2019-11-07 10:07:53,836 training loss; R2: 1.727891e-02 -0.809295
2019-11-07 10:07:54,520 valid 000 1.566848e-02 -0.256725
2019-11-07 10:08:03,902 valid 050 1.724866e-02 -0.963745
2019-11-07 10:08:12,255 validation loss; R2: 1.719859e-02 -1.040269
2019-11-07 10:08:12,329 epoch 464 lr 1.000000e-05
2019-11-07 10:08:13,124 train 000 1.809550e-02 -1.359909
2019-11-07 10:08:22,895 train 050 1.813733e-02 -0.496855
2019-11-07 10:08:32,686 train 100 1.800186e-02 -0.533027
2019-11-07 10:08:42,511 train 150 1.766136e-02 -0.529414
2019-11-07 10:08:52,316 train 200 1.760259e-02 -0.564203
2019-11-07 10:09:02,115 train 250 1.757136e-02 -0.758541
2019-11-07 10:09:11,928 train 300 1.744608e-02 -0.773374
2019-11-07 10:09:21,740 train 350 1.743380e-02 -0.754207
2019-11-07 10:09:31,540 train 400 1.739209e-02 -0.771456
2019-11-07 10:09:41,346 train 450 1.743554e-02 -0.763126
2019-11-07 10:09:51,156 train 500 1.741787e-02 -0.746274
2019-11-07 10:10:00,968 train 550 1.737512e-02 -0.739004
2019-11-07 10:10:10,785 train 600 1.737283e-02 -0.721414
2019-11-07 10:10:20,603 train 650 1.738747e-02 -0.728605
2019-11-07 10:10:30,429 train 700 1.738450e-02 -0.732064
2019-11-07 10:10:40,270 train 750 1.735320e-02 -0.744657
2019-11-07 10:10:50,128 train 800 1.733654e-02 -0.747661
2019-11-07 10:10:59,932 train 850 1.730857e-02 -0.752221
2019-11-07 10:11:02,860 training loss; R2: 1.730705e-02 -0.750188
2019-11-07 10:11:03,489 valid 000 1.604074e-02 -0.180067
2019-11-07 10:11:12,932 valid 050 1.728116e-02 -0.955431
2019-11-07 10:11:21,264 validation loss; R2: 1.744288e-02 -1.664093
2019-11-07 10:11:21,323 epoch 465 lr 1.000000e-05
2019-11-07 10:11:22,076 train 000 1.647436e-02 -0.561195
2019-11-07 10:11:31,778 train 050 1.764383e-02 -0.836899
2019-11-07 10:11:41,502 train 100 1.760361e-02 -0.849604
2019-11-07 10:11:51,251 train 150 1.747011e-02 -0.878614
2019-11-07 10:12:01,006 train 200 1.748629e-02 -0.843401
2019-11-07 10:12:10,769 train 250 1.750523e-02 -0.864290
2019-11-07 10:12:20,535 train 300 1.750964e-02 -0.838979
2019-11-07 10:12:30,297 train 350 1.752547e-02 -0.805732
2019-11-07 10:12:40,058 train 400 1.750684e-02 -0.784783
2019-11-07 10:12:49,813 train 450 1.748380e-02 -0.760361
2019-11-07 10:12:59,592 train 500 1.743997e-02 -0.756880
2019-11-07 10:13:09,352 train 550 1.740526e-02 -0.735756
2019-11-07 10:13:19,138 train 600 1.741354e-02 -0.753959
2019-11-07 10:13:28,911 train 650 1.740274e-02 -0.778777
2019-11-07 10:13:38,694 train 700 1.739435e-02 -0.773578
2019-11-07 10:13:48,482 train 750 1.737707e-02 -0.764941
2019-11-07 10:13:58,278 train 800 1.738984e-02 -0.764636
2019-11-07 10:14:08,085 train 850 1.739465e-02 -0.759252
2019-11-07 10:14:11,013 training loss; R2: 1.737825e-02 -0.761596
2019-11-07 10:14:11,668 valid 000 1.477855e-02 -0.192364
2019-11-07 10:14:21,108 valid 050 1.647288e-02 -1.002880
2019-11-07 10:14:29,450 validation loss; R2: 1.665276e-02 -0.988354
2019-11-07 10:14:29,514 epoch 466 lr 1.000000e-05
2019-11-07 10:14:30,297 train 000 1.812567e-02 -1.342672
2019-11-07 10:14:40,009 train 050 1.720584e-02 -0.670194
2019-11-07 10:14:49,731 train 100 1.716275e-02 -0.742654
2019-11-07 10:14:59,477 train 150 1.721842e-02 -0.746900
2019-11-07 10:15:09,233 train 200 1.713390e-02 -0.800353
2019-11-07 10:15:18,996 train 250 1.720071e-02 -0.768905
2019-11-07 10:15:28,759 train 300 1.720086e-02 -0.730223
2019-11-07 10:15:38,527 train 350 1.720129e-02 -0.781571
2019-11-07 10:15:48,298 train 400 1.725787e-02 -0.760305
2019-11-07 10:15:58,058 train 450 1.720348e-02 -1.066760
2019-11-07 10:16:07,848 train 500 1.723014e-02 -1.039146
2019-11-07 10:16:17,634 train 550 1.723796e-02 -1.009767
2019-11-07 10:16:27,409 train 600 1.722840e-02 -1.112749
2019-11-07 10:16:37,184 train 650 1.724910e-02 -1.061950
2019-11-07 10:16:46,942 train 700 1.723622e-02 -1.037236
2019-11-07 10:16:56,722 train 750 1.724900e-02 -1.006039
2019-11-07 10:17:06,507 train 800 1.723078e-02 -0.982899
2019-11-07 10:17:16,294 train 850 1.723946e-02 -0.967270
2019-11-07 10:17:19,222 training loss; R2: 1.723281e-02 -0.959752
2019-11-07 10:17:19,807 valid 000 1.608689e-02 -5.975998
2019-11-07 10:17:29,193 valid 050 1.733993e-02 -18.452279
2019-11-07 10:17:37,519 validation loss; R2: 1.735312e-02 -10.083754
2019-11-07 10:17:37,587 epoch 467 lr 1.000000e-05
2019-11-07 10:17:38,343 train 000 1.604810e-02 -0.249181
2019-11-07 10:17:48,045 train 050 1.704673e-02 -0.653015
2019-11-07 10:17:57,731 train 100 1.716574e-02 -0.688972
2019-11-07 10:18:07,487 train 150 1.724481e-02 -0.670449
2019-11-07 10:18:17,241 train 200 1.721595e-02 -0.721077
2019-11-07 10:18:27,009 train 250 1.718621e-02 -0.816976
2019-11-07 10:18:36,754 train 300 1.723219e-02 -0.776179
2019-11-07 10:18:46,517 train 350 1.724245e-02 -0.789839
2019-11-07 10:18:56,274 train 400 1.721969e-02 -0.802588
2019-11-07 10:19:06,038 train 450 1.723519e-02 -0.827976
2019-11-07 10:19:15,816 train 500 1.720471e-02 -0.825486
2019-11-07 10:19:25,591 train 550 1.717712e-02 -0.820595
2019-11-07 10:19:35,361 train 600 1.720143e-02 -0.817946
2019-11-07 10:19:45,149 train 650 1.724076e-02 -0.809565
2019-11-07 10:19:54,929 train 700 1.724988e-02 -0.783472
2019-11-07 10:20:04,716 train 750 1.725925e-02 -0.797803
2019-11-07 10:20:14,510 train 800 1.726587e-02 -0.792079
2019-11-07 10:20:24,301 train 850 1.727566e-02 -0.809689
2019-11-07 10:20:27,222 training loss; R2: 1.725824e-02 -0.803682
2019-11-07 10:20:27,918 valid 000 1.527815e-02 -1.446138
2019-11-07 10:20:37,281 valid 050 1.669137e-02 -3.398105
2019-11-07 10:20:45,617 validation loss; R2: 1.664375e-02 -2.376625
2019-11-07 10:20:45,685 epoch 468 lr 1.000000e-05
2019-11-07 10:20:46,433 train 000 1.820532e-02 -1.260175
2019-11-07 10:20:56,148 train 050 1.736157e-02 -0.718968
2019-11-07 10:21:05,845 train 100 1.743645e-02 -1.444719
2019-11-07 10:21:15,601 train 150 1.741532e-02 -1.196121
2019-11-07 10:21:25,367 train 200 1.737810e-02 -1.050305
2019-11-07 10:21:35,136 train 250 1.735112e-02 -0.995879
2019-11-07 10:21:44,893 train 300 1.733591e-02 -0.972270
2019-11-07 10:21:54,665 train 350 1.734215e-02 -0.947105
2019-11-07 10:22:04,433 train 400 1.732217e-02 -0.918884
2019-11-07 10:22:14,211 train 450 1.733825e-02 -0.904024
2019-11-07 10:22:23,975 train 500 1.730949e-02 -0.886968
2019-11-07 10:22:33,747 train 550 1.734122e-02 -0.881241
2019-11-07 10:22:43,518 train 600 1.733306e-02 -0.889060
2019-11-07 10:22:53,292 train 650 1.734769e-02 -0.869299
2019-11-07 10:23:03,059 train 700 1.732951e-02 -0.853255
2019-11-07 10:23:12,824 train 750 1.731654e-02 -0.837756
2019-11-07 10:23:22,589 train 800 1.728399e-02 -0.834092
2019-11-07 10:23:32,368 train 850 1.727792e-02 -0.819782
2019-11-07 10:23:35,288 training loss; R2: 1.726068e-02 -0.814461
2019-11-07 10:23:35,963 valid 000 1.993816e-02 -0.564429
2019-11-07 10:23:45,388 valid 050 1.714860e-02 -1.202511
2019-11-07 10:23:53,748 validation loss; R2: 1.720134e-02 -1.265872
2019-11-07 10:23:53,815 epoch 469 lr 1.000000e-05
2019-11-07 10:23:54,632 train 000 1.906431e-02 -0.216693
2019-11-07 10:24:04,359 train 050 1.681822e-02 -1.643272
2019-11-07 10:24:14,117 train 100 1.697024e-02 -1.089598
2019-11-07 10:24:23,877 train 150 1.723708e-02 -0.960268
2019-11-07 10:24:33,641 train 200 1.723512e-02 -0.878035
2019-11-07 10:24:43,400 train 250 1.727450e-02 -0.860072
2019-11-07 10:24:53,156 train 300 1.724495e-02 -1.864209
2019-11-07 10:25:02,918 train 350 1.724303e-02 -1.681925
2019-11-07 10:25:12,688 train 400 1.725374e-02 -1.649327
2019-11-07 10:25:22,455 train 450 1.727719e-02 -1.556287
2019-11-07 10:25:32,227 train 500 1.727923e-02 -1.508548
2019-11-07 10:25:41,983 train 550 1.727584e-02 -1.413135
2019-11-07 10:25:51,744 train 600 1.727115e-02 -1.375178
2019-11-07 10:26:01,510 train 650 1.725474e-02 -1.321136
2019-11-07 10:26:11,276 train 700 1.725303e-02 -1.274095
2019-11-07 10:26:21,045 train 750 1.727038e-02 -1.303955
2019-11-07 10:26:30,819 train 800 1.727877e-02 -1.264155
2019-11-07 10:26:40,605 train 850 1.727061e-02 -1.236009
2019-11-07 10:26:43,528 training loss; R2: 1.727198e-02 -1.220539
2019-11-07 10:26:44,203 valid 000 1.486950e-02 -0.964282
2019-11-07 10:26:53,572 valid 050 1.683777e-02 -0.832711
2019-11-07 10:27:02,043 validation loss; R2: 1.680700e-02 -0.881783
2019-11-07 10:27:02,111 epoch 470 lr 1.000000e-05
2019-11-07 10:27:02,922 train 000 1.939656e-02 -0.469879
2019-11-07 10:27:12,622 train 050 1.718777e-02 -0.597887
2019-11-07 10:27:22,314 train 100 1.719276e-02 -0.767035
2019-11-07 10:27:32,068 train 150 1.729936e-02 -0.748789
2019-11-07 10:27:41,819 train 200 1.738951e-02 -0.728809
2019-11-07 10:27:51,568 train 250 1.745261e-02 -0.732705
2019-11-07 10:28:01,318 train 300 1.737488e-02 -0.734820
2019-11-07 10:28:11,065 train 350 1.734260e-02 -0.755464
2019-11-07 10:28:20,817 train 400 1.732591e-02 -0.759147
2019-11-07 10:28:30,577 train 450 1.726211e-02 -0.739633
2019-11-07 10:28:40,330 train 500 1.725552e-02 -0.711716
2019-11-07 10:28:50,082 train 550 1.723512e-02 -0.705703
2019-11-07 10:28:59,840 train 600 1.725753e-02 -0.694590
2019-11-07 10:29:09,599 train 650 1.725962e-02 -0.711848
2019-11-07 10:29:19,361 train 700 1.725487e-02 -0.711506
2019-11-07 10:29:29,133 train 750 1.727347e-02 -0.724378
2019-11-07 10:29:38,899 train 800 1.729734e-02 -0.733279
2019-11-07 10:29:48,672 train 850 1.726865e-02 -0.731650
2019-11-07 10:29:51,591 training loss; R2: 1.726637e-02 -0.731791
2019-11-07 10:29:52,285 valid 000 1.856713e-02 -0.195324
2019-11-07 10:30:01,626 valid 050 1.774586e-02 -0.932431
2019-11-07 10:30:10,001 validation loss; R2: 1.780400e-02 -0.998850
2019-11-07 10:30:10,067 epoch 471 lr 1.000000e-05
2019-11-07 10:30:10,859 train 000 1.773718e-02 -1.999531
2019-11-07 10:30:20,568 train 050 1.760145e-02 -0.798499
2019-11-07 10:30:30,307 train 100 1.760915e-02 -0.762700
2019-11-07 10:30:40,069 train 150 1.750673e-02 -0.782647
2019-11-07 10:30:49,832 train 200 1.742747e-02 -0.818512
2019-11-07 10:30:59,633 train 250 1.746876e-02 -0.791124
2019-11-07 10:31:09,426 train 300 1.744650e-02 -0.840802
2019-11-07 10:31:19,211 train 350 1.741889e-02 -0.817520
2019-11-07 10:31:28,993 train 400 1.741924e-02 -0.800872
2019-11-07 10:31:38,790 train 450 1.738614e-02 -0.771527
2019-11-07 10:31:48,587 train 500 1.738669e-02 -0.760086
2019-11-07 10:31:58,384 train 550 1.739930e-02 -0.762027
2019-11-07 10:32:08,171 train 600 1.738417e-02 -0.770207
2019-11-07 10:32:17,960 train 650 1.734553e-02 -0.754647
2019-11-07 10:32:27,760 train 700 1.736419e-02 -0.771629
2019-11-07 10:32:37,564 train 750 1.735203e-02 -0.765820
2019-11-07 10:32:47,373 train 800 1.730266e-02 -0.749696
2019-11-07 10:32:57,192 train 850 1.726289e-02 -0.735870
2019-11-07 10:33:00,125 training loss; R2: 1.725848e-02 -0.743077
2019-11-07 10:33:00,799 valid 000 1.514699e-02 -0.626832
2019-11-07 10:33:10,196 valid 050 1.705876e-02 -1.308676
2019-11-07 10:33:18,569 validation loss; R2: 1.710708e-02 -1.285314
2019-11-07 10:33:18,634 epoch 472 lr 1.000000e-05
2019-11-07 10:33:19,400 train 000 1.472266e-02 -1.356376
2019-11-07 10:33:29,153 train 050 1.706001e-02 -0.655844
2019-11-07 10:33:38,909 train 100 1.719863e-02 -0.911498
2019-11-07 10:33:48,688 train 150 1.718264e-02 -0.792058
2019-11-07 10:33:58,494 train 200 1.717142e-02 -0.716824
2019-11-07 10:34:08,279 train 250 1.722027e-02 -0.739004
2019-11-07 10:34:18,065 train 300 1.731026e-02 -0.714361
2019-11-07 10:34:27,864 train 350 1.729125e-02 -0.728106
2019-11-07 10:34:37,648 train 400 1.731017e-02 -0.725207
2019-11-07 10:34:47,435 train 450 1.733102e-02 -0.728880
2019-11-07 10:34:57,578 train 500 1.734435e-02 -0.722789
2019-11-07 10:35:07,735 train 550 1.732889e-02 -0.746257
2019-11-07 10:35:17,867 train 600 1.732691e-02 -0.743056
2019-11-07 10:35:28,027 train 650 1.728812e-02 -0.781891
2019-11-07 10:35:38,177 train 700 1.727378e-02 -0.787140
2019-11-07 10:35:48,324 train 750 1.726752e-02 -0.778005
2019-11-07 10:35:58,483 train 800 1.725896e-02 -0.761612
2019-11-07 10:36:08,621 train 850 1.723056e-02 -0.751746
2019-11-07 10:36:11,660 training loss; R2: 1.723211e-02 -0.750049
2019-11-07 10:36:12,341 valid 000 1.600413e-02 -4.472109
2019-11-07 10:36:21,646 valid 050 1.606298e-02 -1.107835
2019-11-07 10:36:30,086 validation loss; R2: 1.638736e-02 -0.990408
2019-11-07 10:36:30,155 epoch 473 lr 1.000000e-05
2019-11-07 10:36:30,949 train 000 1.784242e-02 -0.545967
2019-11-07 10:36:41,053 train 050 1.736520e-02 -0.545881
2019-11-07 10:36:51,162 train 100 1.731733e-02 -0.697392
2019-11-07 10:37:01,283 train 150 1.741197e-02 -0.764843
2019-11-07 10:37:11,423 train 200 1.735906e-02 -0.727734
2019-11-07 10:37:21,570 train 250 1.742528e-02 -0.724037
2019-11-07 10:37:31,710 train 300 1.736751e-02 -0.708631
2019-11-07 10:37:41,848 train 350 1.734805e-02 -0.693663
2019-11-07 10:37:51,982 train 400 1.735892e-02 -0.666584
2019-11-07 10:38:02,128 train 450 1.732877e-02 -0.701577
2019-11-07 10:38:12,275 train 500 1.733196e-02 -0.691091
2019-11-07 10:38:22,408 train 550 1.730394e-02 -0.706398
2019-11-07 10:38:32,548 train 600 1.730319e-02 -0.701396
2019-11-07 10:38:42,689 train 650 1.733308e-02 -0.699080
2019-11-07 10:38:52,817 train 700 1.733627e-02 -0.708904
2019-11-07 10:39:02,976 train 750 1.734008e-02 -0.706716
2019-11-07 10:39:13,143 train 800 1.735148e-02 -0.694355
2019-11-07 10:39:23,293 train 850 1.735197e-02 -0.688002
2019-11-07 10:39:26,327 training loss; R2: 1.733984e-02 -0.694890
2019-11-07 10:39:27,017 valid 000 1.440676e-02 -0.797882
2019-11-07 10:39:36,384 valid 050 1.645728e-02 -0.826011
2019-11-07 10:39:44,915 validation loss; R2: 1.654384e-02 -0.758531
2019-11-07 10:39:44,983 epoch 474 lr 1.000000e-05
2019-11-07 10:39:45,789 train 000 1.683141e-02 -1.626970
2019-11-07 10:39:55,598 train 050 1.742480e-02 -0.666558
2019-11-07 10:40:05,385 train 100 1.732994e-02 -0.560959
2019-11-07 10:40:15,170 train 150 1.724301e-02 -0.537545
2019-11-07 10:40:24,991 train 200 1.730607e-02 -0.530789
2019-11-07 10:40:34,816 train 250 1.732140e-02 -0.660647
2019-11-07 10:40:44,646 train 300 1.726716e-02 -0.666595
2019-11-07 10:40:54,459 train 350 1.726273e-02 -0.644953
2019-11-07 10:41:04,278 train 400 1.730473e-02 -0.667874
2019-11-07 10:41:14,098 train 450 1.727592e-02 -0.655032
2019-11-07 10:41:23,932 train 500 1.728521e-02 -0.662479
2019-11-07 10:41:33,756 train 550 1.728020e-02 -0.678992
2019-11-07 10:41:43,602 train 600 1.729077e-02 -0.665862
2019-11-07 10:41:53,433 train 650 1.728527e-02 -0.686846
2019-11-07 10:42:03,267 train 700 1.726082e-02 -0.691410
2019-11-07 10:42:13,104 train 750 1.725583e-02 -0.698656
2019-11-07 10:42:22,963 train 800 1.725872e-02 -0.703276
2019-11-07 10:42:32,814 train 850 1.726469e-02 -0.707901
2019-11-07 10:42:35,762 training loss; R2: 1.726660e-02 -0.709397
2019-11-07 10:42:36,434 valid 000 1.723406e-02 -1.438675
2019-11-07 10:42:45,835 valid 050 1.616619e-02 -1.369974
2019-11-07 10:42:54,276 validation loss; R2: 1.640971e-02 -1.319454
2019-11-07 10:42:54,342 epoch 475 lr 1.000000e-05
2019-11-07 10:42:55,153 train 000 1.735905e-02 -0.029235
2019-11-07 10:43:04,910 train 050 1.726804e-02 -0.445522
2019-11-07 10:43:14,679 train 100 1.740482e-02 -0.510380
2019-11-07 10:43:24,472 train 150 1.729944e-02 -0.529855
2019-11-07 10:43:34,260 train 200 1.732409e-02 -0.582396
2019-11-07 10:43:44,051 train 250 1.736376e-02 -0.602787
2019-11-07 10:43:53,843 train 300 1.732387e-02 -0.615122
2019-11-07 10:44:03,626 train 350 1.727296e-02 -1.130581
2019-11-07 10:44:13,421 train 400 1.725835e-02 -1.102999
2019-11-07 10:44:23,214 train 450 1.723535e-02 -1.032026
2019-11-07 10:44:33,005 train 500 1.723694e-02 -1.017506
2019-11-07 10:44:42,798 train 550 1.722247e-02 -0.992687
2019-11-07 10:44:52,599 train 600 1.723061e-02 -0.982498
2019-11-07 10:45:02,389 train 650 1.723944e-02 -0.976158
2019-11-07 10:45:12,191 train 700 1.723761e-02 -0.949884
2019-11-07 10:45:21,993 train 750 1.722888e-02 -0.918848
2019-11-07 10:45:31,814 train 800 1.725362e-02 -0.922947
2019-11-07 10:45:41,646 train 850 1.725845e-02 -0.919843
2019-11-07 10:45:44,584 training loss; R2: 1.726097e-02 -0.925290
2019-11-07 10:45:45,234 valid 000 2.228148e-02 -0.887698
2019-11-07 10:45:54,668 valid 050 1.725944e-02 -2.263131
2019-11-07 10:46:02,971 validation loss; R2: 1.718488e-02 -1.875595
2019-11-07 10:46:03,036 epoch 476 lr 1.000000e-05
2019-11-07 10:46:03,768 train 000 1.768526e-02 -0.532177
2019-11-07 10:46:13,511 train 050 1.687053e-02 -0.726423
2019-11-07 10:46:23,293 train 100 1.688455e-02 -0.818498
2019-11-07 10:46:33,093 train 150 1.721706e-02 -0.718006
2019-11-07 10:46:42,885 train 200 1.709962e-02 -0.755743
2019-11-07 10:46:52,676 train 250 1.716121e-02 -0.837042
2019-11-07 10:47:02,469 train 300 1.716100e-02 -0.769235
2019-11-07 10:47:12,266 train 350 1.716140e-02 -0.764937
2019-11-07 10:47:22,062 train 400 1.719162e-02 -0.760251
2019-11-07 10:47:31,876 train 450 1.720009e-02 -0.772194
2019-11-07 10:47:41,668 train 500 1.720340e-02 -0.750766
2019-11-07 10:47:51,460 train 550 1.719475e-02 -0.758731
2019-11-07 10:48:01,273 train 600 1.718087e-02 -0.756925
2019-11-07 10:48:11,093 train 650 1.716053e-02 -0.746077
2019-11-07 10:48:20,894 train 700 1.713366e-02 -0.737999
2019-11-07 10:48:30,719 train 750 1.715752e-02 -0.737816
2019-11-07 10:48:40,547 train 800 1.718074e-02 -0.725965
2019-11-07 10:48:50,372 train 850 1.718371e-02 -0.726579
2019-11-07 10:48:53,308 training loss; R2: 1.717911e-02 -0.735361
2019-11-07 10:48:53,907 valid 000 1.451696e-02 -1.771069
2019-11-07 10:49:03,378 valid 050 1.788883e-02 -1.146610
2019-11-07 10:49:11,694 validation loss; R2: 1.776646e-02 -1.138885
2019-11-07 10:49:11,760 epoch 477 lr 1.000000e-05
2019-11-07 10:49:12,542 train 000 2.137326e-02 -0.710412
2019-11-07 10:49:22,296 train 050 1.766538e-02 -1.184556
2019-11-07 10:49:32,086 train 100 1.755426e-02 -1.006018
2019-11-07 10:49:41,866 train 150 1.738933e-02 -3.745500
2019-11-07 10:49:51,657 train 200 1.734629e-02 -2.968413
2019-11-07 10:50:01,456 train 250 1.738989e-02 -2.485436
2019-11-07 10:50:11,237 train 300 1.731308e-02 -2.183295
2019-11-07 10:50:21,022 train 350 1.731352e-02 -1.997985
2019-11-07 10:50:30,808 train 400 1.734584e-02 -1.884534
2019-11-07 10:50:40,592 train 450 1.735763e-02 -1.736563
2019-11-07 10:50:50,374 train 500 1.740295e-02 -1.631021
2019-11-07 10:51:00,168 train 550 1.740185e-02 -1.529070
2019-11-07 10:51:09,967 train 600 1.736772e-02 -1.584905
2019-11-07 10:51:19,777 train 650 1.740046e-02 -1.548380
2019-11-07 10:51:29,588 train 700 1.739207e-02 -1.476996
2019-11-07 10:51:39,416 train 750 1.738243e-02 -1.419299
2019-11-07 10:51:49,231 train 800 1.735846e-02 -1.376537
2019-11-07 10:51:59,048 train 850 1.735611e-02 -1.334453
2019-11-07 10:52:01,983 training loss; R2: 1.734419e-02 -1.321269
2019-11-07 10:52:02,658 valid 000 1.463281e-02 -1.861600
2019-11-07 10:52:12,028 valid 050 1.633901e-02 -0.739268
2019-11-07 10:52:20,473 validation loss; R2: 1.640430e-02 -1.126674
2019-11-07 10:52:20,545 epoch 478 lr 1.000000e-05
2019-11-07 10:52:21,338 train 000 1.586277e-02 -0.264626
2019-11-07 10:52:31,088 train 050 1.730185e-02 -0.673303
2019-11-07 10:52:40,835 train 100 1.727251e-02 -0.738119
2019-11-07 10:52:50,616 train 150 1.734711e-02 -0.896825
2019-11-07 10:53:00,404 train 200 1.736721e-02 -2.099046
2019-11-07 10:53:10,192 train 250 1.730385e-02 -1.804683
2019-11-07 10:53:19,981 train 300 1.733063e-02 -1.665532
2019-11-07 10:53:29,774 train 350 1.731435e-02 -1.556705
2019-11-07 10:53:39,573 train 400 1.734210e-02 -1.471430
2019-11-07 10:53:49,361 train 450 1.734244e-02 -1.398552
2019-11-07 10:53:59,161 train 500 1.728997e-02 -1.501751
2019-11-07 10:54:08,953 train 550 1.733357e-02 -1.880013
2019-11-07 10:54:18,746 train 600 1.730958e-02 -1.761150
2019-11-07 10:54:28,551 train 650 1.728562e-02 -1.675752
2019-11-07 10:54:38,363 train 700 1.730537e-02 -1.597074
2019-11-07 10:54:48,179 train 750 1.732566e-02 -1.540825
2019-11-07 10:54:58,005 train 800 1.730743e-02 -1.489109
2019-11-07 10:55:07,836 train 850 1.731769e-02 -1.556096
2019-11-07 10:55:10,780 training loss; R2: 1.730625e-02 -1.547633
2019-11-07 10:55:11,416 valid 000 1.870904e-02 -1.176386
2019-11-07 10:55:20,891 valid 050 1.744650e-02 -1.308126
2019-11-07 10:55:29,267 validation loss; R2: 1.741394e-02 -1.212713
2019-11-07 10:55:29,332 epoch 479 lr 1.000000e-05
2019-11-07 10:55:30,123 train 000 1.876189e-02 -0.386223
2019-11-07 10:55:39,856 train 050 1.708254e-02 -0.442911
2019-11-07 10:55:49,606 train 100 1.728540e-02 -0.503405
2019-11-07 10:55:59,397 train 150 1.730024e-02 -0.527138
2019-11-07 10:56:09,180 train 200 1.720461e-02 -0.579894
2019-11-07 10:56:18,946 train 250 1.718033e-02 -0.598633
2019-11-07 10:56:28,728 train 300 1.724068e-02 -0.682515
2019-11-07 10:56:38,510 train 350 1.719787e-02 -0.684860
2019-11-07 10:56:48,669 train 400 1.716525e-02 -0.694789
2019-11-07 10:56:58,808 train 450 1.714085e-02 -0.695095
2019-11-07 10:57:08,966 train 500 1.714265e-02 -0.678907
2019-11-07 10:57:18,909 train 550 1.713299e-02 -0.804782
2019-11-07 10:57:28,722 train 600 1.713599e-02 -0.819562
2019-11-07 10:57:38,523 train 650 1.716578e-02 -0.817827
2019-11-07 10:57:48,320 train 700 1.716690e-02 -0.815667
2019-11-07 10:57:58,137 train 750 1.716051e-02 -0.806060
2019-11-07 10:58:07,953 train 800 1.716888e-02 -0.794258
2019-11-07 10:58:17,779 train 850 1.716277e-02 -0.796000
2019-11-07 10:58:20,709 training loss; R2: 1.716641e-02 -0.790537
2019-11-07 10:58:21,393 valid 000 1.916960e-02 -7.283135
2019-11-07 10:58:30,755 valid 050 1.735383e-02 -1.367727
2019-11-07 10:58:39,076 validation loss; R2: 1.718595e-02 -1.189172
2019-11-07 10:58:39,142 epoch 480 lr 1.000000e-05
2019-11-07 10:58:39,879 train 000 1.806872e-02 -0.040645
2019-11-07 10:58:49,636 train 050 1.716553e-02 -1.086594
2019-11-07 10:58:59,398 train 100 1.714821e-02 -0.884746
2019-11-07 10:59:09,185 train 150 1.718549e-02 -0.793406
2019-11-07 10:59:18,966 train 200 1.718688e-02 -0.835875
2019-11-07 10:59:28,755 train 250 1.721575e-02 -0.837203
2019-11-07 10:59:38,549 train 300 1.719627e-02 -0.958547
2019-11-07 10:59:48,337 train 350 1.720130e-02 -0.932552
2019-11-07 10:59:58,138 train 400 1.720328e-02 -0.875278
2019-11-07 11:00:07,937 train 450 1.721285e-02 -0.855716
2019-11-07 11:00:17,733 train 500 1.721298e-02 -0.867182
2019-11-07 11:00:27,531 train 550 1.720257e-02 -0.844895
2019-11-07 11:00:37,484 train 600 1.721520e-02 -0.830125
2019-11-07 11:00:47,335 train 650 1.721658e-02 -0.803394
2019-11-07 11:00:57,185 train 700 1.724270e-02 -0.807237
2019-11-07 11:01:07,034 train 750 1.723249e-02 -0.800313
2019-11-07 11:01:16,898 train 800 1.721410e-02 -0.794842
2019-11-07 11:01:26,768 train 850 1.723293e-02 -0.793924
2019-11-07 11:01:29,709 training loss; R2: 1.724045e-02 -0.786043
2019-11-07 11:01:30,361 valid 000 1.580204e-02 -0.732455
2019-11-07 11:01:39,767 valid 050 1.664927e-02 -1.432122
2019-11-07 11:01:48,080 validation loss; R2: 1.653538e-02 -1.319689
2019-11-07 11:01:48,143 epoch 481 lr 1.000000e-05
2019-11-07 11:01:48,882 train 000 1.667289e-02 -0.939167
2019-11-07 11:01:58,671 train 050 1.737311e-02 -0.721175
2019-11-07 11:02:08,470 train 100 1.728942e-02 -0.672963
2019-11-07 11:02:18,284 train 150 1.729419e-02 -0.768978
2019-11-07 11:02:28,073 train 200 1.725683e-02 -0.725114
2019-11-07 11:02:37,861 train 250 1.731679e-02 -0.768483
2019-11-07 11:02:47,645 train 300 1.728862e-02 -0.729385
2019-11-07 11:02:57,431 train 350 1.722928e-02 -0.734082
2019-11-07 11:03:07,216 train 400 1.723452e-02 -0.755491
2019-11-07 11:03:17,000 train 450 1.721600e-02 -0.743524
2019-11-07 11:03:26,816 train 500 1.723295e-02 -0.730979
2019-11-07 11:03:36,625 train 550 1.730024e-02 -0.738033
2019-11-07 11:03:46,443 train 600 1.725543e-02 -0.744214
2019-11-07 11:03:56,270 train 650 1.725107e-02 -0.729073
2019-11-07 11:04:06,112 train 700 1.725032e-02 -0.721043
2019-11-07 11:04:15,942 train 750 1.723606e-02 -0.704868
2019-11-07 11:04:25,776 train 800 1.721901e-02 -0.691784
2019-11-07 11:04:35,621 train 850 1.723691e-02 -0.691718
2019-11-07 11:04:38,571 training loss; R2: 1.723896e-02 -0.691672
2019-11-07 11:04:39,194 valid 000 1.611292e-02 -0.154683
2019-11-07 11:04:48,622 valid 050 1.711235e-02 -1.084498
2019-11-07 11:04:56,968 validation loss; R2: 1.698537e-02 -0.947321
2019-11-07 11:04:57,028 epoch 482 lr 1.000000e-05
2019-11-07 11:04:57,805 train 000 1.749455e-02 -0.523457
2019-11-07 11:05:07,558 train 050 1.683423e-02 -11.947424
2019-11-07 11:05:17,354 train 100 1.697558e-02 -6.339223
2019-11-07 11:05:27,155 train 150 1.710195e-02 -4.458528
2019-11-07 11:05:36,932 train 200 1.723803e-02 -4.004761
2019-11-07 11:05:46,737 train 250 1.728378e-02 -3.306581
2019-11-07 11:05:56,557 train 300 1.726457e-02 -2.851944
2019-11-07 11:06:06,375 train 350 1.729450e-02 -2.556942
2019-11-07 11:06:16,200 train 400 1.735859e-02 -2.354890
2019-11-07 11:06:26,010 train 450 1.733988e-02 -2.162713
2019-11-07 11:06:35,810 train 500 1.733584e-02 -2.023202
2019-11-07 11:06:45,625 train 550 1.733655e-02 -1.904571
2019-11-07 11:06:55,453 train 600 1.733035e-02 -1.801573
2019-11-07 11:07:05,277 train 650 1.734459e-02 -1.718241
2019-11-07 11:07:15,127 train 700 1.735926e-02 -1.640963
2019-11-07 11:07:24,966 train 750 1.735017e-02 -1.658791
2019-11-07 11:07:34,800 train 800 1.734230e-02 -1.603436
2019-11-07 11:07:44,635 train 850 1.730764e-02 -1.547894
2019-11-07 11:07:47,572 training loss; R2: 1.731060e-02 -1.534845
2019-11-07 11:07:48,220 valid 000 1.595574e-02 -0.411255
2019-11-07 11:07:57,692 valid 050 1.753415e-02 -1.473098
2019-11-07 11:08:06,079 validation loss; R2: 1.799597e-02 -1.663032
2019-11-07 11:08:06,145 epoch 483 lr 1.000000e-05
2019-11-07 11:08:06,922 train 000 1.767042e-02 -2.189769
2019-11-07 11:08:16,673 train 050 1.715410e-02 -0.847701
2019-11-07 11:08:26,452 train 100 1.734683e-02 -0.759386
2019-11-07 11:08:36,235 train 150 1.726613e-02 -0.687998
2019-11-07 11:08:46,016 train 200 1.727219e-02 -0.709222
2019-11-07 11:08:55,801 train 250 1.726183e-02 -0.683866
2019-11-07 11:09:05,606 train 300 1.728555e-02 -0.690485
2019-11-07 11:09:15,394 train 350 1.725933e-02 -0.704329
2019-11-07 11:09:25,188 train 400 1.725351e-02 -0.724998
2019-11-07 11:09:34,980 train 450 1.723236e-02 -0.726510
2019-11-07 11:09:44,771 train 500 1.722794e-02 -0.718325
2019-11-07 11:09:54,594 train 550 1.720673e-02 -0.712888
2019-11-07 11:10:04,417 train 600 1.721558e-02 -0.705338
2019-11-07 11:10:14,224 train 650 1.722142e-02 -0.709302
2019-11-07 11:10:24,050 train 700 1.722486e-02 -0.701510
2019-11-07 11:10:33,881 train 750 1.724065e-02 -0.712782
2019-11-07 11:10:43,698 train 800 1.724532e-02 -0.712654
2019-11-07 11:10:53,514 train 850 1.722807e-02 -0.721366
2019-11-07 11:10:56,446 training loss; R2: 1.721998e-02 -0.730104
2019-11-07 11:10:57,120 valid 000 1.843060e-02 -0.854569
2019-11-07 11:11:06,515 valid 050 1.744973e-02 -2.683120
2019-11-07 11:11:14,843 validation loss; R2: 1.751639e-02 -1.882847
2019-11-07 11:11:14,909 epoch 484 lr 1.000000e-05
2019-11-07 11:11:15,667 train 000 1.811723e-02 -0.250610
2019-11-07 11:11:25,423 train 050 1.710907e-02 -0.649123
2019-11-07 11:11:35,185 train 100 1.714212e-02 -0.931099
2019-11-07 11:11:44,962 train 150 1.723257e-02 -0.982500
2019-11-07 11:11:54,742 train 200 1.733508e-02 -0.976706
2019-11-07 11:12:04,517 train 250 1.734139e-02 -0.884058
2019-11-07 11:12:14,292 train 300 1.731221e-02 -0.900604
2019-11-07 11:12:24,060 train 350 1.729109e-02 -0.875192
2019-11-07 11:12:33,863 train 400 1.727298e-02 -0.872437
2019-11-07 11:12:43,647 train 450 1.722571e-02 -0.843238
2019-11-07 11:12:53,438 train 500 1.721088e-02 -0.807539
2019-11-07 11:13:03,235 train 550 1.722016e-02 -0.811039
2019-11-07 11:13:13,051 train 600 1.720866e-02 -0.812721
2019-11-07 11:13:22,870 train 650 1.721813e-02 -0.787855
2019-11-07 11:13:32,698 train 700 1.722092e-02 -0.772760
2019-11-07 11:13:42,531 train 750 1.722863e-02 -0.774285
2019-11-07 11:13:52,367 train 800 1.724421e-02 -0.766152
2019-11-07 11:14:02,208 train 850 1.724792e-02 -0.754313
2019-11-07 11:14:05,152 training loss; R2: 1.725417e-02 -0.751839
2019-11-07 11:14:05,747 valid 000 1.876007e-02 0.098208
2019-11-07 11:14:15,200 valid 050 1.702533e-02 -1.075721
2019-11-07 11:14:23,507 validation loss; R2: 1.703656e-02 -1.142661
2019-11-07 11:14:23,575 epoch 485 lr 1.000000e-05
2019-11-07 11:14:24,356 train 000 1.753008e-02 -0.037739
2019-11-07 11:14:34,113 train 050 1.715886e-02 -0.647394
2019-11-07 11:14:43,894 train 100 1.734111e-02 -1.321244
2019-11-07 11:14:53,659 train 150 1.744935e-02 -1.173462
2019-11-07 11:15:03,452 train 200 1.748391e-02 -1.046544
2019-11-07 11:15:13,227 train 250 1.747755e-02 -1.039699
2019-11-07 11:15:23,002 train 300 1.745509e-02 -0.959158
2019-11-07 11:15:32,791 train 350 1.744102e-02 -0.909172
2019-11-07 11:15:42,582 train 400 1.739565e-02 -0.954236
2019-11-07 11:15:52,362 train 450 1.733142e-02 -0.927282
2019-11-07 11:16:02,163 train 500 1.729943e-02 -0.907390
2019-11-07 11:16:11,987 train 550 1.726048e-02 -0.903281
2019-11-07 11:16:21,805 train 600 1.727383e-02 -0.892351
2019-11-07 11:16:31,636 train 650 1.729370e-02 -0.876534
2019-11-07 11:16:41,472 train 700 1.729495e-02 -0.871200
2019-11-07 11:16:51,331 train 750 1.726715e-02 -0.859147
2019-11-07 11:17:01,170 train 800 1.723695e-02 -0.869829
2019-11-07 11:17:11,017 train 850 1.722044e-02 -0.865098
2019-11-07 11:17:13,964 training loss; R2: 1.723515e-02 -0.860569
2019-11-07 11:17:14,648 valid 000 1.749658e-02 -2.484458
2019-11-07 11:17:24,035 valid 050 1.773833e-02 -1.278869
2019-11-07 11:17:32,378 validation loss; R2: 1.787387e-02 -1.177731
2019-11-07 11:17:32,444 epoch 486 lr 1.000000e-05
2019-11-07 11:17:33,210 train 000 1.800619e-02 0.035754
2019-11-07 11:17:42,988 train 050 1.716162e-02 -0.782952
2019-11-07 11:17:52,773 train 100 1.716429e-02 -0.687324
2019-11-07 11:18:02,564 train 150 1.715843e-02 -0.713626
2019-11-07 11:18:12,400 train 200 1.726484e-02 -0.712315
2019-11-07 11:18:22,190 train 250 1.722661e-02 -0.685858
2019-11-07 11:18:31,989 train 300 1.719407e-02 -0.704372
2019-11-07 11:18:41,784 train 350 1.721711e-02 -0.699688
2019-11-07 11:18:51,582 train 400 1.724036e-02 -0.676694
2019-11-07 11:19:01,392 train 450 1.720494e-02 -0.712691
2019-11-07 11:19:11,218 train 500 1.723958e-02 -0.737568
2019-11-07 11:19:21,132 train 550 1.723967e-02 -0.735399
2019-11-07 11:19:30,959 train 600 1.724849e-02 -0.736117
2019-11-07 11:19:40,808 train 650 1.718992e-02 -0.716354
2019-11-07 11:19:50,645 train 700 1.719458e-02 -0.708215
2019-11-07 11:20:00,493 train 750 1.718789e-02 -0.738600
2019-11-07 11:20:10,329 train 800 1.717155e-02 -0.738186
2019-11-07 11:20:20,163 train 850 1.719135e-02 -0.734701
2019-11-07 11:20:23,108 training loss; R2: 1.719064e-02 -0.734802
2019-11-07 11:20:23,766 valid 000 1.598682e-02 0.019552
2019-11-07 11:20:33,181 valid 050 1.779545e-02 -1.192012
2019-11-07 11:20:41,494 validation loss; R2: 1.801124e-02 -1.091767
2019-11-07 11:20:41,560 epoch 487 lr 1.000000e-05
2019-11-07 11:20:42,301 train 000 1.733212e-02 -8.542953
2019-11-07 11:20:52,084 train 050 1.754511e-02 -0.904367
2019-11-07 11:21:01,851 train 100 1.734276e-02 -0.971946
2019-11-07 11:21:11,647 train 150 1.726283e-02 -0.814118
2019-11-07 11:21:21,460 train 200 1.719032e-02 -0.768120
2019-11-07 11:21:31,273 train 250 1.718064e-02 -0.698653
2019-11-07 11:21:41,073 train 300 1.720398e-02 -0.712563
2019-11-07 11:21:50,887 train 350 1.720384e-02 -0.719550
2019-11-07 11:22:00,685 train 400 1.716271e-02 -0.712403
2019-11-07 11:22:10,516 train 450 1.718154e-02 -0.725507
2019-11-07 11:22:20,340 train 500 1.720816e-02 -0.779533
2019-11-07 11:22:30,181 train 550 1.720130e-02 -0.789843
2019-11-07 11:22:40,018 train 600 1.719158e-02 -0.787509
2019-11-07 11:22:49,864 train 650 1.721589e-02 -0.792578
2019-11-07 11:22:59,716 train 700 1.720684e-02 -0.783154
2019-11-07 11:23:09,576 train 750 1.719473e-02 -0.781082
2019-11-07 11:23:19,440 train 800 1.719112e-02 -0.790211
2019-11-07 11:23:29,312 train 850 1.720914e-02 -0.796546
2019-11-07 11:23:32,265 training loss; R2: 1.720927e-02 -0.794990
2019-11-07 11:23:32,959 valid 000 1.413161e-02 -3.933630
2019-11-07 11:23:42,321 valid 050 1.558831e-02 -0.870968
2019-11-07 11:23:50,781 validation loss; R2: 1.555740e-02 -0.892881
2019-11-07 11:23:50,864 epoch 488 lr 1.000000e-05
2019-11-07 11:23:51,677 train 000 1.638245e-02 -0.036289
2019-11-07 11:24:01,482 train 050 1.682013e-02 -0.667304
2019-11-07 11:24:11,282 train 100 1.705457e-02 -0.769316
2019-11-07 11:24:21,084 train 150 1.708207e-02 -2.052593
2019-11-07 11:24:30,886 train 200 1.708673e-02 -1.773756
2019-11-07 11:24:40,684 train 250 1.712358e-02 -1.594302
2019-11-07 11:24:50,490 train 300 1.709552e-02 -1.428346
2019-11-07 11:25:00,321 train 350 1.710311e-02 -1.341602
2019-11-07 11:25:10,150 train 400 1.712574e-02 -1.233299
2019-11-07 11:25:19,995 train 450 1.715894e-02 -1.180357
2019-11-07 11:25:29,845 train 500 1.717239e-02 -1.111267
2019-11-07 11:25:39,703 train 550 1.717331e-02 -1.086841
2019-11-07 11:25:49,569 train 600 1.721619e-02 -1.067436
2019-11-07 11:25:59,441 train 650 1.721879e-02 -1.029462
2019-11-07 11:26:09,332 train 700 1.720173e-02 -1.004977
2019-11-07 11:26:19,229 train 750 1.719449e-02 -0.990975
2019-11-07 11:26:29,079 train 800 1.718882e-02 -0.966592
2019-11-07 11:26:38,955 train 850 1.719540e-02 -0.951090
2019-11-07 11:26:41,903 training loss; R2: 1.719256e-02 -0.953673
2019-11-07 11:26:42,601 valid 000 1.562995e-02 -0.011734
2019-11-07 11:26:51,988 valid 050 1.730148e-02 -1.074377
2019-11-07 11:27:00,334 validation loss; R2: 1.726394e-02 -0.992307
2019-11-07 11:27:00,397 epoch 489 lr 1.000000e-05
2019-11-07 11:27:01,169 train 000 1.363370e-02 -1.092742
2019-11-07 11:27:10,949 train 050 1.783946e-02 -0.547337
2019-11-07 11:27:20,744 train 100 1.757253e-02 -0.660621
2019-11-07 11:27:30,532 train 150 1.743241e-02 -0.705780
2019-11-07 11:27:40,306 train 200 1.737032e-02 -0.818831
2019-11-07 11:27:50,095 train 250 1.731722e-02 -0.871378
2019-11-07 11:27:59,882 train 300 1.731407e-02 -0.873332
2019-11-07 11:28:09,677 train 350 1.730156e-02 -0.994183
2019-11-07 11:28:19,489 train 400 1.732028e-02 -1.000219
2019-11-07 11:28:29,317 train 450 1.730396e-02 -0.974356
2019-11-07 11:28:39,153 train 500 1.728108e-02 -0.952613
2019-11-07 11:28:48,990 train 550 1.726399e-02 -0.941737
2019-11-07 11:28:58,838 train 600 1.725009e-02 -1.033306
2019-11-07 11:29:08,718 train 650 1.723848e-02 -0.999061
2019-11-07 11:29:18,572 train 700 1.724157e-02 -0.995931
2019-11-07 11:29:28,428 train 750 1.724479e-02 -0.992554
2019-11-07 11:29:38,295 train 800 1.723794e-02 -0.961329
2019-11-07 11:29:48,175 train 850 1.725115e-02 -0.940059
2019-11-07 11:29:51,153 training loss; R2: 1.725267e-02 -0.939660
2019-11-07 11:29:51,815 valid 000 1.887232e-02 -1.280913
2019-11-07 11:30:01,284 valid 050 1.760404e-02 -1.827857
2019-11-07 11:30:09,628 validation loss; R2: 1.781163e-02 -1.433513
2019-11-07 11:30:09,707 epoch 490 lr 1.000000e-05
2019-11-07 11:30:10,512 train 000 1.780803e-02 0.012564
2019-11-07 11:30:20,277 train 050 1.706424e-02 -0.646244
2019-11-07 11:30:30,046 train 100 1.715625e-02 -0.642748
2019-11-07 11:30:39,822 train 150 1.712052e-02 -0.698024
2019-11-07 11:30:49,602 train 200 1.713378e-02 -0.697907
2019-11-07 11:30:59,377 train 250 1.721243e-02 -0.701505
2019-11-07 11:31:09,160 train 300 1.721891e-02 -0.713591
2019-11-07 11:31:18,942 train 350 1.724967e-02 -0.719511
2019-11-07 11:31:28,737 train 400 1.728398e-02 -0.978112
2019-11-07 11:31:38,529 train 450 1.724748e-02 -0.959320
2019-11-07 11:31:48,335 train 500 1.727095e-02 -0.968995
2019-11-07 11:31:58,154 train 550 1.726156e-02 -0.962300
2019-11-07 11:32:07,969 train 600 1.726992e-02 -0.949308
2019-11-07 11:32:17,768 train 650 1.725487e-02 -0.926641
2019-11-07 11:32:27,571 train 700 1.726136e-02 -0.906429
2019-11-07 11:32:37,367 train 750 1.725904e-02 -0.912136
2019-11-07 11:32:47,206 train 800 1.725681e-02 -0.895535
2019-11-07 11:32:57,036 train 850 1.725310e-02 -0.882874
2019-11-07 11:32:59,975 training loss; R2: 1.725318e-02 -0.878462
2019-11-07 11:33:00,633 valid 000 1.680651e-02 -2.852243
2019-11-07 11:33:10,032 valid 050 1.677727e-02 -1.141182
2019-11-07 11:33:18,343 validation loss; R2: 1.694161e-02 -1.170456
2019-11-07 11:33:18,408 epoch 491 lr 1.000000e-05
2019-11-07 11:33:19,143 train 000 1.846076e-02 -0.845109
2019-11-07 11:33:28,918 train 050 1.735093e-02 -0.597393
2019-11-07 11:33:38,711 train 100 1.722606e-02 -0.599039
2019-11-07 11:33:48,497 train 150 1.718565e-02 -0.599776
2019-11-07 11:33:58,295 train 200 1.710903e-02 -0.634971
2019-11-07 11:34:08,084 train 250 1.708542e-02 -0.633491
2019-11-07 11:34:17,877 train 300 1.710209e-02 -0.659663
2019-11-07 11:34:27,666 train 350 1.715174e-02 -0.646348
2019-11-07 11:34:37,457 train 400 1.714826e-02 -0.657836
2019-11-07 11:34:47,241 train 450 1.717878e-02 -0.656352
2019-11-07 11:34:57,012 train 500 1.717520e-02 -0.644935
2019-11-07 11:35:06,793 train 550 1.719549e-02 -0.661778
2019-11-07 11:35:16,573 train 600 1.719983e-02 -0.651952
2019-11-07 11:35:26,356 train 650 1.722105e-02 -0.657624
2019-11-07 11:35:36,142 train 700 1.722625e-02 -0.669568
2019-11-07 11:35:45,947 train 750 1.720792e-02 -0.671099
2019-11-07 11:35:55,783 train 800 1.719421e-02 -0.691554
2019-11-07 11:36:05,613 train 850 1.721580e-02 -0.681827
2019-11-07 11:36:08,555 training loss; R2: 1.721211e-02 -0.680430
2019-11-07 11:36:09,217 valid 000 1.687214e-02 -0.691229
2019-11-07 11:36:18,619 valid 050 1.751933e-02 -1.036732
2019-11-07 11:36:26,925 validation loss; R2: 1.741945e-02 -1.220380
2019-11-07 11:36:26,991 epoch 492 lr 1.000000e-05
2019-11-07 11:36:27,799 train 000 2.091712e-02 -0.415923
2019-11-07 11:36:37,560 train 050 1.736939e-02 -0.728113
2019-11-07 11:36:47,341 train 100 1.730844e-02 -0.656753
2019-11-07 11:36:57,298 train 150 1.741305e-02 -0.627209
2019-11-07 11:37:07,469 train 200 1.746416e-02 -0.648440
2019-11-07 11:37:17,624 train 250 1.740395e-02 -0.616384
2019-11-07 11:37:27,791 train 300 1.739395e-02 -50.755429
2019-11-07 11:37:37,948 train 350 1.740901e-02 -43.668836
2019-11-07 11:37:48,111 train 400 1.735459e-02 -38.312976
2019-11-07 11:37:58,281 train 450 1.734244e-02 -34.154326
2019-11-07 11:38:08,443 train 500 1.733146e-02 -30.793596
2019-11-07 11:38:18,591 train 550 1.731971e-02 -28.120330
2019-11-07 11:38:28,769 train 600 1.732442e-02 -25.835076
2019-11-07 11:38:38,982 train 650 1.731346e-02 -23.899468
2019-11-07 11:38:49,216 train 700 1.729796e-02 -22.227302
2019-11-07 11:38:59,433 train 750 1.729188e-02 -20.796285
2019-11-07 11:39:09,654 train 800 1.728090e-02 -19.569417
2019-11-07 11:39:19,894 train 850 1.725915e-02 -18.470430
2019-11-07 11:39:22,947 training loss; R2: 1.725093e-02 -18.170959
2019-11-07 11:39:23,597 valid 000 1.789097e-02 -0.106969
2019-11-07 11:39:33,010 valid 050 1.669847e-02 -1.235112
2019-11-07 11:39:41,344 validation loss; R2: 1.682305e-02 -1.073754
2019-11-07 11:39:41,418 epoch 493 lr 1.000000e-05
2019-11-07 11:39:42,155 train 000 1.817452e-02 -0.508068
2019-11-07 11:39:52,298 train 050 1.763420e-02 -0.589839
2019-11-07 11:40:02,460 train 100 1.730068e-02 -0.641200
2019-11-07 11:40:12,645 train 150 1.744415e-02 -0.654148
2019-11-07 11:40:22,678 train 200 1.732082e-02 -0.654451
2019-11-07 11:40:32,501 train 250 1.724360e-02 -0.693168
2019-11-07 11:40:42,293 train 300 1.728030e-02 -0.692240
2019-11-07 11:40:52,079 train 350 1.730922e-02 -0.699208
2019-11-07 11:41:01,872 train 400 1.734638e-02 -0.702212
2019-11-07 11:41:11,669 train 450 1.731444e-02 -0.738063
2019-11-07 11:41:21,479 train 500 1.731841e-02 -0.739479
2019-11-07 11:41:31,299 train 550 1.730780e-02 -0.736047
2019-11-07 11:41:41,117 train 600 1.728274e-02 -0.750356
2019-11-07 11:41:50,952 train 650 1.728662e-02 -0.772270
2019-11-07 11:42:00,791 train 700 1.728875e-02 -0.756857
2019-11-07 11:42:10,627 train 750 1.728818e-02 -0.743838
2019-11-07 11:42:20,462 train 800 1.725854e-02 -0.736333
2019-11-07 11:42:30,313 train 850 1.726500e-02 -0.757406
2019-11-07 11:42:33,254 training loss; R2: 1.727243e-02 -0.751604
2019-11-07 11:42:33,943 valid 000 2.100882e-02 0.057352
2019-11-07 11:42:43,333 valid 050 1.777158e-02 -1.187612
2019-11-07 11:42:51,679 validation loss; R2: 1.776960e-02 -1.149538
2019-11-07 11:42:51,758 epoch 494 lr 1.000000e-05
2019-11-07 11:42:52,539 train 000 1.645840e-02 -0.154587
2019-11-07 11:43:02,330 train 050 1.763543e-02 -0.670892
2019-11-07 11:43:12,130 train 100 1.767256e-02 -0.612740
2019-11-07 11:43:21,922 train 150 1.741239e-02 -0.653861
2019-11-07 11:43:31,726 train 200 1.740775e-02 -0.807052
2019-11-07 11:43:41,542 train 250 1.737686e-02 -0.785157
2019-11-07 11:43:51,338 train 300 1.740768e-02 -0.776917
2019-11-07 11:44:01,131 train 350 1.736237e-02 -0.776815
2019-11-07 11:44:10,923 train 400 1.733269e-02 -0.762870
2019-11-07 11:44:20,741 train 450 1.734148e-02 -0.760668
2019-11-07 11:44:30,564 train 500 1.735720e-02 -0.738175
2019-11-07 11:44:40,386 train 550 1.734951e-02 -0.725921
2019-11-07 11:44:50,223 train 600 1.731249e-02 -0.778898
2019-11-07 11:45:00,068 train 650 1.727204e-02 -0.771841
2019-11-07 11:45:09,908 train 700 1.729621e-02 -0.770034
2019-11-07 11:45:19,767 train 750 1.726921e-02 -0.772410
2019-11-07 11:45:29,616 train 800 1.725313e-02 -0.755491
2019-11-07 11:45:39,488 train 850 1.723480e-02 -0.769208
2019-11-07 11:45:42,440 training loss; R2: 1.723643e-02 -0.764088
2019-11-07 11:45:43,113 valid 000 1.420754e-02 -0.101460
2019-11-07 11:45:52,531 valid 050 1.763852e-02 -1.030752
2019-11-07 11:46:00,938 validation loss; R2: 1.769504e-02 -1.359744
2019-11-07 11:46:01,003 epoch 495 lr 1.000000e-05
2019-11-07 11:46:01,757 train 000 1.645976e-02 -0.658946
2019-11-07 11:46:11,517 train 050 1.720206e-02 -0.799514
2019-11-07 11:46:21,277 train 100 1.716199e-02 -0.756760
2019-11-07 11:46:31,060 train 150 1.717267e-02 -0.710464
2019-11-07 11:46:40,848 train 200 1.730162e-02 -0.698486
2019-11-07 11:46:50,637 train 250 1.730659e-02 -0.739691
2019-11-07 11:47:00,437 train 300 1.733832e-02 -0.739448
2019-11-07 11:47:10,237 train 350 1.731517e-02 -0.733521
2019-11-07 11:47:20,047 train 400 1.726249e-02 -0.749151
2019-11-07 11:47:29,856 train 450 1.726333e-02 -0.729366
2019-11-07 11:47:39,683 train 500 1.726133e-02 -0.715494
2019-11-07 11:47:49,526 train 550 1.724665e-02 -0.736477
2019-11-07 11:47:59,364 train 600 1.722224e-02 -0.722790
2019-11-07 11:48:09,217 train 650 1.724690e-02 -0.703653
2019-11-07 11:48:19,074 train 700 1.724490e-02 -0.704573
2019-11-07 11:48:28,939 train 750 1.723995e-02 -0.713969
2019-11-07 11:48:38,817 train 800 1.726315e-02 -0.727538
2019-11-07 11:48:48,679 train 850 1.726535e-02 -0.746155
2019-11-07 11:48:51,618 training loss; R2: 1.727591e-02 -0.738787
2019-11-07 11:48:52,254 valid 000 1.538772e-02 0.066326
2019-11-07 11:49:01,685 valid 050 1.599587e-02 -0.874939
2019-11-07 11:49:09,961 validation loss; R2: 1.596191e-02 -0.886794
2019-11-07 11:49:10,026 epoch 496 lr 1.000000e-05
2019-11-07 11:49:10,809 train 000 1.760821e-02 0.006839
2019-11-07 11:49:20,565 train 050 1.762553e-02 -0.486211
2019-11-07 11:49:30,335 train 100 1.709172e-02 -0.743119
2019-11-07 11:49:40,133 train 150 1.731872e-02 -0.732621
2019-11-07 11:49:49,922 train 200 1.724400e-02 -0.699495
2019-11-07 11:49:59,701 train 250 1.718928e-02 -0.678407
2019-11-07 11:50:09,497 train 300 1.723276e-02 -0.691435
2019-11-07 11:50:19,321 train 350 1.725991e-02 -0.677666
2019-11-07 11:50:29,126 train 400 1.724662e-02 -0.683467
2019-11-07 11:50:38,946 train 450 1.728538e-02 -0.691768
2019-11-07 11:50:48,782 train 500 1.728745e-02 -0.697526
2019-11-07 11:50:58,642 train 550 1.731927e-02 -0.755132
2019-11-07 11:51:08,468 train 600 1.729638e-02 -0.752871
2019-11-07 11:51:18,313 train 650 1.727235e-02 -0.771879
2019-11-07 11:51:28,162 train 700 1.727150e-02 -0.758756
2019-11-07 11:51:38,017 train 750 1.726578e-02 -0.773920
2019-11-07 11:51:47,871 train 800 1.727321e-02 -0.761482
2019-11-07 11:51:57,736 train 850 1.725979e-02 -0.755293
2019-11-07 11:52:00,684 training loss; R2: 1.725785e-02 -0.757004
2019-11-07 11:52:01,370 valid 000 1.603078e-02 -1.098122
2019-11-07 11:52:10,752 valid 050 1.636639e-02 -1.135162
2019-11-07 11:52:19,117 validation loss; R2: 1.630095e-02 -1.032683
2019-11-07 11:52:19,181 epoch 497 lr 1.000000e-05
2019-11-07 11:52:19,957 train 000 1.698706e-02 -0.418030
2019-11-07 11:52:29,730 train 050 1.702582e-02 -0.873422
2019-11-07 11:52:39,515 train 100 1.690341e-02 -0.642569
2019-11-07 11:52:49,326 train 150 1.695536e-02 -0.774779
2019-11-07 11:52:59,150 train 200 1.711063e-02 -0.850145
2019-11-07 11:53:08,964 train 250 1.715597e-02 -0.864103
2019-11-07 11:53:18,785 train 300 1.721923e-02 -0.870979
2019-11-07 11:53:28,597 train 350 1.723870e-02 -0.877630
2019-11-07 11:53:38,428 train 400 1.723808e-02 -0.850462
2019-11-07 11:53:48,264 train 450 1.726592e-02 -0.868371
2019-11-07 11:53:58,131 train 500 1.726111e-02 -0.843796
2019-11-07 11:54:07,994 train 550 1.723438e-02 -0.829736
2019-11-07 11:54:17,852 train 600 1.723039e-02 -0.821197
2019-11-07 11:54:27,702 train 650 1.723814e-02 -0.850197
2019-11-07 11:54:37,550 train 700 1.722335e-02 -0.838676
2019-11-07 11:54:47,398 train 750 1.723545e-02 -0.824627
2019-11-07 11:54:57,246 train 800 1.725993e-02 -0.812506
2019-11-07 11:55:07,080 train 850 1.725387e-02 -0.806187
2019-11-07 11:55:10,031 training loss; R2: 1.725294e-02 -0.799663
2019-11-07 11:55:10,732 valid 000 1.712957e-02 0.009120
2019-11-07 11:55:20,070 valid 050 1.632173e-02 -1.405751
2019-11-07 11:55:28,570 validation loss; R2: 1.639491e-02 -1.166818
2019-11-07 11:55:28,636 epoch 498 lr 1.000000e-05
2019-11-07 11:55:29,391 train 000 1.683252e-02 -0.047209
2019-11-07 11:55:39,139 train 050 1.689832e-02 -0.638296
2019-11-07 11:55:48,899 train 100 1.699362e-02 -0.682457
2019-11-07 11:55:58,666 train 150 1.704345e-02 -0.646336
2019-11-07 11:56:08,453 train 200 1.702937e-02 -0.670422
2019-11-07 11:56:18,233 train 250 1.704744e-02 -0.694418
2019-11-07 11:56:28,013 train 300 1.711563e-02 -0.698918
2019-11-07 11:56:37,800 train 350 1.714057e-02 -0.663406
2019-11-07 11:56:47,598 train 400 1.713120e-02 -0.682961
2019-11-07 11:56:57,400 train 450 1.710355e-02 -0.706469
2019-11-07 11:57:07,226 train 500 1.708571e-02 -0.713007
2019-11-07 11:57:17,046 train 550 1.708584e-02 -0.749143
2019-11-07 11:57:26,889 train 600 1.712436e-02 -0.730163
2019-11-07 11:57:36,733 train 650 1.715443e-02 -0.745774
2019-11-07 11:57:46,587 train 700 1.718026e-02 -0.738218
2019-11-07 11:57:56,465 train 750 1.716509e-02 -0.739621
2019-11-07 11:58:06,341 train 800 1.714607e-02 -0.720436
2019-11-07 11:58:16,210 train 850 1.713237e-02 -0.721210
2019-11-07 11:58:19,158 training loss; R2: 1.712309e-02 -0.716965
2019-11-07 11:58:19,833 valid 000 1.809807e-02 -0.496432
2019-11-07 11:58:29,159 valid 050 1.795691e-02 -1.482176
2019-11-07 11:58:37,526 validation loss; R2: 1.800221e-02 -1.319136
2019-11-07 11:58:37,585 epoch 499 lr 1.000000e-05
2019-11-07 11:58:38,356 train 000 1.855769e-02 0.071935
2019-11-07 11:58:48,121 train 050 1.727594e-02 -0.694712
2019-11-07 11:58:57,892 train 100 1.730967e-02 -0.642666
2019-11-07 11:59:07,661 train 150 1.723169e-02 -0.637140
2019-11-07 11:59:17,449 train 200 1.728444e-02 -0.655559
2019-11-07 11:59:27,237 train 250 1.723766e-02 -1.110974
2019-11-07 11:59:37,017 train 300 1.719675e-02 -1.067763
2019-11-07 11:59:46,801 train 350 1.725498e-02 -0.982507
2019-11-07 11:59:56,622 train 400 1.725329e-02 -1.131698
2019-11-07 12:00:06,449 train 450 1.724357e-02 -1.083380
2019-11-07 12:00:16,298 train 500 1.725933e-02 -1.040296
2019-11-07 12:00:26,148 train 550 1.722021e-02 -1.004375
2019-11-07 12:00:36,049 train 600 1.722502e-02 -0.972009
2019-11-07 12:00:45,981 train 650 1.721582e-02 -0.954278
2019-11-07 12:00:55,909 train 700 1.723476e-02 -0.948724
2019-11-07 12:01:05,820 train 750 1.723955e-02 -0.920528
2019-11-07 12:01:15,752 train 800 1.727033e-02 -0.918984
2019-11-07 12:01:25,674 train 850 1.727292e-02 -0.900958
2019-11-07 12:01:28,645 training loss; R2: 1.727575e-02 -0.899944
2019-11-07 12:01:29,349 valid 000 2.020128e-02 -0.726610
2019-11-07 12:01:38,685 valid 050 1.715596e-02 -1.163513
2019-11-07 12:01:47,044 validation loss; R2: 1.730231e-02 -1.391284
2019-11-07 12:01:47,111 epoch 500 lr 1.000000e-05
2019-11-07 12:01:47,893 train 000 1.883728e-02 0.133660
2019-11-07 12:01:57,691 train 050 1.720880e-02 -0.470573
2019-11-07 12:02:07,512 train 100 1.712426e-02 -0.690944
2019-11-07 12:02:17,327 train 150 1.721452e-02 -0.669617
2019-11-07 12:02:27,150 train 200 1.720421e-02 -0.643968
2019-11-07 12:02:36,962 train 250 1.718374e-02 -0.685795
2019-11-07 12:02:46,784 train 300 1.729240e-02 -0.697969
2019-11-07 12:02:56,575 train 350 1.725610e-02 -0.700587
2019-11-07 12:03:06,372 train 400 1.723793e-02 -0.671556
2019-11-07 12:03:16,206 train 450 1.725254e-02 -0.702127
2019-11-07 12:03:26,035 train 500 1.727629e-02 -0.706768
2019-11-07 12:03:35,887 train 550 1.726773e-02 -0.689751
2019-11-07 12:03:45,740 train 600 1.724991e-02 -0.692763
2019-11-07 12:03:55,614 train 650 1.720846e-02 -0.691828
2019-11-07 12:04:05,479 train 700 1.717270e-02 -0.683415
2019-11-07 12:04:15,357 train 750 1.717205e-02 -0.707762
2019-11-07 12:04:25,205 train 800 1.715540e-02 -0.701638
2019-11-07 12:04:35,082 train 850 1.717658e-02 -0.708816
2019-11-07 12:04:38,042 training loss; R2: 1.717965e-02 -0.708226
2019-11-07 12:04:38,716 valid 000 2.041642e-02 -0.362319
2019-11-07 12:04:48,078 valid 050 1.664427e-02 -1.269441
2019-11-07 12:04:56,412 validation loss; R2: 1.654613e-02 -1.191853
2019-11-07 12:04:56,477 epoch 501 lr 1.000000e-05
2019-11-07 12:04:57,201 train 000 1.869720e-02 -0.583162
2019-11-07 12:05:06,970 train 050 1.735004e-02 -0.772917
2019-11-07 12:05:16,738 train 100 1.722479e-02 -0.860667
2019-11-07 12:05:26,511 train 150 1.723265e-02 -0.767964
2019-11-07 12:05:36,303 train 200 1.712361e-02 -0.735711
2019-11-07 12:05:46,093 train 250 1.720358e-02 -0.784127
2019-11-07 12:05:55,879 train 300 1.722372e-02 -0.804114
2019-11-07 12:06:05,676 train 350 1.717884e-02 -2.079629
2019-11-07 12:06:15,516 train 400 1.717203e-02 -1.921584
2019-11-07 12:06:25,379 train 450 1.720437e-02 -1.808072
2019-11-07 12:06:35,250 train 500 1.725262e-02 -1.703131
2019-11-07 12:06:45,121 train 550 1.723298e-02 -1.609096
2019-11-07 12:06:54,984 train 600 1.721949e-02 -1.520825
2019-11-07 12:07:04,866 train 650 1.721822e-02 -1.464590
2019-11-07 12:07:14,745 train 700 1.718772e-02 -1.404838
2019-11-07 12:07:24,627 train 750 1.719025e-02 -1.358411
2019-11-07 12:07:34,502 train 800 1.716871e-02 -1.316278
2019-11-07 12:07:44,396 train 850 1.716581e-02 -1.272323
2019-11-07 12:07:47,344 training loss; R2: 1.715568e-02 -1.265184
2019-11-07 12:07:47,999 valid 000 1.780253e-02 -2.823546
2019-11-07 12:07:57,430 valid 050 1.645983e-02 -1.137915
2019-11-07 12:08:05,754 validation loss; R2: 1.662832e-02 -1.094364
2019-11-07 12:08:05,819 epoch 502 lr 1.000000e-05
2019-11-07 12:08:06,644 train 000 1.692686e-02 -3.455755
2019-11-07 12:08:16,412 train 050 1.717539e-02 -0.737284
2019-11-07 12:08:26,220 train 100 1.702268e-02 -0.724065
2019-11-07 12:08:36,006 train 150 1.702794e-02 -0.632953
2019-11-07 12:08:45,805 train 200 1.710222e-02 -0.637577
2019-11-07 12:08:55,622 train 250 1.713449e-02 -0.670266
2019-11-07 12:09:05,434 train 300 1.716551e-02 -0.764070
2019-11-07 12:09:15,242 train 350 1.717644e-02 -0.720620
2019-11-07 12:09:25,091 train 400 1.720028e-02 -0.719133
2019-11-07 12:09:34,957 train 450 1.719764e-02 -0.693502
2019-11-07 12:09:44,825 train 500 1.724429e-02 -0.679447
2019-11-07 12:09:54,710 train 550 1.720640e-02 -0.670775
2019-11-07 12:10:04,588 train 600 1.720725e-02 -0.686903
2019-11-07 12:10:14,463 train 650 1.719486e-02 -0.686347
2019-11-07 12:10:24,333 train 700 1.720835e-02 -0.683571
2019-11-07 12:10:34,212 train 750 1.722388e-02 -0.705645
2019-11-07 12:10:44,086 train 800 1.722965e-02 -3.827251
2019-11-07 12:10:53,981 train 850 1.720158e-02 -3.639819
2019-11-07 12:10:56,935 training loss; R2: 1.719617e-02 -3.583159
2019-11-07 12:10:57,628 valid 000 1.532648e-02 -2.296597
2019-11-07 12:11:07,030 valid 050 1.597310e-02 -1.229338
2019-11-07 12:11:15,350 validation loss; R2: 1.614818e-02 -1.104353
2019-11-07 12:11:15,415 epoch 503 lr 1.000000e-05
2019-11-07 12:11:16,141 train 000 1.315971e-02 -0.591337
2019-11-07 12:11:25,907 train 050 1.723619e-02 -0.518373
2019-11-07 12:11:35,683 train 100 1.740400e-02 -0.599355
2019-11-07 12:11:45,461 train 150 1.745140e-02 -5.809170
2019-11-07 12:11:55,239 train 200 1.724102e-02 -4.521458
2019-11-07 12:12:05,027 train 250 1.717399e-02 -3.761792
2019-11-07 12:12:14,817 train 300 1.719256e-02 -3.291557
2019-11-07 12:12:24,632 train 350 1.722262e-02 -2.927158
2019-11-07 12:12:34,464 train 400 1.725617e-02 -2.647664
2019-11-07 12:12:44,318 train 450 1.724029e-02 -2.440481
2019-11-07 12:12:54,194 train 500 1.725453e-02 -2.273873
2019-11-07 12:13:04,082 train 550 1.725542e-02 -2.119672
2019-11-07 12:13:13,984 train 600 1.728251e-02 -1.999556
2019-11-07 12:13:23,877 train 650 1.724818e-02 -1.893622
2019-11-07 12:13:33,760 train 700 1.725346e-02 -1.812069
2019-11-07 12:13:43,652 train 750 1.726419e-02 -1.730148
2019-11-07 12:13:53,554 train 800 1.725543e-02 -1.656172
2019-11-07 12:14:03,438 train 850 1.723876e-02 -1.630084
2019-11-07 12:14:06,383 training loss; R2: 1.723942e-02 -1.620207
2019-11-07 12:14:07,025 valid 000 1.417650e-02 -1.831681
2019-11-07 12:14:16,431 valid 050 1.644385e-02 -1.118802
2019-11-07 12:14:24,745 validation loss; R2: 1.654440e-02 -1.414869
2019-11-07 12:14:24,811 epoch 504 lr 1.000000e-05
2019-11-07 12:14:25,562 train 000 1.575256e-02 -0.640945
2019-11-07 12:14:35,316 train 050 1.732119e-02 -1.141355
2019-11-07 12:14:45,084 train 100 1.708424e-02 -1.050693
2019-11-07 12:14:54,885 train 150 1.711810e-02 -0.949765
2019-11-07 12:15:04,674 train 200 1.709950e-02 -0.878756
2019-11-07 12:15:14,465 train 250 1.714346e-02 -0.817664
2019-11-07 12:15:24,267 train 300 1.712225e-02 -0.780663
2019-11-07 12:15:34,092 train 350 1.710932e-02 -0.749238
2019-11-07 12:15:43,920 train 400 1.710103e-02 -0.733054
2019-11-07 12:15:53,753 train 450 1.712675e-02 -0.738364
2019-11-07 12:16:03,597 train 500 1.713623e-02 -0.741947
2019-11-07 12:16:13,449 train 550 1.716189e-02 -0.736838
2019-11-07 12:16:23,301 train 600 1.720152e-02 -0.743406
2019-11-07 12:16:33,163 train 650 1.717276e-02 -0.724274
2019-11-07 12:16:43,019 train 700 1.716479e-02 -0.748506
2019-11-07 12:16:52,876 train 750 1.716343e-02 -0.815755
2019-11-07 12:17:02,734 train 800 1.718826e-02 -0.803580
2019-11-07 12:17:12,592 train 850 1.717766e-02 -0.803194
2019-11-07 12:17:15,542 training loss; R2: 1.718567e-02 -0.813582
2019-11-07 12:17:16,172 valid 000 1.838477e-02 -6.684091
2019-11-07 12:17:25,615 valid 050 1.871239e-02 -2.303978
2019-11-07 12:17:34,030 validation loss; R2: 1.894232e-02 -1.907211
2019-11-07 12:17:34,096 epoch 505 lr 1.000000e-05
2019-11-07 12:17:34,890 train 000 1.666259e-02 -0.234221
2019-11-07 12:17:44,655 train 050 1.669894e-02 -0.576542
2019-11-07 12:17:54,442 train 100 1.686552e-02 -1.695316
2019-11-07 12:18:04,235 train 150 1.696689e-02 -1.385609
2019-11-07 12:18:14,017 train 200 1.698031e-02 -1.334741
2019-11-07 12:18:23,813 train 250 1.697109e-02 -1.259161
2019-11-07 12:18:33,597 train 300 1.700959e-02 -1.186447
2019-11-07 12:18:43,373 train 350 1.710451e-02 -1.188862
2019-11-07 12:18:53,144 train 400 1.711914e-02 -1.152666
2019-11-07 12:19:02,929 train 450 1.715401e-02 -1.134977
2019-11-07 12:19:12,752 train 500 1.716497e-02 -1.111586
2019-11-07 12:19:22,564 train 550 1.721053e-02 -1.059930
2019-11-07 12:19:32,392 train 600 1.722475e-02 -1.026357
2019-11-07 12:19:42,227 train 650 1.723624e-02 -0.995138
2019-11-07 12:19:52,070 train 700 1.723600e-02 -0.971776
2019-11-07 12:20:01,903 train 750 1.722658e-02 -0.953778
2019-11-07 12:20:11,747 train 800 1.721481e-02 -0.962320
2019-11-07 12:20:21,601 train 850 1.719347e-02 -0.940628
2019-11-07 12:20:24,533 training loss; R2: 1.718324e-02 -0.935625
2019-11-07 12:20:25,215 valid 000 1.380601e-02 -3.198426
2019-11-07 12:20:34,592 valid 050 1.710831e-02 -1.506869
2019-11-07 12:20:42,879 validation loss; R2: 1.702724e-02 -1.443305
2019-11-07 12:20:42,944 epoch 506 lr 1.000000e-05
2019-11-07 12:20:43,728 train 000 1.677297e-02 -0.101743
2019-11-07 12:20:53,502 train 050 1.678704e-02 -0.834947
2019-11-07 12:21:03,289 train 100 1.725033e-02 -0.725094
2019-11-07 12:21:13,075 train 150 1.710989e-02 -0.864534
2019-11-07 12:21:22,881 train 200 1.710774e-02 -0.938728
2019-11-07 12:21:32,684 train 250 1.708134e-02 -0.960470
2019-11-07 12:21:42,478 train 300 1.710523e-02 -0.958771
2019-11-07 12:21:52,265 train 350 1.710585e-02 -0.913152
2019-11-07 12:22:02,082 train 400 1.707865e-02 -0.877496
2019-11-07 12:22:11,884 train 450 1.712346e-02 -0.845574
2019-11-07 12:22:21,732 train 500 1.717460e-02 -0.806147
2019-11-07 12:22:31,591 train 550 1.721205e-02 -0.846108
2019-11-07 12:22:41,438 train 600 1.721755e-02 -0.833242
2019-11-07 12:22:51,288 train 650 1.721056e-02 -0.838640
2019-11-07 12:23:01,162 train 700 1.720748e-02 -0.821076
2019-11-07 12:23:11,032 train 750 1.723162e-02 -0.802067
2019-11-07 12:23:20,882 train 800 1.720568e-02 -0.795020
2019-11-07 12:23:30,756 train 850 1.720078e-02 -0.796195
2019-11-07 12:23:33,712 training loss; R2: 1.720553e-02 -0.794772
2019-11-07 12:23:34,392 valid 000 1.728378e-02 -3.579119
2019-11-07 12:23:43,803 valid 050 1.768002e-02 -1.198574
2019-11-07 12:23:52,131 validation loss; R2: 1.758499e-02 -1.000361
2019-11-07 12:23:52,196 epoch 507 lr 1.000000e-05
2019-11-07 12:23:52,931 train 000 1.493233e-02 -2.476924
2019-11-07 12:24:02,713 train 050 1.770171e-02 -0.702492
2019-11-07 12:24:12,500 train 100 1.733351e-02 -0.674332
2019-11-07 12:24:22,280 train 150 1.716825e-02 -0.742808
2019-11-07 12:24:32,069 train 200 1.713107e-02 -0.712245
2019-11-07 12:24:41,864 train 250 1.700195e-02 -0.726507
2019-11-07 12:24:51,665 train 300 1.707354e-02 -0.685202
2019-11-07 12:25:01,452 train 350 1.709834e-02 -0.708197
2019-11-07 12:25:11,534 train 400 1.709922e-02 -0.694624
2019-11-07 12:25:21,702 train 450 1.714270e-02 -0.701571
2019-11-07 12:25:31,873 train 500 1.712870e-02 -0.717445
2019-11-07 12:25:42,061 train 550 1.712776e-02 -0.706293
2019-11-07 12:25:52,235 train 600 1.715144e-02 -0.702969
2019-11-07 12:26:02,421 train 650 1.716577e-02 -0.719822
2019-11-07 12:26:12,623 train 700 1.715054e-02 -0.718202
2019-11-07 12:26:22,823 train 750 1.716884e-02 -0.716526
2019-11-07 12:26:33,019 train 800 1.714794e-02 -0.752592
2019-11-07 12:26:43,201 train 850 1.713710e-02 -0.748937
2019-11-07 12:26:46,251 training loss; R2: 1.713598e-02 -0.743818
2019-11-07 12:26:46,938 valid 000 1.522683e-02 -4.278626
2019-11-07 12:26:56,316 valid 050 1.688157e-02 -1.448709
2019-11-07 12:27:04,708 validation loss; R2: 1.702316e-02 -1.497159
2019-11-07 12:27:04,775 epoch 508 lr 1.000000e-05
2019-11-07 12:27:05,545 train 000 1.618610e-02 -0.581006
2019-11-07 12:27:15,294 train 050 1.777273e-02 -0.957104
2019-11-07 12:27:25,051 train 100 1.725900e-02 -0.998218
2019-11-07 12:27:34,833 train 150 1.736916e-02 -0.882250
2019-11-07 12:27:44,612 train 200 1.731740e-02 -0.896652
2019-11-07 12:27:54,383 train 250 1.731145e-02 -0.910491
2019-11-07 12:28:04,163 train 300 1.726636e-02 -1.010317
2019-11-07 12:28:13,964 train 350 1.731062e-02 -0.914932
2019-11-07 12:28:23,771 train 400 1.740031e-02 -0.856325
2019-11-07 12:28:33,581 train 450 1.742669e-02 -0.832433
2019-11-07 12:28:43,397 train 500 1.737602e-02 -0.821770
2019-11-07 12:28:53,222 train 550 1.732169e-02 -0.831291
2019-11-07 12:29:03,051 train 600 1.731746e-02 -0.813557
2019-11-07 12:29:12,901 train 650 1.729140e-02 -0.799726
2019-11-07 12:29:22,745 train 700 1.727232e-02 -0.790726
2019-11-07 12:29:32,591 train 750 1.727563e-02 -0.783575
2019-11-07 12:29:42,438 train 800 1.726551e-02 -0.781466
2019-11-07 12:29:52,292 train 850 1.725193e-02 -0.865645
2019-11-07 12:29:55,233 training loss; R2: 1.724587e-02 -0.855452
2019-11-07 12:29:55,828 valid 000 1.900183e-02 -1.024450
2019-11-07 12:30:05,268 valid 050 1.765257e-02 -4.439708
2019-11-07 12:30:13,564 validation loss; R2: 1.765993e-02 -3.389702
2019-11-07 12:30:13,630 epoch 509 lr 1.000000e-05
2019-11-07 12:30:14,405 train 000 1.878992e-02 -0.362953
2019-11-07 12:30:24,162 train 050 1.726048e-02 -0.769269
2019-11-07 12:30:33,930 train 100 1.722682e-02 -0.630418
2019-11-07 12:30:43,718 train 150 1.717366e-02 -0.580909
2019-11-07 12:30:53,502 train 200 1.709617e-02 -0.616974
2019-11-07 12:31:03,296 train 250 1.713781e-02 -0.665092
2019-11-07 12:31:13,109 train 300 1.715863e-02 -0.712362
2019-11-07 12:31:22,923 train 350 1.717333e-02 -0.726713
2019-11-07 12:31:32,758 train 400 1.711124e-02 -0.720721
2019-11-07 12:31:42,612 train 450 1.716687e-02 -0.718273
2019-11-07 12:31:52,459 train 500 1.716912e-02 -0.757270
2019-11-07 12:32:02,331 train 550 1.719300e-02 -0.761707
2019-11-07 12:32:12,189 train 600 1.718016e-02 -0.757999
2019-11-07 12:32:22,053 train 650 1.719451e-02 -0.765169
2019-11-07 12:32:31,929 train 700 1.720530e-02 -0.799426
2019-11-07 12:32:41,797 train 750 1.721421e-02 -0.791410
2019-11-07 12:32:51,675 train 800 1.719426e-02 -0.775737
2019-11-07 12:33:01,560 train 850 1.715643e-02 -0.769718
2019-11-07 12:33:04,509 training loss; R2: 1.714639e-02 -0.773622
2019-11-07 12:33:05,185 valid 000 1.995519e-02 -0.025570
2019-11-07 12:33:14,591 valid 050 1.693111e-02 -2.790094
2019-11-07 12:33:22,996 validation loss; R2: 1.682788e-02 -1.910615
2019-11-07 12:33:23,063 epoch 510 lr 1.000000e-05
2019-11-07 12:33:23,812 train 000 2.061651e-02 -0.859140
2019-11-07 12:33:33,565 train 050 1.784042e-02 -1.050813
2019-11-07 12:33:43,329 train 100 1.743560e-02 -0.891691
2019-11-07 12:33:53,109 train 150 1.740972e-02 -0.772461
2019-11-07 12:34:02,886 train 200 1.739992e-02 -0.698501
2019-11-07 12:34:12,668 train 250 1.738521e-02 -0.672869
2019-11-07 12:34:22,463 train 300 1.736787e-02 -0.744786
2019-11-07 12:34:32,285 train 350 1.732697e-02 -0.774059
2019-11-07 12:34:42,082 train 400 1.730806e-02 -0.774312
2019-11-07 12:34:51,881 train 450 1.733005e-02 -0.790121
2019-11-07 12:35:01,697 train 500 1.730444e-02 -0.800847
2019-11-07 12:35:11,531 train 550 1.728166e-02 -0.792260
2019-11-07 12:35:21,363 train 600 1.726309e-02 -0.758449
2019-11-07 12:35:31,211 train 650 1.729069e-02 -0.756785
2019-11-07 12:35:41,043 train 700 1.731070e-02 -0.745180
2019-11-07 12:35:50,883 train 750 1.728496e-02 -2.327210
2019-11-07 12:36:00,743 train 800 1.728770e-02 -2.245736
2019-11-07 12:36:10,592 train 850 1.727791e-02 -2.177735
2019-11-07 12:36:13,535 training loss; R2: 1.727362e-02 -2.149216
2019-11-07 12:36:14,176 valid 000 1.696105e-02 -6.157357
2019-11-07 12:36:23,612 valid 050 1.707277e-02 -1.005148
2019-11-07 12:36:32,033 validation loss; R2: 1.691846e-02 -1.045415
2019-11-07 12:36:32,101 epoch 511 lr 1.000000e-05
2019-11-07 12:36:32,891 train 000 1.877328e-02 -0.005177
2019-11-07 12:36:42,660 train 050 1.717424e-02 -0.641444
2019-11-07 12:36:52,418 train 100 1.698933e-02 -0.583215
2019-11-07 12:37:02,226 train 150 1.716674e-02 -0.684110
2019-11-07 12:37:12,025 train 200 1.723285e-02 -0.658692
2019-11-07 12:37:21,823 train 250 1.724374e-02 -0.677545
2019-11-07 12:37:31,629 train 300 1.719076e-02 -0.666212
2019-11-07 12:37:41,440 train 350 1.718025e-02 -0.665533
2019-11-07 12:37:51,251 train 400 1.724402e-02 -0.675176
2019-11-07 12:38:01,083 train 450 1.722389e-02 -0.646840
2019-11-07 12:38:10,912 train 500 1.724044e-02 -0.671966
2019-11-07 12:38:20,753 train 550 1.722009e-02 -0.668396
2019-11-07 12:38:30,601 train 600 1.722380e-02 -0.653675
2019-11-07 12:38:40,446 train 650 1.721300e-02 -1.269559
2019-11-07 12:38:50,309 train 700 1.720353e-02 -1.227887
2019-11-07 12:39:00,172 train 750 1.722522e-02 -11.376075
2019-11-07 12:39:10,055 train 800 1.722444e-02 -10.691943
2019-11-07 12:39:19,928 train 850 1.722608e-02 -10.115587
2019-11-07 12:39:22,873 training loss; R2: 1.722476e-02 -9.956275
2019-11-07 12:39:23,580 valid 000 1.389588e-02 -0.026586
2019-11-07 12:39:32,959 valid 050 1.635688e-02 -3.855841
2019-11-07 12:39:41,469 validation loss; R2: 1.632851e-02 -2.468538
2019-11-07 12:39:41,537 epoch 512 lr 1.000000e-05
2019-11-07 12:39:42,326 train 000 1.702464e-02 0.077780
2019-11-07 12:39:52,074 train 050 1.758590e-02 -0.510802
2019-11-07 12:40:01,844 train 100 1.735080e-02 -0.575476
2019-11-07 12:40:11,642 train 150 1.721893e-02 -0.570546
2019-11-07 12:40:21,436 train 200 1.723784e-02 -0.628600
2019-11-07 12:40:31,244 train 250 1.716014e-02 -0.725158
2019-11-07 12:40:41,059 train 300 1.715989e-02 -0.729730
2019-11-07 12:40:50,875 train 350 1.717788e-02 -0.724775
2019-11-07 12:41:00,700 train 400 1.718127e-02 -0.763523
2019-11-07 12:41:10,535 train 450 1.721264e-02 -0.766504
2019-11-07 12:41:20,390 train 500 1.719779e-02 -0.751710
2019-11-07 12:41:30,254 train 550 1.723546e-02 -0.733205
2019-11-07 12:41:40,141 train 600 1.721592e-02 -0.752210
2019-11-07 12:41:50,020 train 650 1.719442e-02 -0.743071
2019-11-07 12:41:59,905 train 700 1.718788e-02 -0.742342
2019-11-07 12:42:09,799 train 750 1.719280e-02 -0.747126
2019-11-07 12:42:19,685 train 800 1.718835e-02 -0.735744
2019-11-07 12:42:29,592 train 850 1.719366e-02 -0.732485
2019-11-07 12:42:32,548 training loss; R2: 1.719517e-02 -0.728793
2019-11-07 12:42:33,192 valid 000 1.614041e-02 -3.698900
2019-11-07 12:42:42,594 valid 050 1.686969e-02 -1.372149
2019-11-07 12:42:50,977 validation loss; R2: 1.671101e-02 -1.226570
2019-11-07 12:42:51,044 epoch 513 lr 1.000000e-05
2019-11-07 12:42:51,792 train 000 1.575004e-02 -0.389226
2019-11-07 12:43:01,563 train 050 1.725206e-02 -0.991592
2019-11-07 12:43:11,342 train 100 1.718745e-02 -0.830952
2019-11-07 12:43:21,127 train 150 1.711961e-02 -0.838642
2019-11-07 12:43:30,900 train 200 1.719596e-02 -0.852247
2019-11-07 12:43:40,695 train 250 1.724462e-02 -0.800716
2019-11-07 12:43:50,495 train 300 1.719297e-02 -0.785290
2019-11-07 12:44:00,300 train 350 1.720032e-02 -0.764990
2019-11-07 12:44:10,129 train 400 1.721456e-02 -0.754292
2019-11-07 12:44:19,960 train 450 1.720827e-02 -0.730920
2019-11-07 12:44:29,803 train 500 1.723269e-02 -0.708616
2019-11-07 12:44:39,643 train 550 1.720125e-02 -0.708019
2019-11-07 12:44:49,514 train 600 1.716331e-02 -0.721255
2019-11-07 12:44:59,380 train 650 1.720342e-02 -0.707545
2019-11-07 12:45:09,236 train 700 1.721055e-02 -0.716737
2019-11-07 12:45:19,116 train 750 1.722064e-02 -0.701773
2019-11-07 12:45:28,970 train 800 1.723079e-02 -0.732442
2019-11-07 12:45:38,915 train 850 1.724238e-02 -0.735562
2019-11-07 12:45:41,981 training loss; R2: 1.724268e-02 -0.733392
2019-11-07 12:45:42,610 valid 000 1.996424e-02 -0.185650
2019-11-07 12:45:52,058 valid 050 1.741973e-02 -1.376588
2019-11-07 12:46:00,365 validation loss; R2: 1.717126e-02 -1.053283
2019-11-07 12:46:00,429 epoch 514 lr 1.000000e-05
2019-11-07 12:46:01,173 train 000 1.743760e-02 -0.034964
2019-11-07 12:46:10,945 train 050 1.710152e-02 -0.634442
2019-11-07 12:46:20,707 train 100 1.719169e-02 -0.633659
2019-11-07 12:46:30,462 train 150 1.713072e-02 -0.712485
2019-11-07 12:46:40,213 train 200 1.720622e-02 -0.775342
2019-11-07 12:46:49,979 train 250 1.720526e-02 -0.774373
2019-11-07 12:46:59,748 train 300 1.719513e-02 -0.786709
2019-11-07 12:47:09,512 train 350 1.721375e-02 -0.774529
2019-11-07 12:47:19,300 train 400 1.721723e-02 -0.756385
2019-11-07 12:47:29,106 train 450 1.722703e-02 -0.804502
2019-11-07 12:47:38,918 train 500 1.725349e-02 -0.782211
2019-11-07 12:47:48,723 train 550 1.724232e-02 -0.785568
2019-11-07 12:47:58,543 train 600 1.718756e-02 -0.787201
2019-11-07 12:48:08,395 train 650 1.719314e-02 -0.772797
2019-11-07 12:48:18,257 train 700 1.721205e-02 -0.771544
2019-11-07 12:48:28,105 train 750 1.723945e-02 -0.751011
2019-11-07 12:48:37,969 train 800 1.723934e-02 -0.752688
2019-11-07 12:48:47,849 train 850 1.721601e-02 -0.748753
2019-11-07 12:48:50,812 training loss; R2: 1.721475e-02 -0.744760
2019-11-07 12:48:51,523 valid 000 1.855353e-02 -0.343084
2019-11-07 12:49:00,898 valid 050 1.766114e-02 -1.273602
2019-11-07 12:49:09,337 validation loss; R2: 1.731806e-02 -1.290444
2019-11-07 12:49:09,402 epoch 515 lr 1.000000e-05
2019-11-07 12:49:10,157 train 000 1.917042e-02 -0.021721
2019-11-07 12:49:20,111 train 050 1.745714e-02 -0.741746
2019-11-07 12:49:30,222 train 100 1.730067e-02 -1.094496
2019-11-07 12:49:39,982 train 150 1.723326e-02 -0.827591
2019-11-07 12:49:49,742 train 200 1.731839e-02 -0.787516
2019-11-07 12:49:59,527 train 250 1.733170e-02 -0.779151
2019-11-07 12:50:09,305 train 300 1.731997e-02 -0.751616
2019-11-07 12:50:19,086 train 350 1.728126e-02 -0.744589
2019-11-07 12:50:28,881 train 400 1.732128e-02 -1.234824
2019-11-07 12:50:38,683 train 450 1.732371e-02 -1.234191
2019-11-07 12:50:48,481 train 500 1.729873e-02 -1.201185
2019-11-07 12:50:58,306 train 550 1.729540e-02 -1.142463
2019-11-07 12:51:08,127 train 600 1.729074e-02 -1.091721
2019-11-07 12:51:17,956 train 650 1.726313e-02 -1.066728
2019-11-07 12:51:27,807 train 700 1.723080e-02 -1.046167
2019-11-07 12:51:37,636 train 750 1.723413e-02 -1.029972
2019-11-07 12:51:47,498 train 800 1.722217e-02 -1.027289
2019-11-07 12:51:57,336 train 850 1.722505e-02 -1.000950
2019-11-07 12:52:00,277 training loss; R2: 1.722456e-02 -1.000459
2019-11-07 12:52:00,957 valid 000 1.783362e-02 -1.112291
2019-11-07 12:52:10,406 valid 050 1.682227e-02 -2.055620
2019-11-07 12:52:18,758 validation loss; R2: 1.679726e-02 -1.724245
2019-11-07 12:52:18,823 epoch 516 lr 1.000000e-05
2019-11-07 12:52:19,594 train 000 1.507773e-02 -0.256365
2019-11-07 12:52:29,330 train 050 1.730775e-02 -0.664542
2019-11-07 12:52:39,084 train 100 1.706795e-02 -0.813515
2019-11-07 12:52:48,840 train 150 1.721632e-02 -0.816957
2019-11-07 12:52:58,593 train 200 1.717711e-02 -0.829491
2019-11-07 12:53:08,358 train 250 1.722458e-02 -0.784032
2019-11-07 12:53:18,175 train 300 1.721828e-02 -0.751196
2019-11-07 12:53:27,984 train 350 1.720273e-02 -0.755749
2019-11-07 12:53:37,754 train 400 1.721255e-02 -0.726054
2019-11-07 12:53:47,540 train 450 1.718651e-02 -0.706868
2019-11-07 12:53:57,345 train 500 1.718584e-02 -0.705690
2019-11-07 12:54:07,162 train 550 1.717891e-02 -0.683073
2019-11-07 12:54:17,020 train 600 1.719233e-02 -0.674396
2019-11-07 12:54:26,838 train 650 1.718049e-02 -0.672153
2019-11-07 12:54:36,686 train 700 1.722336e-02 -0.666378
2019-11-07 12:54:46,526 train 750 1.721616e-02 -0.654556
2019-11-07 12:54:56,350 train 800 1.720943e-02 -0.652248
2019-11-07 12:55:06,177 train 850 1.719783e-02 -0.675251
2019-11-07 12:55:09,153 training loss; R2: 1.719086e-02 -0.689033
2019-11-07 12:55:09,873 valid 000 1.788870e-02 -1.493451
2019-11-07 12:55:19,272 valid 050 1.706990e-02 -1.082254
2019-11-07 12:55:27,608 validation loss; R2: 1.733139e-02 -1.188079
2019-11-07 12:55:27,685 epoch 517 lr 1.000000e-05
2019-11-07 12:55:28,400 train 000 1.873700e-02 -5.434832
2019-11-07 12:55:38,140 train 050 1.781188e-02 -1.744685
2019-11-07 12:55:47,872 train 100 1.770455e-02 -1.266257
2019-11-07 12:55:57,633 train 150 1.764393e-02 -0.985969
2019-11-07 12:56:07,429 train 200 1.749128e-02 -0.984040
2019-11-07 12:56:17,223 train 250 1.742125e-02 -0.892227
2019-11-07 12:56:27,024 train 300 1.741829e-02 -0.877170
2019-11-07 12:56:36,825 train 350 1.742504e-02 -0.835783
2019-11-07 12:56:46,641 train 400 1.741958e-02 -0.848306
2019-11-07 12:56:56,461 train 450 1.738109e-02 -0.819864
2019-11-07 12:57:06,289 train 500 1.730018e-02 -0.788282
2019-11-07 12:57:16,090 train 550 1.727792e-02 -0.837942
2019-11-07 12:57:25,903 train 600 1.726183e-02 -0.840858
2019-11-07 12:57:35,735 train 650 1.725148e-02 -0.833222
2019-11-07 12:57:45,546 train 700 1.724641e-02 -0.844234
2019-11-07 12:57:55,359 train 750 1.723726e-02 -0.855736
2019-11-07 12:58:05,187 train 800 1.722699e-02 -0.850033
2019-11-07 12:58:15,032 train 850 1.723379e-02 -0.834811
2019-11-07 12:58:17,967 training loss; R2: 1.721810e-02 -0.856739
2019-11-07 12:58:18,675 valid 000 1.983644e-02 -0.986828
2019-11-07 12:58:28,083 valid 050 1.645517e-02 -16.896667
2019-11-07 12:58:36,431 validation loss; R2: 1.635352e-02 -9.349105
2019-11-07 12:58:36,497 epoch 518 lr 1.000000e-05
2019-11-07 12:58:37,246 train 000 1.611700e-02 -0.478692
2019-11-07 12:58:46,976 train 050 1.742791e-02 -0.908476
2019-11-07 12:58:56,720 train 100 1.742088e-02 -0.908009
2019-11-07 12:59:06,461 train 150 1.743006e-02 -1.737980
2019-11-07 12:59:16,230 train 200 1.738636e-02 -1.447748
2019-11-07 12:59:26,013 train 250 1.729460e-02 -1.316396
2019-11-07 12:59:35,802 train 300 1.723035e-02 -1.189804
2019-11-07 12:59:45,599 train 350 1.728507e-02 -1.098800
2019-11-07 12:59:55,397 train 400 1.725633e-02 -1.067546
2019-11-07 13:00:05,230 train 450 1.727258e-02 -1.063821
2019-11-07 13:00:15,079 train 500 1.724374e-02 -1.055944
2019-11-07 13:00:24,927 train 550 1.724053e-02 -1.037986
2019-11-07 13:00:34,777 train 600 1.722837e-02 -1.032824
2019-11-07 13:00:44,642 train 650 1.722355e-02 -1.005174
2019-11-07 13:00:54,493 train 700 1.723446e-02 -0.997394
2019-11-07 13:01:04,360 train 750 1.721157e-02 -0.984077
2019-11-07 13:01:14,214 train 800 1.719175e-02 -0.972376
2019-11-07 13:01:24,082 train 850 1.717698e-02 -0.953681
2019-11-07 13:01:27,033 training loss; R2: 1.717223e-02 -0.942410
2019-11-07 13:01:27,645 valid 000 1.689713e-02 -0.454700
2019-11-07 13:01:37,055 valid 050 1.872173e-02 -1.070251
2019-11-07 13:01:45,374 validation loss; R2: 1.840596e-02 -1.151105
2019-11-07 13:01:45,440 epoch 519 lr 1.000000e-05
2019-11-07 13:01:46,214 train 000 1.754309e-02 -0.230952
2019-11-07 13:01:55,954 train 050 1.718333e-02 -1.352216
2019-11-07 13:02:05,714 train 100 1.699097e-02 -1.082609
2019-11-07 13:02:15,501 train 150 1.709119e-02 -0.978210
2019-11-07 13:02:25,302 train 200 1.715404e-02 -1.001891
2019-11-07 13:02:35,110 train 250 1.715449e-02 -1.016584
2019-11-07 13:02:44,969 train 300 1.714951e-02 -0.954669
2019-11-07 13:02:54,777 train 350 1.711740e-02 -0.916085
2019-11-07 13:03:04,588 train 400 1.711991e-02 -0.878031
2019-11-07 13:03:14,401 train 450 1.710195e-02 -0.854564
2019-11-07 13:03:24,210 train 500 1.711414e-02 -0.838373
2019-11-07 13:03:34,040 train 550 1.715147e-02 -0.804170
2019-11-07 13:03:43,865 train 600 1.717054e-02 -0.802069
2019-11-07 13:03:53,705 train 650 1.719008e-02 -0.784897
2019-11-07 13:04:03,542 train 700 1.718537e-02 -0.774619
2019-11-07 13:04:13,388 train 750 1.718849e-02 -0.766515
2019-11-07 13:04:23,222 train 800 1.717010e-02 -0.751954
2019-11-07 13:04:33,084 train 850 1.719045e-02 -0.757518
2019-11-07 13:04:36,030 training loss; R2: 1.718524e-02 -0.755892
2019-11-07 13:04:36,665 valid 000 1.489962e-02 -0.071114
2019-11-07 13:04:46,107 valid 050 1.690920e-02 -0.890288
2019-11-07 13:04:54,424 validation loss; R2: 1.681907e-02 -0.938503
2019-11-07 13:04:54,490 epoch 520 lr 1.000000e-05
2019-11-07 13:04:55,233 train 000 1.525932e-02 -0.056045
2019-11-07 13:05:04,975 train 050 1.730946e-02 -0.736491
2019-11-07 13:05:14,715 train 100 1.731376e-02 -0.733583
2019-11-07 13:05:24,483 train 150 1.728301e-02 -0.718025
2019-11-07 13:05:34,261 train 200 1.723651e-02 -0.670112
2019-11-07 13:05:44,065 train 250 1.717010e-02 -0.655127
2019-11-07 13:05:53,875 train 300 1.714726e-02 -0.688958
2019-11-07 13:06:03,681 train 350 1.720381e-02 -34.942314
2019-11-07 13:06:13,477 train 400 1.715259e-02 -30.669114
2019-11-07 13:06:23,302 train 450 1.717479e-02 -27.348242
2019-11-07 13:06:33,122 train 500 1.721959e-02 -24.681764
2019-11-07 13:06:42,976 train 550 1.719188e-02 -22.498741
2019-11-07 13:06:52,816 train 600 1.719185e-02 -20.702075
2019-11-07 13:07:02,664 train 650 1.722517e-02 -19.165532
2019-11-07 13:07:12,527 train 700 1.723658e-02 -17.874129
2019-11-07 13:07:22,407 train 750 1.721361e-02 -16.740423
2019-11-07 13:07:32,272 train 800 1.722603e-02 -15.724255
2019-11-07 13:07:42,127 train 850 1.720792e-02 -14.992627
2019-11-07 13:07:45,074 training loss; R2: 1.719479e-02 -14.747490
2019-11-07 13:07:45,766 valid 000 1.738663e-02 -0.199446
2019-11-07 13:07:55,154 valid 050 1.669782e-02 -1.677182
2019-11-07 13:08:03,476 validation loss; R2: 1.684923e-02 -1.355216
2019-11-07 13:08:03,546 epoch 521 lr 1.000000e-05
2019-11-07 13:08:04,288 train 000 1.605344e-02 -1.685999
2019-11-07 13:08:14,043 train 050 1.693835e-02 -0.585631
2019-11-07 13:08:23,812 train 100 1.697620e-02 -0.611313
2019-11-07 13:08:33,590 train 150 1.701414e-02 -0.669572
2019-11-07 13:08:43,378 train 200 1.714470e-02 -0.642552
2019-11-07 13:08:53,178 train 250 1.723248e-02 -0.683862
2019-11-07 13:09:02,982 train 300 1.713970e-02 -0.661075
2019-11-07 13:09:12,790 train 350 1.718553e-02 -0.691981
2019-11-07 13:09:22,611 train 400 1.717975e-02 -0.693107
2019-11-07 13:09:32,443 train 450 1.715750e-02 -0.667680
2019-11-07 13:09:42,300 train 500 1.714484e-02 -0.721690
2019-11-07 13:09:52,119 train 550 1.716936e-02 -16.635175
2019-11-07 13:10:01,972 train 600 1.719768e-02 -15.311880
2019-11-07 13:10:11,820 train 650 1.718258e-02 -14.200098
2019-11-07 13:10:21,733 train 700 1.716180e-02 -13.249485
2019-11-07 13:10:31,971 train 750 1.717386e-02 -12.445012
2019-11-07 13:10:42,213 train 800 1.715808e-02 -11.699666
2019-11-07 13:10:52,454 train 850 1.715283e-02 -11.059240
2019-11-07 13:10:55,511 training loss; R2: 1.716463e-02 -10.886402
2019-11-07 13:10:56,200 valid 000 1.728239e-02 -0.457629
2019-11-07 13:11:05,564 valid 050 1.690973e-02 -1.229186
2019-11-07 13:11:13,892 validation loss; R2: 1.692895e-02 -1.360326
2019-11-07 13:11:13,961 epoch 522 lr 1.000000e-05
2019-11-07 13:11:14,769 train 000 1.463662e-02 -0.304959
2019-11-07 13:11:24,904 train 050 1.731302e-02 -0.692601
2019-11-07 13:11:35,046 train 100 1.735116e-02 -0.721803
2019-11-07 13:11:45,198 train 150 1.722272e-02 -0.700025
2019-11-07 13:11:55,364 train 200 1.716339e-02 -0.781971
2019-11-07 13:12:05,504 train 250 1.711275e-02 -0.754242
2019-11-07 13:12:15,715 train 300 1.709411e-02 -0.774393
2019-11-07 13:12:25,932 train 350 1.708249e-02 -0.909297
2019-11-07 13:12:36,144 train 400 1.707415e-02 -0.893278
2019-11-07 13:12:46,357 train 450 1.709343e-02 -1.018983
2019-11-07 13:12:56,575 train 500 1.709692e-02 -0.967186
2019-11-07 13:13:06,797 train 550 1.707136e-02 -0.941910
2019-11-07 13:13:17,042 train 600 1.707603e-02 -0.916860
2019-11-07 13:13:27,284 train 650 1.706993e-02 -0.905348
2019-11-07 13:13:37,517 train 700 1.707480e-02 -0.929791
2019-11-07 13:13:47,421 train 750 1.709510e-02 -0.901674
2019-11-07 13:13:57,304 train 800 1.711990e-02 -0.888717
2019-11-07 13:14:07,215 train 850 1.710654e-02 -0.868435
2019-11-07 13:14:10,170 training loss; R2: 1.710050e-02 -0.864961
2019-11-07 13:14:10,796 valid 000 1.544596e-02 -0.742944
2019-11-07 13:14:20,215 valid 050 1.652245e-02 -1.255228
2019-11-07 13:14:28,548 validation loss; R2: 1.664453e-02 -1.320846
2019-11-07 13:14:28,613 epoch 523 lr 1.000000e-05
2019-11-07 13:14:29,411 train 000 1.569422e-02 -0.291683
2019-11-07 13:14:39,184 train 050 1.706318e-02 -0.700883
2019-11-07 13:14:48,971 train 100 1.685407e-02 -0.656455
2019-11-07 13:14:58,782 train 150 1.701375e-02 -0.723650
2019-11-07 13:15:08,598 train 200 1.705048e-02 -0.689642
2019-11-07 13:15:18,418 train 250 1.705841e-02 -0.720959
2019-11-07 13:15:28,257 train 300 1.710759e-02 -0.705669
2019-11-07 13:15:38,102 train 350 1.715888e-02 -0.688308
2019-11-07 13:15:47,940 train 400 1.715227e-02 -0.694066
2019-11-07 13:15:57,804 train 450 1.713748e-02 -0.734544
2019-11-07 13:16:07,676 train 500 1.709956e-02 -0.743265
2019-11-07 13:16:17,577 train 550 1.706136e-02 -0.718035
2019-11-07 13:16:27,469 train 600 1.708354e-02 -0.710931
2019-11-07 13:16:37,341 train 650 1.706722e-02 -0.719546
2019-11-07 13:16:47,225 train 700 1.708106e-02 -0.716961
2019-11-07 13:16:57,122 train 750 1.710752e-02 -0.727534
2019-11-07 13:17:07,015 train 800 1.708960e-02 -0.723702
2019-11-07 13:17:16,920 train 850 1.709749e-02 -0.736909
2019-11-07 13:17:19,872 training loss; R2: 1.710422e-02 -0.737165
2019-11-07 13:17:20,459 valid 000 1.745145e-02 -1.281384
2019-11-07 13:17:29,881 valid 050 1.726689e-02 -1.518121
2019-11-07 13:17:38,320 validation loss; R2: 1.734570e-02 -1.551827
2019-11-07 13:17:38,386 epoch 524 lr 1.000000e-05
2019-11-07 13:17:39,191 train 000 1.563158e-02 -0.080415
2019-11-07 13:17:48,962 train 050 1.766060e-02 -0.859096
2019-11-07 13:17:58,742 train 100 1.721921e-02 -0.715036
2019-11-07 13:18:08,549 train 150 1.718702e-02 -0.730443
2019-11-07 13:18:18,370 train 200 1.721337e-02 -0.764085
2019-11-07 13:18:28,206 train 250 1.719979e-02 -0.732797
2019-11-07 13:18:38,070 train 300 1.718507e-02 -0.746025
2019-11-07 13:18:47,912 train 350 1.708331e-02 -0.745599
2019-11-07 13:18:57,788 train 400 1.711272e-02 -0.742795
2019-11-07 13:19:07,666 train 450 1.707409e-02 -0.775215
2019-11-07 13:19:17,567 train 500 1.705549e-02 -0.906576
2019-11-07 13:19:27,448 train 550 1.711387e-02 -0.881954
2019-11-07 13:19:37,356 train 600 1.712340e-02 -0.894453
2019-11-07 13:19:47,299 train 650 1.713819e-02 -0.868706
2019-11-07 13:19:57,213 train 700 1.713630e-02 -0.855346
2019-11-07 13:20:07,128 train 750 1.716587e-02 -0.843822
2019-11-07 13:20:17,016 train 800 1.717841e-02 -0.841364
2019-11-07 13:20:26,887 train 850 1.719154e-02 -0.818202
2019-11-07 13:20:29,837 training loss; R2: 1.719348e-02 -0.819038
2019-11-07 13:20:30,448 valid 000 1.655460e-02 -4.357651
2019-11-07 13:20:39,897 valid 050 1.664949e-02 -1.138313
2019-11-07 13:20:48,200 validation loss; R2: 1.668932e-02 -0.938055
2019-11-07 13:20:48,281 epoch 525 lr 1.000000e-05
2019-11-07 13:20:49,052 train 000 1.595598e-02 -0.859759
2019-11-07 13:20:58,813 train 050 1.700224e-02 -0.781920
2019-11-07 13:21:08,621 train 100 1.713151e-02 -0.669320
2019-11-07 13:21:18,430 train 150 1.716117e-02 -0.665272
2019-11-07 13:21:28,257 train 200 1.715304e-02 -0.649803
2019-11-07 13:21:38,076 train 250 1.718592e-02 -0.660378
2019-11-07 13:21:47,897 train 300 1.718351e-02 -0.615346
2019-11-07 13:21:57,771 train 350 1.723921e-02 -0.660542
2019-11-07 13:22:07,596 train 400 1.721341e-02 -0.681158
2019-11-07 13:22:17,444 train 450 1.723371e-02 -0.654150
2019-11-07 13:22:27,278 train 500 1.722562e-02 -0.651815
2019-11-07 13:22:37,116 train 550 1.722205e-02 -0.660097
2019-11-07 13:22:46,978 train 600 1.722927e-02 -0.649858
2019-11-07 13:22:56,827 train 650 1.724440e-02 -0.652098
2019-11-07 13:23:06,703 train 700 1.723332e-02 -0.666154
2019-11-07 13:23:16,555 train 750 1.724333e-02 -0.662387
2019-11-07 13:23:26,419 train 800 1.722570e-02 -0.681725
2019-11-07 13:23:36,286 train 850 1.719987e-02 -0.672848
2019-11-07 13:23:39,235 training loss; R2: 1.718885e-02 -0.673509
2019-11-07 13:23:39,865 valid 000 1.533909e-02 -0.905154
2019-11-07 13:23:49,389 valid 050 1.627411e-02 -1.255825
2019-11-07 13:23:57,740 validation loss; R2: 1.618016e-02 -1.383668
2019-11-07 13:23:57,807 epoch 526 lr 1.000000e-05
2019-11-07 13:23:58,592 train 000 1.783919e-02 -0.410774
2019-11-07 13:24:08,327 train 050 1.738882e-02 -0.728659
2019-11-07 13:24:18,059 train 100 1.710273e-02 -0.738240
2019-11-07 13:24:27,838 train 150 1.718064e-02 -0.869207
2019-11-07 13:24:37,634 train 200 1.719900e-02 -0.824938
2019-11-07 13:24:47,432 train 250 1.715679e-02 -0.775663
2019-11-07 13:24:57,252 train 300 1.713704e-02 -0.734265
2019-11-07 13:25:07,071 train 350 1.719019e-02 -0.794149
2019-11-07 13:25:16,907 train 400 1.717537e-02 -0.761264
2019-11-07 13:25:26,761 train 450 1.718407e-02 -0.751340
2019-11-07 13:25:36,616 train 500 1.719039e-02 -0.757547
2019-11-07 13:25:46,478 train 550 1.719520e-02 -0.742222
2019-11-07 13:25:56,366 train 600 1.716219e-02 -0.743992
2019-11-07 13:26:06,610 train 650 1.715216e-02 -0.768136
2019-11-07 13:26:16,859 train 700 1.717052e-02 -0.749668
2019-11-07 13:26:27,086 train 750 1.717270e-02 -0.746144
2019-11-07 13:26:37,310 train 800 1.717715e-02 -0.768255
2019-11-07 13:26:47,541 train 850 1.715368e-02 -0.761725
2019-11-07 13:26:50,582 training loss; R2: 1.715782e-02 -0.764118
2019-11-07 13:26:51,230 valid 000 1.770770e-02 -0.211791
2019-11-07 13:27:00,641 valid 050 1.684047e-02 -1.208456
2019-11-07 13:27:08,984 validation loss; R2: 1.692272e-02 -1.211428
2019-11-07 13:27:09,051 epoch 527 lr 1.000000e-05
2019-11-07 13:27:09,831 train 000 1.884179e-02 0.047118
2019-11-07 13:27:19,617 train 050 1.750388e-02 -0.703351
2019-11-07 13:27:29,427 train 100 1.735478e-02 -0.796542
2019-11-07 13:27:39,260 train 150 1.739526e-02 -0.724267
2019-11-07 13:27:49,103 train 200 1.740171e-02 -0.866140
2019-11-07 13:27:58,958 train 250 1.735209e-02 -0.971207
2019-11-07 13:28:08,793 train 300 1.727752e-02 -0.939908
2019-11-07 13:28:18,652 train 350 1.721463e-02 -0.899355
2019-11-07 13:28:28,501 train 400 1.726865e-02 -0.895311
2019-11-07 13:28:38,373 train 450 1.728936e-02 -0.898587
2019-11-07 13:28:48,249 train 500 1.720835e-02 -0.891442
2019-11-07 13:28:58,132 train 550 1.717923e-02 -0.861581
2019-11-07 13:29:08,018 train 600 1.715189e-02 -0.861242
2019-11-07 13:29:17,912 train 650 1.712882e-02 -0.864327
2019-11-07 13:29:27,825 train 700 1.711821e-02 -0.838267
2019-11-07 13:29:37,719 train 750 1.710908e-02 -0.829798
2019-11-07 13:29:47,623 train 800 1.713209e-02 -0.808937
2019-11-07 13:29:57,543 train 850 1.715349e-02 -0.794930
2019-11-07 13:30:00,496 training loss; R2: 1.715444e-02 -0.797480
2019-11-07 13:30:01,166 valid 000 1.827120e-02 -0.331909
2019-11-07 13:30:10,612 valid 050 1.724851e-02 -1.265459
2019-11-07 13:30:18,951 validation loss; R2: 1.722276e-02 -1.283217
2019-11-07 13:30:19,014 epoch 528 lr 1.000000e-05
2019-11-07 13:30:19,736 train 000 1.690321e-02 -1.269430
2019-11-07 13:30:29,520 train 050 1.749307e-02 -0.792946
2019-11-07 13:30:39,307 train 100 1.720800e-02 -0.862957
2019-11-07 13:30:49,118 train 150 1.728820e-02 -0.782770
2019-11-07 13:30:58,942 train 200 1.721913e-02 -0.735706
2019-11-07 13:31:08,761 train 250 1.719688e-02 -0.682456
2019-11-07 13:31:18,591 train 300 1.713810e-02 -0.758019
2019-11-07 13:31:28,415 train 350 1.712314e-02 -0.754797
2019-11-07 13:31:38,268 train 400 1.710937e-02 -0.768796
2019-11-07 13:31:48,125 train 450 1.712368e-02 -0.763142
2019-11-07 13:31:58,014 train 500 1.710927e-02 -0.745862
2019-11-07 13:32:07,890 train 550 1.709805e-02 -0.759306
2019-11-07 13:32:17,772 train 600 1.708090e-02 -0.746630
2019-11-07 13:32:27,661 train 650 1.711433e-02 -0.726768
2019-11-07 13:32:37,599 train 700 1.710782e-02 -0.711350
2019-11-07 13:32:47,519 train 750 1.712048e-02 -0.734564
2019-11-07 13:32:57,434 train 800 1.712455e-02 -0.738335
2019-11-07 13:33:07,355 train 850 1.712813e-02 -0.719319
2019-11-07 13:33:10,330 training loss; R2: 1.714089e-02 -0.721767
2019-11-07 13:33:10,917 valid 000 1.715195e-02 -0.975042
2019-11-07 13:33:20,338 valid 050 1.670053e-02 -1.196685
2019-11-07 13:33:28,620 validation loss; R2: 1.661383e-02 -1.136792
2019-11-07 13:33:28,689 epoch 529 lr 1.000000e-05
2019-11-07 13:33:29,455 train 000 1.815930e-02 -1.052351
2019-11-07 13:33:39,241 train 050 1.713414e-02 -0.579752
2019-11-07 13:33:49,104 train 100 1.730352e-02 -0.538265
2019-11-07 13:33:58,968 train 150 1.713460e-02 -0.601047
2019-11-07 13:34:08,833 train 200 1.715172e-02 -0.594302
2019-11-07 13:34:18,728 train 250 1.713225e-02 -0.635022
2019-11-07 13:34:28,601 train 300 1.710858e-02 -0.627217
2019-11-07 13:34:38,485 train 350 1.715760e-02 -0.676319
2019-11-07 13:34:48,383 train 400 1.716023e-02 -0.734065
2019-11-07 13:34:58,308 train 450 1.712885e-02 -0.702634
2019-11-07 13:35:08,235 train 500 1.714357e-02 -0.689136
2019-11-07 13:35:18,166 train 550 1.716650e-02 -0.717618
2019-11-07 13:35:28,085 train 600 1.712190e-02 -0.858527
2019-11-07 13:35:38,031 train 650 1.717261e-02 -0.862278
2019-11-07 13:35:47,961 train 700 1.719801e-02 -0.843240
2019-11-07 13:35:57,906 train 750 1.719759e-02 -0.854454
2019-11-07 13:36:07,851 train 800 1.719417e-02 -0.840258
2019-11-07 13:36:17,783 train 850 1.717104e-02 -0.829035
2019-11-07 13:36:20,755 training loss; R2: 1.717501e-02 -1.113546
2019-11-07 13:36:21,459 valid 000 1.763887e-02 -1.379412
2019-11-07 13:36:30,796 valid 050 1.657006e-02 -1.027355
2019-11-07 13:36:39,171 validation loss; R2: 1.644521e-02 -0.852857
2019-11-07 13:36:39,238 epoch 530 lr 1.000000e-05
2019-11-07 13:36:40,060 train 000 1.646452e-02 -0.021526
2019-11-07 13:36:49,857 train 050 1.639964e-02 -0.652534
2019-11-07 13:36:59,677 train 100 1.679463e-02 -0.623136
2019-11-07 13:37:09,517 train 150 1.666831e-02 -0.580865
2019-11-07 13:37:19,355 train 200 1.680915e-02 -0.613535
2019-11-07 13:37:29,183 train 250 1.683063e-02 -0.628952
2019-11-07 13:37:39,035 train 300 1.692251e-02 -0.716881
2019-11-07 13:37:48,887 train 350 1.693475e-02 -0.701707
2019-11-07 13:37:58,745 train 400 1.695785e-02 -0.729966
2019-11-07 13:38:08,632 train 450 1.699861e-02 -0.713363
2019-11-07 13:38:18,528 train 500 1.702727e-02 -0.716770
2019-11-07 13:38:28,415 train 550 1.702485e-02 -0.737710
2019-11-07 13:38:38,306 train 600 1.706106e-02 -0.750554
2019-11-07 13:38:48,216 train 650 1.704839e-02 -0.746889
2019-11-07 13:38:58,073 train 700 1.707691e-02 -0.739500
2019-11-07 13:39:07,929 train 750 1.709222e-02 -0.755357
2019-11-07 13:39:17,801 train 800 1.709217e-02 -0.739646
2019-11-07 13:39:27,680 train 850 1.706274e-02 -0.746233
2019-11-07 13:39:30,632 training loss; R2: 1.705779e-02 -0.750850
2019-11-07 13:39:31,280 valid 000 1.738584e-02 -1.744587
2019-11-07 13:39:40,703 valid 050 1.648995e-02 -0.912152
2019-11-07 13:39:49,030 validation loss; R2: 1.652020e-02 -1.039022
2019-11-07 13:39:49,090 epoch 531 lr 1.000000e-05
2019-11-07 13:39:49,873 train 000 1.573030e-02 -0.066717
2019-11-07 13:39:59,642 train 050 1.699796e-02 -0.763733
2019-11-07 13:40:09,436 train 100 1.714109e-02 -0.818377
2019-11-07 13:40:19,251 train 150 1.708235e-02 -0.745190
2019-11-07 13:40:29,065 train 200 1.711169e-02 -107.066603
2019-11-07 13:40:38,865 train 250 1.707670e-02 -85.854555
2019-11-07 13:40:48,681 train 300 1.714821e-02 -71.711844
2019-11-07 13:40:58,512 train 350 1.714942e-02 -61.648667
2019-11-07 13:41:08,349 train 400 1.714607e-02 -54.029117
2019-11-07 13:41:18,214 train 450 1.709168e-02 -48.112843
2019-11-07 13:41:28,079 train 500 1.707281e-02 -43.393072
2019-11-07 13:41:37,948 train 550 1.706477e-02 -39.501855
2019-11-07 13:41:47,817 train 600 1.708925e-02 -36.252392
2019-11-07 13:41:57,699 train 650 1.707551e-02 -33.515703
2019-11-07 13:42:07,601 train 700 1.708829e-02 -31.178847
2019-11-07 13:42:17,483 train 750 1.707913e-02 -29.139474
2019-11-07 13:42:27,366 train 800 1.708346e-02 -27.369985
2019-11-07 13:42:37,261 train 850 1.707994e-02 -25.825336
2019-11-07 13:42:40,215 training loss; R2: 1.708301e-02 -25.391303
2019-11-07 13:42:40,810 valid 000 1.630890e-02 -0.696526
2019-11-07 13:42:50,249 valid 050 1.691640e-02 -1.218832
2019-11-07 13:42:58,570 validation loss; R2: 1.733927e-02 -1.132487
2019-11-07 13:42:58,635 epoch 532 lr 1.000000e-05
2019-11-07 13:42:59,407 train 000 1.720510e-02 0.117574
2019-11-07 13:43:09,178 train 050 1.710668e-02 -0.700660
2019-11-07 13:43:18,996 train 100 1.725226e-02 -0.671953
2019-11-07 13:43:28,810 train 150 1.724941e-02 -0.705233
2019-11-07 13:43:38,634 train 200 1.726784e-02 -0.698101
2019-11-07 13:43:48,455 train 250 1.720841e-02 -0.685948
2019-11-07 13:43:58,283 train 300 1.723969e-02 -0.726168
2019-11-07 13:44:08,129 train 350 1.724281e-02 -0.749741
2019-11-07 13:44:17,998 train 400 1.727325e-02 -0.735101
2019-11-07 13:44:27,863 train 450 1.724533e-02 -0.726851
2019-11-07 13:44:37,749 train 500 1.723626e-02 -0.739317
2019-11-07 13:44:47,646 train 550 1.724546e-02 -0.736974
2019-11-07 13:44:57,512 train 600 1.724789e-02 -0.714246
2019-11-07 13:45:07,408 train 650 1.721477e-02 -0.767613
2019-11-07 13:45:17,308 train 700 1.722968e-02 -0.868354
2019-11-07 13:45:27,206 train 750 1.722418e-02 -0.858162
2019-11-07 13:45:37,118 train 800 1.722037e-02 -0.868894
2019-11-07 13:45:47,024 train 850 1.721630e-02 -0.842049
2019-11-07 13:45:49,984 training loss; R2: 1.722387e-02 -0.837294
2019-11-07 13:45:50,647 valid 000 1.620745e-02 -0.694824
2019-11-07 13:46:00,076 valid 050 1.708299e-02 -0.810925
2019-11-07 13:46:08,430 validation loss; R2: 1.718056e-02 -1.586497
2019-11-07 13:46:08,496 epoch 533 lr 1.000000e-05
2019-11-07 13:46:09,284 train 000 1.515825e-02 -20.148635
2019-11-07 13:46:19,033 train 050 1.704152e-02 -0.892685
2019-11-07 13:46:28,813 train 100 1.716839e-02 -0.817068
2019-11-07 13:46:38,611 train 150 1.708539e-02 -0.801384
2019-11-07 13:46:48,399 train 200 1.699941e-02 -0.790840
2019-11-07 13:46:58,209 train 250 1.704333e-02 -0.786035
2019-11-07 13:47:08,008 train 300 1.714057e-02 -0.740225
2019-11-07 13:47:17,828 train 350 1.712547e-02 -0.742438
2019-11-07 13:47:27,664 train 400 1.712697e-02 -0.734063
2019-11-07 13:47:37,521 train 450 1.713810e-02 -0.719787
2019-11-07 13:47:47,374 train 500 1.712171e-02 -0.743107
2019-11-07 13:47:57,228 train 550 1.715350e-02 -0.731341
2019-11-07 13:48:07,100 train 600 1.715775e-02 -0.729818
2019-11-07 13:48:16,981 train 650 1.717451e-02 -0.735187
2019-11-07 13:48:26,842 train 700 1.716390e-02 -0.728506
2019-11-07 13:48:36,715 train 750 1.718718e-02 -0.729146
2019-11-07 13:48:46,584 train 800 1.719648e-02 -0.750169
2019-11-07 13:48:56,464 train 850 1.720877e-02 -0.750066
2019-11-07 13:48:59,433 training loss; R2: 1.719847e-02 -0.745711
2019-11-07 13:49:00,092 valid 000 1.914481e-02 -0.607156
2019-11-07 13:49:09,482 valid 050 1.611348e-02 -0.759402
2019-11-07 13:49:17,801 validation loss; R2: 1.601525e-02 -0.816871
2019-11-07 13:49:17,884 epoch 534 lr 1.000000e-05
2019-11-07 13:49:18,692 train 000 1.734011e-02 -0.267934
2019-11-07 13:49:28,816 train 050 1.679195e-02 -0.783418
2019-11-07 13:49:38,983 train 100 1.699550e-02 -0.732060
2019-11-07 13:49:49,142 train 150 1.703398e-02 -0.785410
2019-11-07 13:49:59,305 train 200 1.714313e-02 -0.767488
2019-11-07 13:50:09,471 train 250 1.714879e-02 -0.743371
2019-11-07 13:50:19,644 train 300 1.718820e-02 -0.702770
2019-11-07 13:50:29,814 train 350 1.715894e-02 -0.714062
2019-11-07 13:50:39,994 train 400 1.714377e-02 -0.720778
2019-11-07 13:50:50,200 train 450 1.715073e-02 -0.727113
2019-11-07 13:51:00,385 train 500 1.718730e-02 -0.701796
2019-11-07 13:51:10,590 train 550 1.715481e-02 -0.685437
2019-11-07 13:51:20,777 train 600 1.711397e-02 -0.696656
2019-11-07 13:51:31,005 train 650 1.713930e-02 -1.095692
2019-11-07 13:51:41,238 train 700 1.710835e-02 -1.051856
2019-11-07 13:51:51,470 train 750 1.710676e-02 -1.029904
2019-11-07 13:52:01,713 train 800 1.712267e-02 -0.993093
2019-11-07 13:52:11,935 train 850 1.712590e-02 -0.979598
2019-11-07 13:52:14,985 training loss; R2: 1.712716e-02 -0.986560
2019-11-07 13:52:15,640 valid 000 2.123877e-02 -0.070974
2019-11-07 13:52:25,049 valid 050 1.743104e-02 -1.719275
2019-11-07 13:52:33,370 validation loss; R2: 1.728960e-02 -3.394483
2019-11-07 13:52:33,450 epoch 535 lr 1.000000e-05
2019-11-07 13:52:34,244 train 000 1.772053e-02 -0.500016
2019-11-07 13:52:44,005 train 050 1.700478e-02 -0.490960
2019-11-07 13:52:53,789 train 100 1.705943e-02 -0.870264
2019-11-07 13:53:03,573 train 150 1.703741e-02 -0.775127
2019-11-07 13:53:13,355 train 200 1.707624e-02 -0.725334
2019-11-07 13:53:23,142 train 250 1.702893e-02 -0.735394
2019-11-07 13:53:32,929 train 300 1.701048e-02 -0.788823
2019-11-07 13:53:42,730 train 350 1.705993e-02 -0.800102
2019-11-07 13:53:52,563 train 400 1.711658e-02 -1.021515
2019-11-07 13:54:02,384 train 450 1.710710e-02 -0.993552
2019-11-07 13:54:12,208 train 500 1.707528e-02 -0.971285
2019-11-07 13:54:22,058 train 550 1.707039e-02 -0.937051
2019-11-07 13:54:31,899 train 600 1.708066e-02 -0.911889
2019-11-07 13:54:41,760 train 650 1.709997e-02 -1.054578
2019-11-07 13:54:51,609 train 700 1.711303e-02 -1.045978
2019-11-07 13:55:01,458 train 750 1.711709e-02 -1.046976
2019-11-07 13:55:11,290 train 800 1.712713e-02 -1.023210
2019-11-07 13:55:21,134 train 850 1.713007e-02 -1.021222
2019-11-07 13:55:24,089 training loss; R2: 1.712434e-02 -1.018879
2019-11-07 13:55:24,763 valid 000 1.631466e-02 -0.925680
2019-11-07 13:55:34,091 valid 050 1.740145e-02 -4.922627
2019-11-07 13:55:42,515 validation loss; R2: 1.751244e-02 -3.201025
2019-11-07 13:55:42,579 epoch 536 lr 1.000000e-05
2019-11-07 13:55:43,362 train 000 1.775427e-02 -0.284292
2019-11-07 13:55:53,085 train 050 1.745911e-02 -0.850282
2019-11-07 13:56:02,837 train 100 1.695230e-02 -0.830124
2019-11-07 13:56:12,618 train 150 1.699120e-02 -0.848076
2019-11-07 13:56:22,422 train 200 1.716901e-02 -0.789550
2019-11-07 13:56:32,217 train 250 1.720649e-02 -0.767496
2019-11-07 13:56:42,015 train 300 1.722659e-02 -0.743988
2019-11-07 13:56:51,832 train 350 1.718619e-02 -0.705887
2019-11-07 13:57:01,659 train 400 1.723091e-02 -0.709502
2019-11-07 13:57:11,492 train 450 1.721583e-02 -0.693614
2019-11-07 13:57:21,332 train 500 1.720405e-02 -0.760050
2019-11-07 13:57:31,190 train 550 1.719094e-02 -0.747609
2019-11-07 13:57:41,079 train 600 1.720343e-02 -0.727580
2019-11-07 13:57:50,963 train 650 1.721578e-02 -0.714821
2019-11-07 13:58:00,855 train 700 1.723668e-02 -0.749899
2019-11-07 13:58:10,763 train 750 1.721596e-02 -0.794674
2019-11-07 13:58:20,680 train 800 1.725385e-02 -0.793823
2019-11-07 13:58:30,570 train 850 1.723632e-02 -0.779454
2019-11-07 13:58:33,534 training loss; R2: 1.723285e-02 -0.776442
2019-11-07 13:58:34,221 valid 000 1.468236e-02 -0.361153
2019-11-07 13:58:43,661 valid 050 1.750208e-02 -1.669583
2019-11-07 13:58:51,998 validation loss; R2: 1.741492e-02 -1.556196
2019-11-07 13:58:52,064 epoch 537 lr 1.000000e-05
2019-11-07 13:58:52,804 train 000 2.167991e-02 -0.181358
2019-11-07 13:59:02,603 train 050 1.728810e-02 -0.863340
2019-11-07 13:59:12,382 train 100 1.719451e-02 -0.732426
2019-11-07 13:59:22,170 train 150 1.711700e-02 -0.763370
2019-11-07 13:59:31,947 train 200 1.705496e-02 -0.738361
2019-11-07 13:59:41,741 train 250 1.698231e-02 -0.779051
2019-11-07 13:59:51,547 train 300 1.699723e-02 -0.738729
2019-11-07 14:00:01,382 train 350 1.703256e-02 -0.735215
2019-11-07 14:00:11,229 train 400 1.705437e-02 -0.842468
2019-11-07 14:00:21,073 train 450 1.708437e-02 -0.836980
2019-11-07 14:00:30,935 train 500 1.708476e-02 -0.848606
2019-11-07 14:00:40,800 train 550 1.710792e-02 -0.869736
2019-11-07 14:00:50,658 train 600 1.711363e-02 -0.863583
2019-11-07 14:01:00,529 train 650 1.714380e-02 -0.837885
2019-11-07 14:01:10,408 train 700 1.716492e-02 -0.811177
2019-11-07 14:01:20,270 train 750 1.718213e-02 -0.800744
2019-11-07 14:01:30,151 train 800 1.719068e-02 -0.800752
2019-11-07 14:01:40,021 train 850 1.718665e-02 -0.790023
2019-11-07 14:01:42,965 training loss; R2: 1.718166e-02 -0.789803
2019-11-07 14:01:43,567 valid 000 1.349592e-02 -2.533285
2019-11-07 14:01:52,989 valid 050 1.662249e-02 -0.931261
2019-11-07 14:02:01,438 validation loss; R2: 1.658598e-02 -1.032319
2019-11-07 14:02:01,504 epoch 538 lr 1.000000e-05
2019-11-07 14:02:02,271 train 000 1.504897e-02 -0.429149
2019-11-07 14:02:12,022 train 050 1.691519e-02 -0.988796
2019-11-07 14:02:21,778 train 100 1.681086e-02 -0.927230
2019-11-07 14:02:31,568 train 150 1.702222e-02 -0.914182
2019-11-07 14:02:41,370 train 200 1.703614e-02 -0.817065
2019-11-07 14:02:51,163 train 250 1.710735e-02 -0.799263
2019-11-07 14:03:00,966 train 300 1.709120e-02 -0.802927
2019-11-07 14:03:10,768 train 350 1.709268e-02 -0.782436
2019-11-07 14:03:20,581 train 400 1.714400e-02 -0.781867
2019-11-07 14:03:30,408 train 450 1.716942e-02 -0.786186
2019-11-07 14:03:40,245 train 500 1.714562e-02 -0.780114
2019-11-07 14:03:50,088 train 550 1.712129e-02 -0.773745
2019-11-07 14:03:59,963 train 600 1.713319e-02 -0.775975
2019-11-07 14:04:09,828 train 650 1.709647e-02 -0.753580
2019-11-07 14:04:19,695 train 700 1.710594e-02 -0.747751
2019-11-07 14:04:29,558 train 750 1.709452e-02 -0.741488
2019-11-07 14:04:39,419 train 800 1.709578e-02 -0.727033
2019-11-07 14:04:49,300 train 850 1.709655e-02 -0.730287
2019-11-07 14:04:52,249 training loss; R2: 1.709939e-02 -0.727978
2019-11-07 14:04:52,831 valid 000 1.820892e-02 -0.705621
2019-11-07 14:05:02,273 valid 050 1.855746e-02 -22.231071
2019-11-07 14:05:10,744 validation loss; R2: 1.825970e-02 -13.313547
2019-11-07 14:05:10,811 epoch 539 lr 1.000000e-05
2019-11-07 14:05:11,602 train 000 1.724173e-02 -0.401985
2019-11-07 14:05:21,329 train 050 1.717811e-02 -1.475195
2019-11-07 14:05:31,098 train 100 1.713746e-02 -1.084518
2019-11-07 14:05:40,875 train 150 1.727659e-02 -0.843295
2019-11-07 14:05:50,647 train 200 1.720170e-02 -0.821717
2019-11-07 14:06:00,445 train 250 1.716610e-02 -0.815918
2019-11-07 14:06:10,228 train 300 1.715682e-02 -0.883926
2019-11-07 14:06:20,004 train 350 1.712337e-02 -0.828985
2019-11-07 14:06:29,808 train 400 1.717074e-02 -0.838854
2019-11-07 14:06:39,626 train 450 1.717534e-02 -0.816225
2019-11-07 14:06:49,459 train 500 1.716977e-02 -0.798361
2019-11-07 14:06:59,299 train 550 1.716260e-02 -0.785304
2019-11-07 14:07:09,147 train 600 1.715890e-02 -0.779522
2019-11-07 14:07:18,990 train 650 1.715597e-02 -0.773276
2019-11-07 14:07:28,833 train 700 1.714545e-02 -0.842615
2019-11-07 14:07:38,685 train 750 1.715390e-02 -0.817750
2019-11-07 14:07:48,551 train 800 1.714455e-02 -0.801343
2019-11-07 14:07:58,433 train 850 1.715146e-02 -0.785532
2019-11-07 14:08:01,387 training loss; R2: 1.715952e-02 -0.785769
2019-11-07 14:08:02,049 valid 000 1.614571e-02 -0.462274
2019-11-07 14:08:11,500 valid 050 1.696434e-02 -0.787104
2019-11-07 14:08:19,840 validation loss; R2: 1.709197e-02 -1.185467
2019-11-07 14:08:19,905 epoch 540 lr 1.000000e-05
2019-11-07 14:08:20,708 train 000 1.695321e-02 -0.314907
2019-11-07 14:08:30,450 train 050 1.675946e-02 -1.208727
2019-11-07 14:08:40,210 train 100 1.690591e-02 -1.076957
2019-11-07 14:08:49,982 train 150 1.696269e-02 -0.962063
2019-11-07 14:08:59,780 train 200 1.697027e-02 -0.970840
2019-11-07 14:09:09,572 train 250 1.691203e-02 -0.895261
2019-11-07 14:09:19,375 train 300 1.701542e-02 -1.748623
2019-11-07 14:09:29,166 train 350 1.699636e-02 -1.584942
2019-11-07 14:09:38,988 train 400 1.701726e-02 -1.534626
2019-11-07 14:09:48,821 train 450 1.704591e-02 -1.467045
2019-11-07 14:09:58,671 train 500 1.709444e-02 -1.380369
2019-11-07 14:10:08,566 train 550 1.709776e-02 -1.310450
2019-11-07 14:10:18,417 train 600 1.714522e-02 -1.244990
2019-11-07 14:10:28,276 train 650 1.711416e-02 -1.206856
2019-11-07 14:10:38,121 train 700 1.712293e-02 -1.166602
2019-11-07 14:10:47,979 train 750 1.711023e-02 -1.133048
2019-11-07 14:10:57,838 train 800 1.711278e-02 -1.111264
2019-11-07 14:11:07,690 train 850 1.710337e-02 -1.090232
2019-11-07 14:11:10,646 training loss; R2: 1.709812e-02 -1.088928
2019-11-07 14:11:11,355 valid 000 1.668877e-02 -2.172922
2019-11-07 14:11:20,721 valid 050 1.663769e-02 -1.157525
2019-11-07 14:11:29,075 validation loss; R2: 1.663756e-02 -1.217552
2019-11-07 14:11:29,140 epoch 541 lr 1.000000e-05
2019-11-07 14:11:29,908 train 000 1.691171e-02 -0.291781
2019-11-07 14:11:39,666 train 050 1.684927e-02 -0.598847
2019-11-07 14:11:49,421 train 100 1.703952e-02 -0.624877
2019-11-07 14:11:59,212 train 150 1.713384e-02 -0.821388
2019-11-07 14:12:09,006 train 200 1.710367e-02 -0.823690
2019-11-07 14:12:18,802 train 250 1.708659e-02 -0.780361
2019-11-07 14:12:28,600 train 300 1.715884e-02 -0.756294
2019-11-07 14:12:38,404 train 350 1.712738e-02 -0.848316
2019-11-07 14:12:48,227 train 400 1.714504e-02 -0.808739
2019-11-07 14:12:58,111 train 450 1.713871e-02 -0.778155
2019-11-07 14:13:07,968 train 500 1.710512e-02 -0.764850
2019-11-07 14:13:17,822 train 550 1.712465e-02 -0.745989
2019-11-07 14:13:27,685 train 600 1.713902e-02 -0.760127
2019-11-07 14:13:37,548 train 650 1.712715e-02 -0.751042
2019-11-07 14:13:47,404 train 700 1.714595e-02 -0.734709
2019-11-07 14:13:57,267 train 750 1.715671e-02 -0.740407
2019-11-07 14:14:07,156 train 800 1.715916e-02 -0.775567
2019-11-07 14:14:17,015 train 850 1.715653e-02 -0.779879
2019-11-07 14:14:19,970 training loss; R2: 1.714839e-02 -0.776123
2019-11-07 14:14:20,660 valid 000 1.499747e-02 -3.425149
2019-11-07 14:14:30,068 valid 050 1.651188e-02 -1.302003
2019-11-07 14:14:38,484 validation loss; R2: 1.636794e-02 -1.179407
2019-11-07 14:14:38,550 epoch 542 lr 1.000000e-05
2019-11-07 14:14:39,307 train 000 1.815416e-02 -0.394900
2019-11-07 14:14:49,058 train 050 1.720560e-02 -0.700811
2019-11-07 14:14:58,822 train 100 1.700714e-02 -0.735957
2019-11-07 14:15:08,597 train 150 1.699878e-02 -0.769340
2019-11-07 14:15:18,366 train 200 1.689323e-02 -0.803592
2019-11-07 14:15:28,156 train 250 1.695265e-02 -0.913722
2019-11-07 14:15:37,945 train 300 1.701135e-02 -0.877600
2019-11-07 14:15:47,736 train 350 1.702827e-02 -0.837109
2019-11-07 14:15:57,549 train 400 1.702064e-02 -0.810437
2019-11-07 14:16:07,381 train 450 1.707987e-02 -0.845383
2019-11-07 14:16:17,211 train 500 1.708470e-02 -0.843073
2019-11-07 14:16:27,053 train 550 1.705336e-02 -0.854271
2019-11-07 14:16:36,905 train 600 1.704094e-02 -0.891710
2019-11-07 14:16:46,757 train 650 1.704200e-02 -0.869057
2019-11-07 14:16:56,596 train 700 1.704980e-02 -0.859867
2019-11-07 14:17:06,469 train 750 1.706817e-02 -0.850676
2019-11-07 14:17:16,330 train 800 1.706284e-02 -0.840655
2019-11-07 14:17:26,199 train 850 1.708157e-02 -0.822554
2019-11-07 14:17:29,143 training loss; R2: 1.707200e-02 -0.823239
2019-11-07 14:17:29,815 valid 000 1.493798e-02 -0.038367
2019-11-07 14:17:39,209 valid 050 1.663396e-02 -1.662262
2019-11-07 14:17:47,527 validation loss; R2: 1.681282e-02 -1.317631
2019-11-07 14:17:47,592 epoch 543 lr 1.000000e-05
2019-11-07 14:17:48,335 train 000 1.650603e-02 -0.391389
2019-11-07 14:17:58,088 train 050 1.754933e-02 -0.767002
2019-11-07 14:18:07,867 train 100 1.754477e-02 -0.716864
2019-11-07 14:18:17,636 train 150 1.739282e-02 -0.674147
2019-11-07 14:18:27,415 train 200 1.729894e-02 -0.696019
2019-11-07 14:18:37,207 train 250 1.717535e-02 -0.663916
2019-11-07 14:18:46,991 train 300 1.711635e-02 -0.671987
2019-11-07 14:18:56,792 train 350 1.713902e-02 -0.695363
2019-11-07 14:19:06,611 train 400 1.710255e-02 -0.697468
2019-11-07 14:19:16,431 train 450 1.707376e-02 -0.693181
2019-11-07 14:19:26,281 train 500 1.709762e-02 -0.684746
2019-11-07 14:19:36,125 train 550 1.714930e-02 -0.678724
2019-11-07 14:19:45,973 train 600 1.711937e-02 -0.675690
2019-11-07 14:19:55,828 train 650 1.709081e-02 -0.967478
2019-11-07 14:20:05,671 train 700 1.709827e-02 -0.995922
2019-11-07 14:20:15,526 train 750 1.709108e-02 -0.967843
2019-11-07 14:20:25,372 train 800 1.711537e-02 -0.945235
2019-11-07 14:20:35,240 train 850 1.711212e-02 -1.188767
2019-11-07 14:20:38,194 training loss; R2: 1.712939e-02 -1.177136
2019-11-07 14:20:38,851 valid 000 1.587873e-02 -0.335964
2019-11-07 14:20:48,265 valid 050 1.789929e-02 -1.551297
2019-11-07 14:20:56,786 validation loss; R2: 1.814105e-02 -1.435096
2019-11-07 14:20:56,850 epoch 544 lr 1.000000e-05
2019-11-07 14:20:57,634 train 000 2.042047e-02 -0.540685
2019-11-07 14:21:07,381 train 050 1.704304e-02 -1.591211
2019-11-07 14:21:17,174 train 100 1.727527e-02 -1.269196
2019-11-07 14:21:26,957 train 150 1.728221e-02 -1.056218
2019-11-07 14:21:36,735 train 200 1.723757e-02 -0.941508
2019-11-07 14:21:46,526 train 250 1.719418e-02 -0.863785
2019-11-07 14:21:56,315 train 300 1.718435e-02 -0.866598
2019-11-07 14:22:06,105 train 350 1.721139e-02 -0.815682
2019-11-07 14:22:15,909 train 400 1.719759e-02 -0.815926
2019-11-07 14:22:25,743 train 450 1.722323e-02 -0.862925
2019-11-07 14:22:35,576 train 500 1.720238e-02 -0.842985
2019-11-07 14:22:45,410 train 550 1.719833e-02 -0.830916
2019-11-07 14:22:55,296 train 600 1.719802e-02 -0.800433
2019-11-07 14:23:05,165 train 650 1.719043e-02 -0.803858
2019-11-07 14:23:15,016 train 700 1.718494e-02 -0.800496
2019-11-07 14:23:24,881 train 750 1.722081e-02 -0.786048
2019-11-07 14:23:34,746 train 800 1.721487e-02 -0.775169
2019-11-07 14:23:44,606 train 850 1.721849e-02 -0.770392
2019-11-07 14:23:47,541 training loss; R2: 1.720475e-02 -0.766095
2019-11-07 14:23:48,173 valid 000 1.633282e-02 -0.169783
2019-11-07 14:23:57,617 valid 050 1.627727e-02 -1.231226
2019-11-07 14:24:05,934 validation loss; R2: 1.637240e-02 -1.840753
2019-11-07 14:24:05,999 epoch 545 lr 1.000000e-05
2019-11-07 14:24:06,778 train 000 1.634877e-02 -0.669388
2019-11-07 14:24:16,519 train 050 1.722199e-02 -0.736827
2019-11-07 14:24:26,298 train 100 1.709667e-02 -0.725719
2019-11-07 14:24:36,093 train 150 1.713353e-02 -0.773590
2019-11-07 14:24:45,892 train 200 1.713512e-02 -0.801577
2019-11-07 14:24:55,690 train 250 1.707169e-02 -0.761182
2019-11-07 14:25:05,488 train 300 1.715735e-02 -0.745537
2019-11-07 14:25:15,298 train 350 1.713191e-02 -0.726481
2019-11-07 14:25:25,125 train 400 1.716059e-02 -0.737711
2019-11-07 14:25:34,977 train 450 1.717691e-02 -0.718904
2019-11-07 14:25:44,822 train 500 1.712861e-02 -0.729241
2019-11-07 14:25:54,678 train 550 1.709115e-02 -0.887126
2019-11-07 14:26:04,542 train 600 1.709651e-02 -0.882316
2019-11-07 14:26:14,395 train 650 1.709155e-02 -0.866650
2019-11-07 14:26:24,264 train 700 1.710626e-02 -0.847855
2019-11-07 14:26:34,153 train 750 1.711384e-02 -0.847987
2019-11-07 14:26:44,023 train 800 1.708611e-02 -0.862793
2019-11-07 14:26:53,868 train 850 1.709441e-02 -0.848034
2019-11-07 14:26:56,807 training loss; R2: 1.709640e-02 -0.847038
2019-11-07 14:26:57,517 valid 000 1.910791e-02 -1.366911
2019-11-07 14:27:06,864 valid 050 1.764321e-02 -1.372136
2019-11-07 14:27:15,273 validation loss; R2: 1.742397e-02 -1.258605
2019-11-07 14:27:15,340 epoch 546 lr 1.000000e-05
2019-11-07 14:27:16,095 train 000 1.901123e-02 -2.758372
2019-11-07 14:27:25,816 train 050 1.714779e-02 -0.689022
2019-11-07 14:27:35,600 train 100 1.686052e-02 -0.901906
2019-11-07 14:27:45,391 train 150 1.700570e-02 -0.886635
2019-11-07 14:27:55,186 train 200 1.699159e-02 -0.866467
2019-11-07 14:28:04,985 train 250 1.706239e-02 -0.807678
2019-11-07 14:28:14,767 train 300 1.714563e-02 -0.784933
2019-11-07 14:28:24,576 train 350 1.712638e-02 -0.778900
2019-11-07 14:28:34,383 train 400 1.713430e-02 -0.775174
2019-11-07 14:28:44,211 train 450 1.713493e-02 -0.764077
2019-11-07 14:28:54,056 train 500 1.709651e-02 -0.772122
2019-11-07 14:29:03,891 train 550 1.709657e-02 -0.780476
2019-11-07 14:29:13,753 train 600 1.705868e-02 -0.792179
2019-11-07 14:29:23,605 train 650 1.708196e-02 -0.779263
2019-11-07 14:29:33,464 train 700 1.709356e-02 -0.777987
2019-11-07 14:29:43,319 train 750 1.708772e-02 -0.788717
2019-11-07 14:29:53,185 train 800 1.710045e-02 -0.784000
2019-11-07 14:30:03,077 train 850 1.710548e-02 -0.766580
2019-11-07 14:30:06,023 training loss; R2: 1.709006e-02 -0.763397
2019-11-07 14:30:06,712 valid 000 1.578293e-02 0.037157
2019-11-07 14:30:16,105 valid 050 1.665998e-02 -16.252952
2019-11-07 14:30:24,525 validation loss; R2: 1.648135e-02 -9.092471
2019-11-07 14:30:24,611 epoch 547 lr 1.000000e-05
2019-11-07 14:30:25,410 train 000 1.860875e-02 -0.110481
2019-11-07 14:30:35,169 train 050 1.646675e-02 -0.591472
2019-11-07 14:30:44,968 train 100 1.691583e-02 -0.654677
2019-11-07 14:30:54,788 train 150 1.697489e-02 -0.674125
2019-11-07 14:31:04,612 train 200 1.709773e-02 -0.666147
2019-11-07 14:31:14,427 train 250 1.722877e-02 -0.712598
2019-11-07 14:31:24,231 train 300 1.719073e-02 -0.699318
2019-11-07 14:31:34,055 train 350 1.717710e-02 -0.684504
2019-11-07 14:31:43,895 train 400 1.718330e-02 -0.686169
2019-11-07 14:31:53,735 train 450 1.716774e-02 -0.687036
2019-11-07 14:32:03,559 train 500 1.716003e-02 -0.682780
2019-11-07 14:32:13,415 train 550 1.712434e-02 -0.706277
2019-11-07 14:32:23,260 train 600 1.710610e-02 -0.692103
2019-11-07 14:32:33,109 train 650 1.708557e-02 -0.699103
2019-11-07 14:32:42,960 train 700 1.709365e-02 -0.697940
2019-11-07 14:32:52,823 train 750 1.709408e-02 -0.714578
2019-11-07 14:33:02,689 train 800 1.705939e-02 -0.716195
2019-11-07 14:33:12,548 train 850 1.705876e-02 -0.706532
2019-11-07 14:33:15,494 training loss; R2: 1.705094e-02 -0.702597
2019-11-07 14:33:16,116 valid 000 1.442164e-02 -0.655170
2019-11-07 14:33:25,554 valid 050 1.653289e-02 -1.041788
2019-11-07 14:33:33,865 validation loss; R2: 1.654068e-02 -1.072599
2019-11-07 14:33:33,924 epoch 548 lr 1.000000e-05
2019-11-07 14:33:34,696 train 000 1.635842e-02 -0.093365
2019-11-07 14:33:44,468 train 050 1.736417e-02 -0.547962
2019-11-07 14:33:54,228 train 100 1.718885e-02 -0.713745
2019-11-07 14:34:04,023 train 150 1.716076e-02 -0.723647
2019-11-07 14:34:13,832 train 200 1.722759e-02 -0.703451
2019-11-07 14:34:23,655 train 250 1.717472e-02 -0.761209
2019-11-07 14:34:33,469 train 300 1.713868e-02 -0.848940
2019-11-07 14:34:43,285 train 350 1.710933e-02 -0.817534
2019-11-07 14:34:53,128 train 400 1.709463e-02 -0.806330
2019-11-07 14:35:02,960 train 450 1.711008e-02 -0.827700
2019-11-07 14:35:12,811 train 500 1.711969e-02 -0.799616
2019-11-07 14:35:22,653 train 550 1.709473e-02 -0.799094
2019-11-07 14:35:32,489 train 600 1.707667e-02 -0.811758
2019-11-07 14:35:42,331 train 650 1.707747e-02 -0.816257
2019-11-07 14:35:52,178 train 700 1.711318e-02 -0.799585
2019-11-07 14:36:02,023 train 750 1.710326e-02 -0.800424
2019-11-07 14:36:11,891 train 800 1.710649e-02 -0.787159
2019-11-07 14:36:21,769 train 850 1.709385e-02 -0.783723
2019-11-07 14:36:24,724 training loss; R2: 1.709243e-02 -0.782082
2019-11-07 14:36:25,312 valid 000 1.895072e-02 -1.219997
2019-11-07 14:36:34,788 valid 050 1.654515e-02 -1.533463
2019-11-07 14:36:43,106 validation loss; R2: 1.647334e-02 -1.207282
2019-11-07 14:36:43,172 epoch 549 lr 1.000000e-05
2019-11-07 14:36:43,959 train 000 2.086219e-02 0.073438
2019-11-07 14:36:53,713 train 050 1.708947e-02 -1.187595
2019-11-07 14:37:03,492 train 100 1.709527e-02 -0.856480
2019-11-07 14:37:13,273 train 150 1.701525e-02 -0.824411
2019-11-07 14:37:23,059 train 200 1.713787e-02 -0.815400
2019-11-07 14:37:32,859 train 250 1.718385e-02 -0.865330
2019-11-07 14:37:42,646 train 300 1.717319e-02 -0.815984
2019-11-07 14:37:52,451 train 350 1.717703e-02 -0.785667
2019-11-07 14:38:02,263 train 400 1.714499e-02 -0.762108
2019-11-07 14:38:12,095 train 450 1.717518e-02 -0.775380
2019-11-07 14:38:21,926 train 500 1.712749e-02 -0.762711
2019-11-07 14:38:31,770 train 550 1.709520e-02 -0.760537
2019-11-07 14:38:41,625 train 600 1.710565e-02 -0.788888
2019-11-07 14:38:51,465 train 650 1.714375e-02 -0.782278
2019-11-07 14:39:01,301 train 700 1.719328e-02 -0.772803
2019-11-07 14:39:11,145 train 750 1.720821e-02 -0.763200
2019-11-07 14:39:21,014 train 800 1.720647e-02 -0.756926
2019-11-07 14:39:30,866 train 850 1.719850e-02 -0.741279
2019-11-07 14:39:33,820 training loss; R2: 1.719109e-02 -0.737214
2019-11-07 14:39:34,442 valid 000 1.828772e-02 -0.415277
2019-11-07 14:39:43,872 valid 050 1.914684e-02 -5.039078
2019-11-07 14:39:52,238 validation loss; R2: 1.901552e-02 -3.823794
2019-11-07 14:39:52,304 epoch 550 lr 1.000000e-05
2019-11-07 14:39:53,061 train 000 1.842334e-02 0.105916
2019-11-07 14:40:02,813 train 050 1.715491e-02 -0.674469
2019-11-07 14:40:12,592 train 100 1.743327e-02 -0.639601
2019-11-07 14:40:22,359 train 150 1.721911e-02 -0.650941
2019-11-07 14:40:32,135 train 200 1.718086e-02 -0.611686
2019-11-07 14:40:41,909 train 250 1.712390e-02 -0.725369
2019-11-07 14:40:51,692 train 300 1.711686e-02 -0.723822
2019-11-07 14:41:01,489 train 350 1.715313e-02 -0.715173
2019-11-07 14:41:11,287 train 400 1.713017e-02 -0.738397
2019-11-07 14:41:21,094 train 450 1.705938e-02 -0.737387
2019-11-07 14:41:30,920 train 500 1.707427e-02 -0.775643
2019-11-07 14:41:40,755 train 550 1.704824e-02 -0.790178
2019-11-07 14:41:50,578 train 600 1.706232e-02 -0.779431
2019-11-07 14:42:00,415 train 650 1.707322e-02 -0.784869
2019-11-07 14:42:10,250 train 700 1.704267e-02 -0.809623
2019-11-07 14:42:20,112 train 750 1.703685e-02 -0.838702
2019-11-07 14:42:29,954 train 800 1.704349e-02 -0.861826
2019-11-07 14:42:39,802 train 850 1.706526e-02 -0.837277
2019-11-07 14:42:42,745 training loss; R2: 1.706686e-02 -0.837310
2019-11-07 14:42:43,426 valid 000 1.452227e-02 0.074876
2019-11-07 14:42:52,801 valid 050 1.701929e-02 -1.090843
2019-11-07 14:43:01,144 validation loss; R2: 1.672792e-02 -1.075644
2019-11-07 14:43:01,202 epoch 551 lr 1.000000e-05
2019-11-07 14:43:01,968 train 000 1.659681e-02 -0.124141
2019-11-07 14:43:11,726 train 050 1.722989e-02 -1.054790
2019-11-07 14:43:21,486 train 100 1.709777e-02 -0.965951
2019-11-07 14:43:31,262 train 150 1.716637e-02 -0.836657
2019-11-07 14:43:41,052 train 200 1.716249e-02 -0.943192
2019-11-07 14:43:50,846 train 250 1.719793e-02 -0.858451
2019-11-07 14:44:00,638 train 300 1.729105e-02 -0.832613
2019-11-07 14:44:10,442 train 350 1.725746e-02 -0.843544
2019-11-07 14:44:20,250 train 400 1.721657e-02 -0.844755
2019-11-07 14:44:30,085 train 450 1.720975e-02 -0.811952
2019-11-07 14:44:39,937 train 500 1.720681e-02 -0.839971
2019-11-07 14:44:49,784 train 550 1.718936e-02 -0.810927
2019-11-07 14:44:59,635 train 600 1.717568e-02 -0.796392
2019-11-07 14:45:09,490 train 650 1.717038e-02 -0.802957
2019-11-07 14:45:19,345 train 700 1.717027e-02 -0.816803
2019-11-07 14:45:29,200 train 750 1.716536e-02 -0.817360
2019-11-07 14:45:39,054 train 800 1.714064e-02 -0.827908
2019-11-07 14:45:48,922 train 850 1.714224e-02 -0.820659
2019-11-07 14:45:51,862 training loss; R2: 1.714567e-02 -0.818925
2019-11-07 14:45:52,551 valid 000 1.711736e-02 -5.567314
2019-11-07 14:46:01,941 valid 050 1.661077e-02 -1.223725
2019-11-07 14:46:10,261 validation loss; R2: 1.645664e-02 -1.158084
2019-11-07 14:46:10,326 epoch 552 lr 1.000000e-05
2019-11-07 14:46:11,058 train 000 1.595950e-02 -0.178931
2019-11-07 14:46:20,819 train 050 1.696587e-02 -0.712008
2019-11-07 14:46:30,590 train 100 1.685774e-02 -0.732158
2019-11-07 14:46:40,377 train 150 1.692337e-02 -0.694358
2019-11-07 14:46:50,155 train 200 1.699917e-02 -0.686721
2019-11-07 14:46:59,943 train 250 1.705392e-02 -0.666374
2019-11-07 14:47:09,736 train 300 1.704731e-02 -0.736174
2019-11-07 14:47:19,526 train 350 1.706712e-02 -0.700914
2019-11-07 14:47:29,325 train 400 1.704852e-02 -0.710900
2019-11-07 14:47:39,142 train 450 1.710311e-02 -0.715573
2019-11-07 14:47:48,957 train 500 1.708448e-02 -0.743861
2019-11-07 14:47:58,790 train 550 1.711740e-02 -0.740609
2019-11-07 14:48:08,623 train 600 1.711208e-02 -0.748743
2019-11-07 14:48:18,471 train 650 1.711891e-02 -0.751134
2019-11-07 14:48:28,497 train 700 1.710833e-02 -0.757453
2019-11-07 14:48:38,703 train 750 1.710992e-02 -0.749930
2019-11-07 14:48:48,909 train 800 1.709371e-02 -0.779356
2019-11-07 14:48:59,118 train 850 1.711315e-02 -0.807722
2019-11-07 14:49:02,167 training loss; R2: 1.710658e-02 -0.806741
2019-11-07 14:49:02,851 valid 000 1.623756e-02 -1.549166
2019-11-07 14:49:12,226 valid 050 1.717825e-02 -0.716723
2019-11-07 14:49:20,537 validation loss; R2: 1.728621e-02 -1.234647
2019-11-07 14:49:20,611 epoch 553 lr 1.000000e-05
2019-11-07 14:49:21,372 train 000 1.481619e-02 -0.181506
2019-11-07 14:49:31,520 train 050 1.742117e-02 -0.593090
2019-11-07 14:49:41,311 train 100 1.715811e-02 -0.718344
2019-11-07 14:49:51,091 train 150 1.715645e-02 -0.672828
2019-11-07 14:50:00,884 train 200 1.721987e-02 -0.718348
2019-11-07 14:50:10,678 train 250 1.713794e-02 -1.053600
2019-11-07 14:50:20,461 train 300 1.717518e-02 -0.973923
2019-11-07 14:50:30,269 train 350 1.716259e-02 -0.940195
2019-11-07 14:50:40,054 train 400 1.715318e-02 -0.914566
2019-11-07 14:50:49,878 train 450 1.714017e-02 -0.907677
2019-11-07 14:50:59,696 train 500 1.715348e-02 -0.884662
2019-11-07 14:51:09,533 train 550 1.713761e-02 -0.883944
2019-11-07 14:51:19,378 train 600 1.712671e-02 -0.872620
2019-11-07 14:51:29,228 train 650 1.715446e-02 -0.944985
2019-11-07 14:51:39,064 train 700 1.715573e-02 -0.945283
2019-11-07 14:51:48,920 train 750 1.713208e-02 -0.937304
2019-11-07 14:51:58,782 train 800 1.715075e-02 -0.908493
2019-11-07 14:52:08,632 train 850 1.714003e-02 -0.891784
2019-11-07 14:52:11,604 training loss; R2: 1.713864e-02 -0.885781
2019-11-07 14:52:12,227 valid 000 1.640126e-02 -0.040243
2019-11-07 14:52:21,652 valid 050 1.632785e-02 -1.217795
2019-11-07 14:52:29,969 validation loss; R2: 1.624296e-02 -1.189207
2019-11-07 14:52:30,049 epoch 554 lr 1.000000e-05
2019-11-07 14:52:30,767 train 000 1.566804e-02 -0.013405
2019-11-07 14:52:40,948 train 050 1.736821e-02 -1.272428
2019-11-07 14:52:51,120 train 100 1.735577e-02 -0.979497
2019-11-07 14:53:01,295 train 150 1.745872e-02 -0.836441
2019-11-07 14:53:11,452 train 200 1.743036e-02 -0.804842
2019-11-07 14:53:21,624 train 250 1.733555e-02 -0.731197
2019-11-07 14:53:31,802 train 300 1.731833e-02 -0.715095
2019-11-07 14:53:41,970 train 350 1.727110e-02 -0.724979
2019-11-07 14:53:52,147 train 400 1.722554e-02 -0.743627
2019-11-07 14:54:02,312 train 450 1.716950e-02 -0.733461
2019-11-07 14:54:12,496 train 500 1.711797e-02 -0.768191
2019-11-07 14:54:22,704 train 550 1.716914e-02 -0.786894
2019-11-07 14:54:32,912 train 600 1.718395e-02 -0.791241
2019-11-07 14:54:43,095 train 650 1.715903e-02 -0.775132
2019-11-07 14:54:53,288 train 700 1.716418e-02 -0.779424
2019-11-07 14:55:03,510 train 750 1.712454e-02 -0.770156
2019-11-07 14:55:13,733 train 800 1.711866e-02 -0.762855
2019-11-07 14:55:23,940 train 850 1.712487e-02 -0.756677
2019-11-07 14:55:26,996 training loss; R2: 1.711576e-02 -0.752427
2019-11-07 14:55:27,706 valid 000 1.598014e-02 -1.238614
2019-11-07 14:55:37,031 valid 050 1.587226e-02 -2.156634
2019-11-07 14:55:45,442 validation loss; R2: 1.578348e-02 -1.767783
2019-11-07 14:55:45,509 epoch 555 lr 1.000000e-05
2019-11-07 14:55:46,269 train 000 1.689058e-02 -0.009529
2019-11-07 14:55:56,405 train 050 1.684501e-02 -0.776843
2019-11-07 14:56:06,569 train 100 1.711343e-02 -0.705762
2019-11-07 14:56:16,729 train 150 1.704994e-02 -0.768350
2019-11-07 14:56:26,895 train 200 1.706495e-02 -0.780954
2019-11-07 14:56:37,067 train 250 1.711434e-02 -0.816688
2019-11-07 14:56:47,235 train 300 1.704606e-02 -0.805549
2019-11-07 14:56:57,419 train 350 1.707512e-02 -0.791992
2019-11-07 14:57:07,581 train 400 1.703961e-02 -0.765916
2019-11-07 14:57:17,698 train 450 1.701574e-02 -0.785327
2019-11-07 14:57:27,496 train 500 1.702592e-02 -0.768696
2019-11-07 14:57:37,300 train 550 1.704379e-02 -0.739322
2019-11-07 14:57:47,134 train 600 1.705820e-02 -0.764307
2019-11-07 14:57:56,970 train 650 1.706023e-02 -0.758389
2019-11-07 14:58:06,805 train 700 1.704561e-02 -0.755997
2019-11-07 14:58:16,659 train 750 1.701738e-02 -0.736494
2019-11-07 14:58:26,490 train 800 1.703138e-02 -0.745680
2019-11-07 14:58:36,348 train 850 1.705075e-02 -0.730801
2019-11-07 14:58:39,332 training loss; R2: 1.704386e-02 -0.729840
2019-11-07 14:58:40,023 valid 000 1.615050e-02 -1.663524
2019-11-07 14:58:49,392 valid 050 1.542258e-02 -1.247195
2019-11-07 14:58:57,727 validation loss; R2: 1.546444e-02 -1.347073
2019-11-07 14:58:57,799 epoch 556 lr 1.000000e-05
2019-11-07 14:58:58,553 train 000 1.856357e-02 -0.061796
2019-11-07 14:59:08,709 train 050 1.658910e-02 -0.621162
2019-11-07 14:59:18,874 train 100 1.678362e-02 -0.706127
2019-11-07 14:59:29,042 train 150 1.700822e-02 -0.654088
2019-11-07 14:59:39,193 train 200 1.707145e-02 -0.674931
2019-11-07 14:59:49,363 train 250 1.708684e-02 -0.697455
2019-11-07 14:59:59,520 train 300 1.719917e-02 -0.714216
2019-11-07 15:00:09,688 train 350 1.716676e-02 -0.692495
2019-11-07 15:00:19,480 train 400 1.711288e-02 -0.705208
2019-11-07 15:00:29,256 train 450 1.707030e-02 -0.698937
2019-11-07 15:00:39,038 train 500 1.707556e-02 -0.798252
2019-11-07 15:00:48,827 train 550 1.708304e-02 -0.780044
2019-11-07 15:00:58,635 train 600 1.708922e-02 -0.801046
2019-11-07 15:01:08,455 train 650 1.711774e-02 -0.798148
2019-11-07 15:01:18,332 train 700 1.710401e-02 -0.805737
2019-11-07 15:01:28,219 train 750 1.710992e-02 -0.800762
2019-11-07 15:01:38,122 train 800 1.711884e-02 -0.780454
2019-11-07 15:01:48,001 train 850 1.710834e-02 -0.799476
2019-11-07 15:01:50,956 training loss; R2: 1.711607e-02 -0.792621
2019-11-07 15:01:51,656 valid 000 1.736732e-02 -0.728491
2019-11-07 15:02:00,988 valid 050 1.657408e-02 -0.910889
2019-11-07 15:02:09,336 validation loss; R2: 1.661792e-02 -1.475651
2019-11-07 15:02:09,399 epoch 557 lr 1.000000e-05
2019-11-07 15:02:10,119 train 000 1.841862e-02 -0.325369
2019-11-07 15:02:19,907 train 050 1.736007e-02 -0.778910
2019-11-07 15:02:29,703 train 100 1.728026e-02 -0.823286
2019-11-07 15:02:39,506 train 150 1.724018e-02 -0.724666
2019-11-07 15:02:49,330 train 200 1.720309e-02 -0.768483
2019-11-07 15:02:59,149 train 250 1.729180e-02 -0.768022
2019-11-07 15:03:08,963 train 300 1.727906e-02 -0.740942
2019-11-07 15:03:18,779 train 350 1.725311e-02 -0.709945
2019-11-07 15:03:28,591 train 400 1.721375e-02 -0.694409
2019-11-07 15:03:38,424 train 450 1.721017e-02 -0.689404
2019-11-07 15:03:48,306 train 500 1.720510e-02 -0.689448
2019-11-07 15:03:58,169 train 550 1.718397e-02 -0.701502
2019-11-07 15:04:08,072 train 600 1.718855e-02 -0.700226
2019-11-07 15:04:17,960 train 650 1.719672e-02 -0.685070
2019-11-07 15:04:27,847 train 700 1.719189e-02 -0.709417
2019-11-07 15:04:37,741 train 750 1.717353e-02 -0.700969
2019-11-07 15:04:47,635 train 800 1.716410e-02 -0.708097
2019-11-07 15:04:57,527 train 850 1.712442e-02 -0.720093
2019-11-07 15:05:00,486 training loss; R2: 1.710812e-02 -0.719142
2019-11-07 15:05:01,155 valid 000 1.427577e-02 -2.622842
2019-11-07 15:05:10,581 valid 050 1.693640e-02 -1.074264
2019-11-07 15:05:18,882 validation loss; R2: 1.695238e-02 -3.216479
2019-11-07 15:05:18,941 epoch 558 lr 1.000000e-05
2019-11-07 15:05:19,719 train 000 1.552226e-02 -0.190719
2019-11-07 15:05:29,504 train 050 1.694832e-02 -0.542133
2019-11-07 15:05:39,294 train 100 1.680932e-02 -0.636847
2019-11-07 15:05:49,097 train 150 1.687215e-02 -0.704801
2019-11-07 15:05:58,896 train 200 1.699243e-02 -0.658889
2019-11-07 15:06:08,698 train 250 1.700558e-02 -0.636277
2019-11-07 15:06:18,483 train 300 1.700706e-02 -0.725664
2019-11-07 15:06:28,279 train 350 1.702363e-02 -0.715218
2019-11-07 15:06:38,075 train 400 1.700711e-02 -0.736763
2019-11-07 15:06:47,909 train 450 1.700657e-02 -0.747310
2019-11-07 15:06:57,747 train 500 1.703685e-02 -0.736458
2019-11-07 15:07:07,606 train 550 1.703389e-02 -0.710433
2019-11-07 15:07:17,465 train 600 1.702473e-02 -0.715004
2019-11-07 15:07:27,334 train 650 1.702082e-02 -0.854870
2019-11-07 15:07:37,214 train 700 1.700884e-02 -0.850359
2019-11-07 15:07:47,082 train 750 1.702373e-02 -0.844995
2019-11-07 15:07:56,952 train 800 1.707681e-02 -0.832319
2019-11-07 15:08:06,837 train 850 1.705877e-02 -0.822735
2019-11-07 15:08:09,788 training loss; R2: 1.705477e-02 -0.823258
2019-11-07 15:08:10,483 valid 000 1.825364e-02 -1.821713
2019-11-07 15:08:19,866 valid 050 1.800862e-02 -1.747492
2019-11-07 15:08:28,255 validation loss; R2: 1.804053e-02 -1.592768
2019-11-07 15:08:28,322 epoch 559 lr 1.000000e-05
2019-11-07 15:08:29,112 train 000 1.690764e-02 -0.578258
2019-11-07 15:08:38,881 train 050 1.747466e-02 -0.758400
2019-11-07 15:08:48,682 train 100 1.735428e-02 -0.834525
2019-11-07 15:08:58,475 train 150 1.723883e-02 -0.858568
2019-11-07 15:09:08,271 train 200 1.716771e-02 -0.778970
2019-11-07 15:09:18,072 train 250 1.713982e-02 -0.726160
2019-11-07 15:09:27,884 train 300 1.710640e-02 -0.731696
2019-11-07 15:09:37,712 train 350 1.708283e-02 -0.714387
2019-11-07 15:09:47,558 train 400 1.706513e-02 -0.717136
2019-11-07 15:09:57,420 train 450 1.704454e-02 -0.699992
2019-11-07 15:10:07,295 train 500 1.706120e-02 -0.720265
2019-11-07 15:10:17,170 train 550 1.704641e-02 -0.700448
2019-11-07 15:10:27,040 train 600 1.702414e-02 -0.683022
2019-11-07 15:10:36,915 train 650 1.703057e-02 -0.678664
2019-11-07 15:10:46,780 train 700 1.701155e-02 -0.670549
2019-11-07 15:10:56,700 train 750 1.702991e-02 -0.680443
2019-11-07 15:11:06,649 train 800 1.702601e-02 -0.697790
2019-11-07 15:11:16,610 train 850 1.704327e-02 -0.700788
2019-11-07 15:11:19,586 training loss; R2: 1.703566e-02 -0.695668
2019-11-07 15:11:20,232 valid 000 1.374379e-02 -4.524273
2019-11-07 15:11:29,709 valid 050 1.690623e-02 -1.177042
2019-11-07 15:11:38,052 validation loss; R2: 1.715470e-02 -1.590138
2019-11-07 15:11:38,119 epoch 560 lr 1.000000e-05
2019-11-07 15:11:38,914 train 000 1.738609e-02 -0.277557
2019-11-07 15:11:48,685 train 050 1.748381e-02 -0.609383
2019-11-07 15:11:58,469 train 100 1.723661e-02 -0.645134
2019-11-07 15:12:08,278 train 150 1.735873e-02 -0.666387
2019-11-07 15:12:18,079 train 200 1.729184e-02 -0.691416
2019-11-07 15:12:27,883 train 250 1.726971e-02 -0.665222
2019-11-07 15:12:37,683 train 300 1.720683e-02 -0.642544
2019-11-07 15:12:47,512 train 350 1.726424e-02 -0.642818
2019-11-07 15:12:57,363 train 400 1.723516e-02 -0.669568
2019-11-07 15:13:07,225 train 450 1.727270e-02 -0.662941
2019-11-07 15:13:17,088 train 500 1.722842e-02 -0.666647
2019-11-07 15:13:26,936 train 550 1.719233e-02 -0.668679
2019-11-07 15:13:36,794 train 600 1.719126e-02 -0.697414
2019-11-07 15:13:46,647 train 650 1.719392e-02 -0.727568
2019-11-07 15:13:56,504 train 700 1.717118e-02 -0.724384
2019-11-07 15:14:06,388 train 750 1.716884e-02 -0.752122
2019-11-07 15:14:16,273 train 800 1.714829e-02 -0.740950
2019-11-07 15:14:26,166 train 850 1.716812e-02 -0.735670
2019-11-07 15:14:29,165 training loss; R2: 1.716579e-02 -0.763981
2019-11-07 15:14:29,827 valid 000 1.579364e-02 0.081883
2019-11-07 15:14:39,277 valid 050 1.584324e-02 -0.994387
2019-11-07 15:14:47,607 validation loss; R2: 1.569915e-02 -1.009324
2019-11-07 15:14:47,687 epoch 561 lr 1.000000e-05
2019-11-07 15:14:48,497 train 000 1.685239e-02 -0.443180
2019-11-07 15:14:58,238 train 050 1.663240e-02 -0.554901
2019-11-07 15:15:08,007 train 100 1.687046e-02 -0.647696
2019-11-07 15:15:17,793 train 150 1.686987e-02 -0.608291
2019-11-07 15:15:27,567 train 200 1.696976e-02 -0.573609
2019-11-07 15:15:37,337 train 250 1.696427e-02 -0.621630
2019-11-07 15:15:47,112 train 300 1.697639e-02 -0.682447
2019-11-07 15:15:56,901 train 350 1.704661e-02 -0.731053
2019-11-07 15:16:06,688 train 400 1.702815e-02 -0.714822
2019-11-07 15:16:16,487 train 450 1.706102e-02 -0.685685
2019-11-07 15:16:26,295 train 500 1.709670e-02 -0.691834
2019-11-07 15:16:36,146 train 550 1.709220e-02 -0.715193
2019-11-07 15:16:46,004 train 600 1.709633e-02 -0.717838
2019-11-07 15:16:55,852 train 650 1.710632e-02 -0.724361
2019-11-07 15:17:05,705 train 700 1.711694e-02 -0.715076
2019-11-07 15:17:15,551 train 750 1.710477e-02 -0.736469
2019-11-07 15:17:25,412 train 800 1.709557e-02 -0.742208
2019-11-07 15:17:35,261 train 850 1.709172e-02 -0.734560
2019-11-07 15:17:38,209 training loss; R2: 1.710150e-02 -0.748268
2019-11-07 15:17:38,838 valid 000 1.861767e-02 -1.561989
2019-11-07 15:17:48,280 valid 050 1.813045e-02 -1.072713
2019-11-07 15:17:56,593 validation loss; R2: 1.814801e-02 -1.306930
2019-11-07 15:17:56,666 epoch 562 lr 1.000000e-05
2019-11-07 15:17:57,413 train 000 1.622109e-02 0.040640
2019-11-07 15:18:07,170 train 050 1.705970e-02 -0.563093
2019-11-07 15:18:16,933 train 100 1.711902e-02 -0.592443
2019-11-07 15:18:26,728 train 150 1.702961e-02 -0.579310
2019-11-07 15:18:36,522 train 200 1.693018e-02 -0.632304
2019-11-07 15:18:46,324 train 250 1.696930e-02 -0.668902
2019-11-07 15:18:56,169 train 300 1.693067e-02 -0.668820
2019-11-07 15:19:06,001 train 350 1.698381e-02 -0.761427
2019-11-07 15:19:15,819 train 400 1.698111e-02 -0.761253
2019-11-07 15:19:25,642 train 450 1.701678e-02 -0.804896
2019-11-07 15:19:35,487 train 500 1.704806e-02 -0.781379
2019-11-07 15:19:45,337 train 550 1.704412e-02 -0.787702
2019-11-07 15:19:55,182 train 600 1.702293e-02 -0.797598
2019-11-07 15:20:05,044 train 650 1.702830e-02 -0.788033
2019-11-07 15:20:14,925 train 700 1.702971e-02 -0.767577
2019-11-07 15:20:24,818 train 750 1.703535e-02 -0.752942
2019-11-07 15:20:34,704 train 800 1.705021e-02 -0.754380
2019-11-07 15:20:44,565 train 850 1.703720e-02 -0.781798
2019-11-07 15:20:47,509 training loss; R2: 1.703548e-02 -0.778834
2019-11-07 15:20:48,177 valid 000 1.782090e-02 -0.202957
2019-11-07 15:20:57,575 valid 050 1.730719e-02 -0.895251
2019-11-07 15:21:05,894 validation loss; R2: 1.724593e-02 -0.996654
2019-11-07 15:21:05,958 epoch 563 lr 1.000000e-05
2019-11-07 15:21:06,734 train 000 1.736812e-02 -3.890316
2019-11-07 15:21:16,487 train 050 1.744694e-02 -3.535186
2019-11-07 15:21:26,249 train 100 1.745907e-02 -2.163227
2019-11-07 15:21:36,046 train 150 1.746462e-02 -1.778049
2019-11-07 15:21:45,822 train 200 1.735545e-02 -1.572068
2019-11-07 15:21:55,626 train 250 1.732822e-02 -1.349198
2019-11-07 15:22:05,427 train 300 1.725729e-02 -1.221107
2019-11-07 15:22:15,233 train 350 1.722367e-02 -1.139345
2019-11-07 15:22:25,062 train 400 1.720140e-02 -1.104299
2019-11-07 15:22:34,922 train 450 1.723551e-02 -1.078955
2019-11-07 15:22:44,767 train 500 1.720789e-02 -1.049913
2019-11-07 15:22:54,631 train 550 1.717853e-02 -1.044409
2019-11-07 15:23:04,535 train 600 1.718723e-02 -1.029927
2019-11-07 15:23:14,404 train 650 1.717793e-02 -0.990004
2019-11-07 15:23:24,263 train 700 1.718042e-02 -0.961704
2019-11-07 15:23:34,124 train 750 1.718837e-02 -0.949137
2019-11-07 15:23:44,039 train 800 1.717576e-02 -1.215383
2019-11-07 15:23:53,910 train 850 1.715934e-02 -1.188931
2019-11-07 15:23:56,852 training loss; R2: 1.716491e-02 -1.176692
2019-11-07 15:23:57,472 valid 000 1.717960e-02 0.048399
2019-11-07 15:24:06,935 valid 050 1.678365e-02 -0.891676
2019-11-07 15:24:15,244 validation loss; R2: 1.673521e-02 -0.868266
2019-11-07 15:24:15,308 epoch 564 lr 1.000000e-05
2019-11-07 15:24:16,048 train 000 1.465008e-02 -0.207391
2019-11-07 15:24:25,801 train 050 1.770359e-02 -0.688560
2019-11-07 15:24:35,578 train 100 1.759723e-02 -0.656865
2019-11-07 15:24:45,371 train 150 1.730796e-02 -0.601725
2019-11-07 15:24:55,154 train 200 1.729516e-02 -0.582059
2019-11-07 15:25:04,949 train 250 1.727050e-02 -0.602224
2019-11-07 15:25:14,731 train 300 1.728825e-02 -0.633332
2019-11-07 15:25:24,548 train 350 1.723122e-02 -0.692020
2019-11-07 15:25:34,377 train 400 1.722936e-02 -0.746549
2019-11-07 15:25:44,198 train 450 1.726317e-02 -0.746726
2019-11-07 15:25:54,032 train 500 1.725023e-02 -0.744420
2019-11-07 15:26:03,873 train 550 1.722573e-02 -0.728593
2019-11-07 15:26:13,724 train 600 1.720437e-02 -0.734963
2019-11-07 15:26:23,579 train 650 1.720353e-02 -0.800287
2019-11-07 15:26:33,425 train 700 1.720033e-02 -0.804672
2019-11-07 15:26:43,290 train 750 1.717216e-02 -0.804788
2019-11-07 15:26:53,148 train 800 1.716309e-02 -0.782157
2019-11-07 15:27:03,011 train 850 1.715711e-02 -0.784785
2019-11-07 15:27:05,952 training loss; R2: 1.715729e-02 -0.786415
2019-11-07 15:27:06,620 valid 000 1.869280e-02 -1.074687
2019-11-07 15:27:16,039 valid 050 1.676155e-02 -1.265571
2019-11-07 15:27:24,377 validation loss; R2: 1.666517e-02 -1.141578
2019-11-07 15:27:24,443 epoch 565 lr 1.000000e-05
2019-11-07 15:27:25,218 train 000 1.657529e-02 -0.964085
2019-11-07 15:27:34,960 train 050 1.714435e-02 -0.644577
2019-11-07 15:27:44,715 train 100 1.701874e-02 -0.618116
2019-11-07 15:27:54,485 train 150 1.690409e-02 -0.718515
2019-11-07 15:28:04,268 train 200 1.701274e-02 -0.743374
2019-11-07 15:28:14,043 train 250 1.708100e-02 -0.754064
2019-11-07 15:28:23,829 train 300 1.708501e-02 -0.730337
2019-11-07 15:28:33,644 train 350 1.707945e-02 -0.742945
2019-11-07 15:28:43,452 train 400 1.703266e-02 -0.755610
2019-11-07 15:28:53,266 train 450 1.705861e-02 -0.741132
2019-11-07 15:29:03,102 train 500 1.711680e-02 -0.765509
2019-11-07 15:29:12,956 train 550 1.707956e-02 -0.754698
2019-11-07 15:29:22,811 train 600 1.708360e-02 -0.740032
2019-11-07 15:29:32,668 train 650 1.710596e-02 -0.732687
2019-11-07 15:29:42,519 train 700 1.712733e-02 -0.727348
2019-11-07 15:29:52,388 train 750 1.712812e-02 -0.732539
2019-11-07 15:30:02,247 train 800 1.711657e-02 -1.232845
2019-11-07 15:30:12,111 train 850 1.712548e-02 -1.213242
2019-11-07 15:30:15,065 training loss; R2: 1.712817e-02 -1.206399
2019-11-07 15:30:15,724 valid 000 1.964713e-02 -1.901307
2019-11-07 15:30:25,125 valid 050 1.907272e-02 -1.250735
2019-11-07 15:30:33,464 validation loss; R2: 1.900394e-02 -1.942049
2019-11-07 15:30:33,529 epoch 566 lr 1.000000e-05
2019-11-07 15:30:34,271 train 000 1.750872e-02 -0.113877
2019-11-07 15:30:44,034 train 050 1.714307e-02 -0.565607
2019-11-07 15:30:53,794 train 100 1.701247e-02 -0.625408
2019-11-07 15:31:03,583 train 150 1.708038e-02 -0.641148
2019-11-07 15:31:13,371 train 200 1.707117e-02 -0.668194
2019-11-07 15:31:23,160 train 250 1.701825e-02 -0.664287
2019-11-07 15:31:32,949 train 300 1.699159e-02 -0.678526
2019-11-07 15:31:42,756 train 350 1.696893e-02 -0.707997
2019-11-07 15:31:52,582 train 400 1.699891e-02 -0.742305
2019-11-07 15:32:02,420 train 450 1.702052e-02 -0.758133
2019-11-07 15:32:12,279 train 500 1.704647e-02 -0.741024
2019-11-07 15:32:22,130 train 550 1.706107e-02 -0.732471
2019-11-07 15:32:31,969 train 600 1.706845e-02 -0.767761
2019-11-07 15:32:41,820 train 650 1.706148e-02 -0.765693
2019-11-07 15:32:51,664 train 700 1.704494e-02 -0.759129
2019-11-07 15:33:01,518 train 750 1.704232e-02 -0.764507
2019-11-07 15:33:11,402 train 800 1.704476e-02 -0.745643
2019-11-07 15:33:21,275 train 850 1.705236e-02 -0.738583
2019-11-07 15:33:24,224 training loss; R2: 1.707453e-02 -0.734910
2019-11-07 15:33:24,861 valid 000 1.628387e-02 -0.259721
2019-11-07 15:33:34,292 valid 050 1.665292e-02 -1.219314
2019-11-07 15:33:42,605 validation loss; R2: 1.668811e-02 -1.101592
2019-11-07 15:33:42,672 epoch 567 lr 1.000000e-05
2019-11-07 15:33:43,447 train 000 1.402701e-02 -0.624450
2019-11-07 15:33:53,195 train 050 1.709743e-02 -0.447192
2019-11-07 15:34:02,960 train 100 1.719529e-02 -0.651230
2019-11-07 15:34:12,743 train 150 1.708446e-02 -0.804867
2019-11-07 15:34:22,535 train 200 1.713489e-02 -1.124657
2019-11-07 15:34:32,325 train 250 1.714748e-02 -1.046582
2019-11-07 15:34:42,111 train 300 1.718015e-02 -1.017952
2019-11-07 15:34:51,908 train 350 1.714085e-02 -0.970683
2019-11-07 15:35:01,715 train 400 1.708915e-02 -0.920916
2019-11-07 15:35:11,529 train 450 1.705912e-02 -0.918939
2019-11-07 15:35:21,361 train 500 1.705524e-02 -0.880283
2019-11-07 15:35:31,207 train 550 1.711106e-02 -0.856988
2019-11-07 15:35:41,043 train 600 1.711893e-02 -0.846782
2019-11-07 15:35:50,886 train 650 1.710279e-02 -0.823077
2019-11-07 15:36:00,716 train 700 1.708882e-02 -0.872210
2019-11-07 15:36:10,569 train 750 1.706787e-02 -0.901113
2019-11-07 15:36:20,404 train 800 1.705872e-02 -0.889314
2019-11-07 15:36:30,247 train 850 1.705391e-02 -0.909425
2019-11-07 15:36:33,208 training loss; R2: 1.704531e-02 -0.903446
2019-11-07 15:36:33,787 valid 000 2.101187e-02 -1.771925
2019-11-07 15:36:43,260 valid 050 1.841722e-02 -1.727746
2019-11-07 15:36:51,624 validation loss; R2: 1.801731e-02 -1.394924
2019-11-07 15:36:51,691 epoch 568 lr 1.000000e-05
2019-11-07 15:36:52,472 train 000 1.578725e-02 -2.288019
2019-11-07 15:37:02,237 train 050 1.709212e-02 -5.366757
2019-11-07 15:37:12,014 train 100 1.699532e-02 -3.106556
2019-11-07 15:37:21,804 train 150 1.704064e-02 -2.261342
2019-11-07 15:37:31,589 train 200 1.708722e-02 -1.876322
2019-11-07 15:37:41,383 train 250 1.708216e-02 -1.619784
2019-11-07 15:37:51,182 train 300 1.707182e-02 -1.468726
2019-11-07 15:38:01,000 train 350 1.709161e-02 -1.357808
2019-11-07 15:38:10,836 train 400 1.709001e-02 -1.292237
2019-11-07 15:38:20,676 train 450 1.710357e-02 -1.241965
2019-11-07 15:38:30,527 train 500 1.710155e-02 -1.195992
2019-11-07 15:38:40,376 train 550 1.711257e-02 -1.130003
2019-11-07 15:38:50,227 train 600 1.712734e-02 -1.088825
2019-11-07 15:39:00,092 train 650 1.711589e-02 -1.075892
2019-11-07 15:39:09,957 train 700 1.710641e-02 -1.050852
2019-11-07 15:39:19,824 train 750 1.710315e-02 -1.017144
2019-11-07 15:39:29,689 train 800 1.708488e-02 -0.996253
2019-11-07 15:39:39,563 train 850 1.707283e-02 -0.972894
2019-11-07 15:39:42,520 training loss; R2: 1.707274e-02 -0.969619
2019-11-07 15:39:43,220 valid 000 1.986526e-02 -0.493589
2019-11-07 15:39:52,610 valid 050 1.630001e-02 -1.311951
2019-11-07 15:40:00,945 validation loss; R2: 1.630350e-02 -1.306168
2019-11-07 15:40:01,016 epoch 569 lr 1.000000e-05
2019-11-07 15:40:01,817 train 000 2.134330e-02 -0.747016
2019-11-07 15:40:11,977 train 050 1.701963e-02 -0.543205
2019-11-07 15:40:22,176 train 100 1.692652e-02 -0.760904
2019-11-07 15:40:32,356 train 150 1.704787e-02 -0.775999
2019-11-07 15:40:42,540 train 200 1.711131e-02 -0.733374
2019-11-07 15:40:52,729 train 250 1.710923e-02 -0.734621
2019-11-07 15:41:02,915 train 300 1.711900e-02 -0.723260
2019-11-07 15:41:13,104 train 350 1.711399e-02 -0.732419
2019-11-07 15:41:23,302 train 400 1.710751e-02 -0.786576
2019-11-07 15:41:33,506 train 450 1.709526e-02 -0.769342
2019-11-07 15:41:43,577 train 500 1.708374e-02 -0.758729
2019-11-07 15:41:53,477 train 550 1.703791e-02 -0.753087
2019-11-07 15:42:03,355 train 600 1.705089e-02 -0.766697
2019-11-07 15:42:13,233 train 650 1.705991e-02 -0.773765
2019-11-07 15:42:23,143 train 700 1.705035e-02 -0.774782
2019-11-07 15:42:33,051 train 750 1.707640e-02 -0.758269
2019-11-07 15:42:42,949 train 800 1.707441e-02 -0.797849
2019-11-07 15:42:52,842 train 850 1.708750e-02 -0.799000
2019-11-07 15:42:55,849 training loss; R2: 1.709405e-02 -0.796098
2019-11-07 15:42:56,509 valid 000 1.879765e-02 -0.143689
2019-11-07 15:43:05,898 valid 050 1.735244e-02 -1.132823
2019-11-07 15:43:14,245 validation loss; R2: 1.755787e-02 -1.142232
2019-11-07 15:43:14,313 epoch 570 lr 1.000000e-05
2019-11-07 15:43:15,095 train 000 2.054944e-02 -0.077320
2019-11-07 15:43:25,217 train 050 1.697642e-02 -0.588067
2019-11-07 15:43:35,377 train 100 1.718071e-02 -0.674863
2019-11-07 15:43:45,528 train 150 1.724453e-02 -0.745983
2019-11-07 15:43:55,700 train 200 1.721498e-02 -0.689775
2019-11-07 15:44:05,864 train 250 1.719284e-02 -0.721115
2019-11-07 15:44:16,009 train 300 1.716762e-02 -0.688602
2019-11-07 15:44:26,181 train 350 1.716576e-02 -0.713042
2019-11-07 15:44:36,385 train 400 1.709247e-02 -0.688963
2019-11-07 15:44:46,562 train 450 1.712743e-02 -0.708956
2019-11-07 15:44:56,753 train 500 1.715006e-02 -0.726586
2019-11-07 15:45:06,937 train 550 1.713176e-02 -0.724416
2019-11-07 15:45:17,119 train 600 1.713073e-02 -0.724148
2019-11-07 15:45:27,324 train 650 1.711170e-02 -0.720048
2019-11-07 15:45:37,521 train 700 1.710364e-02 -0.729950
2019-11-07 15:45:47,605 train 750 1.712544e-02 -0.729096
2019-11-07 15:45:57,471 train 800 1.710739e-02 -0.724200
2019-11-07 15:46:07,321 train 850 1.708259e-02 -0.729786
2019-11-07 15:46:10,279 training loss; R2: 1.707637e-02 -0.723220
2019-11-07 15:46:10,912 valid 000 1.633461e-02 -1.858925
2019-11-07 15:46:20,408 valid 050 1.694651e-02 -1.200886
2019-11-07 15:46:28,747 validation loss; R2: 1.690170e-02 -1.464539
2019-11-07 15:46:28,813 epoch 571 lr 1.000000e-05
2019-11-07 15:46:29,551 train 000 1.962203e-02 -0.472709
2019-11-07 15:46:39,322 train 050 1.720059e-02 -0.609255
2019-11-07 15:46:49,107 train 100 1.717411e-02 -0.654511
2019-11-07 15:46:58,903 train 150 1.717750e-02 -0.708825
2019-11-07 15:47:08,698 train 200 1.708896e-02 -0.678998
2019-11-07 15:47:18,485 train 250 1.705970e-02 -0.662507
2019-11-07 15:47:28,294 train 300 1.701569e-02 -78.625689
2019-11-07 15:47:38,113 train 350 1.700652e-02 -67.576691
2019-11-07 15:47:47,935 train 400 1.698418e-02 -59.239618
2019-11-07 15:47:57,782 train 450 1.698313e-02 -52.736978
2019-11-07 15:48:07,608 train 500 1.697116e-02 -47.702207
2019-11-07 15:48:17,450 train 550 1.698509e-02 -43.431900
2019-11-07 15:48:27,295 train 600 1.695937e-02 -39.885326
2019-11-07 15:48:37,139 train 650 1.694624e-02 -36.876708
2019-11-07 15:48:46,979 train 700 1.693431e-02 -34.291872
2019-11-07 15:48:56,832 train 750 1.695091e-02 -32.043937
2019-11-07 15:49:06,680 train 800 1.698330e-02 -30.073376
2019-11-07 15:49:16,543 train 850 1.701608e-02 -28.345395
2019-11-07 15:49:19,485 training loss; R2: 1.700904e-02 -27.864077
2019-11-07 15:49:20,188 valid 000 1.678696e-02 -1.871375
2019-11-07 15:49:29,548 valid 050 1.632539e-02 -1.037710
2019-11-07 15:49:37,877 validation loss; R2: 1.630975e-02 -1.079848
2019-11-07 15:49:37,944 epoch 572 lr 1.000000e-05
2019-11-07 15:49:38,713 train 000 1.541674e-02 -0.353883
2019-11-07 15:49:48,479 train 050 1.720561e-02 -0.526978
2019-11-07 15:49:58,245 train 100 1.706997e-02 -0.722490
2019-11-07 15:50:08,048 train 150 1.721827e-02 -0.900255
2019-11-07 15:50:17,839 train 200 1.715160e-02 -0.817227
2019-11-07 15:50:27,635 train 250 1.713327e-02 -0.832496
2019-11-07 15:50:37,467 train 300 1.709501e-02 -0.816639
2019-11-07 15:50:47,290 train 350 1.711936e-02 -0.815046
2019-11-07 15:50:57,117 train 400 1.711147e-02 -0.800075
2019-11-07 15:51:06,953 train 450 1.712160e-02 -0.814879
2019-11-07 15:51:16,802 train 500 1.714533e-02 -0.817780
2019-11-07 15:51:26,662 train 550 1.712957e-02 -0.816241
2019-11-07 15:51:36,553 train 600 1.711578e-02 -0.802071
2019-11-07 15:51:46,416 train 650 1.711721e-02 -0.782312
2019-11-07 15:51:56,290 train 700 1.713115e-02 -0.758775
2019-11-07 15:52:06,153 train 750 1.711760e-02 -0.761720
2019-11-07 15:52:16,028 train 800 1.711591e-02 -0.752836
2019-11-07 15:52:25,906 train 850 1.714943e-02 -0.741629
2019-11-07 15:52:28,848 training loss; R2: 1.715537e-02 -0.750045
2019-11-07 15:52:29,515 valid 000 1.967761e-02 -0.016112
2019-11-07 15:52:38,981 valid 050 1.691782e-02 -0.983305
2019-11-07 15:52:47,332 validation loss; R2: 1.699289e-02 -2.223243
2019-11-07 15:52:47,399 epoch 573 lr 1.000000e-05
2019-11-07 15:52:48,177 train 000 1.534479e-02 -0.542566
2019-11-07 15:52:57,933 train 050 1.637702e-02 -1.057327
2019-11-07 15:53:07,702 train 100 1.675254e-02 -0.960756
2019-11-07 15:53:17,480 train 150 1.686175e-02 -0.801262
2019-11-07 15:53:27,267 train 200 1.692853e-02 -0.791481
2019-11-07 15:53:37,084 train 250 1.693865e-02 -0.788767
2019-11-07 15:53:46,887 train 300 1.698543e-02 -0.747918
2019-11-07 15:53:56,698 train 350 1.691467e-02 -1.176924
2019-11-07 15:54:06,518 train 400 1.690252e-02 -1.163596
2019-11-07 15:54:16,322 train 450 1.692019e-02 -1.105070
2019-11-07 15:54:26,134 train 500 1.696876e-02 -1.085810
2019-11-07 15:54:35,967 train 550 1.696226e-02 -1.045501
2019-11-07 15:54:45,795 train 600 1.697698e-02 -1.038649
2019-11-07 15:54:55,631 train 650 1.700432e-02 -1.014059
2019-11-07 15:55:05,481 train 700 1.700891e-02 -0.986380
2019-11-07 15:55:15,319 train 750 1.702397e-02 -0.967863
2019-11-07 15:55:25,173 train 800 1.706670e-02 -0.938392
2019-11-07 15:55:35,015 train 850 1.707452e-02 -0.923034
2019-11-07 15:55:37,958 training loss; R2: 1.707138e-02 -0.918968
2019-11-07 15:55:38,626 valid 000 1.615581e-02 -0.200459
2019-11-07 15:55:48,008 valid 050 1.661948e-02 -1.467520
2019-11-07 15:55:56,318 validation loss; R2: 1.656054e-02 -1.292789
2019-11-07 15:55:56,391 epoch 574 lr 1.000000e-05
2019-11-07 15:55:57,125 train 000 1.850015e-02 0.046321
2019-11-07 15:56:06,884 train 050 1.748752e-02 -0.793227
2019-11-07 15:56:16,644 train 100 1.731811e-02 -1.115883
2019-11-07 15:56:26,417 train 150 1.720347e-02 -1.112522
2019-11-07 15:56:36,209 train 200 1.702795e-02 -1.032146
2019-11-07 15:56:45,994 train 250 1.698664e-02 -0.922174
2019-11-07 15:56:55,800 train 300 1.700088e-02 -0.981872
2019-11-07 15:57:05,611 train 350 1.703645e-02 -1.070725
2019-11-07 15:57:15,415 train 400 1.705151e-02 -1.016686
2019-11-07 15:57:25,239 train 450 1.703513e-02 -0.983039
2019-11-07 15:57:35,076 train 500 1.702699e-02 -0.991100
2019-11-07 15:57:44,899 train 550 1.706894e-02 -0.966193
2019-11-07 15:57:54,732 train 600 1.706966e-02 -0.970078
2019-11-07 15:58:04,560 train 650 1.706461e-02 -0.946876
2019-11-07 15:58:14,418 train 700 1.708533e-02 -0.919729
2019-11-07 15:58:24,251 train 750 1.713175e-02 -0.903030
2019-11-07 15:58:34,105 train 800 1.713580e-02 -0.889391
2019-11-07 15:58:43,939 train 850 1.710864e-02 -0.867404
2019-11-07 15:58:46,884 training loss; R2: 1.710063e-02 -0.862734
2019-11-07 15:58:47,506 valid 000 1.507525e-02 -0.434347
2019-11-07 15:58:56,928 valid 050 1.619006e-02 -1.034108
2019-11-07 15:59:05,252 validation loss; R2: 1.644397e-02 -1.044604
2019-11-07 15:59:05,319 epoch 575 lr 1.000000e-05
2019-11-07 15:59:06,047 train 000 1.583637e-02 -0.949228
2019-11-07 15:59:15,817 train 050 1.705593e-02 -0.796892
2019-11-07 15:59:25,586 train 100 1.694213e-02 -0.705610
2019-11-07 15:59:35,374 train 150 1.695645e-02 -0.842516
2019-11-07 15:59:45,167 train 200 1.698486e-02 -0.867046
2019-11-07 15:59:54,962 train 250 1.685101e-02 -0.874855
2019-11-07 16:00:04,770 train 300 1.684013e-02 -0.887122
2019-11-07 16:00:14,577 train 350 1.685128e-02 -0.899266
2019-11-07 16:00:24,396 train 400 1.692476e-02 -0.863972
2019-11-07 16:00:34,204 train 450 1.697287e-02 -0.823489
2019-11-07 16:00:44,025 train 500 1.702713e-02 -0.836271
2019-11-07 16:00:53,846 train 550 1.701754e-02 -0.818485
2019-11-07 16:01:03,690 train 600 1.700543e-02 -0.802118
2019-11-07 16:01:13,534 train 650 1.704052e-02 -0.805162
2019-11-07 16:01:23,380 train 700 1.703029e-02 -0.785509
2019-11-07 16:01:33,227 train 750 1.704881e-02 -0.797526
2019-11-07 16:01:43,069 train 800 1.708559e-02 -0.791337
2019-11-07 16:01:52,925 train 850 1.707925e-02 -0.776522
2019-11-07 16:01:55,864 training loss; R2: 1.707988e-02 -0.769291
2019-11-07 16:01:56,578 valid 000 1.936861e-02 -0.933485
2019-11-07 16:02:06,002 valid 050 1.661136e-02 -1.675493
2019-11-07 16:02:14,401 validation loss; R2: 1.661897e-02 -1.336256
2019-11-07 16:02:14,470 epoch 576 lr 1.000000e-05
2019-11-07 16:02:15,270 train 000 1.594081e-02 0.000369
2019-11-07 16:02:25,020 train 050 1.709794e-02 -17.153254
2019-11-07 16:02:34,806 train 100 1.699896e-02 -9.091353
2019-11-07 16:02:44,591 train 150 1.695901e-02 -6.332193
2019-11-07 16:02:54,383 train 200 1.702848e-02 -4.976927
2019-11-07 16:03:04,189 train 250 1.705058e-02 -4.193986
2019-11-07 16:03:13,997 train 300 1.700950e-02 -3.579066
2019-11-07 16:03:23,801 train 350 1.700911e-02 -3.147486
2019-11-07 16:03:33,622 train 400 1.705253e-02 -2.849340
2019-11-07 16:03:43,455 train 450 1.701347e-02 -2.614286
2019-11-07 16:03:53,279 train 500 1.705621e-02 -2.423883
2019-11-07 16:04:03,119 train 550 1.707101e-02 -2.278499
2019-11-07 16:04:12,952 train 600 1.706719e-02 -2.136452
2019-11-07 16:04:22,797 train 650 1.706336e-02 -2.039463
2019-11-07 16:04:32,646 train 700 1.706387e-02 -1.948010
2019-11-07 16:04:42,493 train 750 1.707794e-02 -1.877402
2019-11-07 16:04:52,343 train 800 1.709455e-02 -1.865717
2019-11-07 16:05:02,199 train 850 1.707643e-02 -1.790786
2019-11-07 16:05:05,162 training loss; R2: 1.707050e-02 -1.774447
2019-11-07 16:05:05,807 valid 000 1.606577e-02 -0.770854
2019-11-07 16:05:15,243 valid 050 1.760504e-02 -1.611595
2019-11-07 16:05:23,558 validation loss; R2: 1.736996e-02 -1.408625
2019-11-07 16:05:23,632 epoch 577 lr 1.000000e-05
2019-11-07 16:05:24,373 train 000 1.591937e-02 -1.304015
2019-11-07 16:05:34,162 train 050 1.716293e-02 -0.753609
2019-11-07 16:05:43,928 train 100 1.731993e-02 -0.916106
2019-11-07 16:05:53,713 train 150 1.711602e-02 -34.353141
2019-11-07 16:06:03,505 train 200 1.718786e-02 -25.974809
2019-11-07 16:06:13,287 train 250 1.721122e-02 -20.937586
2019-11-07 16:06:23,077 train 300 1.718137e-02 -17.561194
2019-11-07 16:06:32,881 train 350 1.715037e-02 -15.141193
2019-11-07 16:06:42,690 train 400 1.716433e-02 -13.358235
2019-11-07 16:06:52,509 train 450 1.713385e-02 -11.944318
2019-11-07 16:07:02,311 train 500 1.712590e-02 -10.801884
2019-11-07 16:07:12,123 train 550 1.711792e-02 -9.890258
2019-11-07 16:07:21,957 train 600 1.712798e-02 -9.126233
2019-11-07 16:07:31,788 train 650 1.711517e-02 -8.481892
2019-11-07 16:07:41,622 train 700 1.712385e-02 -7.951408
2019-11-07 16:07:51,463 train 750 1.710476e-02 -7.462495
2019-11-07 16:08:01,303 train 800 1.709569e-02 -7.054636
2019-11-07 16:08:11,174 train 850 1.708323e-02 -6.674424
2019-11-07 16:08:14,122 training loss; R2: 1.707872e-02 -6.582267
2019-11-07 16:08:14,751 valid 000 1.537461e-02 -0.038625
2019-11-07 16:08:24,153 valid 050 1.664103e-02 -1.066830
2019-11-07 16:08:32,464 validation loss; R2: 1.658647e-02 -1.325025
2019-11-07 16:08:32,523 epoch 578 lr 1.000000e-05
2019-11-07 16:08:33,300 train 000 2.239594e-02 0.008768
2019-11-07 16:08:43,047 train 050 1.714108e-02 -0.785346
2019-11-07 16:08:52,831 train 100 1.705745e-02 -0.860051
2019-11-07 16:09:02,612 train 150 1.711391e-02 -0.991435
2019-11-07 16:09:12,410 train 200 1.707609e-02 -0.905826
2019-11-07 16:09:22,214 train 250 1.713817e-02 -0.812330
2019-11-07 16:09:32,009 train 300 1.708188e-02 -0.810617
2019-11-07 16:09:41,829 train 350 1.700483e-02 -0.768057
2019-11-07 16:09:51,656 train 400 1.703180e-02 -0.749886
2019-11-07 16:10:01,491 train 450 1.704409e-02 -0.743738
2019-11-07 16:10:11,315 train 500 1.706409e-02 -0.780263
2019-11-07 16:10:21,163 train 550 1.706895e-02 -0.782351
2019-11-07 16:10:31,001 train 600 1.707486e-02 -0.770007
2019-11-07 16:10:40,840 train 650 1.705573e-02 -0.762179
2019-11-07 16:10:50,708 train 700 1.705421e-02 -0.753514
2019-11-07 16:11:00,578 train 750 1.705954e-02 -0.754352
2019-11-07 16:11:10,455 train 800 1.706618e-02 -0.759772
2019-11-07 16:11:20,314 train 850 1.708206e-02 -0.793439
2019-11-07 16:11:23,265 training loss; R2: 1.708255e-02 -0.804699
2019-11-07 16:11:23,888 valid 000 1.988487e-02 -1.163783
2019-11-07 16:11:33,327 valid 050 1.635185e-02 -2.007323
2019-11-07 16:11:41,670 validation loss; R2: 1.646593e-02 -1.516807
2019-11-07 16:11:41,735 epoch 579 lr 1.000000e-05
2019-11-07 16:11:42,443 train 000 1.754849e-02 -0.006639
2019-11-07 16:11:52,193 train 050 1.707988e-02 -0.811884
2019-11-07 16:12:01,981 train 100 1.721727e-02 -0.648144
2019-11-07 16:12:11,768 train 150 1.710963e-02 -0.652622
2019-11-07 16:12:21,556 train 200 1.705181e-02 -0.661946
2019-11-07 16:12:31,361 train 250 1.701330e-02 -58.545623
2019-11-07 16:12:41,166 train 300 1.706474e-02 -48.919250
2019-11-07 16:12:50,970 train 350 1.706586e-02 -42.070078
2019-11-07 16:13:00,775 train 400 1.706164e-02 -36.910195
2019-11-07 16:13:10,586 train 450 1.705872e-02 -32.905596
2019-11-07 16:13:20,404 train 500 1.702149e-02 -29.675965
2019-11-07 16:13:30,220 train 550 1.699439e-02 -27.058953
2019-11-07 16:13:40,046 train 600 1.698937e-02 -24.878217
2019-11-07 16:13:49,876 train 650 1.698783e-02 -23.007072
2019-11-07 16:13:59,701 train 700 1.697924e-02 -21.419411
2019-11-07 16:14:09,528 train 750 1.698421e-02 -20.033849
2019-11-07 16:14:19,358 train 800 1.697726e-02 -18.846188
2019-11-07 16:14:29,199 train 850 1.699001e-02 -17.777071
2019-11-07 16:14:32,153 training loss; R2: 1.699134e-02 -17.478246
2019-11-07 16:14:32,843 valid 000 1.436878e-02 -0.422771
2019-11-07 16:14:42,269 valid 050 1.615060e-02 -1.280710
2019-11-07 16:14:50,611 validation loss; R2: 1.619114e-02 -1.244026
2019-11-07 16:14:50,685 epoch 580 lr 1.000000e-05
2019-11-07 16:14:51,467 train 000 1.582065e-02 -0.144478
2019-11-07 16:15:01,283 train 050 1.697504e-02 -5.387523
2019-11-07 16:15:11,089 train 100 1.680169e-02 -3.071256
2019-11-07 16:15:20,907 train 150 1.700544e-02 -2.288364
2019-11-07 16:15:30,731 train 200 1.697879e-02 -1.922664
2019-11-07 16:15:40,557 train 250 1.697239e-02 -1.678696
2019-11-07 16:15:50,365 train 300 1.704174e-02 -1.509280
2019-11-07 16:16:00,199 train 350 1.705168e-02 -1.399633
2019-11-07 16:16:10,031 train 400 1.705401e-02 -1.289691
2019-11-07 16:16:19,876 train 450 1.704370e-02 -1.206430
2019-11-07 16:16:29,715 train 500 1.703158e-02 -1.209749
2019-11-07 16:16:39,563 train 550 1.702066e-02 -1.158090
2019-11-07 16:16:49,444 train 600 1.704656e-02 -1.202095
2019-11-07 16:16:59,318 train 650 1.705414e-02 -1.262169
2019-11-07 16:17:09,195 train 700 1.706936e-02 -1.204532
2019-11-07 16:17:19,075 train 750 1.707280e-02 -1.170736
2019-11-07 16:17:28,960 train 800 1.702150e-02 -1.159485
2019-11-07 16:17:38,834 train 850 1.701738e-02 -1.138095
2019-11-07 16:17:41,789 training loss; R2: 1.700844e-02 -1.133013
2019-11-07 16:17:42,488 valid 000 1.514328e-02 -0.974614
2019-11-07 16:17:51,896 valid 050 1.581883e-02 -1.106903
2019-11-07 16:18:00,204 validation loss; R2: 1.566231e-02 -1.249612
2019-11-07 16:18:00,264 epoch 581 lr 1.000000e-05
2019-11-07 16:18:01,040 train 000 1.886260e-02 0.031021
2019-11-07 16:18:10,801 train 050 1.733391e-02 -1.077713
2019-11-07 16:18:20,577 train 100 1.715629e-02 -0.901347
2019-11-07 16:18:30,373 train 150 1.718569e-02 -0.823128
2019-11-07 16:18:40,166 train 200 1.720854e-02 -0.860668
2019-11-07 16:18:49,966 train 250 1.719996e-02 -0.815714
2019-11-07 16:18:59,760 train 300 1.720788e-02 -0.778370
2019-11-07 16:19:09,565 train 350 1.719665e-02 -0.742292
2019-11-07 16:19:19,371 train 400 1.718946e-02 -0.748032
2019-11-07 16:19:29,181 train 450 1.714088e-02 -0.721150
2019-11-07 16:19:38,995 train 500 1.712337e-02 -0.705453
2019-11-07 16:19:48,813 train 550 1.709547e-02 -0.712941
2019-11-07 16:19:58,639 train 600 1.706160e-02 -2.191607
2019-11-07 16:20:08,475 train 650 1.706976e-02 -2.165603
2019-11-07 16:20:18,318 train 700 1.704623e-02 -2.091828
2019-11-07 16:20:28,157 train 750 1.705545e-02 -2.003556
2019-11-07 16:20:37,991 train 800 1.705413e-02 -1.917692
2019-11-07 16:20:47,839 train 850 1.705889e-02 -1.890415
2019-11-07 16:20:50,784 training loss; R2: 1.706534e-02 -1.865929
2019-11-07 16:20:51,414 valid 000 1.586131e-02 -0.134918
2019-11-07 16:21:00,859 valid 050 1.591359e-02 -0.817326
2019-11-07 16:21:09,267 validation loss; R2: 1.579857e-02 -0.902550
2019-11-07 16:21:09,332 epoch 582 lr 1.000000e-05
2019-11-07 16:21:10,068 train 000 1.530363e-02 -0.107790
2019-11-07 16:21:19,822 train 050 1.705414e-02 -0.905053
2019-11-07 16:21:29,560 train 100 1.705843e-02 -0.758646
2019-11-07 16:21:39,337 train 150 1.709009e-02 -0.755924
2019-11-07 16:21:49,124 train 200 1.704279e-02 -0.677130
2019-11-07 16:21:58,915 train 250 1.706436e-02 -0.792722
2019-11-07 16:22:08,709 train 300 1.704847e-02 -0.816094
2019-11-07 16:22:18,516 train 350 1.698992e-02 -0.802973
2019-11-07 16:22:28,324 train 400 1.693569e-02 -0.824697
2019-11-07 16:22:38,146 train 450 1.701634e-02 -0.922719
2019-11-07 16:22:47,964 train 500 1.702958e-02 -0.901544
2019-11-07 16:22:57,779 train 550 1.700947e-02 -0.875124
2019-11-07 16:23:07,604 train 600 1.698925e-02 -0.858451
2019-11-07 16:23:17,432 train 650 1.700914e-02 -0.835860
2019-11-07 16:23:27,263 train 700 1.703257e-02 -0.829832
2019-11-07 16:23:37,103 train 750 1.703666e-02 -0.813052
2019-11-07 16:23:46,943 train 800 1.703131e-02 -0.799060
2019-11-07 16:23:56,804 train 850 1.702300e-02 -0.791002
2019-11-07 16:23:59,750 training loss; R2: 1.704059e-02 -0.787005
2019-11-07 16:24:00,457 valid 000 1.577791e-02 -0.679415
2019-11-07 16:24:09,827 valid 050 1.790391e-02 -2.232814
2019-11-07 16:24:18,212 validation loss; R2: 1.790668e-02 -2.091230
2019-11-07 16:24:18,279 epoch 583 lr 1.000000e-05
2019-11-07 16:24:19,028 train 000 2.046736e-02 -0.007104
2019-11-07 16:24:28,768 train 050 1.711073e-02 -0.797958
2019-11-07 16:24:38,517 train 100 1.705388e-02 -0.726079
2019-11-07 16:24:48,278 train 150 1.688738e-02 -0.784237
2019-11-07 16:24:58,059 train 200 1.688962e-02 -0.789834
2019-11-07 16:25:07,835 train 250 1.688846e-02 -0.750464
2019-11-07 16:25:17,615 train 300 1.692477e-02 -0.780963
2019-11-07 16:25:27,420 train 350 1.696628e-02 -0.772486
2019-11-07 16:25:37,233 train 400 1.702107e-02 -0.799393
2019-11-07 16:25:47,029 train 450 1.699128e-02 -0.770849
2019-11-07 16:25:56,850 train 500 1.698339e-02 -0.764629
2019-11-07 16:26:06,659 train 550 1.697740e-02 -0.788345
2019-11-07 16:26:16,468 train 600 1.699325e-02 -0.820385
2019-11-07 16:26:26,279 train 650 1.701572e-02 -0.835404
2019-11-07 16:26:36,093 train 700 1.700110e-02 -0.820045
2019-11-07 16:26:45,924 train 750 1.699526e-02 -0.821399
2019-11-07 16:26:55,739 train 800 1.699619e-02 -0.804965
2019-11-07 16:27:05,571 train 850 1.701870e-02 -0.795372
2019-11-07 16:27:08,504 training loss; R2: 1.701223e-02 -0.791659
2019-11-07 16:27:09,175 valid 000 1.484848e-02 -0.566745
2019-11-07 16:27:18,503 valid 050 1.632108e-02 -1.242840
2019-11-07 16:27:26,937 validation loss; R2: 1.635436e-02 -1.126829
2019-11-07 16:27:26,999 epoch 584 lr 1.000000e-05
2019-11-07 16:27:27,746 train 000 1.399824e-02 -0.470848
2019-11-07 16:27:37,493 train 050 1.715774e-02 -0.714850
2019-11-07 16:27:47,228 train 100 1.701719e-02 -0.785806
2019-11-07 16:27:56,993 train 150 1.706273e-02 -0.707388
2019-11-07 16:28:06,769 train 200 1.726668e-02 -0.690569
2019-11-07 16:28:16,554 train 250 1.722297e-02 -0.684412
2019-11-07 16:28:26,333 train 300 1.709636e-02 -0.700277
2019-11-07 16:28:36,118 train 350 1.710019e-02 -0.705955
2019-11-07 16:28:45,918 train 400 1.704549e-02 -0.757185
2019-11-07 16:28:55,711 train 450 1.704252e-02 -0.746239
2019-11-07 16:29:05,518 train 500 1.702822e-02 -0.729274
2019-11-07 16:29:15,339 train 550 1.701318e-02 -0.726713
2019-11-07 16:29:25,150 train 600 1.703423e-02 -0.739191
2019-11-07 16:29:34,958 train 650 1.705316e-02 -0.741237
2019-11-07 16:29:44,785 train 700 1.704818e-02 -0.736730
2019-11-07 16:29:54,610 train 750 1.703647e-02 -0.730543
2019-11-07 16:30:04,442 train 800 1.705946e-02 -0.710035
2019-11-07 16:30:14,268 train 850 1.705779e-02 -0.720538
2019-11-07 16:30:17,203 training loss; R2: 1.707305e-02 -0.715795
2019-11-07 16:30:17,817 valid 000 1.514728e-02 -4.491380
2019-11-07 16:30:27,288 valid 050 1.600082e-02 -1.455877
2019-11-07 16:30:35,671 validation loss; R2: 1.608460e-02 -1.360518
2019-11-07 16:30:35,736 epoch 585 lr 1.000000e-05
2019-11-07 16:30:36,521 train 000 2.051190e-02 -0.572287
2019-11-07 16:30:46,270 train 050 1.699145e-02 -0.822902
2019-11-07 16:30:56,020 train 100 1.695877e-02 -0.884345
2019-11-07 16:31:05,814 train 150 1.718155e-02 -0.830369
2019-11-07 16:31:15,611 train 200 1.719733e-02 -0.816362
2019-11-07 16:31:25,406 train 250 1.716492e-02 -0.904761
2019-11-07 16:31:35,201 train 300 1.717848e-02 -0.865338
2019-11-07 16:31:44,994 train 350 1.718130e-02 -0.868730
2019-11-07 16:31:54,787 train 400 1.719468e-02 -0.836938
2019-11-07 16:32:04,587 train 450 1.716411e-02 -0.801235
2019-11-07 16:32:14,382 train 500 1.711058e-02 -0.768562
2019-11-07 16:32:24,191 train 550 1.709872e-02 -0.778530
2019-11-07 16:32:33,997 train 600 1.707025e-02 -0.805645
2019-11-07 16:32:43,811 train 650 1.706249e-02 -0.788214
2019-11-07 16:32:53,606 train 700 1.705212e-02 -0.782857
2019-11-07 16:33:03,408 train 750 1.708080e-02 -0.775544
2019-11-07 16:33:13,230 train 800 1.707255e-02 -0.771370
2019-11-07 16:33:23,038 train 850 1.706404e-02 -0.763475
2019-11-07 16:33:25,973 training loss; R2: 1.706423e-02 -0.763108
2019-11-07 16:33:26,632 valid 000 1.532909e-02 -10.234404
2019-11-07 16:33:36,030 valid 050 1.706163e-02 -1.275677
2019-11-07 16:33:44,344 validation loss; R2: 1.735185e-02 -2.176873
2019-11-07 16:33:44,410 epoch 586 lr 1.000000e-05
2019-11-07 16:33:45,187 train 000 1.681371e-02 0.058945
2019-11-07 16:33:54,944 train 050 1.686336e-02 -0.892689
2019-11-07 16:34:04,707 train 100 1.706568e-02 -0.774025
2019-11-07 16:34:14,470 train 150 1.712175e-02 -0.986395
2019-11-07 16:34:24,256 train 200 1.719147e-02 -0.923781
2019-11-07 16:34:34,033 train 250 1.722407e-02 -0.865699
2019-11-07 16:34:43,822 train 300 1.714845e-02 -0.852983
2019-11-07 16:34:53,603 train 350 1.711113e-02 -0.836931
2019-11-07 16:35:03,399 train 400 1.709515e-02 -0.816839
2019-11-07 16:35:13,210 train 450 1.710686e-02 -0.799034
2019-11-07 16:35:23,019 train 500 1.710150e-02 -0.794735
2019-11-07 16:35:32,826 train 550 1.707525e-02 -0.774008
2019-11-07 16:35:42,618 train 600 1.706879e-02 -0.745587
2019-11-07 16:35:52,406 train 650 1.707611e-02 -0.741557
2019-11-07 16:36:02,187 train 700 1.706365e-02 -0.732110
2019-11-07 16:36:11,975 train 750 1.705280e-02 -0.731030
2019-11-07 16:36:21,765 train 800 1.705875e-02 -0.729117
2019-11-07 16:36:31,557 train 850 1.707708e-02 -0.728815
2019-11-07 16:36:34,477 training loss; R2: 1.707836e-02 -0.729443
2019-11-07 16:36:35,077 valid 000 1.578859e-02 -1.024125
2019-11-07 16:36:44,540 valid 050 1.618350e-02 -1.043306
2019-11-07 16:36:52,889 validation loss; R2: 1.613846e-02 -1.243718
2019-11-07 16:36:52,956 epoch 587 lr 1.000000e-05
2019-11-07 16:36:53,719 train 000 1.699489e-02 -0.064599
2019-11-07 16:37:03,436 train 050 1.706503e-02 -0.914955
2019-11-07 16:37:13,170 train 100 1.707062e-02 -0.857315
2019-11-07 16:37:22,915 train 150 1.702298e-02 -0.840413
2019-11-07 16:37:32,664 train 200 1.708098e-02 -0.799765
2019-11-07 16:37:42,411 train 250 1.705302e-02 -0.813254
2019-11-07 16:37:52,162 train 300 1.706573e-02 -0.915077
2019-11-07 16:38:01,912 train 350 1.710624e-02 -0.848565
2019-11-07 16:38:11,661 train 400 1.715194e-02 -0.865137
2019-11-07 16:38:21,421 train 450 1.712282e-02 -0.841222
2019-11-07 16:38:31,183 train 500 1.713815e-02 -0.846414
2019-11-07 16:38:40,960 train 550 1.713216e-02 -0.851912
2019-11-07 16:38:50,726 train 600 1.714434e-02 -0.847986
2019-11-07 16:39:00,503 train 650 1.714305e-02 -0.833207
2019-11-07 16:39:10,279 train 700 1.716847e-02 -0.828658
2019-11-07 16:39:20,050 train 750 1.716674e-02 -0.814005
2019-11-07 16:39:29,822 train 800 1.716486e-02 -0.819709
2019-11-07 16:39:39,611 train 850 1.715261e-02 -0.814672
2019-11-07 16:39:42,531 training loss; R2: 1.714506e-02 -0.808822
2019-11-07 16:39:43,160 valid 000 1.309487e-02 -3.102251
2019-11-07 16:39:52,594 valid 050 1.685527e-02 -1.401388
2019-11-07 16:40:00,912 validation loss; R2: 1.689474e-02 -1.765819
2019-11-07 16:40:00,976 epoch 588 lr 1.000000e-05
2019-11-07 16:40:01,743 train 000 1.796227e-02 -2.558937
2019-11-07 16:40:11,465 train 050 1.741920e-02 -0.927608
2019-11-07 16:40:21,170 train 100 1.728737e-02 -0.784296
2019-11-07 16:40:30,910 train 150 1.723076e-02 -0.813215
2019-11-07 16:40:40,653 train 200 1.722250e-02 -0.827527
2019-11-07 16:40:50,404 train 250 1.716705e-02 -0.807367
2019-11-07 16:41:00,158 train 300 1.719254e-02 -0.751364
2019-11-07 16:41:09,910 train 350 1.713591e-02 -0.740909
2019-11-07 16:41:19,667 train 400 1.707465e-02 -0.767945
2019-11-07 16:41:29,439 train 450 1.706605e-02 -0.791832
2019-11-07 16:41:39,217 train 500 1.706214e-02 -0.918486
2019-11-07 16:41:48,995 train 550 1.706730e-02 -0.903693
2019-11-07 16:41:58,768 train 600 1.707366e-02 -5.133197
2019-11-07 16:42:08,554 train 650 1.703992e-02 -4.795220
2019-11-07 16:42:18,370 train 700 1.705404e-02 -4.498582
2019-11-07 16:42:28,173 train 750 1.706182e-02 -4.265159
2019-11-07 16:42:37,979 train 800 1.706456e-02 -4.047231
2019-11-07 16:42:47,786 train 850 1.708755e-02 -3.840132
2019-11-07 16:42:50,716 training loss; R2: 1.707806e-02 -3.786520
2019-11-07 16:42:51,362 valid 000 1.875458e-02 -0.063387
2019-11-07 16:43:00,802 valid 050 1.589704e-02 -1.186300
2019-11-07 16:43:09,150 validation loss; R2: 1.606101e-02 -1.094121
2019-11-07 16:43:09,237 epoch 589 lr 1.000000e-05
2019-11-07 16:43:10,033 train 000 1.475290e-02 -0.590025
2019-11-07 16:43:20,149 train 050 1.702135e-02 -0.781756
2019-11-07 16:43:30,289 train 100 1.676829e-02 -0.813654
2019-11-07 16:43:40,421 train 150 1.695658e-02 -0.799276
2019-11-07 16:43:50,568 train 200 1.696596e-02 -0.755479
2019-11-07 16:44:00,729 train 250 1.702276e-02 -0.741123
2019-11-07 16:44:10,888 train 300 1.709889e-02 -0.709312
2019-11-07 16:44:21,036 train 350 1.708035e-02 -0.668333
2019-11-07 16:44:31,180 train 400 1.707378e-02 -0.769819
2019-11-07 16:44:41,325 train 450 1.708036e-02 -0.771286
2019-11-07 16:44:51,484 train 500 1.710481e-02 -0.747377
2019-11-07 16:45:01,625 train 550 1.706145e-02 -0.791510
2019-11-07 16:45:11,793 train 600 1.708636e-02 -0.770867
2019-11-07 16:45:21,963 train 650 1.710692e-02 -0.777249
2019-11-07 16:45:32,120 train 700 1.711442e-02 -0.769250
2019-11-07 16:45:42,279 train 750 1.709950e-02 -0.757448
2019-11-07 16:45:52,447 train 800 1.710274e-02 -0.747378
2019-11-07 16:46:02,606 train 850 1.712957e-02 -0.744493
2019-11-07 16:46:05,653 training loss; R2: 1.712962e-02 -0.746529
2019-11-07 16:46:06,351 valid 000 1.441800e-02 -4.780372
2019-11-07 16:46:15,769 valid 050 1.690529e-02 -1.594800
2019-11-07 16:46:24,112 validation loss; R2: 1.686586e-02 -1.327681
2019-11-07 16:46:24,181 epoch 590 lr 1.000000e-05
2019-11-07 16:46:24,928 train 000 1.603672e-02 -1.052275
2019-11-07 16:46:34,793 train 050 1.699700e-02 -0.808422
2019-11-07 16:46:44,609 train 100 1.699552e-02 -0.945247
2019-11-07 16:46:54,406 train 150 1.702682e-02 -0.823548
2019-11-07 16:47:04,213 train 200 1.700109e-02 -0.826706
2019-11-07 16:47:14,017 train 250 1.699064e-02 -0.816602
2019-11-07 16:47:23,836 train 300 1.699169e-02 -0.801443
2019-11-07 16:47:33,666 train 350 1.702174e-02 -0.793006
2019-11-07 16:47:43,472 train 400 1.706961e-02 -0.804140
2019-11-07 16:47:53,283 train 450 1.709745e-02 -0.773239
2019-11-07 16:48:03,104 train 500 1.706353e-02 -0.763158
2019-11-07 16:48:12,919 train 550 1.703339e-02 -0.793380
2019-11-07 16:48:22,776 train 600 1.708469e-02 -0.793441
2019-11-07 16:48:32,631 train 650 1.708690e-02 -0.798632
2019-11-07 16:48:42,494 train 700 1.706229e-02 -0.785521
2019-11-07 16:48:52,360 train 750 1.706964e-02 -0.839490
2019-11-07 16:49:02,235 train 800 1.706246e-02 -0.823282
2019-11-07 16:49:12,111 train 850 1.707413e-02 -0.817095
2019-11-07 16:49:15,059 training loss; R2: 1.707728e-02 -0.813058
2019-11-07 16:49:15,679 valid 000 1.687221e-02 -1.140267
2019-11-07 16:49:25,145 valid 050 1.555299e-02 -0.808085
2019-11-07 16:49:33,468 validation loss; R2: 1.570311e-02 -0.954083
2019-11-07 16:49:33,536 epoch 591 lr 1.000000e-05
2019-11-07 16:49:34,309 train 000 1.663286e-02 -0.007370
2019-11-07 16:49:44,100 train 050 1.705275e-02 -0.750027
2019-11-07 16:49:53,933 train 100 1.704937e-02 -0.769992
2019-11-07 16:50:03,783 train 150 1.711355e-02 -0.731178
2019-11-07 16:50:13,638 train 200 1.709766e-02 -0.705379
2019-11-07 16:50:23,482 train 250 1.707780e-02 -0.690873
2019-11-07 16:50:33,325 train 300 1.708707e-02 -0.648369
2019-11-07 16:50:43,172 train 350 1.707751e-02 -0.653537
2019-11-07 16:50:53,023 train 400 1.702027e-02 -0.645587
2019-11-07 16:51:02,893 train 450 1.710380e-02 -0.663388
2019-11-07 16:51:12,774 train 500 1.703396e-02 -2.337466
2019-11-07 16:51:22,657 train 550 1.699049e-02 -2.180044
2019-11-07 16:51:32,536 train 600 1.699347e-02 -2.049775
2019-11-07 16:51:42,429 train 650 1.698735e-02 -1.958917
2019-11-07 16:51:52,311 train 700 1.696546e-02 -1.872188
2019-11-07 16:52:02,184 train 750 1.696183e-02 -1.843141
2019-11-07 16:52:12,065 train 800 1.696421e-02 -1.768830
2019-11-07 16:52:21,962 train 850 1.696538e-02 -1.703500
2019-11-07 16:52:24,915 training loss; R2: 1.696909e-02 -1.685411
2019-11-07 16:52:25,592 valid 000 1.595895e-02 -0.296613
2019-11-07 16:52:34,946 valid 050 1.702036e-02 -1.449609
2019-11-07 16:52:43,244 validation loss; R2: 1.681533e-02 -1.389444
2019-11-07 16:52:43,310 epoch 592 lr 1.000000e-05
2019-11-07 16:52:44,082 train 000 1.917175e-02 -0.818585
2019-11-07 16:52:53,859 train 050 1.725060e-02 -1.115420
2019-11-07 16:53:03,708 train 100 1.710553e-02 -3.275691
2019-11-07 16:53:13,577 train 150 1.712867e-02 -2.468279
2019-11-07 16:53:23,428 train 200 1.715768e-02 -1.975600
2019-11-07 16:53:33,264 train 250 1.706004e-02 -1.710394
2019-11-07 16:53:43,121 train 300 1.700570e-02 -1.521742
2019-11-07 16:53:52,991 train 350 1.711501e-02 -1.434652
2019-11-07 16:54:02,862 train 400 1.717737e-02 -1.361717
2019-11-07 16:54:12,740 train 450 1.711984e-02 -1.283642
2019-11-07 16:54:22,588 train 500 1.709627e-02 -1.225284
2019-11-07 16:54:32,419 train 550 1.708276e-02 -1.202090
2019-11-07 16:54:42,243 train 600 1.704556e-02 -1.149939
2019-11-07 16:54:52,085 train 650 1.703373e-02 -1.123212
2019-11-07 16:55:01,916 train 700 1.703903e-02 -1.092359
2019-11-07 16:55:11,755 train 750 1.705796e-02 -1.082648
2019-11-07 16:55:21,579 train 800 1.705440e-02 -1.053632
2019-11-07 16:55:31,405 train 850 1.704086e-02 -1.030821
2019-11-07 16:55:34,346 training loss; R2: 1.703566e-02 -1.028763
2019-11-07 16:55:34,977 valid 000 1.863933e-02 -0.553776
2019-11-07 16:55:44,385 valid 050 1.706163e-02 -1.254291
2019-11-07 16:55:52,741 validation loss; R2: 1.733417e-02 -1.433183
2019-11-07 16:55:52,809 epoch 593 lr 1.000000e-05
2019-11-07 16:55:53,559 train 000 1.497807e-02 -0.230995
2019-11-07 16:56:03,323 train 050 1.716515e-02 -0.751323
2019-11-07 16:56:13,076 train 100 1.709273e-02 -0.628303
2019-11-07 16:56:22,879 train 150 1.716009e-02 -0.721558
2019-11-07 16:56:32,673 train 200 1.719414e-02 -0.732556
2019-11-07 16:56:42,459 train 250 1.717310e-02 -0.763887
2019-11-07 16:56:52,264 train 300 1.718619e-02 -0.731283
2019-11-07 16:57:02,095 train 350 1.718366e-02 -0.714482
2019-11-07 16:57:11,940 train 400 1.708613e-02 -0.728642
2019-11-07 16:57:21,770 train 450 1.701952e-02 -0.749700
2019-11-07 16:57:31,595 train 500 1.702741e-02 -0.765366
2019-11-07 16:57:41,412 train 550 1.697805e-02 -1.290239
2019-11-07 16:57:51,237 train 600 1.699301e-02 -1.243662
2019-11-07 16:58:01,060 train 650 1.701417e-02 -1.186943
2019-11-07 16:58:10,877 train 700 1.700264e-02 -1.154009
2019-11-07 16:58:20,719 train 750 1.701649e-02 -1.124493
2019-11-07 16:58:30,559 train 800 1.701425e-02 -1.090374
2019-11-07 16:58:40,408 train 850 1.702292e-02 -1.087671
2019-11-07 16:58:43,346 training loss; R2: 1.701293e-02 -1.078077
2019-11-07 16:58:44,062 valid 000 1.472888e-02 -1.604260
2019-11-07 16:58:53,481 valid 050 1.532168e-02 -1.106138
2019-11-07 16:59:01,895 validation loss; R2: 1.531999e-02 -1.158185
2019-11-07 16:59:01,977 epoch 594 lr 1.000000e-05
2019-11-07 16:59:02,861 train 000 1.939673e-02 -0.773085
2019-11-07 16:59:13,001 train 050 1.666521e-02 -0.756334
2019-11-07 16:59:23,153 train 100 1.689458e-02 -0.726067
2019-11-07 16:59:33,295 train 150 1.696015e-02 -0.660220
2019-11-07 16:59:43,447 train 200 1.694624e-02 -0.678227
2019-11-07 16:59:53,584 train 250 1.691865e-02 -0.692794
2019-11-07 17:00:03,734 train 300 1.693404e-02 -0.735532
2019-11-07 17:00:13,902 train 350 1.692742e-02 -0.711832
2019-11-07 17:00:24,064 train 400 1.695721e-02 -0.728469
2019-11-07 17:00:34,234 train 450 1.695248e-02 -0.736930
2019-11-07 17:00:44,403 train 500 1.696739e-02 -0.711603
2019-11-07 17:00:54,576 train 550 1.694197e-02 -0.722929
2019-11-07 17:01:04,744 train 600 1.697268e-02 -0.747385
2019-11-07 17:01:14,927 train 650 1.695594e-02 -0.777755
2019-11-07 17:01:25,099 train 700 1.697534e-02 -0.789372
2019-11-07 17:01:35,259 train 750 1.697362e-02 -0.801346
2019-11-07 17:01:45,417 train 800 1.699691e-02 -0.805798
2019-11-07 17:01:55,605 train 850 1.700291e-02 -0.807565
2019-11-07 17:01:58,639 training loss; R2: 1.701459e-02 -0.800293
2019-11-07 17:01:59,347 valid 000 1.734521e-02 -1.472171
2019-11-07 17:02:08,672 valid 050 1.596046e-02 -1.276458
2019-11-07 17:02:17,149 validation loss; R2: 1.587930e-02 -1.476164
2019-11-07 17:02:17,217 epoch 595 lr 1.000000e-05
2019-11-07 17:02:18,026 train 000 1.867780e-02 0.011588
2019-11-07 17:02:28,139 train 050 1.703927e-02 -0.597970
2019-11-07 17:02:38,278 train 100 1.721199e-02 -0.575251
2019-11-07 17:02:48,419 train 150 1.733321e-02 -0.651842
2019-11-07 17:02:58,562 train 200 1.726065e-02 -0.694553
2019-11-07 17:03:08,713 train 250 1.729232e-02 -0.733243
2019-11-07 17:03:18,863 train 300 1.726094e-02 -0.704086
2019-11-07 17:03:29,022 train 350 1.723745e-02 -0.748159
2019-11-07 17:03:39,166 train 400 1.716547e-02 -0.744019
2019-11-07 17:03:49,330 train 450 1.715447e-02 -0.750888
2019-11-07 17:03:59,498 train 500 1.715784e-02 -0.753211
2019-11-07 17:04:09,672 train 550 1.711977e-02 -0.750536
2019-11-07 17:04:19,854 train 600 1.712780e-02 -0.763091
2019-11-07 17:04:30,032 train 650 1.712657e-02 -0.774839
2019-11-07 17:04:40,209 train 700 1.712164e-02 -0.757715
2019-11-07 17:04:50,373 train 750 1.710133e-02 -0.792152
2019-11-07 17:05:00,553 train 800 1.708840e-02 -0.793991
2019-11-07 17:05:10,719 train 850 1.707041e-02 -0.784259
2019-11-07 17:05:13,758 training loss; R2: 1.707327e-02 -0.783776
2019-11-07 17:05:14,457 valid 000 1.370505e-02 -0.952764
2019-11-07 17:05:23,834 valid 050 1.608135e-02 -1.298671
2019-11-07 17:05:32,372 validation loss; R2: 1.634606e-02 -1.238191
2019-11-07 17:05:32,440 epoch 596 lr 1.000000e-05
2019-11-07 17:05:33,269 train 000 1.694489e-02 -1.090939
2019-11-07 17:05:43,356 train 050 1.674559e-02 -0.576957
2019-11-07 17:05:53,489 train 100 1.673242e-02 -0.608172
2019-11-07 17:06:03,627 train 150 1.682596e-02 -0.613247
2019-11-07 17:06:13,767 train 200 1.687852e-02 -0.809697
2019-11-07 17:06:23,921 train 250 1.693615e-02 -2.076597
2019-11-07 17:06:34,063 train 300 1.709533e-02 -1.870162
2019-11-07 17:06:44,208 train 350 1.701477e-02 -1.689390
2019-11-07 17:06:54,366 train 400 1.700471e-02 -1.556607
2019-11-07 17:07:04,533 train 450 1.703239e-02 -1.447552
2019-11-07 17:07:14,713 train 500 1.702570e-02 -1.393247
2019-11-07 17:07:24,864 train 550 1.704304e-02 -1.344957
2019-11-07 17:07:35,028 train 600 1.703697e-02 -1.275951
2019-11-07 17:07:45,176 train 650 1.703273e-02 -1.213070
2019-11-07 17:07:55,342 train 700 1.703438e-02 -1.179123
2019-11-07 17:08:05,509 train 750 1.706082e-02 -1.141706
2019-11-07 17:08:15,685 train 800 1.707200e-02 -1.121311
2019-11-07 17:08:25,852 train 850 1.705673e-02 -1.103761
2019-11-07 17:08:28,876 training loss; R2: 1.705255e-02 -1.089252
2019-11-07 17:08:29,519 valid 000 1.515684e-02 -0.095498
2019-11-07 17:08:38,979 valid 050 1.691192e-02 -1.457157
2019-11-07 17:08:47,293 validation loss; R2: 1.698549e-02 -1.486491
2019-11-07 17:08:47,359 epoch 597 lr 1.000000e-05
2019-11-07 17:08:48,143 train 000 1.667063e-02 -0.405708
2019-11-07 17:08:58,243 train 050 1.734001e-02 -0.575244
2019-11-07 17:09:08,363 train 100 1.729951e-02 -0.569897
2019-11-07 17:09:18,481 train 150 1.723317e-02 -0.637224
2019-11-07 17:09:28,611 train 200 1.735523e-02 -0.624553
2019-11-07 17:09:38,734 train 250 1.726293e-02 -0.687897
2019-11-07 17:09:48,869 train 300 1.718016e-02 -0.685578
2019-11-07 17:09:58,990 train 350 1.716546e-02 -0.677394
2019-11-07 17:10:09,147 train 400 1.719089e-02 -0.675928
2019-11-07 17:10:19,293 train 450 1.717290e-02 -0.695564
2019-11-07 17:10:29,461 train 500 1.712132e-02 -0.721938
2019-11-07 17:10:39,601 train 550 1.710720e-02 -0.719099
2019-11-07 17:10:49,756 train 600 1.711353e-02 -0.721045
2019-11-07 17:10:59,906 train 650 1.709575e-02 -0.703848
2019-11-07 17:11:10,075 train 700 1.709918e-02 -0.703495
2019-11-07 17:11:20,249 train 750 1.707313e-02 -0.705300
2019-11-07 17:11:30,384 train 800 1.703981e-02 -0.708176
2019-11-07 17:11:40,544 train 850 1.700319e-02 -0.925278
2019-11-07 17:11:43,571 training loss; R2: 1.701369e-02 -0.925650
2019-11-07 17:11:44,264 valid 000 2.005894e-02 -0.138049
2019-11-07 17:11:53,646 valid 050 1.822653e-02 -1.658496
2019-11-07 17:12:02,116 validation loss; R2: 1.817822e-02 -1.914762
2019-11-07 17:12:02,184 epoch 598 lr 1.000000e-05
2019-11-07 17:12:02,997 train 000 1.722483e-02 -0.017366
2019-11-07 17:12:13,133 train 050 1.695606e-02 -0.509341
2019-11-07 17:12:23,288 train 100 1.700831e-02 -0.572290
2019-11-07 17:12:33,421 train 150 1.705559e-02 -0.564012
2019-11-07 17:12:43,589 train 200 1.710415e-02 -0.553462
2019-11-07 17:12:53,739 train 250 1.706538e-02 -0.551966
2019-11-07 17:13:03,884 train 300 1.706770e-02 -0.595662
2019-11-07 17:13:14,044 train 350 1.706109e-02 -0.643336
2019-11-07 17:13:24,202 train 400 1.705222e-02 -0.618335
2019-11-07 17:13:34,195 train 450 1.702165e-02 -0.760609
2019-11-07 17:13:44,004 train 500 1.701614e-02 -0.758764
2019-11-07 17:13:53,808 train 550 1.700088e-02 -0.784673
2019-11-07 17:14:03,610 train 600 1.700018e-02 -0.791997
2019-11-07 17:14:13,413 train 650 1.698282e-02 -0.770422
2019-11-07 17:14:23,231 train 700 1.698628e-02 -0.752723
2019-11-07 17:14:33,045 train 750 1.700100e-02 -0.734509
2019-11-07 17:14:42,850 train 800 1.701162e-02 -0.791816
2019-11-07 17:14:52,663 train 850 1.702709e-02 -0.797323
2019-11-07 17:14:55,597 training loss; R2: 1.702429e-02 -0.788508
2019-11-07 17:14:56,295 valid 000 2.140519e-02 -0.713255
2019-11-07 17:15:05,692 valid 050 1.653580e-02 -1.053715
2019-11-07 17:15:14,010 validation loss; R2: 1.640645e-02 -1.406939
2019-11-07 17:15:14,075 epoch 599 lr 1.000000e-05
2019-11-07 17:15:14,864 train 000 1.935790e-02 -0.067965
2019-11-07 17:15:24,605 train 050 1.702614e-02 -0.940528
2019-11-07 17:15:34,371 train 100 1.701345e-02 -1.367691
2019-11-07 17:15:44,123 train 150 1.703819e-02 -1.167564
2019-11-07 17:15:53,924 train 200 1.700044e-02 -1.045311
2019-11-07 17:16:03,718 train 250 1.696892e-02 -1.034713
2019-11-07 17:16:13,516 train 300 1.698053e-02 -0.962654
2019-11-07 17:16:23,337 train 350 1.700187e-02 -0.939635
2019-11-07 17:16:33,174 train 400 1.696775e-02 -0.906123
2019-11-07 17:16:43,015 train 450 1.698436e-02 -0.905780
2019-11-07 17:16:52,870 train 500 1.699702e-02 -0.881627
2019-11-07 17:17:02,706 train 550 1.697441e-02 -0.853881
2019-11-07 17:17:12,552 train 600 1.700290e-02 -0.837730
2019-11-07 17:17:22,402 train 650 1.701412e-02 -0.850031
2019-11-07 17:17:32,237 train 700 1.701188e-02 -0.832676
2019-11-07 17:17:42,105 train 750 1.700901e-02 -0.822021
2019-11-07 17:17:51,950 train 800 1.702199e-02 -0.819217
2019-11-07 17:18:01,804 train 850 1.701899e-02 -0.808523
2019-11-07 17:18:04,739 training loss; R2: 1.701559e-02 -0.806233
2019-11-07 17:18:05,334 valid 000 1.676261e-02 -0.747941
2019-11-07 17:18:14,773 valid 050 1.651920e-02 -1.167587
2019-11-07 17:18:23,156 validation loss; R2: 1.659192e-02 -1.124760
2019-11-07 17:18:23,222 epoch 600 lr 1.000000e-05
2019-11-07 17:18:23,998 train 000 1.839885e-02 -0.153147
2019-11-07 17:18:33,768 train 050 1.737313e-02 -0.842941
2019-11-07 17:18:43,544 train 100 1.717885e-02 -0.704255
2019-11-07 17:18:53,338 train 150 1.711711e-02 -0.686673
2019-11-07 17:19:03,156 train 200 1.706598e-02 -0.701654
2019-11-07 17:19:12,971 train 250 1.698966e-02 -0.693791
2019-11-07 17:19:22,795 train 300 1.700757e-02 -0.699549
2019-11-07 17:19:32,619 train 350 1.696277e-02 -0.730859
2019-11-07 17:19:42,435 train 400 1.694972e-02 -0.743763
2019-11-07 17:19:52,254 train 450 1.695716e-02 -0.746131
2019-11-07 17:20:02,065 train 500 1.694167e-02 -0.741193
2019-11-07 17:20:11,894 train 550 1.695791e-02 -0.797283
2019-11-07 17:20:21,706 train 600 1.697711e-02 -0.792071
2019-11-07 17:20:31,526 train 650 1.699237e-02 -0.777606
2019-11-07 17:20:41,342 train 700 1.697979e-02 -0.788711
2019-11-07 17:20:51,150 train 750 1.699349e-02 -0.770224
2019-11-07 17:21:00,979 train 800 1.699482e-02 -0.787942
2019-11-07 17:21:10,803 train 850 1.698500e-02 -0.786753
2019-11-07 17:21:13,739 training loss; R2: 1.698168e-02 -0.786464
2019-11-07 17:21:14,392 valid 000 1.762155e-02 -4.599535
2019-11-07 17:21:23,798 valid 050 1.641406e-02 -2.221424
2019-11-07 17:21:32,248 validation loss; R2: 1.623056e-02 -1.760362
2019-11-07 17:21:32,314 epoch 601 lr 1.000000e-05
2019-11-07 17:21:33,073 train 000 1.887450e-02 -0.948948
2019-11-07 17:21:42,850 train 050 1.761098e-02 -0.758299
2019-11-07 17:21:52,630 train 100 1.743183e-02 -0.737088
2019-11-07 17:22:02,432 train 150 1.734273e-02 -0.742624
2019-11-07 17:22:12,235 train 200 1.713424e-02 -0.744290
2019-11-07 17:22:22,068 train 250 1.701388e-02 -0.740900
2019-11-07 17:22:31,907 train 300 1.705786e-02 -0.756068
2019-11-07 17:22:41,727 train 350 1.702441e-02 -0.795933
2019-11-07 17:22:51,567 train 400 1.698077e-02 -0.772161
2019-11-07 17:23:01,393 train 450 1.697446e-02 -0.759420
2019-11-07 17:23:11,222 train 500 1.700193e-02 -0.780171
2019-11-07 17:23:21,050 train 550 1.704233e-02 -0.788107
2019-11-07 17:23:30,887 train 600 1.704688e-02 -0.778117
2019-11-07 17:23:40,710 train 650 1.707141e-02 -0.785098
2019-11-07 17:23:50,527 train 700 1.709109e-02 -0.781247
2019-11-07 17:24:00,348 train 750 1.709112e-02 -0.769666
2019-11-07 17:24:10,179 train 800 1.712549e-02 -0.772175
2019-11-07 17:24:20,006 train 850 1.712970e-02 -0.754270
2019-11-07 17:24:22,944 training loss; R2: 1.713151e-02 -0.756396
2019-11-07 17:24:23,643 valid 000 1.706260e-02 -1.425113
2019-11-07 17:24:33,011 valid 050 1.562486e-02 -1.564277
2019-11-07 17:24:41,436 validation loss; R2: 1.595367e-02 -1.321062
2019-11-07 17:24:41,503 epoch 602 lr 1.000000e-05
2019-11-07 17:24:42,305 train 000 1.431515e-02 -0.149795
2019-11-07 17:24:52,096 train 050 1.676019e-02 -0.832002
2019-11-07 17:25:01,865 train 100 1.678430e-02 -0.748266
2019-11-07 17:25:11,668 train 150 1.689971e-02 -0.850300
2019-11-07 17:25:21,447 train 200 1.690437e-02 -0.756148
2019-11-07 17:25:31,254 train 250 1.696504e-02 -0.723325
2019-11-07 17:25:41,043 train 300 1.698540e-02 -0.741961
2019-11-07 17:25:50,821 train 350 1.695811e-02 -0.714454
2019-11-07 17:26:00,574 train 400 1.695182e-02 -0.710069
2019-11-07 17:26:10,321 train 450 1.692574e-02 -0.739114
2019-11-07 17:26:20,064 train 500 1.694157e-02 -0.735627
2019-11-07 17:26:29,811 train 550 1.695363e-02 -0.738949
2019-11-07 17:26:39,665 train 600 1.697644e-02 -0.733870
2019-11-07 17:26:49,824 train 650 1.698827e-02 -0.879099
2019-11-07 17:26:59,977 train 700 1.698909e-02 -0.884295
2019-11-07 17:27:10,124 train 750 1.698363e-02 -0.987796
2019-11-07 17:27:20,280 train 800 1.699131e-02 -0.967448
2019-11-07 17:27:30,431 train 850 1.701306e-02 -0.956725
2019-11-07 17:27:33,465 training loss; R2: 1.701377e-02 -0.954058
2019-11-07 17:27:34,121 valid 000 2.114631e-02 -0.453891
2019-11-07 17:27:43,541 valid 050 1.726508e-02 -1.181114
2019-11-07 17:27:51,881 validation loss; R2: 1.725027e-02 -1.746082
2019-11-07 17:27:51,948 epoch 603 lr 1.000000e-05
2019-11-07 17:27:52,677 train 000 1.937482e-02 -3.652891
2019-11-07 17:28:02,757 train 050 1.687662e-02 -0.872253
2019-11-07 17:28:12,867 train 100 1.717546e-02 -0.755161
2019-11-07 17:28:22,971 train 150 1.702803e-02 -0.788431
2019-11-07 17:28:33,095 train 200 1.701506e-02 -0.834609
2019-11-07 17:28:43,191 train 250 1.698128e-02 -0.788119
2019-11-07 17:28:53,331 train 300 1.703343e-02 -0.830652
2019-11-07 17:29:03,480 train 350 1.702055e-02 -0.799206
2019-11-07 17:29:13,630 train 400 1.699203e-02 -0.786872
2019-11-07 17:29:23,774 train 450 1.701207e-02 -0.804689
2019-11-07 17:29:33,921 train 500 1.705507e-02 -0.779602
2019-11-07 17:29:44,069 train 550 1.704228e-02 -0.783095
2019-11-07 17:29:54,214 train 600 1.703992e-02 -0.779093
2019-11-07 17:30:04,368 train 650 1.704639e-02 -0.789105
2019-11-07 17:30:14,516 train 700 1.702481e-02 -0.781635
2019-11-07 17:30:24,655 train 750 1.699909e-02 -0.763676
2019-11-07 17:30:34,800 train 800 1.699917e-02 -0.750674
2019-11-07 17:30:44,957 train 850 1.698301e-02 -0.751252
2019-11-07 17:30:47,980 training loss; R2: 1.699556e-02 -0.750294
2019-11-07 17:30:48,667 valid 000 1.868294e-02 -0.442134
2019-11-07 17:30:58,052 valid 050 1.694534e-02 -1.287024
2019-11-07 17:31:06,423 validation loss; R2: 1.709867e-02 -1.135777
2019-11-07 17:31:06,490 epoch 604 lr 1.000000e-05
2019-11-07 17:31:07,246 train 000 1.864208e-02 0.015793
2019-11-07 17:31:17,372 train 050 1.728506e-02 -0.439602
2019-11-07 17:31:27,270 train 100 1.695777e-02 -0.548902
2019-11-07 17:31:37,037 train 150 1.694160e-02 -0.578825
2019-11-07 17:31:46,814 train 200 1.689222e-02 -0.615543
2019-11-07 17:31:56,622 train 250 1.691829e-02 -0.666184
2019-11-07 17:32:06,431 train 300 1.694297e-02 -0.675162
2019-11-07 17:32:16,240 train 350 1.689897e-02 -0.720247
2019-11-07 17:32:26,037 train 400 1.690062e-02 -0.708109
2019-11-07 17:32:35,831 train 450 1.693914e-02 -0.734393
2019-11-07 17:32:45,614 train 500 1.696607e-02 -0.734175
2019-11-07 17:32:55,414 train 550 1.699038e-02 -0.720532
2019-11-07 17:33:05,213 train 600 1.698552e-02 -0.721186
2019-11-07 17:33:15,002 train 650 1.697850e-02 -0.727625
2019-11-07 17:33:24,807 train 700 1.699636e-02 -0.753153
2019-11-07 17:33:34,620 train 750 1.700953e-02 -0.783970
2019-11-07 17:33:44,440 train 800 1.701906e-02 -0.780065
2019-11-07 17:33:54,250 train 850 1.702694e-02 -0.773895
2019-11-07 17:33:57,197 training loss; R2: 1.703347e-02 -0.771639
2019-11-07 17:33:57,843 valid 000 2.285354e-02 -0.580861
2019-11-07 17:34:07,283 valid 050 2.374748e-02 -5.678671
2019-11-07 17:34:15,628 validation loss; R2: 2.381497e-02 -4.213656
2019-11-07 17:34:15,694 epoch 605 lr 1.000000e-05
2019-11-07 17:34:16,456 train 000 1.485879e-02 0.082648
2019-11-07 17:34:26,191 train 050 1.712811e-02 -0.831814
2019-11-07 17:34:35,983 train 100 1.714532e-02 -0.817743
2019-11-07 17:34:45,783 train 150 1.706392e-02 -0.838726
2019-11-07 17:34:55,582 train 200 1.705992e-02 -0.809121
2019-11-07 17:35:05,368 train 250 1.701075e-02 -0.779613
2019-11-07 17:35:15,156 train 300 1.701083e-02 -0.754480
2019-11-07 17:35:24,940 train 350 1.702540e-02 -0.750942
2019-11-07 17:35:34,715 train 400 1.700150e-02 -0.836456
2019-11-07 17:35:44,503 train 450 1.698233e-02 -0.821341
2019-11-07 17:35:54,309 train 500 1.700369e-02 -0.819789
2019-11-07 17:36:04,089 train 550 1.699253e-02 -0.798377
2019-11-07 17:36:13,869 train 600 1.701166e-02 -0.791178
2019-11-07 17:36:23,662 train 650 1.702230e-02 -0.796616
2019-11-07 17:36:33,458 train 700 1.701111e-02 -0.803484
2019-11-07 17:36:43,257 train 750 1.706414e-02 -0.780474
2019-11-07 17:36:53,054 train 800 1.705283e-02 -0.775514
2019-11-07 17:37:02,860 train 850 1.705008e-02 -0.767649
2019-11-07 17:37:05,792 training loss; R2: 1.705148e-02 -0.774466
2019-11-07 17:37:06,494 valid 000 1.632833e-02 0.023415
2019-11-07 17:37:15,933 valid 050 1.640249e-02 -1.656034
2019-11-07 17:37:24,261 validation loss; R2: 1.628236e-02 -1.420605
2019-11-07 17:37:24,326 epoch 606 lr 1.000000e-05
2019-11-07 17:37:25,107 train 000 1.624259e-02 -0.101019
2019-11-07 17:37:34,867 train 050 1.680400e-02 -0.764242
2019-11-07 17:37:44,640 train 100 1.688629e-02 -0.758865
2019-11-07 17:37:54,445 train 150 1.690400e-02 -0.742151
2019-11-07 17:38:04,250 train 200 1.693030e-02 -1.373842
2019-11-07 17:38:14,049 train 250 1.692100e-02 -1.227350
2019-11-07 17:38:23,849 train 300 1.696363e-02 -1.139537
2019-11-07 17:38:33,661 train 350 1.697865e-02 -1.049534
2019-11-07 17:38:43,459 train 400 1.700445e-02 -0.981457
2019-11-07 17:38:53,256 train 450 1.697688e-02 -0.936296
2019-11-07 17:39:03,038 train 500 1.696704e-02 -0.903503
2019-11-07 17:39:12,834 train 550 1.694175e-02 -0.878879
2019-11-07 17:39:22,614 train 600 1.694978e-02 -0.848636
2019-11-07 17:39:32,406 train 650 1.696799e-02 -0.823991
2019-11-07 17:39:42,188 train 700 1.697081e-02 -0.855295
2019-11-07 17:39:51,972 train 750 1.698164e-02 -0.858969
2019-11-07 17:40:01,775 train 800 1.697377e-02 -0.852787
2019-11-07 17:40:11,584 train 850 1.696487e-02 -0.967699
2019-11-07 17:40:14,514 training loss; R2: 1.696415e-02 -0.971906
2019-11-07 17:40:15,159 valid 000 1.877370e-02 -4.969265
2019-11-07 17:40:24,601 valid 050 1.734688e-02 -4.784429
2019-11-07 17:40:32,916 validation loss; R2: 1.706371e-02 -3.147475
2019-11-07 17:40:32,981 epoch 607 lr 1.000000e-05
2019-11-07 17:40:33,750 train 000 1.627814e-02 -0.293300
2019-11-07 17:40:43,519 train 050 1.697524e-02 -0.949454
2019-11-07 17:40:53,295 train 100 1.712690e-02 -0.962843
2019-11-07 17:41:03,079 train 150 1.701891e-02 -0.883011
2019-11-07 17:41:12,865 train 200 1.708014e-02 -1.067964
2019-11-07 17:41:22,664 train 250 1.705578e-02 -0.981822
2019-11-07 17:41:32,462 train 300 1.704681e-02 -0.942700
2019-11-07 17:41:42,247 train 350 1.714026e-02 -0.936430
2019-11-07 17:41:52,037 train 400 1.710513e-02 -0.939304
2019-11-07 17:42:01,834 train 450 1.703925e-02 -0.963688
2019-11-07 17:42:11,630 train 500 1.700997e-02 -0.969633
2019-11-07 17:42:21,420 train 550 1.700873e-02 -0.963505
2019-11-07 17:42:31,203 train 600 1.703239e-02 -0.941791
2019-11-07 17:42:41,006 train 650 1.704478e-02 -0.914914
2019-11-07 17:42:50,812 train 700 1.703248e-02 -0.888564
2019-11-07 17:43:00,622 train 750 1.702798e-02 -0.872997
2019-11-07 17:43:10,442 train 800 1.700582e-02 -0.850434
2019-11-07 17:43:20,260 train 850 1.700830e-02 -0.842591
2019-11-07 17:43:23,228 training loss; R2: 1.700451e-02 -0.847989
2019-11-07 17:43:23,909 valid 000 1.728350e-02 -0.582736
2019-11-07 17:43:33,299 valid 050 1.532200e-02 -1.043336
2019-11-07 17:43:41,660 validation loss; R2: 1.546772e-02 -1.036503
2019-11-07 17:43:41,737 epoch 608 lr 1.000000e-05
2019-11-07 17:43:42,524 train 000 1.608866e-02 -1.917347
2019-11-07 17:43:52,658 train 050 1.721448e-02 -0.589349
2019-11-07 17:44:02,836 train 100 1.720134e-02 -0.732511
2019-11-07 17:44:13,007 train 150 1.710208e-02 -0.737481
2019-11-07 17:44:23,214 train 200 1.700244e-02 -0.693961
2019-11-07 17:44:33,424 train 250 1.696188e-02 -0.730940
2019-11-07 17:44:43,639 train 300 1.700918e-02 -0.712623
2019-11-07 17:44:53,842 train 350 1.701406e-02 -0.730469
2019-11-07 17:45:04,054 train 400 1.700603e-02 -0.703426
2019-11-07 17:45:14,276 train 450 1.704459e-02 -0.676717
2019-11-07 17:45:24,472 train 500 1.704453e-02 -0.701486
2019-11-07 17:45:34,686 train 550 1.703398e-02 -0.691536
2019-11-07 17:45:44,900 train 600 1.704974e-02 -0.692951
2019-11-07 17:45:54,792 train 650 1.704501e-02 -0.682315
2019-11-07 17:46:04,659 train 700 1.706020e-02 -0.686183
2019-11-07 17:46:14,525 train 750 1.705542e-02 -0.695260
2019-11-07 17:46:24,392 train 800 1.701504e-02 -0.712964
2019-11-07 17:46:34,246 train 850 1.702830e-02 -0.711751
2019-11-07 17:46:37,202 training loss; R2: 1.702271e-02 -0.724768
2019-11-07 17:46:37,898 valid 000 2.003055e-02 -5.513600
2019-11-07 17:46:47,258 valid 050 1.975047e-02 -3.122874
2019-11-07 17:46:55,565 validation loss; R2: 1.965964e-02 -2.741556
2019-11-07 17:46:55,628 epoch 609 lr 1.000000e-05
2019-11-07 17:46:56,422 train 000 1.670094e-02 -0.577751
2019-11-07 17:47:06,217 train 050 1.730944e-02 -0.704803
2019-11-07 17:47:16,034 train 100 1.707952e-02 -0.731931
2019-11-07 17:47:25,845 train 150 1.701506e-02 -0.699886
2019-11-07 17:47:35,686 train 200 1.706508e-02 -0.765064
2019-11-07 17:47:45,512 train 250 1.712871e-02 -0.769147
2019-11-07 17:47:55,357 train 300 1.708962e-02 -0.748741
2019-11-07 17:48:05,182 train 350 1.703313e-02 -0.758245
2019-11-07 17:48:15,028 train 400 1.706792e-02 -0.776610
2019-11-07 17:48:24,861 train 450 1.703524e-02 -0.761416
2019-11-07 17:48:34,700 train 500 1.707483e-02 -0.757590
2019-11-07 17:48:44,529 train 550 1.702194e-02 -0.736552
2019-11-07 17:48:54,390 train 600 1.702589e-02 -0.724331
2019-11-07 17:49:04,232 train 650 1.701486e-02 -0.739934
2019-11-07 17:49:14,074 train 700 1.701893e-02 -0.762448
2019-11-07 17:49:23,906 train 750 1.702055e-02 -0.752214
2019-11-07 17:49:33,750 train 800 1.701514e-02 -0.748299
2019-11-07 17:49:43,603 train 850 1.701657e-02 -0.743008
2019-11-07 17:49:46,541 training loss; R2: 1.703110e-02 -0.742785
2019-11-07 17:49:47,140 valid 000 1.400987e-02 -1.365147
2019-11-07 17:49:56,550 valid 050 1.548719e-02 -1.647555
2019-11-07 17:50:05,016 validation loss; R2: 1.564990e-02 -1.385371
2019-11-07 17:50:05,079 epoch 610 lr 1.000000e-05
2019-11-07 17:50:05,865 train 000 1.591691e-02 -0.771962
2019-11-07 17:50:15,621 train 050 1.692161e-02 -0.926664
2019-11-07 17:50:25,398 train 100 1.727444e-02 -0.783823
2019-11-07 17:50:35,174 train 150 1.727759e-02 -0.799961
2019-11-07 17:50:44,971 train 200 1.731326e-02 -0.777691
2019-11-07 17:50:54,777 train 250 1.731949e-02 -0.722928
2019-11-07 17:51:04,563 train 300 1.727356e-02 -0.686361
2019-11-07 17:51:14,375 train 350 1.724476e-02 -0.712789
2019-11-07 17:51:24,150 train 400 1.720165e-02 -0.700644
2019-11-07 17:51:34,320 train 450 1.714707e-02 -0.713222
2019-11-07 17:51:44,476 train 500 1.714271e-02 -0.693792
2019-11-07 17:51:54,297 train 550 1.706737e-02 -0.703263
2019-11-07 17:52:04,094 train 600 1.703771e-02 -0.713055
2019-11-07 17:52:13,884 train 650 1.705208e-02 -0.719810
2019-11-07 17:52:23,685 train 700 1.703240e-02 -0.736690
2019-11-07 17:52:33,466 train 750 1.701376e-02 -0.744956
2019-11-07 17:52:43,261 train 800 1.701536e-02 -0.754410
2019-11-07 17:52:53,068 train 850 1.699434e-02 -0.764886
2019-11-07 17:52:56,001 training loss; R2: 1.698252e-02 -0.761059
2019-11-07 17:52:56,673 valid 000 1.343513e-02 -2.182900
2019-11-07 17:53:06,064 valid 050 1.652553e-02 -1.041153
2019-11-07 17:53:14,389 validation loss; R2: 1.629825e-02 -10.718115
2019-11-07 17:53:14,447 epoch 611 lr 1.000000e-05
2019-11-07 17:53:15,182 train 000 1.578320e-02 -0.132094
2019-11-07 17:53:24,946 train 050 1.699425e-02 -0.741795
2019-11-07 17:53:34,722 train 100 1.696791e-02 -0.624498
2019-11-07 17:53:44,500 train 150 1.686863e-02 -0.608147
2019-11-07 17:53:54,312 train 200 1.685965e-02 -0.587933
2019-11-07 17:54:04,125 train 250 1.684147e-02 -0.599596
2019-11-07 17:54:13,934 train 300 1.682106e-02 -0.636440
2019-11-07 17:54:23,759 train 350 1.690900e-02 -0.616365
2019-11-07 17:54:33,564 train 400 1.690573e-02 -0.633300
2019-11-07 17:54:43,391 train 450 1.684702e-02 -0.628364
2019-11-07 17:54:53,211 train 500 1.692704e-02 -0.680578
2019-11-07 17:55:03,028 train 550 1.692387e-02 -0.668296
2019-11-07 17:55:12,846 train 600 1.693290e-02 -0.691452
2019-11-07 17:55:22,674 train 650 1.695282e-02 -0.688056
2019-11-07 17:55:32,502 train 700 1.696617e-02 -0.689001
2019-11-07 17:55:42,323 train 750 1.695968e-02 -0.687125
2019-11-07 17:55:52,157 train 800 1.697204e-02 -0.684998
2019-11-07 17:56:01,975 train 850 1.697709e-02 -0.675091
2019-11-07 17:56:04,911 training loss; R2: 1.696871e-02 -0.681016
2019-11-07 17:56:05,483 valid 000 1.461756e-02 -4.711553
2019-11-07 17:56:14,930 valid 050 1.587548e-02 -1.248686
2019-11-07 17:56:23,234 validation loss; R2: 1.580435e-02 -1.320171
2019-11-07 17:56:23,293 epoch 612 lr 1.000000e-05
2019-11-07 17:56:24,045 train 000 1.588765e-02 -0.200821
2019-11-07 17:56:33,815 train 050 1.683118e-02 -0.748949
2019-11-07 17:56:43,605 train 100 1.697658e-02 -0.713876
2019-11-07 17:56:53,418 train 150 1.703782e-02 -0.814373
2019-11-07 17:57:03,239 train 200 1.705735e-02 -0.845893
2019-11-07 17:57:13,060 train 250 1.694759e-02 -0.817850
2019-11-07 17:57:22,886 train 300 1.692665e-02 -0.784797
2019-11-07 17:57:32,725 train 350 1.691175e-02 -0.828702
2019-11-07 17:57:42,543 train 400 1.690221e-02 -0.829560
2019-11-07 17:57:52,359 train 450 1.685774e-02 -0.812549
2019-11-07 17:58:02,200 train 500 1.687582e-02 -0.792461
2019-11-07 17:58:12,041 train 550 1.690959e-02 -0.768389
2019-11-07 17:58:21,863 train 600 1.696903e-02 -0.765612
2019-11-07 17:58:31,680 train 650 1.698497e-02 -0.748959
2019-11-07 17:58:41,520 train 700 1.699238e-02 -0.742393
2019-11-07 17:58:51,358 train 750 1.697629e-02 -0.741987
2019-11-07 17:59:01,178 train 800 1.697439e-02 -0.748472
2019-11-07 17:59:11,014 train 850 1.696985e-02 -0.759703
2019-11-07 17:59:13,954 training loss; R2: 1.696729e-02 -0.757212
2019-11-07 17:59:14,575 valid 000 1.575268e-02 -0.540670
2019-11-07 17:59:24,036 valid 050 1.711360e-02 -1.160057
2019-11-07 17:59:32,368 validation loss; R2: 1.687693e-02 -1.693227
2019-11-07 17:59:32,432 epoch 613 lr 1.000000e-05
2019-11-07 17:59:33,198 train 000 1.704423e-02 -0.728089
2019-11-07 17:59:42,993 train 050 1.729110e-02 -0.663629
2019-11-07 17:59:52,809 train 100 1.713485e-02 -0.728531
2019-11-07 18:00:02,632 train 150 1.708834e-02 -0.718909
2019-11-07 18:00:12,457 train 200 1.704406e-02 -0.867307
2019-11-07 18:00:22,290 train 250 1.702497e-02 -0.859608
2019-11-07 18:00:32,106 train 300 1.705748e-02 -0.844121
2019-11-07 18:00:41,924 train 350 1.703267e-02 -0.819286
2019-11-07 18:00:51,741 train 400 1.702301e-02 -0.783996
2019-11-07 18:01:01,575 train 450 1.700260e-02 -0.796383
2019-11-07 18:01:11,385 train 500 1.698177e-02 -0.785629
2019-11-07 18:01:21,207 train 550 1.699795e-02 -0.770063
2019-11-07 18:01:31,026 train 600 1.698889e-02 -0.754190
2019-11-07 18:01:40,842 train 650 1.701639e-02 -0.746039
2019-11-07 18:01:50,678 train 700 1.701563e-02 -0.745613
2019-11-07 18:02:00,523 train 750 1.701859e-02 -0.732204
2019-11-07 18:02:10,348 train 800 1.702835e-02 -0.725110
2019-11-07 18:02:20,192 train 850 1.702083e-02 -0.743333
2019-11-07 18:02:23,139 training loss; R2: 1.701785e-02 -0.747332
2019-11-07 18:02:23,837 valid 000 1.469121e-02 -3.475359
2019-11-07 18:02:33,204 valid 050 1.617285e-02 -0.959460
2019-11-07 18:02:41,557 validation loss; R2: 1.617213e-02 -1.133612
2019-11-07 18:02:41,623 epoch 614 lr 1.000000e-05
2019-11-07 18:02:42,383 train 000 1.722540e-02 -0.108646
2019-11-07 18:02:52,183 train 050 1.712162e-02 -0.773952
2019-11-07 18:03:02,021 train 100 1.721340e-02 -0.651226
2019-11-07 18:03:11,884 train 150 1.718817e-02 -0.717125
2019-11-07 18:03:21,743 train 200 1.711844e-02 -0.692168
2019-11-07 18:03:31,602 train 250 1.705224e-02 -0.718010
2019-11-07 18:03:41,464 train 300 1.698048e-02 -0.744501
2019-11-07 18:03:51,319 train 350 1.702485e-02 -0.715833
2019-11-07 18:04:01,183 train 400 1.702507e-02 -0.692044
2019-11-07 18:04:11,055 train 450 1.698271e-02 -0.680378
2019-11-07 18:04:20,910 train 500 1.697142e-02 -4.032961
2019-11-07 18:04:30,760 train 550 1.699361e-02 -3.731770
2019-11-07 18:04:40,611 train 600 1.699522e-02 -3.475241
2019-11-07 18:04:50,423 train 650 1.699091e-02 -3.260436
2019-11-07 18:05:00,170 train 700 1.700510e-02 -3.068007
2019-11-07 18:05:09,935 train 750 1.703794e-02 -2.922444
2019-11-07 18:05:19,735 train 800 1.702985e-02 -2.771008
2019-11-07 18:05:29,538 train 850 1.701304e-02 -2.658086
2019-11-07 18:05:32,461 training loss; R2: 1.700942e-02 -2.616606
2019-11-07 18:05:33,108 valid 000 1.663528e-02 -1.237277
2019-11-07 18:05:42,507 valid 050 1.576221e-02 -1.092206
2019-11-07 18:05:50,856 validation loss; R2: 1.577049e-02 -1.109767
2019-11-07 18:05:50,922 epoch 615 lr 1.000000e-05
2019-11-07 18:05:51,650 train 000 1.699883e-02 -0.657592
2019-11-07 18:06:01,385 train 050 1.696566e-02 -0.786473
2019-11-07 18:06:11,127 train 100 1.680840e-02 -0.662442
2019-11-07 18:06:20,888 train 150 1.685753e-02 -0.810023
2019-11-07 18:06:30,644 train 200 1.685431e-02 -0.837856
2019-11-07 18:06:40,391 train 250 1.693377e-02 -0.825213
2019-11-07 18:06:50,148 train 300 1.695313e-02 -0.774609
2019-11-07 18:06:59,900 train 350 1.692277e-02 -0.748132
2019-11-07 18:07:09,667 train 400 1.695576e-02 -0.750587
2019-11-07 18:07:19,441 train 450 1.699962e-02 -0.745982
2019-11-07 18:07:29,224 train 500 1.699785e-02 -0.736450
2019-11-07 18:07:38,994 train 550 1.700492e-02 -0.750982
2019-11-07 18:07:48,763 train 600 1.701981e-02 -0.753946
2019-11-07 18:07:58,528 train 650 1.703222e-02 -0.753199
2019-11-07 18:08:08,295 train 700 1.702085e-02 -0.770155
2019-11-07 18:08:18,066 train 750 1.698705e-02 -0.751573
2019-11-07 18:08:27,847 train 800 1.698794e-02 -0.742186
2019-11-07 18:08:37,631 train 850 1.698044e-02 -0.729876
2019-11-07 18:08:40,591 training loss; R2: 1.697850e-02 -0.728404
2019-11-07 18:08:41,207 valid 000 1.841959e-02 -2.725469
2019-11-07 18:08:50,685 valid 050 1.793385e-02 -1.610958
2019-11-07 18:08:59,087 validation loss; R2: 1.771730e-02 -1.704975
2019-11-07 18:08:59,170 epoch 616 lr 1.000000e-05
2019-11-07 18:08:59,969 train 000 1.778634e-02 -0.081881
2019-11-07 18:09:10,031 train 050 1.710189e-02 -6.232659
2019-11-07 18:09:19,847 train 100 1.690853e-02 -3.414339
2019-11-07 18:09:29,666 train 150 1.696048e-02 -2.561336
2019-11-07 18:09:39,503 train 200 1.698136e-02 -2.054899
2019-11-07 18:09:49,336 train 250 1.694355e-02 -1.814839
2019-11-07 18:09:59,163 train 300 1.694568e-02 -1.663651
2019-11-07 18:10:08,995 train 350 1.698804e-02 -1.554905
2019-11-07 18:10:18,831 train 400 1.696961e-02 -1.436507
2019-11-07 18:10:28,659 train 450 1.703510e-02 -3.768938
2019-11-07 18:10:38,478 train 500 1.702195e-02 -3.527537
2019-11-07 18:10:48,238 train 550 1.699730e-02 -3.264791
2019-11-07 18:10:58,013 train 600 1.699053e-02 -3.059217
2019-11-07 18:11:07,791 train 650 1.697618e-02 -2.871597
2019-11-07 18:11:17,582 train 700 1.698443e-02 -2.727168
2019-11-07 18:11:27,357 train 750 1.697845e-02 -2.614487
2019-11-07 18:11:37,133 train 800 1.697952e-02 -2.501741
2019-11-07 18:11:46,909 train 850 1.701170e-02 -2.400011
2019-11-07 18:11:49,826 training loss; R2: 1.701595e-02 -2.365933
2019-11-07 18:11:50,452 valid 000 1.659777e-02 -0.756881
2019-11-07 18:11:59,870 valid 050 1.577090e-02 -1.063837
2019-11-07 18:12:08,178 validation loss; R2: 1.573020e-02 -0.953139
2019-11-07 18:12:08,244 epoch 617 lr 1.000000e-05
2019-11-07 18:12:09,018 train 000 1.482740e-02 -0.010530
2019-11-07 18:12:18,721 train 050 1.655721e-02 -0.481010
2019-11-07 18:12:28,443 train 100 1.673852e-02 -0.677920
2019-11-07 18:12:38,166 train 150 1.679042e-02 -0.689492
2019-11-07 18:12:47,912 train 200 1.683471e-02 -0.736557
2019-11-07 18:12:57,666 train 250 1.688838e-02 -0.686603
2019-11-07 18:13:07,415 train 300 1.688446e-02 -0.715913
2019-11-07 18:13:17,168 train 350 1.691272e-02 -0.708317
2019-11-07 18:13:26,934 train 400 1.693427e-02 -0.719788
2019-11-07 18:13:36,699 train 450 1.695547e-02 -0.697544
2019-11-07 18:13:46,467 train 500 1.697372e-02 -0.682420
2019-11-07 18:13:56,232 train 550 1.694269e-02 -0.698389
2019-11-07 18:14:05,998 train 600 1.699535e-02 -0.683266
2019-11-07 18:14:15,765 train 650 1.699599e-02 -0.669642
2019-11-07 18:14:25,538 train 700 1.700520e-02 -0.702220
2019-11-07 18:14:35,329 train 750 1.701158e-02 -0.713059
2019-11-07 18:14:45,151 train 800 1.700994e-02 -0.718208
2019-11-07 18:14:54,949 train 850 1.703000e-02 -0.720136
2019-11-07 18:14:57,877 training loss; R2: 1.702616e-02 -0.718052
2019-11-07 18:14:58,475 valid 000 1.681453e-02 -0.208939
2019-11-07 18:15:07,865 valid 050 1.652399e-02 -1.282121
2019-11-07 18:15:16,267 validation loss; R2: 1.647076e-02 -1.248074
2019-11-07 18:15:16,335 epoch 618 lr 1.000000e-05
2019-11-07 18:15:17,080 train 000 1.663328e-02 -2.862873
2019-11-07 18:15:26,817 train 050 1.710752e-02 -0.821459
2019-11-07 18:15:36,553 train 100 1.705139e-02 -0.866423
2019-11-07 18:15:46,316 train 150 1.696538e-02 -0.795859
2019-11-07 18:15:56,078 train 200 1.704749e-02 -0.837422
2019-11-07 18:16:05,854 train 250 1.695710e-02 -0.842616
2019-11-07 18:16:15,626 train 300 1.698754e-02 -0.866138
2019-11-07 18:16:25,410 train 350 1.703029e-02 -1.109844
2019-11-07 18:16:35,194 train 400 1.705991e-02 -1.086497
2019-11-07 18:16:44,990 train 450 1.701590e-02 -1.051167
2019-11-07 18:16:54,775 train 500 1.701866e-02 -1.041012
2019-11-07 18:17:04,576 train 550 1.702029e-02 -1.005750
2019-11-07 18:17:14,371 train 600 1.703101e-02 -0.984634
2019-11-07 18:17:24,169 train 650 1.700924e-02 -1.564580
2019-11-07 18:17:33,968 train 700 1.702521e-02 -1.487504
2019-11-07 18:17:43,753 train 750 1.702239e-02 -1.449782
2019-11-07 18:17:53,551 train 800 1.699163e-02 -1.411452
2019-11-07 18:18:03,345 train 850 1.696809e-02 -1.376875
2019-11-07 18:18:06,284 training loss; R2: 1.697101e-02 -1.362592
2019-11-07 18:18:06,985 valid 000 1.632196e-02 -0.282549
2019-11-07 18:18:16,355 valid 050 1.654080e-02 -0.824006
2019-11-07 18:18:24,712 validation loss; R2: 1.650356e-02 -0.946463
2019-11-07 18:18:24,780 epoch 619 lr 1.000000e-05
2019-11-07 18:18:25,598 train 000 1.574753e-02 -0.838398
2019-11-07 18:18:35,299 train 050 1.687740e-02 -1.019136
2019-11-07 18:18:45,029 train 100 1.695823e-02 -0.770187
2019-11-07 18:18:54,778 train 150 1.683341e-02 -0.689200
2019-11-07 18:19:04,524 train 200 1.688402e-02 -0.707627
2019-11-07 18:19:14,288 train 250 1.687326e-02 -0.707712
2019-11-07 18:19:24,098 train 300 1.686473e-02 -0.711651
2019-11-07 18:19:33,916 train 350 1.690686e-02 -0.688466
2019-11-07 18:19:43,737 train 400 1.689100e-02 -0.681139
2019-11-07 18:19:53,545 train 450 1.688420e-02 -0.878586
2019-11-07 18:20:03,350 train 500 1.689843e-02 -0.871088
2019-11-07 18:20:13,129 train 550 1.691378e-02 -0.872813
2019-11-07 18:20:22,919 train 600 1.691607e-02 -0.879344
2019-11-07 18:20:32,708 train 650 1.691258e-02 -0.849646
2019-11-07 18:20:42,503 train 700 1.691387e-02 -0.874803
2019-11-07 18:20:52,291 train 750 1.693885e-02 -0.853093
2019-11-07 18:21:02,089 train 800 1.694962e-02 -0.840328
2019-11-07 18:21:11,889 train 850 1.691965e-02 -0.831064
2019-11-07 18:21:14,817 training loss; R2: 1.692069e-02 -0.829879
2019-11-07 18:21:15,440 valid 000 2.324515e-02 -0.309313
2019-11-07 18:21:24,896 valid 050 2.009096e-02 -2.136605
2019-11-07 18:21:33,309 validation loss; R2: 1.995071e-02 -2.095213
2019-11-07 18:21:33,375 epoch 620 lr 1.000000e-05
2019-11-07 18:21:34,145 train 000 1.945064e-02 -0.099805
2019-11-07 18:21:43,891 train 050 1.682942e-02 -1.090374
2019-11-07 18:21:53,660 train 100 1.687315e-02 -1.739583
2019-11-07 18:22:03,452 train 150 1.690033e-02 -1.405023
2019-11-07 18:22:13,249 train 200 1.686931e-02 -1.186429
2019-11-07 18:22:23,060 train 250 1.699444e-02 -1.148432
2019-11-07 18:22:32,860 train 300 1.700848e-02 -1.069236
2019-11-07 18:22:42,680 train 350 1.704350e-02 -1.015472
2019-11-07 18:22:52,539 train 400 1.703332e-02 -0.979903
2019-11-07 18:23:02,369 train 450 1.699185e-02 -0.971822
2019-11-07 18:23:12,197 train 500 1.697947e-02 -0.943933
2019-11-07 18:23:22,048 train 550 1.696814e-02 -0.925503
2019-11-07 18:23:31,892 train 600 1.695937e-02 -0.924492
2019-11-07 18:23:41,714 train 650 1.695893e-02 -0.917678
2019-11-07 18:23:51,552 train 700 1.695018e-02 -0.897832
2019-11-07 18:24:01,395 train 750 1.698590e-02 -0.904921
2019-11-07 18:24:11,227 train 800 1.700309e-02 -0.900671
2019-11-07 18:24:21,074 train 850 1.697402e-02 -0.883752
2019-11-07 18:24:24,009 training loss; R2: 1.696756e-02 -0.886576
2019-11-07 18:24:24,696 valid 000 1.520651e-02 -1.007556
2019-11-07 18:24:34,130 valid 050 1.647236e-02 -1.171703
2019-11-07 18:24:42,489 validation loss; R2: 1.667731e-02 -1.297672
2019-11-07 18:24:42,555 epoch 621 lr 1.000000e-05
2019-11-07 18:24:43,326 train 000 1.535662e-02 0.023924
2019-11-07 18:24:53,082 train 050 1.719060e-02 -0.535869
2019-11-07 18:25:02,845 train 100 1.705203e-02 -0.595470
2019-11-07 18:25:12,620 train 150 1.686438e-02 -0.667027
2019-11-07 18:25:22,411 train 200 1.676855e-02 -0.698855
2019-11-07 18:25:32,199 train 250 1.672560e-02 -0.697237
2019-11-07 18:25:41,995 train 300 1.676566e-02 -0.677929
2019-11-07 18:25:51,795 train 350 1.679022e-02 -0.694945
2019-11-07 18:26:01,598 train 400 1.677330e-02 -0.674316
2019-11-07 18:26:11,401 train 450 1.680886e-02 -0.712163
2019-11-07 18:26:21,203 train 500 1.685198e-02 -0.749450
2019-11-07 18:26:30,998 train 550 1.684416e-02 -0.728127
2019-11-07 18:26:40,803 train 600 1.690416e-02 -0.732616
2019-11-07 18:26:50,610 train 650 1.691570e-02 -0.725058
2019-11-07 18:27:00,407 train 700 1.694448e-02 -0.736900
2019-11-07 18:27:10,218 train 750 1.696017e-02 -0.756822
2019-11-07 18:27:20,019 train 800 1.692823e-02 -0.842730
2019-11-07 18:27:29,835 train 850 1.692698e-02 -0.824677
2019-11-07 18:27:32,768 training loss; R2: 1.693563e-02 -0.820116
2019-11-07 18:27:33,454 valid 000 1.518025e-02 -0.187261
2019-11-07 18:27:42,890 valid 050 1.531887e-02 -0.976724
2019-11-07 18:27:51,218 validation loss; R2: 1.538342e-02 -1.099810
2019-11-07 18:27:51,282 epoch 622 lr 1.000000e-05
2019-11-07 18:27:52,023 train 000 1.441027e-02 -2.725530
2019-11-07 18:28:01,774 train 050 1.711599e-02 -0.725302
2019-11-07 18:28:11,551 train 100 1.707677e-02 -0.781493
2019-11-07 18:28:21,307 train 150 1.698849e-02 -0.779213
2019-11-07 18:28:31,093 train 200 1.697612e-02 -0.777291
2019-11-07 18:28:40,897 train 250 1.699249e-02 -0.786975
2019-11-07 18:28:50,720 train 300 1.697459e-02 -0.763503
2019-11-07 18:29:00,537 train 350 1.694521e-02 -0.906819
2019-11-07 18:29:10,324 train 400 1.693803e-02 -0.951189
2019-11-07 18:29:20,125 train 450 1.695874e-02 -0.924530
2019-11-07 18:29:29,947 train 500 1.695600e-02 -0.918650
2019-11-07 18:29:39,772 train 550 1.697058e-02 -0.897975
2019-11-07 18:29:49,611 train 600 1.694137e-02 -0.867624
2019-11-07 18:29:59,436 train 650 1.699484e-02 -0.913915
2019-11-07 18:30:09,261 train 700 1.696143e-02 -0.912426
2019-11-07 18:30:19,087 train 750 1.695947e-02 -0.878977
2019-11-07 18:30:28,911 train 800 1.694543e-02 -0.869581
2019-11-07 18:30:38,734 train 850 1.695661e-02 -0.852429
2019-11-07 18:30:41,669 training loss; R2: 1.696718e-02 -0.849908
2019-11-07 18:30:42,241 valid 000 1.463624e-02 -0.356604
2019-11-07 18:30:51,664 valid 050 1.653260e-02 -1.079514
2019-11-07 18:31:00,041 validation loss; R2: 1.667739e-02 -1.313000
2019-11-07 18:31:00,104 epoch 623 lr 1.000000e-05
2019-11-07 18:31:00,888 train 000 1.547754e-02 -0.128026
2019-11-07 18:31:10,618 train 050 1.710896e-02 -0.595474
2019-11-07 18:31:20,382 train 100 1.706842e-02 -0.650520
2019-11-07 18:31:30,159 train 150 1.704840e-02 -0.755586
2019-11-07 18:31:39,938 train 200 1.695168e-02 -0.709829
2019-11-07 18:31:49,716 train 250 1.697418e-02 -0.692441
2019-11-07 18:31:59,498 train 300 1.697825e-02 -0.672197
2019-11-07 18:32:09,286 train 350 1.699408e-02 -0.752647
2019-11-07 18:32:19,077 train 400 1.700524e-02 -0.771539
2019-11-07 18:32:28,866 train 450 1.701624e-02 -0.769913
2019-11-07 18:32:38,650 train 500 1.698145e-02 -0.756847
2019-11-07 18:32:48,449 train 550 1.700321e-02 -0.791204
2019-11-07 18:32:58,257 train 600 1.702070e-02 -0.794414
2019-11-07 18:33:08,065 train 650 1.701863e-02 -0.775137
2019-11-07 18:33:17,864 train 700 1.701784e-02 -0.767701
2019-11-07 18:33:27,665 train 750 1.700443e-02 -0.758859
2019-11-07 18:33:37,471 train 800 1.699596e-02 -0.754672
2019-11-07 18:33:47,267 train 850 1.703423e-02 -0.752702
2019-11-07 18:33:50,196 training loss; R2: 1.703593e-02 -0.757795
2019-11-07 18:33:50,822 valid 000 1.753542e-02 -0.027839
2019-11-07 18:34:00,267 valid 050 1.589394e-02 -1.315117
2019-11-07 18:34:08,591 validation loss; R2: 1.579676e-02 -1.354753
2019-11-07 18:34:08,655 epoch 624 lr 1.000000e-05
2019-11-07 18:34:09,419 train 000 1.927614e-02 -0.064282
2019-11-07 18:34:19,141 train 050 1.702398e-02 -0.769814
2019-11-07 18:34:28,865 train 100 1.697245e-02 -0.733513
2019-11-07 18:34:38,614 train 150 1.700218e-02 -1.042114
2019-11-07 18:34:48,382 train 200 1.697979e-02 -0.950209
2019-11-07 18:34:58,154 train 250 1.698909e-02 -0.868319
2019-11-07 18:35:07,945 train 300 1.697684e-02 -0.844713
2019-11-07 18:35:17,742 train 350 1.694248e-02 -0.858659
2019-11-07 18:35:27,525 train 400 1.691426e-02 -0.852680
2019-11-07 18:35:37,311 train 450 1.692787e-02 -0.820972
2019-11-07 18:35:47,097 train 500 1.689728e-02 -0.792023
2019-11-07 18:35:56,881 train 550 1.688509e-02 -0.768808
2019-11-07 18:36:06,674 train 600 1.688543e-02 -0.764733
2019-11-07 18:36:16,462 train 650 1.689164e-02 -0.773967
2019-11-07 18:36:26,251 train 700 1.689268e-02 -0.779614
2019-11-07 18:36:36,042 train 750 1.692013e-02 -0.773683
2019-11-07 18:36:45,839 train 800 1.689894e-02 -0.762748
2019-11-07 18:36:55,635 train 850 1.692791e-02 -0.763761
2019-11-07 18:36:58,570 training loss; R2: 1.693950e-02 -0.761006
2019-11-07 18:36:59,266 valid 000 2.009922e-02 -0.515017
2019-11-07 18:37:08,658 valid 050 1.640244e-02 -1.046920
2019-11-07 18:37:16,973 validation loss; R2: 1.630584e-02 -0.899514
2019-11-07 18:37:17,040 epoch 625 lr 1.000000e-05
2019-11-07 18:37:17,820 train 000 1.809064e-02 -0.065658
2019-11-07 18:37:27,534 train 050 1.724523e-02 -0.634758
2019-11-07 18:37:37,253 train 100 1.701440e-02 -0.665812
2019-11-07 18:37:47,005 train 150 1.688101e-02 -0.654585
2019-11-07 18:37:56,751 train 200 1.688050e-02 -0.741212
2019-11-07 18:38:06,503 train 250 1.690472e-02 -0.728918
2019-11-07 18:38:16,282 train 300 1.694287e-02 -1.571619
2019-11-07 18:38:26,071 train 350 1.687937e-02 -1.449697
2019-11-07 18:38:35,875 train 400 1.682995e-02 -1.370113
2019-11-07 18:38:45,662 train 450 1.680975e-02 -1.281705
2019-11-07 18:38:55,457 train 500 1.681368e-02 -1.228356
2019-11-07 18:39:05,245 train 550 1.679609e-02 -1.169778
2019-11-07 18:39:15,032 train 600 1.677962e-02 -1.108704
2019-11-07 18:39:24,817 train 650 1.678999e-02 -1.106941
2019-11-07 18:39:34,615 train 700 1.681828e-02 -1.083006
2019-11-07 18:39:44,424 train 750 1.682970e-02 -1.077662
2019-11-07 18:39:54,220 train 800 1.685764e-02 -1.086852
2019-11-07 18:40:04,025 train 850 1.690151e-02 -1.141043
2019-11-07 18:40:06,943 training loss; R2: 1.689968e-02 -1.128400
2019-11-07 18:40:07,587 valid 000 1.705776e-02 -0.493596
2019-11-07 18:40:16,990 valid 050 1.612445e-02 -1.042792
2019-11-07 18:40:25,293 validation loss; R2: 1.599285e-02 -1.060734
2019-11-07 18:40:25,361 epoch 626 lr 1.000000e-05
2019-11-07 18:40:26,135 train 000 1.985390e-02 -0.200114
2019-11-07 18:40:35,868 train 050 1.716214e-02 -0.589561
2019-11-07 18:40:45,617 train 100 1.707734e-02 -0.626436
2019-11-07 18:40:55,379 train 150 1.693793e-02 -0.651645
2019-11-07 18:41:05,148 train 200 1.703163e-02 -0.694206
2019-11-07 18:41:14,919 train 250 1.701503e-02 -0.674612
2019-11-07 18:41:24,690 train 300 1.710829e-02 -0.698886
2019-11-07 18:41:34,486 train 350 1.713695e-02 -0.708211
2019-11-07 18:41:44,277 train 400 1.707194e-02 -0.705673
2019-11-07 18:41:54,076 train 450 1.708358e-02 -0.702522
2019-11-07 18:42:03,881 train 500 1.707996e-02 -0.819994
2019-11-07 18:42:13,662 train 550 1.707787e-02 -0.811841
2019-11-07 18:42:23,465 train 600 1.704209e-02 -0.816071
2019-11-07 18:42:33,290 train 650 1.703712e-02 -0.799595
2019-11-07 18:42:43,114 train 700 1.702878e-02 -0.794440
2019-11-07 18:42:52,948 train 750 1.701432e-02 -0.797441
2019-11-07 18:43:02,760 train 800 1.699898e-02 -0.822358
2019-11-07 18:43:12,570 train 850 1.698685e-02 -0.821041
2019-11-07 18:43:15,513 training loss; R2: 1.700441e-02 -0.813656
2019-11-07 18:43:16,194 valid 000 2.012549e-02 -0.315990
2019-11-07 18:43:25,570 valid 050 1.795900e-02 -1.230966
2019-11-07 18:43:34,058 validation loss; R2: 1.793081e-02 -1.462075
2019-11-07 18:43:34,126 epoch 627 lr 1.000000e-05
2019-11-07 18:43:34,947 train 000 1.930943e-02 -0.578850
2019-11-07 18:43:44,691 train 050 1.725622e-02 -0.696469
2019-11-07 18:43:54,445 train 100 1.704252e-02 -0.712697
2019-11-07 18:44:04,240 train 150 1.705958e-02 -0.747449
2019-11-07 18:44:14,023 train 200 1.722813e-02 -0.756206
2019-11-07 18:44:24,126 train 250 1.706988e-02 -0.731523
2019-11-07 18:44:34,270 train 300 1.705069e-02 -0.743158
2019-11-07 18:44:44,394 train 350 1.698109e-02 -0.714899
2019-11-07 18:44:54,537 train 400 1.699716e-02 -0.712563
2019-11-07 18:45:04,697 train 450 1.699095e-02 -0.717094
2019-11-07 18:45:14,846 train 500 1.699992e-02 -0.735280
2019-11-07 18:45:24,996 train 550 1.701152e-02 -0.731744
2019-11-07 18:45:35,176 train 600 1.702875e-02 -0.736009
2019-11-07 18:45:45,341 train 650 1.702695e-02 -0.728770
2019-11-07 18:45:55,524 train 700 1.702425e-02 -0.732565
2019-11-07 18:46:05,712 train 750 1.702632e-02 -0.721059
2019-11-07 18:46:15,887 train 800 1.699698e-02 -0.720498
2019-11-07 18:46:26,082 train 850 1.702564e-02 -31.684756
2019-11-07 18:46:29,130 training loss; R2: 1.702576e-02 -31.146247
2019-11-07 18:46:29,787 valid 000 1.480812e-02 -1.236184
2019-11-07 18:46:39,215 valid 050 1.623951e-02 -1.206261
2019-11-07 18:46:47,535 validation loss; R2: 1.611195e-02 -1.276970
2019-11-07 18:46:47,614 epoch 628 lr 1.000000e-05
2019-11-07 18:46:48,437 train 000 1.465033e-02 -0.205352
2019-11-07 18:46:58,184 train 050 1.689184e-02 -0.632552
2019-11-07 18:47:07,948 train 100 1.675804e-02 -0.647509
2019-11-07 18:47:17,736 train 150 1.696328e-02 -0.563778
2019-11-07 18:47:27,535 train 200 1.688305e-02 -0.561610
2019-11-07 18:47:37,322 train 250 1.694374e-02 -0.616579
2019-11-07 18:47:47,114 train 300 1.693771e-02 -0.601086
2019-11-07 18:47:56,909 train 350 1.695738e-02 -0.649399
2019-11-07 18:48:06,699 train 400 1.694648e-02 -0.678003
2019-11-07 18:48:16,487 train 450 1.695009e-02 -0.651469
2019-11-07 18:48:26,289 train 500 1.699673e-02 -0.658175
2019-11-07 18:48:36,094 train 550 1.697916e-02 -0.645699
2019-11-07 18:48:45,892 train 600 1.695911e-02 -0.639258
2019-11-07 18:48:55,697 train 650 1.697092e-02 -0.630228
2019-11-07 18:49:05,504 train 700 1.698371e-02 -0.651791
2019-11-07 18:49:15,297 train 750 1.698904e-02 -0.672541
2019-11-07 18:49:25,107 train 800 1.698682e-02 -1.105994
2019-11-07 18:49:34,892 train 850 1.698400e-02 -17.520469
2019-11-07 18:49:37,856 training loss; R2: 1.698081e-02 -17.231842
2019-11-07 18:49:38,504 valid 000 1.636420e-02 -0.550193
2019-11-07 18:49:47,920 valid 050 1.593667e-02 -0.786187
2019-11-07 18:49:56,241 validation loss; R2: 1.603450e-02 -0.843922
2019-11-07 18:49:56,315 epoch 629 lr 1.000000e-05
2019-11-07 18:49:57,103 train 000 1.745749e-02 -0.370165
2019-11-07 18:50:06,860 train 050 1.674819e-02 -0.846168
2019-11-07 18:50:16,633 train 100 1.678322e-02 -0.775678
2019-11-07 18:50:26,402 train 150 1.684712e-02 -0.729970
2019-11-07 18:50:36,176 train 200 1.690207e-02 -0.906625
2019-11-07 18:50:45,956 train 250 1.695051e-02 -0.852459
2019-11-07 18:50:55,729 train 300 1.696471e-02 -0.807079
2019-11-07 18:51:05,505 train 350 1.690495e-02 -0.841835
2019-11-07 18:51:15,286 train 400 1.691716e-02 -1.319425
2019-11-07 18:51:25,073 train 450 1.696217e-02 -1.244118
2019-11-07 18:51:34,873 train 500 1.700560e-02 -1.240735
2019-11-07 18:51:44,679 train 550 1.694786e-02 -1.185408
2019-11-07 18:51:54,491 train 600 1.694225e-02 -1.138584
2019-11-07 18:52:04,296 train 650 1.700630e-02 -1.126986
2019-11-07 18:52:14,100 train 700 1.699732e-02 -1.093914
2019-11-07 18:52:23,905 train 750 1.700326e-02 -1.074249
2019-11-07 18:52:33,720 train 800 1.700240e-02 -1.049849
2019-11-07 18:52:43,526 train 850 1.699918e-02 -1.014939
2019-11-07 18:52:46,482 training loss; R2: 1.699687e-02 -1.015364
2019-11-07 18:52:47,137 valid 000 1.798432e-02 -0.186748
2019-11-07 18:52:56,568 valid 050 1.549242e-02 -1.008432
2019-11-07 18:53:04,882 validation loss; R2: 1.540719e-02 -0.854077
2019-11-07 18:53:04,958 epoch 630 lr 1.000000e-05
2019-11-07 18:53:05,818 train 000 1.575882e-02 -0.257230
2019-11-07 18:53:15,567 train 050 1.685504e-02 -0.574377
2019-11-07 18:53:25,313 train 100 1.690902e-02 -0.524861
2019-11-07 18:53:35,104 train 150 1.693248e-02 -0.602916
2019-11-07 18:53:44,873 train 200 1.689236e-02 -0.670223
2019-11-07 18:53:54,662 train 250 1.677904e-02 -0.785201
2019-11-07 18:54:04,444 train 300 1.683153e-02 -0.763014
2019-11-07 18:54:14,212 train 350 1.678687e-02 -0.765969
2019-11-07 18:54:23,979 train 400 1.676993e-02 -0.725549
2019-11-07 18:54:33,735 train 450 1.679983e-02 -0.724831
2019-11-07 18:54:43,498 train 500 1.682266e-02 -0.733162
2019-11-07 18:54:53,263 train 550 1.684694e-02 -0.745213
2019-11-07 18:55:03,032 train 600 1.685961e-02 -0.742723
2019-11-07 18:55:12,788 train 650 1.684295e-02 -0.728667
2019-11-07 18:55:22,538 train 700 1.686389e-02 -0.744373
2019-11-07 18:55:32,293 train 750 1.686280e-02 -0.741384
2019-11-07 18:55:42,063 train 800 1.689090e-02 -0.756179
2019-11-07 18:55:51,825 train 850 1.691166e-02 -0.757293
2019-11-07 18:55:54,741 training loss; R2: 1.691949e-02 -0.750155
2019-11-07 18:55:55,359 valid 000 1.837980e-02 -1.658972
2019-11-07 18:56:04,812 valid 050 1.719705e-02 -1.836484
2019-11-07 18:56:13,143 validation loss; R2: 1.725476e-02 -1.943309
2019-11-07 18:56:13,203 epoch 631 lr 1.000000e-05
2019-11-07 18:56:13,954 train 000 1.928413e-02 -0.019965
2019-11-07 18:56:23,666 train 050 1.707926e-02 -0.759794
2019-11-07 18:56:33,382 train 100 1.700116e-02 -0.594406
2019-11-07 18:56:43,096 train 150 1.687850e-02 -0.571565
2019-11-07 18:56:52,829 train 200 1.694930e-02 -0.558207
2019-11-07 18:57:02,559 train 250 1.699310e-02 -0.575237
2019-11-07 18:57:12,297 train 300 1.701500e-02 -0.613054
2019-11-07 18:57:22,031 train 350 1.702821e-02 -0.636030
2019-11-07 18:57:31,787 train 400 1.697578e-02 -0.710314
2019-11-07 18:57:41,532 train 450 1.701019e-02 -0.817223
2019-11-07 18:57:51,286 train 500 1.700495e-02 -0.866438
2019-11-07 18:58:01,050 train 550 1.701476e-02 -0.876657
2019-11-07 18:58:10,802 train 600 1.698528e-02 -0.891018
2019-11-07 18:58:20,548 train 650 1.696219e-02 -0.899346
2019-11-07 18:58:30,298 train 700 1.696089e-02 -0.885117
2019-11-07 18:58:40,057 train 750 1.700394e-02 -0.878805
2019-11-07 18:58:49,826 train 800 1.700770e-02 -0.866638
2019-11-07 18:58:59,595 train 850 1.701499e-02 -0.861630
2019-11-07 18:59:02,514 training loss; R2: 1.701018e-02 -0.861080
2019-11-07 18:59:03,152 valid 000 2.033205e-02 -0.427737
2019-11-07 18:59:12,597 valid 050 1.606794e-02 -1.563661
2019-11-07 18:59:20,903 validation loss; R2: 1.622904e-02 -1.340054
2019-11-07 18:59:20,967 epoch 632 lr 1.000000e-05
2019-11-07 18:59:21,724 train 000 1.548201e-02 0.059155
2019-11-07 18:59:31,439 train 050 1.710986e-02 -0.578455
2019-11-07 18:59:41,160 train 100 1.715163e-02 -0.631002
2019-11-07 18:59:50,893 train 150 1.711652e-02 -0.639526
2019-11-07 19:00:00,632 train 200 1.708654e-02 -0.615651
2019-11-07 19:00:10,375 train 250 1.706081e-02 -0.660705
2019-11-07 19:00:20,163 train 300 1.703189e-02 -0.676019
2019-11-07 19:00:29,973 train 350 1.701781e-02 -0.724266
2019-11-07 19:00:40,050 train 400 1.702401e-02 -0.727060
2019-11-07 19:00:50,222 train 450 1.693945e-02 -0.747993
2019-11-07 19:01:00,398 train 500 1.693602e-02 -0.726327
2019-11-07 19:01:10,579 train 550 1.696199e-02 -0.725894
2019-11-07 19:01:20,753 train 600 1.695405e-02 -0.774895
2019-11-07 19:01:30,917 train 650 1.695400e-02 -0.764283
2019-11-07 19:01:41,071 train 700 1.695504e-02 -0.755331
2019-11-07 19:01:51,218 train 750 1.695228e-02 -0.745914
2019-11-07 19:02:01,371 train 800 1.695152e-02 -0.740267
2019-11-07 19:02:11,530 train 850 1.696694e-02 -0.772068
2019-11-07 19:02:14,563 training loss; R2: 1.695820e-02 -0.772442
2019-11-07 19:02:15,229 valid 000 1.389014e-02 -0.693866
2019-11-07 19:02:24,616 valid 050 1.519225e-02 -0.865885
2019-11-07 19:02:33,042 validation loss; R2: 1.524740e-02 -0.916791
2019-11-07 19:02:33,111 epoch 633 lr 1.000000e-05
2019-11-07 19:02:33,876 train 000 1.700346e-02 -0.441192
2019-11-07 19:02:43,988 train 050 1.697986e-02 -0.968927
2019-11-07 19:02:54,158 train 100 1.694492e-02 -0.796164
2019-11-07 19:03:04,297 train 150 1.688950e-02 -0.724702
2019-11-07 19:03:14,440 train 200 1.685126e-02 -0.728539
2019-11-07 19:03:24,597 train 250 1.687402e-02 -0.747233
2019-11-07 19:03:34,770 train 300 1.685193e-02 -0.741463
2019-11-07 19:03:44,913 train 350 1.687392e-02 -0.729746
2019-11-07 19:03:55,081 train 400 1.686811e-02 -0.706746
2019-11-07 19:04:05,261 train 450 1.687876e-02 -0.705973
2019-11-07 19:04:15,450 train 500 1.685259e-02 -0.699245
2019-11-07 19:04:25,620 train 550 1.686762e-02 -0.674118
2019-11-07 19:04:35,799 train 600 1.689694e-02 -0.669795
2019-11-07 19:04:45,977 train 650 1.691004e-02 -0.673511
2019-11-07 19:04:56,168 train 700 1.690884e-02 -0.665390
2019-11-07 19:05:06,355 train 750 1.693690e-02 -0.673958
2019-11-07 19:05:16,533 train 800 1.694560e-02 -0.674755
2019-11-07 19:05:26,722 train 850 1.695499e-02 -0.663780
2019-11-07 19:05:29,757 training loss; R2: 1.695389e-02 -0.661921
2019-11-07 19:05:30,440 valid 000 1.811747e-02 0.032566
2019-11-07 19:05:39,828 valid 050 1.634530e-02 -1.016897
2019-11-07 19:05:48,164 validation loss; R2: 1.637396e-02 -0.988692
2019-11-07 19:05:48,232 epoch 634 lr 1.000000e-05
2019-11-07 19:05:48,966 train 000 1.788752e-02 -0.768428
2019-11-07 19:05:59,120 train 050 1.703601e-02 -0.570961
2019-11-07 19:06:09,301 train 100 1.680174e-02 -0.759049
2019-11-07 19:06:19,190 train 150 1.678723e-02 -0.825114
2019-11-07 19:06:28,997 train 200 1.676666e-02 -1.065334
2019-11-07 19:06:38,794 train 250 1.676485e-02 -0.980288
2019-11-07 19:06:48,596 train 300 1.678291e-02 -0.949856
2019-11-07 19:06:58,411 train 350 1.679279e-02 -0.904870
2019-11-07 19:07:08,225 train 400 1.681680e-02 -0.908492
2019-11-07 19:07:18,062 train 450 1.683861e-02 -0.877019
2019-11-07 19:07:27,900 train 500 1.681875e-02 -0.858374
2019-11-07 19:07:37,736 train 550 1.685939e-02 -0.850520
2019-11-07 19:07:47,564 train 600 1.685995e-02 -0.838385
2019-11-07 19:07:57,384 train 650 1.685684e-02 -0.818377
2019-11-07 19:08:07,215 train 700 1.687065e-02 -0.815056
2019-11-07 19:08:17,048 train 750 1.689481e-02 -0.812869
2019-11-07 19:08:26,884 train 800 1.692974e-02 -0.799530
2019-11-07 19:08:36,724 train 850 1.694844e-02 -0.790868
2019-11-07 19:08:39,662 training loss; R2: 1.694549e-02 -0.781990
2019-11-07 19:08:40,325 valid 000 1.799551e-02 -0.511075
2019-11-07 19:08:49,731 valid 050 1.587683e-02 -1.085461
2019-11-07 19:08:58,054 validation loss; R2: 1.577429e-02 -1.363184
2019-11-07 19:08:58,122 epoch 635 lr 1.000000e-05
2019-11-07 19:08:58,851 train 000 1.629446e-02 -0.755468
2019-11-07 19:09:08,634 train 050 1.729726e-02 -0.914285
2019-11-07 19:09:18,425 train 100 1.695722e-02 -0.699485
2019-11-07 19:09:28,233 train 150 1.690090e-02 -0.667470
2019-11-07 19:09:38,047 train 200 1.687497e-02 -0.689942
2019-11-07 19:09:47,846 train 250 1.692003e-02 -1.009105
2019-11-07 19:09:57,654 train 300 1.693019e-02 -0.989497
2019-11-07 19:10:07,484 train 350 1.692270e-02 -0.955265
2019-11-07 19:10:17,305 train 400 1.691301e-02 -0.948922
2019-11-07 19:10:27,133 train 450 1.693222e-02 -0.912603
2019-11-07 19:10:36,948 train 500 1.693427e-02 -0.884142
2019-11-07 19:10:46,774 train 550 1.695592e-02 -0.864624
2019-11-07 19:10:56,607 train 600 1.693981e-02 -0.865272
2019-11-07 19:11:06,430 train 650 1.694536e-02 -0.873904
2019-11-07 19:11:16,254 train 700 1.692983e-02 -0.882432
2019-11-07 19:11:26,082 train 750 1.689811e-02 -0.856013
2019-11-07 19:11:35,911 train 800 1.686181e-02 -0.852605
2019-11-07 19:11:45,740 train 850 1.685577e-02 -0.844450
2019-11-07 19:11:48,678 training loss; R2: 1.685613e-02 -0.847332
2019-11-07 19:11:49,358 valid 000 1.817226e-02 -0.440355
2019-11-07 19:11:58,716 valid 050 1.629272e-02 -1.178092
2019-11-07 19:12:07,127 validation loss; R2: 1.648877e-02 -1.356389
2019-11-07 19:12:07,192 epoch 636 lr 1.000000e-05
2019-11-07 19:12:08,050 train 000 1.568917e-02 0.008821
2019-11-07 19:12:17,793 train 050 1.702315e-02 -0.645798
2019-11-07 19:12:27,582 train 100 1.691670e-02 -0.590066
2019-11-07 19:12:37,396 train 150 1.696422e-02 -0.587863
2019-11-07 19:12:47,202 train 200 1.698000e-02 -0.612608
2019-11-07 19:12:56,993 train 250 1.697964e-02 -0.642064
2019-11-07 19:13:06,788 train 300 1.699034e-02 -0.660746
2019-11-07 19:13:16,595 train 350 1.698572e-02 -0.666609
2019-11-07 19:13:26,392 train 400 1.698090e-02 -0.676590
2019-11-07 19:13:36,198 train 450 1.701015e-02 -0.674667
2019-11-07 19:13:45,996 train 500 1.701471e-02 -0.674144
2019-11-07 19:13:55,800 train 550 1.703114e-02 -0.660601
2019-11-07 19:14:05,606 train 600 1.704998e-02 -0.669745
2019-11-07 19:14:15,406 train 650 1.709323e-02 -0.674012
2019-11-07 19:14:25,200 train 700 1.706841e-02 -0.764721
2019-11-07 19:14:35,005 train 750 1.706381e-02 -0.768293
2019-11-07 19:14:44,814 train 800 1.702935e-02 -0.759317
2019-11-07 19:14:54,617 train 850 1.702216e-02 -0.767709
2019-11-07 19:14:57,547 training loss; R2: 1.702058e-02 -0.763369
2019-11-07 19:14:58,187 valid 000 1.505500e-02 -0.158179
2019-11-07 19:15:07,626 valid 050 1.603068e-02 -0.796670
2019-11-07 19:15:15,954 validation loss; R2: 1.607631e-02 -0.986361
2019-11-07 19:15:16,021 epoch 637 lr 1.000000e-05
2019-11-07 19:15:16,860 train 000 1.491403e-02 0.133423
2019-11-07 19:15:26,603 train 050 1.734030e-02 -0.908328
2019-11-07 19:15:36,381 train 100 1.691024e-02 -0.751078
2019-11-07 19:15:46,169 train 150 1.706689e-02 -0.781206
2019-11-07 19:15:55,941 train 200 1.694583e-02 -0.721298
2019-11-07 19:16:05,744 train 250 1.704323e-02 -0.732414
2019-11-07 19:16:15,571 train 300 1.701755e-02 -0.736254
2019-11-07 19:16:25,396 train 350 1.705609e-02 -0.719534
2019-11-07 19:16:35,214 train 400 1.709169e-02 -0.715643
2019-11-07 19:16:45,031 train 450 1.705240e-02 -0.747034
2019-11-07 19:16:54,852 train 500 1.705511e-02 -0.788905
2019-11-07 19:17:04,667 train 550 1.705256e-02 -0.776535
2019-11-07 19:17:14,487 train 600 1.703476e-02 -0.742058
2019-11-07 19:17:24,299 train 650 1.699732e-02 -0.729972
2019-11-07 19:17:34,113 train 700 1.699771e-02 -0.722955
2019-11-07 19:17:43,896 train 750 1.698980e-02 -0.722974
2019-11-07 19:17:53,678 train 800 1.698496e-02 -0.723481
2019-11-07 19:18:03,467 train 850 1.702004e-02 -0.722910
2019-11-07 19:18:06,397 training loss; R2: 1.700688e-02 -0.731698
2019-11-07 19:18:07,096 valid 000 1.532725e-02 -10.631772
2019-11-07 19:18:16,472 valid 050 1.566488e-02 -1.451475
2019-11-07 19:18:24,817 validation loss; R2: 1.568439e-02 -2.036204
2019-11-07 19:18:24,884 epoch 638 lr 1.000000e-05
2019-11-07 19:18:25,635 train 000 1.726703e-02 0.043775
2019-11-07 19:18:35,370 train 050 1.748812e-02 -0.652257
2019-11-07 19:18:45,157 train 100 1.735713e-02 -0.695037
2019-11-07 19:18:54,937 train 150 1.721321e-02 -2.505026
2019-11-07 19:19:04,724 train 200 1.721199e-02 -2.122045
2019-11-07 19:19:14,520 train 250 1.732024e-02 -1.849380
2019-11-07 19:19:24,324 train 300 1.727255e-02 -1.661434
2019-11-07 19:19:34,145 train 350 1.718631e-02 -1.564640
2019-11-07 19:19:43,946 train 400 1.714133e-02 -1.436921
2019-11-07 19:19:53,736 train 450 1.708313e-02 -1.428477
2019-11-07 19:20:03,535 train 500 1.706972e-02 -1.360846
2019-11-07 19:20:13,319 train 550 1.706731e-02 -1.289942
2019-11-07 19:20:23,111 train 600 1.704210e-02 -1.242500
2019-11-07 19:20:32,912 train 650 1.702790e-02 -1.195150
2019-11-07 19:20:42,699 train 700 1.702070e-02 -1.166842
2019-11-07 19:20:52,517 train 750 1.702240e-02 -1.156793
2019-11-07 19:21:02,342 train 800 1.700599e-02 -1.149934
2019-11-07 19:21:12,164 train 850 1.700460e-02 -1.113072
2019-11-07 19:21:15,126 training loss; R2: 1.700875e-02 -1.107805
2019-11-07 19:21:15,771 valid 000 1.516295e-02 -0.756921
2019-11-07 19:21:25,195 valid 050 1.597164e-02 -1.307003
2019-11-07 19:21:33,523 validation loss; R2: 1.596517e-02 -1.204852
2019-11-07 19:21:33,600 epoch 639 lr 1.000000e-05
2019-11-07 19:21:34,361 train 000 1.724529e-02 -0.872302
2019-11-07 19:21:44,162 train 050 1.723783e-02 -0.615891
2019-11-07 19:21:53,964 train 100 1.723108e-02 -0.715554
2019-11-07 19:22:03,756 train 150 1.709428e-02 -0.707672
2019-11-07 19:22:13,569 train 200 1.721172e-02 -0.717845
2019-11-07 19:22:23,379 train 250 1.713265e-02 -0.721681
2019-11-07 19:22:33,204 train 300 1.712428e-02 -0.725264
2019-11-07 19:22:43,017 train 350 1.707716e-02 -0.721672
2019-11-07 19:22:52,837 train 400 1.709545e-02 -0.718671
2019-11-07 19:23:02,667 train 450 1.705034e-02 -0.712437
2019-11-07 19:23:12,490 train 500 1.700833e-02 -0.731381
2019-11-07 19:23:22,322 train 550 1.700682e-02 -0.719233
2019-11-07 19:23:32,133 train 600 1.701698e-02 -0.716749
2019-11-07 19:23:41,952 train 650 1.701925e-02 -0.710464
2019-11-07 19:23:51,780 train 700 1.702087e-02 -0.708522
2019-11-07 19:24:01,609 train 750 1.703210e-02 -0.725673
2019-11-07 19:24:11,451 train 800 1.701494e-02 -0.728669
2019-11-07 19:24:21,278 train 850 1.701627e-02 -0.721730
2019-11-07 19:24:24,246 training loss; R2: 1.701085e-02 -0.725196
2019-11-07 19:24:24,929 valid 000 2.103555e-02 -1.216261
2019-11-07 19:24:34,312 valid 050 1.951525e-02 -2.070902
2019-11-07 19:24:42,756 validation loss; R2: 1.957794e-02 -1.960550
2019-11-07 19:24:42,838 epoch 640 lr 1.000000e-05
2019-11-07 19:24:43,671 train 000 1.927688e-02 -0.330501
2019-11-07 19:24:53,442 train 050 1.729105e-02 -2.033453
2019-11-07 19:25:03,247 train 100 1.713312e-02 -1.400756
2019-11-07 19:25:13,063 train 150 1.711791e-02 -1.169138
2019-11-07 19:25:22,865 train 200 1.700294e-02 -69.362876
2019-11-07 19:25:32,690 train 250 1.706380e-02 -55.678945
2019-11-07 19:25:42,504 train 300 1.703394e-02 -46.509423
2019-11-07 19:25:52,320 train 350 1.699829e-02 -39.989540
2019-11-07 19:26:02,144 train 400 1.701004e-02 -35.071777
2019-11-07 19:26:11,965 train 450 1.699237e-02 -31.230734
2019-11-07 19:26:21,790 train 500 1.698740e-02 -28.170587
2019-11-07 19:26:31,613 train 550 1.699144e-02 -25.677051
2019-11-07 19:26:41,438 train 600 1.697745e-02 -23.574263
2019-11-07 19:26:51,251 train 650 1.699306e-02 -21.831143
2019-11-07 19:27:01,074 train 700 1.701194e-02 -20.346584
2019-11-07 19:27:10,899 train 750 1.701233e-02 -19.043200
2019-11-07 19:27:20,709 train 800 1.698752e-02 -17.901244
2019-11-07 19:27:30,523 train 850 1.696034e-02 -16.900270
2019-11-07 19:27:33,455 training loss; R2: 1.696132e-02 -16.619988
2019-11-07 19:27:34,172 valid 000 1.400924e-02 -3.249929
2019-11-07 19:27:43,517 valid 050 1.631384e-02 -1.391747
2019-11-07 19:27:51,870 validation loss; R2: 1.653837e-02 -1.315899
2019-11-07 19:27:51,935 epoch 641 lr 1.000000e-05
2019-11-07 19:27:52,707 train 000 1.857767e-02 -0.960424
2019-11-07 19:28:02,465 train 050 1.641836e-02 -0.655326
2019-11-07 19:28:12,223 train 100 1.665678e-02 -0.731019
2019-11-07 19:28:22,014 train 150 1.677108e-02 -0.699967
2019-11-07 19:28:31,794 train 200 1.686986e-02 -0.781537
2019-11-07 19:28:41,578 train 250 1.680507e-02 -0.852536
2019-11-07 19:28:51,376 train 300 1.679806e-02 -0.819315
2019-11-07 19:29:01,164 train 350 1.676254e-02 -0.862552
2019-11-07 19:29:10,951 train 400 1.683358e-02 -0.858821
2019-11-07 19:29:20,771 train 450 1.688687e-02 -0.825859
2019-11-07 19:29:30,581 train 500 1.691911e-02 -0.823394
2019-11-07 19:29:40,372 train 550 1.693304e-02 -0.823451
2019-11-07 19:29:50,162 train 600 1.693374e-02 -0.819480
2019-11-07 19:29:59,973 train 650 1.693532e-02 -0.806861
2019-11-07 19:30:09,775 train 700 1.695085e-02 -0.810074
2019-11-07 19:30:19,571 train 750 1.693742e-02 -0.788378
2019-11-07 19:30:29,370 train 800 1.694762e-02 -0.797666
2019-11-07 19:30:39,163 train 850 1.695004e-02 -0.794598
2019-11-07 19:30:42,090 training loss; R2: 1.694176e-02 -0.813558
2019-11-07 19:30:42,728 valid 000 1.782645e-02 -1.074666
2019-11-07 19:30:52,150 valid 050 1.600789e-02 -1.329882
2019-11-07 19:31:00,575 validation loss; R2: 1.617502e-02 -1.193280
2019-11-07 19:31:00,634 epoch 642 lr 1.000000e-05
2019-11-07 19:31:01,396 train 000 1.388914e-02 -0.643526
2019-11-07 19:31:11,155 train 050 1.698186e-02 -0.613363
2019-11-07 19:31:20,904 train 100 1.698648e-02 -0.631236
2019-11-07 19:31:30,672 train 150 1.689890e-02 -1.208372
2019-11-07 19:31:40,453 train 200 1.692736e-02 -1.142125
2019-11-07 19:31:50,243 train 250 1.687194e-02 -1.057443
2019-11-07 19:32:00,022 train 300 1.691173e-02 -0.992831
2019-11-07 19:32:09,814 train 350 1.690694e-02 -0.932291
2019-11-07 19:32:19,612 train 400 1.690791e-02 -0.904024
2019-11-07 19:32:29,404 train 450 1.691937e-02 -0.886459
2019-11-07 19:32:39,193 train 500 1.694908e-02 -0.854893
2019-11-07 19:32:48,979 train 550 1.700405e-02 -0.834036
2019-11-07 19:32:58,772 train 600 1.701679e-02 -0.824372
2019-11-07 19:33:08,554 train 650 1.701009e-02 -0.978565
2019-11-07 19:33:18,343 train 700 1.700584e-02 -0.960974
2019-11-07 19:33:28,121 train 750 1.700446e-02 -0.939851
2019-11-07 19:33:37,899 train 800 1.700339e-02 -0.922285
2019-11-07 19:33:47,681 train 850 1.699351e-02 -0.917604
2019-11-07 19:33:50,599 training loss; R2: 1.699837e-02 -0.908963
2019-11-07 19:33:51,292 valid 000 1.579636e-02 -5.290694
2019-11-07 19:34:00,620 valid 050 1.670920e-02 -1.279856
2019-11-07 19:34:09,020 validation loss; R2: 1.669561e-02 -1.544050
2019-11-07 19:34:09,090 epoch 643 lr 1.000000e-05
2019-11-07 19:34:09,881 train 000 1.600176e-02 -0.138319
2019-11-07 19:34:19,615 train 050 1.692727e-02 -0.765152
2019-11-07 19:34:29,385 train 100 1.679679e-02 -0.857462
2019-11-07 19:34:39,142 train 150 1.675927e-02 -0.724776
2019-11-07 19:34:48,917 train 200 1.679975e-02 -0.902903
2019-11-07 19:34:58,707 train 250 1.693185e-02 -0.882626
2019-11-07 19:35:08,508 train 300 1.689280e-02 -0.862245
2019-11-07 19:35:18,308 train 350 1.695186e-02 -0.837066
2019-11-07 19:35:28,099 train 400 1.694972e-02 -0.837645
2019-11-07 19:35:37,893 train 450 1.693544e-02 -0.810010
2019-11-07 19:35:47,688 train 500 1.694991e-02 -0.808401
2019-11-07 19:35:57,485 train 550 1.693781e-02 -0.777981
2019-11-07 19:36:07,283 train 600 1.694719e-02 -0.759224
2019-11-07 19:36:17,090 train 650 1.694768e-02 -0.756255
2019-11-07 19:36:26,905 train 700 1.695954e-02 -0.751387
2019-11-07 19:36:36,849 train 750 1.695353e-02 -0.733802
2019-11-07 19:36:47,015 train 800 1.696869e-02 -0.727212
2019-11-07 19:36:57,181 train 850 1.698248e-02 -0.716800
2019-11-07 19:37:00,214 training loss; R2: 1.699581e-02 -0.720252
2019-11-07 19:37:00,854 valid 000 1.555088e-02 -1.934196
2019-11-07 19:37:10,240 valid 050 1.665021e-02 -0.975447
2019-11-07 19:37:18,544 validation loss; R2: 1.649287e-02 -1.378868
2019-11-07 19:37:18,611 epoch 644 lr 1.000000e-05
2019-11-07 19:37:19,364 train 000 1.543364e-02 -0.024961
2019-11-07 19:37:29,487 train 050 1.663857e-02 -1.045292
2019-11-07 19:37:39,644 train 100 1.679180e-02 -1.568506
2019-11-07 19:37:49,779 train 150 1.700393e-02 -1.356612
2019-11-07 19:37:59,920 train 200 1.703502e-02 -1.183914
2019-11-07 19:38:10,071 train 250 1.705811e-02 -1.108928
2019-11-07 19:38:20,256 train 300 1.700943e-02 -1.054168
2019-11-07 19:38:30,429 train 350 1.700800e-02 -1.034729
2019-11-07 19:38:40,593 train 400 1.695089e-02 -0.987622
2019-11-07 19:38:50,693 train 450 1.691969e-02 -0.933112
2019-11-07 19:39:00,474 train 500 1.694192e-02 -0.948411
2019-11-07 19:39:10,266 train 550 1.691190e-02 -0.932021
2019-11-07 19:39:20,052 train 600 1.692499e-02 -0.910196
2019-11-07 19:39:29,840 train 650 1.690585e-02 -0.894221
2019-11-07 19:39:39,633 train 700 1.694507e-02 -0.873323
2019-11-07 19:39:49,422 train 750 1.695698e-02 -0.876345
2019-11-07 19:39:59,216 train 800 1.694401e-02 -0.854197
2019-11-07 19:40:09,011 train 850 1.695937e-02 -0.858259
2019-11-07 19:40:11,939 training loss; R2: 1.695767e-02 -0.851675
2019-11-07 19:40:12,578 valid 000 1.545835e-02 -0.453350
2019-11-07 19:40:22,052 valid 050 1.612766e-02 -1.416923
2019-11-07 19:40:30,414 validation loss; R2: 1.593246e-02 -1.178571
2019-11-07 19:40:30,481 epoch 645 lr 1.000000e-05
2019-11-07 19:40:31,273 train 000 1.446711e-02 -0.648146
2019-11-07 19:40:40,984 train 050 1.692268e-02 -1.109859
2019-11-07 19:40:50,719 train 100 1.674963e-02 -0.870950
2019-11-07 19:41:00,487 train 150 1.676489e-02 -0.803412
2019-11-07 19:41:10,268 train 200 1.679665e-02 -0.887505
2019-11-07 19:41:20,075 train 250 1.682749e-02 -0.869110
2019-11-07 19:41:29,867 train 300 1.687722e-02 -0.824768
2019-11-07 19:41:39,649 train 350 1.689954e-02 -0.881283
2019-11-07 19:41:49,448 train 400 1.687643e-02 -0.845157
2019-11-07 19:41:59,227 train 450 1.682211e-02 -0.811765
2019-11-07 19:42:09,009 train 500 1.682120e-02 -0.842044
2019-11-07 19:42:18,785 train 550 1.681316e-02 -0.826815
2019-11-07 19:42:28,565 train 600 1.684225e-02 -0.817049
2019-11-07 19:42:38,339 train 650 1.682255e-02 -0.799028
2019-11-07 19:42:48,133 train 700 1.681321e-02 -0.786258
2019-11-07 19:42:57,931 train 750 1.682148e-02 -0.797617
2019-11-07 19:43:07,727 train 800 1.682315e-02 -0.783508
2019-11-07 19:43:17,511 train 850 1.683866e-02 -0.784887
2019-11-07 19:43:20,436 training loss; R2: 1.684668e-02 -0.784465
2019-11-07 19:43:21,090 valid 000 1.684036e-02 -1.640218
2019-11-07 19:43:30,558 valid 050 1.597988e-02 -1.393215
2019-11-07 19:43:38,951 validation loss; R2: 1.610020e-02 -1.306909
2019-11-07 19:43:39,020 epoch 646 lr 1.000000e-05
2019-11-07 19:43:39,757 train 000 1.467562e-02 -0.444647
2019-11-07 19:43:49,473 train 050 1.697561e-02 -1.198457
2019-11-07 19:43:59,191 train 100 1.697577e-02 -0.890084
2019-11-07 19:44:08,954 train 150 1.704082e-02 -0.852769
2019-11-07 19:44:18,713 train 200 1.694261e-02 -1.035568
2019-11-07 19:44:28,480 train 250 1.688345e-02 -0.942267
2019-11-07 19:44:38,238 train 300 1.684394e-02 -0.884933
2019-11-07 19:44:48,001 train 350 1.683448e-02 -0.882094
2019-11-07 19:44:57,767 train 400 1.680473e-02 -0.852967
2019-11-07 19:45:07,535 train 450 1.676492e-02 -0.834379
2019-11-07 19:45:17,303 train 500 1.677658e-02 -0.829672
2019-11-07 19:45:27,068 train 550 1.681934e-02 -0.815905
2019-11-07 19:45:36,851 train 600 1.682984e-02 -0.804932
2019-11-07 19:45:46,624 train 650 1.686093e-02 -0.791740
2019-11-07 19:45:56,404 train 700 1.689109e-02 -0.787886
2019-11-07 19:46:06,164 train 750 1.692437e-02 -0.791053
2019-11-07 19:46:15,936 train 800 1.692620e-02 -0.801270
2019-11-07 19:46:25,706 train 850 1.693553e-02 -0.790346
2019-11-07 19:46:28,630 training loss; R2: 1.693533e-02 -0.787920
2019-11-07 19:46:29,255 valid 000 1.940476e-02 -0.708207
2019-11-07 19:46:38,693 valid 050 1.639273e-02 -1.116412
2019-11-07 19:46:47,068 validation loss; R2: 1.642931e-02 -1.270062
2019-11-07 19:46:47,148 epoch 647 lr 1.000000e-05
2019-11-07 19:46:47,946 train 000 1.690101e-02 0.007517
2019-11-07 19:46:57,653 train 050 1.731888e-02 -0.735302
2019-11-07 19:47:07,386 train 100 1.727082e-02 -0.751260
2019-11-07 19:47:17,132 train 150 1.712122e-02 -0.624964
2019-11-07 19:47:26,884 train 200 1.714756e-02 -0.668469
2019-11-07 19:47:36,645 train 250 1.707386e-02 -0.722644
2019-11-07 19:47:46,435 train 300 1.707252e-02 -0.688143
2019-11-07 19:47:56,240 train 350 1.703713e-02 -0.724613
2019-11-07 19:48:06,042 train 400 1.702343e-02 -0.686763
2019-11-07 19:48:15,855 train 450 1.703102e-02 -0.707601
2019-11-07 19:48:25,664 train 500 1.704026e-02 -0.686377
2019-11-07 19:48:35,470 train 550 1.701962e-02 -1.023234
2019-11-07 19:48:45,300 train 600 1.701252e-02 -0.989543
2019-11-07 19:48:55,111 train 650 1.700609e-02 -0.970582
2019-11-07 19:49:05,293 train 700 1.700434e-02 -0.969553
2019-11-07 19:49:15,442 train 750 1.700203e-02 -0.955899
2019-11-07 19:49:25,608 train 800 1.699369e-02 -0.949169
2019-11-07 19:49:35,773 train 850 1.698218e-02 -0.933943
2019-11-07 19:49:38,802 training loss; R2: 1.698400e-02 -0.938109
2019-11-07 19:49:39,506 valid 000 1.642468e-02 -0.151349
2019-11-07 19:49:48,864 valid 050 1.730937e-02 -1.651702
2019-11-07 19:49:57,242 validation loss; R2: 1.694785e-02 -1.879549
2019-11-07 19:49:57,311 epoch 648 lr 1.000000e-05
2019-11-07 19:49:58,090 train 000 1.876418e-02 -0.035369
2019-11-07 19:50:08,211 train 050 1.694184e-02 -1.044213
2019-11-07 19:50:18,358 train 100 1.701490e-02 -0.754694
2019-11-07 19:50:28,492 train 150 1.711388e-02 -1.151419
2019-11-07 19:50:38,641 train 200 1.695738e-02 -1.052701
2019-11-07 19:50:48,801 train 250 1.693140e-02 -0.970783
2019-11-07 19:50:58,959 train 300 1.694351e-02 -0.946541
2019-11-07 19:51:09,125 train 350 1.688462e-02 -0.951701
2019-11-07 19:51:19,292 train 400 1.687884e-02 -0.931371
2019-11-07 19:51:29,469 train 450 1.687642e-02 -0.895115
2019-11-07 19:51:39,654 train 500 1.685275e-02 -0.861250
2019-11-07 19:51:49,849 train 550 1.682973e-02 -0.844450
2019-11-07 19:51:59,904 train 600 1.683030e-02 -0.840327
2019-11-07 19:52:09,700 train 650 1.682980e-02 -0.829143
2019-11-07 19:52:19,509 train 700 1.682350e-02 -0.826364
2019-11-07 19:52:29,311 train 750 1.685781e-02 -0.813112
2019-11-07 19:52:39,110 train 800 1.686287e-02 -0.826548
2019-11-07 19:52:48,897 train 850 1.689889e-02 -0.818370
2019-11-07 19:52:51,822 training loss; R2: 1.690295e-02 -0.814819
2019-11-07 19:52:52,490 valid 000 3.574888e-02 -7.618808
2019-11-07 19:53:01,894 valid 050 3.183698e-02 -5.240959
2019-11-07 19:53:10,192 validation loss; R2: 3.211868e-02 -4.573273
2019-11-07 19:53:10,271 epoch 649 lr 1.000000e-05
2019-11-07 19:53:11,085 train 000 1.378361e-02 -0.037811
2019-11-07 19:53:21,193 train 050 1.717236e-02 -1.056993
2019-11-07 19:53:31,322 train 100 1.702979e-02 -0.844486
2019-11-07 19:53:41,462 train 150 1.709267e-02 -0.770022
2019-11-07 19:53:51,607 train 200 1.706001e-02 -0.726721
2019-11-07 19:54:01,760 train 250 1.707096e-02 -0.709192
2019-11-07 19:54:11,913 train 300 1.703769e-02 -0.815358
2019-11-07 19:54:22,044 train 350 1.702278e-02 -0.798857
2019-11-07 19:54:32,187 train 400 1.703039e-02 -0.844580
2019-11-07 19:54:42,336 train 450 1.701657e-02 -0.799367
2019-11-07 19:54:52,489 train 500 1.702804e-02 -0.819492
2019-11-07 19:55:02,629 train 550 1.703993e-02 -0.807406
2019-11-07 19:55:12,784 train 600 1.705080e-02 -0.805399
2019-11-07 19:55:22,945 train 650 1.704868e-02 -0.793494
2019-11-07 19:55:33,085 train 700 1.702433e-02 -0.785486
2019-11-07 19:55:43,244 train 750 1.701636e-02 -0.784770
2019-11-07 19:55:53,405 train 800 1.700708e-02 -0.776768
2019-11-07 19:56:03,558 train 850 1.700470e-02 -0.758580
2019-11-07 19:56:06,590 training loss; R2: 1.699090e-02 -0.759506
2019-11-07 19:56:07,231 valid 000 1.650231e-02 -1.836000
2019-11-07 19:56:16,627 valid 050 1.692720e-02 -1.435828
2019-11-07 19:56:24,978 validation loss; R2: 1.665646e-02 -1.537289
2019-11-07 19:56:25,048 epoch 650 lr 1.000000e-05
2019-11-07 19:56:25,829 train 000 1.586074e-02 -0.045449
2019-11-07 19:56:35,944 train 050 1.646108e-02 -0.543626
2019-11-07 19:56:46,076 train 100 1.674537e-02 -0.548891
2019-11-07 19:56:56,072 train 150 1.681986e-02 -0.607183
2019-11-07 19:57:05,877 train 200 1.680746e-02 -0.652983
2019-11-07 19:57:15,694 train 250 1.682196e-02 -0.656485
2019-11-07 19:57:25,514 train 300 1.685304e-02 -0.705497
2019-11-07 19:57:35,334 train 350 1.692571e-02 -0.754470
2019-11-07 19:57:45,142 train 400 1.689379e-02 -0.781559
2019-11-07 19:57:54,957 train 450 1.693933e-02 -0.746732
2019-11-07 19:58:04,780 train 500 1.695515e-02 -0.772369
2019-11-07 19:58:14,581 train 550 1.693752e-02 -0.769298
2019-11-07 19:58:24,362 train 600 1.690913e-02 -0.757607
2019-11-07 19:58:34,148 train 650 1.692069e-02 -0.750984
2019-11-07 19:58:43,953 train 700 1.691383e-02 -0.746383
2019-11-07 19:58:53,728 train 750 1.690050e-02 -0.754994
2019-11-07 19:59:03,525 train 800 1.690842e-02 -0.747862
2019-11-07 19:59:13,297 train 850 1.690933e-02 -0.745851
2019-11-07 19:59:16,219 training loss; R2: 1.689336e-02 -0.754018
2019-11-07 19:59:16,854 valid 000 1.429956e-02 -2.401416
2019-11-07 19:59:26,289 valid 050 1.586233e-02 -1.199955
2019-11-07 19:59:34,688 validation loss; R2: 1.574983e-02 -1.323887
2019-11-07 19:59:34,753 epoch 651 lr 1.000000e-05
2019-11-07 19:59:35,537 train 000 1.924476e-02 -5.376578
2019-11-07 19:59:45,250 train 050 1.753815e-02 -56.641896
2019-11-07 19:59:54,986 train 100 1.702310e-02 -28.996500
2019-11-07 20:00:04,757 train 150 1.695900e-02 -19.700384
2019-11-07 20:00:14,532 train 200 1.701096e-02 -14.961347
2019-11-07 20:00:24,296 train 250 1.695409e-02 -12.139192
2019-11-07 20:00:34,077 train 300 1.697025e-02 -10.328976
2019-11-07 20:00:43,844 train 350 1.695893e-02 -8.951936
2019-11-07 20:00:53,608 train 400 1.700442e-02 -7.909607
2019-11-07 20:01:03,379 train 450 1.697141e-02 -7.081561
2019-11-07 20:01:13,157 train 500 1.699511e-02 -6.443683
2019-11-07 20:01:22,927 train 550 1.697049e-02 -5.904808
2019-11-07 20:01:32,691 train 600 1.700057e-02 -5.468147
2019-11-07 20:01:42,471 train 650 1.700671e-02 -5.109197
2019-11-07 20:01:52,254 train 700 1.699061e-02 -4.790444
2019-11-07 20:02:02,030 train 750 1.699259e-02 -4.516537
2019-11-07 20:02:11,825 train 800 1.699135e-02 -4.297023
2019-11-07 20:02:21,614 train 850 1.699624e-02 -4.157534
2019-11-07 20:02:24,533 training loss; R2: 1.699971e-02 -4.102045
2019-11-07 20:02:25,150 valid 000 1.771434e-02 -11.052927
2019-11-07 20:02:34,565 valid 050 1.982643e-02 -2.098737
2019-11-07 20:02:42,869 validation loss; R2: 1.996824e-02 -5.486708
2019-11-07 20:02:42,928 epoch 652 lr 1.000000e-05
2019-11-07 20:02:43,676 train 000 1.651414e-02 -0.294964
2019-11-07 20:02:53,424 train 050 1.694579e-02 -0.703220
2019-11-07 20:03:03,190 train 100 1.694724e-02 -0.565447
2019-11-07 20:03:12,964 train 150 1.695243e-02 -0.647984
2019-11-07 20:03:22,745 train 200 1.693549e-02 -0.700300
2019-11-07 20:03:32,541 train 250 1.690707e-02 -0.709653
2019-11-07 20:03:42,329 train 300 1.692243e-02 -0.713308
2019-11-07 20:03:52,127 train 350 1.689107e-02 -1.089522
2019-11-07 20:04:01,921 train 400 1.690776e-02 -1.039546
2019-11-07 20:04:11,715 train 450 1.690651e-02 -0.984922
2019-11-07 20:04:21,504 train 500 1.693783e-02 -0.968000
2019-11-07 20:04:31,303 train 550 1.691352e-02 -0.985644
2019-11-07 20:04:41,098 train 600 1.690617e-02 -0.962606
2019-11-07 20:04:50,932 train 650 1.688679e-02 -0.944875
2019-11-07 20:05:00,767 train 700 1.688651e-02 -0.926013
2019-11-07 20:05:10,607 train 750 1.690066e-02 -0.908076
2019-11-07 20:05:20,423 train 800 1.688376e-02 -0.914523
2019-11-07 20:05:30,250 train 850 1.689492e-02 -0.910095
2019-11-07 20:05:33,181 training loss; R2: 1.690363e-02 -0.905928
2019-11-07 20:05:33,860 valid 000 2.302944e-02 -1.258036
2019-11-07 20:05:43,280 valid 050 2.197627e-02 -3.910520
2019-11-07 20:05:51,585 validation loss; R2: 2.203463e-02 -4.827815
2019-11-07 20:05:51,650 epoch 653 lr 1.000000e-05
2019-11-07 20:05:52,379 train 000 1.869335e-02 0.135665
2019-11-07 20:06:02,138 train 050 1.685985e-02 -1.093148
2019-11-07 20:06:11,891 train 100 1.679939e-02 -0.821857
2019-11-07 20:06:21,676 train 150 1.691654e-02 -0.705919
2019-11-07 20:06:31,467 train 200 1.690074e-02 -0.738359
2019-11-07 20:06:41,253 train 250 1.691435e-02 -0.762557
2019-11-07 20:06:51,040 train 300 1.694426e-02 -0.787350
2019-11-07 20:07:00,820 train 350 1.693962e-02 -3.186782
2019-11-07 20:07:10,605 train 400 1.693347e-02 -2.860893
2019-11-07 20:07:20,417 train 450 1.701470e-02 -2.587873
2019-11-07 20:07:30,238 train 500 1.701497e-02 -2.387138
2019-11-07 20:07:40,042 train 550 1.702023e-02 -2.244259
2019-11-07 20:07:49,831 train 600 1.699426e-02 -2.124849
2019-11-07 20:07:59,623 train 650 1.698830e-02 -2.043776
2019-11-07 20:08:09,408 train 700 1.698989e-02 -1.972263
2019-11-07 20:08:19,196 train 750 1.697340e-02 -1.895934
2019-11-07 20:08:28,987 train 800 1.694944e-02 -1.826191
2019-11-07 20:08:38,784 train 850 1.695533e-02 -1.755077
2019-11-07 20:08:41,708 training loss; R2: 1.696958e-02 -1.738674
2019-11-07 20:08:42,340 valid 000 1.811739e-02 -2.148368
2019-11-07 20:08:51,779 valid 050 1.793966e-02 -2.023234
2019-11-07 20:09:00,098 validation loss; R2: 1.791505e-02 -2.083419
2019-11-07 20:09:00,160 epoch 654 lr 1.000000e-05
2019-11-07 20:09:00,952 train 000 1.308104e-02 -0.365952
2019-11-07 20:09:10,717 train 050 1.680631e-02 -0.621054
2019-11-07 20:09:20,507 train 100 1.661072e-02 -0.671942
2019-11-07 20:09:30,288 train 150 1.664855e-02 -0.644662
2019-11-07 20:09:40,069 train 200 1.665985e-02 -0.633581
2019-11-07 20:09:49,857 train 250 1.677513e-02 -0.602803
2019-11-07 20:09:59,657 train 300 1.678146e-02 -0.586068
2019-11-07 20:10:09,452 train 350 1.681206e-02 -0.585591
2019-11-07 20:10:19,232 train 400 1.683534e-02 -0.636662
2019-11-07 20:10:29,034 train 450 1.688008e-02 -0.631775
2019-11-07 20:10:38,818 train 500 1.687425e-02 -0.641499
2019-11-07 20:10:48,622 train 550 1.688991e-02 -0.649703
2019-11-07 20:10:58,410 train 600 1.687815e-02 -0.648641
2019-11-07 20:11:08,195 train 650 1.687873e-02 -0.647248
2019-11-07 20:11:17,994 train 700 1.684611e-02 -0.653671
2019-11-07 20:11:27,802 train 750 1.684612e-02 -0.647432
2019-11-07 20:11:37,601 train 800 1.685392e-02 -0.666423
2019-11-07 20:11:47,411 train 850 1.686720e-02 -0.665952
2019-11-07 20:11:50,382 training loss; R2: 1.686774e-02 -0.666374
2019-11-07 20:11:50,992 valid 000 1.578382e-02 -0.356309
2019-11-07 20:12:00,426 valid 050 1.525720e-02 -0.975508
2019-11-07 20:12:08,769 validation loss; R2: 1.534832e-02 -0.946745
2019-11-07 20:12:08,851 epoch 655 lr 1.000000e-05
2019-11-07 20:12:09,595 train 000 1.737089e-02 -0.070380
2019-11-07 20:12:19,721 train 050 1.719233e-02 -0.473996
2019-11-07 20:12:29,838 train 100 1.693519e-02 -0.592801
2019-11-07 20:12:39,948 train 150 1.709382e-02 -0.584541
2019-11-07 20:12:50,089 train 200 1.704686e-02 -0.551209
2019-11-07 20:13:00,233 train 250 1.700096e-02 -1.992734
2019-11-07 20:13:10,380 train 300 1.697827e-02 -1.774743
2019-11-07 20:13:20,510 train 350 1.694634e-02 -1.639639
2019-11-07 20:13:30,658 train 400 1.689224e-02 -1.506860
2019-11-07 20:13:40,805 train 450 1.686881e-02 -1.433930
2019-11-07 20:13:50,943 train 500 1.688479e-02 -1.397225
2019-11-07 20:14:01,092 train 550 1.688077e-02 -1.320638
2019-11-07 20:14:11,241 train 600 1.687234e-02 -1.254806
2019-11-07 20:14:21,367 train 650 1.689786e-02 -1.226491
2019-11-07 20:14:31,503 train 700 1.690363e-02 -1.185049
2019-11-07 20:14:41,645 train 750 1.689713e-02 -1.187100
2019-11-07 20:14:51,790 train 800 1.689775e-02 -1.143657
2019-11-07 20:15:01,929 train 850 1.690774e-02 -1.126811
2019-11-07 20:15:04,954 training loss; R2: 1.690908e-02 -1.115954
2019-11-07 20:15:05,582 valid 000 1.689976e-02 -0.423733
2019-11-07 20:15:14,983 valid 050 1.484027e-02 -0.814559
2019-11-07 20:15:23,312 validation loss; R2: 1.479360e-02 -1.047300
2019-11-07 20:15:23,379 epoch 656 lr 1.000000e-05
2019-11-07 20:15:24,120 train 000 1.629642e-02 0.032179
2019-11-07 20:15:34,264 train 050 1.723095e-02 -0.647015
2019-11-07 20:15:44,408 train 100 1.742663e-02 -0.766094
2019-11-07 20:15:54,571 train 150 1.721216e-02 -39.245647
2019-11-07 20:16:04,740 train 200 1.714623e-02 -29.696876
2019-11-07 20:16:14,904 train 250 1.708920e-02 -23.921517
2019-11-07 20:16:25,048 train 300 1.710561e-02 -20.065128
2019-11-07 20:16:35,222 train 350 1.699825e-02 -17.289755
2019-11-07 20:16:45,396 train 400 1.700270e-02 -15.229296
2019-11-07 20:16:55,552 train 450 1.696871e-02 -13.621019
2019-11-07 20:17:05,732 train 500 1.700882e-02 -12.338701
2019-11-07 20:17:15,905 train 550 1.698244e-02 -11.276785
2019-11-07 20:17:26,086 train 600 1.694911e-02 -10.391984
2019-11-07 20:17:36,262 train 650 1.697968e-02 -9.648423
2019-11-07 20:17:46,426 train 700 1.698424e-02 -9.040734
2019-11-07 20:17:56,600 train 750 1.698338e-02 -8.476372
2019-11-07 20:18:06,779 train 800 1.697357e-02 -8.049839
2019-11-07 20:18:16,960 train 850 1.697140e-02 -7.666495
2019-11-07 20:18:19,999 training loss; R2: 1.697387e-02 -7.543200
2019-11-07 20:18:20,639 valid 000 2.369178e-02 -2.728027
2019-11-07 20:18:30,118 valid 050 2.256454e-02 -2.219349
2019-11-07 20:18:38,436 validation loss; R2: 2.266462e-02 -2.764598
2019-11-07 20:18:38,503 epoch 657 lr 1.000000e-05
2019-11-07 20:18:39,335 train 000 1.544762e-02 -0.085096
2019-11-07 20:18:49,457 train 050 1.720052e-02 -1.540781
2019-11-07 20:18:59,579 train 100 1.706764e-02 -1.067643
2019-11-07 20:19:09,713 train 150 1.707074e-02 -1.054377
2019-11-07 20:19:19,867 train 200 1.703041e-02 -1.071294
2019-11-07 20:19:30,014 train 250 1.693334e-02 -1.040149
2019-11-07 20:19:40,152 train 300 1.691652e-02 -0.994894
2019-11-07 20:19:50,323 train 350 1.692218e-02 -1.549029
2019-11-07 20:20:00,461 train 400 1.695201e-02 -1.424618
2019-11-07 20:20:10,624 train 450 1.692844e-02 -1.327245
2019-11-07 20:20:20,783 train 500 1.693600e-02 -1.265878
2019-11-07 20:20:30,917 train 550 1.692931e-02 -1.199665
2019-11-07 20:20:41,081 train 600 1.693998e-02 -1.161067
2019-11-07 20:20:51,244 train 650 1.693934e-02 -1.120282
2019-11-07 20:21:01,395 train 700 1.692218e-02 -1.098433
2019-11-07 20:21:11,549 train 750 1.690789e-02 -1.076468
2019-11-07 20:21:21,688 train 800 1.690457e-02 -1.054461
2019-11-07 20:21:31,819 train 850 1.690112e-02 -1.038832
2019-11-07 20:21:34,866 training loss; R2: 1.690623e-02 -1.030179
2019-11-07 20:21:35,532 valid 000 1.774904e-02 0.126034
2019-11-07 20:21:44,923 valid 050 1.617973e-02 -1.106890
2019-11-07 20:21:53,257 validation loss; R2: 1.623090e-02 -0.977353
2019-11-07 20:21:53,334 epoch 658 lr 1.000000e-05
2019-11-07 20:21:54,108 train 000 1.782007e-02 0.076313
2019-11-07 20:22:04,226 train 050 1.673121e-02 -0.948434
2019-11-07 20:22:14,404 train 100 1.691994e-02 -0.957673
2019-11-07 20:22:24,578 train 150 1.677759e-02 -1.010216
2019-11-07 20:22:34,651 train 200 1.677543e-02 -1.162517
2019-11-07 20:22:44,461 train 250 1.679088e-02 -1.045417
2019-11-07 20:22:54,252 train 300 1.683459e-02 -0.981858
2019-11-07 20:23:04,035 train 350 1.683135e-02 -0.968988
2019-11-07 20:23:13,841 train 400 1.681547e-02 -0.935151
2019-11-07 20:23:23,642 train 450 1.681210e-02 -0.905926
2019-11-07 20:23:33,443 train 500 1.682492e-02 -0.865837
2019-11-07 20:23:43,251 train 550 1.685234e-02 -0.844677
2019-11-07 20:23:53,045 train 600 1.685422e-02 -0.847967
2019-11-07 20:24:02,849 train 650 1.685178e-02 -0.815290
2019-11-07 20:24:12,652 train 700 1.683807e-02 -0.806792
2019-11-07 20:24:22,445 train 750 1.684190e-02 -0.799559
2019-11-07 20:24:32,262 train 800 1.685933e-02 -0.790395
2019-11-07 20:24:42,049 train 850 1.685084e-02 -0.779175
2019-11-07 20:24:44,995 training loss; R2: 1.686317e-02 -0.774381
2019-11-07 20:24:45,672 valid 000 1.881934e-02 -92.222538
2019-11-07 20:24:55,091 valid 050 2.008349e-02 -3.877570
2019-11-07 20:25:03,460 validation loss; R2: 2.001551e-02 -2.639284
2019-11-07 20:25:03,527 epoch 659 lr 1.000000e-05
2019-11-07 20:25:04,304 train 000 1.861682e-02 -0.953488
2019-11-07 20:25:14,050 train 050 1.687616e-02 -1.258989
2019-11-07 20:25:23,822 train 100 1.693936e-02 -0.991653
2019-11-07 20:25:33,639 train 150 1.689982e-02 -0.921793
2019-11-07 20:25:43,468 train 200 1.692709e-02 -0.885601
2019-11-07 20:25:53,284 train 250 1.686939e-02 -0.831335
2019-11-07 20:26:03,097 train 300 1.690999e-02 -0.767159
2019-11-07 20:26:12,923 train 350 1.688665e-02 -0.734463
2019-11-07 20:26:22,752 train 400 1.691130e-02 -0.720807
2019-11-07 20:26:32,594 train 450 1.692990e-02 -0.703661
2019-11-07 20:26:42,430 train 500 1.691997e-02 -1.242403
2019-11-07 20:26:52,274 train 550 1.689513e-02 -1.204157
2019-11-07 20:27:02,107 train 600 1.689418e-02 -1.178279
2019-11-07 20:27:11,924 train 650 1.690514e-02 -1.130247
2019-11-07 20:27:21,761 train 700 1.690665e-02 -1.085838
2019-11-07 20:27:31,615 train 750 1.689065e-02 -1.051866
2019-11-07 20:27:41,462 train 800 1.686719e-02 -1.033369
2019-11-07 20:27:51,318 train 850 1.686674e-02 -1.014759
2019-11-07 20:27:54,259 training loss; R2: 1.686659e-02 -1.010753
2019-11-07 20:27:54,850 valid 000 1.561600e-02 -1.533023
2019-11-07 20:28:04,281 valid 050 2.013935e-02 -2.632513
2019-11-07 20:28:12,686 validation loss; R2: 2.004912e-02 -2.514341
2019-11-07 20:28:12,753 epoch 660 lr 1.000000e-05
2019-11-07 20:28:13,564 train 000 1.542030e-02 -0.080634
2019-11-07 20:28:23,361 train 050 1.711168e-02 -0.644590
2019-11-07 20:28:33,183 train 100 1.690844e-02 -0.626967
2019-11-07 20:28:43,011 train 150 1.689024e-02 -0.898864
2019-11-07 20:28:52,853 train 200 1.677235e-02 -0.818174
2019-11-07 20:29:02,710 train 250 1.681622e-02 -0.874389
2019-11-07 20:29:12,558 train 300 1.682685e-02 -0.846464
2019-11-07 20:29:22,430 train 350 1.688955e-02 -0.819040
2019-11-07 20:29:32,271 train 400 1.688583e-02 -0.841787
2019-11-07 20:29:42,116 train 450 1.689344e-02 -0.833355
2019-11-07 20:29:51,965 train 500 1.689018e-02 -0.796812
2019-11-07 20:30:01,801 train 550 1.689513e-02 -0.796770
2019-11-07 20:30:11,622 train 600 1.687730e-02 -0.788019
2019-11-07 20:30:21,463 train 650 1.687333e-02 -0.791202
2019-11-07 20:30:31,296 train 700 1.690052e-02 -0.790269
2019-11-07 20:30:41,111 train 750 1.691169e-02 -0.793948
2019-11-07 20:30:50,897 train 800 1.691564e-02 -0.793325
2019-11-07 20:31:00,696 train 850 1.689683e-02 -0.790704
2019-11-07 20:31:03,627 training loss; R2: 1.690202e-02 -0.789713
2019-11-07 20:31:04,258 valid 000 1.657456e-02 -1.602942
2019-11-07 20:31:13,724 valid 050 1.611811e-02 -1.592113
2019-11-07 20:31:22,119 validation loss; R2: 1.616410e-02 -1.692102
2019-11-07 20:31:22,184 epoch 661 lr 1.000000e-05
2019-11-07 20:31:22,930 train 000 1.622123e-02 -0.578788
2019-11-07 20:31:32,672 train 050 1.717915e-02 -0.743350
2019-11-07 20:31:42,439 train 100 1.713044e-02 -0.750129
2019-11-07 20:31:52,203 train 150 1.702260e-02 -0.762460
2019-11-07 20:32:01,971 train 200 1.707475e-02 -0.772195
2019-11-07 20:32:11,763 train 250 1.709294e-02 -0.736846
2019-11-07 20:32:21,551 train 300 1.704587e-02 -0.702021
2019-11-07 20:32:31,327 train 350 1.706716e-02 -0.712171
2019-11-07 20:32:41,110 train 400 1.699321e-02 -0.799075
2019-11-07 20:32:50,881 train 450 1.694563e-02 -0.774821
2019-11-07 20:33:00,653 train 500 1.691128e-02 -0.789721
2019-11-07 20:33:10,433 train 550 1.697773e-02 -0.804163
2019-11-07 20:33:20,233 train 600 1.698575e-02 -0.798096
2019-11-07 20:33:30,039 train 650 1.700999e-02 -0.787454
2019-11-07 20:33:39,830 train 700 1.697970e-02 -0.783201
2019-11-07 20:33:49,625 train 750 1.695323e-02 -0.782373
2019-11-07 20:33:59,423 train 800 1.696330e-02 -0.821040
2019-11-07 20:34:09,236 train 850 1.693319e-02 -0.823384
2019-11-07 20:34:12,160 training loss; R2: 1.692107e-02 -0.818627
2019-11-07 20:34:12,860 valid 000 1.547302e-02 -0.001978
2019-11-07 20:34:22,276 valid 050 1.624945e-02 -1.566145
2019-11-07 20:34:30,624 validation loss; R2: 1.636092e-02 -1.282566
2019-11-07 20:34:30,690 epoch 662 lr 1.000000e-05
2019-11-07 20:34:31,428 train 000 1.586138e-02 -0.346531
2019-11-07 20:34:41,195 train 050 1.723348e-02 -1.201045
2019-11-07 20:34:50,968 train 100 1.699335e-02 -0.909909
2019-11-07 20:35:00,754 train 150 1.690221e-02 -0.899227
2019-11-07 20:35:10,529 train 200 1.688734e-02 -0.836061
2019-11-07 20:35:20,322 train 250 1.694759e-02 -0.801913
2019-11-07 20:35:30,106 train 300 1.701797e-02 -0.833943
2019-11-07 20:35:39,891 train 350 1.698004e-02 -0.836727
2019-11-07 20:35:49,678 train 400 1.701038e-02 -0.798744
2019-11-07 20:35:59,481 train 450 1.702113e-02 -0.804927
2019-11-07 20:36:09,274 train 500 1.700117e-02 -0.775358
2019-11-07 20:36:19,045 train 550 1.694893e-02 -0.789980
2019-11-07 20:36:28,850 train 600 1.695070e-02 -0.782182
2019-11-07 20:36:38,652 train 650 1.694984e-02 -0.758852
2019-11-07 20:36:48,451 train 700 1.695303e-02 -0.751615
2019-11-07 20:36:58,240 train 750 1.696943e-02 -0.736972
2019-11-07 20:37:08,019 train 800 1.695781e-02 -0.725022
2019-11-07 20:37:17,817 train 850 1.693121e-02 -0.739457
2019-11-07 20:37:20,749 training loss; R2: 1.693208e-02 -0.736735
2019-11-07 20:37:21,418 valid 000 1.624692e-02 -2.407979
2019-11-07 20:37:30,801 valid 050 1.722383e-02 -2.587002
2019-11-07 20:37:39,162 validation loss; R2: 1.722589e-02 -2.164775
2019-11-07 20:37:39,227 epoch 663 lr 1.000000e-05
2019-11-07 20:37:39,952 train 000 1.670993e-02 -1.288974
2019-11-07 20:37:49,692 train 050 1.752588e-02 -0.944064
2019-11-07 20:37:59,458 train 100 1.717446e-02 -0.770557
2019-11-07 20:38:09,247 train 150 1.701436e-02 -0.742658
2019-11-07 20:38:19,051 train 200 1.698897e-02 -0.722058
2019-11-07 20:38:28,845 train 250 1.696379e-02 -0.725335
2019-11-07 20:38:38,659 train 300 1.694570e-02 -0.713150
2019-11-07 20:38:48,472 train 350 1.693309e-02 -0.733466
2019-11-07 20:38:58,282 train 400 1.689221e-02 -0.747198
2019-11-07 20:39:08,077 train 450 1.685955e-02 -0.752191
2019-11-07 20:39:17,878 train 500 1.686794e-02 -0.741377
2019-11-07 20:39:27,672 train 550 1.688095e-02 -0.737558
2019-11-07 20:39:37,472 train 600 1.688107e-02 -0.729474
2019-11-07 20:39:47,309 train 650 1.686519e-02 -1.259544
2019-11-07 20:39:57,162 train 700 1.686422e-02 -1.229818
2019-11-07 20:40:06,994 train 750 1.688595e-02 -1.214584
2019-11-07 20:40:16,811 train 800 1.689159e-02 -1.169819
2019-11-07 20:40:26,626 train 850 1.690273e-02 -1.128926
2019-11-07 20:40:29,561 training loss; R2: 1.689611e-02 -1.122157
2019-11-07 20:40:30,261 valid 000 1.761666e-02 -0.611224
2019-11-07 20:40:39,691 valid 050 1.716944e-02 -1.622327
2019-11-07 20:40:48,173 validation loss; R2: 1.759510e-02 -1.713600
2019-11-07 20:40:48,239 epoch 664 lr 1.000000e-05
2019-11-07 20:40:49,022 train 000 1.751362e-02 -0.104156
2019-11-07 20:40:58,771 train 050 1.661242e-02 -0.861448
2019-11-07 20:41:08,531 train 100 1.685419e-02 -0.762045
2019-11-07 20:41:18,298 train 150 1.691140e-02 -0.765705
2019-11-07 20:41:28,087 train 200 1.698156e-02 -0.782401
2019-11-07 20:41:37,872 train 250 1.692918e-02 -0.806461
2019-11-07 20:41:47,659 train 300 1.693610e-02 -0.785579
2019-11-07 20:41:57,467 train 350 1.688090e-02 -0.750098
2019-11-07 20:42:07,273 train 400 1.687599e-02 -0.799905
2019-11-07 20:42:17,094 train 450 1.688942e-02 -0.819771
2019-11-07 20:42:26,907 train 500 1.686523e-02 -0.807166
2019-11-07 20:42:36,727 train 550 1.684495e-02 -2.251386
2019-11-07 20:42:46,547 train 600 1.686688e-02 -2.113384
2019-11-07 20:42:56,358 train 650 1.685325e-02 -2.004212
2019-11-07 20:43:06,185 train 700 1.685991e-02 -1.934750
2019-11-07 20:43:16,011 train 750 1.687191e-02 -1.872117
2019-11-07 20:43:25,845 train 800 1.687444e-02 -1.854418
2019-11-07 20:43:35,674 train 850 1.687713e-02 -1.791530
2019-11-07 20:43:38,614 training loss; R2: 1.689216e-02 -1.769174
2019-11-07 20:43:39,217 valid 000 2.038468e-02 -0.770365
2019-11-07 20:43:48,650 valid 050 1.661773e-02 -0.625246
2019-11-07 20:43:56,991 validation loss; R2: 1.650119e-02 -0.964889
2019-11-07 20:43:57,057 epoch 665 lr 1.000000e-05
2019-11-07 20:43:57,836 train 000 1.731034e-02 -0.691191
2019-11-07 20:44:07,614 train 050 1.695611e-02 -0.440551
2019-11-07 20:44:17,378 train 100 1.669773e-02 -0.550896
2019-11-07 20:44:27,163 train 150 1.673209e-02 -0.591041
2019-11-07 20:44:36,932 train 200 1.679042e-02 -0.576607
2019-11-07 20:44:46,732 train 250 1.672674e-02 -0.604339
2019-11-07 20:44:56,523 train 300 1.680877e-02 -0.728481
2019-11-07 20:45:06,332 train 350 1.684826e-02 -0.760044
2019-11-07 20:45:16,104 train 400 1.690753e-02 -0.761435
2019-11-07 20:45:25,877 train 450 1.687170e-02 -0.763652
2019-11-07 20:45:35,656 train 500 1.684264e-02 -0.744867
2019-11-07 20:45:45,433 train 550 1.688275e-02 -0.724856
2019-11-07 20:45:55,211 train 600 1.686095e-02 -0.733073
2019-11-07 20:46:04,986 train 650 1.687495e-02 -0.733904
2019-11-07 20:46:14,773 train 700 1.686564e-02 -0.720092
2019-11-07 20:46:24,556 train 750 1.686159e-02 -0.723495
2019-11-07 20:46:34,336 train 800 1.687637e-02 -0.721713
2019-11-07 20:46:44,113 train 850 1.686955e-02 -0.722091
2019-11-07 20:46:47,043 training loss; R2: 1.686392e-02 -0.719295
2019-11-07 20:46:47,669 valid 000 2.776708e-02 -0.913114
2019-11-07 20:46:57,095 valid 050 2.865923e-02 -3.867881
2019-11-07 20:47:05,393 validation loss; R2: 2.887552e-02 -3.226780
2019-11-07 20:47:05,465 epoch 666 lr 1.000000e-05
2019-11-07 20:47:06,288 train 000 1.721889e-02 -0.202264
2019-11-07 20:47:15,996 train 050 1.678174e-02 -0.771894
2019-11-07 20:47:25,719 train 100 1.696361e-02 -0.723061
2019-11-07 20:47:35,459 train 150 1.699471e-02 -0.665273
2019-11-07 20:47:45,199 train 200 1.698840e-02 -0.641996
2019-11-07 20:47:54,947 train 250 1.694795e-02 -0.664113
2019-11-07 20:48:04,700 train 300 1.695451e-02 -0.659002
2019-11-07 20:48:14,462 train 350 1.694149e-02 -0.678906
2019-11-07 20:48:24,229 train 400 1.695526e-02 -0.666479
2019-11-07 20:48:33,986 train 450 1.695822e-02 -0.685402
2019-11-07 20:48:43,755 train 500 1.695746e-02 -0.692671
2019-11-07 20:48:53,515 train 550 1.692660e-02 -0.686137
2019-11-07 20:49:03,278 train 600 1.693838e-02 -0.684084
2019-11-07 20:49:13,054 train 650 1.693744e-02 -0.672728
2019-11-07 20:49:22,824 train 700 1.693508e-02 -0.678184
2019-11-07 20:49:32,600 train 750 1.693023e-02 -0.691093
2019-11-07 20:49:42,363 train 800 1.691330e-02 -0.679464
2019-11-07 20:49:52,135 train 850 1.691094e-02 -0.696331
2019-11-07 20:49:55,051 training loss; R2: 1.691183e-02 -0.697887
2019-11-07 20:49:55,726 valid 000 1.895059e-02 -0.066146
2019-11-07 20:50:05,170 valid 050 1.592721e-02 -0.898857
2019-11-07 20:50:13,501 validation loss; R2: 1.564736e-02 -1.087478
2019-11-07 20:50:13,566 epoch 667 lr 1.000000e-05
2019-11-07 20:50:14,326 train 000 2.042136e-02 -0.195878
2019-11-07 20:50:24,035 train 050 1.680208e-02 -0.906617
2019-11-07 20:50:33,735 train 100 1.661451e-02 -0.857169
2019-11-07 20:50:43,448 train 150 1.668824e-02 -0.745004
2019-11-07 20:50:53,191 train 200 1.672535e-02 -0.718071
2019-11-07 20:51:02,934 train 250 1.683928e-02 -0.694291
2019-11-07 20:51:12,697 train 300 1.687386e-02 -0.711918
2019-11-07 20:51:22,441 train 350 1.690111e-02 -0.687498
2019-11-07 20:51:32,187 train 400 1.686434e-02 -0.700164
2019-11-07 20:51:41,936 train 450 1.686711e-02 -0.715976
2019-11-07 20:51:51,680 train 500 1.688230e-02 -0.707412
2019-11-07 20:52:01,441 train 550 1.687077e-02 -0.683718
2019-11-07 20:52:11,208 train 600 1.691041e-02 -0.687308
2019-11-07 20:52:20,971 train 650 1.691786e-02 -0.685742
2019-11-07 20:52:30,735 train 700 1.691419e-02 -0.677704
2019-11-07 20:52:40,493 train 750 1.688527e-02 -0.675982
2019-11-07 20:52:50,252 train 800 1.688107e-02 -0.688174
2019-11-07 20:53:00,015 train 850 1.688250e-02 -0.692851
2019-11-07 20:53:02,951 training loss; R2: 1.687701e-02 -0.691321
2019-11-07 20:53:03,643 valid 000 1.456258e-02 -1.818956
2019-11-07 20:53:13,042 valid 050 1.663677e-02 -1.124642
2019-11-07 20:53:21,355 validation loss; R2: 1.645085e-02 -1.143980
2019-11-07 20:53:21,421 epoch 668 lr 1.000000e-05
2019-11-07 20:53:22,167 train 000 1.988294e-02 0.007807
2019-11-07 20:53:31,910 train 050 1.705462e-02 -0.726823
2019-11-07 20:53:41,665 train 100 1.686917e-02 -0.649699
2019-11-07 20:53:51,428 train 150 1.687333e-02 -0.660357
2019-11-07 20:54:01,203 train 200 1.687568e-02 -0.683268
2019-11-07 20:54:10,969 train 250 1.688413e-02 -0.747452
2019-11-07 20:54:20,757 train 300 1.690753e-02 -0.749875
2019-11-07 20:54:30,540 train 350 1.686613e-02 -0.761873
2019-11-07 20:54:40,342 train 400 1.686989e-02 -0.771307
2019-11-07 20:54:50,176 train 450 1.684761e-02 -0.790807
2019-11-07 20:54:59,974 train 500 1.682633e-02 -0.783623
2019-11-07 20:55:09,764 train 550 1.679673e-02 -0.795587
2019-11-07 20:55:19,551 train 600 1.682949e-02 -0.765120
2019-11-07 20:55:29,346 train 650 1.681887e-02 -0.768893
2019-11-07 20:55:39,150 train 700 1.683180e-02 -0.757138
2019-11-07 20:55:48,957 train 750 1.683840e-02 -0.739573
2019-11-07 20:55:58,759 train 800 1.686162e-02 -0.792250
2019-11-07 20:56:08,565 train 850 1.685798e-02 -0.800324
2019-11-07 20:56:11,483 training loss; R2: 1.686819e-02 -0.793558
2019-11-07 20:56:12,146 valid 000 1.684364e-02 -0.294340
2019-11-07 20:56:21,558 valid 050 1.637892e-02 -1.206750
2019-11-07 20:56:29,879 validation loss; R2: 1.638465e-02 -1.281111
2019-11-07 20:56:29,945 epoch 669 lr 1.000000e-05
2019-11-07 20:56:30,701 train 000 1.666071e-02 0.030383
2019-11-07 20:56:40,450 train 050 1.680743e-02 -0.832559
2019-11-07 20:56:50,221 train 100 1.700941e-02 -0.892696
2019-11-07 20:57:00,003 train 150 1.700638e-02 -0.925301
2019-11-07 20:57:09,775 train 200 1.694925e-02 -0.905859
2019-11-07 20:57:19,557 train 250 1.702558e-02 -0.872552
2019-11-07 20:57:29,333 train 300 1.698167e-02 -0.805864
2019-11-07 20:57:39,112 train 350 1.699027e-02 -0.835068
2019-11-07 20:57:48,895 train 400 1.695796e-02 -0.792937
2019-11-07 20:57:58,671 train 450 1.696525e-02 -0.761039
2019-11-07 20:58:08,445 train 500 1.695873e-02 -0.757585
2019-11-07 20:58:18,230 train 550 1.692842e-02 -0.778370
2019-11-07 20:58:28,037 train 600 1.692331e-02 -0.765331
2019-11-07 20:58:37,839 train 650 1.691160e-02 -2.176271
2019-11-07 20:58:47,627 train 700 1.692732e-02 -2.113253
2019-11-07 20:58:57,418 train 750 1.691252e-02 -2.016809
2019-11-07 20:59:07,219 train 800 1.692901e-02 -1.935397
2019-11-07 20:59:17,021 train 850 1.694250e-02 -1.853961
2019-11-07 20:59:19,949 training loss; R2: 1.694584e-02 -1.837869
2019-11-07 20:59:20,570 valid 000 1.498564e-02 -3.447763
2019-11-07 20:59:30,002 valid 050 1.558581e-02 -0.890812
2019-11-07 20:59:38,322 validation loss; R2: 1.545162e-02 -0.812865
2019-11-07 20:59:38,380 epoch 670 lr 1.000000e-05
2019-11-07 20:59:39,111 train 000 2.249494e-02 0.019207
2019-11-07 20:59:48,858 train 050 1.669810e-02 -0.597362
2019-11-07 20:59:58,608 train 100 1.674057e-02 -0.535353
2019-11-07 21:00:08,364 train 150 1.671151e-02 -0.585880
2019-11-07 21:00:18,128 train 200 1.683718e-02 -0.622509
2019-11-07 21:00:27,888 train 250 1.683545e-02 -0.624305
2019-11-07 21:00:37,650 train 300 1.685362e-02 -0.614783
2019-11-07 21:00:47,420 train 350 1.681379e-02 -0.616975
2019-11-07 21:00:57,191 train 400 1.680111e-02 -0.612972
2019-11-07 21:01:06,965 train 450 1.683702e-02 -0.617417
2019-11-07 21:01:16,744 train 500 1.684499e-02 -0.639111
2019-11-07 21:01:26,524 train 550 1.685752e-02 -0.622139
2019-11-07 21:01:36,303 train 600 1.688477e-02 -0.624803
2019-11-07 21:01:46,079 train 650 1.690007e-02 -0.633382
2019-11-07 21:01:55,897 train 700 1.687399e-02 -0.635763
2019-11-07 21:02:05,696 train 750 1.688389e-02 -0.662977
2019-11-07 21:02:15,481 train 800 1.687706e-02 -0.719552
2019-11-07 21:02:25,268 train 850 1.687255e-02 -0.727963
2019-11-07 21:02:28,196 training loss; R2: 1.687848e-02 -0.724491
2019-11-07 21:02:28,833 valid 000 1.408229e-02 -1.020476
2019-11-07 21:02:38,230 valid 050 1.605346e-02 -1.137496
2019-11-07 21:02:46,579 validation loss; R2: 1.617882e-02 -1.056952
2019-11-07 21:02:46,648 epoch 671 lr 1.000000e-05
2019-11-07 21:02:47,436 train 000 1.895617e-02 -0.355649
2019-11-07 21:02:57,194 train 050 1.708896e-02 -0.540732
2019-11-07 21:03:06,956 train 100 1.719399e-02 -0.547950
2019-11-07 21:03:16,697 train 150 1.703756e-02 -0.700904
2019-11-07 21:03:26,451 train 200 1.696383e-02 -0.638837
2019-11-07 21:03:36,221 train 250 1.695591e-02 -0.616038
2019-11-07 21:03:45,985 train 300 1.696730e-02 -0.655895
2019-11-07 21:03:55,750 train 350 1.689253e-02 -0.646312
2019-11-07 21:04:05,512 train 400 1.688464e-02 -0.633167
2019-11-07 21:04:15,279 train 450 1.690544e-02 -0.634628
2019-11-07 21:04:25,407 train 500 1.691482e-02 -0.629628
2019-11-07 21:04:35,566 train 550 1.690840e-02 -0.637997
2019-11-07 21:04:45,728 train 600 1.692956e-02 -0.661779
2019-11-07 21:04:55,878 train 650 1.697225e-02 -0.657446
2019-11-07 21:05:06,041 train 700 1.696429e-02 -0.653563
2019-11-07 21:05:16,228 train 750 1.696628e-02 -0.649048
2019-11-07 21:05:26,405 train 800 1.696734e-02 -0.658802
2019-11-07 21:05:36,577 train 850 1.695676e-02 -0.695004
2019-11-07 21:05:39,614 training loss; R2: 1.695767e-02 -0.697831
2019-11-07 21:05:40,246 valid 000 1.632936e-02 -0.632446
2019-11-07 21:05:49,665 valid 050 1.577067e-02 -1.091631
2019-11-07 21:05:57,998 validation loss; R2: 1.568532e-02 -1.067994
2019-11-07 21:05:58,077 epoch 672 lr 1.000000e-05
2019-11-07 21:05:58,820 train 000 1.677720e-02 -0.819527
2019-11-07 21:06:08,924 train 050 1.687767e-02 -0.675748
2019-11-07 21:06:19,076 train 100 1.683427e-02 -0.725636
2019-11-07 21:06:29,204 train 150 1.696769e-02 -0.711188
2019-11-07 21:06:39,361 train 200 1.699289e-02 -0.692739
2019-11-07 21:06:49,513 train 250 1.696972e-02 -0.674671
2019-11-07 21:06:59,671 train 300 1.701714e-02 -0.690440
2019-11-07 21:07:09,814 train 350 1.699739e-02 -0.671440
2019-11-07 21:07:19,954 train 400 1.702321e-02 -0.656009
2019-11-07 21:07:30,127 train 450 1.695571e-02 -0.664400
2019-11-07 21:07:40,125 train 500 1.695856e-02 -0.677772
2019-11-07 21:07:49,915 train 550 1.699982e-02 -0.758799
2019-11-07 21:07:59,707 train 600 1.702926e-02 -0.755106
2019-11-07 21:08:09,517 train 650 1.702324e-02 -0.747758
2019-11-07 21:08:19,314 train 700 1.701683e-02 -0.763700
2019-11-07 21:08:29,146 train 750 1.699565e-02 -0.760124
2019-11-07 21:08:38,973 train 800 1.698952e-02 -0.746219
2019-11-07 21:08:48,812 train 850 1.700859e-02 -0.760887
2019-11-07 21:08:51,748 training loss; R2: 1.700427e-02 -0.768101
2019-11-07 21:08:52,390 valid 000 1.565520e-02 -1.281497
2019-11-07 21:09:01,810 valid 050 1.540020e-02 -0.945457
2019-11-07 21:09:10,129 validation loss; R2: 1.516912e-02 -1.015488
2019-11-07 21:09:10,194 epoch 673 lr 1.000000e-05
2019-11-07 21:09:10,951 train 000 1.670522e-02 -0.689500
2019-11-07 21:09:20,708 train 050 1.692264e-02 -0.437759
2019-11-07 21:09:30,493 train 100 1.657241e-02 -0.637747
2019-11-07 21:09:40,290 train 150 1.666085e-02 -0.781777
2019-11-07 21:09:50,084 train 200 1.678139e-02 -0.757436
2019-11-07 21:09:59,880 train 250 1.682095e-02 -0.770752
2019-11-07 21:10:09,671 train 300 1.682252e-02 -0.818279
2019-11-07 21:10:19,469 train 350 1.683454e-02 -0.818100
2019-11-07 21:10:29,291 train 400 1.681094e-02 -0.809185
2019-11-07 21:10:39,112 train 450 1.680607e-02 -0.800152
2019-11-07 21:10:48,930 train 500 1.682593e-02 -0.760086
2019-11-07 21:10:58,776 train 550 1.685486e-02 -0.749568
2019-11-07 21:11:08,597 train 600 1.687500e-02 -0.735240
2019-11-07 21:11:18,428 train 650 1.687106e-02 -0.755022
2019-11-07 21:11:28,261 train 700 1.688176e-02 -0.758711
2019-11-07 21:11:38,104 train 750 1.690257e-02 -0.758808
2019-11-07 21:11:47,947 train 800 1.689238e-02 -0.753429
2019-11-07 21:11:57,775 train 850 1.688269e-02 -0.744298
2019-11-07 21:12:00,718 training loss; R2: 1.687302e-02 -0.739866
2019-11-07 21:12:01,310 valid 000 1.804717e-02 -7.875101
2019-11-07 21:12:10,790 valid 050 1.628134e-02 -1.345900
2019-11-07 21:12:19,145 validation loss; R2: 1.611636e-02 -1.112612
2019-11-07 21:12:19,213 epoch 674 lr 1.000000e-05
2019-11-07 21:12:19,969 train 000 1.441755e-02 -0.477635
2019-11-07 21:12:29,745 train 050 1.661737e-02 -0.778117
2019-11-07 21:12:39,551 train 100 1.677727e-02 -0.649980
2019-11-07 21:12:49,346 train 150 1.666594e-02 -0.689947
2019-11-07 21:12:59,137 train 200 1.678851e-02 -0.759962
2019-11-07 21:13:08,935 train 250 1.684155e-02 -0.751471
2019-11-07 21:13:18,711 train 300 1.683768e-02 -0.744914
2019-11-07 21:13:28,521 train 350 1.687626e-02 -0.722598
2019-11-07 21:13:38,338 train 400 1.692422e-02 -0.731604
2019-11-07 21:13:48,150 train 450 1.694701e-02 -0.733957
2019-11-07 21:13:57,951 train 500 1.695372e-02 -0.738837
2019-11-07 21:14:07,768 train 550 1.692984e-02 -0.744149
2019-11-07 21:14:17,585 train 600 1.694940e-02 -0.749018
2019-11-07 21:14:27,403 train 650 1.691151e-02 -0.788488
2019-11-07 21:14:37,230 train 700 1.691581e-02 -0.801425
2019-11-07 21:14:47,049 train 750 1.691304e-02 -0.799829
2019-11-07 21:14:56,867 train 800 1.689646e-02 -0.804135
2019-11-07 21:15:06,690 train 850 1.688322e-02 -0.815333
2019-11-07 21:15:09,625 training loss; R2: 1.688898e-02 -0.813488
2019-11-07 21:15:10,322 valid 000 1.395844e-02 -0.706150
2019-11-07 21:15:19,705 valid 050 1.588326e-02 -0.945831
2019-11-07 21:15:28,141 validation loss; R2: 1.581807e-02 -1.081433
2019-11-07 21:15:28,208 epoch 675 lr 1.000000e-05
2019-11-07 21:15:29,070 train 000 1.810870e-02 -0.070999
2019-11-07 21:15:38,813 train 050 1.689687e-02 -0.857975
2019-11-07 21:15:48,601 train 100 1.698838e-02 -0.781625
2019-11-07 21:15:58,388 train 150 1.701383e-02 -0.779783
2019-11-07 21:16:08,179 train 200 1.695175e-02 -0.843369
2019-11-07 21:16:17,990 train 250 1.690455e-02 -0.780306
2019-11-07 21:16:27,800 train 300 1.692796e-02 -0.778675
2019-11-07 21:16:37,622 train 350 1.691493e-02 -0.791682
2019-11-07 21:16:47,459 train 400 1.690337e-02 -0.818831
2019-11-07 21:16:57,278 train 450 1.687439e-02 -0.836853
2019-11-07 21:17:07,102 train 500 1.692044e-02 -0.837120
2019-11-07 21:17:16,926 train 550 1.691012e-02 -0.846621
2019-11-07 21:17:26,746 train 600 1.688092e-02 -0.839707
2019-11-07 21:17:36,571 train 650 1.692782e-02 -0.818830
2019-11-07 21:17:46,392 train 700 1.691174e-02 -0.814014
2019-11-07 21:17:56,218 train 750 1.689214e-02 -0.801532
2019-11-07 21:18:06,067 train 800 1.691772e-02 -0.795134
2019-11-07 21:18:15,904 train 850 1.690694e-02 -0.816409
2019-11-07 21:18:18,842 training loss; R2: 1.690207e-02 -0.823747
2019-11-07 21:18:19,520 valid 000 2.810163e-02 -1.403648
2019-11-07 21:18:28,893 valid 050 2.836253e-02 -2.878946
2019-11-07 21:18:37,226 validation loss; R2: 2.794934e-02 -3.136389
2019-11-07 21:18:37,290 epoch 676 lr 1.000000e-05
2019-11-07 21:18:38,024 train 000 1.740437e-02 -0.258068
2019-11-07 21:18:47,800 train 050 1.732540e-02 -0.921353
2019-11-07 21:18:57,594 train 100 1.701889e-02 -1.363912
2019-11-07 21:19:07,383 train 150 1.697110e-02 -1.157649
2019-11-07 21:19:17,191 train 200 1.697731e-02 -1.025494
2019-11-07 21:19:27,023 train 250 1.703370e-02 -0.987353
2019-11-07 21:19:36,857 train 300 1.701648e-02 -1.012676
2019-11-07 21:19:46,686 train 350 1.698415e-02 -0.952123
2019-11-07 21:19:56,553 train 400 1.695806e-02 -0.919151
2019-11-07 21:20:06,392 train 450 1.694309e-02 -0.886582
2019-11-07 21:20:16,216 train 500 1.695807e-02 -0.877829
2019-11-07 21:20:26,030 train 550 1.693344e-02 -0.859661
2019-11-07 21:20:35,860 train 600 1.691855e-02 -0.884534
2019-11-07 21:20:45,678 train 650 1.691223e-02 -0.904086
2019-11-07 21:20:55,513 train 700 1.690711e-02 -0.888443
2019-11-07 21:21:05,364 train 750 1.691408e-02 -0.864362
2019-11-07 21:21:15,186 train 800 1.693411e-02 -0.856898
2019-11-07 21:21:24,996 train 850 1.694071e-02 -0.839410
2019-11-07 21:21:27,937 training loss; R2: 1.694340e-02 -0.833299
2019-11-07 21:21:28,624 valid 000 1.449386e-02 -0.019981
2019-11-07 21:21:37,997 valid 050 1.558949e-02 -1.369718
2019-11-07 21:21:46,310 validation loss; R2: 1.567494e-02 -1.426225
2019-11-07 21:21:46,377 epoch 677 lr 1.000000e-05
2019-11-07 21:21:47,101 train 000 2.036177e-02 -0.604534
2019-11-07 21:21:56,834 train 050 1.729002e-02 -0.644769
2019-11-07 21:22:06,572 train 100 1.725465e-02 -0.596059
2019-11-07 21:22:16,338 train 150 1.714083e-02 -0.594955
2019-11-07 21:22:26,082 train 200 1.717153e-02 -0.579458
2019-11-07 21:22:35,836 train 250 1.707690e-02 -0.583742
2019-11-07 21:22:45,616 train 300 1.705210e-02 -0.606496
2019-11-07 21:22:55,390 train 350 1.696735e-02 -0.654459
2019-11-07 21:23:05,165 train 400 1.696489e-02 -0.688848
2019-11-07 21:23:14,946 train 450 1.694505e-02 -0.707867
2019-11-07 21:23:24,728 train 500 1.692255e-02 -0.702993
2019-11-07 21:23:34,504 train 550 1.693329e-02 -0.702659
2019-11-07 21:23:44,289 train 600 1.694958e-02 -0.734976
2019-11-07 21:23:54,068 train 650 1.698307e-02 -0.744459
2019-11-07 21:24:03,857 train 700 1.699726e-02 -0.748752
2019-11-07 21:24:13,637 train 750 1.700572e-02 -0.749139
2019-11-07 21:24:23,425 train 800 1.700188e-02 -0.742431
2019-11-07 21:24:33,208 train 850 1.698018e-02 -0.732344
2019-11-07 21:24:36,130 training loss; R2: 1.697578e-02 -0.735899
2019-11-07 21:24:36,819 valid 000 1.361784e-02 -2.800671
2019-11-07 21:24:46,204 valid 050 1.511905e-02 -1.184934
2019-11-07 21:24:54,553 validation loss; R2: 1.536249e-02 -1.230119
2019-11-07 21:24:54,618 epoch 678 lr 1.000000e-05
2019-11-07 21:24:55,345 train 000 1.728167e-02 -0.098216
2019-11-07 21:25:05,083 train 050 1.695370e-02 -0.688198
2019-11-07 21:25:14,840 train 100 1.697433e-02 -0.612774
2019-11-07 21:25:24,610 train 150 1.696673e-02 -0.580480
2019-11-07 21:25:34,379 train 200 1.696184e-02 -0.617942
2019-11-07 21:25:44,150 train 250 1.691149e-02 -0.667203
2019-11-07 21:25:53,942 train 300 1.680260e-02 -0.776071
2019-11-07 21:26:03,749 train 350 1.685691e-02 -0.745268
2019-11-07 21:26:13,551 train 400 1.690210e-02 -0.742907
2019-11-07 21:26:23,333 train 450 1.688219e-02 -0.722696
2019-11-07 21:26:33,126 train 500 1.689837e-02 -0.717242
2019-11-07 21:26:42,913 train 550 1.687128e-02 -0.713977
2019-11-07 21:26:52,701 train 600 1.688714e-02 -0.713022
2019-11-07 21:27:02,489 train 650 1.691098e-02 -0.720562
2019-11-07 21:27:12,295 train 700 1.690033e-02 -0.722694
2019-11-07 21:27:22,093 train 750 1.690670e-02 -0.735834
2019-11-07 21:27:31,887 train 800 1.689789e-02 -0.729690
2019-11-07 21:27:41,675 train 850 1.691634e-02 -0.742547
2019-11-07 21:27:44,602 training loss; R2: 1.690960e-02 -0.744073
2019-11-07 21:27:45,234 valid 000 1.621050e-02 0.024608
2019-11-07 21:27:54,673 valid 050 1.558613e-02 -0.789752
2019-11-07 21:28:02,995 validation loss; R2: 1.554449e-02 -0.903387
2019-11-07 21:28:03,072 epoch 679 lr 1.000000e-05
2019-11-07 21:28:03,792 train 000 1.744929e-02 -0.429143
2019-11-07 21:28:13,517 train 050 1.712534e-02 -0.526193
2019-11-07 21:28:23,251 train 100 1.701907e-02 -0.662966
2019-11-07 21:28:33,006 train 150 1.691320e-02 -0.610655
2019-11-07 21:28:42,781 train 200 1.693385e-02 -0.649919
2019-11-07 21:28:52,536 train 250 1.691746e-02 -0.643057
2019-11-07 21:29:02,321 train 300 1.697632e-02 -0.623097
2019-11-07 21:29:12,109 train 350 1.697607e-02 -0.715019
2019-11-07 21:29:21,901 train 400 1.698819e-02 -0.720310
2019-11-07 21:29:31,705 train 450 1.698270e-02 -0.732509
2019-11-07 21:29:41,511 train 500 1.695388e-02 -0.736194
2019-11-07 21:29:51,321 train 550 1.696660e-02 -10.957751
2019-11-07 21:30:01,159 train 600 1.693766e-02 -10.111578
2019-11-07 21:30:10,966 train 650 1.693256e-02 -9.402097
2019-11-07 21:30:20,786 train 700 1.688460e-02 -8.795548
2019-11-07 21:30:30,599 train 750 1.688091e-02 -8.272264
2019-11-07 21:30:40,412 train 800 1.685046e-02 -7.779888
2019-11-07 21:30:50,230 train 850 1.682625e-02 -7.372951
2019-11-07 21:30:53,167 training loss; R2: 1.682753e-02 -7.252146
2019-11-07 21:30:53,846 valid 000 1.510730e-02 -1.839649
2019-11-07 21:31:03,257 valid 050 1.522113e-02 -1.239169
2019-11-07 21:31:11,552 validation loss; R2: 1.513581e-02 -1.283587
2019-11-07 21:31:11,618 epoch 680 lr 1.000000e-05
2019-11-07 21:31:12,365 train 000 1.663364e-02 -1.109220
2019-11-07 21:31:22,125 train 050 1.717205e-02 -0.849719
2019-11-07 21:31:31,887 train 100 1.684418e-02 -0.876764
2019-11-07 21:31:41,676 train 150 1.688739e-02 -0.857186
2019-11-07 21:31:51,465 train 200 1.682397e-02 -0.826994
2019-11-07 21:32:01,257 train 250 1.681784e-02 -0.842532
2019-11-07 21:32:11,062 train 300 1.684095e-02 -0.854159
2019-11-07 21:32:20,873 train 350 1.686078e-02 -0.878335
2019-11-07 21:32:30,694 train 400 1.688641e-02 -0.874129
2019-11-07 21:32:40,486 train 450 1.682778e-02 -0.861959
2019-11-07 21:32:50,265 train 500 1.681163e-02 -0.835647
2019-11-07 21:33:00,039 train 550 1.681381e-02 -0.836752
2019-11-07 21:33:09,838 train 600 1.679544e-02 -0.810224
2019-11-07 21:33:19,657 train 650 1.682616e-02 -0.809961
2019-11-07 21:33:29,444 train 700 1.679998e-02 -0.793161
2019-11-07 21:33:39,242 train 750 1.680396e-02 -0.797345
2019-11-07 21:33:49,041 train 800 1.679763e-02 -0.784773
2019-11-07 21:33:58,831 train 850 1.681524e-02 -0.794152
2019-11-07 21:34:01,757 training loss; R2: 1.682013e-02 -0.799767
2019-11-07 21:34:02,392 valid 000 1.893931e-02 -1.915777
2019-11-07 21:34:11,854 valid 050 1.982000e-02 -2.316953
2019-11-07 21:34:20,158 validation loss; R2: 1.964829e-02 -2.356914
2019-11-07 21:34:20,224 epoch 681 lr 1.000000e-05
2019-11-07 21:34:20,968 train 000 2.048248e-02 -0.453198
2019-11-07 21:34:30,700 train 050 1.711774e-02 -0.653256
2019-11-07 21:34:40,438 train 100 1.712206e-02 -0.714052
2019-11-07 21:34:50,196 train 150 1.702625e-02 -0.726050
2019-11-07 21:34:59,958 train 200 1.693981e-02 -0.782209
2019-11-07 21:35:09,729 train 250 1.691549e-02 -0.824526
2019-11-07 21:35:19,499 train 300 1.694069e-02 -0.787373
2019-11-07 21:35:29,272 train 350 1.692144e-02 -0.807784
2019-11-07 21:35:39,066 train 400 1.696615e-02 -0.816160
2019-11-07 21:35:48,850 train 450 1.694485e-02 -0.778141
2019-11-07 21:35:58,628 train 500 1.695787e-02 -0.771271
2019-11-07 21:36:08,416 train 550 1.699464e-02 -0.759783
2019-11-07 21:36:18,209 train 600 1.700862e-02 -0.748663
2019-11-07 21:36:28,003 train 650 1.698144e-02 -0.727589
2019-11-07 21:36:37,794 train 700 1.693275e-02 -0.731317
2019-11-07 21:36:47,606 train 750 1.691225e-02 -0.721175
2019-11-07 21:36:57,406 train 800 1.690199e-02 -0.711188
2019-11-07 21:37:07,220 train 850 1.691676e-02 -0.738728
2019-11-07 21:37:10,156 training loss; R2: 1.692279e-02 -0.759549
2019-11-07 21:37:10,770 valid 000 1.608323e-02 -0.055410
2019-11-07 21:37:20,170 valid 050 1.507215e-02 -0.783595
2019-11-07 21:37:28,486 validation loss; R2: 1.502103e-02 -1.786112
2019-11-07 21:37:28,551 epoch 682 lr 1.000000e-05
2019-11-07 21:37:29,322 train 000 1.656259e-02 -0.680980
2019-11-07 21:37:39,066 train 050 1.696970e-02 -0.704978
2019-11-07 21:37:48,833 train 100 1.700068e-02 -0.814230
2019-11-07 21:37:58,626 train 150 1.699494e-02 -0.911513
2019-11-07 21:38:08,427 train 200 1.700415e-02 -0.922041
2019-11-07 21:38:18,226 train 250 1.701012e-02 -0.916306
2019-11-07 21:38:28,029 train 300 1.700902e-02 -0.895333
2019-11-07 21:38:37,837 train 350 1.698746e-02 -0.854849
2019-11-07 21:38:47,664 train 400 1.695299e-02 -0.834555
2019-11-07 21:38:57,487 train 450 1.698458e-02 -0.824066
2019-11-07 21:39:07,302 train 500 1.700147e-02 -0.834793
2019-11-07 21:39:17,103 train 550 1.696339e-02 -0.895808
2019-11-07 21:39:26,938 train 600 1.698959e-02 -0.875735
2019-11-07 21:39:36,749 train 650 1.697863e-02 -0.846452
2019-11-07 21:39:46,577 train 700 1.696456e-02 -0.837023
2019-11-07 21:39:56,387 train 750 1.697161e-02 -0.835987
2019-11-07 21:40:06,195 train 800 1.696367e-02 -0.822087
2019-11-07 21:40:16,031 train 850 1.698006e-02 -0.802914
2019-11-07 21:40:18,960 training loss; R2: 1.697931e-02 -0.801863
2019-11-07 21:40:19,557 valid 000 1.673158e-02 -0.429254
2019-11-07 21:40:29,024 valid 050 1.591263e-02 -0.878807
2019-11-07 21:40:37,354 validation loss; R2: 1.585891e-02 -1.318398
2019-11-07 21:40:37,421 epoch 683 lr 1.000000e-05
2019-11-07 21:40:38,157 train 000 1.688586e-02 0.021211
2019-11-07 21:40:47,910 train 050 1.688365e-02 -0.634551
2019-11-07 21:40:57,674 train 100 1.695601e-02 -0.656590
2019-11-07 21:41:07,461 train 150 1.695539e-02 -0.711434
2019-11-07 21:41:17,261 train 200 1.696250e-02 -0.665092
2019-11-07 21:41:27,069 train 250 1.691266e-02 -0.796331
2019-11-07 21:41:36,871 train 300 1.692673e-02 -0.809217
2019-11-07 21:41:46,684 train 350 1.695233e-02 -0.844735
2019-11-07 21:41:56,501 train 400 1.692471e-02 -0.856655
2019-11-07 21:42:06,315 train 450 1.693795e-02 -1.064556
2019-11-07 21:42:16,119 train 500 1.694457e-02 -1.024563
2019-11-07 21:42:25,927 train 550 1.696275e-02 -0.991565
2019-11-07 21:42:35,732 train 600 1.698905e-02 -4.165123
2019-11-07 21:42:45,548 train 650 1.696309e-02 -3.908038
2019-11-07 21:42:55,370 train 700 1.697600e-02 -3.683429
2019-11-07 21:43:05,190 train 750 1.697947e-02 -3.472830
2019-11-07 21:43:15,012 train 800 1.697072e-02 -3.323064
2019-11-07 21:43:24,825 train 850 1.695941e-02 -3.167228
2019-11-07 21:43:27,760 training loss; R2: 1.696546e-02 -3.121698
2019-11-07 21:43:28,375 valid 000 1.468032e-02 -0.501862
2019-11-07 21:43:37,846 valid 050 1.467007e-02 -1.127250
2019-11-07 21:43:46,185 validation loss; R2: 1.465087e-02 -1.049976
2019-11-07 21:43:46,260 epoch 684 lr 1.000000e-05
2019-11-07 21:43:47,037 train 000 1.724155e-02 -0.379913
2019-11-07 21:43:56,942 train 050 1.691241e-02 -0.712246
2019-11-07 21:44:06,690 train 100 1.697744e-02 -0.826936
2019-11-07 21:44:16,447 train 150 1.699025e-02 -0.827072
2019-11-07 21:44:26,230 train 200 1.697089e-02 -0.849505
2019-11-07 21:44:36,017 train 250 1.693567e-02 -0.840264
2019-11-07 21:44:45,806 train 300 1.703686e-02 -0.816397
2019-11-07 21:44:55,573 train 350 1.703669e-02 -0.797687
2019-11-07 21:45:05,357 train 400 1.699806e-02 -0.785803
2019-11-07 21:45:15,144 train 450 1.695552e-02 -0.933934
2019-11-07 21:45:24,927 train 500 1.695246e-02 -0.949346
2019-11-07 21:45:34,719 train 550 1.697143e-02 -0.912526
2019-11-07 21:45:44,512 train 600 1.699998e-02 -0.881905
2019-11-07 21:45:54,303 train 650 1.697680e-02 -0.864673
2019-11-07 21:46:04,085 train 700 1.697092e-02 -0.854599
2019-11-07 21:46:13,875 train 750 1.696119e-02 -0.835165
2019-11-07 21:46:23,658 train 800 1.695327e-02 -2.917845
2019-11-07 21:46:33,442 train 850 1.692249e-02 -2.792500
2019-11-07 21:46:36,379 training loss; R2: 1.693427e-02 -2.758651
2019-11-07 21:46:37,011 valid 000 1.881078e-02 -13.322951
2019-11-07 21:46:46,484 valid 050 1.936180e-02 -2.500403
2019-11-07 21:46:54,809 validation loss; R2: 1.941477e-02 -3.096284
2019-11-07 21:46:54,876 epoch 685 lr 1.000000e-05
2019-11-07 21:46:55,601 train 000 1.792753e-02 -0.120297
2019-11-07 21:47:05,342 train 050 1.673535e-02 -0.878590
2019-11-07 21:47:15,131 train 100 1.674059e-02 -0.790090
2019-11-07 21:47:24,916 train 150 1.679987e-02 -0.782911
2019-11-07 21:47:34,710 train 200 1.683882e-02 -0.793784
2019-11-07 21:47:44,506 train 250 1.689709e-02 -0.825266
2019-11-07 21:47:54,289 train 300 1.694988e-02 -0.809948
2019-11-07 21:48:04,085 train 350 1.693654e-02 -0.937947
2019-11-07 21:48:13,890 train 400 1.691456e-02 -0.896113
2019-11-07 21:48:23,698 train 450 1.690900e-02 -0.859472
2019-11-07 21:48:33,489 train 500 1.692660e-02 -0.879669
2019-11-07 21:48:43,289 train 550 1.692139e-02 -0.854688
2019-11-07 21:48:53,106 train 600 1.693813e-02 -0.840776
2019-11-07 21:49:02,935 train 650 1.691204e-02 -0.811789
2019-11-07 21:49:12,767 train 700 1.694735e-02 -0.796615
2019-11-07 21:49:22,593 train 750 1.693488e-02 -0.784264
2019-11-07 21:49:32,414 train 800 1.693915e-02 -0.762281
2019-11-07 21:49:42,214 train 850 1.695377e-02 -0.767658
2019-11-07 21:49:45,137 training loss; R2: 1.695455e-02 -0.768678
2019-11-07 21:49:45,734 valid 000 2.144422e-02 -1.691585
2019-11-07 21:49:55,139 valid 050 1.922415e-02 -2.231092
2019-11-07 21:50:03,465 validation loss; R2: 1.945158e-02 -2.315896
2019-11-07 21:50:03,530 epoch 686 lr 1.000000e-05
2019-11-07 21:50:04,289 train 000 1.584873e-02 -0.058216
2019-11-07 21:50:14,078 train 050 1.657794e-02 -0.706813
2019-11-07 21:50:23,885 train 100 1.672723e-02 -0.708315
2019-11-07 21:50:33,680 train 150 1.683920e-02 -0.760792
2019-11-07 21:50:43,475 train 200 1.684518e-02 -0.741806
2019-11-07 21:50:53,269 train 250 1.678108e-02 -0.729167
2019-11-07 21:51:03,077 train 300 1.685999e-02 -0.737297
2019-11-07 21:51:12,884 train 350 1.685249e-02 -0.707024
2019-11-07 21:51:22,697 train 400 1.687267e-02 -0.704650
2019-11-07 21:51:32,515 train 450 1.691974e-02 -0.727215
2019-11-07 21:51:42,324 train 500 1.695623e-02 -0.715479
2019-11-07 21:51:52,133 train 550 1.698295e-02 -0.713097
2019-11-07 21:52:01,963 train 600 1.701721e-02 -0.735112
2019-11-07 21:52:11,794 train 650 1.697159e-02 -0.734931
2019-11-07 21:52:21,616 train 700 1.696344e-02 -0.780524
2019-11-07 21:52:31,441 train 750 1.699962e-02 -1.003161
2019-11-07 21:52:41,277 train 800 1.701943e-02 -0.993120
2019-11-07 21:52:51,101 train 850 1.699366e-02 -0.979609
2019-11-07 21:52:54,062 training loss; R2: 1.698887e-02 -0.969031
2019-11-07 21:52:54,689 valid 000 1.793254e-02 -0.669326
2019-11-07 21:53:04,116 valid 050 1.690511e-02 -1.547254
2019-11-07 21:53:12,471 validation loss; R2: 1.714352e-02 -1.579375
2019-11-07 21:53:12,539 epoch 687 lr 1.000000e-05
2019-11-07 21:53:13,323 train 000 1.540869e-02 -0.045499
2019-11-07 21:53:23,133 train 050 1.691674e-02 -1.899774
2019-11-07 21:53:32,965 train 100 1.684792e-02 -1.759736
2019-11-07 21:53:42,839 train 150 1.684453e-02 -1.504389
2019-11-07 21:53:52,694 train 200 1.687142e-02 -1.298053
2019-11-07 21:54:02,473 train 250 1.695455e-02 -1.171101
2019-11-07 21:54:12,249 train 300 1.695345e-02 -1.080950
2019-11-07 21:54:22,013 train 350 1.689438e-02 -1.026205
2019-11-07 21:54:31,773 train 400 1.692192e-02 -0.967919
2019-11-07 21:54:41,566 train 450 1.696508e-02 -1.358542
2019-11-07 21:54:51,381 train 500 1.697470e-02 -1.319948
2019-11-07 21:55:01,193 train 550 1.700322e-02 -1.258944
2019-11-07 21:55:11,012 train 600 1.698601e-02 -1.217390
2019-11-07 21:55:20,818 train 650 1.697552e-02 -1.169514
2019-11-07 21:55:30,635 train 700 1.696616e-02 -1.151629
2019-11-07 21:55:40,459 train 750 1.695936e-02 -1.113173
2019-11-07 21:55:50,269 train 800 1.694907e-02 -1.079075
2019-11-07 21:56:00,094 train 850 1.695171e-02 -1.075367
2019-11-07 21:56:03,027 training loss; R2: 1.694591e-02 -1.065757
2019-11-07 21:56:03,712 valid 000 1.391529e-02 -0.013398
2019-11-07 21:56:13,129 valid 050 1.581060e-02 -1.469272
2019-11-07 21:56:21,446 validation loss; R2: 1.580754e-02 -1.360330
2019-11-07 21:56:21,512 epoch 688 lr 1.000000e-05
2019-11-07 21:56:22,303 train 000 1.933872e-02 -0.288430
2019-11-07 21:56:32,046 train 050 1.767070e-02 -0.624823
2019-11-07 21:56:41,805 train 100 1.741739e-02 -0.643860
2019-11-07 21:56:51,556 train 150 1.718993e-02 -0.611927
2019-11-07 21:57:01,342 train 200 1.714258e-02 -0.721730
2019-11-07 21:57:11,137 train 250 1.717004e-02 -0.708606
2019-11-07 21:57:20,933 train 300 1.719282e-02 -0.759340
2019-11-07 21:57:30,737 train 350 1.718472e-02 -0.740189
2019-11-07 21:57:40,533 train 400 1.718535e-02 -0.760281
2019-11-07 21:57:50,350 train 450 1.716267e-02 -0.753452
2019-11-07 21:58:00,129 train 500 1.706896e-02 -0.745607
2019-11-07 21:58:09,918 train 550 1.703607e-02 -0.750013
2019-11-07 21:58:19,707 train 600 1.701137e-02 -0.738082
2019-11-07 21:58:29,511 train 650 1.703550e-02 -0.726293
2019-11-07 21:58:39,305 train 700 1.702096e-02 -0.745475
2019-11-07 21:58:49,086 train 750 1.700152e-02 -0.783118
2019-11-07 21:58:58,880 train 800 1.697700e-02 -0.790477
2019-11-07 21:59:08,657 train 850 1.696510e-02 -0.770768
2019-11-07 21:59:11,582 training loss; R2: 1.695595e-02 -0.768830
2019-11-07 21:59:12,227 valid 000 1.382613e-02 -0.106367
2019-11-07 21:59:21,654 valid 050 1.648409e-02 -1.279386
2019-11-07 21:59:29,973 validation loss; R2: 1.642770e-02 -1.347607
2019-11-07 21:59:30,042 epoch 689 lr 1.000000e-05
2019-11-07 21:59:30,809 train 000 1.896740e-02 0.014702
2019-11-07 21:59:40,546 train 050 1.725155e-02 -0.597355
2019-11-07 21:59:50,289 train 100 1.709251e-02 -0.649284
2019-11-07 22:00:00,057 train 150 1.696354e-02 -0.684049
2019-11-07 22:00:09,834 train 200 1.698818e-02 -0.671224
2019-11-07 22:00:19,603 train 250 1.695995e-02 -0.680778
2019-11-07 22:00:29,381 train 300 1.697489e-02 -0.662287
2019-11-07 22:00:39,153 train 350 1.687437e-02 -0.713731
2019-11-07 22:00:48,937 train 400 1.691392e-02 -0.721294
2019-11-07 22:00:58,736 train 450 1.690638e-02 -0.755696
2019-11-07 22:01:08,517 train 500 1.691187e-02 -0.755987
2019-11-07 22:01:18,309 train 550 1.693298e-02 -0.762168
2019-11-07 22:01:28,096 train 600 1.693734e-02 -0.744378
2019-11-07 22:01:37,875 train 650 1.692055e-02 -0.731687
2019-11-07 22:01:47,692 train 700 1.690503e-02 -0.728248
2019-11-07 22:01:57,479 train 750 1.689849e-02 -0.740751
2019-11-07 22:02:07,258 train 800 1.690452e-02 -0.754324
2019-11-07 22:02:17,043 train 850 1.691965e-02 -0.752093
2019-11-07 22:02:19,971 training loss; R2: 1.692817e-02 -0.753143
2019-11-07 22:02:20,669 valid 000 1.472849e-02 -0.198417
2019-11-07 22:02:30,106 valid 050 1.521184e-02 -1.048026
2019-11-07 22:02:38,485 validation loss; R2: 1.543695e-02 -1.192534
2019-11-07 22:02:38,549 epoch 690 lr 1.000000e-05
2019-11-07 22:02:39,327 train 000 1.983055e-02 0.105501
2019-11-07 22:02:49,071 train 050 1.673219e-02 -0.574391
2019-11-07 22:02:58,803 train 100 1.689257e-02 -0.608373
2019-11-07 22:03:08,577 train 150 1.702365e-02 -0.628134
2019-11-07 22:03:18,341 train 200 1.698659e-02 -0.884244
2019-11-07 22:03:28,113 train 250 1.701957e-02 -0.837513
2019-11-07 22:03:37,905 train 300 1.698512e-02 -0.812433
2019-11-07 22:03:47,698 train 350 1.696886e-02 -0.804447
2019-11-07 22:03:57,485 train 400 1.691898e-02 -0.865603
2019-11-07 22:04:07,276 train 450 1.691785e-02 -0.882550
2019-11-07 22:04:17,064 train 500 1.693359e-02 -0.851288
2019-11-07 22:04:26,858 train 550 1.694268e-02 -0.849166
2019-11-07 22:04:36,660 train 600 1.694997e-02 -0.839504
2019-11-07 22:04:46,458 train 650 1.695809e-02 -0.830802
2019-11-07 22:04:56,262 train 700 1.696264e-02 -0.844437
2019-11-07 22:05:06,052 train 750 1.696218e-02 -1.011826
2019-11-07 22:05:15,849 train 800 1.693357e-02 -1.063017
2019-11-07 22:05:25,644 train 850 1.691942e-02 -1.046956
2019-11-07 22:05:28,570 training loss; R2: 1.692085e-02 -1.070964
2019-11-07 22:05:29,268 valid 000 3.208636e-02 -3.327181
2019-11-07 22:05:38,625 valid 050 3.202442e-02 -3.571304
2019-11-07 22:05:46,961 validation loss; R2: 3.242006e-02 -4.033415
2019-11-07 22:05:47,041 epoch 691 lr 1.000000e-05
2019-11-07 22:05:47,827 train 000 1.661183e-02 -0.534943
2019-11-07 22:05:57,562 train 050 1.635589e-02 -0.756734
2019-11-07 22:06:07,286 train 100 1.658877e-02 -0.751002
2019-11-07 22:06:17,038 train 150 1.638435e-02 -0.803683
2019-11-07 22:06:26,801 train 200 1.649819e-02 -0.816732
2019-11-07 22:06:36,576 train 250 1.652573e-02 -0.763475
2019-11-07 22:06:46,362 train 300 1.660359e-02 -0.756077
2019-11-07 22:06:56,128 train 350 1.663432e-02 -2.914008
2019-11-07 22:07:05,921 train 400 1.670233e-02 -2.642207
2019-11-07 22:07:15,693 train 450 1.672473e-02 -2.431690
2019-11-07 22:07:25,488 train 500 1.678241e-02 -2.290585
2019-11-07 22:07:35,306 train 550 1.679289e-02 -2.300051
2019-11-07 22:07:45,126 train 600 1.681618e-02 -2.166874
2019-11-07 22:07:54,946 train 650 1.684514e-02 -2.060753
2019-11-07 22:08:04,757 train 700 1.687670e-02 -1.969659
2019-11-07 22:08:14,581 train 750 1.684744e-02 -1.893821
2019-11-07 22:08:24,406 train 800 1.682647e-02 -13.437854
2019-11-07 22:08:34,236 train 850 1.681905e-02 -12.697714
2019-11-07 22:08:37,180 training loss; R2: 1.682503e-02 -12.492896
2019-11-07 22:08:37,824 valid 000 1.537408e-02 -1.241986
2019-11-07 22:08:47,272 valid 050 1.583686e-02 -1.365948
2019-11-07 22:08:55,596 validation loss; R2: 1.584929e-02 -1.159177
2019-11-07 22:08:55,660 epoch 692 lr 1.000000e-05
2019-11-07 22:08:56,440 train 000 1.621211e-02 0.028784
2019-11-07 22:09:06,192 train 050 1.678039e-02 -0.703966
2019-11-07 22:09:15,989 train 100 1.682428e-02 -0.607067
2019-11-07 22:09:25,806 train 150 1.680824e-02 -0.623576
2019-11-07 22:09:35,645 train 200 1.686033e-02 -0.597342
2019-11-07 22:09:45,462 train 250 1.682356e-02 -0.576082
2019-11-07 22:09:55,312 train 300 1.684116e-02 -0.598962
2019-11-07 22:10:05,161 train 350 1.680420e-02 -0.636125
2019-11-07 22:10:15,003 train 400 1.678553e-02 -0.648599
2019-11-07 22:10:24,854 train 450 1.682991e-02 -0.650063
2019-11-07 22:10:34,707 train 500 1.682372e-02 -0.670710
2019-11-07 22:10:44,542 train 550 1.683104e-02 -0.679736
2019-11-07 22:10:54,383 train 600 1.683221e-02 -0.677392
2019-11-07 22:11:04,229 train 650 1.682262e-02 -0.677785
2019-11-07 22:11:14,071 train 700 1.683561e-02 -0.677234
2019-11-07 22:11:23,917 train 750 1.686174e-02 -0.690103
2019-11-07 22:11:33,778 train 800 1.687607e-02 -0.696447
2019-11-07 22:11:43,633 train 850 1.686931e-02 -0.696840
2019-11-07 22:11:46,576 training loss; R2: 1.687089e-02 -0.695926
2019-11-07 22:11:47,228 valid 000 2.267615e-02 -0.931910
2019-11-07 22:11:56,690 valid 050 2.108657e-02 -2.469161
2019-11-07 22:12:05,055 validation loss; R2: 2.126971e-02 -2.359069
2019-11-07 22:12:05,121 epoch 693 lr 1.000000e-05
2019-11-07 22:12:05,892 train 000 1.724356e-02 -0.508379
2019-11-07 22:12:15,623 train 050 1.690016e-02 -0.914582
2019-11-07 22:12:25,378 train 100 1.698669e-02 -0.719604
2019-11-07 22:12:35,151 train 150 1.686802e-02 -0.712165
2019-11-07 22:12:44,925 train 200 1.686401e-02 -0.760666
2019-11-07 22:12:54,701 train 250 1.686981e-02 -0.730098
2019-11-07 22:13:04,484 train 300 1.681492e-02 -0.746167
2019-11-07 22:13:14,256 train 350 1.685332e-02 -0.776817
2019-11-07 22:13:24,017 train 400 1.686899e-02 -0.753316
2019-11-07 22:13:33,764 train 450 1.689873e-02 -0.923965
2019-11-07 22:13:43,531 train 500 1.689098e-02 -0.923929
2019-11-07 22:13:53,282 train 550 1.690605e-02 -0.905731
2019-11-07 22:14:03,044 train 600 1.689483e-02 -0.892365
2019-11-07 22:14:12,813 train 650 1.689319e-02 -0.869521
2019-11-07 22:14:22,575 train 700 1.694200e-02 -0.864607
2019-11-07 22:14:32,343 train 750 1.694791e-02 -0.918534
2019-11-07 22:14:42,119 train 800 1.695399e-02 -0.903760
2019-11-07 22:14:51,876 train 850 1.696216e-02 -0.879970
2019-11-07 22:14:54,786 training loss; R2: 1.696455e-02 -0.882578
2019-11-07 22:14:55,495 valid 000 1.753089e-02 -0.583523
2019-11-07 22:15:04,803 valid 050 2.014682e-02 -2.426345
2019-11-07 22:15:13,288 validation loss; R2: 2.033774e-02 -2.512193
2019-11-07 22:15:13,355 epoch 694 lr 1.000000e-05
2019-11-07 22:15:14,079 train 000 1.617133e-02 -0.404742
2019-11-07 22:15:23,801 train 050 1.708909e-02 -0.707978
2019-11-07 22:15:33,489 train 100 1.719684e-02 -0.737911
2019-11-07 22:15:43,214 train 150 1.714943e-02 -0.909163
2019-11-07 22:15:52,954 train 200 1.711990e-02 -0.950090
2019-11-07 22:16:02,706 train 250 1.707369e-02 -0.906382
2019-11-07 22:16:12,456 train 300 1.703911e-02 -0.879886
2019-11-07 22:16:22,203 train 350 1.698063e-02 -0.864447
2019-11-07 22:16:31,952 train 400 1.697593e-02 -0.877730
2019-11-07 22:16:41,708 train 450 1.698328e-02 -0.856960
2019-11-07 22:16:51,464 train 500 1.698994e-02 -0.842839
2019-11-07 22:17:01,224 train 550 1.695765e-02 -4.342096
2019-11-07 22:17:10,978 train 600 1.691235e-02 -4.065673
2019-11-07 22:17:20,733 train 650 1.693860e-02 -3.801668
2019-11-07 22:17:30,487 train 700 1.690633e-02 -3.568322
2019-11-07 22:17:40,240 train 750 1.692676e-02 -3.377484
2019-11-07 22:17:50,007 train 800 1.692430e-02 -3.207387
2019-11-07 22:17:59,762 train 850 1.692555e-02 -3.062995
2019-11-07 22:18:02,678 training loss; R2: 1.691823e-02 -3.018300
2019-11-07 22:18:03,263 valid 000 1.729452e-02 -4.147495
2019-11-07 22:18:12,762 valid 050 1.581321e-02 -0.880506
2019-11-07 22:18:21,145 validation loss; R2: 1.583492e-02 -1.286695
2019-11-07 22:18:21,225 epoch 695 lr 1.000000e-05
2019-11-07 22:18:22,032 train 000 1.570978e-02 -0.102482
2019-11-07 22:18:31,756 train 050 1.661408e-02 -0.725895
2019-11-07 22:18:41,489 train 100 1.690303e-02 -1.844738
2019-11-07 22:18:51,255 train 150 1.677192e-02 -1.441214
2019-11-07 22:19:01,042 train 200 1.674679e-02 -1.224519
2019-11-07 22:19:10,858 train 250 1.680344e-02 -1.097066
2019-11-07 22:19:20,670 train 300 1.681701e-02 -1.003123
2019-11-07 22:19:30,493 train 350 1.686429e-02 -0.981371
2019-11-07 22:19:40,322 train 400 1.686053e-02 -0.965538
2019-11-07 22:19:50,145 train 450 1.693073e-02 -0.916343
2019-11-07 22:19:59,971 train 500 1.695129e-02 -0.889108
2019-11-07 22:20:09,794 train 550 1.694473e-02 -0.896892
2019-11-07 22:20:19,619 train 600 1.692069e-02 -0.881458
2019-11-07 22:20:29,443 train 650 1.693515e-02 -0.886441
2019-11-07 22:20:39,271 train 700 1.690795e-02 -0.887840
2019-11-07 22:20:49,091 train 750 1.686630e-02 -0.870558
2019-11-07 22:20:58,910 train 800 1.688151e-02 -0.868539
2019-11-07 22:21:08,743 train 850 1.688098e-02 -0.862838
2019-11-07 22:21:11,680 training loss; R2: 1.688513e-02 -0.859146
2019-11-07 22:21:12,367 valid 000 1.397464e-02 0.060731
2019-11-07 22:21:21,730 valid 050 1.559536e-02 -1.031707
2019-11-07 22:21:30,102 validation loss; R2: 1.579503e-02 -1.151602
2019-11-07 22:21:30,169 epoch 696 lr 1.000000e-05
2019-11-07 22:21:30,938 train 000 1.511756e-02 0.007831
2019-11-07 22:21:40,693 train 050 1.668328e-02 -0.597720
2019-11-07 22:21:50,474 train 100 1.667808e-02 -0.634511
2019-11-07 22:22:00,263 train 150 1.678705e-02 -0.679018
2019-11-07 22:22:10,063 train 200 1.683000e-02 -0.713437
2019-11-07 22:22:19,854 train 250 1.680015e-02 -0.720846
2019-11-07 22:22:29,647 train 300 1.679149e-02 -0.667037
2019-11-07 22:22:39,459 train 350 1.686319e-02 -0.657391
2019-11-07 22:22:49,250 train 400 1.689456e-02 -0.667215
2019-11-07 22:22:59,052 train 450 1.689135e-02 -0.956356
2019-11-07 22:23:08,860 train 500 1.691441e-02 -0.978598
2019-11-07 22:23:18,655 train 550 1.690017e-02 -0.937401
2019-11-07 22:23:28,454 train 600 1.691911e-02 -0.914664
2019-11-07 22:23:38,267 train 650 1.693000e-02 -0.882417
2019-11-07 22:23:48,062 train 700 1.689498e-02 -0.869460
2019-11-07 22:23:57,855 train 750 1.688461e-02 -0.848524
2019-11-07 22:24:07,653 train 800 1.689724e-02 -0.864309
2019-11-07 22:24:17,451 train 850 1.690840e-02 -0.848952
2019-11-07 22:24:20,380 training loss; R2: 1.690575e-02 -0.844671
2019-11-07 22:24:21,087 valid 000 1.523939e-02 0.055539
2019-11-07 22:24:30,425 valid 050 1.506704e-02 -1.706726
2019-11-07 22:24:38,768 validation loss; R2: 1.492190e-02 -1.378970
2019-11-07 22:24:38,834 epoch 697 lr 1.000000e-05
2019-11-07 22:24:39,595 train 000 1.672339e-02 -0.323603
2019-11-07 22:24:49,337 train 050 1.660101e-02 -0.810784
2019-11-07 22:24:59,059 train 100 1.676678e-02 -0.794527
2019-11-07 22:25:08,827 train 150 1.688361e-02 -0.783872
2019-11-07 22:25:18,614 train 200 1.691692e-02 -0.774466
2019-11-07 22:25:28,387 train 250 1.692464e-02 -0.732308
2019-11-07 22:25:38,167 train 300 1.693390e-02 -0.757736
2019-11-07 22:25:47,935 train 350 1.688433e-02 -0.697591
2019-11-07 22:25:57,712 train 400 1.690303e-02 -0.714417
2019-11-07 22:26:07,491 train 450 1.688148e-02 -0.696355
2019-11-07 22:26:17,265 train 500 1.690878e-02 -0.695620
2019-11-07 22:26:27,051 train 550 1.693438e-02 -1.104554
2019-11-07 22:26:36,825 train 600 1.692173e-02 -1.068699
2019-11-07 22:26:46,608 train 650 1.689174e-02 -1.036945
2019-11-07 22:26:56,388 train 700 1.687191e-02 -1.004318
2019-11-07 22:27:06,162 train 750 1.685021e-02 -0.977236
2019-11-07 22:27:15,948 train 800 1.683647e-02 -0.955310
2019-11-07 22:27:25,729 train 850 1.684213e-02 -0.943900
2019-11-07 22:27:28,655 training loss; R2: 1.684388e-02 -0.946804
2019-11-07 22:27:29,284 valid 000 1.568424e-02 -1.196649
2019-11-07 22:27:38,728 valid 050 1.508013e-02 -1.208223
2019-11-07 22:27:47,125 validation loss; R2: 1.522267e-02 -1.058507
2019-11-07 22:27:47,191 epoch 698 lr 1.000000e-05
2019-11-07 22:27:47,994 train 000 1.887669e-02 -1.176301
2019-11-07 22:27:57,718 train 050 1.700433e-02 -0.728326
2019-11-07 22:28:07,472 train 100 1.679731e-02 -0.767594
2019-11-07 22:28:17,229 train 150 1.693140e-02 -0.731426
2019-11-07 22:28:27,002 train 200 1.690858e-02 -0.741256
2019-11-07 22:28:36,769 train 250 1.686379e-02 -0.728691
2019-11-07 22:28:46,548 train 300 1.693023e-02 -0.682757
2019-11-07 22:28:56,334 train 350 1.695869e-02 -0.668664
2019-11-07 22:29:06,115 train 400 1.691013e-02 -0.630210
2019-11-07 22:29:15,901 train 450 1.689337e-02 -0.643769
2019-11-07 22:29:25,678 train 500 1.687182e-02 -0.698359
2019-11-07 22:29:35,459 train 550 1.686152e-02 -0.718841
2019-11-07 22:29:45,253 train 600 1.688390e-02 -0.717111
2019-11-07 22:29:55,048 train 650 1.689712e-02 -0.706731
2019-11-07 22:30:04,831 train 700 1.691731e-02 -0.723971
2019-11-07 22:30:14,623 train 750 1.689744e-02 -0.717446
2019-11-07 22:30:24,427 train 800 1.690604e-02 -0.716663
2019-11-07 22:30:34,224 train 850 1.691159e-02 -0.725228
2019-11-07 22:30:37,158 training loss; R2: 1.689605e-02 -0.733424
2019-11-07 22:30:37,793 valid 000 2.547134e-02 -1.766377
2019-11-07 22:30:47,245 valid 050 2.726374e-02 -2.570827
2019-11-07 22:30:55,578 validation loss; R2: 2.708133e-02 -2.517710
2019-11-07 22:30:55,643 epoch 699 lr 1.000000e-05
2019-11-07 22:30:56,410 train 000 1.560092e-02 -1.336346
2019-11-07 22:31:06,154 train 050 1.682249e-02 -0.664186
2019-11-07 22:31:15,908 train 100 1.679329e-02 -0.583218
2019-11-07 22:31:25,684 train 150 1.676642e-02 -0.585005
2019-11-07 22:31:35,453 train 200 1.685690e-02 -1.900673
2019-11-07 22:31:45,237 train 250 1.687284e-02 -1.936190
2019-11-07 22:31:55,018 train 300 1.690519e-02 -2.348177
2019-11-07 22:32:04,816 train 350 1.697169e-02 -2.111699
2019-11-07 22:32:14,587 train 400 1.693045e-02 -1.894994
2019-11-07 22:32:24,361 train 450 1.692495e-02 -1.769831
2019-11-07 22:32:34,148 train 500 1.688438e-02 -1.660880
2019-11-07 22:32:43,927 train 550 1.689554e-02 -1.573536
2019-11-07 22:32:53,707 train 600 1.690130e-02 -1.521399
2019-11-07 22:33:03,495 train 650 1.687691e-02 -1.495961
2019-11-07 22:33:13,273 train 700 1.688664e-02 -1.464199
2019-11-07 22:33:23,050 train 750 1.689093e-02 -1.429480
2019-11-07 22:33:32,827 train 800 1.689999e-02 -1.388055
2019-11-07 22:33:42,619 train 850 1.688253e-02 -1.349260
2019-11-07 22:33:45,559 training loss; R2: 1.688284e-02 -1.339108
2019-11-07 22:33:46,195 valid 000 2.251954e-02 -1.092123
2019-11-07 22:33:55,634 valid 050 2.191372e-02 -1.820605
2019-11-07 22:34:03,964 validation loss; R2: 2.189376e-02 -2.159159
2019-11-07 22:34:04,042 epoch 700 lr 1.000000e-05
2019-11-07 22:34:04,799 train 000 1.683822e-02 -0.150469
2019-11-07 22:34:14,925 train 050 1.700382e-02 -0.578347
2019-11-07 22:34:25,068 train 100 1.688936e-02 -0.762625
2019-11-07 22:34:35,202 train 150 1.678501e-02 -0.743471
2019-11-07 22:34:45,357 train 200 1.685798e-02 -0.799082
2019-11-07 22:34:55,513 train 250 1.692922e-02 -0.826089
2019-11-07 22:35:05,668 train 300 1.696582e-02 -0.836903
2019-11-07 22:35:15,827 train 350 1.701666e-02 -0.826768
2019-11-07 22:35:25,967 train 400 1.701754e-02 -0.804976
2019-11-07 22:35:36,150 train 450 1.702197e-02 -0.770483
2019-11-07 22:35:46,330 train 500 1.699599e-02 -0.759314
2019-11-07 22:35:56,507 train 550 1.698486e-02 -0.745906
2019-11-07 22:36:06,695 train 600 1.696584e-02 -0.722818
2019-11-07 22:36:16,880 train 650 1.693776e-02 -0.711359
2019-11-07 22:36:27,064 train 700 1.692723e-02 -0.700129
2019-11-07 22:36:37,248 train 750 1.692197e-02 -0.694596
2019-11-07 22:36:47,436 train 800 1.692434e-02 -0.726318
2019-11-07 22:36:57,614 train 850 1.694165e-02 -0.728092
2019-11-07 22:37:00,673 training loss; R2: 1.692689e-02 -0.727171
2019-11-07 22:37:01,371 valid 000 1.830116e-02 -0.000976
2019-11-07 22:37:10,746 valid 050 1.566303e-02 -1.080619
2019-11-07 22:37:19,062 validation loss; R2: 1.556673e-02 -1.061378
2019-11-07 22:37:19,147 epoch 701 lr 1.000000e-05
2019-11-07 22:37:19,859 train 000 1.830917e-02 -0.121823
2019-11-07 22:37:29,599 train 050 1.677168e-02 -0.829583
2019-11-07 22:37:39,369 train 100 1.695795e-02 -0.789651
2019-11-07 22:37:49,162 train 150 1.696709e-02 -0.757681
2019-11-07 22:37:58,953 train 200 1.695446e-02 -0.733066
2019-11-07 22:38:08,757 train 250 1.698271e-02 -0.694027
2019-11-07 22:38:18,559 train 300 1.693128e-02 -0.705091
2019-11-07 22:38:28,367 train 350 1.694101e-02 -0.702463
2019-11-07 22:38:38,167 train 400 1.693764e-02 -0.730980
2019-11-07 22:38:47,979 train 450 1.693759e-02 -0.698573
2019-11-07 22:38:57,791 train 500 1.694219e-02 -0.711715
2019-11-07 22:39:07,602 train 550 1.693150e-02 -0.812714
2019-11-07 22:39:17,403 train 600 1.694623e-02 -0.807120
2019-11-07 22:39:27,226 train 650 1.693397e-02 -0.793106
2019-11-07 22:39:37,039 train 700 1.692029e-02 -0.777829
2019-11-07 22:39:46,862 train 750 1.692990e-02 -0.789310
2019-11-07 22:39:56,704 train 800 1.695453e-02 -0.784552
2019-11-07 22:40:06,510 train 850 1.696565e-02 -0.800523
2019-11-07 22:40:09,437 training loss; R2: 1.696709e-02 -0.798250
2019-11-07 22:40:10,092 valid 000 1.663790e-02 0.037203
2019-11-07 22:40:19,520 valid 050 1.732144e-02 -1.187042
2019-11-07 22:40:27,824 validation loss; R2: 1.693759e-02 -1.398018
2019-11-07 22:40:27,889 epoch 702 lr 1.000000e-05
2019-11-07 22:40:28,685 train 000 1.685018e-02 -0.387867
2019-11-07 22:40:38,432 train 050 1.694672e-02 -0.712965
2019-11-07 22:40:48,195 train 100 1.710031e-02 -0.714963
2019-11-07 22:40:57,979 train 150 1.700045e-02 -1.335457
2019-11-07 22:41:07,783 train 200 1.697167e-02 -1.214614
2019-11-07 22:41:17,584 train 250 1.693046e-02 -1.104029
2019-11-07 22:41:27,389 train 300 1.696245e-02 -0.991518
2019-11-07 22:41:37,195 train 350 1.695090e-02 -0.926445
2019-11-07 22:41:47,004 train 400 1.697971e-02 -1.038581
2019-11-07 22:41:56,816 train 450 1.697472e-02 -1.011254
2019-11-07 22:42:06,630 train 500 1.697068e-02 -0.985540
2019-11-07 22:42:16,435 train 550 1.695325e-02 -0.948955
2019-11-07 22:42:26,255 train 600 1.694693e-02 -0.937811
2019-11-07 22:42:36,111 train 650 1.691372e-02 -0.936460
2019-11-07 22:42:45,922 train 700 1.691489e-02 -0.936572
2019-11-07 22:42:55,736 train 750 1.691394e-02 -0.920727
2019-11-07 22:43:05,567 train 800 1.689788e-02 -0.902134
2019-11-07 22:43:15,405 train 850 1.691699e-02 -0.902372
2019-11-07 22:43:18,337 training loss; R2: 1.691558e-02 -0.905137
2019-11-07 22:43:18,972 valid 000 3.896764e-02 -1.098658
2019-11-07 22:43:28,399 valid 050 3.362034e-02 -3.429873
2019-11-07 22:43:36,709 validation loss; R2: 3.300437e-02 -4.050483
2019-11-07 22:43:36,776 epoch 703 lr 1.000000e-05
2019-11-07 22:43:37,513 train 000 1.861344e-02 -0.096628
2019-11-07 22:43:47,245 train 050 1.681618e-02 -0.502482
2019-11-07 22:43:57,011 train 100 1.700945e-02 -0.617419
2019-11-07 22:44:06,796 train 150 1.689573e-02 -0.637672
2019-11-07 22:44:16,586 train 200 1.695783e-02 -0.627051
2019-11-07 22:44:26,378 train 250 1.695904e-02 -0.685025
2019-11-07 22:44:36,196 train 300 1.696184e-02 -0.680415
2019-11-07 22:44:46,003 train 350 1.701469e-02 -0.669203
2019-11-07 22:44:55,820 train 400 1.703564e-02 -0.683691
2019-11-07 22:45:05,613 train 450 1.702571e-02 -0.667352
2019-11-07 22:45:15,410 train 500 1.703587e-02 -0.817890
2019-11-07 22:45:25,219 train 550 1.699678e-02 -0.795719
2019-11-07 22:45:35,019 train 600 1.696299e-02 -0.784159
2019-11-07 22:45:44,824 train 650 1.697204e-02 -0.767234
2019-11-07 22:45:54,627 train 700 1.695294e-02 -0.760413
2019-11-07 22:46:04,421 train 750 1.697765e-02 -0.744424
2019-11-07 22:46:14,242 train 800 1.699857e-02 -0.750681
2019-11-07 22:46:24,027 train 850 1.698524e-02 -0.751440
2019-11-07 22:46:26,969 training loss; R2: 1.699197e-02 -0.761341
2019-11-07 22:46:27,654 valid 000 1.826867e-02 -3.594523
2019-11-07 22:46:37,065 valid 050 1.769962e-02 -1.717354
2019-11-07 22:46:45,379 validation loss; R2: 1.804165e-02 -13.230369
2019-11-07 22:46:45,445 epoch 704 lr 1.000000e-05
2019-11-07 22:46:46,168 train 000 1.485826e-02 -0.828273
2019-11-07 22:46:55,886 train 050 1.729426e-02 -0.827916
2019-11-07 22:47:05,620 train 100 1.732385e-02 -0.718447
2019-11-07 22:47:15,394 train 150 1.705165e-02 -0.695630
2019-11-07 22:47:25,162 train 200 1.710629e-02 -0.671423
2019-11-07 22:47:34,933 train 250 1.706192e-02 -1.247105
2019-11-07 22:47:44,709 train 300 1.701649e-02 -1.138075
2019-11-07 22:47:54,500 train 350 1.705320e-02 -1.071421
2019-11-07 22:48:04,295 train 400 1.699620e-02 -1.280856
2019-11-07 22:48:14,099 train 450 1.694366e-02 -1.194929
2019-11-07 22:48:23,897 train 500 1.693322e-02 -1.136133
2019-11-07 22:48:33,698 train 550 1.693836e-02 -1.093512
2019-11-07 22:48:43,490 train 600 1.695465e-02 -1.059329
2019-11-07 22:48:53,292 train 650 1.695617e-02 -1.044953
2019-11-07 22:49:03,092 train 700 1.692972e-02 -1.021063
2019-11-07 22:49:12,897 train 750 1.691589e-02 -1.003029
2019-11-07 22:49:22,724 train 800 1.691355e-02 -0.979053
2019-11-07 22:49:32,542 train 850 1.692310e-02 -0.979424
2019-11-07 22:49:35,478 training loss; R2: 1.691522e-02 -0.967635
2019-11-07 22:49:36,140 valid 000 1.604662e-02 -1.862797
2019-11-07 22:49:45,491 valid 050 1.718503e-02 -0.867970
2019-11-07 22:49:53,865 validation loss; R2: 1.716548e-02 -1.027492
2019-11-07 22:49:53,931 epoch 705 lr 1.000000e-05
2019-11-07 22:49:54,714 train 000 1.717213e-02 -0.167797
2019-11-07 22:50:04,480 train 050 1.703943e-02 -0.754143
2019-11-07 22:50:14,280 train 100 1.689533e-02 -0.633161
2019-11-07 22:50:24,078 train 150 1.684102e-02 -0.718349
2019-11-07 22:50:33,877 train 200 1.692521e-02 -0.707652
2019-11-07 22:50:43,673 train 250 1.696480e-02 -0.712851
2019-11-07 22:50:53,483 train 300 1.707710e-02 -0.776612
2019-11-07 22:51:03,293 train 350 1.705516e-02 -0.739623
2019-11-07 22:51:13,088 train 400 1.706075e-02 -0.750377
2019-11-07 22:51:22,873 train 450 1.707153e-02 -0.783614
2019-11-07 22:51:32,636 train 500 1.704817e-02 -0.850748
2019-11-07 22:51:42,412 train 550 1.702903e-02 -0.830755
2019-11-07 22:51:52,190 train 600 1.699614e-02 -0.817356
2019-11-07 22:52:01,957 train 650 1.695205e-02 -0.817434
2019-11-07 22:52:11,729 train 700 1.693675e-02 -0.803945
2019-11-07 22:52:21,512 train 750 1.696494e-02 -0.813242
2019-11-07 22:52:31,286 train 800 1.693134e-02 -0.800987
2019-11-07 22:52:41,094 train 850 1.692333e-02 -0.795871
2019-11-07 22:52:44,017 training loss; R2: 1.692156e-02 -0.795437
2019-11-07 22:52:44,650 valid 000 1.783749e-02 0.038088
2019-11-07 22:52:54,094 valid 050 1.527419e-02 -0.714315
2019-11-07 22:53:02,434 validation loss; R2: 1.535019e-02 -0.902485
2019-11-07 22:53:02,501 epoch 706 lr 1.000000e-05
2019-11-07 22:53:03,299 train 000 1.391649e-02 -0.687600
2019-11-07 22:53:13,054 train 050 1.697922e-02 -0.744418
2019-11-07 22:53:22,824 train 100 1.678168e-02 -0.665853
2019-11-07 22:53:32,610 train 150 1.679587e-02 -0.712500
2019-11-07 22:53:42,405 train 200 1.674752e-02 -0.721061
2019-11-07 22:53:52,187 train 250 1.674955e-02 -0.710144
2019-11-07 22:54:01,977 train 300 1.682189e-02 -0.686361
2019-11-07 22:54:11,761 train 350 1.684473e-02 -0.693630
2019-11-07 22:54:21,575 train 400 1.685570e-02 -0.713375
2019-11-07 22:54:31,362 train 450 1.684046e-02 -0.680877
2019-11-07 22:54:41,150 train 500 1.684150e-02 -0.705775
2019-11-07 22:54:50,958 train 550 1.685700e-02 -0.708281
2019-11-07 22:55:00,767 train 600 1.689982e-02 -0.706600
2019-11-07 22:55:10,557 train 650 1.690473e-02 -0.764733
2019-11-07 22:55:20,349 train 700 1.690447e-02 -0.769332
2019-11-07 22:55:30,145 train 750 1.689175e-02 -0.774605
2019-11-07 22:55:39,927 train 800 1.687385e-02 -1.224789
2019-11-07 22:55:49,725 train 850 1.687041e-02 -1.189110
2019-11-07 22:55:52,658 training loss; R2: 1.685568e-02 -1.182610
2019-11-07 22:55:53,310 valid 000 1.124659e-02 -0.841105
2019-11-07 22:56:02,725 valid 050 1.504013e-02 -0.707641
2019-11-07 22:56:11,023 validation loss; R2: 1.516158e-02 -0.777826
2019-11-07 22:56:11,082 epoch 707 lr 1.000000e-05
2019-11-07 22:56:11,871 train 000 1.842694e-02 -0.283540
2019-11-07 22:56:21,616 train 050 1.703070e-02 -0.490369
2019-11-07 22:56:31,359 train 100 1.694022e-02 -0.673571
2019-11-07 22:56:41,141 train 150 1.686056e-02 -0.683944
2019-11-07 22:56:50,924 train 200 1.685165e-02 -0.702843
2019-11-07 22:57:00,725 train 250 1.682690e-02 -0.734430
2019-11-07 22:57:10,501 train 300 1.677462e-02 -0.742557
2019-11-07 22:57:20,297 train 350 1.678930e-02 -0.739301
2019-11-07 22:57:30,099 train 400 1.680223e-02 -0.743751
2019-11-07 22:57:39,899 train 450 1.681505e-02 -0.748796
2019-11-07 22:57:49,700 train 500 1.680652e-02 -0.737135
2019-11-07 22:57:59,504 train 550 1.680301e-02 -0.732919
2019-11-07 22:58:09,292 train 600 1.676074e-02 -0.755295
2019-11-07 22:58:19,107 train 650 1.676274e-02 -0.746517
2019-11-07 22:58:28,904 train 700 1.675008e-02 -0.762491
2019-11-07 22:58:38,720 train 750 1.676568e-02 -0.770946
2019-11-07 22:58:48,514 train 800 1.677474e-02 -30.879191
2019-11-07 22:58:58,311 train 850 1.678571e-02 -29.157207
2019-11-07 22:59:01,235 training loss; R2: 1.678874e-02 -28.664284
2019-11-07 22:59:01,914 valid 000 1.576190e-02 -0.149127
2019-11-07 22:59:11,303 valid 050 1.529661e-02 -0.962645
2019-11-07 22:59:19,618 validation loss; R2: 1.535821e-02 -1.051496
2019-11-07 22:59:19,686 epoch 708 lr 1.000000e-05
2019-11-07 22:59:20,471 train 000 1.634191e-02 0.055517
2019-11-07 22:59:30,224 train 050 1.654103e-02 -0.611366
2019-11-07 22:59:39,985 train 100 1.659848e-02 -0.641271
2019-11-07 22:59:49,749 train 150 1.674718e-02 -0.706283
2019-11-07 22:59:59,524 train 200 1.680682e-02 -0.627469
2019-11-07 23:00:09,288 train 250 1.681313e-02 -0.648207
2019-11-07 23:00:19,045 train 300 1.682664e-02 -0.633299
2019-11-07 23:00:28,828 train 350 1.682675e-02 -0.637033
2019-11-07 23:00:38,618 train 400 1.678239e-02 -2.551076
2019-11-07 23:00:48,402 train 450 1.681276e-02 -2.439868
2019-11-07 23:00:58,174 train 500 1.681870e-02 -2.252687
2019-11-07 23:01:07,972 train 550 1.682141e-02 -2.106210
2019-11-07 23:01:17,757 train 600 1.686108e-02 -1.979043
2019-11-07 23:01:27,567 train 650 1.689213e-02 -1.872969
2019-11-07 23:01:37,381 train 700 1.689138e-02 -1.796142
2019-11-07 23:01:47,188 train 750 1.689447e-02 -1.721076
2019-11-07 23:01:57,007 train 800 1.688140e-02 -1.656800
2019-11-07 23:02:06,818 train 850 1.687899e-02 -1.598944
2019-11-07 23:02:09,757 training loss; R2: 1.688296e-02 -1.580441
2019-11-07 23:02:10,410 valid 000 1.836486e-02 -2.764319
2019-11-07 23:02:19,849 valid 050 1.705563e-02 -0.866120
2019-11-07 23:02:28,154 validation loss; R2: 1.715210e-02 -0.862026
2019-11-07 23:02:28,221 epoch 709 lr 1.000000e-05
2019-11-07 23:02:28,961 train 000 1.975612e-02 -0.006843
2019-11-07 23:02:38,710 train 050 1.699883e-02 -1.131243
2019-11-07 23:02:48,472 train 100 1.700967e-02 -0.847253
2019-11-07 23:02:58,252 train 150 1.698944e-02 -0.727914
2019-11-07 23:03:08,041 train 200 1.697862e-02 -0.803422
2019-11-07 23:03:17,808 train 250 1.690551e-02 -0.786018
2019-11-07 23:03:27,576 train 300 1.691185e-02 -0.840492
2019-11-07 23:03:37,341 train 350 1.686814e-02 -0.856282
2019-11-07 23:03:47,100 train 400 1.689809e-02 -0.885253
2019-11-07 23:03:56,860 train 450 1.692159e-02 -0.847060
2019-11-07 23:04:06,633 train 500 1.691320e-02 -0.829289
2019-11-07 23:04:16,398 train 550 1.690441e-02 -0.846037
2019-11-07 23:04:26,167 train 600 1.693246e-02 -0.840463
2019-11-07 23:04:35,924 train 650 1.689404e-02 -0.824052
2019-11-07 23:04:45,689 train 700 1.690091e-02 -0.816882
2019-11-07 23:04:55,459 train 750 1.692232e-02 -0.810110
2019-11-07 23:05:05,256 train 800 1.689767e-02 -0.806367
2019-11-07 23:05:15,060 train 850 1.690243e-02 -0.800443
2019-11-07 23:05:17,992 training loss; R2: 1.689710e-02 -0.799903
2019-11-07 23:05:18,577 valid 000 3.120340e-02 -0.861988
2019-11-07 23:05:28,093 valid 050 3.451367e-02 -0.681014
2019-11-07 23:05:36,412 validation loss; R2: 3.442706e-02 -0.627659
2019-11-07 23:05:36,484 epoch 710 lr 1.000000e-05
2019-11-07 23:05:37,228 train 000 1.540239e-02 -2.693436
2019-11-07 23:05:46,966 train 050 1.705185e-02 -1.643181
2019-11-07 23:05:56,722 train 100 1.706976e-02 -1.098456
2019-11-07 23:06:06,491 train 150 1.694597e-02 -0.962276
2019-11-07 23:06:16,282 train 200 1.688789e-02 -2.157659
2019-11-07 23:06:26,067 train 250 1.682405e-02 -1.845604
2019-11-07 23:06:35,856 train 300 1.675624e-02 -1.666015
2019-11-07 23:06:45,638 train 350 1.683180e-02 -1.509607
2019-11-07 23:06:55,425 train 400 1.685076e-02 -1.534750
2019-11-07 23:07:05,224 train 450 1.684625e-02 -1.431217
2019-11-07 23:07:15,017 train 500 1.690387e-02 -1.351833
2019-11-07 23:07:24,795 train 550 1.689222e-02 -1.297169
2019-11-07 23:07:34,579 train 600 1.692862e-02 -1.270260
2019-11-07 23:07:44,357 train 650 1.690724e-02 -1.252324
2019-11-07 23:07:54,136 train 700 1.689553e-02 -1.220581
2019-11-07 23:08:03,938 train 750 1.691468e-02 -1.167675
2019-11-07 23:08:13,733 train 800 1.691253e-02 -1.131003
2019-11-07 23:08:23,539 train 850 1.690963e-02 -1.491722
2019-11-07 23:08:26,464 training loss; R2: 1.689490e-02 -1.474297
2019-11-07 23:08:27,106 valid 000 2.597311e-02 -1.561465
2019-11-07 23:08:36,549 valid 050 2.517101e-02 -4.285244
2019-11-07 23:08:44,865 validation loss; R2: 2.495225e-02 -3.210781
2019-11-07 23:08:44,930 epoch 711 lr 1.000000e-05
2019-11-07 23:08:45,706 train 000 1.714334e-02 -1.220611
2019-11-07 23:08:55,473 train 050 1.669349e-02 -0.690973
2019-11-07 23:09:05,227 train 100 1.671408e-02 -0.625014
2019-11-07 23:09:14,999 train 150 1.663741e-02 -0.810275
2019-11-07 23:09:25,155 train 200 1.659708e-02 -0.849210
2019-11-07 23:09:35,043 train 250 1.662703e-02 -0.812176
2019-11-07 23:09:44,814 train 300 1.669350e-02 -0.792542
2019-11-07 23:09:54,616 train 350 1.675901e-02 -0.769447
2019-11-07 23:10:04,407 train 400 1.675562e-02 -0.783353
2019-11-07 23:10:14,196 train 450 1.676353e-02 -0.782783
2019-11-07 23:10:23,995 train 500 1.676992e-02 -0.784802
2019-11-07 23:10:33,784 train 550 1.680099e-02 -0.782675
2019-11-07 23:10:43,583 train 600 1.682487e-02 -0.789383
2019-11-07 23:10:53,388 train 650 1.680782e-02 -0.875376
2019-11-07 23:11:03,206 train 700 1.684301e-02 -0.859929
2019-11-07 23:11:13,014 train 750 1.681955e-02 -0.848107
2019-11-07 23:11:22,829 train 800 1.681105e-02 -0.850681
2019-11-07 23:11:32,660 train 850 1.682334e-02 -0.840340
2019-11-07 23:11:35,594 training loss; R2: 1.682018e-02 -0.834672
2019-11-07 23:11:36,256 valid 000 2.196516e-02 -1.975746
2019-11-07 23:11:45,670 valid 050 1.671514e-02 -1.217630
2019-11-07 23:11:54,191 validation loss; R2: 1.695387e-02 -1.545657
2019-11-07 23:11:54,259 epoch 712 lr 1.000000e-05
2019-11-07 23:11:55,027 train 000 1.509472e-02 -0.089281
2019-11-07 23:12:04,789 train 050 1.688221e-02 -0.900878
2019-11-07 23:12:14,561 train 100 1.698533e-02 -0.809736
2019-11-07 23:12:24,348 train 150 1.687650e-02 -0.852113
2019-11-07 23:12:34,145 train 200 1.686905e-02 -0.865613
2019-11-07 23:12:43,908 train 250 1.690276e-02 -0.791813
2019-11-07 23:12:53,679 train 300 1.689327e-02 -0.776278
2019-11-07 23:13:03,457 train 350 1.686855e-02 -0.766655
2019-11-07 23:13:13,250 train 400 1.691484e-02 -0.784763
2019-11-07 23:13:23,028 train 450 1.688028e-02 -0.904678
2019-11-07 23:13:32,803 train 500 1.685280e-02 -0.881102
2019-11-07 23:13:42,595 train 550 1.684829e-02 -1.322515
2019-11-07 23:13:52,385 train 600 1.686427e-02 -1.248929
2019-11-07 23:14:02,171 train 650 1.687367e-02 -1.218015
2019-11-07 23:14:11,966 train 700 1.687014e-02 -1.182385
2019-11-07 23:14:21,757 train 750 1.687305e-02 -1.146895
2019-11-07 23:14:31,550 train 800 1.689336e-02 -1.122075
2019-11-07 23:14:41,349 train 850 1.687430e-02 -1.103003
2019-11-07 23:14:44,271 training loss; R2: 1.685998e-02 -1.093219
2019-11-07 23:14:44,913 valid 000 1.654749e-02 -2.476530
2019-11-07 23:14:54,276 valid 050 1.546497e-02 -1.124247
2019-11-07 23:15:02,600 validation loss; R2: 1.540280e-02 -1.183926
2019-11-07 23:15:02,663 epoch 713 lr 1.000000e-05
2019-11-07 23:15:03,447 train 000 1.759237e-02 -0.415475
2019-11-07 23:15:13,195 train 050 1.726142e-02 -0.859365
2019-11-07 23:15:22,949 train 100 1.696530e-02 -0.686066
2019-11-07 23:15:32,728 train 150 1.699495e-02 -0.759343
2019-11-07 23:15:42,506 train 200 1.700826e-02 -0.737954
2019-11-07 23:15:52,265 train 250 1.699993e-02 -0.756698
2019-11-07 23:16:01,998 train 300 1.695455e-02 -0.783055
2019-11-07 23:16:11,729 train 350 1.698582e-02 -0.758178
2019-11-07 23:16:21,459 train 400 1.690625e-02 -0.759807
2019-11-07 23:16:31,206 train 450 1.693059e-02 -0.756943
2019-11-07 23:16:40,949 train 500 1.692752e-02 -0.732495
2019-11-07 23:16:50,697 train 550 1.694541e-02 -0.711009
2019-11-07 23:17:00,471 train 600 1.693734e-02 -0.764622
2019-11-07 23:17:10,235 train 650 1.692554e-02 -0.802565
2019-11-07 23:17:20,003 train 700 1.690551e-02 -0.803474
2019-11-07 23:17:29,760 train 750 1.689311e-02 -0.788410
2019-11-07 23:17:39,517 train 800 1.689511e-02 -0.795849
2019-11-07 23:17:49,279 train 850 1.687126e-02 -0.833115
2019-11-07 23:17:52,198 training loss; R2: 1.686386e-02 -0.838800
2019-11-07 23:17:52,863 valid 000 2.204697e-02 -0.547209
2019-11-07 23:18:02,197 valid 050 2.223274e-02 -2.400994
2019-11-07 23:18:10,581 validation loss; R2: 2.277420e-02 -2.721988
2019-11-07 23:18:10,647 epoch 714 lr 1.000000e-05
2019-11-07 23:18:11,454 train 000 1.604602e-02 -0.559284
2019-11-07 23:18:21,172 train 050 1.734285e-02 -0.751398
2019-11-07 23:18:30,897 train 100 1.721897e-02 -0.755926
2019-11-07 23:18:40,619 train 150 1.695482e-02 -0.714776
2019-11-07 23:18:50,340 train 200 1.703921e-02 -0.796336
2019-11-07 23:19:00,062 train 250 1.696480e-02 -0.801243
2019-11-07 23:19:09,790 train 300 1.698303e-02 -0.769032
2019-11-07 23:19:19,520 train 350 1.693256e-02 -0.798582
2019-11-07 23:19:29,251 train 400 1.699551e-02 -0.772455
2019-11-07 23:19:38,997 train 450 1.696725e-02 -0.786025
2019-11-07 23:19:48,731 train 500 1.693995e-02 -0.778997
2019-11-07 23:19:58,475 train 550 1.695974e-02 -0.771467
2019-11-07 23:20:08,234 train 600 1.696303e-02 -0.776533
2019-11-07 23:20:18,001 train 650 1.698023e-02 -0.785045
2019-11-07 23:20:27,759 train 700 1.696323e-02 -0.774601
2019-11-07 23:20:37,528 train 750 1.694667e-02 -0.770816
2019-11-07 23:20:47,297 train 800 1.693136e-02 -0.791133
2019-11-07 23:20:57,076 train 850 1.695880e-02 -0.794138
2019-11-07 23:21:00,000 training loss; R2: 1.695009e-02 -0.794256
2019-11-07 23:21:00,649 valid 000 1.528845e-02 -2.015072
2019-11-07 23:21:10,034 valid 050 1.392562e-02 -0.966891
2019-11-07 23:21:18,327 validation loss; R2: 1.404350e-02 -0.896219
2019-11-07 23:21:18,405 epoch 715 lr 1.000000e-05
2019-11-07 23:21:19,165 train 000 1.628073e-02 -0.685932
2019-11-07 23:21:29,325 train 050 1.660775e-02 -0.669445
2019-11-07 23:21:39,505 train 100 1.676565e-02 -0.757664
2019-11-07 23:21:49,664 train 150 1.689650e-02 -0.851557
2019-11-07 23:21:59,834 train 200 1.691301e-02 -1.160319
2019-11-07 23:22:09,999 train 250 1.686760e-02 -1.053760
2019-11-07 23:22:20,167 train 300 1.685371e-02 -1.017367
2019-11-07 23:22:30,316 train 350 1.688930e-02 -1.026328
2019-11-07 23:22:40,466 train 400 1.689268e-02 -1.107789
2019-11-07 23:22:50,640 train 450 1.684790e-02 -1.092876
2019-11-07 23:23:00,812 train 500 1.691008e-02 -1.041791
2019-11-07 23:23:10,990 train 550 1.691903e-02 -1.007024
2019-11-07 23:23:21,180 train 600 1.691661e-02 -0.990502
2019-11-07 23:23:31,378 train 650 1.692140e-02 -0.973554
2019-11-07 23:23:41,550 train 700 1.691786e-02 -0.947523
2019-11-07 23:23:51,723 train 750 1.692502e-02 -0.925706
2019-11-07 23:24:01,905 train 800 1.694954e-02 -0.911174
2019-11-07 23:24:12,084 train 850 1.694615e-02 -0.891736
2019-11-07 23:24:15,090 training loss; R2: 1.694712e-02 -0.885767
2019-11-07 23:24:15,738 valid 000 1.652548e-02 -0.627309
2019-11-07 23:24:25,164 valid 050 1.504295e-02 -0.910758
2019-11-07 23:24:33,470 validation loss; R2: 1.527055e-02 -1.056485
2019-11-07 23:24:33,535 epoch 716 lr 1.000000e-05
2019-11-07 23:24:34,330 train 000 1.561803e-02 -0.412372
2019-11-07 23:24:44,084 train 050 1.687254e-02 -1.356172
2019-11-07 23:24:53,847 train 100 1.704750e-02 -1.017672
2019-11-07 23:25:03,618 train 150 1.686914e-02 -0.905428
2019-11-07 23:25:13,400 train 200 1.684624e-02 -0.882100
2019-11-07 23:25:23,175 train 250 1.687332e-02 -0.808361
2019-11-07 23:25:32,980 train 300 1.682172e-02 -0.804307
2019-11-07 23:25:42,770 train 350 1.683838e-02 -0.780326
2019-11-07 23:25:52,577 train 400 1.680873e-02 -0.824762
2019-11-07 23:26:02,372 train 450 1.685775e-02 -0.806123
2019-11-07 23:26:12,174 train 500 1.683626e-02 -0.810563
2019-11-07 23:26:21,964 train 550 1.683022e-02 -0.824051
2019-11-07 23:26:31,763 train 600 1.684826e-02 -0.809880
2019-11-07 23:26:41,567 train 650 1.686966e-02 -0.798737
2019-11-07 23:26:51,381 train 700 1.687165e-02 -0.855424
2019-11-07 23:27:01,271 train 750 1.687827e-02 -0.856554
2019-11-07 23:27:11,129 train 800 1.686422e-02 -0.846355
2019-11-07 23:27:20,992 train 850 1.684539e-02 -0.852846
2019-11-07 23:27:23,960 training loss; R2: 1.683880e-02 -0.847648
2019-11-07 23:27:24,621 valid 000 2.483982e-02 -1.266504
2019-11-07 23:27:34,022 valid 050 2.528723e-02 -3.170299
2019-11-07 23:27:42,320 validation loss; R2: 2.527958e-02 -3.004166
2019-11-07 23:27:42,390 epoch 717 lr 1.000000e-05
2019-11-07 23:27:43,171 train 000 1.538822e-02 -1.273858
2019-11-07 23:27:52,967 train 050 1.676514e-02 -0.797172
2019-11-07 23:28:02,786 train 100 1.677970e-02 -0.984362
2019-11-07 23:28:12,610 train 150 1.676928e-02 -1.042085
2019-11-07 23:28:22,452 train 200 1.680836e-02 -0.920972
2019-11-07 23:28:32,284 train 250 1.691712e-02 -0.882861
2019-11-07 23:28:42,148 train 300 1.689523e-02 -0.861353
2019-11-07 23:28:51,995 train 350 1.687283e-02 -0.848900
2019-11-07 23:29:01,847 train 400 1.682522e-02 -0.881605
2019-11-07 23:29:11,692 train 450 1.687976e-02 -0.906889
2019-11-07 23:29:21,542 train 500 1.686121e-02 -0.873708
2019-11-07 23:29:31,345 train 550 1.687879e-02 -0.875934
2019-11-07 23:29:41,135 train 600 1.689648e-02 -0.851595
2019-11-07 23:29:50,935 train 650 1.688217e-02 -0.826096
2019-11-07 23:30:00,736 train 700 1.683754e-02 -0.804347
2019-11-07 23:30:10,528 train 750 1.684131e-02 -0.790772
2019-11-07 23:30:20,333 train 800 1.683395e-02 -0.776736
2019-11-07 23:30:30,141 train 850 1.681395e-02 -0.756496
2019-11-07 23:30:33,068 training loss; R2: 1.680337e-02 -0.755274
2019-11-07 23:30:33,771 valid 000 1.633495e-02 -4.751312
2019-11-07 23:30:43,147 valid 050 1.498320e-02 -1.213594
2019-11-07 23:30:51,505 validation loss; R2: 1.509258e-02 -1.007416
2019-11-07 23:30:51,570 epoch 718 lr 1.000000e-05
2019-11-07 23:30:52,350 train 000 1.616963e-02 -0.789126
2019-11-07 23:31:02,090 train 050 1.660519e-02 -0.819154
2019-11-07 23:31:11,864 train 100 1.681545e-02 -0.936248
2019-11-07 23:31:21,641 train 150 1.674435e-02 -0.876039
2019-11-07 23:31:31,426 train 200 1.673145e-02 -0.830394
2019-11-07 23:31:41,214 train 250 1.676325e-02 -0.799359
2019-11-07 23:31:51,001 train 300 1.674907e-02 -0.776236
2019-11-07 23:32:00,793 train 350 1.680723e-02 -0.734671
2019-11-07 23:32:10,591 train 400 1.676564e-02 -0.970826
2019-11-07 23:32:20,384 train 450 1.680037e-02 -0.974463
2019-11-07 23:32:30,185 train 500 1.682974e-02 -0.930909
2019-11-07 23:32:39,966 train 550 1.683857e-02 -0.912930
2019-11-07 23:32:49,756 train 600 1.684623e-02 -0.877040
2019-11-07 23:32:59,564 train 650 1.683655e-02 -0.867182
2019-11-07 23:33:09,371 train 700 1.681849e-02 -0.849324
2019-11-07 23:33:19,180 train 750 1.683420e-02 -0.848347
2019-11-07 23:33:28,999 train 800 1.683327e-02 -0.836479
2019-11-07 23:33:38,825 train 850 1.684497e-02 -0.856169
2019-11-07 23:33:41,764 training loss; R2: 1.683963e-02 -0.848560
2019-11-07 23:33:42,412 valid 000 1.561671e-02 -0.031123
2019-11-07 23:33:51,826 valid 050 1.517916e-02 -0.645852
2019-11-07 23:34:00,150 validation loss; R2: 1.505358e-02 -0.687908
2019-11-07 23:34:00,209 epoch 719 lr 1.000000e-05
2019-11-07 23:34:00,990 train 000 1.739107e-02 -0.547311
2019-11-07 23:34:10,744 train 050 1.699703e-02 -9.069078
2019-11-07 23:34:20,504 train 100 1.690747e-02 -4.848202
2019-11-07 23:34:30,301 train 150 1.690257e-02 -3.593324
2019-11-07 23:34:40,106 train 200 1.694664e-02 -2.858470
2019-11-07 23:34:49,893 train 250 1.700623e-02 -2.404084
2019-11-07 23:34:59,675 train 300 1.704493e-02 -2.144291
2019-11-07 23:35:09,465 train 350 1.705909e-02 -1.924264
2019-11-07 23:35:19,254 train 400 1.702670e-02 -1.777713
2019-11-07 23:35:29,044 train 450 1.698624e-02 -1.658546
2019-11-07 23:35:38,846 train 500 1.694636e-02 -1.567599
2019-11-07 23:35:48,629 train 550 1.691268e-02 -1.476150
2019-11-07 23:35:58,428 train 600 1.692987e-02 -1.398080
2019-11-07 23:36:08,243 train 650 1.693829e-02 -1.328885
2019-11-07 23:36:18,041 train 700 1.694678e-02 -1.291577
2019-11-07 23:36:27,842 train 750 1.693905e-02 -1.266016
2019-11-07 23:36:37,652 train 800 1.694465e-02 -1.226491
2019-11-07 23:36:47,445 train 850 1.693485e-02 -1.212403
2019-11-07 23:36:50,408 training loss; R2: 1.693016e-02 -1.198631
2019-11-07 23:36:51,045 valid 000 1.371200e-02 -0.150489
2019-11-07 23:37:00,524 valid 050 1.508519e-02 -1.242407
2019-11-07 23:37:08,878 validation loss; R2: 1.530596e-02 -1.060261
2019-11-07 23:37:08,944 epoch 720 lr 1.000000e-05
2019-11-07 23:37:09,722 train 000 1.968627e-02 -0.437669
2019-11-07 23:37:19,837 train 050 1.689738e-02 -1.915206
2019-11-07 23:37:29,952 train 100 1.682216e-02 -1.365081
2019-11-07 23:37:39,862 train 150 1.672532e-02 -1.208569
2019-11-07 23:37:49,994 train 200 1.684548e-02 -1.059159
2019-11-07 23:38:00,116 train 250 1.681762e-02 -1.010223
2019-11-07 23:38:10,258 train 300 1.683323e-02 -0.973304
2019-11-07 23:38:20,386 train 350 1.685827e-02 -0.948705
2019-11-07 23:38:30,533 train 400 1.689192e-02 -0.949804
2019-11-07 23:38:40,665 train 450 1.687022e-02 -0.927773
2019-11-07 23:38:50,797 train 500 1.686940e-02 -0.903580
2019-11-07 23:39:00,923 train 550 1.687714e-02 -0.908653
2019-11-07 23:39:11,083 train 600 1.684228e-02 -0.892150
2019-11-07 23:39:21,234 train 650 1.687547e-02 -0.894442
2019-11-07 23:39:31,390 train 700 1.688198e-02 -0.867876
2019-11-07 23:39:41,558 train 750 1.687512e-02 -0.853162
2019-11-07 23:39:51,734 train 800 1.686317e-02 -1.148546
2019-11-07 23:40:01,912 train 850 1.686435e-02 -1.109736
2019-11-07 23:40:04,945 training loss; R2: 1.686106e-02 -1.097452
2019-11-07 23:40:05,643 valid 000 2.646748e-02 -0.427631
2019-11-07 23:40:15,009 valid 050 2.486141e-02 -3.290688
2019-11-07 23:40:23,348 validation loss; R2: 2.494955e-02 -2.913636
2019-11-07 23:40:23,414 epoch 721 lr 1.000000e-05
2019-11-07 23:40:24,155 train 000 1.715466e-02 -2.498720
2019-11-07 23:40:34,276 train 050 1.660097e-02 -0.790374
2019-11-07 23:40:44,417 train 100 1.687511e-02 -0.786118
2019-11-07 23:40:54,444 train 150 1.690012e-02 -0.740028
2019-11-07 23:41:04,202 train 200 1.681613e-02 -0.699753
2019-11-07 23:41:13,975 train 250 1.681053e-02 -0.729949
2019-11-07 23:41:24,040 train 300 1.682338e-02 -0.709140
2019-11-07 23:41:34,164 train 350 1.677845e-02 -0.707402
2019-11-07 23:41:44,296 train 400 1.677961e-02 -0.697230
2019-11-07 23:41:54,429 train 450 1.680873e-02 -0.709653
2019-11-07 23:42:04,565 train 500 1.681511e-02 -0.703205
2019-11-07 23:42:14,739 train 550 1.683570e-02 -1.230169
2019-11-07 23:42:24,891 train 600 1.683411e-02 -1.177694
2019-11-07 23:42:35,054 train 650 1.685818e-02 -1.132884
2019-11-07 23:42:45,215 train 700 1.684016e-02 -1.108474
2019-11-07 23:42:55,387 train 750 1.685715e-02 -1.118841
2019-11-07 23:43:05,547 train 800 1.683798e-02 -1.097413
2019-11-07 23:43:15,698 train 850 1.684713e-02 -1.082858
2019-11-07 23:43:18,733 training loss; R2: 1.684400e-02 -1.084600
2019-11-07 23:43:19,417 valid 000 1.797850e-02 -0.321783
2019-11-07 23:43:28,735 valid 050 1.541461e-02 -1.288831
2019-11-07 23:43:37,124 validation loss; R2: 1.538282e-02 -1.207396
2019-11-07 23:43:37,192 epoch 722 lr 1.000000e-05
2019-11-07 23:43:37,979 train 000 1.343961e-02 -0.233186
2019-11-07 23:43:48,094 train 050 1.656069e-02 -0.537084
2019-11-07 23:43:58,203 train 100 1.674141e-02 -0.544541
2019-11-07 23:44:08,340 train 150 1.685756e-02 -0.522911
2019-11-07 23:44:18,493 train 200 1.681235e-02 -0.615903
2019-11-07 23:44:28,619 train 250 1.677386e-02 -0.790535
2019-11-07 23:44:38,744 train 300 1.680091e-02 -0.752947
2019-11-07 23:44:48,876 train 350 1.676363e-02 -0.771966
2019-11-07 23:44:59,018 train 400 1.682877e-02 -0.782985
2019-11-07 23:45:09,145 train 450 1.680530e-02 -0.763902
2019-11-07 23:45:19,293 train 500 1.683211e-02 -0.789829
2019-11-07 23:45:29,441 train 550 1.680629e-02 -0.787922
2019-11-07 23:45:39,594 train 600 1.676644e-02 -0.771496
2019-11-07 23:45:49,736 train 650 1.678300e-02 -0.769138
2019-11-07 23:45:59,893 train 700 1.681764e-02 -0.764288
2019-11-07 23:46:10,049 train 750 1.682182e-02 -0.760880
2019-11-07 23:46:20,196 train 800 1.680894e-02 -0.766055
2019-11-07 23:46:30,349 train 850 1.681933e-02 -0.763667
2019-11-07 23:46:33,390 training loss; R2: 1.682735e-02 -0.758591
2019-11-07 23:46:34,016 valid 000 1.505246e-02 0.053377
2019-11-07 23:46:43,460 valid 050 1.593043e-02 -1.440534
2019-11-07 23:46:51,763 validation loss; R2: 1.605503e-02 -1.304917
2019-11-07 23:46:51,830 epoch 723 lr 1.000000e-05
2019-11-07 23:46:52,623 train 000 1.626056e-02 -0.346079
2019-11-07 23:47:02,737 train 050 1.725441e-02 -0.814391
2019-11-07 23:47:12,873 train 100 1.707945e-02 -1.150064
2019-11-07 23:47:22,995 train 150 1.703548e-02 -1.134284
2019-11-07 23:47:33,122 train 200 1.702808e-02 -1.155351
2019-11-07 23:47:43,258 train 250 1.703986e-02 -1.061655
2019-11-07 23:47:53,399 train 300 1.699862e-02 -1.021340
2019-11-07 23:48:03,531 train 350 1.698577e-02 -0.986707
2019-11-07 23:48:13,656 train 400 1.700558e-02 -0.969125
2019-11-07 23:48:23,805 train 450 1.693803e-02 -0.922702
2019-11-07 23:48:33,939 train 500 1.691916e-02 -0.913010
2019-11-07 23:48:44,085 train 550 1.691103e-02 -0.905035
2019-11-07 23:48:54,224 train 600 1.687542e-02 -0.898355
2019-11-07 23:49:04,375 train 650 1.689119e-02 -0.902085
2019-11-07 23:49:14,539 train 700 1.688826e-02 -0.906476
2019-11-07 23:49:24,710 train 750 1.688550e-02 -0.901263
2019-11-07 23:49:34,863 train 800 1.688375e-02 -0.943928
2019-11-07 23:49:44,808 train 850 1.685533e-02 -0.931010
2019-11-07 23:49:47,756 training loss; R2: 1.685423e-02 -0.925280
2019-11-07 23:49:48,386 valid 000 1.897512e-02 -0.769396
2019-11-07 23:49:57,864 valid 050 1.742546e-02 -1.841573
2019-11-07 23:50:06,231 validation loss; R2: 1.727534e-02 -1.656367
2019-11-07 23:50:06,316 epoch 724 lr 1.000000e-05
2019-11-07 23:50:07,118 train 000 1.668501e-02 -0.959744
2019-11-07 23:50:16,844 train 050 1.670235e-02 -2.095077
2019-11-07 23:50:26,559 train 100 1.681282e-02 -1.463012
2019-11-07 23:50:36,335 train 150 1.680614e-02 -1.236363
2019-11-07 23:50:46,098 train 200 1.687312e-02 -1.122395
2019-11-07 23:50:55,850 train 250 1.686244e-02 -1.046852
2019-11-07 23:51:05,616 train 300 1.688119e-02 -1.062364
2019-11-07 23:51:15,381 train 350 1.688571e-02 -1.009593
2019-11-07 23:51:25,145 train 400 1.688405e-02 -0.993702
2019-11-07 23:51:34,943 train 450 1.685548e-02 -0.970881
2019-11-07 23:51:44,728 train 500 1.685835e-02 -0.949967
2019-11-07 23:51:54,523 train 550 1.684968e-02 -0.956574
2019-11-07 23:52:04,332 train 600 1.686999e-02 -0.970770
2019-11-07 23:52:14,145 train 650 1.686897e-02 -0.967059
2019-11-07 23:52:23,949 train 700 1.685553e-02 -0.946658
2019-11-07 23:52:33,764 train 750 1.685257e-02 -0.933886
2019-11-07 23:52:43,576 train 800 1.686403e-02 -0.923464
2019-11-07 23:52:53,381 train 850 1.689160e-02 -0.923703
2019-11-07 23:52:56,321 training loss; R2: 1.688632e-02 -0.920645
2019-11-07 23:52:57,016 valid 000 2.611609e-02 -0.519746
2019-11-07 23:53:06,367 valid 050 2.571469e-02 -6.402315
2019-11-07 23:53:14,874 validation loss; R2: 2.572545e-02 -4.708794
2019-11-07 23:53:14,955 epoch 725 lr 1.000000e-05
2019-11-07 23:53:15,731 train 000 1.635821e-02 -0.404397
2019-11-07 23:53:25,484 train 050 1.713597e-02 -0.912800
2019-11-07 23:53:35,216 train 100 1.700085e-02 -0.938081
2019-11-07 23:53:44,960 train 150 1.686091e-02 -0.857983
2019-11-07 23:53:54,700 train 200 1.698895e-02 -0.819353
2019-11-07 23:54:04,441 train 250 1.696794e-02 -0.771711
2019-11-07 23:54:14,167 train 300 1.689164e-02 -0.748967
2019-11-07 23:54:23,904 train 350 1.688101e-02 -0.761353
2019-11-07 23:54:33,656 train 400 1.691277e-02 -0.774225
2019-11-07 23:54:43,396 train 450 1.695953e-02 -0.745128
2019-11-07 23:54:53,141 train 500 1.695146e-02 -0.721386
2019-11-07 23:55:02,926 train 550 1.696191e-02 -0.722335
2019-11-07 23:55:12,719 train 600 1.691923e-02 -0.736445
2019-11-07 23:55:22,528 train 650 1.689429e-02 -0.719202
2019-11-07 23:55:32,338 train 700 1.691294e-02 -0.720983
2019-11-07 23:55:42,158 train 750 1.690849e-02 -0.737409
2019-11-07 23:55:51,976 train 800 1.691274e-02 -0.737684
2019-11-07 23:56:01,790 train 850 1.689418e-02 -0.729675
2019-11-07 23:56:04,725 training loss; R2: 1.687003e-02 -0.737505
2019-11-07 23:56:05,342 valid 000 1.346048e-02 0.101072
2019-11-07 23:56:14,762 valid 050 1.419523e-02 -0.572971
2019-11-07 23:56:23,176 validation loss; R2: 1.410702e-02 -0.705101
2019-11-07 23:56:23,245 epoch 726 lr 1.000000e-05
2019-11-07 23:56:24,022 train 000 1.390228e-02 -0.590430
2019-11-07 23:56:33,742 train 050 1.655499e-02 -0.705549
2019-11-07 23:56:43,473 train 100 1.667911e-02 -1.837110
2019-11-07 23:56:53,240 train 150 1.669398e-02 -1.418618
2019-11-07 23:57:03,021 train 200 1.679595e-02 -1.218052
2019-11-07 23:57:12,773 train 250 1.681362e-02 -1.057341
2019-11-07 23:57:22,504 train 300 1.684357e-02 -1.016026
2019-11-07 23:57:32,222 train 350 1.679607e-02 -0.954336
2019-11-07 23:57:41,947 train 400 1.679754e-02 -0.941907
2019-11-07 23:57:51,695 train 450 1.683067e-02 -0.937669
2019-11-07 23:58:01,480 train 500 1.685469e-02 -0.896161
2019-11-07 23:58:11,251 train 550 1.685729e-02 -0.882234
2019-11-07 23:58:21,390 train 600 1.687474e-02 -0.871334
2019-11-07 23:58:31,553 train 650 1.685931e-02 -0.879092
2019-11-07 23:58:41,705 train 700 1.688127e-02 -0.879087
2019-11-07 23:58:51,857 train 750 1.686708e-02 -0.864879
2019-11-07 23:59:02,019 train 800 1.685864e-02 -0.872722
2019-11-07 23:59:12,195 train 850 1.685144e-02 -0.866210
2019-11-07 23:59:15,236 training loss; R2: 1.685613e-02 -0.860186
2019-11-07 23:59:15,890 valid 000 1.513422e-02 0.122311
2019-11-07 23:59:25,293 valid 050 1.500870e-02 -0.908037
2019-11-07 23:59:33,615 validation loss; R2: 1.482877e-02 -0.988447
2019-11-07 23:59:33,682 epoch 727 lr 1.000000e-05
2019-11-07 23:59:34,412 train 000 1.613276e-02 -0.189760
2019-11-07 23:59:44,437 train 050 1.672024e-02 -0.983982
2019-11-07 23:59:54,195 train 100 1.662577e-02 -0.864146
2019-11-08 00:00:03,945 train 150 1.660774e-02 -1.847950
2019-11-08 00:00:13,700 train 200 1.667128e-02 -1.531998
2019-11-08 00:00:23,462 train 250 1.670503e-02 -1.341258
2019-11-08 00:00:33,218 train 300 1.676320e-02 -1.198248
2019-11-08 00:00:42,982 train 350 1.678388e-02 -1.108498
2019-11-08 00:00:52,758 train 400 1.677351e-02 -1.062725
2019-11-08 00:01:02,561 train 450 1.680104e-02 -1.048609
2019-11-08 00:01:12,343 train 500 1.679562e-02 -1.006548
2019-11-08 00:01:22,142 train 550 1.680633e-02 -0.962304
2019-11-08 00:01:31,947 train 600 1.679616e-02 -0.927235
2019-11-08 00:01:41,751 train 650 1.678413e-02 -0.908897
2019-11-08 00:01:51,550 train 700 1.679426e-02 -0.889381
2019-11-08 00:02:01,610 train 750 1.682172e-02 -0.872425
2019-11-08 00:02:11,797 train 800 1.683036e-02 -0.859924
2019-11-08 00:02:21,977 train 850 1.684365e-02 -0.842442
2019-11-08 00:02:25,022 training loss; R2: 1.685056e-02 -0.840835
2019-11-08 00:02:25,697 valid 000 1.561297e-02 -0.428933
2019-11-08 00:02:35,130 valid 050 1.573711e-02 -1.219290
2019-11-08 00:02:43,496 validation loss; R2: 1.567868e-02 -1.055747
2019-11-08 00:02:43,564 epoch 728 lr 1.000000e-05
2019-11-08 00:02:44,359 train 000 1.640002e-02 0.078300
2019-11-08 00:02:54,506 train 050 1.696234e-02 -0.594668
2019-11-08 00:03:04,646 train 100 1.697562e-02 -0.630211
2019-11-08 00:03:14,804 train 150 1.712336e-02 -0.623281
2019-11-08 00:03:24,962 train 200 1.686756e-02 -0.652896
2019-11-08 00:03:35,088 train 250 1.683175e-02 -0.690035
2019-11-08 00:03:45,239 train 300 1.690079e-02 -0.979481
2019-11-08 00:03:55,390 train 350 1.686957e-02 -0.956498
2019-11-08 00:04:05,422 train 400 1.682484e-02 -0.928630
2019-11-08 00:04:15,189 train 450 1.681336e-02 -0.884202
2019-11-08 00:04:24,955 train 500 1.680597e-02 -0.857388
2019-11-08 00:04:34,711 train 550 1.681266e-02 -0.844269
2019-11-08 00:04:44,498 train 600 1.675743e-02 -0.817694
2019-11-08 00:04:54,309 train 650 1.674541e-02 -1.971432
2019-11-08 00:05:04,095 train 700 1.671256e-02 -1.889171
2019-11-08 00:05:13,895 train 750 1.673948e-02 -1.798635
2019-11-08 00:05:23,731 train 800 1.676510e-02 -1.723016
2019-11-08 00:05:33,490 train 850 1.675897e-02 -1.684880
2019-11-08 00:05:36,402 training loss; R2: 1.675874e-02 -1.674475
2019-11-08 00:05:37,025 valid 000 1.615955e-02 0.035590
2019-11-08 00:05:46,441 valid 050 1.602581e-02 -2.162104
2019-11-08 00:05:54,750 validation loss; R2: 1.586125e-02 -1.923463
2019-11-08 00:05:54,816 epoch 729 lr 1.000000e-05
2019-11-08 00:05:55,573 train 000 1.643784e-02 -0.263956
2019-11-08 00:06:05,272 train 050 1.710037e-02 -0.765513
2019-11-08 00:06:14,987 train 100 1.686786e-02 -0.725123
2019-11-08 00:06:24,698 train 150 1.678642e-02 -0.752473
2019-11-08 00:06:34,433 train 200 1.677123e-02 -0.697493
2019-11-08 00:06:44,166 train 250 1.676508e-02 -0.706163
2019-11-08 00:06:53,900 train 300 1.683895e-02 -0.686225
2019-11-08 00:07:03,617 train 350 1.683839e-02 -0.691194
2019-11-08 00:07:13,374 train 400 1.686082e-02 -0.728440
2019-11-08 00:07:23,120 train 450 1.683150e-02 -0.718115
2019-11-08 00:07:32,852 train 500 1.681994e-02 -0.761196
2019-11-08 00:07:42,614 train 550 1.682090e-02 -0.752748
2019-11-08 00:07:52,406 train 600 1.676322e-02 -0.768701
2019-11-08 00:08:02,213 train 650 1.679212e-02 -0.784981
2019-11-08 00:08:11,995 train 700 1.677468e-02 -0.780080
2019-11-08 00:08:21,781 train 750 1.681663e-02 -0.779865
2019-11-08 00:08:31,579 train 800 1.681500e-02 -0.771835
2019-11-08 00:08:41,371 train 850 1.682649e-02 -0.770437
2019-11-08 00:08:44,299 training loss; R2: 1.682395e-02 -0.771595
2019-11-08 00:08:44,989 valid 000 1.890673e-02 -0.444528
2019-11-08 00:08:54,407 valid 050 2.443246e-02 -2.642592
2019-11-08 00:09:02,750 validation loss; R2: 2.485857e-02 -2.613264
2019-11-08 00:09:02,817 epoch 730 lr 1.000000e-05
2019-11-08 00:09:03,573 train 000 1.622916e-02 -0.496134
2019-11-08 00:09:13,295 train 050 1.662565e-02 -0.900069
2019-11-08 00:09:23,033 train 100 1.687189e-02 -0.847246
2019-11-08 00:09:32,783 train 150 1.677234e-02 -0.834979
2019-11-08 00:09:42,535 train 200 1.679123e-02 -0.758082
2019-11-08 00:09:52,296 train 250 1.676463e-02 -0.767900
2019-11-08 00:10:02,046 train 300 1.678032e-02 -0.717743
2019-11-08 00:10:11,799 train 350 1.680305e-02 -0.711596
2019-11-08 00:10:21,562 train 400 1.677946e-02 -0.759409
2019-11-08 00:10:31,320 train 450 1.679765e-02 -0.752536
2019-11-08 00:10:41,080 train 500 1.676739e-02 -47.167850
2019-11-08 00:10:50,885 train 550 1.679320e-02 -42.941526
2019-11-08 00:11:00,666 train 600 1.681876e-02 -39.418026
2019-11-08 00:11:10,456 train 650 1.678914e-02 -36.432504
2019-11-08 00:11:20,243 train 700 1.677932e-02 -33.919131
2019-11-08 00:11:30,030 train 750 1.680927e-02 -31.704982
2019-11-08 00:11:39,824 train 800 1.682249e-02 -29.765769
2019-11-08 00:11:49,601 train 850 1.680298e-02 -28.061813
2019-11-08 00:11:52,527 training loss; R2: 1.680065e-02 -27.587500
2019-11-08 00:11:53,162 valid 000 2.319584e-02 -1.426914
2019-11-08 00:12:02,540 valid 050 2.576018e-02 -2.896464
2019-11-08 00:12:11,005 validation loss; R2: 2.576346e-02 -3.151466
2019-11-08 00:12:11,072 epoch 731 lr 1.000000e-05
2019-11-08 00:12:11,865 train 000 1.674427e-02 -0.679109
2019-11-08 00:12:21,596 train 050 1.685003e-02 -0.392132
2019-11-08 00:12:31,333 train 100 1.664474e-02 -0.567071
2019-11-08 00:12:41,100 train 150 1.659214e-02 -0.703662
2019-11-08 00:12:50,863 train 200 1.666030e-02 -0.703215
2019-11-08 00:13:00,627 train 250 1.668105e-02 -0.713236
2019-11-08 00:13:10,385 train 300 1.673890e-02 -0.707774
2019-11-08 00:13:20,143 train 350 1.675048e-02 -0.695693
2019-11-08 00:13:29,896 train 400 1.672581e-02 -0.696755
2019-11-08 00:13:39,654 train 450 1.673602e-02 -0.686527
2019-11-08 00:13:49,429 train 500 1.679372e-02 -0.739342
2019-11-08 00:13:59,182 train 550 1.678374e-02 -0.727867
2019-11-08 00:14:08,958 train 600 1.682016e-02 -0.748950
2019-11-08 00:14:18,743 train 650 1.681481e-02 -0.772865
2019-11-08 00:14:28,535 train 700 1.681818e-02 -0.768744
2019-11-08 00:14:38,315 train 750 1.680061e-02 -0.759250
2019-11-08 00:14:48,098 train 800 1.678918e-02 -0.758639
2019-11-08 00:14:57,888 train 850 1.679499e-02 -0.764237
2019-11-08 00:15:00,804 training loss; R2: 1.680607e-02 -0.764218
2019-11-08 00:15:01,440 valid 000 1.871430e-02 -1.611104
2019-11-08 00:15:10,881 valid 050 1.983684e-02 -2.547078
2019-11-08 00:15:19,222 validation loss; R2: 1.985200e-02 -2.441228
2019-11-08 00:15:19,289 epoch 732 lr 1.000000e-05
2019-11-08 00:15:20,107 train 000 1.444704e-02 -1.445592
2019-11-08 00:15:29,827 train 050 1.704359e-02 -0.878040
2019-11-08 00:15:39,555 train 100 1.670891e-02 -0.859765
2019-11-08 00:15:49,335 train 150 1.682942e-02 -0.843007
2019-11-08 00:15:59,112 train 200 1.685873e-02 -0.848504
2019-11-08 00:16:08,893 train 250 1.681748e-02 -0.843165
2019-11-08 00:16:18,678 train 300 1.679298e-02 -0.832543
2019-11-08 00:16:28,451 train 350 1.679264e-02 -0.930239
2019-11-08 00:16:38,229 train 400 1.678298e-02 -0.909364
2019-11-08 00:16:48,002 train 450 1.684118e-02 -0.866325
2019-11-08 00:16:57,800 train 500 1.686234e-02 -0.829152
2019-11-08 00:17:07,591 train 550 1.685309e-02 -0.813936
2019-11-08 00:17:17,383 train 600 1.686152e-02 -0.830742
2019-11-08 00:17:27,178 train 650 1.686325e-02 -0.841519
2019-11-08 00:17:36,979 train 700 1.686126e-02 -0.979519
2019-11-08 00:17:46,776 train 750 1.687804e-02 -0.950167
2019-11-08 00:17:56,581 train 800 1.686486e-02 -0.940076
2019-11-08 00:18:06,376 train 850 1.686666e-02 -0.995222
2019-11-08 00:18:09,315 training loss; R2: 1.687447e-02 -0.989273
2019-11-08 00:18:09,932 valid 000 1.573956e-02 -13.610480
2019-11-08 00:18:19,387 valid 050 1.589383e-02 -2.018249
2019-11-08 00:18:27,728 validation loss; R2: 1.584435e-02 -2.051352
2019-11-08 00:18:27,795 epoch 733 lr 1.000000e-05
2019-11-08 00:18:28,539 train 000 1.747610e-02 -0.211951
2019-11-08 00:18:38,268 train 050 1.689942e-02 -0.594684
2019-11-08 00:18:48,039 train 100 1.683566e-02 -0.638191
2019-11-08 00:18:57,836 train 150 1.687383e-02 -0.732254
2019-11-08 00:19:07,622 train 200 1.680931e-02 -0.820373
2019-11-08 00:19:17,389 train 250 1.684319e-02 -0.841039
2019-11-08 00:19:27,183 train 300 1.689165e-02 -0.821202
2019-11-08 00:19:37,006 train 350 1.688834e-02 -0.813179
2019-11-08 00:19:46,834 train 400 1.692538e-02 -0.763780
2019-11-08 00:19:56,653 train 450 1.698117e-02 -0.744472
2019-11-08 00:20:06,477 train 500 1.697023e-02 -0.782060
2019-11-08 00:20:16,315 train 550 1.698690e-02 -0.776411
2019-11-08 00:20:26,115 train 600 1.699963e-02 -0.765684
2019-11-08 00:20:35,930 train 650 1.694657e-02 -0.758853
2019-11-08 00:20:45,726 train 700 1.693829e-02 -0.756569
2019-11-08 00:20:55,524 train 750 1.692878e-02 -0.763218
2019-11-08 00:21:05,332 train 800 1.690031e-02 -0.785435
2019-11-08 00:21:15,123 train 850 1.689205e-02 -0.782277
2019-11-08 00:21:18,048 training loss; R2: 1.690350e-02 -0.800908
2019-11-08 00:21:18,747 valid 000 2.528717e-02 -1.484713
2019-11-08 00:21:28,167 valid 050 2.911778e-02 -2.367023
2019-11-08 00:21:36,431 validation loss; R2: 2.966895e-02 -3.098775
2019-11-08 00:21:36,496 epoch 734 lr 1.000000e-05
2019-11-08 00:21:37,239 train 000 1.889340e-02 -0.328939
2019-11-08 00:21:47,000 train 050 1.691042e-02 -0.952292
2019-11-08 00:21:56,766 train 100 1.689063e-02 -1.168192
2019-11-08 00:22:06,527 train 150 1.685628e-02 -0.993558
2019-11-08 00:22:16,313 train 200 1.694226e-02 -1.042374
2019-11-08 00:22:26,102 train 250 1.699728e-02 -0.926000
2019-11-08 00:22:35,888 train 300 1.692486e-02 -0.883743
2019-11-08 00:22:45,677 train 350 1.692484e-02 -0.865460
2019-11-08 00:22:55,479 train 400 1.696317e-02 -0.822100
2019-11-08 00:23:05,282 train 450 1.697663e-02 -0.803388
2019-11-08 00:23:15,073 train 500 1.693887e-02 -0.791746
2019-11-08 00:23:24,883 train 550 1.691329e-02 -0.804727
2019-11-08 00:23:34,692 train 600 1.695533e-02 -0.775189
2019-11-08 00:23:44,482 train 650 1.692142e-02 -0.761782
2019-11-08 00:23:54,278 train 700 1.691604e-02 -0.738597
2019-11-08 00:24:04,086 train 750 1.692849e-02 -0.744055
2019-11-08 00:24:13,875 train 800 1.690660e-02 -0.742627
2019-11-08 00:24:23,671 train 850 1.689464e-02 -0.739403
2019-11-08 00:24:26,598 training loss; R2: 1.688305e-02 -0.734189
2019-11-08 00:24:27,218 valid 000 1.581651e-02 -0.245347
2019-11-08 00:24:36,644 valid 050 1.591376e-02 -1.600926
2019-11-08 00:24:44,966 validation loss; R2: 1.581235e-02 -1.642989
2019-11-08 00:24:45,035 epoch 735 lr 1.000000e-05
2019-11-08 00:24:45,769 train 000 1.431418e-02 -0.455510
2019-11-08 00:24:55,504 train 050 1.665949e-02 -0.719455
2019-11-08 00:25:05,244 train 100 1.674008e-02 -0.977803
2019-11-08 00:25:14,994 train 150 1.677950e-02 -1.186888
2019-11-08 00:25:24,754 train 200 1.691599e-02 -1.038583
2019-11-08 00:25:34,536 train 250 1.695114e-02 -4.599570
2019-11-08 00:25:44,324 train 300 1.693682e-02 -3.953981
2019-11-08 00:25:54,104 train 350 1.692028e-02 -3.494064
2019-11-08 00:26:03,890 train 400 1.690735e-02 -3.158811
2019-11-08 00:26:13,675 train 450 1.689726e-02 -2.892945
2019-11-08 00:26:23,453 train 500 1.684047e-02 -2.693673
2019-11-08 00:26:33,234 train 550 1.684927e-02 -2.510948
2019-11-08 00:26:43,026 train 600 1.683199e-02 -2.358347
2019-11-08 00:26:52,817 train 650 1.686328e-02 -2.237374
2019-11-08 00:27:02,608 train 700 1.685706e-02 -2.132256
2019-11-08 00:27:12,393 train 750 1.685840e-02 -2.034704
2019-11-08 00:27:22,188 train 800 1.685824e-02 -1.938930
2019-11-08 00:27:31,986 train 850 1.686882e-02 -1.862649
2019-11-08 00:27:34,914 training loss; R2: 1.687777e-02 -1.842745
2019-11-08 00:27:35,614 valid 000 1.907700e-02 -0.134577
2019-11-08 00:27:44,987 valid 050 1.638860e-02 -0.925329
2019-11-08 00:27:53,360 validation loss; R2: 1.652328e-02 -0.818433
2019-11-08 00:27:53,427 epoch 736 lr 1.000000e-05
2019-11-08 00:27:54,174 train 000 1.883376e-02 -0.792745
2019-11-08 00:28:03,918 train 050 1.675641e-02 -0.901317
2019-11-08 00:28:13,642 train 100 1.655935e-02 -0.781770
2019-11-08 00:28:23,400 train 150 1.667359e-02 -0.750134
2019-11-08 00:28:33,178 train 200 1.673957e-02 -0.881460
2019-11-08 00:28:42,973 train 250 1.678193e-02 -0.893408
2019-11-08 00:28:52,753 train 300 1.675918e-02 -0.916434
2019-11-08 00:29:02,542 train 350 1.673258e-02 -0.873878
2019-11-08 00:29:12,329 train 400 1.678786e-02 -0.870160
2019-11-08 00:29:22,118 train 450 1.676061e-02 -0.857120
2019-11-08 00:29:31,901 train 500 1.673013e-02 -0.836529
2019-11-08 00:29:41,707 train 550 1.677930e-02 -0.832297
2019-11-08 00:29:51,514 train 600 1.678678e-02 -0.838141
2019-11-08 00:30:01,309 train 650 1.681688e-02 -0.831956
2019-11-08 00:30:11,091 train 700 1.681107e-02 -0.827519
2019-11-08 00:30:20,875 train 750 1.680826e-02 -0.809621
2019-11-08 00:30:30,656 train 800 1.680933e-02 -0.789183
2019-11-08 00:30:40,463 train 850 1.681920e-02 -0.790488
2019-11-08 00:30:43,402 training loss; R2: 1.682418e-02 -0.784599
2019-11-08 00:30:44,080 valid 000 1.556802e-02 -2.016054
2019-11-08 00:30:53,444 valid 050 1.436683e-02 -0.595629
2019-11-08 00:31:01,859 validation loss; R2: 1.437980e-02 -0.808577
2019-11-08 00:31:01,927 epoch 737 lr 1.000000e-05
2019-11-08 00:31:02,694 train 000 1.602331e-02 0.019487
2019-11-08 00:31:12,431 train 050 1.714771e-02 -0.674635
2019-11-08 00:31:22,168 train 100 1.695469e-02 -0.631030
2019-11-08 00:31:31,931 train 150 1.694284e-02 -0.650894
2019-11-08 00:31:41,710 train 200 1.694103e-02 -0.645900
2019-11-08 00:31:51,507 train 250 1.697982e-02 -0.649055
2019-11-08 00:32:01,305 train 300 1.700265e-02 -0.646878
2019-11-08 00:32:11,114 train 350 1.695919e-02 -0.668489
2019-11-08 00:32:20,933 train 400 1.692720e-02 -0.682860
2019-11-08 00:32:30,740 train 450 1.690744e-02 -2.798799
2019-11-08 00:32:40,529 train 500 1.687916e-02 -2.581406
2019-11-08 00:32:50,331 train 550 1.690227e-02 -2.407433
2019-11-08 00:33:00,125 train 600 1.687295e-02 -2.274073
2019-11-08 00:33:09,925 train 650 1.690369e-02 -2.171078
2019-11-08 00:33:19,723 train 700 1.691889e-02 -2.065233
2019-11-08 00:33:29,515 train 750 1.693726e-02 -1.987932
2019-11-08 00:33:39,302 train 800 1.694030e-02 -1.918328
2019-11-08 00:33:49,100 train 850 1.693333e-02 -1.833986
2019-11-08 00:33:52,034 training loss; R2: 1.692917e-02 -1.809868
2019-11-08 00:33:52,666 valid 000 2.722196e-02 -1.036427
2019-11-08 00:34:02,100 valid 050 2.463119e-02 -3.167806
2019-11-08 00:34:10,450 validation loss; R2: 2.477789e-02 -3.161744
2019-11-08 00:34:10,516 epoch 738 lr 1.000000e-05
2019-11-08 00:34:11,252 train 000 1.693892e-02 0.110140
2019-11-08 00:34:21,022 train 050 1.687952e-02 -0.765915
2019-11-08 00:34:30,783 train 100 1.690802e-02 -0.684223
2019-11-08 00:34:40,556 train 150 1.685948e-02 -0.665536
2019-11-08 00:34:50,334 train 200 1.679157e-02 -0.707532
2019-11-08 00:35:00,126 train 250 1.679992e-02 -0.746951
2019-11-08 00:35:09,918 train 300 1.680062e-02 -0.722874
2019-11-08 00:35:19,803 train 350 1.675953e-02 -0.688505
2019-11-08 00:35:29,967 train 400 1.676999e-02 -0.716878
2019-11-08 00:35:40,127 train 450 1.674573e-02 -0.717289
2019-11-08 00:35:50,169 train 500 1.673847e-02 -0.748091
2019-11-08 00:35:59,969 train 550 1.676693e-02 -0.734086
2019-11-08 00:36:09,762 train 600 1.674532e-02 -0.727809
2019-11-08 00:36:19,556 train 650 1.677170e-02 -0.740842
2019-11-08 00:36:29,352 train 700 1.676596e-02 -0.730363
2019-11-08 00:36:39,143 train 750 1.680975e-02 -0.718030
2019-11-08 00:36:48,930 train 800 1.683076e-02 -0.709020
2019-11-08 00:36:58,714 train 850 1.684044e-02 -0.723520
2019-11-08 00:37:01,647 training loss; R2: 1.683428e-02 -0.723722
2019-11-08 00:37:02,281 valid 000 1.914429e-02 -0.672529
2019-11-08 00:37:11,664 valid 050 2.111264e-02 -2.318117
2019-11-08 00:37:20,120 validation loss; R2: 2.140935e-02 -2.282432
2019-11-08 00:37:20,187 epoch 739 lr 1.000000e-05
2019-11-08 00:37:20,975 train 000 1.578662e-02 -0.162656
2019-11-08 00:37:30,721 train 050 1.657529e-02 -0.684196
2019-11-08 00:37:40,503 train 100 1.674297e-02 -0.808143
2019-11-08 00:37:50,292 train 150 1.666526e-02 -0.988030
2019-11-08 00:38:00,110 train 200 1.672301e-02 -0.982568
2019-11-08 00:38:09,937 train 250 1.671649e-02 -0.924675
2019-11-08 00:38:19,762 train 300 1.677815e-02 -0.886037
2019-11-08 00:38:29,573 train 350 1.679141e-02 -0.834613
2019-11-08 00:38:39,408 train 400 1.680351e-02 -0.830553
2019-11-08 00:38:49,237 train 450 1.683428e-02 -0.848245
2019-11-08 00:38:59,051 train 500 1.684862e-02 -0.830229
2019-11-08 00:39:08,848 train 550 1.683539e-02 -0.826014
2019-11-08 00:39:18,643 train 600 1.681941e-02 -0.809227
2019-11-08 00:39:28,442 train 650 1.682918e-02 -0.800290
2019-11-08 00:39:38,242 train 700 1.683670e-02 -0.798222
2019-11-08 00:39:48,049 train 750 1.683247e-02 -0.779659
2019-11-08 00:39:57,866 train 800 1.683866e-02 -0.807272
2019-11-08 00:40:07,673 train 850 1.682234e-02 -0.782969
2019-11-08 00:40:10,599 training loss; R2: 1.681841e-02 -0.776861
2019-11-08 00:40:11,314 valid 000 1.645705e-02 -7.902871
2019-11-08 00:40:20,675 valid 050 1.510708e-02 -1.006551
2019-11-08 00:40:28,964 validation loss; R2: 1.513697e-02 -1.086844
2019-11-08 00:40:29,032 epoch 740 lr 1.000000e-05
2019-11-08 00:40:29,814 train 000 1.419427e-02 -0.865995
2019-11-08 00:40:39,586 train 050 1.679113e-02 -0.648879
2019-11-08 00:40:49,382 train 100 1.676549e-02 -0.618974
2019-11-08 00:40:59,181 train 150 1.674744e-02 -0.725474
2019-11-08 00:41:08,995 train 200 1.680863e-02 -0.720921
2019-11-08 00:41:18,808 train 250 1.675075e-02 -0.698940
2019-11-08 00:41:28,634 train 300 1.681137e-02 -0.693502
2019-11-08 00:41:38,466 train 350 1.678277e-02 -0.713048
2019-11-08 00:41:48,295 train 400 1.676882e-02 -0.716232
2019-11-08 00:41:58,123 train 450 1.675221e-02 -0.731934
2019-11-08 00:42:07,943 train 500 1.679262e-02 -0.737915
2019-11-08 00:42:17,766 train 550 1.678944e-02 -0.725649
2019-11-08 00:42:27,591 train 600 1.678191e-02 -0.799618
2019-11-08 00:42:37,404 train 650 1.681563e-02 -0.787698
2019-11-08 00:42:47,260 train 700 1.680856e-02 -1.023702
2019-11-08 00:42:57,071 train 750 1.681762e-02 -0.988693
2019-11-08 00:43:06,868 train 800 1.680119e-02 -0.977602
2019-11-08 00:43:16,675 train 850 1.681631e-02 -0.970462
2019-11-08 00:43:19,601 training loss; R2: 1.682128e-02 -0.965644
2019-11-08 00:43:20,286 valid 000 1.376646e-02 -2.240546
2019-11-08 00:43:29,692 valid 050 1.693301e-02 -1.540610
2019-11-08 00:43:38,000 validation loss; R2: 1.679044e-02 -2.620123
2019-11-08 00:43:38,067 epoch 741 lr 1.000000e-05
2019-11-08 00:43:38,828 train 000 1.665223e-02 -0.137458
2019-11-08 00:43:48,556 train 050 1.664737e-02 -0.737395
2019-11-08 00:43:58,320 train 100 1.661339e-02 -0.747823
2019-11-08 00:44:08,099 train 150 1.662738e-02 -0.742915
2019-11-08 00:44:17,889 train 200 1.667765e-02 -0.688683
2019-11-08 00:44:27,683 train 250 1.668281e-02 -0.688931
2019-11-08 00:44:37,470 train 300 1.669026e-02 -0.706931
2019-11-08 00:44:47,263 train 350 1.670859e-02 -0.661894
2019-11-08 00:44:57,059 train 400 1.674643e-02 -0.656122
2019-11-08 00:45:06,867 train 450 1.679578e-02 -0.681618
2019-11-08 00:45:16,670 train 500 1.675501e-02 -0.674216
2019-11-08 00:45:26,463 train 550 1.674906e-02 -0.848162
2019-11-08 00:45:36,264 train 600 1.679468e-02 -0.844617
2019-11-08 00:45:46,059 train 650 1.681020e-02 -0.837724
2019-11-08 00:45:55,851 train 700 1.682155e-02 -0.818063
2019-11-08 00:46:05,648 train 750 1.683828e-02 -0.819173
2019-11-08 00:46:15,456 train 800 1.684126e-02 -0.799083
2019-11-08 00:46:25,250 train 850 1.685942e-02 -0.811237
2019-11-08 00:46:28,183 training loss; R2: 1.687034e-02 -0.809413
2019-11-08 00:46:28,818 valid 000 1.810732e-02 -3.817589
2019-11-08 00:46:38,253 valid 050 1.520282e-02 -1.799512
2019-11-08 00:46:46,578 validation loss; R2: 1.493660e-02 -1.445201
2019-11-08 00:46:46,642 epoch 742 lr 1.000000e-05
2019-11-08 00:46:47,413 train 000 1.545771e-02 -0.539235
2019-11-08 00:46:57,153 train 050 1.685075e-02 -0.754663
2019-11-08 00:47:06,912 train 100 1.690821e-02 -0.642980
2019-11-08 00:47:16,680 train 150 1.693888e-02 -0.597480
2019-11-08 00:47:26,472 train 200 1.686639e-02 -0.708967
2019-11-08 00:47:36,252 train 250 1.686428e-02 -0.684516
2019-11-08 00:47:46,041 train 300 1.687858e-02 -0.670350
2019-11-08 00:47:55,840 train 350 1.688237e-02 -0.683950
2019-11-08 00:48:05,631 train 400 1.690570e-02 -0.672650
2019-11-08 00:48:15,420 train 450 1.689240e-02 -0.695144
2019-11-08 00:48:25,218 train 500 1.684617e-02 -0.719598
2019-11-08 00:48:35,015 train 550 1.686969e-02 -0.727201
2019-11-08 00:48:44,807 train 600 1.684768e-02 -0.721610
2019-11-08 00:48:54,612 train 650 1.686315e-02 -0.734545
2019-11-08 00:49:04,408 train 700 1.685606e-02 -0.749778
2019-11-08 00:49:14,236 train 750 1.685994e-02 -0.763828
2019-11-08 00:49:24,055 train 800 1.688544e-02 -0.763872
2019-11-08 00:49:33,868 train 850 1.686614e-02 -0.764593
2019-11-08 00:49:36,804 training loss; R2: 1.685244e-02 -0.760288
2019-11-08 00:49:37,437 valid 000 2.177021e-02 -6.046331
2019-11-08 00:49:46,890 valid 050 2.377912e-02 -2.363445
2019-11-08 00:49:55,195 validation loss; R2: 2.366689e-02 -2.823125
2019-11-08 00:49:55,262 epoch 743 lr 1.000000e-05
2019-11-08 00:49:55,987 train 000 1.619083e-02 -0.374226
2019-11-08 00:50:05,719 train 050 1.683393e-02 -0.823615
2019-11-08 00:50:15,467 train 100 1.670369e-02 -0.757402
2019-11-08 00:50:25,264 train 150 1.664594e-02 -0.764411
2019-11-08 00:50:35,073 train 200 1.689804e-02 -0.764129
2019-11-08 00:50:44,881 train 250 1.691854e-02 -0.719003
2019-11-08 00:50:54,706 train 300 1.691147e-02 -0.746843
2019-11-08 00:51:04,522 train 350 1.691577e-02 -0.726051
2019-11-08 00:51:14,335 train 400 1.683592e-02 -0.716603
2019-11-08 00:51:24,138 train 450 1.683300e-02 -0.757240
2019-11-08 00:51:33,930 train 500 1.680789e-02 -0.782525
2019-11-08 00:51:43,733 train 550 1.677338e-02 -0.786665
2019-11-08 00:51:53,542 train 600 1.683717e-02 -0.891210
2019-11-08 00:52:03,357 train 650 1.681858e-02 -0.883098
2019-11-08 00:52:13,172 train 700 1.680837e-02 -0.863207
2019-11-08 00:52:22,992 train 750 1.682460e-02 -0.866936
2019-11-08 00:52:32,815 train 800 1.683536e-02 -0.859135
2019-11-08 00:52:42,641 train 850 1.684489e-02 -0.853423
2019-11-08 00:52:45,574 training loss; R2: 1.684109e-02 -0.853123
2019-11-08 00:52:46,195 valid 000 3.122848e-02 -5.381945
2019-11-08 00:52:55,590 valid 050 2.554457e-02 -3.561704
2019-11-08 00:53:03,906 validation loss; R2: 2.573450e-02 -22.254483
2019-11-08 00:53:03,964 epoch 744 lr 1.000000e-05
2019-11-08 00:53:04,697 train 000 1.706022e-02 -0.017654
2019-11-08 00:53:14,461 train 050 1.719503e-02 -0.681155
2019-11-08 00:53:24,232 train 100 1.696633e-02 -0.933968
2019-11-08 00:53:34,391 train 150 1.695746e-02 -0.854236
2019-11-08 00:53:44,562 train 200 1.682626e-02 -0.794293
2019-11-08 00:53:54,770 train 250 1.680999e-02 -0.826855
2019-11-08 00:54:04,952 train 300 1.678417e-02 -0.843349
2019-11-08 00:54:15,142 train 350 1.682936e-02 -0.797514
2019-11-08 00:54:25,361 train 400 1.680549e-02 -0.783361
2019-11-08 00:54:35,555 train 450 1.679388e-02 -0.766665
2019-11-08 00:54:45,740 train 500 1.679467e-02 -0.748777
2019-11-08 00:54:55,932 train 550 1.681666e-02 -0.774129
2019-11-08 00:55:06,125 train 600 1.680108e-02 -0.781139
2019-11-08 00:55:16,335 train 650 1.676896e-02 -0.761723
2019-11-08 00:55:26,540 train 700 1.679274e-02 -0.765927
2019-11-08 00:55:36,748 train 750 1.677232e-02 -0.753018
2019-11-08 00:55:46,979 train 800 1.676708e-02 -0.743208
2019-11-08 00:55:57,203 train 850 1.679850e-02 -0.745218
2019-11-08 00:56:00,250 training loss; R2: 1.680423e-02 -0.745099
2019-11-08 00:56:00,851 valid 000 1.820939e-02 -1.046220
2019-11-08 00:56:10,317 valid 050 1.507084e-02 -0.718453
2019-11-08 00:56:18,636 validation loss; R2: 1.505888e-02 -0.649757
2019-11-08 00:56:18,700 epoch 745 lr 1.000000e-05
2019-11-08 00:56:19,482 train 000 1.615582e-02 -0.003718
2019-11-08 00:56:29,603 train 050 1.718423e-02 -0.515917
2019-11-08 00:56:39,759 train 100 1.690212e-02 -0.617286
2019-11-08 00:56:49,912 train 150 1.693473e-02 -0.760239
2019-11-08 00:57:00,079 train 200 1.685836e-02 -0.695229
2019-11-08 00:57:10,248 train 250 1.683465e-02 -0.652250
2019-11-08 00:57:20,435 train 300 1.678322e-02 -0.666202
2019-11-08 00:57:30,617 train 350 1.683200e-02 -0.691311
2019-11-08 00:57:40,826 train 400 1.683582e-02 -0.719021
2019-11-08 00:57:50,708 train 450 1.676596e-02 -0.704788
2019-11-08 00:58:00,536 train 500 1.676211e-02 -0.680928
2019-11-08 00:58:10,365 train 550 1.678048e-02 -0.665660
2019-11-08 00:58:20,197 train 600 1.676410e-02 -0.675641
2019-11-08 00:58:30,024 train 650 1.679079e-02 -0.713561
2019-11-08 00:58:39,852 train 700 1.678580e-02 -0.719753
2019-11-08 00:58:49,687 train 750 1.676909e-02 -0.717634
2019-11-08 00:58:59,526 train 800 1.675018e-02 -0.741547
2019-11-08 00:59:09,337 train 850 1.674497e-02 -0.746227
2019-11-08 00:59:12,274 training loss; R2: 1.675536e-02 -0.741957
2019-11-08 00:59:12,964 valid 000 2.921766e-02 -3.655204
2019-11-08 00:59:22,365 valid 050 3.540791e-02 -2.959998
2019-11-08 00:59:30,710 validation loss; R2: 3.477941e-02 -3.406398
2019-11-08 00:59:30,775 epoch 746 lr 1.000000e-05
2019-11-08 00:59:31,539 train 000 1.268733e-02 -1.349247
2019-11-08 00:59:41,306 train 050 1.686342e-02 -0.556022
2019-11-08 00:59:51,085 train 100 1.690234e-02 -0.959275
2019-11-08 01:00:00,896 train 150 1.686041e-02 -0.917425
2019-11-08 01:00:10,681 train 200 1.672750e-02 -0.853355
2019-11-08 01:00:20,391 train 250 1.676571e-02 -0.864713
2019-11-08 01:00:30,097 train 300 1.680609e-02 -0.814549
2019-11-08 01:00:39,852 train 350 1.680909e-02 -0.828802
2019-11-08 01:00:49,622 train 400 1.681037e-02 -0.813732
2019-11-08 01:00:59,413 train 450 1.676711e-02 -0.895571
2019-11-08 01:01:09,204 train 500 1.679340e-02 -0.861664
2019-11-08 01:01:18,986 train 550 1.680076e-02 -0.870272
2019-11-08 01:01:28,767 train 600 1.681166e-02 -0.854249
2019-11-08 01:01:38,548 train 650 1.682519e-02 -0.849250
2019-11-08 01:01:48,330 train 700 1.681842e-02 -0.825030
2019-11-08 01:01:58,143 train 750 1.681162e-02 -0.847240
2019-11-08 01:02:07,938 train 800 1.684717e-02 -0.831126
2019-11-08 01:02:17,726 train 850 1.683510e-02 -0.841026
2019-11-08 01:02:20,682 training loss; R2: 1.683685e-02 -0.838956
2019-11-08 01:02:21,382 valid 000 1.249625e-02 -0.550415
2019-11-08 01:02:30,712 valid 050 1.494208e-02 -1.271440
2019-11-08 01:02:39,144 validation loss; R2: 1.501264e-02 -1.313576
2019-11-08 01:02:39,225 epoch 747 lr 1.000000e-05
2019-11-08 01:02:40,004 train 000 1.714302e-02 -2.406792
2019-11-08 01:02:49,788 train 050 1.625998e-02 -0.817308
2019-11-08 01:02:59,543 train 100 1.641323e-02 -0.967067
2019-11-08 01:03:09,308 train 150 1.667440e-02 -0.788529
2019-11-08 01:03:19,051 train 200 1.661707e-02 -0.722279
2019-11-08 01:03:28,815 train 250 1.662536e-02 -0.741401
2019-11-08 01:03:38,576 train 300 1.666069e-02 -0.723950
2019-11-08 01:03:48,339 train 350 1.661712e-02 -0.715141
2019-11-08 01:03:58,105 train 400 1.663542e-02 -0.726155
2019-11-08 01:04:07,894 train 450 1.664672e-02 -0.709663
2019-11-08 01:04:17,672 train 500 1.669782e-02 -0.717101
2019-11-08 01:04:27,460 train 550 1.674478e-02 -0.711431
2019-11-08 01:04:37,231 train 600 1.675029e-02 -0.705990
2019-11-08 01:04:47,006 train 650 1.674836e-02 -0.766000
2019-11-08 01:04:56,796 train 700 1.674976e-02 -0.756105
2019-11-08 01:05:06,577 train 750 1.675097e-02 -0.747436
2019-11-08 01:05:16,372 train 800 1.677453e-02 -0.741201
2019-11-08 01:05:26,160 train 850 1.676002e-02 -0.742969
2019-11-08 01:05:29,111 training loss; R2: 1.676413e-02 -0.750126
2019-11-08 01:05:29,812 valid 000 1.544159e-02 -0.918077
2019-11-08 01:05:39,195 valid 050 1.491683e-02 -0.636932
2019-11-08 01:05:47,542 validation loss; R2: 1.497552e-02 -0.901412
2019-11-08 01:05:47,626 epoch 748 lr 1.000000e-05
2019-11-08 01:05:48,426 train 000 1.480520e-02 -0.314232
2019-11-08 01:05:58,541 train 050 1.669356e-02 -0.702848
2019-11-08 01:06:08,677 train 100 1.665595e-02 -0.809176
2019-11-08 01:06:18,801 train 150 1.677917e-02 -0.724960
2019-11-08 01:06:28,928 train 200 1.686442e-02 -0.712659
2019-11-08 01:06:39,087 train 250 1.682675e-02 -0.714532
2019-11-08 01:06:49,218 train 300 1.679069e-02 -0.721885
2019-11-08 01:06:59,359 train 350 1.680648e-02 -0.674334
2019-11-08 01:07:09,522 train 400 1.681313e-02 -0.675769
2019-11-08 01:07:19,684 train 450 1.681368e-02 -0.709302
2019-11-08 01:07:29,833 train 500 1.682310e-02 -0.732805
2019-11-08 01:07:39,998 train 550 1.686410e-02 -0.742128
2019-11-08 01:07:50,161 train 600 1.683141e-02 -0.903148
2019-11-08 01:08:00,337 train 650 1.683207e-02 -0.873235
2019-11-08 01:08:10,511 train 700 1.683311e-02 -0.858654
2019-11-08 01:08:20,689 train 750 1.681906e-02 -0.866075
2019-11-08 01:08:30,860 train 800 1.682639e-02 -0.845130
2019-11-08 01:08:41,022 train 850 1.681536e-02 -0.848704
2019-11-08 01:08:44,050 training loss; R2: 1.682592e-02 -0.840102
2019-11-08 01:08:44,702 valid 000 1.433120e-02 0.053688
2019-11-08 01:08:54,123 valid 050 1.545460e-02 -0.780815
2019-11-08 01:09:02,434 validation loss; R2: 1.558427e-02 -0.927558
2019-11-08 01:09:02,502 epoch 749 lr 1.000000e-05
2019-11-08 01:09:03,209 train 000 1.657161e-02 0.064665
2019-11-08 01:09:13,306 train 050 1.696476e-02 -0.711019
2019-11-08 01:09:23,407 train 100 1.680061e-02 -1.072110
2019-11-08 01:09:33,509 train 150 1.671372e-02 -0.953001
2019-11-08 01:09:43,638 train 200 1.694486e-02 -0.909921
2019-11-08 01:09:53,762 train 250 1.690098e-02 -0.865546
2019-11-08 01:10:03,925 train 300 1.687967e-02 -0.860770
2019-11-08 01:10:14,085 train 350 1.690860e-02 -0.838990
2019-11-08 01:10:24,248 train 400 1.691803e-02 -0.838110
2019-11-08 01:10:34,419 train 450 1.691455e-02 -0.810908
2019-11-08 01:10:44,582 train 500 1.689434e-02 -0.809245
2019-11-08 01:10:54,746 train 550 1.689819e-02 -0.781608
2019-11-08 01:11:04,920 train 600 1.687016e-02 -0.771799
2019-11-08 01:11:15,102 train 650 1.684115e-02 -0.753986
2019-11-08 01:11:25,274 train 700 1.681068e-02 -0.773114
2019-11-08 01:11:35,457 train 750 1.679200e-02 -0.756494
2019-11-08 01:11:45,637 train 800 1.680764e-02 -0.770989
2019-11-08 01:11:55,826 train 850 1.680267e-02 -0.767009
2019-11-08 01:11:58,863 training loss; R2: 1.680472e-02 -0.759780
2019-11-08 01:11:59,566 valid 000 1.531438e-02 -2.388669
2019-11-08 01:12:08,957 valid 050 1.505616e-02 -0.779785
2019-11-08 01:12:17,334 validation loss; R2: 1.520132e-02 -0.752491
2019-11-08 01:12:17,405 epoch 750 lr 1.000000e-05
2019-11-08 01:12:18,185 train 000 1.469818e-02 -0.388917
2019-11-08 01:12:28,108 train 050 1.674842e-02 -0.901786
2019-11-08 01:12:37,872 train 100 1.660591e-02 -0.820267
2019-11-08 01:12:47,640 train 150 1.662491e-02 -0.730997
2019-11-08 01:12:57,431 train 200 1.671042e-02 -0.658304
2019-11-08 01:13:07,240 train 250 1.676013e-02 -0.690798
2019-11-08 01:13:17,042 train 300 1.674477e-02 -0.673369
2019-11-08 01:13:26,836 train 350 1.681709e-02 -0.662105
2019-11-08 01:13:36,636 train 400 1.681161e-02 -0.649821
2019-11-08 01:13:46,429 train 450 1.680520e-02 -0.661859
2019-11-08 01:13:56,249 train 500 1.676869e-02 -0.689265
2019-11-08 01:14:06,054 train 550 1.677116e-02 -0.757275
2019-11-08 01:14:15,867 train 600 1.676516e-02 -0.735501
2019-11-08 01:14:25,682 train 650 1.677206e-02 -0.736619
2019-11-08 01:14:35,493 train 700 1.678158e-02 -0.725052
2019-11-08 01:14:45,313 train 750 1.679688e-02 -0.708553
2019-11-08 01:14:55,120 train 800 1.678626e-02 -0.705284
2019-11-08 01:15:04,941 train 850 1.679696e-02 -0.706040
2019-11-08 01:15:07,879 training loss; R2: 1.679754e-02 -0.703871
2019-11-08 01:15:08,461 valid 000 1.589156e-02 -3.039424
2019-11-08 01:15:17,938 valid 050 1.822884e-02 -1.809993
2019-11-08 01:15:26,313 validation loss; R2: 1.785953e-02 -1.576081
2019-11-08 01:15:26,378 epoch 751 lr 1.000000e-05
2019-11-08 01:15:27,125 train 000 1.592668e-02 -0.044078
2019-11-08 01:15:36,901 train 050 1.693674e-02 -0.751310
2019-11-08 01:15:46,697 train 100 1.670599e-02 -0.672093
2019-11-08 01:15:56,543 train 150 1.691315e-02 -0.700251
2019-11-08 01:16:06,388 train 200 1.691862e-02 -0.726210
2019-11-08 01:16:16,207 train 250 1.689915e-02 -0.775963
2019-11-08 01:16:26,057 train 300 1.692158e-02 -0.776758
2019-11-08 01:16:35,934 train 350 1.685011e-02 -1.030703
2019-11-08 01:16:45,791 train 400 1.680721e-02 -0.997943
2019-11-08 01:16:55,653 train 450 1.681307e-02 -0.957807
2019-11-08 01:17:05,525 train 500 1.680196e-02 -0.958795
2019-11-08 01:17:15,387 train 550 1.680395e-02 -0.984081
2019-11-08 01:17:25,277 train 600 1.684682e-02 -0.936477
2019-11-08 01:17:35,146 train 650 1.681636e-02 -0.921702
2019-11-08 01:17:45,030 train 700 1.682559e-02 -0.915974
2019-11-08 01:17:54,900 train 750 1.684577e-02 -0.916804
2019-11-08 01:18:04,767 train 800 1.684756e-02 -0.890655
2019-11-08 01:18:14,633 train 850 1.685180e-02 -0.875891
2019-11-08 01:18:17,618 training loss; R2: 1.685949e-02 -0.869341
2019-11-08 01:18:18,293 valid 000 4.065677e-02 -0.792839
2019-11-08 01:18:27,730 valid 050 3.521380e-02 -11.990487
2019-11-08 01:18:36,071 validation loss; R2: 3.516990e-02 -8.617242
2019-11-08 01:18:36,147 epoch 752 lr 1.000000e-05
2019-11-08 01:18:36,898 train 000 1.989519e-02 0.075181
2019-11-08 01:18:46,654 train 050 1.700601e-02 -3.696531
2019-11-08 01:18:56,441 train 100 1.688835e-02 -2.191522
2019-11-08 01:19:06,257 train 150 1.686529e-02 -1.663636
2019-11-08 01:19:16,065 train 200 1.692648e-02 -1.516608
2019-11-08 01:19:25,877 train 250 1.689847e-02 -1.335392
2019-11-08 01:19:35,688 train 300 1.685745e-02 -1.266143
2019-11-08 01:19:45,511 train 350 1.680029e-02 -1.194563
2019-11-08 01:19:55,323 train 400 1.681589e-02 -1.159931
2019-11-08 01:20:05,131 train 450 1.684775e-02 -1.115034
2019-11-08 01:20:14,950 train 500 1.686723e-02 -1.064686
2019-11-08 01:20:24,763 train 550 1.687588e-02 -1.023008
2019-11-08 01:20:34,574 train 600 1.684954e-02 -1.004491
2019-11-08 01:20:44,390 train 650 1.680492e-02 -41.471571
2019-11-08 01:20:54,210 train 700 1.679405e-02 -38.567590
2019-11-08 01:21:04,036 train 750 1.679794e-02 -36.056332
2019-11-08 01:21:13,853 train 800 1.677242e-02 -33.844900
2019-11-08 01:21:23,662 train 850 1.676143e-02 -31.893202
2019-11-08 01:21:26,597 training loss; R2: 1.676685e-02 -31.353713
2019-11-08 01:21:27,233 valid 000 1.828860e-02 -5.006680
2019-11-08 01:21:36,651 valid 050 1.713080e-02 -1.852364
2019-11-08 01:21:45,097 validation loss; R2: 1.724477e-02 -1.730631
2019-11-08 01:21:45,163 epoch 753 lr 1.000000e-05
2019-11-08 01:21:45,966 train 000 1.576945e-02 -0.787965
2019-11-08 01:21:55,719 train 050 1.674957e-02 -0.632005
2019-11-08 01:22:05,501 train 100 1.673573e-02 -0.724740
2019-11-08 01:22:15,300 train 150 1.676839e-02 -0.771839
2019-11-08 01:22:25,114 train 200 1.681949e-02 -0.808422
2019-11-08 01:22:34,912 train 250 1.679504e-02 -0.832250
2019-11-08 01:22:44,708 train 300 1.678528e-02 -0.877444
2019-11-08 01:22:54,489 train 350 1.678054e-02 -0.850458
2019-11-08 01:23:04,239 train 400 1.679288e-02 -0.838389
2019-11-08 01:23:13,997 train 450 1.682431e-02 -0.810170
2019-11-08 01:23:23,787 train 500 1.685459e-02 -0.797469
2019-11-08 01:23:33,602 train 550 1.683135e-02 -0.785285
2019-11-08 01:23:43,393 train 600 1.683727e-02 -0.774616
2019-11-08 01:23:53,204 train 650 1.679161e-02 -0.800943
2019-11-08 01:24:03,028 train 700 1.682497e-02 -0.811073
2019-11-08 01:24:12,829 train 750 1.681577e-02 -0.826157
2019-11-08 01:24:22,618 train 800 1.681936e-02 -0.817526
2019-11-08 01:24:32,409 train 850 1.680800e-02 -0.804792
2019-11-08 01:24:35,344 training loss; R2: 1.681665e-02 -0.799419
2019-11-08 01:24:35,975 valid 000 2.994231e-02 -0.969228
2019-11-08 01:24:45,430 valid 050 3.357040e-02 -3.196397
2019-11-08 01:24:53,724 validation loss; R2: 3.354306e-02 -3.363400
2019-11-08 01:24:53,790 epoch 754 lr 1.000000e-05
2019-11-08 01:24:54,555 train 000 1.768498e-02 -0.984785
2019-11-08 01:25:04,303 train 050 1.696316e-02 -0.771259
2019-11-08 01:25:14,032 train 100 1.686833e-02 -1.851612
2019-11-08 01:25:23,766 train 150 1.681174e-02 -1.498988
2019-11-08 01:25:33,505 train 200 1.680846e-02 -1.757200
2019-11-08 01:25:43,243 train 250 1.680758e-02 -1.509831
2019-11-08 01:25:52,988 train 300 1.679403e-02 -1.410348
2019-11-08 01:26:02,735 train 350 1.676400e-02 -1.322606
2019-11-08 01:26:12,485 train 400 1.677385e-02 -1.261213
2019-11-08 01:26:22,221 train 450 1.676266e-02 -1.223744
2019-11-08 01:26:31,974 train 500 1.674375e-02 -1.153663
2019-11-08 01:26:41,724 train 550 1.671417e-02 -1.104848
2019-11-08 01:26:51,469 train 600 1.672357e-02 -1.093453
2019-11-08 01:27:01,214 train 650 1.672989e-02 -1.070782
2019-11-08 01:27:10,960 train 700 1.673847e-02 -1.035610
2019-11-08 01:27:20,723 train 750 1.675410e-02 -1.004224
2019-11-08 01:27:30,479 train 800 1.676934e-02 -0.984189
2019-11-08 01:27:40,239 train 850 1.677046e-02 -0.965826
2019-11-08 01:27:43,191 training loss; R2: 1.677316e-02 -0.959144
2019-11-08 01:27:43,837 valid 000 1.164355e-02 -0.674333
2019-11-08 01:27:53,231 valid 050 1.619309e-02 -1.205585
2019-11-08 01:28:01,683 validation loss; R2: 1.602996e-02 -1.295928
2019-11-08 01:28:01,765 epoch 755 lr 1.000000e-05
2019-11-08 01:28:02,567 train 000 1.419824e-02 -1.122083
2019-11-08 01:28:12,693 train 050 1.686913e-02 -0.679644
2019-11-08 01:28:22,829 train 100 1.674088e-02 -0.734533
2019-11-08 01:28:32,988 train 150 1.668757e-02 -0.767606
2019-11-08 01:28:43,121 train 200 1.678841e-02 -0.784715
2019-11-08 01:28:53,263 train 250 1.685304e-02 -0.861131
2019-11-08 01:29:03,402 train 300 1.689349e-02 -0.802149
2019-11-08 01:29:13,556 train 350 1.681132e-02 -0.781731
2019-11-08 01:29:23,713 train 400 1.679472e-02 -0.747390
2019-11-08 01:29:33,852 train 450 1.677091e-02 -0.791043
2019-11-08 01:29:43,979 train 500 1.681624e-02 -0.787050
2019-11-08 01:29:54,114 train 550 1.683513e-02 -0.781223
2019-11-08 01:30:04,240 train 600 1.681840e-02 -0.785244
2019-11-08 01:30:14,375 train 650 1.682283e-02 -16.970269
2019-11-08 01:30:24,524 train 700 1.682825e-02 -15.798163
2019-11-08 01:30:34,666 train 750 1.681819e-02 -14.821138
2019-11-08 01:30:44,832 train 800 1.687184e-02 -13.938474
2019-11-08 01:30:54,999 train 850 1.688242e-02 -13.147480
2019-11-08 01:30:58,024 training loss; R2: 1.689429e-02 -12.927428
2019-11-08 01:30:58,656 valid 000 1.375782e-02 -0.284947
2019-11-08 01:31:08,073 valid 050 1.401238e-02 -0.796634
2019-11-08 01:31:16,438 validation loss; R2: 1.376095e-02 -0.984895
2019-11-08 01:31:16,507 epoch 756 lr 1.000000e-05
2019-11-08 01:31:17,310 train 000 1.738210e-02 -0.265566
2019-11-08 01:31:27,401 train 050 1.718661e-02 -0.766723
2019-11-08 01:31:37,512 train 100 1.692450e-02 -0.657698
2019-11-08 01:31:47,637 train 150 1.695270e-02 -0.666688
2019-11-08 01:31:57,768 train 200 1.699373e-02 -0.678156
2019-11-08 01:32:07,902 train 250 1.692607e-02 -0.660157
2019-11-08 01:32:18,039 train 300 1.692723e-02 -0.677268
2019-11-08 01:32:28,177 train 350 1.688517e-02 -0.675170
2019-11-08 01:32:38,330 train 400 1.684429e-02 -0.656737
2019-11-08 01:32:48,092 train 450 1.683196e-02 -0.662141
2019-11-08 01:32:57,861 train 500 1.687725e-02 -0.680476
2019-11-08 01:33:07,636 train 550 1.685125e-02 -0.663559
2019-11-08 01:33:17,406 train 600 1.685340e-02 -0.670444
2019-11-08 01:33:27,173 train 650 1.688013e-02 -0.673671
2019-11-08 01:33:36,948 train 700 1.685702e-02 -0.681835
2019-11-08 01:33:46,717 train 750 1.686071e-02 -0.679212
2019-11-08 01:33:56,480 train 800 1.684592e-02 -0.696754
2019-11-08 01:34:06,266 train 850 1.685923e-02 -0.683973
2019-11-08 01:34:09,191 training loss; R2: 1.686060e-02 -0.687655
2019-11-08 01:34:09,833 valid 000 1.563279e-02 -0.588494
2019-11-08 01:34:19,291 valid 050 1.539728e-02 -1.037757
2019-11-08 01:34:27,658 validation loss; R2: 1.531452e-02 -1.089831
2019-11-08 01:34:27,723 epoch 757 lr 1.000000e-05
2019-11-08 01:34:28,440 train 000 1.358987e-02 -0.077468
2019-11-08 01:34:38,202 train 050 1.681340e-02 -0.883030
2019-11-08 01:34:47,967 train 100 1.705549e-02 -0.707542
2019-11-08 01:34:57,722 train 150 1.694883e-02 -0.731162
2019-11-08 01:35:07,502 train 200 1.687025e-02 -0.692052
2019-11-08 01:35:17,307 train 250 1.685653e-02 -0.679189
2019-11-08 01:35:27,052 train 300 1.676957e-02 -0.674110
2019-11-08 01:35:36,802 train 350 1.679303e-02 -0.675211
2019-11-08 01:35:46,549 train 400 1.675856e-02 -0.697480
2019-11-08 01:35:56,297 train 450 1.677121e-02 -0.684399
2019-11-08 01:36:06,041 train 500 1.680811e-02 -0.721853
2019-11-08 01:36:15,789 train 550 1.676129e-02 -0.721009
2019-11-08 01:36:25,540 train 600 1.677790e-02 -0.719347
2019-11-08 01:36:35,292 train 650 1.676075e-02 -0.703323
2019-11-08 01:36:45,059 train 700 1.676935e-02 -0.688712
2019-11-08 01:36:54,820 train 750 1.676913e-02 -0.689009
2019-11-08 01:37:04,593 train 800 1.682149e-02 -0.685079
2019-11-08 01:37:14,366 train 850 1.682503e-02 -0.698322
2019-11-08 01:37:17,281 training loss; R2: 1.681541e-02 -0.699138
2019-11-08 01:37:17,895 valid 000 2.038513e-02 -0.864759
2019-11-08 01:37:27,320 valid 050 1.670797e-02 -1.348389
2019-11-08 01:37:35,661 validation loss; R2: 1.688078e-02 -1.407136
2019-11-08 01:37:35,725 epoch 758 lr 1.000000e-05
2019-11-08 01:37:36,482 train 000 1.963924e-02 -0.084102
2019-11-08 01:37:46,178 train 050 1.673307e-02 -0.700155
2019-11-08 01:37:55,913 train 100 1.702696e-02 -0.879899
2019-11-08 01:38:05,649 train 150 1.707762e-02 -0.780628
2019-11-08 01:38:15,385 train 200 1.694374e-02 -1.154965
2019-11-08 01:38:25,114 train 250 1.689068e-02 -1.062894
2019-11-08 01:38:34,851 train 300 1.694550e-02 -0.988134
2019-11-08 01:38:44,589 train 350 1.689732e-02 -0.917940
2019-11-08 01:38:54,344 train 400 1.688955e-02 -0.880061
2019-11-08 01:39:04,090 train 450 1.685139e-02 -0.845634
2019-11-08 01:39:13,856 train 500 1.683624e-02 -0.809573
2019-11-08 01:39:23,609 train 550 1.683590e-02 -0.800915
2019-11-08 01:39:33,364 train 600 1.681527e-02 -0.801455
2019-11-08 01:39:43,107 train 650 1.681663e-02 -0.778205
2019-11-08 01:39:52,875 train 700 1.679013e-02 -0.782563
2019-11-08 01:40:02,655 train 750 1.678055e-02 -0.783897
2019-11-08 01:40:12,426 train 800 1.676177e-02 -0.769324
2019-11-08 01:40:22,205 train 850 1.677300e-02 -0.759837
2019-11-08 01:40:25,132 training loss; R2: 1.677916e-02 -0.755239
2019-11-08 01:40:25,839 valid 000 1.649641e-02 -0.044671
2019-11-08 01:40:35,197 valid 050 1.761480e-02 -0.516860
2019-11-08 01:40:43,522 validation loss; R2: 1.735454e-02 -0.890698
2019-11-08 01:40:43,586 epoch 759 lr 1.000000e-05
2019-11-08 01:40:44,340 train 000 1.532553e-02 0.105409
2019-11-08 01:40:54,072 train 050 1.676523e-02 -0.955707
2019-11-08 01:41:03,817 train 100 1.688152e-02 -0.879411
2019-11-08 01:41:13,571 train 150 1.690387e-02 -0.752726
2019-11-08 01:41:23,309 train 200 1.683527e-02 -0.744874
2019-11-08 01:41:33,052 train 250 1.684068e-02 -0.743407
2019-11-08 01:41:42,799 train 300 1.686330e-02 -0.702810
2019-11-08 01:41:52,560 train 350 1.690102e-02 -0.685186
2019-11-08 01:42:02,349 train 400 1.691041e-02 -0.703756
2019-11-08 01:42:12,104 train 450 1.691507e-02 -0.705154
2019-11-08 01:42:21,855 train 500 1.691320e-02 -0.712265
2019-11-08 01:42:31,627 train 550 1.689543e-02 -0.735624
2019-11-08 01:42:41,378 train 600 1.688110e-02 -0.740621
2019-11-08 01:42:51,154 train 650 1.688554e-02 -0.785552
2019-11-08 01:43:00,932 train 700 1.686199e-02 -0.956193
2019-11-08 01:43:10,705 train 750 1.685519e-02 -0.933146
2019-11-08 01:43:20,486 train 800 1.681471e-02 -0.917770
2019-11-08 01:43:30,257 train 850 1.681251e-02 -0.907050
2019-11-08 01:43:33,218 training loss; R2: 1.681460e-02 -0.903459
2019-11-08 01:43:33,819 valid 000 1.856410e-02 -1.545195
2019-11-08 01:43:43,284 valid 050 2.102145e-02 -2.724037
2019-11-08 01:43:51,633 validation loss; R2: 2.101284e-02 -2.478290
2019-11-08 01:43:51,721 epoch 760 lr 1.000000e-05
2019-11-08 01:43:52,511 train 000 1.610402e-02 0.096021
2019-11-08 01:44:02,229 train 050 1.674214e-02 -0.456198
2019-11-08 01:44:11,930 train 100 1.694204e-02 -0.574054
2019-11-08 01:44:21,666 train 150 1.689497e-02 -0.613804
2019-11-08 01:44:31,404 train 200 1.688093e-02 -0.622928
2019-11-08 01:44:41,187 train 250 1.688175e-02 -0.645910
2019-11-08 01:44:51,180 train 300 1.684837e-02 -0.717430
2019-11-08 01:45:01,332 train 350 1.685500e-02 -0.716336
2019-11-08 01:45:11,492 train 400 1.680539e-02 -0.800231
2019-11-08 01:45:21,635 train 450 1.681065e-02 -0.796507
2019-11-08 01:45:31,761 train 500 1.679523e-02 -0.758466
2019-11-08 01:45:41,929 train 550 1.681039e-02 -0.760131
2019-11-08 01:45:52,092 train 600 1.680720e-02 -0.744196
2019-11-08 01:46:02,244 train 650 1.683257e-02 -0.753881
2019-11-08 01:46:12,391 train 700 1.682039e-02 -0.761640
2019-11-08 01:46:22,540 train 750 1.683183e-02 -0.746911
2019-11-08 01:46:32,680 train 800 1.681076e-02 -0.738866
2019-11-08 01:46:42,813 train 850 1.681806e-02 -0.746508
2019-11-08 01:46:45,842 training loss; R2: 1.681562e-02 -0.752757
2019-11-08 01:46:46,528 valid 000 1.676467e-02 -0.423287
2019-11-08 01:46:55,927 valid 050 1.898210e-02 -1.932397
2019-11-08 01:47:04,287 validation loss; R2: 1.890942e-02 -1.962935
2019-11-08 01:47:04,354 epoch 761 lr 1.000000e-05
2019-11-08 01:47:05,115 train 000 1.611364e-02 -0.640693
2019-11-08 01:47:14,883 train 050 1.673170e-02 -1.015334
2019-11-08 01:47:24,697 train 100 1.660615e-02 -2.407457
2019-11-08 01:47:34,502 train 150 1.665921e-02 -1.833353
2019-11-08 01:47:44,321 train 200 1.674251e-02 -1.545041
2019-11-08 01:47:54,143 train 250 1.675943e-02 -1.370225
2019-11-08 01:48:03,954 train 300 1.676789e-02 -1.231503
2019-11-08 01:48:13,770 train 350 1.673452e-02 -1.181466
2019-11-08 01:48:23,582 train 400 1.674833e-02 -1.163761
2019-11-08 01:48:33,407 train 450 1.685167e-02 -1.126611
2019-11-08 01:48:43,202 train 500 1.685588e-02 -1.067379
2019-11-08 01:48:53,028 train 550 1.684751e-02 -1.047994
2019-11-08 01:49:02,853 train 600 1.683537e-02 -1.015455
2019-11-08 01:49:12,680 train 650 1.685058e-02 -0.993432
2019-11-08 01:49:22,506 train 700 1.683816e-02 -0.965504
2019-11-08 01:49:32,360 train 750 1.683119e-02 -0.951918
2019-11-08 01:49:42,221 train 800 1.682021e-02 -0.944697
2019-11-08 01:49:52,085 train 850 1.681919e-02 -0.930447
2019-11-08 01:49:55,027 training loss; R2: 1.681097e-02 -0.926550
2019-11-08 01:49:55,702 valid 000 3.000313e-02 -9.629054
2019-11-08 01:50:05,092 valid 050 3.281360e-02 -3.681100
2019-11-08 01:50:13,424 validation loss; R2: 3.299560e-02 -3.962605
2019-11-08 01:50:13,489 epoch 762 lr 1.000000e-05
2019-11-08 01:50:14,256 train 000 1.432901e-02 -0.668708
2019-11-08 01:50:24,059 train 050 1.683231e-02 -0.707872
2019-11-08 01:50:33,864 train 100 1.682452e-02 -0.701316
2019-11-08 01:50:43,688 train 150 1.680245e-02 -0.756148
2019-11-08 01:50:53,510 train 200 1.673495e-02 -0.691789
2019-11-08 01:51:03,311 train 250 1.676548e-02 -0.713891
2019-11-08 01:51:13,113 train 300 1.669553e-02 -0.722020
2019-11-08 01:51:22,921 train 350 1.674707e-02 -0.719847
2019-11-08 01:51:32,725 train 400 1.674449e-02 -0.707413
2019-11-08 01:51:42,526 train 450 1.672531e-02 -0.686620
2019-11-08 01:51:52,346 train 500 1.674247e-02 -0.674446
2019-11-08 01:52:02,150 train 550 1.672280e-02 -0.690361
2019-11-08 01:52:11,965 train 600 1.673838e-02 -0.691327
2019-11-08 01:52:21,774 train 650 1.673362e-02 -0.742953
2019-11-08 01:52:31,578 train 700 1.675061e-02 -0.739550
2019-11-08 01:52:41,391 train 750 1.674805e-02 -0.729408
2019-11-08 01:52:51,200 train 800 1.673869e-02 -0.717583
2019-11-08 01:53:01,014 train 850 1.675743e-02 -0.709634
2019-11-08 01:53:03,949 training loss; R2: 1.675321e-02 -0.726872
2019-11-08 01:53:04,669 valid 000 2.409139e-02 -0.229798
2019-11-08 01:53:14,043 valid 050 2.477838e-02 -3.235098
2019-11-08 01:53:22,375 validation loss; R2: 2.478944e-02 -3.389132
2019-11-08 01:53:22,450 epoch 763 lr 1.000000e-05
2019-11-08 01:53:23,206 train 000 1.749153e-02 0.001835
2019-11-08 01:53:32,983 train 050 1.692167e-02 -0.519121
2019-11-08 01:53:42,783 train 100 1.688675e-02 -0.646688
2019-11-08 01:53:52,584 train 150 1.692609e-02 -0.624897
2019-11-08 01:54:02,382 train 200 1.685339e-02 -0.654999
2019-11-08 01:54:12,203 train 250 1.678588e-02 -0.681327
2019-11-08 01:54:22,005 train 300 1.678385e-02 -0.707609
2019-11-08 01:54:31,808 train 350 1.676275e-02 -1.006070
2019-11-08 01:54:41,619 train 400 1.678209e-02 -0.973868
2019-11-08 01:54:51,440 train 450 1.677827e-02 -0.921888
2019-11-08 01:55:01,233 train 500 1.675905e-02 -0.884956
2019-11-08 01:55:11,024 train 550 1.675544e-02 -0.865149
2019-11-08 01:55:20,838 train 600 1.675931e-02 -1.533860
2019-11-08 01:55:30,641 train 650 1.676181e-02 -1.468794
2019-11-08 01:55:40,438 train 700 1.677470e-02 -1.410644
2019-11-08 01:55:50,251 train 750 1.676684e-02 -1.359353
2019-11-08 01:56:00,068 train 800 1.676531e-02 -1.775826
2019-11-08 01:56:09,880 train 850 1.678282e-02 -1.715809
2019-11-08 01:56:12,814 training loss; R2: 1.679098e-02 -1.709604
2019-11-08 01:56:13,458 valid 000 1.356254e-02 -0.895450
2019-11-08 01:56:22,903 valid 050 1.479928e-02 -1.980625
2019-11-08 01:56:31,210 validation loss; R2: 1.512878e-02 -1.519922
2019-11-08 01:56:31,275 epoch 764 lr 1.000000e-05
2019-11-08 01:56:32,013 train 000 1.525230e-02 -2.349314
2019-11-08 01:56:41,802 train 050 1.686987e-02 -0.666803
2019-11-08 01:56:51,619 train 100 1.674370e-02 -0.622231
2019-11-08 01:57:01,429 train 150 1.700054e-02 -63.031223
2019-11-08 01:57:11,243 train 200 1.685145e-02 -47.600801
2019-11-08 01:57:21,057 train 250 1.680953e-02 -38.270059
2019-11-08 01:57:30,876 train 300 1.682049e-02 -32.035603
2019-11-08 01:57:40,693 train 350 1.679798e-02 -27.549783
2019-11-08 01:57:50,526 train 400 1.684117e-02 -24.202414
2019-11-08 01:58:00,357 train 450 1.686254e-02 -21.559967
2019-11-08 01:58:10,187 train 500 1.691184e-02 -19.486336
2019-11-08 01:58:20,043 train 550 1.690272e-02 -17.778614
2019-11-08 01:58:29,879 train 600 1.689273e-02 -16.363320
2019-11-08 01:58:39,723 train 650 1.686453e-02 -15.155862
2019-11-08 01:58:49,560 train 700 1.685718e-02 -14.114113
2019-11-08 01:58:59,388 train 750 1.684874e-02 -13.217112
2019-11-08 01:59:09,227 train 800 1.683060e-02 -12.425798
2019-11-08 01:59:19,051 train 850 1.682571e-02 -11.751333
2019-11-08 01:59:22,024 training loss; R2: 1.681652e-02 -11.558902
2019-11-08 01:59:22,680 valid 000 1.457123e-02 -0.126344
2019-11-08 01:59:32,127 valid 050 1.562531e-02 -1.101677
2019-11-08 01:59:40,427 validation loss; R2: 1.559709e-02 -1.258231
2019-11-08 01:59:40,499 epoch 765 lr 1.000000e-05
2019-11-08 01:59:41,290 train 000 1.392462e-02 -0.178459
2019-11-08 01:59:51,420 train 050 1.646502e-02 -0.593612
2019-11-08 02:00:01,582 train 100 1.662561e-02 -0.631711
2019-11-08 02:00:11,391 train 150 1.666012e-02 -0.664361
2019-11-08 02:00:21,207 train 200 1.667625e-02 -0.706334
2019-11-08 02:00:31,014 train 250 1.674487e-02 -0.697741
2019-11-08 02:00:40,819 train 300 1.671558e-02 -0.711483
2019-11-08 02:00:50,624 train 350 1.669898e-02 -0.677614
2019-11-08 02:01:00,463 train 400 1.671745e-02 -0.651811
2019-11-08 02:01:10,275 train 450 1.674047e-02 -0.655223
2019-11-08 02:01:20,091 train 500 1.674063e-02 -0.641595
2019-11-08 02:01:29,913 train 550 1.673115e-02 -0.686033
2019-11-08 02:01:39,717 train 600 1.677544e-02 -0.675551
2019-11-08 02:01:49,515 train 650 1.680764e-02 -0.693789
2019-11-08 02:01:59,327 train 700 1.680305e-02 -0.684417
2019-11-08 02:02:09,165 train 750 1.680202e-02 -0.685273
2019-11-08 02:02:18,986 train 800 1.681997e-02 -0.688761
2019-11-08 02:02:28,824 train 850 1.682526e-02 -0.714201
2019-11-08 02:02:31,764 training loss; R2: 1.682589e-02 -0.710439
2019-11-08 02:02:32,446 valid 000 1.486042e-02 -1.087373
2019-11-08 02:02:41,907 valid 050 1.630012e-02 -0.880546
2019-11-08 02:02:50,287 validation loss; R2: 1.621354e-02 -0.902218
2019-11-08 02:02:50,357 epoch 766 lr 1.000000e-05
2019-11-08 02:02:51,104 train 000 1.566449e-02 -0.549060
2019-11-08 02:03:00,861 train 050 1.709658e-02 -0.616112
2019-11-08 02:03:10,648 train 100 1.701044e-02 -0.576484
2019-11-08 02:03:20,448 train 150 1.697265e-02 -0.636112
2019-11-08 02:03:30,261 train 200 1.690301e-02 -0.704106
2019-11-08 02:03:40,074 train 250 1.689082e-02 -0.692088
2019-11-08 02:03:49,852 train 300 1.686637e-02 -0.900720
2019-11-08 02:03:59,645 train 350 1.682268e-02 -0.893608
2019-11-08 02:04:09,425 train 400 1.675970e-02 -0.870056
2019-11-08 02:04:19,215 train 450 1.679055e-02 -0.859788
2019-11-08 02:04:28,990 train 500 1.681364e-02 -0.842192
2019-11-08 02:04:38,792 train 550 1.682503e-02 -0.828314
2019-11-08 02:04:48,577 train 600 1.681897e-02 -0.811533
2019-11-08 02:04:58,375 train 650 1.684750e-02 -2.243879
2019-11-08 02:05:08,173 train 700 1.683683e-02 -2.130736
2019-11-08 02:05:17,977 train 750 1.683113e-02 -2.043431
2019-11-08 02:05:27,760 train 800 1.683696e-02 -1.952455
2019-11-08 02:05:37,566 train 850 1.682024e-02 -1.883469
2019-11-08 02:05:40,531 training loss; R2: 1.683871e-02 -1.862499
2019-11-08 02:05:41,204 valid 000 1.658163e-02 -1.775081
2019-11-08 02:05:50,596 valid 050 1.593180e-02 -0.915907
2019-11-08 02:05:58,901 validation loss; R2: 1.584849e-02 -0.967285
2019-11-08 02:05:58,975 epoch 767 lr 1.000000e-05
2019-11-08 02:05:59,752 train 000 1.831097e-02 -0.243769
2019-11-08 02:06:09,869 train 050 1.673463e-02 -1.458816
2019-11-08 02:06:19,975 train 100 1.679211e-02 -18.868498
2019-11-08 02:06:30,110 train 150 1.670174e-02 -12.749847
2019-11-08 02:06:40,265 train 200 1.687113e-02 -9.978611
2019-11-08 02:06:50,424 train 250 1.684181e-02 -8.180032
2019-11-08 02:07:00,569 train 300 1.687665e-02 -6.913280
2019-11-08 02:07:10,718 train 350 1.685444e-02 -6.054614
2019-11-08 02:07:20,883 train 400 1.684246e-02 -5.388530
2019-11-08 02:07:31,028 train 450 1.683453e-02 -4.880084
2019-11-08 02:07:41,179 train 500 1.683785e-02 -4.482711
2019-11-08 02:07:51,330 train 550 1.686756e-02 -4.128192
2019-11-08 02:08:01,476 train 600 1.686827e-02 -3.842109
2019-11-08 02:08:11,630 train 650 1.686692e-02 -3.590510
2019-11-08 02:08:21,773 train 700 1.684205e-02 -3.381332
2019-11-08 02:08:31,922 train 750 1.683731e-02 -3.240311
2019-11-08 02:08:42,061 train 800 1.683603e-02 -3.114813
2019-11-08 02:08:52,199 train 850 1.680231e-02 -3.012642
2019-11-08 02:08:55,234 training loss; R2: 1.680573e-02 -2.976670
2019-11-08 02:08:55,934 valid 000 2.112619e-02 -11.786874
2019-11-08 02:09:05,303 valid 050 2.427424e-02 -2.488034
2019-11-08 02:09:13,712 validation loss; R2: 2.443216e-02 -2.663448
2019-11-08 02:09:13,780 epoch 768 lr 1.000000e-05
2019-11-08 02:09:14,585 train 000 1.534448e-02 -0.645281
2019-11-08 02:09:24,694 train 050 1.619013e-02 -0.648321
2019-11-08 02:09:34,803 train 100 1.663217e-02 -0.886743
2019-11-08 02:09:44,936 train 150 1.661103e-02 -0.834598
2019-11-08 02:09:55,039 train 200 1.670960e-02 -0.808769
2019-11-08 02:10:05,139 train 250 1.678473e-02 -0.827675
2019-11-08 02:10:15,271 train 300 1.685486e-02 -0.843837
2019-11-08 02:10:25,411 train 350 1.686300e-02 -0.836452
2019-11-08 02:10:35,531 train 400 1.682302e-02 -0.838408
2019-11-08 02:10:45,606 train 450 1.688351e-02 -0.851816
2019-11-08 02:10:55,350 train 500 1.688648e-02 -0.848207
2019-11-08 02:11:05,110 train 550 1.688393e-02 -0.835660
2019-11-08 02:11:14,876 train 600 1.686861e-02 -0.807888
2019-11-08 02:11:24,638 train 650 1.688802e-02 -0.815124
2019-11-08 02:11:34,412 train 700 1.687994e-02 -0.805851
2019-11-08 02:11:44,190 train 750 1.685116e-02 -0.801771
2019-11-08 02:11:53,958 train 800 1.685267e-02 -0.792734
2019-11-08 02:12:03,726 train 850 1.682903e-02 -0.789070
2019-11-08 02:12:06,652 training loss; R2: 1.683441e-02 -0.783726
2019-11-08 02:12:07,320 valid 000 4.300785e-02 -3.918593
2019-11-08 02:12:16,697 valid 050 3.746445e-02 -4.885673
2019-11-08 02:12:25,171 validation loss; R2: 3.787495e-02 -4.274454
2019-11-08 02:12:25,233 epoch 769 lr 1.000000e-05
2019-11-08 02:12:25,979 train 000 1.569516e-02 0.011639
2019-11-08 02:12:35,711 train 050 1.671768e-02 -0.614765
2019-11-08 02:12:45,454 train 100 1.690521e-02 -0.663925
2019-11-08 02:12:55,194 train 150 1.696892e-02 -0.647163
2019-11-08 02:13:04,982 train 200 1.688185e-02 -0.674561
2019-11-08 02:13:14,774 train 250 1.683180e-02 -0.686635
2019-11-08 02:13:24,546 train 300 1.684139e-02 -0.712029
2019-11-08 02:13:34,328 train 350 1.687698e-02 -0.729976
2019-11-08 02:13:44,096 train 400 1.687475e-02 -0.852845
2019-11-08 02:13:53,872 train 450 1.686384e-02 -0.855474
2019-11-08 02:14:03,642 train 500 1.687043e-02 -0.840553
2019-11-08 02:14:13,419 train 550 1.687824e-02 -0.857315
2019-11-08 02:14:23,197 train 600 1.685852e-02 -0.834655
2019-11-08 02:14:32,973 train 650 1.686191e-02 -0.811766
2019-11-08 02:14:42,745 train 700 1.686228e-02 -0.815110
2019-11-08 02:14:52,531 train 750 1.684876e-02 -0.819287
2019-11-08 02:15:02,319 train 800 1.684479e-02 -0.841945
2019-11-08 02:15:12,094 train 850 1.684007e-02 -0.953613
2019-11-08 02:15:15,058 training loss; R2: 1.683381e-02 -0.945823
2019-11-08 02:15:15,757 valid 000 1.572961e-02 -6.182461
2019-11-08 02:15:25,190 valid 050 1.535082e-02 -0.900133
2019-11-08 02:15:33,508 validation loss; R2: 1.525371e-02 -0.886259
2019-11-08 02:15:33,592 epoch 770 lr 1.000000e-05
2019-11-08 02:15:34,396 train 000 1.476991e-02 -1.263307
2019-11-08 02:15:44,539 train 050 1.664679e-02 -0.665259
2019-11-08 02:15:54,676 train 100 1.672333e-02 -0.644006
2019-11-08 02:16:04,821 train 150 1.674930e-02 -0.696725
2019-11-08 02:16:14,989 train 200 1.680316e-02 -0.714089
2019-11-08 02:16:25,159 train 250 1.687649e-02 -7.950052
2019-11-08 02:16:35,329 train 300 1.686911e-02 -6.732392
2019-11-08 02:16:45,505 train 350 1.682322e-02 -5.849697
2019-11-08 02:16:55,673 train 400 1.682227e-02 -5.201805
2019-11-08 02:17:05,825 train 450 1.679999e-02 -4.692391
2019-11-08 02:17:15,973 train 500 1.683929e-02 -4.302461
2019-11-08 02:17:26,123 train 550 1.683244e-02 -3.973648
2019-11-08 02:17:36,265 train 600 1.681382e-02 -3.722941
2019-11-08 02:17:46,417 train 650 1.683945e-02 -3.764481
2019-11-08 02:17:56,572 train 700 1.681985e-02 -3.554583
2019-11-08 02:18:06,731 train 750 1.683968e-02 -3.370915
2019-11-08 02:18:16,901 train 800 1.683963e-02 -3.192662
2019-11-08 02:18:27,043 train 850 1.684397e-02 -3.048368
2019-11-08 02:18:30,071 training loss; R2: 1.683530e-02 -3.006519
2019-11-08 02:18:30,756 valid 000 1.498221e-02 -2.769050
2019-11-08 02:18:40,151 valid 050 1.591108e-02 -1.236427
2019-11-08 02:18:48,473 validation loss; R2: 1.605817e-02 -1.152549
2019-11-08 02:18:48,540 epoch 771 lr 1.000000e-05
2019-11-08 02:18:49,326 train 000 1.617816e-02 -0.089889
2019-11-08 02:18:59,451 train 050 1.695991e-02 -0.582942
2019-11-08 02:19:09,595 train 100 1.682345e-02 -0.634027
2019-11-08 02:19:19,752 train 150 1.659681e-02 -0.760585
2019-11-08 02:19:29,739 train 200 1.654528e-02 -0.924239
2019-11-08 02:19:39,513 train 250 1.668877e-02 -0.863487
2019-11-08 02:19:49,294 train 300 1.679530e-02 -0.812597
2019-11-08 02:19:59,080 train 350 1.674556e-02 -0.768196
2019-11-08 02:20:08,853 train 400 1.677118e-02 -0.741044
2019-11-08 02:20:18,638 train 450 1.675358e-02 -0.755655
2019-11-08 02:20:28,420 train 500 1.675200e-02 -0.729395
2019-11-08 02:20:38,196 train 550 1.676483e-02 -0.720524
2019-11-08 02:20:47,967 train 600 1.676523e-02 -0.740635
2019-11-08 02:20:57,758 train 650 1.676295e-02 -0.872767
2019-11-08 02:21:07,556 train 700 1.676063e-02 -0.877478
2019-11-08 02:21:17,346 train 750 1.675277e-02 -0.877016
2019-11-08 02:21:27,152 train 800 1.675502e-02 -0.854529
2019-11-08 02:21:36,952 train 850 1.676024e-02 -0.864106
2019-11-08 02:21:39,870 training loss; R2: 1.675774e-02 -0.861672
2019-11-08 02:21:40,466 valid 000 1.693200e-02 -0.380618
2019-11-08 02:21:49,885 valid 050 1.733025e-02 -1.991310
2019-11-08 02:21:58,203 validation loss; R2: 1.738170e-02 -1.781230
2019-11-08 02:21:58,261 epoch 772 lr 1.000000e-05
2019-11-08 02:21:59,042 train 000 1.599016e-02 -0.196873
2019-11-08 02:22:08,747 train 050 1.667323e-02 -0.554102
2019-11-08 02:22:18,503 train 100 1.675016e-02 -0.625520
2019-11-08 02:22:28,279 train 150 1.682147e-02 -0.669510
2019-11-08 02:22:38,078 train 200 1.683201e-02 -0.639025
2019-11-08 02:22:47,831 train 250 1.676879e-02 -0.611470
2019-11-08 02:22:57,607 train 300 1.682868e-02 -0.635962
2019-11-08 02:23:07,373 train 350 1.681486e-02 -0.659001
2019-11-08 02:23:17,156 train 400 1.681795e-02 -0.661618
2019-11-08 02:23:26,935 train 450 1.682290e-02 -0.679682
2019-11-08 02:23:36,708 train 500 1.684141e-02 -0.689005
2019-11-08 02:23:46,481 train 550 1.685094e-02 -0.678444
2019-11-08 02:23:56,271 train 600 1.683180e-02 -0.694509
2019-11-08 02:24:06,067 train 650 1.679469e-02 -0.773319
2019-11-08 02:24:15,843 train 700 1.678925e-02 -0.778329
2019-11-08 02:24:25,618 train 750 1.680535e-02 -0.791694
2019-11-08 02:24:35,398 train 800 1.680543e-02 -0.781950
2019-11-08 02:24:45,193 train 850 1.682573e-02 -0.781354
2019-11-08 02:24:48,119 training loss; R2: 1.683336e-02 -0.776874
2019-11-08 02:24:48,715 valid 000 1.673104e-02 -0.479897
2019-11-08 02:24:58,162 valid 050 1.476423e-02 -0.690129
2019-11-08 02:25:06,598 validation loss; R2: 1.465692e-02 -0.886221
2019-11-08 02:25:06,665 epoch 773 lr 1.000000e-05
2019-11-08 02:25:07,419 train 000 1.670591e-02 -0.586557
2019-11-08 02:25:17,142 train 050 1.649594e-02 -0.694720
2019-11-08 02:25:26,880 train 100 1.649326e-02 -0.718317
2019-11-08 02:25:36,643 train 150 1.675665e-02 -0.676661
2019-11-08 02:25:46,456 train 200 1.675879e-02 -0.680247
2019-11-08 02:25:56,220 train 250 1.673062e-02 -0.728944
2019-11-08 02:26:05,988 train 300 1.678652e-02 -0.717421
2019-11-08 02:26:15,748 train 350 1.680108e-02 -0.694182
2019-11-08 02:26:25,506 train 400 1.680503e-02 -0.686521
2019-11-08 02:26:35,269 train 450 1.679416e-02 -0.675046
2019-11-08 02:26:45,043 train 500 1.678191e-02 -0.727664
2019-11-08 02:26:54,808 train 550 1.678523e-02 -0.734268
2019-11-08 02:27:04,568 train 600 1.676928e-02 -0.732088
2019-11-08 02:27:14,349 train 650 1.677286e-02 -0.716412
2019-11-08 02:27:24,145 train 700 1.678114e-02 -0.707103
2019-11-08 02:27:33,935 train 750 1.677880e-02 -0.704226
2019-11-08 02:27:43,723 train 800 1.678314e-02 -0.702825
2019-11-08 02:27:53,524 train 850 1.679718e-02 -0.707269
2019-11-08 02:27:56,458 training loss; R2: 1.681537e-02 -0.703648
2019-11-08 02:27:57,042 valid 000 1.598196e-02 0.067481
2019-11-08 02:28:06,526 valid 050 1.644081e-02 -0.738792
2019-11-08 02:28:14,872 validation loss; R2: 1.651768e-02 -1.049057
2019-11-08 02:28:14,939 epoch 774 lr 1.000000e-05
2019-11-08 02:28:15,650 train 000 1.668488e-02 -0.783851
2019-11-08 02:28:25,394 train 050 1.705763e-02 -0.635489
2019-11-08 02:28:35,135 train 100 1.689805e-02 -0.721476
2019-11-08 02:28:44,889 train 150 1.684224e-02 -0.762291
2019-11-08 02:28:54,646 train 200 1.677582e-02 -0.720042
2019-11-08 02:29:04,423 train 250 1.674213e-02 -0.710600
2019-11-08 02:29:14,191 train 300 1.678276e-02 -0.672584
2019-11-08 02:29:23,966 train 350 1.677875e-02 -0.688836
2019-11-08 02:29:33,741 train 400 1.677981e-02 -0.713331
2019-11-08 02:29:43,512 train 450 1.675528e-02 -0.695679
2019-11-08 02:29:53,291 train 500 1.674940e-02 -0.688867
2019-11-08 02:30:03,058 train 550 1.672020e-02 -0.697867
2019-11-08 02:30:12,828 train 600 1.672315e-02 -0.694798
2019-11-08 02:30:22,613 train 650 1.670943e-02 -0.693888
2019-11-08 02:30:32,404 train 700 1.672924e-02 -0.694850
2019-11-08 02:30:42,195 train 750 1.671488e-02 -0.698056
2019-11-08 02:30:51,980 train 800 1.671223e-02 -0.700947
2019-11-08 02:31:01,761 train 850 1.672645e-02 -0.700878
2019-11-08 02:31:04,688 training loss; R2: 1.673863e-02 -0.706085
2019-11-08 02:31:05,371 valid 000 1.354448e-02 -1.237493
2019-11-08 02:31:14,736 valid 050 1.470770e-02 -0.809439
2019-11-08 02:31:23,049 validation loss; R2: 1.469921e-02 -0.838083
2019-11-08 02:31:23,115 epoch 775 lr 1.000000e-05
2019-11-08 02:31:23,827 train 000 1.536637e-02 -0.192062
2019-11-08 02:31:33,563 train 050 1.690416e-02 -0.752442
2019-11-08 02:31:43,324 train 100 1.678569e-02 -1.692983
2019-11-08 02:31:53,095 train 150 1.675852e-02 -1.387343
2019-11-08 02:32:02,866 train 200 1.675513e-02 -1.214073
2019-11-08 02:32:12,637 train 250 1.681961e-02 -1.135972
2019-11-08 02:32:22,418 train 300 1.678997e-02 -1.060056
2019-11-08 02:32:32,202 train 350 1.683511e-02 -1.019833
2019-11-08 02:32:41,987 train 400 1.676742e-02 -0.974046
2019-11-08 02:32:51,778 train 450 1.676652e-02 -0.933298
2019-11-08 02:33:01,556 train 500 1.678230e-02 -0.995772
2019-11-08 02:33:11,330 train 550 1.680743e-02 -1.046630
2019-11-08 02:33:21,093 train 600 1.680958e-02 -1.022591
2019-11-08 02:33:30,881 train 650 1.682321e-02 -1.017727
2019-11-08 02:33:40,678 train 700 1.681416e-02 -0.995999
2019-11-08 02:33:50,463 train 750 1.681901e-02 -0.994637
2019-11-08 02:34:00,249 train 800 1.681095e-02 -0.967020
2019-11-08 02:34:10,024 train 850 1.680825e-02 -0.943294
2019-11-08 02:34:12,959 training loss; R2: 1.680405e-02 -0.947763
2019-11-08 02:34:13,540 valid 000 1.356484e-02 -2.654202
2019-11-08 02:34:22,999 valid 050 1.674463e-02 -1.617329
2019-11-08 02:34:31,310 validation loss; R2: 1.653422e-02 -1.884611
2019-11-08 02:34:31,376 epoch 776 lr 1.000000e-05
2019-11-08 02:34:32,138 train 000 1.843476e-02 -0.485505
2019-11-08 02:34:41,886 train 050 1.714891e-02 -0.948037
2019-11-08 02:34:51,651 train 100 1.690117e-02 -0.755536
2019-11-08 02:35:01,426 train 150 1.703694e-02 -0.685497
2019-11-08 02:35:11,193 train 200 1.694109e-02 -0.761068
2019-11-08 02:35:20,961 train 250 1.685615e-02 -0.714595
2019-11-08 02:35:30,744 train 300 1.680785e-02 -0.712616
2019-11-08 02:35:40,526 train 350 1.685591e-02 -0.733690
2019-11-08 02:35:50,297 train 400 1.680768e-02 -0.726039
2019-11-08 02:36:00,075 train 450 1.679413e-02 -0.728823
2019-11-08 02:36:09,856 train 500 1.679235e-02 -0.726950
2019-11-08 02:36:19,626 train 550 1.678621e-02 -0.713643
2019-11-08 02:36:29,404 train 600 1.679129e-02 -0.710011
2019-11-08 02:36:39,182 train 650 1.680034e-02 -0.696497
2019-11-08 02:36:48,968 train 700 1.679213e-02 -0.702210
2019-11-08 02:36:58,748 train 750 1.678444e-02 -0.697140
2019-11-08 02:37:08,532 train 800 1.678588e-02 -0.762076
2019-11-08 02:37:18,330 train 850 1.680188e-02 -0.760176
2019-11-08 02:37:21,260 training loss; R2: 1.680796e-02 -0.758363
2019-11-08 02:37:21,931 valid 000 1.275739e-02 -0.518081
2019-11-08 02:37:31,350 valid 050 1.595255e-02 -1.684898
2019-11-08 02:37:39,630 validation loss; R2: 1.581474e-02 -1.295832
2019-11-08 02:37:39,695 epoch 777 lr 1.000000e-05
2019-11-08 02:37:40,475 train 000 1.834537e-02 -0.595321
2019-11-08 02:37:50,207 train 050 1.723151e-02 -130.884065
2019-11-08 02:37:59,954 train 100 1.714417e-02 -66.487261
2019-11-08 02:38:09,714 train 150 1.694190e-02 -44.649977
2019-11-08 02:38:19,477 train 200 1.686504e-02 -33.730532
2019-11-08 02:38:29,244 train 250 1.682220e-02 -27.125258
2019-11-08 02:38:39,016 train 300 1.683141e-02 -22.773392
2019-11-08 02:38:48,782 train 350 1.682312e-02 -19.636112
2019-11-08 02:38:58,546 train 400 1.680929e-02 -17.280060
2019-11-08 02:39:08,314 train 450 1.681006e-02 -15.432844
2019-11-08 02:39:18,042 train 500 1.684865e-02 -13.985238
2019-11-08 02:39:27,790 train 550 1.681971e-02 -12.808560
2019-11-08 02:39:37,521 train 600 1.681891e-02 -11.926448
2019-11-08 02:39:47,258 train 650 1.680824e-02 -11.066845
2019-11-08 02:39:56,998 train 700 1.680817e-02 -10.347892
2019-11-08 02:40:06,734 train 750 1.680368e-02 -9.705847
2019-11-08 02:40:16,468 train 800 1.680620e-02 -9.142068
2019-11-08 02:40:26,206 train 850 1.678763e-02 -8.637679
2019-11-08 02:40:29,120 training loss; R2: 1.677809e-02 -8.500564
2019-11-08 02:40:29,826 valid 000 1.928706e-02 -0.340049
2019-11-08 02:40:39,172 valid 050 1.842797e-02 -1.618281
2019-11-08 02:40:47,545 validation loss; R2: 1.825291e-02 -1.581313
2019-11-08 02:40:47,610 epoch 778 lr 1.000000e-05
2019-11-08 02:40:48,396 train 000 1.601172e-02 -1.298129
2019-11-08 02:40:58,116 train 050 1.695247e-02 -0.593927
2019-11-08 02:41:07,889 train 100 1.681614e-02 -0.735943
2019-11-08 02:41:17,695 train 150 1.687047e-02 -0.670791
2019-11-08 02:41:27,502 train 200 1.674987e-02 -0.707093
2019-11-08 02:41:37,300 train 250 1.670691e-02 -0.666629
2019-11-08 02:41:47,105 train 300 1.670863e-02 -0.653983
2019-11-08 02:41:56,922 train 350 1.673706e-02 -0.663109
2019-11-08 02:42:06,753 train 400 1.674577e-02 -0.733379
2019-11-08 02:42:16,593 train 450 1.674204e-02 -0.706679
2019-11-08 02:42:26,416 train 500 1.670268e-02 -0.692553
2019-11-08 02:42:36,233 train 550 1.670690e-02 -0.711809
2019-11-08 02:42:46,038 train 600 1.673368e-02 -0.724045
2019-11-08 02:42:55,824 train 650 1.671663e-02 -0.743730
2019-11-08 02:43:05,620 train 700 1.672552e-02 -0.754592
2019-11-08 02:43:15,410 train 750 1.674423e-02 -0.748207
2019-11-08 02:43:25,206 train 800 1.672533e-02 -0.744199
2019-11-08 02:43:34,997 train 850 1.675004e-02 -0.737178
2019-11-08 02:43:37,928 training loss; R2: 1.673777e-02 -0.731901
2019-11-08 02:43:38,622 valid 000 1.974155e-02 -3.732964
2019-11-08 02:43:47,972 valid 050 1.748352e-02 -1.417148
2019-11-08 02:43:56,378 validation loss; R2: 1.753372e-02 -1.722088
2019-11-08 02:43:56,443 epoch 779 lr 1.000000e-05
2019-11-08 02:43:57,246 train 000 1.729883e-02 -6.139671
2019-11-08 02:44:06,946 train 050 1.699024e-02 -0.911301
2019-11-08 02:44:16,656 train 100 1.688681e-02 -0.791430
2019-11-08 02:44:26,409 train 150 1.686076e-02 -0.766415
2019-11-08 02:44:36,158 train 200 1.683350e-02 -0.756721
2019-11-08 02:44:45,916 train 250 1.675972e-02 -0.728146
2019-11-08 02:44:55,673 train 300 1.677885e-02 -0.715510
2019-11-08 02:45:05,456 train 350 1.680108e-02 -0.712540
2019-11-08 02:45:15,221 train 400 1.684620e-02 -0.727709
2019-11-08 02:45:24,985 train 450 1.683342e-02 -0.750561
2019-11-08 02:45:34,746 train 500 1.675454e-02 -0.759039
2019-11-08 02:45:44,512 train 550 1.676295e-02 -0.771110
2019-11-08 02:45:54,274 train 600 1.674557e-02 -0.755374
2019-11-08 02:46:04,042 train 650 1.671901e-02 -0.767097
2019-11-08 02:46:13,805 train 700 1.669825e-02 -0.758106
2019-11-08 02:46:23,557 train 750 1.670410e-02 -0.762070
2019-11-08 02:46:33,346 train 800 1.671474e-02 -0.741571
2019-11-08 02:46:43,126 train 850 1.669416e-02 -0.735796
2019-11-08 02:46:46,050 training loss; R2: 1.667424e-02 -0.747067
2019-11-08 02:46:46,692 valid 000 3.723337e-02 -3.404721
2019-11-08 02:46:56,085 valid 050 3.823566e-02 -4.947820
2019-11-08 02:47:04,373 validation loss; R2: 3.790909e-02 -4.848586
2019-11-08 02:47:04,440 epoch 780 lr 1.000000e-05
2019-11-08 02:47:05,229 train 000 1.990074e-02 -0.100778
2019-11-08 02:47:14,937 train 050 1.652410e-02 -0.654313
2019-11-08 02:47:24,674 train 100 1.681498e-02 -0.628321
2019-11-08 02:47:34,441 train 150 1.694450e-02 -0.630248
2019-11-08 02:47:44,207 train 200 1.693866e-02 -0.616503
2019-11-08 02:47:53,966 train 250 1.693964e-02 -0.649808
2019-11-08 02:48:03,732 train 300 1.689552e-02 -0.774109
2019-11-08 02:48:13,520 train 350 1.685172e-02 -0.768367
2019-11-08 02:48:23,290 train 400 1.686886e-02 -0.760578
2019-11-08 02:48:33,050 train 450 1.687364e-02 -0.790062
2019-11-08 02:48:42,834 train 500 1.688160e-02 -0.821420
2019-11-08 02:48:52,613 train 550 1.687326e-02 -0.830824
2019-11-08 02:49:02,384 train 600 1.687527e-02 -0.822564
2019-11-08 02:49:12,152 train 650 1.687406e-02 -0.813442
2019-11-08 02:49:21,929 train 700 1.687705e-02 -0.800671
2019-11-08 02:49:32,069 train 750 1.686144e-02 -0.819492
2019-11-08 02:49:42,196 train 800 1.686043e-02 -0.938857
2019-11-08 02:49:52,336 train 850 1.685345e-02 -0.979175
2019-11-08 02:49:55,352 training loss; R2: 1.686483e-02 -0.971038
2019-11-08 02:49:56,049 valid 000 1.490972e-02 -0.858906
2019-11-08 02:50:05,432 valid 050 1.480310e-02 -1.382870
2019-11-08 02:50:13,738 validation loss; R2: 1.482617e-02 -1.438802
2019-11-08 02:50:13,807 epoch 781 lr 1.000000e-05
2019-11-08 02:50:14,552 train 000 1.593229e-02 0.101484
2019-11-08 02:50:24,671 train 050 1.680674e-02 -0.757416
2019-11-08 02:50:34,782 train 100 1.659785e-02 -0.890658
2019-11-08 02:50:44,943 train 150 1.671165e-02 -0.794637
2019-11-08 02:50:55,108 train 200 1.670771e-02 -0.754655
2019-11-08 02:51:05,262 train 250 1.674126e-02 -0.738371
2019-11-08 02:51:15,403 train 300 1.683512e-02 -0.718787
2019-11-08 02:51:25,547 train 350 1.674573e-02 -0.711293
2019-11-08 02:51:35,715 train 400 1.680698e-02 -0.685128
2019-11-08 02:51:45,866 train 450 1.678691e-02 -1.072525
2019-11-08 02:51:55,982 train 500 1.678060e-02 -1.058075
2019-11-08 02:52:05,747 train 550 1.682783e-02 -1.029382
2019-11-08 02:52:15,522 train 600 1.677822e-02 -1.005928
2019-11-08 02:52:25,311 train 650 1.679299e-02 -0.973185
2019-11-08 02:52:35,106 train 700 1.680254e-02 -0.950467
2019-11-08 02:52:44,896 train 750 1.681900e-02 -0.926667
2019-11-08 02:52:54,677 train 800 1.681791e-02 -0.908457
2019-11-08 02:53:04,460 train 850 1.681491e-02 -0.885912
2019-11-08 02:53:07,389 training loss; R2: 1.681618e-02 -0.889556
2019-11-08 02:53:08,040 valid 000 1.919147e-02 -1.044197
2019-11-08 02:53:17,490 valid 050 1.707697e-02 -2.336021
2019-11-08 02:53:25,822 validation loss; R2: 1.728394e-02 -2.456431
2019-11-08 02:53:25,888 epoch 782 lr 1.000000e-05
2019-11-08 02:53:26,670 train 000 1.619035e-02 -0.142319
2019-11-08 02:53:36,399 train 050 1.707703e-02 -0.832555
2019-11-08 02:53:46,142 train 100 1.697463e-02 -0.751091
2019-11-08 02:53:55,898 train 150 1.686832e-02 -0.705893
2019-11-08 02:54:05,651 train 200 1.683924e-02 -0.752630
2019-11-08 02:54:15,409 train 250 1.678332e-02 -1.197927
2019-11-08 02:54:25,192 train 300 1.674944e-02 -1.138930
2019-11-08 02:54:35,107 train 350 1.680265e-02 -1.065076
2019-11-08 02:54:45,279 train 400 1.683599e-02 -1.013438
2019-11-08 02:54:55,412 train 450 1.677943e-02 -0.991681
2019-11-08 02:55:05,557 train 500 1.677445e-02 -0.978831
2019-11-08 02:55:15,685 train 550 1.679290e-02 -0.973568
2019-11-08 02:55:25,820 train 600 1.677259e-02 -0.949094
2019-11-08 02:55:35,953 train 650 1.676626e-02 -0.939635
2019-11-08 02:55:46,102 train 700 1.676447e-02 -0.921399
2019-11-08 02:55:56,185 train 750 1.678421e-02 -0.969401
2019-11-08 02:56:05,947 train 800 1.679466e-02 -0.981966
2019-11-08 02:56:15,704 train 850 1.678249e-02 -0.974631
2019-11-08 02:56:18,621 training loss; R2: 1.677771e-02 -0.970314
2019-11-08 02:56:19,265 valid 000 1.519538e-02 -0.256193
2019-11-08 02:56:28,682 valid 050 1.696836e-02 -1.025350
2019-11-08 02:56:36,999 validation loss; R2: 1.691595e-02 -0.891402
2019-11-08 02:56:37,060 epoch 783 lr 1.000000e-05
2019-11-08 02:56:37,825 train 000 1.632629e-02 0.087327
2019-11-08 02:56:47,541 train 050 1.680905e-02 -0.823309
2019-11-08 02:56:57,259 train 100 1.667946e-02 -0.986719
2019-11-08 02:57:06,999 train 150 1.671602e-02 -0.900115
2019-11-08 02:57:16,752 train 200 1.681120e-02 -0.892692
2019-11-08 02:57:26,504 train 250 1.676537e-02 -0.843383
2019-11-08 02:57:36,244 train 300 1.673778e-02 -0.840739
2019-11-08 02:57:46,005 train 350 1.673082e-02 -0.796729
2019-11-08 02:57:55,773 train 400 1.674381e-02 -1.016474
2019-11-08 02:58:05,531 train 450 1.675170e-02 -1.066659
2019-11-08 02:58:15,297 train 500 1.674951e-02 -1.039522
2019-11-08 02:58:25,072 train 550 1.675692e-02 -1.022757
2019-11-08 02:58:34,854 train 600 1.674898e-02 -1.045451
2019-11-08 02:58:44,624 train 650 1.672489e-02 -1.032267
2019-11-08 02:58:54,397 train 700 1.673002e-02 -1.003992
2019-11-08 02:59:04,179 train 750 1.672002e-02 -0.996260
2019-11-08 02:59:13,955 train 800 1.673456e-02 -0.973111
2019-11-08 02:59:23,727 train 850 1.674194e-02 -0.961479
2019-11-08 02:59:26,649 training loss; R2: 1.674119e-02 -0.952926
2019-11-08 02:59:27,305 valid 000 1.588254e-02 -1.730501
2019-11-08 02:59:36,740 valid 050 1.650210e-02 -1.289598
2019-11-08 02:59:45,231 validation loss; R2: 1.627587e-02 -0.971539
2019-11-08 02:59:45,297 epoch 784 lr 1.000000e-05
2019-11-08 02:59:46,059 train 000 2.057661e-02 -2.059728
2019-11-08 02:59:55,753 train 050 1.678303e-02 -0.476312
2019-11-08 03:00:05,465 train 100 1.680914e-02 -0.608412
2019-11-08 03:00:15,203 train 150 1.692524e-02 -0.630003
2019-11-08 03:00:24,954 train 200 1.695509e-02 -0.600958
2019-11-08 03:00:34,701 train 250 1.695322e-02 -0.749011
2019-11-08 03:00:44,450 train 300 1.694710e-02 -0.732998
2019-11-08 03:00:54,213 train 350 1.689847e-02 -0.743353
2019-11-08 03:01:03,972 train 400 1.690088e-02 -0.781042
2019-11-08 03:01:13,720 train 450 1.687224e-02 -1.052154
2019-11-08 03:01:23,478 train 500 1.680991e-02 -1.005860
2019-11-08 03:01:33,228 train 550 1.679619e-02 -1.003549
2019-11-08 03:01:43,016 train 600 1.679279e-02 -0.955969
2019-11-08 03:01:52,809 train 650 1.682002e-02 -0.959626
2019-11-08 03:02:02,587 train 700 1.680477e-02 -0.939284
2019-11-08 03:02:12,404 train 750 1.678145e-02 -0.912514
2019-11-08 03:02:22,213 train 800 1.675857e-02 -0.905255
2019-11-08 03:02:32,025 train 850 1.677983e-02 -0.922164
2019-11-08 03:02:34,958 training loss; R2: 1.678133e-02 -0.933682
2019-11-08 03:02:35,605 valid 000 1.477764e-02 -1.002605
2019-11-08 03:02:45,017 valid 050 1.440995e-02 -0.914265
2019-11-08 03:02:53,323 validation loss; R2: 1.453776e-02 -1.118559
2019-11-08 03:02:53,391 epoch 785 lr 1.000000e-05
2019-11-08 03:02:54,155 train 000 1.470163e-02 -0.350250
2019-11-08 03:03:03,880 train 050 1.617853e-02 -0.892498
2019-11-08 03:03:13,597 train 100 1.666483e-02 -0.718196
2019-11-08 03:03:23,344 train 150 1.687357e-02 -0.721988
2019-11-08 03:03:33,094 train 200 1.690792e-02 -0.739102
2019-11-08 03:03:42,856 train 250 1.687804e-02 -0.730418
2019-11-08 03:03:52,622 train 300 1.683983e-02 -0.724939
2019-11-08 03:04:02,403 train 350 1.678225e-02 -0.668571
2019-11-08 03:04:12,177 train 400 1.682485e-02 -0.677225
2019-11-08 03:04:21,951 train 450 1.683235e-02 -0.698897
2019-11-08 03:04:31,729 train 500 1.680731e-02 -0.676821
2019-11-08 03:04:41,528 train 550 1.677072e-02 -0.689338
2019-11-08 03:04:51,352 train 600 1.675421e-02 -0.685542
2019-11-08 03:05:01,169 train 650 1.674883e-02 -0.688525
2019-11-08 03:05:10,985 train 700 1.676318e-02 -0.694415
2019-11-08 03:05:20,806 train 750 1.674891e-02 -0.687953
2019-11-08 03:05:30,619 train 800 1.675554e-02 -0.689172
2019-11-08 03:05:40,441 train 850 1.675495e-02 -0.729718
2019-11-08 03:05:43,379 training loss; R2: 1.676289e-02 -0.723198
2019-11-08 03:05:44,004 valid 000 1.249863e-02 0.133290
2019-11-08 03:05:53,423 valid 050 1.552767e-02 -0.775195
2019-11-08 03:06:01,743 validation loss; R2: 1.558539e-02 -0.895298
2019-11-08 03:06:01,828 epoch 786 lr 1.000000e-05
2019-11-08 03:06:02,625 train 000 1.802718e-02 -0.414357
2019-11-08 03:06:12,410 train 050 1.691167e-02 -0.892126
2019-11-08 03:06:22,193 train 100 1.684522e-02 -0.897803
2019-11-08 03:06:31,985 train 150 1.682354e-02 -0.887830
2019-11-08 03:06:41,763 train 200 1.678202e-02 -0.826153
2019-11-08 03:06:51,563 train 250 1.679311e-02 -0.761013
2019-11-08 03:07:01,370 train 300 1.683494e-02 -0.725126
2019-11-08 03:07:11,159 train 350 1.681058e-02 -0.697759
2019-11-08 03:07:20,955 train 400 1.683774e-02 -0.674961
2019-11-08 03:07:30,751 train 450 1.683911e-02 -0.685259
2019-11-08 03:07:40,556 train 500 1.683381e-02 -0.684480
2019-11-08 03:07:50,372 train 550 1.684025e-02 -0.710088
2019-11-08 03:08:00,193 train 600 1.680296e-02 -0.724775
2019-11-08 03:08:10,017 train 650 1.679272e-02 -0.747549
2019-11-08 03:08:19,830 train 700 1.678149e-02 -0.744600
2019-11-08 03:08:29,643 train 750 1.679155e-02 -0.757182
2019-11-08 03:08:39,462 train 800 1.679009e-02 -0.740348
2019-11-08 03:08:49,291 train 850 1.676641e-02 -0.742592
2019-11-08 03:08:52,231 training loss; R2: 1.677453e-02 -0.735559
2019-11-08 03:08:52,851 valid 000 2.311641e-02 -0.338541
2019-11-08 03:09:02,311 valid 050 2.000628e-02 -2.271606
2019-11-08 03:09:10,681 validation loss; R2: 2.021433e-02 -2.632734
2019-11-08 03:09:10,751 epoch 787 lr 1.000000e-05
2019-11-08 03:09:11,535 train 000 1.619109e-02 -0.179512
2019-11-08 03:09:21,315 train 050 1.640463e-02 -0.578754
2019-11-08 03:09:31,102 train 100 1.657636e-02 -0.523939
2019-11-08 03:09:40,951 train 150 1.659760e-02 -0.612454
2019-11-08 03:09:50,746 train 200 1.668564e-02 -0.675786
2019-11-08 03:10:00,559 train 250 1.668387e-02 -0.694614
2019-11-08 03:10:10,378 train 300 1.670089e-02 -0.679859
2019-11-08 03:10:20,207 train 350 1.669851e-02 -0.688912
2019-11-08 03:10:30,041 train 400 1.674094e-02 -0.658860
2019-11-08 03:10:39,877 train 450 1.675607e-02 -0.656741
2019-11-08 03:10:49,705 train 500 1.675603e-02 -0.657525
2019-11-08 03:10:59,549 train 550 1.675791e-02 -0.663649
2019-11-08 03:11:09,404 train 600 1.677863e-02 -0.646670
2019-11-08 03:11:19,253 train 650 1.679718e-02 -0.674362
2019-11-08 03:11:29,086 train 700 1.678374e-02 -0.704342
2019-11-08 03:11:38,923 train 750 1.677971e-02 -0.716796
2019-11-08 03:11:48,764 train 800 1.679548e-02 -0.727165
2019-11-08 03:11:58,609 train 850 1.679977e-02 -0.749182
2019-11-08 03:12:01,546 training loss; R2: 1.679689e-02 -0.746449
2019-11-08 03:12:02,237 valid 000 1.253017e-02 -3.005636
2019-11-08 03:12:11,583 valid 050 1.581538e-02 -1.120281
2019-11-08 03:12:19,930 validation loss; R2: 1.594947e-02 -1.102922
2019-11-08 03:12:20,009 epoch 788 lr 1.000000e-05
2019-11-08 03:12:20,804 train 000 1.979936e-02 -0.874304
2019-11-08 03:12:30,572 train 050 1.688291e-02 -1.155095
2019-11-08 03:12:40,349 train 100 1.685558e-02 -0.911493
2019-11-08 03:12:50,155 train 150 1.680430e-02 -0.827534
2019-11-08 03:12:59,953 train 200 1.681899e-02 -0.782762
2019-11-08 03:13:09,735 train 250 1.676849e-02 -0.836227
2019-11-08 03:13:19,503 train 300 1.682539e-02 -0.803336
2019-11-08 03:13:29,300 train 350 1.679424e-02 -0.780696
2019-11-08 03:13:39,105 train 400 1.681170e-02 -0.796917
2019-11-08 03:13:48,897 train 450 1.681014e-02 -0.781207
2019-11-08 03:13:58,700 train 500 1.684330e-02 -0.751062
2019-11-08 03:14:08,505 train 550 1.684370e-02 -0.727079
2019-11-08 03:14:18,319 train 600 1.685638e-02 -0.740635
2019-11-08 03:14:28,124 train 650 1.685861e-02 -0.735442
2019-11-08 03:14:37,927 train 700 1.686179e-02 -0.763242
2019-11-08 03:14:47,737 train 750 1.684271e-02 -0.740116
2019-11-08 03:14:57,540 train 800 1.685215e-02 -0.747945
2019-11-08 03:15:07,353 train 850 1.683960e-02 -0.812447
2019-11-08 03:15:10,282 training loss; R2: 1.683239e-02 -0.811241
2019-11-08 03:15:10,869 valid 000 1.691462e-02 0.033846
2019-11-08 03:15:20,338 valid 050 1.487532e-02 -1.242256
2019-11-08 03:15:28,649 validation loss; R2: 1.496983e-02 -1.090944
2019-11-08 03:15:28,714 epoch 789 lr 1.000000e-05
2019-11-08 03:15:29,495 train 000 1.715022e-02 -0.391674
2019-11-08 03:15:39,260 train 050 1.670069e-02 -0.878375
2019-11-08 03:15:49,047 train 100 1.676228e-02 -0.742856
2019-11-08 03:15:58,856 train 150 1.665426e-02 -0.780511
2019-11-08 03:16:08,682 train 200 1.656728e-02 -0.737699
2019-11-08 03:16:18,477 train 250 1.659464e-02 -0.755123
2019-11-08 03:16:28,288 train 300 1.663003e-02 -0.719447
2019-11-08 03:16:38,129 train 350 1.665469e-02 -0.704405
2019-11-08 03:16:47,954 train 400 1.671592e-02 -0.689014
2019-11-08 03:16:57,795 train 450 1.674252e-02 -0.705335
2019-11-08 03:17:07,612 train 500 1.677933e-02 -0.714314
2019-11-08 03:17:17,449 train 550 1.679893e-02 -0.735647
2019-11-08 03:17:27,288 train 600 1.680034e-02 -0.728163
2019-11-08 03:17:37,132 train 650 1.681588e-02 -3.159566
2019-11-08 03:17:46,968 train 700 1.678108e-02 -2.985629
2019-11-08 03:17:56,794 train 750 1.678507e-02 -2.842421
2019-11-08 03:18:06,602 train 800 1.677628e-02 -2.716456
2019-11-08 03:18:16,406 train 850 1.678071e-02 -2.597734
2019-11-08 03:18:19,342 training loss; R2: 1.677586e-02 -2.557904
2019-11-08 03:18:20,029 valid 000 1.363732e-02 0.181544
2019-11-08 03:18:29,399 valid 050 1.451602e-02 -0.806628
2019-11-08 03:18:37,910 validation loss; R2: 1.472333e-02 -0.754068
2019-11-08 03:18:37,977 epoch 790 lr 1.000000e-05
2019-11-08 03:18:38,754 train 000 1.772783e-02 -0.867205
2019-11-08 03:18:48,514 train 050 1.679975e-02 -0.637041
2019-11-08 03:18:58,283 train 100 1.688142e-02 -0.698315
2019-11-08 03:19:08,067 train 150 1.706811e-02 -0.694013
2019-11-08 03:19:17,858 train 200 1.700963e-02 -0.726534
2019-11-08 03:19:27,657 train 250 1.695964e-02 -0.721714
2019-11-08 03:19:37,453 train 300 1.695082e-02 -0.706060
2019-11-08 03:19:47,236 train 350 1.693835e-02 -0.706194
2019-11-08 03:19:57,051 train 400 1.693193e-02 -0.715086
2019-11-08 03:20:06,861 train 450 1.685805e-02 -0.714114
2019-11-08 03:20:16,683 train 500 1.690517e-02 -0.749389
2019-11-08 03:20:26,512 train 550 1.689685e-02 -0.721931
2019-11-08 03:20:36,348 train 600 1.689965e-02 -0.814583
2019-11-08 03:20:46,175 train 650 1.688649e-02 -0.803510
2019-11-08 03:20:55,996 train 700 1.688779e-02 -0.784489
2019-11-08 03:21:05,808 train 750 1.688641e-02 -0.787172
2019-11-08 03:21:15,627 train 800 1.686634e-02 -0.788979
2019-11-08 03:21:25,455 train 850 1.686110e-02 -0.786226
2019-11-08 03:21:28,389 training loss; R2: 1.685333e-02 -0.780454
2019-11-08 03:21:29,076 valid 000 1.362545e-02 -1.139271
2019-11-08 03:21:38,429 valid 050 1.504108e-02 -1.175523
2019-11-08 03:21:46,824 validation loss; R2: 1.522388e-02 -1.056809
2019-11-08 03:21:46,888 epoch 791 lr 1.000000e-05
2019-11-08 03:21:47,619 train 000 1.693479e-02 -0.616802
2019-11-08 03:21:57,374 train 050 1.673779e-02 -0.466668
2019-11-08 03:22:07,135 train 100 1.664772e-02 -0.543928
2019-11-08 03:22:16,930 train 150 1.674009e-02 -0.607143
2019-11-08 03:22:26,683 train 200 1.674185e-02 -0.609105
2019-11-08 03:22:36,433 train 250 1.671126e-02 -0.583761
2019-11-08 03:22:46,198 train 300 1.674358e-02 -0.582567
2019-11-08 03:22:55,962 train 350 1.674398e-02 -0.569042
2019-11-08 03:23:05,749 train 400 1.676394e-02 -0.598459
2019-11-08 03:23:15,529 train 450 1.674156e-02 -0.610879
2019-11-08 03:23:25,327 train 500 1.673268e-02 -0.650039
2019-11-08 03:23:35,109 train 550 1.669233e-02 -0.654631
2019-11-08 03:23:44,902 train 600 1.670864e-02 -0.659856
2019-11-08 03:23:54,707 train 650 1.672486e-02 -0.652688
2019-11-08 03:24:04,503 train 700 1.673120e-02 -0.702048
2019-11-08 03:24:14,292 train 750 1.673780e-02 -0.709526
2019-11-08 03:24:24,087 train 800 1.675082e-02 -0.701982
2019-11-08 03:24:33,879 train 850 1.675875e-02 -0.698471
2019-11-08 03:24:36,803 training loss; R2: 1.675089e-02 -0.700389
2019-11-08 03:24:37,440 valid 000 1.581323e-02 -0.343326
2019-11-08 03:24:46,822 valid 050 1.549856e-02 -0.850207
2019-11-08 03:24:55,245 validation loss; R2: 1.547502e-02 -1.113290
2019-11-08 03:24:55,311 epoch 792 lr 1.000000e-05
2019-11-08 03:24:56,161 train 000 1.641267e-02 -1.077403
2019-11-08 03:25:05,918 train 050 1.673173e-02 -0.926337
2019-11-08 03:25:15,707 train 100 1.662788e-02 -0.771897
2019-11-08 03:25:25,488 train 150 1.669942e-02 -0.774570
2019-11-08 03:25:35,277 train 200 1.669442e-02 -0.769117
2019-11-08 03:25:45,064 train 250 1.668939e-02 -0.749115
2019-11-08 03:25:54,861 train 300 1.667540e-02 -0.709379
2019-11-08 03:26:04,658 train 350 1.669564e-02 -0.739038
2019-11-08 03:26:14,461 train 400 1.673026e-02 -0.724199
2019-11-08 03:26:24,302 train 450 1.672831e-02 -0.725543
2019-11-08 03:26:34,164 train 500 1.673098e-02 -0.696641
2019-11-08 03:26:44,026 train 550 1.671089e-02 -0.716360
2019-11-08 03:26:53,943 train 600 1.669917e-02 -0.733347
2019-11-08 03:27:04,143 train 650 1.668455e-02 -0.740299
2019-11-08 03:27:14,312 train 700 1.666354e-02 -0.751323
2019-11-08 03:27:24,518 train 750 1.668848e-02 -0.783366
2019-11-08 03:27:34,718 train 800 1.668486e-02 -0.784237
2019-11-08 03:27:44,913 train 850 1.670421e-02 -0.789481
2019-11-08 03:27:47,958 training loss; R2: 1.671140e-02 -0.787664
2019-11-08 03:27:48,650 valid 000 2.595372e-02 -1.124156
2019-11-08 03:27:58,049 valid 050 2.634941e-02 -3.022099
2019-11-08 03:28:06,373 validation loss; R2: 2.587711e-02 -2.899526
2019-11-08 03:28:06,449 epoch 793 lr 1.000000e-05
2019-11-08 03:28:07,195 train 000 1.884419e-02 -0.072112
2019-11-08 03:28:16,928 train 050 1.686723e-02 -0.494572
2019-11-08 03:28:26,681 train 100 1.661809e-02 -0.751282
2019-11-08 03:28:36,460 train 150 1.657435e-02 -0.679218
2019-11-08 03:28:46,227 train 200 1.657653e-02 -0.679518
2019-11-08 03:28:56,016 train 250 1.662800e-02 -0.782720
2019-11-08 03:29:05,829 train 300 1.669755e-02 -0.720341
2019-11-08 03:29:15,649 train 350 1.666791e-02 -0.742742
2019-11-08 03:29:25,462 train 400 1.667362e-02 -0.750620
2019-11-08 03:29:35,283 train 450 1.668878e-02 -0.752095
2019-11-08 03:29:45,102 train 500 1.668771e-02 -0.740872
2019-11-08 03:29:54,911 train 550 1.673778e-02 -0.720777
2019-11-08 03:30:04,722 train 600 1.676826e-02 -0.713730
2019-11-08 03:30:14,522 train 650 1.678313e-02 -0.682866
2019-11-08 03:30:24,325 train 700 1.677547e-02 -0.699803
2019-11-08 03:30:34,113 train 750 1.673126e-02 -0.736585
2019-11-08 03:30:43,906 train 800 1.673490e-02 -0.786749
2019-11-08 03:30:53,701 train 850 1.673697e-02 -0.801656
2019-11-08 03:30:56,630 training loss; R2: 1.673773e-02 -0.818331
2019-11-08 03:30:57,275 valid 000 1.498985e-02 -0.602696
2019-11-08 03:31:06,713 valid 050 1.494040e-02 -1.402560
2019-11-08 03:31:15,059 validation loss; R2: 1.495794e-02 -1.217233
2019-11-08 03:31:15,124 epoch 794 lr 1.000000e-05
2019-11-08 03:31:15,911 train 000 1.546243e-02 -0.488444
2019-11-08 03:31:25,669 train 050 1.665947e-02 -0.584899
2019-11-08 03:31:35,439 train 100 1.671350e-02 -0.630305
2019-11-08 03:31:45,236 train 150 1.675615e-02 -0.632933
2019-11-08 03:31:55,028 train 200 1.674917e-02 -0.761649
2019-11-08 03:32:04,819 train 250 1.678400e-02 -0.782003
2019-11-08 03:32:14,646 train 300 1.676682e-02 -0.759388
2019-11-08 03:32:24,464 train 350 1.678652e-02 -0.774032
2019-11-08 03:32:34,271 train 400 1.674505e-02 -0.758434
2019-11-08 03:32:44,076 train 450 1.674367e-02 -0.727845
2019-11-08 03:32:53,870 train 500 1.669165e-02 -0.760301
2019-11-08 03:33:03,683 train 550 1.669068e-02 -0.766943
2019-11-08 03:33:13,507 train 600 1.667873e-02 -0.747145
2019-11-08 03:33:23,322 train 650 1.667262e-02 -0.738609
2019-11-08 03:33:33,184 train 700 1.669570e-02 -0.730640
2019-11-08 03:33:43,019 train 750 1.668742e-02 -0.841417
2019-11-08 03:33:52,847 train 800 1.669267e-02 -0.824551
2019-11-08 03:34:02,700 train 850 1.669566e-02 -0.820252
2019-11-08 03:34:05,636 training loss; R2: 1.669219e-02 -0.816388
2019-11-08 03:34:06,326 valid 000 1.323774e-02 -0.278784
2019-11-08 03:34:15,689 valid 050 1.519412e-02 -1.014370
2019-11-08 03:34:24,017 validation loss; R2: 1.533155e-02 -1.036980
2019-11-08 03:34:24,083 epoch 795 lr 1.000000e-05
2019-11-08 03:34:24,815 train 000 1.580412e-02 -2.178720
2019-11-08 03:34:34,567 train 050 1.688347e-02 -0.568836
2019-11-08 03:34:44,317 train 100 1.698261e-02 -0.642607
2019-11-08 03:34:54,074 train 150 1.697570e-02 -0.619116
2019-11-08 03:35:03,841 train 200 1.697352e-02 -0.655802
2019-11-08 03:35:13,600 train 250 1.692395e-02 -0.680574
2019-11-08 03:35:23,379 train 300 1.695905e-02 -0.746763
2019-11-08 03:35:33,191 train 350 1.696999e-02 -0.738733
2019-11-08 03:35:42,968 train 400 1.689967e-02 -0.751846
2019-11-08 03:35:52,763 train 450 1.690335e-02 -0.766255
2019-11-08 03:36:02,549 train 500 1.689746e-02 -0.750713
2019-11-08 03:36:12,340 train 550 1.686741e-02 -0.772208
2019-11-08 03:36:22,123 train 600 1.686028e-02 -0.801857
2019-11-08 03:36:31,921 train 650 1.683010e-02 -0.778990
2019-11-08 03:36:41,701 train 700 1.684156e-02 -0.771752
2019-11-08 03:36:51,495 train 750 1.684595e-02 -0.789109
2019-11-08 03:37:01,276 train 800 1.684466e-02 -0.786016
2019-11-08 03:37:11,066 train 850 1.682594e-02 -1.014103
2019-11-08 03:37:13,997 training loss; R2: 1.683588e-02 -1.012778
2019-11-08 03:37:14,703 valid 000 1.838633e-02 -0.182808
2019-11-08 03:37:24,086 valid 050 1.489958e-02 -1.596630
2019-11-08 03:37:32,414 validation loss; R2: 1.492349e-02 -1.231908
2019-11-08 03:37:32,480 epoch 796 lr 1.000000e-05
2019-11-08 03:37:33,208 train 000 1.675628e-02 -0.308406
2019-11-08 03:37:42,933 train 050 1.698151e-02 -0.611980
2019-11-08 03:37:52,644 train 100 1.703894e-02 -0.661169
2019-11-08 03:38:02,411 train 150 1.693107e-02 -0.732003
2019-11-08 03:38:12,176 train 200 1.696284e-02 -0.706333
2019-11-08 03:38:21,951 train 250 1.696658e-02 -0.715498
2019-11-08 03:38:31,723 train 300 1.693371e-02 -0.737897
2019-11-08 03:38:41,507 train 350 1.687468e-02 -0.715223
2019-11-08 03:38:51,308 train 400 1.682592e-02 -0.728724
2019-11-08 03:39:01,100 train 450 1.684741e-02 -0.707317
2019-11-08 03:39:10,886 train 500 1.685242e-02 -0.687752
2019-11-08 03:39:20,678 train 550 1.684698e-02 -0.690586
2019-11-08 03:39:30,470 train 600 1.683375e-02 -0.711811
2019-11-08 03:39:40,260 train 650 1.681878e-02 -0.732254
2019-11-08 03:39:50,055 train 700 1.680333e-02 -0.732177
2019-11-08 03:39:59,851 train 750 1.678346e-02 -0.742202
2019-11-08 03:40:09,643 train 800 1.678719e-02 -0.735124
2019-11-08 03:40:19,438 train 850 1.680363e-02 -0.728949
2019-11-08 03:40:22,398 training loss; R2: 1.679257e-02 -0.733274
2019-11-08 03:40:23,018 valid 000 1.566222e-02 -0.235363
2019-11-08 03:40:32,411 valid 050 1.574019e-02 -0.900349
2019-11-08 03:40:40,739 validation loss; R2: 1.605797e-02 -1.081895
2019-11-08 03:40:40,824 epoch 797 lr 1.000000e-05
2019-11-08 03:40:41,640 train 000 1.747465e-02 -0.268130
2019-11-08 03:40:51,761 train 050 1.652384e-02 -1.461245
2019-11-08 03:41:01,620 train 100 1.655731e-02 -1.025587
2019-11-08 03:41:11,397 train 150 1.644657e-02 -0.897965
2019-11-08 03:41:21,177 train 200 1.651778e-02 -0.812292
2019-11-08 03:41:30,943 train 250 1.663567e-02 -0.907058
2019-11-08 03:41:40,715 train 300 1.668437e-02 -0.871672
2019-11-08 03:41:50,488 train 350 1.666820e-02 -0.854336
2019-11-08 03:42:00,289 train 400 1.667427e-02 -0.821823
2019-11-08 03:42:10,075 train 450 1.663974e-02 -0.805137
2019-11-08 03:42:19,867 train 500 1.665217e-02 -0.788312
2019-11-08 03:42:29,664 train 550 1.670319e-02 -0.762001
2019-11-08 03:42:39,447 train 600 1.670152e-02 -0.786845
2019-11-08 03:42:49,239 train 650 1.670368e-02 -0.915208
2019-11-08 03:42:59,026 train 700 1.672184e-02 -0.914785
2019-11-08 03:43:08,836 train 750 1.670552e-02 -0.925994
2019-11-08 03:43:18,639 train 800 1.673740e-02 -0.913529
2019-11-08 03:43:28,432 train 850 1.670523e-02 -0.908164
2019-11-08 03:43:31,356 training loss; R2: 1.671605e-02 -0.901436
2019-11-08 03:43:32,028 valid 000 2.110746e-02 -4.465766
2019-11-08 03:43:41,424 valid 050 2.051118e-02 -2.514995
2019-11-08 03:43:49,751 validation loss; R2: 2.071227e-02 -2.203071
2019-11-08 03:43:49,816 epoch 798 lr 1.000000e-05
2019-11-08 03:43:50,587 train 000 1.884855e-02 -0.491750
2019-11-08 03:44:00,316 train 050 1.664828e-02 -0.694163
2019-11-08 03:44:10,047 train 100 1.672763e-02 -0.722267
2019-11-08 03:44:19,812 train 150 1.667293e-02 -0.761180
2019-11-08 03:44:29,567 train 200 1.671032e-02 -0.708481
2019-11-08 03:44:39,330 train 250 1.666525e-02 -0.715148
2019-11-08 03:44:49,108 train 300 1.662428e-02 -0.710964
2019-11-08 03:44:58,894 train 350 1.663517e-02 -0.728947
2019-11-08 03:45:08,679 train 400 1.666866e-02 -0.741118
2019-11-08 03:45:18,479 train 450 1.668271e-02 -0.737120
2019-11-08 03:45:28,279 train 500 1.664679e-02 -0.719921
2019-11-08 03:45:38,089 train 550 1.668831e-02 -0.760023
2019-11-08 03:45:47,900 train 600 1.669707e-02 -0.741491
2019-11-08 03:45:57,702 train 650 1.669995e-02 -0.735376
2019-11-08 03:46:07,544 train 700 1.672556e-02 -0.745557
2019-11-08 03:46:17,379 train 750 1.673159e-02 -0.732858
2019-11-08 03:46:27,215 train 800 1.674452e-02 -0.732181
2019-11-08 03:46:37,053 train 850 1.675102e-02 -0.727287
2019-11-08 03:46:40,000 training loss; R2: 1.676898e-02 -0.722721
2019-11-08 03:46:40,662 valid 000 1.423291e-02 -0.482931
2019-11-08 03:46:50,040 valid 050 1.526644e-02 -0.898342
2019-11-08 03:46:58,333 validation loss; R2: 1.568948e-02 -0.920148
2019-11-08 03:46:58,398 epoch 799 lr 1.000000e-05
2019-11-08 03:46:59,165 train 000 1.900755e-02 -0.371830
2019-11-08 03:47:08,915 train 050 1.710751e-02 -0.723095
2019-11-08 03:47:18,723 train 100 1.706696e-02 -0.727433
2019-11-08 03:47:28,529 train 150 1.700402e-02 -0.876701
2019-11-08 03:47:38,349 train 200 1.704124e-02 -0.828067
2019-11-08 03:47:48,168 train 250 1.704774e-02 -0.769057
2019-11-08 03:47:58,021 train 300 1.697731e-02 -0.769869
2019-11-08 03:48:07,867 train 350 1.694015e-02 -0.802088
2019-11-08 03:48:17,728 train 400 1.691688e-02 -0.788274
2019-11-08 03:48:27,592 train 450 1.686111e-02 -0.956538
2019-11-08 03:48:37,458 train 500 1.685688e-02 -0.966287
2019-11-08 03:48:47,328 train 550 1.683520e-02 -0.978308
2019-11-08 03:48:57,186 train 600 1.682413e-02 -0.953921
2019-11-08 03:49:07,038 train 650 1.683353e-02 -0.914578
2019-11-08 03:49:16,915 train 700 1.682465e-02 -0.937334
2019-11-08 03:49:26,782 train 750 1.682011e-02 -0.931546
2019-11-08 03:49:36,650 train 800 1.680630e-02 -0.911878
2019-11-08 03:49:46,523 train 850 1.678716e-02 -0.907464
2019-11-08 03:49:49,470 training loss; R2: 1.677068e-02 -0.900744
2019-11-08 03:49:50,119 valid 000 1.485517e-02 -0.225931
2019-11-08 03:49:59,551 valid 050 1.666699e-02 -0.498032
2019-11-08 03:50:07,941 validation loss; R2: 1.670938e-02 -0.477970
2019-11-08 03:50:08,007 epoch 800 lr 1.000000e-05
2019-11-08 03:50:08,800 train 000 1.554839e-02 -0.091374
2019-11-08 03:50:18,538 train 050 1.702449e-02 -0.552387
2019-11-08 03:50:28,290 train 100 1.654629e-02 -0.667700
2019-11-08 03:50:38,052 train 150 1.663962e-02 -0.666442
2019-11-08 03:50:47,805 train 200 1.671098e-02 -0.690944
2019-11-08 03:50:57,562 train 250 1.669447e-02 -0.708136
2019-11-08 03:51:07,344 train 300 1.668775e-02 -0.736144
2019-11-08 03:51:17,107 train 350 1.670950e-02 -0.727144
2019-11-08 03:51:26,888 train 400 1.675797e-02 -0.718962
2019-11-08 03:51:36,652 train 450 1.672168e-02 -0.708187
2019-11-08 03:51:46,415 train 500 1.676263e-02 -0.694247
2019-11-08 03:51:56,196 train 550 1.674274e-02 -0.709199
2019-11-08 03:52:05,969 train 600 1.676614e-02 -0.699731
2019-11-08 03:52:15,737 train 650 1.675093e-02 -0.693294
2019-11-08 03:52:25,500 train 700 1.673596e-02 -0.694257
2019-11-08 03:52:35,273 train 750 1.675487e-02 -0.697450
2019-11-08 03:52:45,049 train 800 1.674089e-02 -0.712979
2019-11-08 03:52:54,817 train 850 1.675623e-02 -0.697826
2019-11-08 03:52:57,746 training loss; R2: 1.675903e-02 -0.691178
2019-11-08 03:52:58,400 valid 000 1.802788e-02 0.087738
2019-11-08 03:53:07,876 valid 050 1.545740e-02 -0.979411
2019-11-08 03:53:16,244 validation loss; R2: 1.564179e-02 -2.596349
2019-11-08 03:53:16,327 epoch 801 lr 1.000000e-05
2019-11-08 03:53:17,221 train 000 1.609239e-02 -0.473193
2019-11-08 03:53:27,187 train 050 1.660659e-02 -0.814585
2019-11-08 03:53:37,168 train 100 1.669165e-02 -0.924732
2019-11-08 03:53:47,095 train 150 1.682671e-02 -0.822430
2019-11-08 03:53:56,868 train 200 1.686550e-02 -0.759501
2019-11-08 03:54:06,683 train 250 1.678918e-02 -0.744228
2019-11-08 03:54:16,470 train 300 1.673155e-02 -0.882251
2019-11-08 03:54:26,267 train 350 1.669010e-02 -0.938181
2019-11-08 03:54:36,066 train 400 1.667900e-02 -0.939807
2019-11-08 03:54:45,886 train 450 1.668969e-02 -0.897515
2019-11-08 03:54:55,687 train 500 1.670837e-02 -0.881854
2019-11-08 03:55:05,485 train 550 1.669632e-02 -0.848714
2019-11-08 03:55:15,300 train 600 1.676598e-02 -0.853472
2019-11-08 03:55:25,097 train 650 1.680482e-02 -0.819158
2019-11-08 03:55:34,888 train 700 1.681669e-02 -0.812543
2019-11-08 03:55:44,675 train 750 1.678648e-02 -0.806227
2019-11-08 03:55:54,477 train 800 1.680753e-02 -0.787849
2019-11-08 03:56:04,281 train 850 1.682400e-02 -0.773638
2019-11-08 03:56:07,209 training loss; R2: 1.683542e-02 -0.772086
2019-11-08 03:56:07,914 valid 000 1.629320e-02 -0.372990
2019-11-08 03:56:17,281 valid 050 1.515320e-02 -1.387720
2019-11-08 03:56:25,770 validation loss; R2: 1.513775e-02 -1.202623
2019-11-08 03:56:25,855 epoch 802 lr 1.000000e-05
2019-11-08 03:56:26,636 train 000 1.797311e-02 -0.219398
2019-11-08 03:56:36,365 train 050 1.679508e-02 -0.791966
2019-11-08 03:56:46,140 train 100 1.689737e-02 -1.126973
2019-11-08 03:56:55,918 train 150 1.694141e-02 -0.943037
2019-11-08 03:57:05,720 train 200 1.688392e-02 -0.926113
2019-11-08 03:57:15,546 train 250 1.686001e-02 -0.908236
2019-11-08 03:57:25,369 train 300 1.684373e-02 -0.888537
2019-11-08 03:57:35,198 train 350 1.682928e-02 -0.865904
2019-11-08 03:57:45,011 train 400 1.678651e-02 -0.850744
2019-11-08 03:57:54,801 train 450 1.679471e-02 -0.840429
2019-11-08 03:58:04,601 train 500 1.678121e-02 -0.802519
2019-11-08 03:58:14,400 train 550 1.675272e-02 -0.816655
2019-11-08 03:58:24,197 train 600 1.675703e-02 -0.804095
2019-11-08 03:58:34,000 train 650 1.676121e-02 -0.800493
2019-11-08 03:58:43,797 train 700 1.676954e-02 -0.793130
2019-11-08 03:58:53,596 train 750 1.677953e-02 -0.788907
2019-11-08 03:59:03,393 train 800 1.676448e-02 -0.806275
2019-11-08 03:59:13,198 train 850 1.677382e-02 -0.807555
2019-11-08 03:59:16,128 training loss; R2: 1.677488e-02 -0.802321
2019-11-08 03:59:16,808 valid 000 1.580776e-02 -0.632834
2019-11-08 03:59:26,210 valid 050 1.492639e-02 -1.234120
2019-11-08 03:59:34,525 validation loss; R2: 1.520812e-02 -1.434133
2019-11-08 03:59:34,591 epoch 803 lr 1.000000e-05
2019-11-08 03:59:35,349 train 000 1.915776e-02 -0.749655
2019-11-08 03:59:45,080 train 050 1.652693e-02 -1.193800
2019-11-08 03:59:54,822 train 100 1.661254e-02 -1.050002
2019-11-08 04:00:04,583 train 150 1.670071e-02 -0.959134
2019-11-08 04:00:14,361 train 200 1.684283e-02 -0.867687
2019-11-08 04:00:24,145 train 250 1.677733e-02 -0.823187
2019-11-08 04:00:33,946 train 300 1.677336e-02 -0.804721
2019-11-08 04:00:43,761 train 350 1.678376e-02 -0.802428
2019-11-08 04:00:53,572 train 400 1.684608e-02 -0.772832
2019-11-08 04:01:03,372 train 450 1.679741e-02 -0.785973
2019-11-08 04:01:13,195 train 500 1.679812e-02 -28.231008
2019-11-08 04:01:23,016 train 550 1.677966e-02 -25.735192
2019-11-08 04:01:32,836 train 600 1.677930e-02 -23.656301
2019-11-08 04:01:42,653 train 650 1.676818e-02 -21.881707
2019-11-08 04:01:52,466 train 700 1.675730e-02 -20.362359
2019-11-08 04:02:02,262 train 750 1.675762e-02 -19.040161
2019-11-08 04:02:12,072 train 800 1.677093e-02 -17.907726
2019-11-08 04:02:21,855 train 850 1.677849e-02 -16.899213
2019-11-08 04:02:24,812 training loss; R2: 1.677962e-02 -16.618732
2019-11-08 04:02:25,421 valid 000 1.899848e-02 -0.201925
2019-11-08 04:02:34,905 valid 050 2.187668e-02 -2.437860
2019-11-08 04:02:43,253 validation loss; R2: 2.216696e-02 -2.391459
2019-11-08 04:02:43,332 epoch 804 lr 1.000000e-05
2019-11-08 04:02:44,110 train 000 1.821930e-02 -0.597825
2019-11-08 04:02:53,801 train 050 1.673088e-02 -0.637418
2019-11-08 04:03:03,482 train 100 1.684405e-02 -0.577630
2019-11-08 04:03:13,199 train 150 1.669840e-02 -0.641564
2019-11-08 04:03:22,928 train 200 1.666334e-02 -0.658299
2019-11-08 04:03:32,642 train 250 1.666524e-02 -0.661123
2019-11-08 04:03:42,368 train 300 1.678183e-02 -0.617093
2019-11-08 04:03:52,122 train 350 1.680763e-02 -0.594646
2019-11-08 04:04:01,873 train 400 1.677783e-02 -14.282261
2019-11-08 04:04:11,623 train 450 1.679417e-02 -12.814690
2019-11-08 04:04:21,383 train 500 1.680432e-02 -11.619160
2019-11-08 04:04:31,135 train 550 1.679153e-02 -10.647570
2019-11-08 04:04:40,884 train 600 1.678612e-02 -9.800892
2019-11-08 04:04:50,621 train 650 1.676819e-02 -9.092182
2019-11-08 04:05:00,370 train 700 1.675634e-02 -8.494954
2019-11-08 04:05:10,126 train 750 1.674161e-02 -7.970970
2019-11-08 04:05:19,875 train 800 1.674106e-02 -7.550263
2019-11-08 04:05:29,614 train 850 1.673757e-02 -7.141535
2019-11-08 04:05:32,527 training loss; R2: 1.672199e-02 -7.034570
2019-11-08 04:05:33,231 valid 000 1.807044e-02 -0.812753
2019-11-08 04:05:42,601 valid 050 1.470997e-02 -1.461612
2019-11-08 04:05:50,945 validation loss; R2: 1.482123e-02 -1.333572
2019-11-08 04:05:51,009 epoch 805 lr 1.000000e-05
2019-11-08 04:05:51,720 train 000 1.488307e-02 -9.910688
2019-11-08 04:06:01,416 train 050 1.721474e-02 -0.887589
2019-11-08 04:06:11,096 train 100 1.708290e-02 -0.714655
2019-11-08 04:06:20,801 train 150 1.712014e-02 -0.730385
2019-11-08 04:06:30,516 train 200 1.703786e-02 -0.767167
2019-11-08 04:06:40,231 train 250 1.702012e-02 -0.693570
2019-11-08 04:06:49,963 train 300 1.699627e-02 -0.695862
2019-11-08 04:06:59,740 train 350 1.703336e-02 -0.687924
2019-11-08 04:07:09,520 train 400 1.698045e-02 -0.710729
2019-11-08 04:07:19,310 train 450 1.691663e-02 -0.710951
2019-11-08 04:07:29,120 train 500 1.694288e-02 -0.732103
2019-11-08 04:07:38,902 train 550 1.693623e-02 -0.749576
2019-11-08 04:07:48,688 train 600 1.691735e-02 -0.772137
2019-11-08 04:07:58,474 train 650 1.689105e-02 -0.763667
2019-11-08 04:08:08,274 train 700 1.686465e-02 -0.774070
2019-11-08 04:08:18,061 train 750 1.686755e-02 -0.800687
2019-11-08 04:08:27,865 train 800 1.684745e-02 -0.804080
2019-11-08 04:08:37,675 train 850 1.682829e-02 -0.825251
2019-11-08 04:08:40,617 training loss; R2: 1.682394e-02 -0.823664
2019-11-08 04:08:41,247 valid 000 1.791822e-02 -0.088545
2019-11-08 04:08:50,698 valid 050 1.604228e-02 -1.175856
2019-11-08 04:08:59,009 validation loss; R2: 1.624273e-02 -1.057566
2019-11-08 04:08:59,087 epoch 806 lr 1.000000e-05
2019-11-08 04:08:59,885 train 000 1.477351e-02 -0.143217
2019-11-08 04:09:09,609 train 050 1.691587e-02 -0.725080
2019-11-08 04:09:19,352 train 100 1.698346e-02 -0.819464
2019-11-08 04:09:29,119 train 150 1.689361e-02 -0.799011
2019-11-08 04:09:38,889 train 200 1.680045e-02 -0.902714
2019-11-08 04:09:48,631 train 250 1.681853e-02 -0.856032
2019-11-08 04:09:58,373 train 300 1.691458e-02 -0.802009
2019-11-08 04:10:08,106 train 350 1.693214e-02 -0.759335
2019-11-08 04:10:17,887 train 400 1.694976e-02 -0.750749
2019-11-08 04:10:27,654 train 450 1.694297e-02 -0.742125
2019-11-08 04:10:37,440 train 500 1.689353e-02 -0.750665
2019-11-08 04:10:47,220 train 550 1.686745e-02 -0.756478
2019-11-08 04:10:57,023 train 600 1.685538e-02 -0.735105
2019-11-08 04:11:06,813 train 650 1.684268e-02 -0.745107
2019-11-08 04:11:16,614 train 700 1.684477e-02 -0.725821
2019-11-08 04:11:26,393 train 750 1.683055e-02 -0.731324
2019-11-08 04:11:36,184 train 800 1.681407e-02 -0.748897
2019-11-08 04:11:45,977 train 850 1.681629e-02 -0.735727
2019-11-08 04:11:48,910 training loss; R2: 1.680562e-02 -0.740733
2019-11-08 04:11:49,550 valid 000 1.778449e-02 0.106959
2019-11-08 04:11:58,972 valid 050 1.528648e-02 -0.996102
2019-11-08 04:12:07,318 validation loss; R2: 1.514740e-02 -0.873268
2019-11-08 04:12:07,384 epoch 807 lr 1.000000e-05
2019-11-08 04:12:08,123 train 000 1.461278e-02 0.003235
2019-11-08 04:12:17,877 train 050 1.649516e-02 -0.567558
2019-11-08 04:12:27,628 train 100 1.678212e-02 -0.560934
2019-11-08 04:12:37,392 train 150 1.676004e-02 -0.563549
2019-11-08 04:12:47,165 train 200 1.674083e-02 -0.551784
2019-11-08 04:12:56,923 train 250 1.678711e-02 -0.535177
2019-11-08 04:13:06,693 train 300 1.676109e-02 -0.539364
2019-11-08 04:13:16,477 train 350 1.676397e-02 -0.580289
2019-11-08 04:13:26,247 train 400 1.676908e-02 -0.594171
2019-11-08 04:13:36,021 train 450 1.674464e-02 -0.598727
2019-11-08 04:13:45,806 train 500 1.678886e-02 -0.626965
2019-11-08 04:13:55,584 train 550 1.678624e-02 -0.650783
2019-11-08 04:14:05,665 train 600 1.677540e-02 -0.740021
2019-11-08 04:14:15,828 train 650 1.674762e-02 -0.734018
2019-11-08 04:14:25,974 train 700 1.675958e-02 -0.739006
2019-11-08 04:14:36,179 train 750 1.677139e-02 -0.746521
2019-11-08 04:14:46,368 train 800 1.678344e-02 -0.746506
2019-11-08 04:14:56,562 train 850 1.678686e-02 -0.739010
2019-11-08 04:14:59,599 training loss; R2: 1.678595e-02 -0.738500
2019-11-08 04:15:00,285 valid 000 1.470250e-02 -0.138786
2019-11-08 04:15:09,678 valid 050 1.440627e-02 -0.739771
2019-11-08 04:15:17,984 validation loss; R2: 1.445697e-02 -0.893081
2019-11-08 04:15:18,052 epoch 808 lr 1.000000e-05
2019-11-08 04:15:18,842 train 000 1.949966e-02 -2.022036
2019-11-08 04:15:28,950 train 050 1.739253e-02 -0.830330
2019-11-08 04:15:39,072 train 100 1.717011e-02 -0.838123
2019-11-08 04:15:49,190 train 150 1.704651e-02 -0.785151
2019-11-08 04:15:59,333 train 200 1.689260e-02 -0.764997
2019-11-08 04:16:09,477 train 250 1.695403e-02 -0.738354
2019-11-08 04:16:19,639 train 300 1.692257e-02 -0.727457
2019-11-08 04:16:29,795 train 350 1.691163e-02 -0.749727
2019-11-08 04:16:39,641 train 400 1.683782e-02 -0.716807
2019-11-08 04:16:49,434 train 450 1.684123e-02 -0.710055
2019-11-08 04:16:59,222 train 500 1.682107e-02 -0.695618
2019-11-08 04:17:09,022 train 550 1.682369e-02 -0.688567
2019-11-08 04:17:18,824 train 600 1.681380e-02 -1.066528
2019-11-08 04:17:28,623 train 650 1.680529e-02 -1.035702
2019-11-08 04:17:38,442 train 700 1.680772e-02 -1.021421
2019-11-08 04:17:48,251 train 750 1.682257e-02 -0.996744
2019-11-08 04:17:58,065 train 800 1.681685e-02 -0.975995
2019-11-08 04:18:07,883 train 850 1.680214e-02 -0.980336
2019-11-08 04:18:10,810 training loss; R2: 1.679873e-02 -0.974849
2019-11-08 04:18:11,480 valid 000 1.898054e-02 -0.845672
2019-11-08 04:18:20,932 valid 050 1.771832e-02 -0.987006
2019-11-08 04:18:29,224 validation loss; R2: 1.760913e-02 -1.211941
2019-11-08 04:18:29,290 epoch 809 lr 1.000000e-05
2019-11-08 04:18:30,030 train 000 1.772630e-02 -0.874644
2019-11-08 04:18:39,770 train 050 1.691346e-02 -0.678513
2019-11-08 04:18:49,522 train 100 1.665044e-02 -0.825049
2019-11-08 04:18:59,287 train 150 1.661600e-02 -0.743123
2019-11-08 04:19:09,054 train 200 1.662951e-02 -0.816061
2019-11-08 04:19:18,848 train 250 1.670211e-02 -0.765229
2019-11-08 04:19:28,644 train 300 1.670096e-02 -0.775068
2019-11-08 04:19:38,462 train 350 1.671879e-02 -0.764694
2019-11-08 04:19:48,257 train 400 1.670140e-02 -1.063783
2019-11-08 04:19:58,050 train 450 1.668494e-02 -1.044832
2019-11-08 04:20:07,851 train 500 1.667330e-02 -0.999648
2019-11-08 04:20:17,650 train 550 1.668411e-02 -1.024141
2019-11-08 04:20:27,448 train 600 1.669862e-02 -1.287105
2019-11-08 04:20:37,262 train 650 1.672349e-02 -1.477513
2019-11-08 04:20:47,067 train 700 1.674713e-02 -1.443920
2019-11-08 04:20:56,859 train 750 1.677645e-02 -1.466612
2019-11-08 04:21:06,665 train 800 1.676761e-02 -1.432698
2019-11-08 04:21:16,478 train 850 1.678290e-02 -1.377666
2019-11-08 04:21:19,441 training loss; R2: 1.677454e-02 -1.359013
2019-11-08 04:21:20,048 valid 000 1.498990e-02 -1.140575
2019-11-08 04:21:29,561 valid 050 1.571800e-02 -1.021786
2019-11-08 04:21:37,855 validation loss; R2: 1.557707e-02 -1.045910
2019-11-08 04:21:37,933 epoch 810 lr 1.000000e-05
2019-11-08 04:21:38,749 train 000 1.671547e-02 -0.257555
2019-11-08 04:21:48,518 train 050 1.662948e-02 -0.975571
2019-11-08 04:21:58,313 train 100 1.683157e-02 -0.880682
2019-11-08 04:22:08,111 train 150 1.668991e-02 -1.465875
2019-11-08 04:22:17,925 train 200 1.684434e-02 -1.228176
2019-11-08 04:22:27,721 train 250 1.689812e-02 -1.124666
2019-11-08 04:22:37,517 train 300 1.687923e-02 -1.074022
2019-11-08 04:22:47,328 train 350 1.684050e-02 -1.014342
2019-11-08 04:22:57,154 train 400 1.681028e-02 -1.000352
2019-11-08 04:23:06,965 train 450 1.682096e-02 -0.986211
2019-11-08 04:23:16,788 train 500 1.679731e-02 -0.951498
2019-11-08 04:23:26,598 train 550 1.680510e-02 -0.933910
2019-11-08 04:23:36,398 train 600 1.678505e-02 -0.918469
2019-11-08 04:23:46,209 train 650 1.680113e-02 -0.898354
2019-11-08 04:23:56,018 train 700 1.678923e-02 -0.874664
2019-11-08 04:24:05,811 train 750 1.680158e-02 -0.862364
2019-11-08 04:24:15,595 train 800 1.679151e-02 -0.855480
2019-11-08 04:24:25,385 train 850 1.677661e-02 -0.834086
2019-11-08 04:24:28,309 training loss; R2: 1.678027e-02 -0.829514
2019-11-08 04:24:28,957 valid 000 1.802713e-02 -1.637352
2019-11-08 04:24:38,396 valid 050 1.616596e-02 -0.817206
2019-11-08 04:24:46,718 validation loss; R2: 1.604483e-02 -0.877388
2019-11-08 04:24:46,782 epoch 811 lr 1.000000e-05
2019-11-08 04:24:47,510 train 000 1.747970e-02 -1.462953
2019-11-08 04:24:57,254 train 050 1.716728e-02 -1.089844
2019-11-08 04:25:06,997 train 100 1.704606e-02 -0.846912
2019-11-08 04:25:16,745 train 150 1.691652e-02 -0.707419
2019-11-08 04:25:26,522 train 200 1.693948e-02 -0.719285
2019-11-08 04:25:36,307 train 250 1.688150e-02 -0.742863
2019-11-08 04:25:46,112 train 300 1.684827e-02 -0.707137
2019-11-08 04:25:55,915 train 350 1.682543e-02 -0.677265
2019-11-08 04:26:05,720 train 400 1.680386e-02 -0.734509
2019-11-08 04:26:15,513 train 450 1.674722e-02 -0.747561
2019-11-08 04:26:25,305 train 500 1.675949e-02 -0.737498
2019-11-08 04:26:35,093 train 550 1.673254e-02 -0.715426
2019-11-08 04:26:44,884 train 600 1.675360e-02 -0.714125
2019-11-08 04:26:54,677 train 650 1.674961e-02 -0.702759
2019-11-08 04:27:04,485 train 700 1.675569e-02 -0.694760
2019-11-08 04:27:14,290 train 750 1.673622e-02 -0.795955
2019-11-08 04:27:24,098 train 800 1.674844e-02 -0.792803
2019-11-08 04:27:33,901 train 850 1.674691e-02 -0.791557
2019-11-08 04:27:36,829 training loss; R2: 1.674530e-02 -0.800716
2019-11-08 04:27:37,472 valid 000 1.637089e-02 -0.762615
2019-11-08 04:27:46,935 valid 050 1.471177e-02 -1.037149
2019-11-08 04:27:55,276 validation loss; R2: 1.498725e-02 -1.170792
2019-11-08 04:27:55,342 epoch 812 lr 1.000000e-05
2019-11-08 04:27:56,095 train 000 1.617312e-02 -0.499135
2019-11-08 04:28:05,818 train 050 1.690904e-02 -0.640201
2019-11-08 04:28:15,564 train 100 1.692513e-02 -0.588146
2019-11-08 04:28:25,368 train 150 1.695328e-02 -8.912101
2019-11-08 04:28:35,138 train 200 1.680181e-02 -6.896697
2019-11-08 04:28:44,924 train 250 1.675268e-02 -5.650663
2019-11-08 04:28:54,710 train 300 1.682384e-02 -4.845770
2019-11-08 04:29:04,489 train 350 1.676246e-02 -4.282762
2019-11-08 04:29:14,254 train 400 1.674370e-02 -3.810866
2019-11-08 04:29:24,022 train 450 1.674665e-02 -3.479249
2019-11-08 04:29:33,797 train 500 1.677524e-02 -3.221178
2019-11-08 04:29:43,580 train 550 1.676366e-02 -2.981415
2019-11-08 04:29:53,362 train 600 1.674902e-02 -2.831627
2019-11-08 04:30:03,146 train 650 1.673609e-02 -2.701456
2019-11-08 04:30:12,917 train 700 1.673518e-02 -2.559506
2019-11-08 04:30:22,706 train 750 1.674294e-02 -2.444887
2019-11-08 04:30:32,485 train 800 1.674927e-02 -2.348943
2019-11-08 04:30:42,268 train 850 1.676652e-02 -2.261242
2019-11-08 04:30:45,204 training loss; R2: 1.677484e-02 -2.234119
2019-11-08 04:30:45,863 valid 000 1.482250e-02 0.015955
2019-11-08 04:30:55,281 valid 050 1.514047e-02 -0.981238
2019-11-08 04:31:03,608 validation loss; R2: 1.515996e-02 -0.919067
2019-11-08 04:31:03,674 epoch 813 lr 1.000000e-05
2019-11-08 04:31:04,466 train 000 1.710916e-02 -0.273976
2019-11-08 04:31:14,215 train 050 1.688647e-02 -0.967848
2019-11-08 04:31:23,968 train 100 1.677226e-02 -0.898977
2019-11-08 04:31:33,719 train 150 1.663038e-02 -0.825394
2019-11-08 04:31:43,485 train 200 1.672266e-02 -0.823997
2019-11-08 04:31:53,277 train 250 1.682769e-02 -0.778807
2019-11-08 04:32:03,065 train 300 1.682971e-02 -0.752278
2019-11-08 04:32:12,840 train 350 1.674678e-02 -0.883186
2019-11-08 04:32:22,620 train 400 1.675130e-02 -0.876403
2019-11-08 04:32:32,404 train 450 1.677773e-02 -0.871741
2019-11-08 04:32:42,172 train 500 1.677441e-02 -0.868314
2019-11-08 04:32:51,945 train 550 1.677678e-02 -0.866953
2019-11-08 04:33:01,718 train 600 1.676769e-02 -0.838397
2019-11-08 04:33:11,498 train 650 1.675304e-02 -0.850141
2019-11-08 04:33:21,285 train 700 1.677682e-02 -0.840625
2019-11-08 04:33:31,071 train 750 1.678716e-02 -0.971311
2019-11-08 04:33:40,847 train 800 1.683224e-02 -0.965828
2019-11-08 04:33:50,623 train 850 1.682254e-02 -0.969434
2019-11-08 04:33:53,548 training loss; R2: 1.683498e-02 -0.965459
2019-11-08 04:33:54,146 valid 000 1.662799e-02 0.047676
2019-11-08 04:34:03,576 valid 050 1.484208e-02 -0.762951
2019-11-08 04:34:11,890 validation loss; R2: 1.452052e-02 -1.018193
2019-11-08 04:34:11,954 epoch 814 lr 1.000000e-05
2019-11-08 04:34:12,724 train 000 1.600824e-02 -0.677773
2019-11-08 04:34:22,457 train 050 1.695260e-02 -0.778174
2019-11-08 04:34:32,196 train 100 1.678324e-02 -0.853153
2019-11-08 04:34:41,949 train 150 1.665112e-02 -0.965898
2019-11-08 04:34:51,726 train 200 1.663400e-02 -0.866910
2019-11-08 04:35:01,492 train 250 1.670356e-02 -0.854159
2019-11-08 04:35:11,268 train 300 1.666070e-02 -0.855910
2019-11-08 04:35:21,039 train 350 1.669424e-02 -0.878724
2019-11-08 04:35:30,808 train 400 1.673292e-02 -0.835450
2019-11-08 04:35:40,584 train 450 1.679918e-02 -0.822977
2019-11-08 04:35:50,379 train 500 1.682558e-02 -0.828775
2019-11-08 04:36:00,158 train 550 1.684647e-02 -0.799409
2019-11-08 04:36:09,932 train 600 1.682603e-02 -0.796780
2019-11-08 04:36:19,713 train 650 1.685536e-02 -0.797623
2019-11-08 04:36:29,486 train 700 1.680977e-02 -0.774960
2019-11-08 04:36:39,270 train 750 1.681688e-02 -0.780877
2019-11-08 04:36:49,038 train 800 1.680507e-02 -0.782031
2019-11-08 04:36:58,827 train 850 1.680045e-02 -0.778457
2019-11-08 04:37:01,756 training loss; R2: 1.680312e-02 -0.786584
2019-11-08 04:37:02,443 valid 000 1.506922e-02 -0.646628
2019-11-08 04:37:11,819 valid 050 1.817475e-02 -1.365093
2019-11-08 04:37:20,143 validation loss; R2: 1.789222e-02 -1.441944
2019-11-08 04:37:20,208 epoch 815 lr 1.000000e-05
2019-11-08 04:37:20,978 train 000 1.483366e-02 0.006441
2019-11-08 04:37:30,712 train 050 1.714119e-02 -0.394055
2019-11-08 04:37:40,474 train 100 1.706430e-02 -0.544866
2019-11-08 04:37:50,241 train 150 1.705571e-02 -0.578924
2019-11-08 04:38:00,011 train 200 1.688581e-02 -0.647345
2019-11-08 04:38:09,785 train 250 1.684614e-02 -0.691397
2019-11-08 04:38:19,550 train 300 1.685409e-02 -0.681295
2019-11-08 04:38:29,321 train 350 1.684311e-02 -0.681077
2019-11-08 04:38:39,098 train 400 1.685551e-02 -0.696675
2019-11-08 04:38:48,873 train 450 1.682386e-02 -0.697163
2019-11-08 04:38:58,655 train 500 1.681318e-02 -0.693049
2019-11-08 04:39:08,435 train 550 1.684169e-02 -0.732269
2019-11-08 04:39:18,227 train 600 1.683970e-02 -0.729913
2019-11-08 04:39:28,006 train 650 1.685503e-02 -0.727418
2019-11-08 04:39:37,793 train 700 1.684527e-02 -0.737270
2019-11-08 04:39:47,590 train 750 1.685767e-02 -0.751299
2019-11-08 04:39:57,393 train 800 1.686401e-02 -0.744524
2019-11-08 04:40:07,200 train 850 1.683707e-02 -0.749758
2019-11-08 04:40:10,137 training loss; R2: 1.683374e-02 -0.752747
2019-11-08 04:40:10,727 valid 000 1.851526e-02 -0.299911
2019-11-08 04:40:20,182 valid 050 2.345323e-02 -2.989898
2019-11-08 04:40:28,640 validation loss; R2: 2.346042e-02 -3.023341
2019-11-08 04:40:28,719 epoch 816 lr 1.000000e-05
2019-11-08 04:40:29,529 train 000 1.555359e-02 -0.490998
2019-11-08 04:40:39,270 train 050 1.687999e-02 -0.686761
2019-11-08 04:40:49,034 train 100 1.677131e-02 -0.646690
2019-11-08 04:40:58,807 train 150 1.665355e-02 -0.716261
2019-11-08 04:41:08,579 train 200 1.678252e-02 -0.712858
2019-11-08 04:41:18,354 train 250 1.675276e-02 -0.719987
2019-11-08 04:41:28,128 train 300 1.679257e-02 -0.757793
2019-11-08 04:41:37,912 train 350 1.677526e-02 -0.738493
2019-11-08 04:41:47,683 train 400 1.678770e-02 -0.753699
2019-11-08 04:41:57,461 train 450 1.678470e-02 -0.765677
2019-11-08 04:42:07,230 train 500 1.675204e-02 -0.751020
2019-11-08 04:42:17,004 train 550 1.678227e-02 -0.756659
2019-11-08 04:42:26,785 train 600 1.674243e-02 -0.757012
2019-11-08 04:42:36,571 train 650 1.671006e-02 -0.742093
2019-11-08 04:42:46,363 train 700 1.670667e-02 -0.746576
2019-11-08 04:42:56,142 train 750 1.671758e-02 -0.731489
2019-11-08 04:43:05,923 train 800 1.670223e-02 -0.714307
2019-11-08 04:43:15,709 train 850 1.672424e-02 -0.713546
2019-11-08 04:43:18,673 training loss; R2: 1.671942e-02 -0.712706
2019-11-08 04:43:19,276 valid 000 1.604742e-02 -2.746658
2019-11-08 04:43:28,735 valid 050 1.446758e-02 -1.238586
2019-11-08 04:43:37,026 validation loss; R2: 1.452006e-02 -1.058816
2019-11-08 04:43:37,103 epoch 817 lr 1.000000e-05
2019-11-08 04:43:37,895 train 000 1.443675e-02 -0.471981
2019-11-08 04:43:48,021 train 050 1.688718e-02 -0.631199
2019-11-08 04:43:58,171 train 100 1.690266e-02 -0.890667
2019-11-08 04:44:08,337 train 150 1.687739e-02 -1.008211
2019-11-08 04:44:18,512 train 200 1.682006e-02 -0.944275
2019-11-08 04:44:28,654 train 250 1.684114e-02 -0.863864
2019-11-08 04:44:38,794 train 300 1.682007e-02 -0.810883
2019-11-08 04:44:48,949 train 350 1.681300e-02 -0.933332
2019-11-08 04:44:59,090 train 400 1.677581e-02 -0.916192
2019-11-08 04:45:09,244 train 450 1.673523e-02 -0.883929
2019-11-08 04:45:19,411 train 500 1.678035e-02 -0.867046
2019-11-08 04:45:29,560 train 550 1.677257e-02 -1.149088
2019-11-08 04:45:39,714 train 600 1.681467e-02 -1.097864
2019-11-08 04:45:49,894 train 650 1.682175e-02 -1.083765
2019-11-08 04:46:00,074 train 700 1.682717e-02 -1.068467
2019-11-08 04:46:10,238 train 750 1.684195e-02 -1.062861
2019-11-08 04:46:20,396 train 800 1.685248e-02 -1.047488
2019-11-08 04:46:30,533 train 850 1.684593e-02 -1.031904
2019-11-08 04:46:33,563 training loss; R2: 1.684280e-02 -1.023167
2019-11-08 04:46:34,242 valid 000 2.171156e-02 -0.193537
2019-11-08 04:46:43,638 valid 050 2.121966e-02 -1.100011
2019-11-08 04:46:51,980 validation loss; R2: 2.126711e-02 -1.195935
2019-11-08 04:46:52,050 epoch 818 lr 1.000000e-05
2019-11-08 04:46:52,807 train 000 1.642020e-02 -0.840972
2019-11-08 04:47:02,949 train 050 1.675341e-02 -0.777037
2019-11-08 04:47:13,089 train 100 1.681650e-02 -0.814872
2019-11-08 04:47:23,219 train 150 1.687081e-02 -0.810589
2019-11-08 04:47:33,377 train 200 1.694560e-02 -0.750077
2019-11-08 04:47:43,546 train 250 1.698938e-02 -0.773996
2019-11-08 04:47:53,710 train 300 1.693246e-02 -0.742695
2019-11-08 04:48:03,863 train 350 1.692993e-02 -0.724104
2019-11-08 04:48:14,024 train 400 1.687829e-02 -0.761802
2019-11-08 04:48:24,195 train 450 1.685217e-02 -0.724044
2019-11-08 04:48:34,373 train 500 1.678029e-02 -0.739208
2019-11-08 04:48:44,536 train 550 1.676872e-02 -0.734194
2019-11-08 04:48:54,698 train 600 1.675107e-02 -0.729633
2019-11-08 04:49:04,887 train 650 1.677602e-02 -0.725202
2019-11-08 04:49:15,065 train 700 1.677013e-02 -0.730240
2019-11-08 04:49:25,221 train 750 1.678592e-02 -0.722134
2019-11-08 04:49:35,403 train 800 1.680375e-02 -0.805991
2019-11-08 04:49:45,568 train 850 1.679783e-02 -0.789266
2019-11-08 04:49:48,616 training loss; R2: 1.679777e-02 -0.794596
2019-11-08 04:49:49,298 valid 000 1.765501e-02 -0.243297
2019-11-08 04:49:58,679 valid 050 1.520563e-02 -0.728505
2019-11-08 04:50:07,116 validation loss; R2: 1.524557e-02 -0.921174
2019-11-08 04:50:07,182 epoch 819 lr 1.000000e-05
2019-11-08 04:50:07,983 train 000 1.591491e-02 -0.130026
2019-11-08 04:50:18,088 train 050 1.702460e-02 -0.875776
2019-11-08 04:50:28,219 train 100 1.673263e-02 -0.850032
2019-11-08 04:50:38,354 train 150 1.679275e-02 -0.942715
2019-11-08 04:50:48,485 train 200 1.681724e-02 -2.711453
2019-11-08 04:50:58,636 train 250 1.682842e-02 -2.316120
2019-11-08 04:51:08,772 train 300 1.677453e-02 -2.054475
2019-11-08 04:51:18,941 train 350 1.681274e-02 -1.848112
2019-11-08 04:51:29,085 train 400 1.678206e-02 -1.686115
2019-11-08 04:51:39,247 train 450 1.679670e-02 -1.564549
2019-11-08 04:51:49,389 train 500 1.678613e-02 -1.463821
2019-11-08 04:51:59,536 train 550 1.672264e-02 -1.403673
2019-11-08 04:52:09,706 train 600 1.675137e-02 -1.337391
2019-11-08 04:52:19,855 train 650 1.675186e-02 -1.298455
2019-11-08 04:52:30,005 train 700 1.675001e-02 -1.269545
2019-11-08 04:52:40,147 train 750 1.676209e-02 -1.237793
2019-11-08 04:52:50,282 train 800 1.676038e-02 -1.210191
2019-11-08 04:53:00,443 train 850 1.674649e-02 -1.177773
2019-11-08 04:53:03,475 training loss; R2: 1.675980e-02 -1.164369
2019-11-08 04:53:04,148 valid 000 2.062119e-02 -0.416193
2019-11-08 04:53:13,557 valid 050 2.331108e-02 -1.867492
2019-11-08 04:53:21,905 validation loss; R2: 2.345333e-02 -2.102488
2019-11-08 04:53:21,980 epoch 820 lr 1.000000e-05
2019-11-08 04:53:22,730 train 000 1.575128e-02 -0.160747
2019-11-08 04:53:32,860 train 050 1.642691e-02 -0.703834
2019-11-08 04:53:42,998 train 100 1.661847e-02 -0.596213
2019-11-08 04:53:53,149 train 150 1.675278e-02 -0.633599
2019-11-08 04:54:03,302 train 200 1.673331e-02 -0.573350
2019-11-08 04:54:13,462 train 250 1.665030e-02 -0.630352
2019-11-08 04:54:23,603 train 300 1.670024e-02 -0.596372
2019-11-08 04:54:33,745 train 350 1.666693e-02 -0.599901
2019-11-08 04:54:43,912 train 400 1.670040e-02 -0.624955
2019-11-08 04:54:54,084 train 450 1.675881e-02 -0.628809
2019-11-08 04:55:04,246 train 500 1.677711e-02 -0.626794
2019-11-08 04:55:14,412 train 550 1.672553e-02 -0.622878
2019-11-08 04:55:24,544 train 600 1.673933e-02 -0.620497
2019-11-08 04:55:34,707 train 650 1.675891e-02 -0.621737
2019-11-08 04:55:44,868 train 700 1.675043e-02 -0.628831
2019-11-08 04:55:55,033 train 750 1.676899e-02 -0.648980
2019-11-08 04:56:05,187 train 800 1.677830e-02 -0.641320
2019-11-08 04:56:15,343 train 850 1.676621e-02 -0.655913
2019-11-08 04:56:18,376 training loss; R2: 1.676208e-02 -0.656477
2019-11-08 04:56:19,009 valid 000 1.502036e-02 0.031369
2019-11-08 04:56:28,429 valid 050 1.532212e-02 -0.799990
2019-11-08 04:56:36,745 validation loss; R2: 1.551852e-02 -1.070170
2019-11-08 04:56:36,811 epoch 821 lr 1.000000e-05
2019-11-08 04:56:37,580 train 000 1.728304e-02 -0.273126
2019-11-08 04:56:47,710 train 050 1.659346e-02 -0.861353
2019-11-08 04:56:57,839 train 100 1.683936e-02 -0.772657
2019-11-08 04:57:07,966 train 150 1.671799e-02 -0.763250
2019-11-08 04:57:18,093 train 200 1.674403e-02 -0.771890
2019-11-08 04:57:28,218 train 250 1.673010e-02 -0.726030
2019-11-08 04:57:38,196 train 300 1.669847e-02 -0.715902
2019-11-08 04:57:47,988 train 350 1.672307e-02 -0.748366
2019-11-08 04:57:57,814 train 400 1.677544e-02 -0.728665
2019-11-08 04:58:07,626 train 450 1.679285e-02 -0.733514
2019-11-08 04:58:17,457 train 500 1.679631e-02 -0.735960
2019-11-08 04:58:27,269 train 550 1.678413e-02 -0.737826
2019-11-08 04:58:37,072 train 600 1.676562e-02 -0.733746
2019-11-08 04:58:46,889 train 650 1.677052e-02 -0.737233
2019-11-08 04:58:56,687 train 700 1.674403e-02 -0.750869
2019-11-08 04:59:06,502 train 750 1.673026e-02 -0.737405
2019-11-08 04:59:16,325 train 800 1.675815e-02 -0.767610
2019-11-08 04:59:26,140 train 850 1.676512e-02 -0.755969
2019-11-08 04:59:29,074 training loss; R2: 1.674937e-02 -0.761396
2019-11-08 04:59:29,691 valid 000 1.787781e-02 -0.049256
2019-11-08 04:59:39,121 valid 050 1.613524e-02 -0.465638
2019-11-08 04:59:47,464 validation loss; R2: 1.613070e-02 -0.727540
2019-11-08 04:59:47,529 epoch 822 lr 1.000000e-05
2019-11-08 04:59:48,306 train 000 1.794569e-02 -0.546034
2019-11-08 04:59:58,086 train 050 1.685597e-02 -0.835325
2019-11-08 05:00:07,907 train 100 1.671744e-02 -0.933657
2019-11-08 05:00:17,756 train 150 1.667699e-02 -0.835486
2019-11-08 05:00:27,584 train 200 1.668059e-02 -0.774422
2019-11-08 05:00:37,407 train 250 1.663619e-02 -0.729748
2019-11-08 05:00:47,199 train 300 1.663958e-02 -0.767255
2019-11-08 05:00:56,983 train 350 1.662360e-02 -0.757587
2019-11-08 05:01:06,776 train 400 1.670774e-02 -0.779715
2019-11-08 05:01:16,563 train 450 1.673795e-02 -0.791227
2019-11-08 05:01:26,352 train 500 1.675514e-02 -0.766576
2019-11-08 05:01:36,134 train 550 1.675342e-02 -0.788280
2019-11-08 05:01:45,904 train 600 1.673091e-02 -0.770015
2019-11-08 05:01:55,683 train 650 1.672243e-02 -0.760878
2019-11-08 05:02:05,464 train 700 1.672066e-02 -0.769292
2019-11-08 05:02:15,276 train 750 1.672851e-02 -0.758667
2019-11-08 05:02:25,062 train 800 1.673775e-02 -0.755248
2019-11-08 05:02:34,841 train 850 1.675640e-02 -0.758561
2019-11-08 05:02:37,765 training loss; R2: 1.676720e-02 -0.761214
2019-11-08 05:02:38,392 valid 000 1.625844e-02 -0.142420
2019-11-08 05:02:47,816 valid 050 1.475773e-02 -0.917680
2019-11-08 05:02:56,121 validation loss; R2: 1.473162e-02 -0.896763
2019-11-08 05:02:56,186 epoch 823 lr 1.000000e-05
2019-11-08 05:02:56,966 train 000 1.736245e-02 -1.163489
2019-11-08 05:03:06,751 train 050 1.674579e-02 -0.741498
2019-11-08 05:03:16,578 train 100 1.667642e-02 -0.718757
2019-11-08 05:03:26,393 train 150 1.669782e-02 -0.700021
2019-11-08 05:03:36,204 train 200 1.670540e-02 -0.840723
2019-11-08 05:03:45,999 train 250 1.674281e-02 -0.902462
2019-11-08 05:03:55,825 train 300 1.673913e-02 -0.858821
2019-11-08 05:04:05,631 train 350 1.680735e-02 -0.833600
2019-11-08 05:04:15,439 train 400 1.682993e-02 -0.801073
2019-11-08 05:04:25,254 train 450 1.687050e-02 -0.846973
2019-11-08 05:04:35,063 train 500 1.687134e-02 -0.828655
2019-11-08 05:04:44,902 train 550 1.688074e-02 -0.817439
2019-11-08 05:04:54,720 train 600 1.684992e-02 -0.825607
2019-11-08 05:05:04,522 train 650 1.683400e-02 -0.833459
2019-11-08 05:05:14,331 train 700 1.680772e-02 -0.816170
2019-11-08 05:05:24,164 train 750 1.680381e-02 -0.816815
2019-11-08 05:05:34,002 train 800 1.681119e-02 -0.842758
2019-11-08 05:05:43,844 train 850 1.684094e-02 -0.868010
2019-11-08 05:05:46,782 training loss; R2: 1.683484e-02 -0.861910
2019-11-08 05:05:47,484 valid 000 1.597976e-02 -1.221636
2019-11-08 05:05:56,840 valid 050 1.528240e-02 -0.688762
2019-11-08 05:06:05,248 validation loss; R2: 1.528197e-02 -0.660831
2019-11-08 05:06:05,319 epoch 824 lr 1.000000e-05
2019-11-08 05:06:06,098 train 000 1.711414e-02 -0.207064
2019-11-08 05:06:15,848 train 050 1.713515e-02 -0.493373
2019-11-08 05:06:25,618 train 100 1.678412e-02 -0.581038
2019-11-08 05:06:35,391 train 150 1.673954e-02 -0.604239
2019-11-08 05:06:45,174 train 200 1.680490e-02 -0.689099
2019-11-08 05:06:54,961 train 250 1.678146e-02 -0.683171
2019-11-08 05:07:04,739 train 300 1.674917e-02 -0.714526
2019-11-08 05:07:14,530 train 350 1.676545e-02 -0.696832
2019-11-08 05:07:24,325 train 400 1.680775e-02 -0.755882
2019-11-08 05:07:34,109 train 450 1.679647e-02 -0.762470
2019-11-08 05:07:43,909 train 500 1.685705e-02 -0.745689
2019-11-08 05:07:53,687 train 550 1.683562e-02 -0.738708
2019-11-08 05:08:03,481 train 600 1.682602e-02 -0.721229
2019-11-08 05:08:13,248 train 650 1.680238e-02 -0.718170
2019-11-08 05:08:23,032 train 700 1.680486e-02 -0.704716
2019-11-08 05:08:32,815 train 750 1.680281e-02 -0.711021
2019-11-08 05:08:42,611 train 800 1.679594e-02 -0.705779
2019-11-08 05:08:52,400 train 850 1.678794e-02 -0.721956
2019-11-08 05:08:55,323 training loss; R2: 1.677708e-02 -0.740799
2019-11-08 05:08:55,966 valid 000 3.076191e-02 -3.846320
2019-11-08 05:09:05,368 valid 050 3.043788e-02 -3.749637
2019-11-08 05:09:13,805 validation loss; R2: 3.107496e-02 -3.700882
2019-11-08 05:09:13,887 epoch 825 lr 1.000000e-05
2019-11-08 05:09:14,720 train 000 1.479454e-02 -2.003523
2019-11-08 05:09:24,831 train 050 1.667451e-02 -0.499699
2019-11-08 05:09:34,991 train 100 1.665891e-02 -0.617903
2019-11-08 05:09:45,140 train 150 1.661680e-02 -0.639694
2019-11-08 05:09:55,295 train 200 1.671680e-02 -0.707470
2019-11-08 05:10:05,461 train 250 1.675714e-02 -0.730093
2019-11-08 05:10:15,628 train 300 1.678109e-02 -0.736858
2019-11-08 05:10:25,806 train 350 1.679090e-02 -0.735208
2019-11-08 05:10:35,975 train 400 1.679311e-02 -0.763001
2019-11-08 05:10:46,071 train 450 1.677644e-02 -0.767362
2019-11-08 05:10:55,877 train 500 1.677280e-02 -0.794979
2019-11-08 05:11:05,683 train 550 1.683317e-02 -0.782472
2019-11-08 05:11:15,463 train 600 1.684030e-02 -0.928844
2019-11-08 05:11:25,272 train 650 1.684562e-02 -0.936838
2019-11-08 05:11:35,085 train 700 1.685121e-02 -0.922119
2019-11-08 05:11:44,916 train 750 1.686987e-02 -0.910394
2019-11-08 05:11:54,724 train 800 1.686832e-02 -0.909685
2019-11-08 05:12:04,528 train 850 1.685231e-02 -0.905400
2019-11-08 05:12:07,471 training loss; R2: 1.686505e-02 -0.899256
2019-11-08 05:12:08,158 valid 000 1.581175e-02 -0.786550
2019-11-08 05:12:17,566 valid 050 1.862821e-02 -1.842043
2019-11-08 05:12:25,887 validation loss; R2: 1.882851e-02 -1.522424
2019-11-08 05:12:25,953 epoch 826 lr 1.000000e-05
2019-11-08 05:12:26,737 train 000 1.843572e-02 -1.357191
2019-11-08 05:12:36,466 train 050 1.676701e-02 -0.707836
2019-11-08 05:12:46,258 train 100 1.678163e-02 -0.650900
2019-11-08 05:12:56,338 train 150 1.685656e-02 -0.681697
2019-11-08 05:13:06,191 train 200 1.681209e-02 -0.638549
2019-11-08 05:13:15,999 train 250 1.672707e-02 -0.632798
2019-11-08 05:13:25,819 train 300 1.676616e-02 -0.642541
2019-11-08 05:13:35,640 train 350 1.680580e-02 -0.619787
2019-11-08 05:13:45,463 train 400 1.679779e-02 -0.647240
2019-11-08 05:13:55,293 train 450 1.679048e-02 -0.650802
2019-11-08 05:14:05,123 train 500 1.683380e-02 -0.665070
2019-11-08 05:14:14,948 train 550 1.682134e-02 -0.659450
2019-11-08 05:14:24,780 train 600 1.681535e-02 -0.663132
2019-11-08 05:14:34,599 train 650 1.678727e-02 -0.698849
2019-11-08 05:14:44,426 train 700 1.680889e-02 -0.701447
2019-11-08 05:14:54,238 train 750 1.679430e-02 -0.703737
2019-11-08 05:15:04,049 train 800 1.679073e-02 -0.698297
2019-11-08 05:15:13,860 train 850 1.678186e-02 -0.713324
2019-11-08 05:15:16,790 training loss; R2: 1.677187e-02 -0.712307
2019-11-08 05:15:17,478 valid 000 1.802024e-02 -1.812343
2019-11-08 05:15:26,950 valid 050 1.991693e-02 -3.023669
2019-11-08 05:15:35,291 validation loss; R2: 1.991923e-02 -2.652741
2019-11-08 05:15:35,355 epoch 827 lr 1.000000e-05
2019-11-08 05:15:36,099 train 000 1.803053e-02 -0.223632
2019-11-08 05:15:45,874 train 050 1.690666e-02 -0.602816
2019-11-08 05:15:55,655 train 100 1.680337e-02 -0.745167
2019-11-08 05:16:05,390 train 150 1.672907e-02 -0.661801
2019-11-08 05:16:15,129 train 200 1.669294e-02 -0.621589
2019-11-08 05:16:24,858 train 250 1.672665e-02 -0.627417
2019-11-08 05:16:34,605 train 300 1.675256e-02 -0.658000
2019-11-08 05:16:44,334 train 350 1.680873e-02 -0.636702
2019-11-08 05:16:54,095 train 400 1.683309e-02 -0.625542
2019-11-08 05:17:03,846 train 450 1.682238e-02 -0.645594
2019-11-08 05:17:13,594 train 500 1.679338e-02 -0.630088
2019-11-08 05:17:23,344 train 550 1.678010e-02 -0.651601
2019-11-08 05:17:33,096 train 600 1.678362e-02 -0.654254
2019-11-08 05:17:42,847 train 650 1.676051e-02 -0.650347
2019-11-08 05:17:52,595 train 700 1.676398e-02 -0.704369
2019-11-08 05:18:02,357 train 750 1.675883e-02 -0.688877
2019-11-08 05:18:12,103 train 800 1.676466e-02 -0.716328
2019-11-08 05:18:21,858 train 850 1.675855e-02 -0.718333
2019-11-08 05:18:24,770 training loss; R2: 1.676021e-02 -0.720258
2019-11-08 05:18:25,414 valid 000 2.344311e-02 -0.548286
2019-11-08 05:18:34,846 valid 050 2.211923e-02 -2.388083
2019-11-08 05:18:43,149 validation loss; R2: 2.227958e-02 -2.249984
2019-11-08 05:18:43,213 epoch 828 lr 1.000000e-05
2019-11-08 05:18:43,987 train 000 1.746586e-02 -0.232471
2019-11-08 05:18:53,721 train 050 1.717446e-02 -0.597418
2019-11-08 05:19:03,471 train 100 1.681882e-02 -0.812087
2019-11-08 05:19:13,249 train 150 1.679332e-02 -0.722531
2019-11-08 05:19:23,049 train 200 1.674592e-02 -0.656796
2019-11-08 05:19:32,861 train 250 1.672847e-02 -0.645563
2019-11-08 05:19:42,652 train 300 1.678738e-02 -0.631942
2019-11-08 05:19:52,466 train 350 1.677900e-02 -0.610099
2019-11-08 05:20:02,263 train 400 1.668379e-02 -0.597906
2019-11-08 05:20:12,052 train 450 1.670978e-02 -0.621234
2019-11-08 05:20:21,857 train 500 1.668982e-02 -0.626268
2019-11-08 05:20:31,704 train 550 1.674900e-02 -0.618293
2019-11-08 05:20:41,539 train 600 1.671529e-02 -0.625725
2019-11-08 05:20:51,373 train 650 1.670749e-02 -0.636050
2019-11-08 05:21:01,201 train 700 1.671655e-02 -0.637658
2019-11-08 05:21:11,027 train 750 1.670995e-02 -0.640029
2019-11-08 05:21:20,837 train 800 1.671014e-02 -0.638620
2019-11-08 05:21:30,663 train 850 1.675153e-02 -0.667290
2019-11-08 05:21:33,600 training loss; R2: 1.675188e-02 -0.665644
2019-11-08 05:21:34,287 valid 000 1.453653e-02 -0.616731
2019-11-08 05:21:43,640 valid 050 1.566338e-02 -0.654661
2019-11-08 05:21:51,970 validation loss; R2: 1.541397e-02 -0.786361
2019-11-08 05:21:52,033 epoch 829 lr 1.000000e-05
2019-11-08 05:21:52,816 train 000 1.602461e-02 -0.261610
2019-11-08 05:22:02,594 train 050 1.698773e-02 -0.708363
2019-11-08 05:22:12,410 train 100 1.708238e-02 -0.657795
2019-11-08 05:22:22,217 train 150 1.695440e-02 -0.646107
2019-11-08 05:22:32,040 train 200 1.690922e-02 -0.704273
2019-11-08 05:22:41,846 train 250 1.681632e-02 -0.691794
2019-11-08 05:22:51,674 train 300 1.688228e-02 -0.692944
2019-11-08 05:23:01,504 train 350 1.686414e-02 -0.697357
2019-11-08 05:23:11,319 train 400 1.692081e-02 -0.683992
2019-11-08 05:23:21,138 train 450 1.692241e-02 -0.720677
2019-11-08 05:23:30,970 train 500 1.689105e-02 -0.712579
2019-11-08 05:23:40,776 train 550 1.685068e-02 -0.729585
2019-11-08 05:23:50,600 train 600 1.681728e-02 -0.721545
2019-11-08 05:24:00,429 train 650 1.680384e-02 -0.739238
2019-11-08 05:24:10,259 train 700 1.680912e-02 -0.751637
2019-11-08 05:24:20,087 train 750 1.680198e-02 -0.746526
2019-11-08 05:24:29,915 train 800 1.679292e-02 -0.751917
2019-11-08 05:24:39,748 train 850 1.681315e-02 -0.748568
2019-11-08 05:24:42,678 training loss; R2: 1.681629e-02 -0.743257
2019-11-08 05:24:43,366 valid 000 1.487840e-02 -0.178679
2019-11-08 05:24:52,774 valid 050 1.520568e-02 -1.098109
2019-11-08 05:25:01,103 validation loss; R2: 1.515785e-02 -1.005944
2019-11-08 05:25:01,166 epoch 830 lr 1.000000e-05
2019-11-08 05:25:01,942 train 000 1.604190e-02 -0.328271
2019-11-08 05:25:11,701 train 050 1.658786e-02 -0.886610
2019-11-08 05:25:21,493 train 100 1.667987e-02 -0.795610
2019-11-08 05:25:31,286 train 150 1.670190e-02 -17.274493
2019-11-08 05:25:41,057 train 200 1.675366e-02 -13.172511
2019-11-08 05:25:50,805 train 250 1.677091e-02 -10.686097
2019-11-08 05:26:00,551 train 300 1.671756e-02 -9.029881
2019-11-08 05:26:10,299 train 350 1.667450e-02 -7.825047
2019-11-08 05:26:20,045 train 400 1.670384e-02 -6.913106
2019-11-08 05:26:29,777 train 450 1.669344e-02 -6.258789
2019-11-08 05:26:39,523 train 500 1.667051e-02 -5.719434
2019-11-08 05:26:49,258 train 550 1.663660e-02 -5.258421
2019-11-08 05:26:59,011 train 600 1.664441e-02 -4.867612
2019-11-08 05:27:08,766 train 650 1.666559e-02 -4.569215
2019-11-08 05:27:18,515 train 700 1.668365e-02 -4.303830
2019-11-08 05:27:28,272 train 750 1.669322e-02 -4.160950
2019-11-08 05:27:38,030 train 800 1.669843e-02 -3.959034
2019-11-08 05:27:47,767 train 850 1.670514e-02 -3.771556
2019-11-08 05:27:50,714 training loss; R2: 1.671963e-02 -3.720488
2019-11-08 05:27:51,379 valid 000 2.076223e-02 -1.176143
2019-11-08 05:28:00,790 valid 050 1.880836e-02 -2.637955
2019-11-08 05:28:09,099 validation loss; R2: 1.865868e-02 -2.809503
2019-11-08 05:28:09,176 epoch 831 lr 1.000000e-05
2019-11-08 05:28:09,977 train 000 1.573950e-02 -0.124495
2019-11-08 05:28:19,746 train 050 1.631551e-02 -0.962952
2019-11-08 05:28:29,538 train 100 1.641205e-02 -0.750372
2019-11-08 05:28:39,333 train 150 1.659189e-02 -0.698985
2019-11-08 05:28:49,142 train 200 1.655813e-02 -0.695084
2019-11-08 05:28:59,009 train 250 1.657968e-02 -0.681979
2019-11-08 05:29:08,814 train 300 1.663147e-02 -0.673474
2019-11-08 05:29:18,618 train 350 1.661023e-02 -0.681312
2019-11-08 05:29:28,428 train 400 1.668398e-02 -0.672903
2019-11-08 05:29:38,234 train 450 1.668185e-02 -0.683727
2019-11-08 05:29:48,029 train 500 1.669343e-02 -0.702050
2019-11-08 05:29:57,833 train 550 1.668919e-02 -0.684048
2019-11-08 05:30:07,665 train 600 1.669915e-02 -0.665968
2019-11-08 05:30:17,469 train 650 1.671125e-02 -0.683156
2019-11-08 05:30:27,283 train 700 1.671743e-02 -0.683193
2019-11-08 05:30:37,081 train 750 1.671410e-02 -0.687813
2019-11-08 05:30:46,887 train 800 1.671838e-02 -0.672200
2019-11-08 05:30:56,709 train 850 1.674175e-02 -0.669800
2019-11-08 05:30:59,641 training loss; R2: 1.674405e-02 -0.668268
2019-11-08 05:31:00,286 valid 000 1.844479e-02 0.010500
2019-11-08 05:31:09,645 valid 050 1.561241e-02 -0.939299
2019-11-08 05:31:18,050 validation loss; R2: 1.569141e-02 -0.847462
2019-11-08 05:31:18,114 epoch 832 lr 1.000000e-05
2019-11-08 05:31:18,874 train 000 1.716847e-02 -0.270088
2019-11-08 05:31:28,635 train 050 1.650593e-02 -1.110158
2019-11-08 05:31:38,427 train 100 1.694352e-02 -1.592412
2019-11-08 05:31:48,227 train 150 1.689914e-02 -2.308852
2019-11-08 05:31:58,038 train 200 1.685084e-02 -1.909970
2019-11-08 05:32:07,858 train 250 1.676931e-02 -1.699765
2019-11-08 05:32:17,664 train 300 1.677268e-02 -1.503254
2019-11-08 05:32:27,479 train 350 1.676738e-02 -1.400890
2019-11-08 05:32:37,266 train 400 1.676865e-02 -1.342679
2019-11-08 05:32:47,014 train 450 1.676523e-02 -1.261247
2019-11-08 05:32:56,765 train 500 1.677753e-02 -1.196445
2019-11-08 05:33:06,531 train 550 1.676305e-02 -1.139961
2019-11-08 05:33:16,304 train 600 1.675403e-02 -1.116088
2019-11-08 05:33:26,104 train 650 1.675624e-02 -1.102437
2019-11-08 05:33:35,902 train 700 1.675938e-02 -1.067865
2019-11-08 05:33:45,704 train 750 1.679544e-02 -1.030118
2019-11-08 05:33:55,500 train 800 1.677901e-02 -1.029943
2019-11-08 05:34:05,298 train 850 1.678604e-02 -1.023677
2019-11-08 05:34:08,234 training loss; R2: 1.679160e-02 -1.016574
2019-11-08 05:34:08,908 valid 000 1.475461e-02 -1.322392
2019-11-08 05:34:18,266 valid 050 1.561179e-02 -0.893669
2019-11-08 05:34:26,635 validation loss; R2: 1.559016e-02 -1.004389
2019-11-08 05:34:26,702 epoch 833 lr 1.000000e-05
2019-11-08 05:34:27,491 train 000 1.453469e-02 0.038613
2019-11-08 05:34:37,228 train 050 1.658385e-02 -0.730886
2019-11-08 05:34:46,972 train 100 1.668054e-02 -0.904376
2019-11-08 05:34:56,733 train 150 1.671627e-02 -0.864741
2019-11-08 05:35:06,510 train 200 1.682230e-02 -0.829848
2019-11-08 05:35:16,266 train 250 1.681770e-02 -0.823128
2019-11-08 05:35:26,046 train 300 1.679709e-02 -0.862695
2019-11-08 05:35:35,832 train 350 1.675102e-02 -0.806152
2019-11-08 05:35:45,598 train 400 1.677380e-02 -0.773541
2019-11-08 05:35:55,371 train 450 1.676642e-02 -0.768921
2019-11-08 05:36:05,139 train 500 1.676354e-02 -0.758747
2019-11-08 05:36:14,896 train 550 1.673965e-02 -1.121042
2019-11-08 05:36:24,671 train 600 1.676123e-02 -1.100062
2019-11-08 05:36:34,447 train 650 1.678444e-02 -1.075969
2019-11-08 05:36:44,224 train 700 1.678605e-02 -1.043328
2019-11-08 05:36:53,999 train 750 1.676691e-02 -1.019013
2019-11-08 05:37:03,793 train 800 1.678343e-02 -1.013899
2019-11-08 05:37:13,605 train 850 1.676771e-02 -0.990111
2019-11-08 05:37:16,531 training loss; R2: 1.676636e-02 -0.989924
2019-11-08 05:37:17,185 valid 000 1.767170e-02 -9.686809
2019-11-08 05:37:26,621 valid 050 1.645079e-02 -1.179424
2019-11-08 05:37:34,907 validation loss; R2: 1.621724e-02 -1.279396
2019-11-08 05:37:34,972 epoch 834 lr 1.000000e-05
2019-11-08 05:37:35,719 train 000 1.654904e-02 -0.010235
2019-11-08 05:37:45,463 train 050 1.694477e-02 -0.700789
2019-11-08 05:37:55,226 train 100 1.682243e-02 -0.757052
2019-11-08 05:38:04,998 train 150 1.677889e-02 -0.857173
2019-11-08 05:38:14,773 train 200 1.674803e-02 -0.821434
2019-11-08 05:38:24,558 train 250 1.678923e-02 -1.285015
2019-11-08 05:38:34,340 train 300 1.684086e-02 -1.191146
2019-11-08 05:38:44,104 train 350 1.679858e-02 -1.105690
2019-11-08 05:38:53,894 train 400 1.678385e-02 -1.054113
2019-11-08 05:39:03,666 train 450 1.676289e-02 -1.028631
2019-11-08 05:39:13,445 train 500 1.677277e-02 -0.995419
2019-11-08 05:39:23,243 train 550 1.674910e-02 -0.954007
2019-11-08 05:39:33,042 train 600 1.673948e-02 -0.936810
2019-11-08 05:39:42,851 train 650 1.672263e-02 -0.905219
2019-11-08 05:39:52,656 train 700 1.672741e-02 -0.889117
2019-11-08 05:40:02,468 train 750 1.672029e-02 -0.863631
2019-11-08 05:40:12,275 train 800 1.672974e-02 -0.846668
2019-11-08 05:40:22,106 train 850 1.673456e-02 -0.840995
2019-11-08 05:40:25,036 training loss; R2: 1.674012e-02 -0.838198
2019-11-08 05:40:25,689 valid 000 1.490325e-02 -0.694172
2019-11-08 05:40:35,116 valid 050 1.665360e-02 -1.510689
2019-11-08 05:40:43,421 validation loss; R2: 1.660954e-02 -1.440605
2019-11-08 05:40:43,488 epoch 835 lr 1.000000e-05
2019-11-08 05:40:44,274 train 000 2.110732e-02 -0.015173
2019-11-08 05:40:53,994 train 050 1.700860e-02 -0.765437
2019-11-08 05:41:03,757 train 100 1.692888e-02 -0.711543
2019-11-08 05:41:13,570 train 150 1.690251e-02 -0.690341
2019-11-08 05:41:23,379 train 200 1.685429e-02 -0.941101
2019-11-08 05:41:33,174 train 250 1.684005e-02 -0.921550
2019-11-08 05:41:42,961 train 300 1.679655e-02 -0.939879
2019-11-08 05:41:52,756 train 350 1.674204e-02 -0.885858
2019-11-08 05:42:02,567 train 400 1.678207e-02 -0.871191
2019-11-08 05:42:12,352 train 450 1.675899e-02 -0.849464
2019-11-08 05:42:22,177 train 500 1.680369e-02 -0.817659
2019-11-08 05:42:31,972 train 550 1.681422e-02 -0.818362
2019-11-08 05:42:41,778 train 600 1.680068e-02 -0.799207
2019-11-08 05:42:51,610 train 650 1.681074e-02 -0.784681
2019-11-08 05:43:01,459 train 700 1.681735e-02 -0.788958
2019-11-08 05:43:11,280 train 750 1.679716e-02 -0.774109
2019-11-08 05:43:21,114 train 800 1.679860e-02 -0.790816
2019-11-08 05:43:30,950 train 850 1.679104e-02 -0.801430
2019-11-08 05:43:33,886 training loss; R2: 1.679264e-02 -0.796995
2019-11-08 05:43:34,587 valid 000 1.655075e-02 -0.627847
2019-11-08 05:43:43,977 valid 050 1.699376e-02 -1.712386
2019-11-08 05:43:52,335 validation loss; R2: 1.735842e-02 -1.406649
2019-11-08 05:43:52,401 epoch 836 lr 1.000000e-05
2019-11-08 05:43:53,215 train 000 1.648546e-02 0.055847
2019-11-08 05:44:02,971 train 050 1.700917e-02 -0.527993
2019-11-08 05:44:12,743 train 100 1.689483e-02 -0.496232
2019-11-08 05:44:22,522 train 150 1.700080e-02 -0.507685
2019-11-08 05:44:32,282 train 200 1.682087e-02 -0.692874
2019-11-08 05:44:42,046 train 250 1.680799e-02 -0.979632
2019-11-08 05:44:51,809 train 300 1.669582e-02 -0.909420
2019-11-08 05:45:01,567 train 350 1.667613e-02 -0.879934
2019-11-08 05:45:11,331 train 400 1.667771e-02 -0.899884
2019-11-08 05:45:21,098 train 450 1.667972e-02 -0.909245
2019-11-08 05:45:30,873 train 500 1.669013e-02 -0.873282
2019-11-08 05:45:40,655 train 550 1.671988e-02 -0.852555
2019-11-08 05:45:50,428 train 600 1.676542e-02 -0.873788
2019-11-08 05:46:00,203 train 650 1.675813e-02 -0.847322
2019-11-08 05:46:09,977 train 700 1.677711e-02 -0.841225
2019-11-08 05:46:19,755 train 750 1.678462e-02 -0.827323
2019-11-08 05:46:29,550 train 800 1.676953e-02 -0.815122
2019-11-08 05:46:39,361 train 850 1.674776e-02 -0.832118
2019-11-08 05:46:42,290 training loss; R2: 1.675197e-02 -0.867720
2019-11-08 05:46:42,920 valid 000 1.423361e-02 -0.601211
2019-11-08 05:46:52,331 valid 050 1.622709e-02 -1.360124
2019-11-08 05:47:00,726 validation loss; R2: 1.645079e-02 -1.284128
2019-11-08 05:47:00,791 epoch 837 lr 1.000000e-05
2019-11-08 05:47:01,568 train 000 1.603156e-02 -0.602560
2019-11-08 05:47:11,312 train 050 1.689817e-02 -0.892456
2019-11-08 05:47:21,060 train 100 1.695116e-02 -0.820486
2019-11-08 05:47:30,831 train 150 1.687057e-02 -0.745858
2019-11-08 05:47:40,605 train 200 1.684379e-02 -0.711543
2019-11-08 05:47:50,377 train 250 1.674756e-02 -0.668834
2019-11-08 05:48:00,167 train 300 1.667719e-02 -0.684627
2019-11-08 05:48:09,961 train 350 1.662167e-02 -0.718784
2019-11-08 05:48:19,740 train 400 1.661724e-02 -0.886292
2019-11-08 05:48:29,521 train 450 1.664592e-02 -0.890572
2019-11-08 05:48:39,294 train 500 1.666509e-02 -0.865464
2019-11-08 05:48:49,065 train 550 1.667552e-02 -0.843603
2019-11-08 05:48:58,849 train 600 1.667730e-02 -0.829413
2019-11-08 05:49:08,608 train 650 1.669270e-02 -0.823915
2019-11-08 05:49:18,354 train 700 1.668733e-02 -0.848683
2019-11-08 05:49:28,101 train 750 1.672398e-02 -0.837567
2019-11-08 05:49:37,834 train 800 1.671365e-02 -0.838426
2019-11-08 05:49:47,580 train 850 1.671663e-02 -0.840384
2019-11-08 05:49:50,490 training loss; R2: 1.672496e-02 -0.855934
2019-11-08 05:49:51,194 valid 000 2.648860e-02 -0.272995
2019-11-08 05:50:00,577 valid 050 2.208349e-02 -2.822697
2019-11-08 05:50:08,878 validation loss; R2: 2.192401e-02 -2.558376
2019-11-08 05:50:08,937 epoch 838 lr 1.000000e-05
2019-11-08 05:50:09,737 train 000 1.767826e-02 -0.761724
2019-11-08 05:50:19,453 train 050 1.684365e-02 -0.775633
2019-11-08 05:50:29,184 train 100 1.685472e-02 -0.770512
2019-11-08 05:50:38,914 train 150 1.678423e-02 -0.747659
2019-11-08 05:50:48,665 train 200 1.676247e-02 -0.861203
2019-11-08 05:50:58,403 train 250 1.679830e-02 -0.813654
2019-11-08 05:51:08,171 train 300 1.683016e-02 -0.809163
2019-11-08 05:51:17,928 train 350 1.682008e-02 -1.509851
2019-11-08 05:51:27,670 train 400 1.677076e-02 -1.391830
2019-11-08 05:51:37,407 train 450 1.673209e-02 -1.328558
2019-11-08 05:51:47,154 train 500 1.668100e-02 -1.264952
2019-11-08 05:51:56,905 train 550 1.671106e-02 -1.208960
2019-11-08 05:52:06,659 train 600 1.671702e-02 -1.173756
2019-11-08 05:52:16,410 train 650 1.672958e-02 -1.152707
2019-11-08 05:52:26,155 train 700 1.674329e-02 -1.775265
2019-11-08 05:52:35,912 train 750 1.674730e-02 -1.705195
2019-11-08 05:52:45,655 train 800 1.674403e-02 -1.635112
2019-11-08 05:52:55,397 train 850 1.676030e-02 -1.582091
2019-11-08 05:52:58,345 training loss; R2: 1.676759e-02 -1.560148
2019-11-08 05:52:59,019 valid 000 1.855958e-02 -0.127371
2019-11-08 05:53:08,418 valid 050 1.705515e-02 -1.318695
2019-11-08 05:53:16,778 validation loss; R2: 1.710399e-02 -1.746496
2019-11-08 05:53:16,845 epoch 839 lr 1.000000e-05
2019-11-08 05:53:17,583 train 000 1.781838e-02 -0.615141
2019-11-08 05:53:27,678 train 050 1.689736e-02 -0.975957
2019-11-08 05:53:37,785 train 100 1.672528e-02 -0.706006
2019-11-08 05:53:47,912 train 150 1.672093e-02 -0.717360
2019-11-08 05:53:58,051 train 200 1.678348e-02 -0.836914
2019-11-08 05:54:08,188 train 250 1.686453e-02 -0.846560
2019-11-08 05:54:18,323 train 300 1.684681e-02 -0.852852
2019-11-08 05:54:28,467 train 350 1.684579e-02 -0.847552
2019-11-08 05:54:38,606 train 400 1.683026e-02 -0.841627
2019-11-08 05:54:48,743 train 450 1.679575e-02 -0.820587
2019-11-08 05:54:58,880 train 500 1.684460e-02 -0.798259
2019-11-08 05:55:09,026 train 550 1.682579e-02 -0.788027
2019-11-08 05:55:19,160 train 600 1.683979e-02 -0.769335
2019-11-08 05:55:29,314 train 650 1.682271e-02 -0.768818
2019-11-08 05:55:39,436 train 700 1.683883e-02 -0.754294
2019-11-08 05:55:49,568 train 750 1.683202e-02 -0.755476
2019-11-08 05:55:59,703 train 800 1.684696e-02 -0.748647
2019-11-08 05:56:09,851 train 850 1.681790e-02 -0.761269
2019-11-08 05:56:12,884 training loss; R2: 1.680709e-02 -0.754501
2019-11-08 05:56:13,526 valid 000 1.115804e-02 -1.654509
2019-11-08 05:56:22,940 valid 050 1.390076e-02 -1.303538
2019-11-08 05:56:31,263 validation loss; R2: 1.377305e-02 -1.160397
2019-11-08 05:56:31,331 epoch 840 lr 1.000000e-05
2019-11-08 05:56:32,096 train 000 1.480087e-02 -0.801917
2019-11-08 05:56:42,241 train 050 1.637199e-02 -0.495019
2019-11-08 05:56:52,401 train 100 1.677947e-02 -0.677778
2019-11-08 05:57:02,552 train 150 1.672589e-02 -0.724588
2019-11-08 05:57:12,718 train 200 1.677858e-02 -0.861806
2019-11-08 05:57:22,881 train 250 1.682933e-02 -0.879497
2019-11-08 05:57:33,033 train 300 1.686573e-02 -0.789867
2019-11-08 05:57:43,177 train 350 1.687479e-02 -0.750927
2019-11-08 05:57:53,337 train 400 1.679685e-02 -0.727879
2019-11-08 05:58:03,473 train 450 1.680854e-02 -0.724384
2019-11-08 05:58:13,620 train 500 1.676567e-02 -0.760156
2019-11-08 05:58:23,786 train 550 1.677659e-02 -0.784437
2019-11-08 05:58:33,951 train 600 1.674924e-02 -0.784908
2019-11-08 05:58:44,123 train 650 1.673984e-02 -0.766706
2019-11-08 05:58:54,271 train 700 1.673309e-02 -0.757595
2019-11-08 05:59:04,449 train 750 1.673245e-02 -0.760850
2019-11-08 05:59:14,613 train 800 1.671102e-02 -0.765577
2019-11-08 05:59:24,785 train 850 1.672052e-02 -0.765650
2019-11-08 05:59:27,784 training loss; R2: 1.672436e-02 -0.767200
2019-11-08 05:59:28,485 valid 000 1.450668e-02 -3.170524
2019-11-08 05:59:37,831 valid 050 1.488787e-02 -1.233452
2019-11-08 05:59:46,284 validation loss; R2: 1.502216e-02 -1.452839
2019-11-08 05:59:46,363 epoch 841 lr 1.000000e-05
2019-11-08 05:59:47,166 train 000 1.557935e-02 -0.429905
2019-11-08 05:59:56,883 train 050 1.692993e-02 -0.570488
2019-11-08 06:00:06,644 train 100 1.673864e-02 -0.730626
2019-11-08 06:00:16,431 train 150 1.677642e-02 -0.666257
2019-11-08 06:00:26,250 train 200 1.674950e-02 -0.855287
2019-11-08 06:00:36,071 train 250 1.679795e-02 -0.823099
2019-11-08 06:00:45,877 train 300 1.676723e-02 -0.806382
2019-11-08 06:00:55,698 train 350 1.678297e-02 -0.920245
2019-11-08 06:01:05,507 train 400 1.674134e-02 -0.867435
2019-11-08 06:01:15,318 train 450 1.673293e-02 -0.851221
2019-11-08 06:01:25,149 train 500 1.673438e-02 -0.837114
2019-11-08 06:01:34,987 train 550 1.672942e-02 -0.814841
2019-11-08 06:01:44,820 train 600 1.673667e-02 -0.784221
2019-11-08 06:01:54,620 train 650 1.675391e-02 -0.774858
2019-11-08 06:02:04,438 train 700 1.675886e-02 -0.778487
2019-11-08 06:02:14,240 train 750 1.677231e-02 -0.763424
2019-11-08 06:02:24,053 train 800 1.676972e-02 -0.769855
2019-11-08 06:02:33,873 train 850 1.677073e-02 -0.761556
2019-11-08 06:02:36,809 training loss; R2: 1.676335e-02 -0.755403
2019-11-08 06:02:37,497 valid 000 1.580861e-02 -0.137138
2019-11-08 06:02:46,869 valid 050 1.505504e-02 -0.998973
2019-11-08 06:02:55,241 validation loss; R2: 1.507961e-02 -0.970790
2019-11-08 06:02:55,307 epoch 842 lr 1.000000e-05
2019-11-08 06:02:56,098 train 000 2.016844e-02 -0.231718
2019-11-08 06:03:05,839 train 050 1.683773e-02 -1.535605
2019-11-08 06:03:15,616 train 100 1.671481e-02 -1.101602
2019-11-08 06:03:25,421 train 150 1.668812e-02 -0.959357
2019-11-08 06:03:35,225 train 200 1.668179e-02 -0.874804
2019-11-08 06:03:45,042 train 250 1.676025e-02 -0.897414
2019-11-08 06:03:54,836 train 300 1.670853e-02 -0.833154
2019-11-08 06:04:04,628 train 350 1.664691e-02 -0.833109
2019-11-08 06:04:14,411 train 400 1.661825e-02 -1.314785
2019-11-08 06:04:24,225 train 450 1.661368e-02 -1.214245
2019-11-08 06:04:34,036 train 500 1.662677e-02 -1.189612
2019-11-08 06:04:43,833 train 550 1.664886e-02 -1.148872
2019-11-08 06:04:53,646 train 600 1.669165e-02 -1.100215
2019-11-08 06:05:03,460 train 650 1.671437e-02 -1.069746
2019-11-08 06:05:13,250 train 700 1.671635e-02 -1.070913
2019-11-08 06:05:23,038 train 750 1.672340e-02 -1.050252
2019-11-08 06:05:32,840 train 800 1.672620e-02 -1.023043
2019-11-08 06:05:42,658 train 850 1.674591e-02 -1.028812
2019-11-08 06:05:45,601 training loss; R2: 1.675254e-02 -1.020808
2019-11-08 06:05:46,295 valid 000 2.096841e-02 -1.990491
2019-11-08 06:05:55,632 valid 050 1.967603e-02 -1.787411
2019-11-08 06:06:03,949 validation loss; R2: 1.955347e-02 -1.753974
2019-11-08 06:06:04,014 epoch 843 lr 1.000000e-05
2019-11-08 06:06:04,790 train 000 1.568038e-02 -0.919291
2019-11-08 06:06:14,558 train 050 1.689114e-02 -0.894880
2019-11-08 06:06:24,347 train 100 1.675844e-02 -0.951712
2019-11-08 06:06:34,134 train 150 1.687294e-02 -1.239949
2019-11-08 06:06:43,919 train 200 1.680976e-02 -1.174216
2019-11-08 06:06:53,719 train 250 1.674570e-02 -1.044694
2019-11-08 06:07:03,525 train 300 1.676952e-02 -0.973991
2019-11-08 06:07:13,331 train 350 1.676736e-02 -1.243398
2019-11-08 06:07:23,142 train 400 1.678491e-02 -1.190031
2019-11-08 06:07:32,945 train 450 1.676783e-02 -1.132212
2019-11-08 06:07:42,741 train 500 1.678591e-02 -1.079483
2019-11-08 06:07:52,539 train 550 1.678096e-02 -1.057626
2019-11-08 06:08:02,347 train 600 1.679134e-02 -1.026778
2019-11-08 06:08:12,151 train 650 1.677071e-02 -1.025449
2019-11-08 06:08:21,970 train 700 1.677222e-02 -0.986813
2019-11-08 06:08:31,777 train 750 1.678220e-02 -0.971164
2019-11-08 06:08:41,588 train 800 1.679297e-02 -0.946757
2019-11-08 06:08:51,392 train 850 1.681009e-02 -0.934955
2019-11-08 06:08:54,326 training loss; R2: 1.681160e-02 -0.939191
2019-11-08 06:08:55,009 valid 000 1.714429e-02 -2.725451
2019-11-08 06:09:04,420 valid 050 1.574275e-02 -1.247391
2019-11-08 06:09:12,750 validation loss; R2: 1.604328e-02 -1.617692
2019-11-08 06:09:12,816 epoch 844 lr 1.000000e-05
2019-11-08 06:09:13,598 train 000 1.503137e-02 -1.394944
2019-11-08 06:09:23,365 train 050 1.609703e-02 -0.781440
2019-11-08 06:09:33,171 train 100 1.629511e-02 -0.758859
2019-11-08 06:09:42,962 train 150 1.655000e-02 -0.770755
2019-11-08 06:09:52,754 train 200 1.665363e-02 -0.722804
2019-11-08 06:10:02,561 train 250 1.664240e-02 -0.716077
2019-11-08 06:10:12,367 train 300 1.665629e-02 -0.758387
2019-11-08 06:10:22,189 train 350 1.668220e-02 -0.757415
2019-11-08 06:10:31,995 train 400 1.665294e-02 -0.766987
2019-11-08 06:10:41,807 train 450 1.665074e-02 -0.761881
2019-11-08 06:10:51,617 train 500 1.666062e-02 -0.770010
2019-11-08 06:11:01,434 train 550 1.663818e-02 -0.790557
2019-11-08 06:11:11,250 train 600 1.663941e-02 -0.924463
2019-11-08 06:11:21,060 train 650 1.666803e-02 -0.918755
2019-11-08 06:11:30,869 train 700 1.669279e-02 -0.925185
2019-11-08 06:11:40,676 train 750 1.669384e-02 -0.921859
2019-11-08 06:11:50,480 train 800 1.668978e-02 -0.923996
2019-11-08 06:12:00,297 train 850 1.669265e-02 -0.912302
2019-11-08 06:12:03,259 training loss; R2: 1.669040e-02 -0.902155
2019-11-08 06:12:03,895 valid 000 1.499632e-02 0.036218
2019-11-08 06:12:13,353 valid 050 1.413737e-02 -1.184501
2019-11-08 06:12:21,690 validation loss; R2: 1.413911e-02 -1.102876
2019-11-08 06:12:21,772 epoch 845 lr 1.000000e-05
2019-11-08 06:12:22,563 train 000 1.760749e-02 -0.295596
2019-11-08 06:12:32,341 train 050 1.668458e-02 -0.742004
2019-11-08 06:12:42,168 train 100 1.686350e-02 -0.752382
2019-11-08 06:12:52,010 train 150 1.678765e-02 -0.791941
2019-11-08 06:13:01,855 train 200 1.675667e-02 -0.826491
2019-11-08 06:13:11,706 train 250 1.676861e-02 -0.757294
2019-11-08 06:13:21,538 train 300 1.674443e-02 -0.736556
2019-11-08 06:13:31,372 train 350 1.678025e-02 -0.732855
2019-11-08 06:13:41,170 train 400 1.675884e-02 -0.733737
2019-11-08 06:13:50,969 train 450 1.676296e-02 -0.753367
2019-11-08 06:14:00,773 train 500 1.673916e-02 -0.741602
2019-11-08 06:14:10,565 train 550 1.673734e-02 -0.747644
2019-11-08 06:14:20,369 train 600 1.672250e-02 -0.729648
2019-11-08 06:14:30,165 train 650 1.673742e-02 -0.719004
2019-11-08 06:14:39,971 train 700 1.671937e-02 -0.726895
2019-11-08 06:14:49,754 train 750 1.671474e-02 -0.718389
2019-11-08 06:14:59,563 train 800 1.672645e-02 -0.715468
2019-11-08 06:15:09,352 train 850 1.672899e-02 -0.720200
2019-11-08 06:15:12,272 training loss; R2: 1.672748e-02 -0.725979
2019-11-08 06:15:12,932 valid 000 1.280687e-02 0.010522
2019-11-08 06:15:22,340 valid 050 1.415434e-02 -1.062281
2019-11-08 06:15:30,687 validation loss; R2: 1.430598e-02 -1.160270
2019-11-08 06:15:30,753 epoch 846 lr 1.000000e-05
2019-11-08 06:15:31,527 train 000 1.733349e-02 -1.581738
2019-11-08 06:15:41,280 train 050 1.680536e-02 -0.801116
2019-11-08 06:15:51,093 train 100 1.681205e-02 -0.686617
2019-11-08 06:16:00,941 train 150 1.691528e-02 -0.638284
2019-11-08 06:16:10,793 train 200 1.685564e-02 -0.684889
2019-11-08 06:16:20,616 train 250 1.684207e-02 -0.624914
2019-11-08 06:16:30,433 train 300 1.679350e-02 -0.629161
2019-11-08 06:16:40,271 train 350 1.678844e-02 -0.664526
2019-11-08 06:16:50,106 train 400 1.682968e-02 -0.746448
2019-11-08 06:16:59,951 train 450 1.683769e-02 -0.746161
2019-11-08 06:17:09,818 train 500 1.684339e-02 -0.782709
2019-11-08 06:17:19,657 train 550 1.681079e-02 -0.772628
2019-11-08 06:17:29,479 train 600 1.682603e-02 -0.782866
2019-11-08 06:17:39,219 train 650 1.683880e-02 -0.767483
2019-11-08 06:17:48,962 train 700 1.682718e-02 -0.783978
2019-11-08 06:17:58,698 train 750 1.682618e-02 -0.837536
2019-11-08 06:18:08,455 train 800 1.683129e-02 -0.857352
2019-11-08 06:18:18,202 train 850 1.683236e-02 -0.843975
2019-11-08 06:18:21,110 training loss; R2: 1.682453e-02 -0.836897
2019-11-08 06:18:21,754 valid 000 1.369787e-02 -0.450119
2019-11-08 06:18:31,189 valid 050 1.438734e-02 -0.677721
2019-11-08 06:18:39,486 validation loss; R2: 1.422290e-02 -0.802495
2019-11-08 06:18:39,552 epoch 847 lr 1.000000e-05
2019-11-08 06:18:40,300 train 000 1.621212e-02 -0.376174
2019-11-08 06:18:50,009 train 050 1.699240e-02 -0.572632
2019-11-08 06:18:59,741 train 100 1.679561e-02 -0.707879
2019-11-08 06:19:09,480 train 150 1.669091e-02 -0.756777
2019-11-08 06:19:19,217 train 200 1.669728e-02 -0.731530
2019-11-08 06:19:28,963 train 250 1.662175e-02 -0.731114
2019-11-08 06:19:38,722 train 300 1.675563e-02 -0.726823
2019-11-08 06:19:48,466 train 350 1.680368e-02 -0.757332
2019-11-08 06:19:58,219 train 400 1.681699e-02 -0.763226
2019-11-08 06:20:07,973 train 450 1.681477e-02 -0.815713
2019-11-08 06:20:17,732 train 500 1.679923e-02 -0.796078
2019-11-08 06:20:27,481 train 550 1.679344e-02 -0.763608
2019-11-08 06:20:37,236 train 600 1.678050e-02 -0.759232
2019-11-08 06:20:46,983 train 650 1.679624e-02 -0.745951
2019-11-08 06:20:56,727 train 700 1.680292e-02 -4.035767
2019-11-08 06:21:06,501 train 750 1.679566e-02 -3.821465
2019-11-08 06:21:16,303 train 800 1.678172e-02 -11.118816
2019-11-08 06:21:26,112 train 850 1.679978e-02 -10.513652
2019-11-08 06:21:29,044 training loss; R2: 1.679619e-02 -10.352541
2019-11-08 06:21:29,686 valid 000 2.304319e-02 -2.015638
2019-11-08 06:21:39,108 valid 050 2.400842e-02 -4.040074
2019-11-08 06:21:47,539 validation loss; R2: 2.405678e-02 -3.319316
2019-11-08 06:21:47,606 epoch 848 lr 1.000000e-05
2019-11-08 06:21:48,363 train 000 2.055249e-02 -1.049177
2019-11-08 06:21:58,103 train 050 1.668605e-02 -0.806252
2019-11-08 06:22:07,860 train 100 1.675636e-02 -0.668897
2019-11-08 06:22:17,631 train 150 1.665560e-02 -0.771074
2019-11-08 06:22:27,399 train 200 1.666616e-02 -0.744067
2019-11-08 06:22:37,187 train 250 1.674220e-02 -0.776665
2019-11-08 06:22:46,971 train 300 1.672090e-02 -0.744325
2019-11-08 06:22:56,752 train 350 1.671513e-02 -0.746031
2019-11-08 06:23:06,530 train 400 1.674764e-02 -0.727462
2019-11-08 06:23:16,307 train 450 1.675201e-02 -0.745216
2019-11-08 06:23:26,092 train 500 1.679595e-02 -0.732556
2019-11-08 06:23:35,866 train 550 1.677316e-02 -0.741663
2019-11-08 06:23:45,645 train 600 1.676374e-02 -0.730488
2019-11-08 06:23:55,421 train 650 1.676457e-02 -0.755471
2019-11-08 06:24:05,224 train 700 1.676751e-02 -0.752613
2019-11-08 06:24:15,030 train 750 1.675440e-02 -0.740008
2019-11-08 06:24:24,833 train 800 1.676416e-02 -0.728634
2019-11-08 06:24:34,624 train 850 1.677628e-02 -0.723602
2019-11-08 06:24:37,590 training loss; R2: 1.678144e-02 -0.721582
2019-11-08 06:24:38,225 valid 000 1.833742e-02 -1.750802
2019-11-08 06:24:47,641 valid 050 1.528077e-02 -1.214536
2019-11-08 06:24:55,942 validation loss; R2: 1.508446e-02 -1.313617
2019-11-08 06:24:56,011 epoch 849 lr 1.000000e-05
2019-11-08 06:24:56,774 train 000 1.736247e-02 -1.368565
2019-11-08 06:25:06,537 train 050 1.704644e-02 -136.246937
2019-11-08 06:25:16,294 train 100 1.689160e-02 -69.018600
2019-11-08 06:25:26,052 train 150 1.684814e-02 -46.440013
2019-11-08 06:25:35,816 train 200 1.682361e-02 -35.088939
2019-11-08 06:25:45,599 train 250 1.673566e-02 -28.306527
2019-11-08 06:25:55,369 train 300 1.675688e-02 -23.778087
2019-11-08 06:26:05,162 train 350 1.675752e-02 -20.451465
2019-11-08 06:26:14,963 train 400 1.675913e-02 -17.989732
2019-11-08 06:26:24,763 train 450 1.679353e-02 -16.066650
2019-11-08 06:26:34,533 train 500 1.675409e-02 -14.532523
2019-11-08 06:26:44,352 train 550 1.675081e-02 -13.274009
2019-11-08 06:26:54,179 train 600 1.672661e-02 -12.238833
2019-11-08 06:27:03,991 train 650 1.674318e-02 -11.357469
2019-11-08 06:27:13,808 train 700 1.674659e-02 -10.602801
2019-11-08 06:27:23,614 train 750 1.672032e-02 -9.925428
2019-11-08 06:27:33,419 train 800 1.674704e-02 -9.339788
2019-11-08 06:27:43,249 train 850 1.676019e-02 -8.847164
2019-11-08 06:27:46,177 training loss; R2: 1.675224e-02 -8.702109
2019-11-08 06:27:46,847 valid 000 1.664251e-02 -0.595394
2019-11-08 06:27:56,256 valid 050 1.615380e-02 -1.308696
2019-11-08 06:28:04,565 validation loss; R2: 1.622127e-02 -1.239387
2019-11-08 06:28:04,629 epoch 850 lr 1.000000e-05
2019-11-08 06:28:05,390 train 000 1.357473e-02 -0.105976
2019-11-08 06:28:15,161 train 050 1.647434e-02 -1.075949
2019-11-08 06:28:24,971 train 100 1.642673e-02 -0.925928
2019-11-08 06:28:34,764 train 150 1.650724e-02 -0.861185
2019-11-08 06:28:44,578 train 200 1.648502e-02 -0.905783
2019-11-08 06:28:54,385 train 250 1.661861e-02 -0.875568
2019-11-08 06:29:04,192 train 300 1.668994e-02 -0.857551
2019-11-08 06:29:13,990 train 350 1.664783e-02 -0.851584
2019-11-08 06:29:23,810 train 400 1.662591e-02 -0.869345
2019-11-08 06:29:33,622 train 450 1.665650e-02 -0.847032
2019-11-08 06:29:43,435 train 500 1.667999e-02 -0.862838
2019-11-08 06:29:53,287 train 550 1.663891e-02 -0.846992
2019-11-08 06:30:03,103 train 600 1.660750e-02 -0.829584
2019-11-08 06:30:12,923 train 650 1.664717e-02 -0.827900
2019-11-08 06:30:22,742 train 700 1.663677e-02 -0.833976
2019-11-08 06:30:32,561 train 750 1.666495e-02 -0.824714
2019-11-08 06:30:42,369 train 800 1.669424e-02 -1.089132
2019-11-08 06:30:52,181 train 850 1.670852e-02 -1.064711
2019-11-08 06:30:55,149 training loss; R2: 1.670908e-02 -1.061418
2019-11-08 06:30:55,802 valid 000 1.252670e-02 -0.115377
2019-11-08 06:31:05,256 valid 050 1.529741e-02 -0.723842
2019-11-08 06:31:13,579 validation loss; R2: 1.525329e-02 -0.861919
2019-11-08 06:31:13,658 epoch 851 lr 1.000000e-05
2019-11-08 06:31:14,450 train 000 1.767474e-02 -1.202074
2019-11-08 06:31:24,191 train 050 1.674575e-02 -0.888636
2019-11-08 06:31:33,964 train 100 1.670418e-02 -0.818625
2019-11-08 06:31:43,745 train 150 1.671117e-02 -0.797654
2019-11-08 06:31:53,544 train 200 1.675484e-02 -0.735027
2019-11-08 06:32:03,335 train 250 1.676185e-02 -0.736218
2019-11-08 06:32:13,116 train 300 1.682972e-02 -0.735909
2019-11-08 06:32:22,905 train 350 1.676147e-02 -0.736769
2019-11-08 06:32:32,724 train 400 1.668856e-02 -0.810645
2019-11-08 06:32:42,517 train 450 1.672044e-02 -0.818323
2019-11-08 06:32:52,311 train 500 1.674921e-02 -0.812868
2019-11-08 06:33:02,123 train 550 1.675400e-02 -0.819974
2019-11-08 06:33:11,952 train 600 1.675593e-02 -0.825341
2019-11-08 06:33:21,762 train 650 1.676543e-02 -0.835096
2019-11-08 06:33:31,564 train 700 1.677209e-02 -1.218928
2019-11-08 06:33:41,385 train 750 1.675626e-02 -1.185062
2019-11-08 06:33:51,188 train 800 1.677391e-02 -1.145253
2019-11-08 06:34:01,012 train 850 1.678071e-02 -1.122829
2019-11-08 06:34:03,982 training loss; R2: 1.677735e-02 -1.118752
2019-11-08 06:34:04,690 valid 000 1.667407e-02 -3.024170
2019-11-08 06:34:14,030 valid 050 1.618045e-02 -1.332314
2019-11-08 06:34:22,396 validation loss; R2: 1.609064e-02 -1.536519
2019-11-08 06:34:22,463 epoch 852 lr 1.000000e-05
2019-11-08 06:34:23,215 train 000 1.509960e-02 -1.152169
2019-11-08 06:34:32,973 train 050 1.662898e-02 -0.574933
2019-11-08 06:34:42,731 train 100 1.658733e-02 -0.626599
2019-11-08 06:34:52,511 train 150 1.665651e-02 -0.653753
2019-11-08 06:35:02,284 train 200 1.680214e-02 -0.646408
2019-11-08 06:35:12,076 train 250 1.680768e-02 -0.627581
2019-11-08 06:35:21,861 train 300 1.680795e-02 -0.645069
2019-11-08 06:35:31,625 train 350 1.680986e-02 -0.685940
2019-11-08 06:35:41,404 train 400 1.677046e-02 -0.676247
2019-11-08 06:35:51,185 train 450 1.679836e-02 -0.724245
2019-11-08 06:36:00,996 train 500 1.678646e-02 -0.728270
2019-11-08 06:36:10,796 train 550 1.683884e-02 -0.727329
2019-11-08 06:36:20,604 train 600 1.681251e-02 -0.738085
2019-11-08 06:36:30,399 train 650 1.679682e-02 -0.733174
2019-11-08 06:36:40,191 train 700 1.681155e-02 -0.710131
2019-11-08 06:36:49,993 train 750 1.683152e-02 -0.725991
2019-11-08 06:36:59,803 train 800 1.680071e-02 -0.720764
2019-11-08 06:37:09,633 train 850 1.680092e-02 -0.721923
2019-11-08 06:37:12,592 training loss; R2: 1.679270e-02 -0.727132
2019-11-08 06:37:13,220 valid 000 1.310893e-02 0.043636
2019-11-08 06:37:22,717 valid 050 1.475036e-02 -0.912358
2019-11-08 06:37:31,048 validation loss; R2: 1.478774e-02 -0.819066
2019-11-08 06:37:31,128 epoch 853 lr 1.000000e-05
2019-11-08 06:37:31,942 train 000 1.760270e-02 -0.013734
2019-11-08 06:37:42,050 train 050 1.690914e-02 -0.759476
2019-11-08 06:37:51,841 train 100 1.687780e-02 -0.747124
2019-11-08 06:38:01,659 train 150 1.697111e-02 -0.965459
2019-11-08 06:38:11,475 train 200 1.686412e-02 -0.856196
2019-11-08 06:38:21,291 train 250 1.679948e-02 -0.835788
2019-11-08 06:38:31,101 train 300 1.673527e-02 -0.812734
2019-11-08 06:38:40,911 train 350 1.670836e-02 -0.783560
2019-11-08 06:38:50,714 train 400 1.668131e-02 -0.764133
2019-11-08 06:39:00,510 train 450 1.667734e-02 -0.769837
2019-11-08 06:39:10,307 train 500 1.666684e-02 -0.857324
2019-11-08 06:39:20,113 train 550 1.667351e-02 -0.854236
2019-11-08 06:39:29,898 train 600 1.669709e-02 -1.432347
2019-11-08 06:39:39,692 train 650 1.669590e-02 -1.393434
2019-11-08 06:39:49,501 train 700 1.671713e-02 -1.353527
2019-11-08 06:39:59,309 train 750 1.674755e-02 -1.297679
2019-11-08 06:40:09,118 train 800 1.675461e-02 -1.294663
2019-11-08 06:40:18,925 train 850 1.677853e-02 -1.257952
2019-11-08 06:40:21,852 training loss; R2: 1.677613e-02 -1.253001
2019-11-08 06:40:22,497 valid 000 1.655073e-02 0.103807
2019-11-08 06:40:31,922 valid 050 1.466732e-02 -0.747382
2019-11-08 06:40:40,256 validation loss; R2: 1.450824e-02 -0.783685
2019-11-08 06:40:40,323 epoch 854 lr 1.000000e-05
2019-11-08 06:40:41,074 train 000 2.104927e-02 -0.538156
2019-11-08 06:40:50,800 train 050 1.714355e-02 -0.527635
2019-11-08 06:41:00,512 train 100 1.686671e-02 -0.793312
2019-11-08 06:41:10,256 train 150 1.684228e-02 -0.709822
2019-11-08 06:41:20,004 train 200 1.692968e-02 -0.689096
2019-11-08 06:41:29,744 train 250 1.693477e-02 -0.695561
2019-11-08 06:41:39,488 train 300 1.696903e-02 -0.678064
2019-11-08 06:41:49,241 train 350 1.692298e-02 -0.831277
2019-11-08 06:41:59,017 train 400 1.689917e-02 -0.813048
2019-11-08 06:42:08,791 train 450 1.685945e-02 -0.785830
2019-11-08 06:42:18,577 train 500 1.685050e-02 -0.853780
2019-11-08 06:42:28,379 train 550 1.680637e-02 -0.827735
2019-11-08 06:42:38,191 train 600 1.678761e-02 -0.844033
2019-11-08 06:42:47,986 train 650 1.678966e-02 -0.838762
2019-11-08 06:42:57,794 train 700 1.677849e-02 -13.380241
2019-11-08 06:43:07,596 train 750 1.678017e-02 -12.540679
2019-11-08 06:43:17,401 train 800 1.677451e-02 -11.822987
2019-11-08 06:43:27,190 train 850 1.676272e-02 -11.173385
2019-11-08 06:43:30,123 training loss; R2: 1.676837e-02 -10.990336
2019-11-08 06:43:30,743 valid 000 1.356931e-02 -0.147463
2019-11-08 06:43:40,156 valid 050 1.518592e-02 -0.726573
2019-11-08 06:43:48,472 validation loss; R2: 1.515442e-02 -0.744189
2019-11-08 06:43:48,540 epoch 855 lr 1.000000e-05
2019-11-08 06:43:49,293 train 000 2.115752e-02 -0.041957
2019-11-08 06:43:59,033 train 050 1.638253e-02 -0.815615
2019-11-08 06:44:08,796 train 100 1.648181e-02 -0.647565
2019-11-08 06:44:18,577 train 150 1.670153e-02 -1.057304
2019-11-08 06:44:28,320 train 200 1.673737e-02 -0.945768
2019-11-08 06:44:38,065 train 250 1.683014e-02 -0.915670
2019-11-08 06:44:47,803 train 300 1.672808e-02 -0.881776
2019-11-08 06:44:57,542 train 350 1.671677e-02 -0.836391
2019-11-08 06:45:07,284 train 400 1.675383e-02 -0.825527
2019-11-08 06:45:17,036 train 450 1.673620e-02 -0.834284
2019-11-08 06:45:26,803 train 500 1.675173e-02 -0.803774
2019-11-08 06:45:36,576 train 550 1.671839e-02 -0.810003
2019-11-08 06:45:46,350 train 600 1.672705e-02 -0.789495
2019-11-08 06:45:56,115 train 650 1.670380e-02 -0.799202
2019-11-08 06:46:05,876 train 700 1.671581e-02 -0.793805
2019-11-08 06:46:15,649 train 750 1.673045e-02 -0.806935
2019-11-08 06:46:25,413 train 800 1.673513e-02 -0.799848
2019-11-08 06:46:35,185 train 850 1.675177e-02 -0.808040
2019-11-08 06:46:38,106 training loss; R2: 1.675088e-02 -0.805193
2019-11-08 06:46:38,784 valid 000 1.378035e-02 -0.304554
2019-11-08 06:46:48,134 valid 050 1.493750e-02 -1.035898
2019-11-08 06:46:56,496 validation loss; R2: 1.499676e-02 -0.974535
2019-11-08 06:46:56,563 epoch 856 lr 1.000000e-05
2019-11-08 06:46:57,326 train 000 1.661859e-02 -0.053652
2019-11-08 06:47:07,039 train 050 1.667974e-02 -2.027379
2019-11-08 06:47:16,776 train 100 1.679475e-02 -1.395506
2019-11-08 06:47:26,508 train 150 1.685430e-02 -2.534910
2019-11-08 06:47:36,236 train 200 1.688774e-02 -2.152771
2019-11-08 06:47:45,976 train 250 1.689572e-02 -1.900635
2019-11-08 06:47:55,723 train 300 1.685201e-02 -1.696431
2019-11-08 06:48:05,483 train 350 1.693160e-02 -1.540378
2019-11-08 06:48:15,258 train 400 1.693226e-02 -1.424765
2019-11-08 06:48:25,026 train 450 1.693101e-02 -1.351556
2019-11-08 06:48:34,800 train 500 1.692409e-02 -1.294480
2019-11-08 06:48:44,559 train 550 1.690658e-02 -1.270382
2019-11-08 06:48:54,327 train 600 1.687175e-02 -1.209388
2019-11-08 06:49:04,092 train 650 1.686134e-02 -1.150487
2019-11-08 06:49:13,857 train 700 1.685702e-02 -1.122713
2019-11-08 06:49:23,620 train 750 1.684828e-02 -1.087512
2019-11-08 06:49:33,402 train 800 1.684734e-02 -1.066994
2019-11-08 06:49:43,175 train 850 1.685647e-02 -1.044477
2019-11-08 06:49:46,094 training loss; R2: 1.684580e-02 -1.043053
2019-11-08 06:49:46,730 valid 000 1.780782e-02 0.064575
2019-11-08 06:49:56,187 valid 050 1.527568e-02 -1.532363
2019-11-08 06:50:04,533 validation loss; R2: 1.529795e-02 -1.358480
2019-11-08 06:50:04,600 epoch 857 lr 1.000000e-05
2019-11-08 06:50:05,386 train 000 1.688039e-02 -0.597348
2019-11-08 06:50:15,108 train 050 1.723472e-02 -0.633957
2019-11-08 06:50:24,834 train 100 1.681178e-02 -0.618737
2019-11-08 06:50:34,565 train 150 1.685678e-02 -0.651181
2019-11-08 06:50:44,319 train 200 1.686774e-02 -0.719090
2019-11-08 06:50:54,089 train 250 1.689925e-02 -0.727744
2019-11-08 06:51:03,859 train 300 1.687251e-02 -0.697973
2019-11-08 06:51:13,641 train 350 1.683528e-02 -0.685290
2019-11-08 06:51:23,417 train 400 1.682024e-02 -0.691218
2019-11-08 06:51:33,199 train 450 1.682566e-02 -0.684603
2019-11-08 06:51:42,973 train 500 1.682109e-02 -0.696728
2019-11-08 06:51:52,741 train 550 1.677477e-02 -0.721206
2019-11-08 06:52:02,525 train 600 1.676091e-02 -0.716197
2019-11-08 06:52:12,301 train 650 1.676555e-02 -0.744544
2019-11-08 06:52:22,066 train 700 1.677650e-02 -0.738480
2019-11-08 06:52:31,846 train 750 1.676781e-02 -0.740669
2019-11-08 06:52:41,632 train 800 1.678691e-02 -0.742053
2019-11-08 06:52:51,407 train 850 1.678396e-02 -0.741538
2019-11-08 06:52:54,326 training loss; R2: 1.677277e-02 -0.738275
2019-11-08 06:52:55,003 valid 000 2.606189e-02 -0.765024
2019-11-08 06:53:04,407 valid 050 2.535501e-02 -2.773516
2019-11-08 06:53:12,742 validation loss; R2: 2.504670e-02 -2.792037
2019-11-08 06:53:12,815 epoch 858 lr 1.000000e-05
2019-11-08 06:53:13,582 train 000 1.839615e-02 -1.247950
2019-11-08 06:53:23,321 train 050 1.732574e-02 -0.848092
2019-11-08 06:53:33,075 train 100 1.688745e-02 -0.778943
2019-11-08 06:53:42,861 train 150 1.678476e-02 -0.745800
2019-11-08 06:53:52,633 train 200 1.673248e-02 -0.934687
2019-11-08 06:54:02,406 train 250 1.680633e-02 -0.858988
2019-11-08 06:54:12,242 train 300 1.685374e-02 -0.850694
2019-11-08 06:54:22,057 train 350 1.684432e-02 -0.858635
2019-11-08 06:54:31,870 train 400 1.681317e-02 -1.028104
2019-11-08 06:54:41,698 train 450 1.676714e-02 -0.996272
2019-11-08 06:54:51,522 train 500 1.673126e-02 -0.955614
2019-11-08 06:55:01,351 train 550 1.673678e-02 -0.939818
2019-11-08 06:55:11,176 train 600 1.675254e-02 -0.924372
2019-11-08 06:55:21,020 train 650 1.676776e-02 -0.916943
2019-11-08 06:55:30,838 train 700 1.675079e-02 -0.907253
2019-11-08 06:55:40,660 train 750 1.675925e-02 -0.900829
2019-11-08 06:55:50,495 train 800 1.674664e-02 -0.984100
2019-11-08 06:56:00,322 train 850 1.674967e-02 -1.036914
2019-11-08 06:56:03,253 training loss; R2: 1.675956e-02 -1.030541
2019-11-08 06:56:03,937 valid 000 1.360167e-02 -1.210466
2019-11-08 06:56:13,359 valid 050 1.488248e-02 -0.781547
2019-11-08 06:56:21,671 validation loss; R2: 1.504337e-02 -1.043079
2019-11-08 06:56:21,736 epoch 859 lr 1.000000e-05
2019-11-08 06:56:22,515 train 000 1.687776e-02 -0.023639
2019-11-08 06:56:32,291 train 050 1.653979e-02 -1.255828
2019-11-08 06:56:42,051 train 100 1.671242e-02 -0.906608
2019-11-08 06:56:51,832 train 150 1.666066e-02 -0.793581
2019-11-08 06:57:01,616 train 200 1.667537e-02 -0.778754
2019-11-08 06:57:11,396 train 250 1.655833e-02 -0.723659
2019-11-08 06:57:21,193 train 300 1.662497e-02 -0.744419
2019-11-08 06:57:30,995 train 350 1.660721e-02 -1.341953
2019-11-08 06:57:40,800 train 400 1.660219e-02 -1.265071
2019-11-08 06:57:50,626 train 450 1.666734e-02 -1.238768
2019-11-08 06:58:00,450 train 500 1.669955e-02 -1.182752
2019-11-08 06:58:10,262 train 550 1.667389e-02 -1.145309
2019-11-08 06:58:20,068 train 600 1.667993e-02 -24.920412
2019-11-08 06:58:29,890 train 650 1.665776e-02 -23.053381
2019-11-08 06:58:39,719 train 700 1.666590e-02 -21.456563
2019-11-08 06:58:49,551 train 750 1.669655e-02 -20.081205
2019-11-08 06:58:59,371 train 800 1.671975e-02 -18.868714
2019-11-08 06:59:09,175 train 850 1.669985e-02 -17.797929
2019-11-08 06:59:12,142 training loss; R2: 1.670916e-02 -17.509049
2019-11-08 06:59:12,768 valid 000 3.033230e-02 -1.185125
2019-11-08 06:59:22,246 valid 050 2.631435e-02 -39.498897
2019-11-08 06:59:30,554 validation loss; R2: 2.608003e-02 -22.305420
2019-11-08 06:59:30,625 epoch 860 lr 1.000000e-05
2019-11-08 06:59:31,406 train 000 1.417215e-02 0.052079
2019-11-08 06:59:41,152 train 050 1.687805e-02 -0.654066
2019-11-08 06:59:50,903 train 100 1.665650e-02 -0.680609
2019-11-08 07:00:00,670 train 150 1.672958e-02 -1.031877
2019-11-08 07:00:10,447 train 200 1.679137e-02 -0.973710
2019-11-08 07:00:20,210 train 250 1.671944e-02 -0.913879
2019-11-08 07:00:29,999 train 300 1.669841e-02 -0.875877
2019-11-08 07:00:39,812 train 350 1.668689e-02 -0.906466
2019-11-08 07:00:49,605 train 400 1.673908e-02 -0.864050
2019-11-08 07:00:59,409 train 450 1.670594e-02 -0.876118
2019-11-08 07:01:09,210 train 500 1.675304e-02 -0.845983
2019-11-08 07:01:19,022 train 550 1.675565e-02 -0.852270
2019-11-08 07:01:28,821 train 600 1.678422e-02 -0.852242
2019-11-08 07:01:38,634 train 650 1.678686e-02 -0.840857
2019-11-08 07:01:48,435 train 700 1.676064e-02 -0.825389
2019-11-08 07:01:58,250 train 750 1.677781e-02 -0.829154
2019-11-08 07:02:08,053 train 800 1.676093e-02 -0.825294
2019-11-08 07:02:17,844 train 850 1.677542e-02 -0.833362
2019-11-08 07:02:20,766 training loss; R2: 1.678595e-02 -0.831926
2019-11-08 07:02:21,417 valid 000 1.600789e-02 -3.589944
2019-11-08 07:02:30,848 valid 050 1.819554e-02 -1.426211
2019-11-08 07:02:39,255 validation loss; R2: 1.836583e-02 -1.478223
2019-11-08 07:02:39,321 epoch 861 lr 1.000000e-05
2019-11-08 07:02:40,115 train 000 1.752022e-02 -0.212401
2019-11-08 07:02:49,850 train 050 1.695871e-02 -0.834322
2019-11-08 07:02:59,590 train 100 1.692758e-02 -0.829193
2019-11-08 07:03:09,350 train 150 1.690264e-02 -1.313258
2019-11-08 07:03:19,109 train 200 1.677970e-02 -1.157934
2019-11-08 07:03:28,868 train 250 1.678048e-02 -1.015931
2019-11-08 07:03:38,635 train 300 1.680511e-02 -0.935463
2019-11-08 07:03:48,405 train 350 1.676793e-02 -0.905346
2019-11-08 07:03:58,201 train 400 1.679400e-02 -0.858350
2019-11-08 07:04:08,008 train 450 1.681950e-02 -0.848277
2019-11-08 07:04:17,801 train 500 1.680920e-02 -0.860675
2019-11-08 07:04:27,597 train 550 1.676558e-02 -0.826876
2019-11-08 07:04:37,389 train 600 1.676887e-02 -0.826608
2019-11-08 07:04:47,172 train 650 1.677038e-02 -0.809560
2019-11-08 07:04:56,967 train 700 1.676112e-02 -0.818767
2019-11-08 07:05:06,765 train 750 1.676463e-02 -0.821499
2019-11-08 07:05:16,567 train 800 1.674301e-02 -0.968611
2019-11-08 07:05:26,358 train 850 1.673837e-02 -0.993829
2019-11-08 07:05:29,285 training loss; R2: 1.673797e-02 -0.990807
2019-11-08 07:05:29,879 valid 000 1.580548e-02 -0.149966
2019-11-08 07:05:39,340 valid 050 1.542107e-02 -1.534579
2019-11-08 07:05:47,653 validation loss; R2: 1.537701e-02 -1.605128
2019-11-08 07:05:47,717 epoch 862 lr 1.000000e-05
2019-11-08 07:05:48,506 train 000 1.695591e-02 -0.131504
2019-11-08 07:05:58,249 train 050 1.674771e-02 -0.691486
2019-11-08 07:06:08,012 train 100 1.670891e-02 -0.824880
2019-11-08 07:06:17,784 train 150 1.666072e-02 -0.770064
2019-11-08 07:06:27,574 train 200 1.676859e-02 -0.730837
2019-11-08 07:06:37,342 train 250 1.676132e-02 -0.730263
2019-11-08 07:06:47,117 train 300 1.679911e-02 -0.703889
2019-11-08 07:06:56,896 train 350 1.676274e-02 -0.720159
2019-11-08 07:07:06,705 train 400 1.670850e-02 -0.687320
2019-11-08 07:07:16,509 train 450 1.668032e-02 -0.683380
2019-11-08 07:07:26,331 train 500 1.671054e-02 -0.697346
2019-11-08 07:07:36,143 train 550 1.674218e-02 -0.692802
2019-11-08 07:07:45,959 train 600 1.670269e-02 -0.695644
2019-11-08 07:07:55,774 train 650 1.668443e-02 -0.692781
2019-11-08 07:08:05,583 train 700 1.668619e-02 -0.693218
2019-11-08 07:08:15,380 train 750 1.670095e-02 -0.688792
2019-11-08 07:08:25,210 train 800 1.671678e-02 -0.739991
2019-11-08 07:08:35,033 train 850 1.670279e-02 -0.757814
2019-11-08 07:08:37,972 training loss; R2: 1.672297e-02 -0.758488
2019-11-08 07:08:38,572 valid 000 1.536600e-02 0.000104
2019-11-08 07:08:47,958 valid 050 1.644975e-02 -0.924333
2019-11-08 07:08:56,393 validation loss; R2: 1.650227e-02 -0.797816
2019-11-08 07:08:56,459 epoch 863 lr 1.000000e-05
2019-11-08 07:08:57,259 train 000 2.017760e-02 -0.201639
2019-11-08 07:09:07,000 train 050 1.671961e-02 -0.776355
2019-11-08 07:09:16,784 train 100 1.657173e-02 -0.863011
2019-11-08 07:09:26,578 train 150 1.650552e-02 -0.855971
2019-11-08 07:09:36,368 train 200 1.660553e-02 -5.200832
2019-11-08 07:09:46,177 train 250 1.662806e-02 -4.305668
2019-11-08 07:09:55,969 train 300 1.656598e-02 -3.700388
2019-11-08 07:10:05,779 train 350 1.666285e-02 -3.272370
2019-11-08 07:10:15,614 train 400 1.670989e-02 -2.936565
2019-11-08 07:10:25,413 train 450 1.669262e-02 -2.689713
2019-11-08 07:10:35,230 train 500 1.669449e-02 -2.504135
2019-11-08 07:10:45,039 train 550 1.669353e-02 -2.332790
2019-11-08 07:10:54,855 train 600 1.668188e-02 -2.201271
2019-11-08 07:11:04,663 train 650 1.670517e-02 -2.083188
2019-11-08 07:11:14,478 train 700 1.674412e-02 -1.976153
2019-11-08 07:11:24,285 train 750 1.673803e-02 -1.910599
2019-11-08 07:11:34,121 train 800 1.675426e-02 -1.816088
2019-11-08 07:11:43,920 train 850 1.675665e-02 -1.750363
2019-11-08 07:11:46,853 training loss; R2: 1.676289e-02 -1.733458
2019-11-08 07:11:47,526 valid 000 1.738934e-02 -2.703194
2019-11-08 07:11:56,958 valid 050 1.624050e-02 -1.267839
2019-11-08 07:12:05,292 validation loss; R2: 1.602433e-02 -1.123226
2019-11-08 07:12:05,361 epoch 864 lr 1.000000e-05
2019-11-08 07:12:06,137 train 000 1.584716e-02 -1.396999
2019-11-08 07:12:15,897 train 050 1.688141e-02 -0.613979
2019-11-08 07:12:25,640 train 100 1.671311e-02 -0.816856
2019-11-08 07:12:35,403 train 150 1.678432e-02 -0.795993
2019-11-08 07:12:45,173 train 200 1.682826e-02 -0.836013
2019-11-08 07:12:54,944 train 250 1.674014e-02 -0.791266
2019-11-08 07:13:04,728 train 300 1.676387e-02 -0.772493
2019-11-08 07:13:14,514 train 350 1.672237e-02 -0.748465
2019-11-08 07:13:24,302 train 400 1.672090e-02 -0.736065
2019-11-08 07:13:34,092 train 450 1.670959e-02 -0.717022
2019-11-08 07:13:44,189 train 500 1.667696e-02 -0.714434
2019-11-08 07:13:54,356 train 550 1.667930e-02 -0.704546
2019-11-08 07:14:04,530 train 600 1.670124e-02 -0.823177
2019-11-08 07:14:14,698 train 650 1.673543e-02 -0.847290
2019-11-08 07:14:24,859 train 700 1.674810e-02 -0.828596
2019-11-08 07:14:35,041 train 750 1.676375e-02 -0.849416
2019-11-08 07:14:45,206 train 800 1.677895e-02 -0.855776
2019-11-08 07:14:55,379 train 850 1.680560e-02 -0.849391
2019-11-08 07:14:58,427 training loss; R2: 1.680825e-02 -0.858214
2019-11-08 07:14:59,019 valid 000 1.510656e-02 -3.440501
2019-11-08 07:15:08,478 valid 050 1.598798e-02 -0.650524
2019-11-08 07:15:16,894 validation loss; R2: 1.623270e-02 -1.223972
2019-11-08 07:15:16,961 epoch 865 lr 1.000000e-05
2019-11-08 07:15:17,728 train 000 1.598158e-02 -0.246023
2019-11-08 07:15:27,866 train 050 1.688179e-02 -0.737953
2019-11-08 07:15:38,022 train 100 1.680052e-02 -0.711758
2019-11-08 07:15:48,161 train 150 1.698482e-02 -0.811132
2019-11-08 07:15:58,274 train 200 1.687553e-02 -0.816814
2019-11-08 07:16:08,434 train 250 1.690933e-02 -0.813577
2019-11-08 07:16:18,588 train 300 1.678801e-02 -0.794653
2019-11-08 07:16:28,727 train 350 1.676418e-02 -0.767495
2019-11-08 07:16:38,915 train 400 1.678831e-02 -0.750079
2019-11-08 07:16:49,072 train 450 1.678418e-02 -0.744555
2019-11-08 07:16:59,258 train 500 1.675150e-02 -0.741345
2019-11-08 07:17:09,439 train 550 1.676959e-02 -0.736159
2019-11-08 07:17:19,607 train 600 1.673824e-02 -0.739069
2019-11-08 07:17:29,817 train 650 1.670654e-02 -0.749251
2019-11-08 07:17:39,996 train 700 1.671527e-02 -0.754524
2019-11-08 07:17:50,163 train 750 1.672289e-02 -0.737820
2019-11-08 07:18:00,355 train 800 1.671951e-02 -0.729649
2019-11-08 07:18:10,527 train 850 1.673779e-02 -4.021421
2019-11-08 07:18:13,565 training loss; R2: 1.674042e-02 -3.963177
2019-11-08 07:18:14,154 valid 000 1.294425e-02 -2.490159
2019-11-08 07:18:23,611 valid 050 1.464156e-02 -1.213427
2019-11-08 07:18:31,987 validation loss; R2: 1.455977e-02 -1.302421
2019-11-08 07:18:32,056 epoch 866 lr 1.000000e-05
2019-11-08 07:18:32,875 train 000 1.609904e-02 -0.855672
2019-11-08 07:18:43,014 train 050 1.715857e-02 -0.512352
2019-11-08 07:18:53,133 train 100 1.693781e-02 -0.576874
2019-11-08 07:19:03,282 train 150 1.673642e-02 -0.545472
2019-11-08 07:19:13,428 train 200 1.679887e-02 -0.620343
2019-11-08 07:19:23,561 train 250 1.677037e-02 -0.616199
2019-11-08 07:19:33,739 train 300 1.676646e-02 -0.637510
2019-11-08 07:19:43,892 train 350 1.672772e-02 -0.647105
2019-11-08 07:19:54,041 train 400 1.667130e-02 -0.675974
2019-11-08 07:20:04,186 train 450 1.668136e-02 -0.667688
2019-11-08 07:20:14,363 train 500 1.669040e-02 -0.686672
2019-11-08 07:20:24,553 train 550 1.674429e-02 -0.667782
2019-11-08 07:20:34,711 train 600 1.674772e-02 -0.679426
2019-11-08 07:20:44,875 train 650 1.670746e-02 -0.690064
2019-11-08 07:20:55,045 train 700 1.673082e-02 -0.687357
2019-11-08 07:21:05,226 train 750 1.673499e-02 -0.680704
2019-11-08 07:21:15,386 train 800 1.673859e-02 -0.696241
2019-11-08 07:21:25,542 train 850 1.672876e-02 -0.704115
2019-11-08 07:21:28,588 training loss; R2: 1.672262e-02 -0.704162
2019-11-08 07:21:29,292 valid 000 1.428508e-02 0.058204
2019-11-08 07:21:38,707 valid 050 1.484056e-02 -0.961562
2019-11-08 07:21:47,139 validation loss; R2: 1.475131e-02 -0.981001
2019-11-08 07:21:47,206 epoch 867 lr 1.000000e-05
2019-11-08 07:21:47,985 train 000 1.869273e-02 -0.635188
2019-11-08 07:21:58,097 train 050 1.664527e-02 -0.817420
2019-11-08 07:22:08,227 train 100 1.697167e-02 -0.754599
2019-11-08 07:22:18,363 train 150 1.694819e-02 -0.688904
2019-11-08 07:22:28,507 train 200 1.692712e-02 -0.671149
2019-11-08 07:22:38,655 train 250 1.689955e-02 -0.678359
2019-11-08 07:22:48,788 train 300 1.683471e-02 -0.653671
2019-11-08 07:22:58,929 train 350 1.687542e-02 -0.763655
2019-11-08 07:23:09,084 train 400 1.685307e-02 -0.763895
2019-11-08 07:23:19,237 train 450 1.679618e-02 -0.740027
2019-11-08 07:23:29,340 train 500 1.677482e-02 -0.733511
2019-11-08 07:23:39,489 train 550 1.675731e-02 -0.734826
2019-11-08 07:23:49,641 train 600 1.676636e-02 -0.725878
2019-11-08 07:23:59,788 train 650 1.676892e-02 -0.741672
2019-11-08 07:24:09,948 train 700 1.675764e-02 -1.043797
2019-11-08 07:24:20,115 train 750 1.677507e-02 -3.398954
2019-11-08 07:24:30,259 train 800 1.676444e-02 -3.247072
2019-11-08 07:24:40,421 train 850 1.675874e-02 -3.128480
2019-11-08 07:24:43,470 training loss; R2: 1.676267e-02 -3.092314
2019-11-08 07:24:44,150 valid 000 1.836743e-02 -0.240314
2019-11-08 07:24:53,503 valid 050 1.582680e-02 -0.796132
2019-11-08 07:25:01,910 validation loss; R2: 1.561898e-02 -0.866389
2019-11-08 07:25:01,970 epoch 868 lr 1.000000e-05
2019-11-08 07:25:02,767 train 000 1.372124e-02 -0.267074
2019-11-08 07:25:12,743 train 050 1.683701e-02 -0.920396
2019-11-08 07:25:22,610 train 100 1.685135e-02 -0.748388
2019-11-08 07:25:32,431 train 150 1.676793e-02 -1.197663
2019-11-08 07:25:42,250 train 200 1.667784e-02 -1.134898
2019-11-08 07:25:52,084 train 250 1.685203e-02 -1.013089
2019-11-08 07:26:01,901 train 300 1.687356e-02 -0.985929
2019-11-08 07:26:11,701 train 350 1.690358e-02 -0.957024
2019-11-08 07:26:21,492 train 400 1.689369e-02 -15.453257
2019-11-08 07:26:31,278 train 450 1.685554e-02 -13.841600
2019-11-08 07:26:41,078 train 500 1.681889e-02 -12.530003
2019-11-08 07:26:50,862 train 550 1.682023e-02 -11.440268
2019-11-08 07:27:00,650 train 600 1.681650e-02 -10.543227
2019-11-08 07:27:10,466 train 650 1.679335e-02 -9.806863
2019-11-08 07:27:20,265 train 700 1.682125e-02 -9.149970
2019-11-08 07:27:30,059 train 750 1.682533e-02 -8.588120
2019-11-08 07:27:39,869 train 800 1.685153e-02 -8.103429
2019-11-08 07:27:49,661 train 850 1.684396e-02 -7.666529
2019-11-08 07:27:52,587 training loss; R2: 1.685420e-02 -7.549565
2019-11-08 07:27:53,284 valid 000 1.815846e-02 -0.894454
2019-11-08 07:28:02,691 valid 050 1.688425e-02 -1.175078
2019-11-08 07:28:11,043 validation loss; R2: 1.671488e-02 -1.359542
2019-11-08 07:28:11,122 epoch 869 lr 1.000000e-05
2019-11-08 07:28:11,904 train 000 1.619997e-02 0.002858
2019-11-08 07:28:21,627 train 050 1.665062e-02 -0.530325
2019-11-08 07:28:31,352 train 100 1.661231e-02 -0.489350
2019-11-08 07:28:41,127 train 150 1.667833e-02 -0.591479
2019-11-08 07:28:50,881 train 200 1.666768e-02 -0.689869
2019-11-08 07:29:00,646 train 250 1.669521e-02 -0.684422
2019-11-08 07:29:10,427 train 300 1.673538e-02 -0.710723
2019-11-08 07:29:20,198 train 350 1.669469e-02 -0.733729
2019-11-08 07:29:29,965 train 400 1.669753e-02 -0.721204
2019-11-08 07:29:39,745 train 450 1.669241e-02 -0.768113
2019-11-08 07:29:49,509 train 500 1.666720e-02 -0.778736
2019-11-08 07:29:59,272 train 550 1.670892e-02 -0.754907
2019-11-08 07:30:09,061 train 600 1.671987e-02 -0.792363
2019-11-08 07:30:18,843 train 650 1.671801e-02 -0.793968
2019-11-08 07:30:28,659 train 700 1.668623e-02 -0.778180
2019-11-08 07:30:38,437 train 750 1.669365e-02 -0.782401
2019-11-08 07:30:48,252 train 800 1.670585e-02 -0.767715
2019-11-08 07:30:58,054 train 850 1.671978e-02 -0.766991
2019-11-08 07:31:00,977 training loss; R2: 1.671457e-02 -0.764599
2019-11-08 07:31:01,665 valid 000 1.303500e-02 -1.880395
2019-11-08 07:31:11,014 valid 050 1.441930e-02 -1.135310
2019-11-08 07:31:19,406 validation loss; R2: 1.456255e-02 -0.991477
2019-11-08 07:31:19,473 epoch 870 lr 1.000000e-05
2019-11-08 07:31:20,269 train 000 1.645407e-02 -0.154082
2019-11-08 07:31:30,013 train 050 1.705471e-02 -0.634808
2019-11-08 07:31:39,779 train 100 1.668731e-02 -1.246203
2019-11-08 07:31:49,561 train 150 1.681080e-02 -1.162570
2019-11-08 07:31:59,339 train 200 1.677461e-02 -1.050489
2019-11-08 07:32:09,137 train 250 1.673416e-02 -1.061762
2019-11-08 07:32:18,953 train 300 1.670889e-02 -0.981031
2019-11-08 07:32:28,732 train 350 1.665243e-02 -1.007412
2019-11-08 07:32:38,527 train 400 1.663929e-02 -0.972700
2019-11-08 07:32:48,330 train 450 1.667697e-02 -0.950497
2019-11-08 07:32:58,112 train 500 1.667422e-02 -0.909912
2019-11-08 07:33:07,908 train 550 1.666670e-02 -0.893641
2019-11-08 07:33:17,718 train 600 1.672400e-02 -3.255731
2019-11-08 07:33:27,520 train 650 1.673401e-02 -3.097152
2019-11-08 07:33:37,324 train 700 1.671886e-02 -2.914205
2019-11-08 07:33:47,132 train 750 1.672406e-02 -2.760606
2019-11-08 07:33:56,922 train 800 1.671530e-02 -2.628214
2019-11-08 07:34:06,715 train 850 1.670984e-02 -2.520348
2019-11-08 07:34:09,635 training loss; R2: 1.671893e-02 -2.484640
2019-11-08 07:34:10,264 valid 000 1.732633e-02 -0.528501
2019-11-08 07:34:19,663 valid 050 1.558374e-02 -1.247414
2019-11-08 07:34:28,060 validation loss; R2: 1.573536e-02 -1.287728
2019-11-08 07:34:28,127 epoch 871 lr 1.000000e-05
2019-11-08 07:34:28,896 train 000 1.709907e-02 -0.009231
2019-11-08 07:34:38,652 train 050 1.695830e-02 -0.575782
2019-11-08 07:34:48,423 train 100 1.701364e-02 -0.637566
2019-11-08 07:34:58,180 train 150 1.704746e-02 -0.738841
2019-11-08 07:35:07,960 train 200 1.706869e-02 -0.777612
2019-11-08 07:35:17,729 train 250 1.698382e-02 -0.728419
2019-11-08 07:35:27,503 train 300 1.693196e-02 -0.749899
2019-11-08 07:35:37,291 train 350 1.691847e-02 -0.755065
2019-11-08 07:35:47,079 train 400 1.691140e-02 -0.749194
2019-11-08 07:35:56,863 train 450 1.688909e-02 -0.732653
2019-11-08 07:36:06,650 train 500 1.684153e-02 -0.723647
2019-11-08 07:36:16,420 train 550 1.680241e-02 -0.727592
2019-11-08 07:36:26,195 train 600 1.680645e-02 -0.738244
2019-11-08 07:36:35,968 train 650 1.681293e-02 -0.740636
2019-11-08 07:36:45,738 train 700 1.680925e-02 -0.723195
2019-11-08 07:36:55,523 train 750 1.682133e-02 -0.726120
2019-11-08 07:37:05,318 train 800 1.682950e-02 -0.713959
2019-11-08 07:37:15,105 train 850 1.685818e-02 -0.710389
2019-11-08 07:37:18,073 training loss; R2: 1.686069e-02 -0.706903
2019-11-08 07:37:18,709 valid 000 1.673866e-02 -1.056365
2019-11-08 07:37:28,106 valid 050 1.662140e-02 -1.803453
2019-11-08 07:37:36,517 validation loss; R2: 1.693976e-02 -1.516916
2019-11-08 07:37:36,583 epoch 872 lr 1.000000e-05
2019-11-08 07:37:37,387 train 000 1.462287e-02 -0.183461
2019-11-08 07:37:47,534 train 050 1.689662e-02 -0.837994
2019-11-08 07:37:57,677 train 100 1.683045e-02 -0.761473
2019-11-08 07:38:07,857 train 150 1.682202e-02 -0.717840
2019-11-08 07:38:18,023 train 200 1.683972e-02 -0.673552
2019-11-08 07:38:28,195 train 250 1.677092e-02 -0.718013
2019-11-08 07:38:38,372 train 300 1.679046e-02 -0.698728
2019-11-08 07:38:48,530 train 350 1.683239e-02 -0.727605
2019-11-08 07:38:58,704 train 400 1.681377e-02 -0.772231
2019-11-08 07:39:08,887 train 450 1.682144e-02 -0.756643
2019-11-08 07:39:19,087 train 500 1.680419e-02 -0.753708
2019-11-08 07:39:29,277 train 550 1.677083e-02 -0.750921
2019-11-08 07:39:39,463 train 600 1.677552e-02 -0.758851
2019-11-08 07:39:49,623 train 650 1.676875e-02 -0.883894
2019-11-08 07:39:59,802 train 700 1.676461e-02 -0.886972
2019-11-08 07:40:09,965 train 750 1.674373e-02 -0.916569
2019-11-08 07:40:20,142 train 800 1.677310e-02 -0.897621
2019-11-08 07:40:30,356 train 850 1.681667e-02 -0.914914
2019-11-08 07:40:33,289 training loss; R2: 1.681113e-02 -0.908281
2019-11-08 07:40:33,960 valid 000 1.704113e-02 -0.312272
2019-11-08 07:40:43,343 valid 050 1.947807e-02 -1.719528
2019-11-08 07:40:51,681 validation loss; R2: 1.942440e-02 -2.155304
2019-11-08 07:40:51,746 epoch 873 lr 1.000000e-05
2019-11-08 07:40:52,525 train 000 1.743630e-02 -0.223521
2019-11-08 07:41:02,260 train 050 1.666852e-02 -0.843685
2019-11-08 07:41:12,015 train 100 1.663956e-02 -0.842016
2019-11-08 07:41:21,766 train 150 1.669584e-02 -0.773836
2019-11-08 07:41:31,509 train 200 1.666061e-02 -0.744313
2019-11-08 07:41:41,267 train 250 1.662410e-02 -0.772300
2019-11-08 07:41:51,036 train 300 1.666709e-02 -0.776162
2019-11-08 07:42:00,813 train 350 1.667433e-02 -0.754904
2019-11-08 07:42:10,594 train 400 1.675374e-02 -0.756405
2019-11-08 07:42:20,359 train 450 1.676465e-02 -0.745699
2019-11-08 07:42:30,132 train 500 1.678782e-02 -0.741442
2019-11-08 07:42:39,907 train 550 1.677839e-02 -0.740011
2019-11-08 07:42:49,693 train 600 1.678391e-02 -0.744437
2019-11-08 07:42:59,479 train 650 1.682459e-02 -0.761772
2019-11-08 07:43:09,265 train 700 1.683986e-02 -0.769471
2019-11-08 07:43:19,055 train 750 1.683888e-02 -0.766421
2019-11-08 07:43:28,830 train 800 1.683582e-02 -0.741299
2019-11-08 07:43:38,610 train 850 1.683084e-02 -0.731355
2019-11-08 07:43:41,529 training loss; R2: 1.683166e-02 -0.733166
2019-11-08 07:43:42,183 valid 000 1.620583e-02 -0.409404
2019-11-08 07:43:51,552 valid 050 1.606359e-02 -1.231177
2019-11-08 07:43:59,889 validation loss; R2: 1.593090e-02 -1.189963
2019-11-08 07:43:59,953 epoch 874 lr 1.000000e-05
2019-11-08 07:44:00,736 train 000 1.465900e-02 -6.693599
2019-11-08 07:44:10,473 train 050 1.654311e-02 -0.738129
2019-11-08 07:44:20,236 train 100 1.678341e-02 -0.793842
2019-11-08 07:44:29,994 train 150 1.685680e-02 -0.906085
2019-11-08 07:44:39,762 train 200 1.682413e-02 -0.920662
2019-11-08 07:44:49,543 train 250 1.684047e-02 -0.895205
2019-11-08 07:44:59,324 train 300 1.688491e-02 -0.830341
2019-11-08 07:45:09,094 train 350 1.681468e-02 -0.804156
2019-11-08 07:45:18,867 train 400 1.679708e-02 -0.801121
2019-11-08 07:45:28,659 train 450 1.681095e-02 -0.782304
2019-11-08 07:45:38,451 train 500 1.677603e-02 -0.774691
2019-11-08 07:45:48,257 train 550 1.678462e-02 -0.768142
2019-11-08 07:45:58,030 train 600 1.675015e-02 -0.782772
2019-11-08 07:46:07,822 train 650 1.675781e-02 -0.771570
2019-11-08 07:46:17,599 train 700 1.678789e-02 -0.748872
2019-11-08 07:46:27,420 train 750 1.677456e-02 -0.735947
2019-11-08 07:46:37,200 train 800 1.674496e-02 -0.729454
2019-11-08 07:46:46,955 train 850 1.676639e-02 -0.732381
2019-11-08 07:46:49,868 training loss; R2: 1.675753e-02 -0.729268
2019-11-08 07:46:50,563 valid 000 1.873145e-02 -0.139671
2019-11-08 07:46:59,987 valid 050 1.564518e-02 -2.361562
2019-11-08 07:47:08,349 validation loss; R2: 1.562893e-02 -1.729471
2019-11-08 07:47:08,414 epoch 875 lr 1.000000e-05
2019-11-08 07:47:09,180 train 000 1.772744e-02 -1.003605
2019-11-08 07:47:18,920 train 050 1.688072e-02 -0.855255
2019-11-08 07:47:28,682 train 100 1.686285e-02 -0.737457
2019-11-08 07:47:38,469 train 150 1.691581e-02 -3.173464
2019-11-08 07:47:48,260 train 200 1.690791e-02 -2.507987
2019-11-08 07:47:58,054 train 250 1.696025e-02 -2.162688
2019-11-08 07:48:07,856 train 300 1.696020e-02 -1.939543
2019-11-08 07:48:17,653 train 350 1.688293e-02 -1.741899
2019-11-08 07:48:27,442 train 400 1.686504e-02 -1.592119
2019-11-08 07:48:37,239 train 450 1.683837e-02 -1.508389
2019-11-08 07:48:47,027 train 500 1.683380e-02 -1.432331
2019-11-08 07:48:56,824 train 550 1.683230e-02 -1.436920
2019-11-08 07:49:06,619 train 600 1.683697e-02 -1.384900
2019-11-08 07:49:16,407 train 650 1.683409e-02 -1.341543
2019-11-08 07:49:26,206 train 700 1.684851e-02 -1.290478
2019-11-08 07:49:36,008 train 750 1.683401e-02 -1.237132
2019-11-08 07:49:45,804 train 800 1.682550e-02 -1.204550
2019-11-08 07:49:55,602 train 850 1.682822e-02 -1.209753
2019-11-08 07:49:58,563 training loss; R2: 1.682094e-02 -1.198982
2019-11-08 07:49:59,253 valid 000 1.500529e-02 -0.750905
2019-11-08 07:50:08,687 valid 050 1.595943e-02 -0.941090
2019-11-08 07:50:17,067 validation loss; R2: 1.586939e-02 -1.227029
2019-11-08 07:50:17,152 epoch 876 lr 1.000000e-05
2019-11-08 07:50:17,983 train 000 1.974365e-02 -2.704922
2019-11-08 07:50:27,699 train 050 1.671964e-02 -0.647728
2019-11-08 07:50:37,449 train 100 1.685824e-02 -0.687761
2019-11-08 07:50:47,214 train 150 1.662807e-02 -0.723858
2019-11-08 07:50:56,977 train 200 1.668859e-02 -0.736449
2019-11-08 07:51:06,753 train 250 1.675469e-02 -0.731301
2019-11-08 07:51:16,508 train 300 1.679834e-02 -0.804471
2019-11-08 07:51:26,294 train 350 1.681348e-02 -3.732385
2019-11-08 07:51:36,063 train 400 1.674647e-02 -3.367358
2019-11-08 07:51:45,832 train 450 1.677212e-02 -3.103932
2019-11-08 07:51:55,591 train 500 1.676867e-02 -2.903549
2019-11-08 07:52:05,382 train 550 1.676728e-02 -2.867102
2019-11-08 07:52:15,145 train 600 1.675924e-02 -2.717534
2019-11-08 07:52:24,929 train 650 1.675848e-02 -2.565907
2019-11-08 07:52:34,698 train 700 1.673895e-02 -2.436123
2019-11-08 07:52:44,449 train 750 1.673968e-02 -2.314093
2019-11-08 07:52:54,226 train 800 1.674139e-02 -2.215755
2019-11-08 07:53:04,015 train 850 1.675550e-02 -2.121298
2019-11-08 07:53:06,937 training loss; R2: 1.676370e-02 -2.090607
2019-11-08 07:53:07,616 valid 000 1.436073e-02 -1.001185
2019-11-08 07:53:17,047 valid 050 1.466361e-02 -0.663795
2019-11-08 07:53:25,386 validation loss; R2: 1.485253e-02 -0.728369
2019-11-08 07:53:25,451 epoch 877 lr 1.000000e-05
2019-11-08 07:53:26,181 train 000 1.618729e-02 -0.723431
2019-11-08 07:53:35,908 train 050 1.714121e-02 -0.540807
2019-11-08 07:53:45,646 train 100 1.694175e-02 -0.790418
2019-11-08 07:53:55,431 train 150 1.694805e-02 -0.796299
2019-11-08 07:54:05,209 train 200 1.693451e-02 -0.864380
2019-11-08 07:54:14,986 train 250 1.685998e-02 -0.902120
2019-11-08 07:54:24,756 train 300 1.683285e-02 -0.918347
2019-11-08 07:54:34,527 train 350 1.677269e-02 -0.931824
2019-11-08 07:54:44,306 train 400 1.671837e-02 -0.897371
2019-11-08 07:54:54,085 train 450 1.675424e-02 -0.918508
2019-11-08 07:55:03,886 train 500 1.672433e-02 -0.888121
2019-11-08 07:55:13,718 train 550 1.675619e-02 -0.910657
2019-11-08 07:55:23,543 train 600 1.675162e-02 -0.889190
2019-11-08 07:55:33,389 train 650 1.676767e-02 -0.894649
2019-11-08 07:55:43,214 train 700 1.678067e-02 -0.880884
2019-11-08 07:55:53,043 train 750 1.679754e-02 -0.869300
2019-11-08 07:56:02,877 train 800 1.678948e-02 -0.864921
2019-11-08 07:56:12,708 train 850 1.681171e-02 -0.857784
2019-11-08 07:56:15,645 training loss; R2: 1.681090e-02 -0.859933
2019-11-08 07:56:16,256 valid 000 2.482435e-02 -1.373668
2019-11-08 07:56:25,673 valid 050 1.962614e-02 -2.303435
2019-11-08 07:56:34,124 validation loss; R2: 1.957083e-02 -2.745833
2019-11-08 07:56:34,199 epoch 878 lr 1.000000e-05
2019-11-08 07:56:34,964 train 000 1.793907e-02 0.108857
2019-11-08 07:56:44,736 train 050 1.687237e-02 -0.452570
2019-11-08 07:56:54,505 train 100 1.674063e-02 -0.506722
2019-11-08 07:57:04,294 train 150 1.688810e-02 -0.606670
2019-11-08 07:57:14,114 train 200 1.688413e-02 -0.638831
2019-11-08 07:57:23,940 train 250 1.684938e-02 -0.650466
2019-11-08 07:57:33,764 train 300 1.674999e-02 -0.676448
2019-11-08 07:57:43,555 train 350 1.678833e-02 -0.665346
2019-11-08 07:57:53,370 train 400 1.679681e-02 -0.667946
2019-11-08 07:58:03,169 train 450 1.675025e-02 -0.678607
2019-11-08 07:58:12,999 train 500 1.674609e-02 -0.684751
2019-11-08 07:58:22,801 train 550 1.677207e-02 -0.692300
2019-11-08 07:58:32,635 train 600 1.677557e-02 -0.691521
2019-11-08 07:58:42,443 train 650 1.676413e-02 -0.694222
2019-11-08 07:58:52,248 train 700 1.678030e-02 -0.696457
2019-11-08 07:59:02,075 train 750 1.676929e-02 -0.696432
2019-11-08 07:59:11,879 train 800 1.678607e-02 -0.713748
2019-11-08 07:59:21,707 train 850 1.678516e-02 -0.762807
2019-11-08 07:59:24,639 training loss; R2: 1.678274e-02 -0.759918
2019-11-08 07:59:25,215 valid 000 1.474592e-02 -0.791874
2019-11-08 07:59:34,656 valid 050 1.510010e-02 -0.822902
2019-11-08 07:59:42,967 validation loss; R2: 1.538274e-02 -1.053903
2019-11-08 07:59:43,033 epoch 879 lr 1.000000e-05
2019-11-08 07:59:43,820 train 000 1.663927e-02 0.075222
2019-11-08 07:59:53,619 train 050 1.665316e-02 -0.642859
2019-11-08 08:00:03,453 train 100 1.663994e-02 -0.618257
2019-11-08 08:00:13,286 train 150 1.672470e-02 -0.626224
2019-11-08 08:00:23,143 train 200 1.678723e-02 -0.695452
2019-11-08 08:00:32,972 train 250 1.683078e-02 -0.733641
2019-11-08 08:00:42,771 train 300 1.682755e-02 -0.692201
2019-11-08 08:00:52,582 train 350 1.682172e-02 -0.696744
2019-11-08 08:01:02,397 train 400 1.685248e-02 -0.713998
2019-11-08 08:01:12,204 train 450 1.688242e-02 -0.742853
2019-11-08 08:01:22,049 train 500 1.685995e-02 -0.713856
2019-11-08 08:01:31,888 train 550 1.683563e-02 -0.721503
2019-11-08 08:01:41,722 train 600 1.682457e-02 -0.720900
2019-11-08 08:01:51,565 train 650 1.686096e-02 -0.778448
2019-11-08 08:02:01,407 train 700 1.683619e-02 -0.769015
2019-11-08 08:02:11,234 train 750 1.686309e-02 -0.762796
2019-11-08 08:02:21,063 train 800 1.685094e-02 -0.758214
2019-11-08 08:02:30,884 train 850 1.683818e-02 -0.768534
2019-11-08 08:02:33,826 training loss; R2: 1.683896e-02 -0.768446
2019-11-08 08:02:34,478 valid 000 1.393988e-02 -0.025623
2019-11-08 08:02:43,868 valid 050 1.364495e-02 -1.655035
2019-11-08 08:02:52,271 validation loss; R2: 1.375108e-02 -2.721580
2019-11-08 08:02:52,334 epoch 880 lr 1.000000e-05
2019-11-08 08:02:53,098 train 000 1.574858e-02 -5.636565
2019-11-08 08:03:02,862 train 050 1.663727e-02 -0.818941
2019-11-08 08:03:12,627 train 100 1.659674e-02 -0.720182
2019-11-08 08:03:22,407 train 150 1.670131e-02 -0.744746
2019-11-08 08:03:32,171 train 200 1.671221e-02 -0.690662
2019-11-08 08:03:41,947 train 250 1.666765e-02 -0.715418
2019-11-08 08:03:51,726 train 300 1.662900e-02 -0.725118
2019-11-08 08:04:01,506 train 350 1.663449e-02 -0.735806
2019-11-08 08:04:11,288 train 400 1.667626e-02 -0.802627
2019-11-08 08:04:21,080 train 450 1.670974e-02 -0.792308
2019-11-08 08:04:30,886 train 500 1.671088e-02 -0.790174
2019-11-08 08:04:40,670 train 550 1.673526e-02 -0.793493
2019-11-08 08:04:50,464 train 600 1.670864e-02 -0.783294
2019-11-08 08:05:00,252 train 650 1.668483e-02 -0.763981
2019-11-08 08:05:10,057 train 700 1.666011e-02 -0.828228
2019-11-08 08:05:19,868 train 750 1.664386e-02 -0.811947
2019-11-08 08:05:29,674 train 800 1.666335e-02 -0.993393
2019-11-08 08:05:39,479 train 850 1.669129e-02 -1.001284
2019-11-08 08:05:42,409 training loss; R2: 1.670320e-02 -0.992860
2019-11-08 08:05:43,094 valid 000 1.689622e-02 -0.426027
2019-11-08 08:05:52,460 valid 050 1.499564e-02 -0.977735
2019-11-08 08:06:00,785 validation loss; R2: 1.488910e-02 -8.089697
2019-11-08 08:06:00,852 epoch 881 lr 1.000000e-05
2019-11-08 08:06:01,562 train 000 1.416283e-02 -1.408694
2019-11-08 08:06:11,298 train 050 1.648456e-02 -0.809540
2019-11-08 08:06:21,040 train 100 1.647641e-02 -0.920967
2019-11-08 08:06:30,811 train 150 1.671854e-02 -0.827281
2019-11-08 08:06:40,600 train 200 1.670514e-02 -0.825903
2019-11-08 08:06:50,375 train 250 1.659935e-02 -1.122534
2019-11-08 08:07:00,148 train 300 1.662797e-02 -1.047282
2019-11-08 08:07:09,918 train 350 1.663411e-02 -1.093960
2019-11-08 08:07:19,700 train 400 1.664586e-02 -1.051655
2019-11-08 08:07:29,488 train 450 1.665840e-02 -1.000674
2019-11-08 08:07:39,278 train 500 1.669704e-02 -0.966338
2019-11-08 08:07:49,077 train 550 1.672921e-02 -0.935600
2019-11-08 08:07:58,867 train 600 1.674078e-02 -0.996416
2019-11-08 08:08:08,650 train 650 1.674687e-02 -0.968601
2019-11-08 08:08:18,433 train 700 1.676081e-02 -0.931413
2019-11-08 08:08:28,221 train 750 1.674929e-02 -0.915115
2019-11-08 08:08:38,024 train 800 1.676078e-02 -0.896986
2019-11-08 08:08:47,803 train 850 1.678603e-02 -0.872572
2019-11-08 08:08:50,729 training loss; R2: 1.678852e-02 -0.869055
2019-11-08 08:08:51,377 valid 000 1.466736e-02 0.083442
2019-11-08 08:09:00,818 valid 050 1.450769e-02 -0.544890
2019-11-08 08:09:09,217 validation loss; R2: 1.424561e-02 -0.678041
2019-11-08 08:09:09,283 epoch 882 lr 1.000000e-05
2019-11-08 08:09:10,061 train 000 1.670927e-02 -0.701415
2019-11-08 08:09:19,805 train 050 1.685622e-02 -0.464636
2019-11-08 08:09:29,579 train 100 1.688631e-02 -0.541680
2019-11-08 08:09:39,362 train 150 1.700572e-02 -6.418852
2019-11-08 08:09:49,146 train 200 1.703536e-02 -4.995541
2019-11-08 08:09:58,912 train 250 1.694584e-02 -4.144674
2019-11-08 08:10:08,700 train 300 1.688078e-02 -3.578708
2019-11-08 08:10:18,486 train 350 1.687499e-02 -3.181022
2019-11-08 08:10:28,267 train 400 1.692514e-02 -2.872499
2019-11-08 08:10:38,051 train 450 1.689920e-02 -2.645717
2019-11-08 08:10:47,823 train 500 1.683007e-02 -2.469766
2019-11-08 08:10:57,626 train 550 1.680553e-02 -2.306159
2019-11-08 08:11:07,417 train 600 1.682048e-02 -2.224534
2019-11-08 08:11:17,208 train 650 1.678336e-02 -2.097139
2019-11-08 08:11:26,994 train 700 1.675700e-02 -1.993801
2019-11-08 08:11:36,801 train 750 1.679369e-02 -1.929227
2019-11-08 08:11:46,611 train 800 1.678387e-02 -1.870793
2019-11-08 08:11:56,418 train 850 1.676201e-02 -1.801225
2019-11-08 08:11:59,342 training loss; R2: 1.676646e-02 -1.788930
2019-11-08 08:11:59,967 valid 000 1.401932e-02 -1.872153
2019-11-08 08:12:09,399 valid 050 1.618341e-02 -1.013832
2019-11-08 08:12:17,723 validation loss; R2: 1.604054e-02 -1.078206
2019-11-08 08:12:17,793 epoch 883 lr 1.000000e-05
2019-11-08 08:12:18,512 train 000 1.839158e-02 -0.008944
2019-11-08 08:12:28,261 train 050 1.709690e-02 -0.707941
2019-11-08 08:12:37,993 train 100 1.688751e-02 -0.687359
2019-11-08 08:12:47,760 train 150 1.683507e-02 -0.661450
2019-11-08 08:12:57,523 train 200 1.677679e-02 -0.645496
2019-11-08 08:13:07,284 train 250 1.680639e-02 -0.682292
2019-11-08 08:13:17,045 train 300 1.680934e-02 -0.683631
2019-11-08 08:13:26,834 train 350 1.681479e-02 -0.688400
2019-11-08 08:13:36,602 train 400 1.684331e-02 -0.741243
2019-11-08 08:13:46,373 train 450 1.684720e-02 -0.738128
2019-11-08 08:13:56,146 train 500 1.680841e-02 -0.737103
2019-11-08 08:14:05,929 train 550 1.680492e-02 -0.732393
2019-11-08 08:14:15,707 train 600 1.678518e-02 -0.747836
2019-11-08 08:14:25,483 train 650 1.679720e-02 -0.747841
2019-11-08 08:14:35,265 train 700 1.678209e-02 -0.756732
2019-11-08 08:14:45,049 train 750 1.680866e-02 -0.758629
2019-11-08 08:14:54,834 train 800 1.680983e-02 -0.750877
2019-11-08 08:15:04,649 train 850 1.682796e-02 -0.744923
2019-11-08 08:15:07,572 training loss; R2: 1.683508e-02 -0.751554
2019-11-08 08:15:08,231 valid 000 1.394136e-02 -1.165048
2019-11-08 08:15:17,628 valid 050 1.597593e-02 -0.995864
2019-11-08 08:15:25,919 validation loss; R2: 1.599559e-02 -1.123859
2019-11-08 08:15:25,983 epoch 884 lr 1.000000e-05
2019-11-08 08:15:26,714 train 000 1.748890e-02 -0.004213
2019-11-08 08:15:36,484 train 050 1.710678e-02 -0.553994
2019-11-08 08:15:46,249 train 100 1.678549e-02 -0.603596
2019-11-08 08:15:56,020 train 150 1.674985e-02 -0.594561
2019-11-08 08:16:05,788 train 200 1.682137e-02 -0.605606
2019-11-08 08:16:15,553 train 250 1.684527e-02 -0.674477
2019-11-08 08:16:25,338 train 300 1.682938e-02 -0.701407
2019-11-08 08:16:35,150 train 350 1.681214e-02 -0.705921
2019-11-08 08:16:44,909 train 400 1.680115e-02 -0.694481
2019-11-08 08:16:54,682 train 450 1.675918e-02 -0.868487
2019-11-08 08:17:04,465 train 500 1.676874e-02 -0.860932
2019-11-08 08:17:14,229 train 550 1.675178e-02 -0.846047
2019-11-08 08:17:23,997 train 600 1.676672e-02 -0.862808
2019-11-08 08:17:33,775 train 650 1.673698e-02 -0.872459
2019-11-08 08:17:43,555 train 700 1.673171e-02 -0.864192
2019-11-08 08:17:53,341 train 750 1.673298e-02 -0.849090
2019-11-08 08:18:03,104 train 800 1.670518e-02 -0.842837
2019-11-08 08:18:12,908 train 850 1.671155e-02 -0.842613
2019-11-08 08:18:15,841 training loss; R2: 1.671234e-02 -0.843247
2019-11-08 08:18:16,529 valid 000 1.724767e-02 -0.428207
2019-11-08 08:18:25,889 valid 050 1.954662e-02 -1.856671
2019-11-08 08:18:34,344 validation loss; R2: 1.941841e-02 -2.056224
2019-11-08 08:18:34,411 epoch 885 lr 1.000000e-05
2019-11-08 08:18:35,193 train 000 1.644099e-02 -0.857763
2019-11-08 08:18:44,946 train 050 1.704870e-02 -0.706019
2019-11-08 08:18:54,702 train 100 1.685496e-02 -0.718169
2019-11-08 08:19:04,480 train 150 1.669617e-02 -0.707399
2019-11-08 08:19:14,271 train 200 1.659804e-02 -0.727277
2019-11-08 08:19:24,048 train 250 1.657352e-02 -0.745482
2019-11-08 08:19:33,854 train 300 1.659921e-02 -0.758828
2019-11-08 08:19:43,659 train 350 1.666973e-02 -0.758267
2019-11-08 08:19:53,450 train 400 1.662333e-02 -0.780357
2019-11-08 08:20:03,259 train 450 1.664777e-02 -0.773844
2019-11-08 08:20:13,045 train 500 1.666122e-02 -0.749124
2019-11-08 08:20:22,846 train 550 1.670812e-02 -0.733706
2019-11-08 08:20:32,642 train 600 1.668680e-02 -0.729779
2019-11-08 08:20:42,455 train 650 1.667982e-02 -0.723373
2019-11-08 08:20:52,232 train 700 1.665283e-02 -0.721383
2019-11-08 08:21:02,042 train 750 1.667231e-02 -0.713466
2019-11-08 08:21:11,868 train 800 1.671253e-02 -0.715902
2019-11-08 08:21:21,683 train 850 1.671559e-02 -0.719579
2019-11-08 08:21:24,622 training loss; R2: 1.671850e-02 -0.714253
2019-11-08 08:21:25,295 valid 000 3.163584e-02 -2.889399
2019-11-08 08:21:34,680 valid 050 3.156162e-02 -11.739019
2019-11-08 08:21:42,996 validation loss; R2: 3.214550e-02 -7.832594
2019-11-08 08:21:43,063 epoch 886 lr 1.000000e-05
2019-11-08 08:21:43,829 train 000 1.502587e-02 -0.489536
2019-11-08 08:21:53,562 train 050 1.641546e-02 -0.777012
2019-11-08 08:22:03,356 train 100 1.680930e-02 -0.755088
2019-11-08 08:22:13,148 train 150 1.685623e-02 -0.805893
2019-11-08 08:22:22,943 train 200 1.686847e-02 -0.766848
2019-11-08 08:22:32,723 train 250 1.683618e-02 -0.787853
2019-11-08 08:22:42,528 train 300 1.682081e-02 -0.761172
2019-11-08 08:22:52,328 train 350 1.683053e-02 -0.754253
2019-11-08 08:23:02,120 train 400 1.687636e-02 -0.803756
2019-11-08 08:23:11,910 train 450 1.683451e-02 -0.809034
2019-11-08 08:23:21,711 train 500 1.685109e-02 -0.840635
2019-11-08 08:23:31,519 train 550 1.686155e-02 -0.828717
2019-11-08 08:23:41,323 train 600 1.685147e-02 -0.809749
2019-11-08 08:23:51,146 train 650 1.682065e-02 -0.813469
2019-11-08 08:24:00,961 train 700 1.681262e-02 -0.794156
2019-11-08 08:24:10,738 train 750 1.679671e-02 -0.808394
2019-11-08 08:24:20,542 train 800 1.678718e-02 -0.793845
2019-11-08 08:24:30,341 train 850 1.679272e-02 -0.792373
2019-11-08 08:24:33,269 training loss; R2: 1.679579e-02 -0.799622
2019-11-08 08:24:33,907 valid 000 1.350462e-02 -1.392527
2019-11-08 08:24:43,294 valid 050 1.519700e-02 -0.833794
2019-11-08 08:24:51,642 validation loss; R2: 1.523385e-02 -0.869741
2019-11-08 08:24:51,707 epoch 887 lr 1.000000e-05
2019-11-08 08:24:52,497 train 000 1.441948e-02 -0.952332
2019-11-08 08:25:02,233 train 050 1.678487e-02 -0.688028
2019-11-08 08:25:11,992 train 100 1.670133e-02 -0.648928
2019-11-08 08:25:21,774 train 150 1.672885e-02 -0.854812
2019-11-08 08:25:31,556 train 200 1.675905e-02 -0.865323
2019-11-08 08:25:41,367 train 250 1.680515e-02 -0.830147
2019-11-08 08:25:51,155 train 300 1.681078e-02 -0.776285
2019-11-08 08:26:00,958 train 350 1.676457e-02 -0.730442
2019-11-08 08:26:10,764 train 400 1.674804e-02 -0.713068
2019-11-08 08:26:20,563 train 450 1.677611e-02 -0.720120
2019-11-08 08:26:30,362 train 500 1.676722e-02 -0.722796
2019-11-08 08:26:40,153 train 550 1.675749e-02 -0.759771
2019-11-08 08:26:49,965 train 600 1.675092e-02 -0.772629
2019-11-08 08:26:59,778 train 650 1.674495e-02 -0.781893
2019-11-08 08:27:09,598 train 700 1.674023e-02 -0.768115
2019-11-08 08:27:19,394 train 750 1.672874e-02 -0.761692
2019-11-08 08:27:29,195 train 800 1.675546e-02 -0.752730
2019-11-08 08:27:38,985 train 850 1.674995e-02 -0.733426
2019-11-08 08:27:41,919 training loss; R2: 1.675399e-02 -0.728613
2019-11-08 08:27:42,553 valid 000 2.446406e-02 -5.484114
2019-11-08 08:27:51,981 valid 050 2.869693e-02 -3.017756
2019-11-08 08:28:00,451 validation loss; R2: 2.925035e-02 -2.963976
2019-11-08 08:28:00,513 epoch 888 lr 1.000000e-05
2019-11-08 08:28:01,286 train 000 1.845190e-02 -0.070440
2019-11-08 08:28:11,039 train 050 1.673863e-02 -0.703672
2019-11-08 08:28:20,796 train 100 1.671896e-02 -1.252629
2019-11-08 08:28:30,582 train 150 1.667734e-02 -1.052812
2019-11-08 08:28:40,364 train 200 1.666948e-02 -1.026900
2019-11-08 08:28:50,134 train 250 1.665065e-02 -1.012681
2019-11-08 08:28:59,931 train 300 1.671417e-02 -0.976315
2019-11-08 08:29:09,730 train 350 1.675277e-02 -0.952495
2019-11-08 08:29:19,515 train 400 1.672190e-02 -0.930609
2019-11-08 08:29:29,304 train 450 1.674173e-02 -0.936135
2019-11-08 08:29:39,088 train 500 1.676376e-02 -0.966194
2019-11-08 08:29:48,873 train 550 1.676195e-02 -0.929251
2019-11-08 08:29:58,664 train 600 1.674878e-02 -0.940364
2019-11-08 08:30:08,465 train 650 1.675431e-02 -0.936461
2019-11-08 08:30:18,244 train 700 1.678851e-02 -0.911471
2019-11-08 08:30:28,021 train 750 1.676695e-02 -0.887550
2019-11-08 08:30:37,812 train 800 1.675692e-02 -0.910689
2019-11-08 08:30:47,601 train 850 1.675340e-02 -0.915463
2019-11-08 08:30:50,530 training loss; R2: 1.677085e-02 -0.910967
2019-11-08 08:30:51,188 valid 000 1.345403e-02 0.052644
2019-11-08 08:31:00,609 valid 050 1.382015e-02 -0.618283
2019-11-08 08:31:09,026 validation loss; R2: 1.401738e-02 -0.765585
2019-11-08 08:31:09,093 epoch 889 lr 1.000000e-05
2019-11-08 08:31:09,865 train 000 1.702804e-02 -0.971953
2019-11-08 08:31:19,628 train 050 1.662790e-02 -7.293477
2019-11-08 08:31:29,405 train 100 1.655455e-02 -4.036713
2019-11-08 08:31:39,177 train 150 1.677132e-02 -3.079185
2019-11-08 08:31:48,954 train 200 1.667071e-02 -2.492616
2019-11-08 08:31:58,747 train 250 1.671984e-02 -2.137891
2019-11-08 08:32:08,539 train 300 1.666047e-02 -1.943677
2019-11-08 08:32:18,328 train 350 1.667487e-02 -1.786445
2019-11-08 08:32:28,133 train 400 1.668425e-02 -1.671128
2019-11-08 08:32:37,919 train 450 1.669196e-02 -1.562688
2019-11-08 08:32:47,707 train 500 1.670125e-02 -1.473984
2019-11-08 08:32:57,523 train 550 1.669726e-02 -1.439605
2019-11-08 08:33:07,325 train 600 1.673136e-02 -1.408283
2019-11-08 08:33:17,129 train 650 1.670788e-02 -1.350490
2019-11-08 08:33:26,906 train 700 1.669461e-02 -1.342473
2019-11-08 08:33:36,695 train 750 1.674387e-02 -1.312196
2019-11-08 08:33:46,479 train 800 1.673114e-02 -1.283305
2019-11-08 08:33:56,268 train 850 1.672660e-02 -1.255498
2019-11-08 08:33:59,190 training loss; R2: 1.673574e-02 -1.251052
2019-11-08 08:33:59,892 valid 000 1.838163e-02 0.008695
2019-11-08 08:34:09,214 valid 050 1.770966e-02 -1.223895
2019-11-08 08:34:17,547 validation loss; R2: 1.759722e-02 -1.579196
2019-11-08 08:34:17,612 epoch 890 lr 1.000000e-05
2019-11-08 08:34:18,378 train 000 1.716077e-02 -0.510874
2019-11-08 08:34:28,125 train 050 1.658753e-02 -0.935736
2019-11-08 08:34:37,864 train 100 1.638493e-02 -0.796574
2019-11-08 08:34:47,646 train 150 1.649970e-02 -1.238835
2019-11-08 08:34:57,419 train 200 1.645238e-02 -1.113961
2019-11-08 08:35:07,198 train 250 1.654363e-02 -1.027961
2019-11-08 08:35:17,002 train 300 1.660546e-02 -1.025850
2019-11-08 08:35:26,796 train 350 1.653944e-02 -0.997034
2019-11-08 08:35:36,583 train 400 1.660593e-02 -0.933705
2019-11-08 08:35:46,385 train 450 1.667820e-02 -0.880057
2019-11-08 08:35:56,172 train 500 1.665953e-02 -0.889091
2019-11-08 08:36:05,980 train 550 1.667324e-02 -0.879550
2019-11-08 08:36:15,794 train 600 1.668433e-02 -0.856064
2019-11-08 08:36:25,594 train 650 1.668575e-02 -0.867700
2019-11-08 08:36:35,394 train 700 1.671726e-02 -0.858854
2019-11-08 08:36:45,192 train 750 1.670784e-02 -0.854681
2019-11-08 08:36:54,984 train 800 1.670641e-02 -0.847532
2019-11-08 08:37:04,778 train 850 1.669793e-02 -0.851524
2019-11-08 08:37:07,707 training loss; R2: 1.671172e-02 -0.847071
2019-11-08 08:37:08,383 valid 000 1.273161e-02 -3.182915
2019-11-08 08:37:17,779 valid 050 1.492974e-02 -1.149896
2019-11-08 08:37:26,096 validation loss; R2: 1.518668e-02 -0.923515
2019-11-08 08:37:26,162 epoch 891 lr 1.000000e-05
2019-11-08 08:37:26,918 train 000 1.773557e-02 -0.114204
2019-11-08 08:37:36,675 train 050 1.689614e-02 -0.563871
2019-11-08 08:37:46,474 train 100 1.695470e-02 -0.600084
2019-11-08 08:37:56,263 train 150 1.685838e-02 -0.561090
2019-11-08 08:38:06,046 train 200 1.695579e-02 -0.547102
2019-11-08 08:38:15,834 train 250 1.688146e-02 -0.586593
2019-11-08 08:38:25,627 train 300 1.682136e-02 -0.613722
2019-11-08 08:38:35,422 train 350 1.680277e-02 -0.634461
2019-11-08 08:38:45,224 train 400 1.682342e-02 -0.661760
2019-11-08 08:38:55,009 train 450 1.677530e-02 -0.676665
2019-11-08 08:39:04,793 train 500 1.675392e-02 -0.659401
2019-11-08 08:39:14,577 train 550 1.673670e-02 -0.650862
2019-11-08 08:39:24,358 train 600 1.675098e-02 -0.657119
2019-11-08 08:39:34,147 train 650 1.672128e-02 -0.654061
2019-11-08 08:39:43,943 train 700 1.670439e-02 -0.681264
2019-11-08 08:39:53,722 train 750 1.671501e-02 -0.682936
2019-11-08 08:40:03,520 train 800 1.670002e-02 -0.691916
2019-11-08 08:40:13,327 train 850 1.670400e-02 -0.712929
2019-11-08 08:40:16,246 training loss; R2: 1.669389e-02 -0.710190
2019-11-08 08:40:16,901 valid 000 2.681113e-02 -4.685198
2019-11-08 08:40:26,365 valid 050 2.674664e-02 -2.253360
2019-11-08 08:40:34,680 validation loss; R2: 2.639575e-02 -2.545535
2019-11-08 08:40:34,744 epoch 892 lr 1.000000e-05
2019-11-08 08:40:35,538 train 000 1.401061e-02 -6.638580
2019-11-08 08:40:45,279 train 050 1.685655e-02 -0.922836
2019-11-08 08:40:55,035 train 100 1.678485e-02 -0.822620
2019-11-08 08:41:04,807 train 150 1.678489e-02 -0.816336
2019-11-08 08:41:14,576 train 200 1.677458e-02 -0.783547
2019-11-08 08:41:24,335 train 250 1.673518e-02 -0.749025
2019-11-08 08:41:34,122 train 300 1.676029e-02 -0.728571
2019-11-08 08:41:43,903 train 350 1.678198e-02 -0.699676
2019-11-08 08:41:53,695 train 400 1.677272e-02 -0.719397
2019-11-08 08:42:03,472 train 450 1.671682e-02 -56.194088
2019-11-08 08:42:13,252 train 500 1.675232e-02 -50.663946
2019-11-08 08:42:23,031 train 550 1.678936e-02 -46.138367
2019-11-08 08:42:32,790 train 600 1.678071e-02 -42.342072
2019-11-08 08:42:42,546 train 650 1.679272e-02 -39.145146
2019-11-08 08:42:52,332 train 700 1.679133e-02 -36.394593
2019-11-08 08:43:02,117 train 750 1.678447e-02 -34.011918
2019-11-08 08:43:11,905 train 800 1.677926e-02 -31.925238
2019-11-08 08:43:21,677 train 850 1.680248e-02 -30.092911
2019-11-08 08:43:24,601 training loss; R2: 1.678851e-02 -29.584410
2019-11-08 08:43:25,282 valid 000 1.507494e-02 0.023091
2019-11-08 08:43:34,710 valid 050 1.518480e-02 -3.841740
2019-11-08 08:43:43,107 validation loss; R2: 1.481672e-02 -2.604410
2019-11-08 08:43:43,171 epoch 893 lr 1.000000e-05
2019-11-08 08:43:43,958 train 000 1.507605e-02 -1.148352
2019-11-08 08:43:53,673 train 050 1.644008e-02 -0.565829
2019-11-08 08:44:03,417 train 100 1.658017e-02 -0.625868
2019-11-08 08:44:13,189 train 150 1.657546e-02 -0.685375
2019-11-08 08:44:22,972 train 200 1.661992e-02 -0.671585
2019-11-08 08:44:32,734 train 250 1.658676e-02 -0.651654
2019-11-08 08:44:42,500 train 300 1.660176e-02 -0.728155
2019-11-08 08:44:52,281 train 350 1.665484e-02 -0.761449
2019-11-08 08:45:02,079 train 400 1.664740e-02 -0.728037
2019-11-08 08:45:11,861 train 450 1.664008e-02 -0.746155
2019-11-08 08:45:21,636 train 500 1.664850e-02 -0.756258
2019-11-08 08:45:31,415 train 550 1.663611e-02 -0.767421
2019-11-08 08:45:41,196 train 600 1.663819e-02 -0.758000
2019-11-08 08:45:50,980 train 650 1.666370e-02 -0.758746
2019-11-08 08:46:00,767 train 700 1.665835e-02 -0.753969
2019-11-08 08:46:10,534 train 750 1.666386e-02 -0.751666
2019-11-08 08:46:20,325 train 800 1.667709e-02 -0.761266
2019-11-08 08:46:30,123 train 850 1.670601e-02 -0.743203
2019-11-08 08:46:33,044 training loss; R2: 1.671715e-02 -0.738454
2019-11-08 08:46:33,701 valid 000 1.609954e-02 -0.004875
2019-11-08 08:46:43,090 valid 050 1.558581e-02 -1.650993
2019-11-08 08:46:51,387 validation loss; R2: 1.559674e-02 -1.762736
2019-11-08 08:46:51,454 epoch 894 lr 1.000000e-05
2019-11-08 08:46:52,240 train 000 1.870762e-02 -0.586678
2019-11-08 08:47:01,982 train 050 1.664444e-02 -0.902400
2019-11-08 08:47:11,750 train 100 1.651165e-02 -0.800326
2019-11-08 08:47:21,775 train 150 1.649965e-02 -0.669587
2019-11-08 08:47:31,904 train 200 1.651837e-02 -0.707097
2019-11-08 08:47:42,019 train 250 1.660346e-02 -0.692036
2019-11-08 08:47:52,161 train 300 1.662499e-02 -0.675058
2019-11-08 08:48:02,295 train 350 1.664602e-02 -0.683059
2019-11-08 08:48:12,416 train 400 1.667338e-02 -0.687685
2019-11-08 08:48:22,577 train 450 1.670536e-02 -0.702266
2019-11-08 08:48:32,750 train 500 1.667266e-02 -0.742338
2019-11-08 08:48:42,929 train 550 1.667485e-02 -0.740218
2019-11-08 08:48:53,086 train 600 1.669835e-02 -0.730054
2019-11-08 08:49:03,241 train 650 1.673687e-02 -0.739172
2019-11-08 08:49:13,429 train 700 1.671995e-02 -0.730764
2019-11-08 08:49:23,603 train 750 1.670707e-02 -0.731728
2019-11-08 08:49:33,781 train 800 1.672506e-02 -0.728942
2019-11-08 08:49:43,962 train 850 1.672474e-02 -0.719119
2019-11-08 08:49:46,993 training loss; R2: 1.672737e-02 -0.721970
2019-11-08 08:49:47,711 valid 000 1.462391e-02 -1.307531
2019-11-08 08:49:57,050 valid 050 1.395155e-02 -1.267621
2019-11-08 08:50:05,411 validation loss; R2: 1.384855e-02 -1.216409
2019-11-08 08:50:05,490 epoch 895 lr 1.000000e-05
2019-11-08 08:50:06,231 train 000 1.595432e-02 -1.425405
2019-11-08 08:50:15,946 train 050 1.628152e-02 -0.646989
2019-11-08 08:50:25,687 train 100 1.655956e-02 -0.618148
2019-11-08 08:50:35,446 train 150 1.662578e-02 -0.597229
2019-11-08 08:50:45,196 train 200 1.661929e-02 -0.641168
2019-11-08 08:50:54,952 train 250 1.665275e-02 -0.722428
2019-11-08 08:51:04,715 train 300 1.665931e-02 -0.719185
2019-11-08 08:51:14,466 train 350 1.659826e-02 -0.715037
2019-11-08 08:51:24,235 train 400 1.665470e-02 -0.842765
2019-11-08 08:51:34,012 train 450 1.666984e-02 -0.844080
2019-11-08 08:51:43,761 train 500 1.668010e-02 -0.823650
2019-11-08 08:51:53,521 train 550 1.668015e-02 -0.823988
2019-11-08 08:52:03,295 train 600 1.668498e-02 -0.837749
2019-11-08 08:52:13,065 train 650 1.668628e-02 -0.820638
2019-11-08 08:52:22,827 train 700 1.670760e-02 -0.824181
2019-11-08 08:52:32,602 train 750 1.671505e-02 -0.816766
2019-11-08 08:52:42,403 train 800 1.671471e-02 -0.810506
2019-11-08 08:52:52,199 train 850 1.673453e-02 -0.810406
2019-11-08 08:52:55,118 training loss; R2: 1.673836e-02 -0.801036
2019-11-08 08:52:55,755 valid 000 1.744469e-02 -0.003975
2019-11-08 08:53:05,118 valid 050 1.662821e-02 -1.669045
2019-11-08 08:53:13,485 validation loss; R2: 1.656852e-02 -1.907245
2019-11-08 08:53:13,552 epoch 896 lr 1.000000e-05
2019-11-08 08:53:14,340 train 000 1.583074e-02 -0.184846
2019-11-08 08:53:24,056 train 050 1.640669e-02 -0.871450
2019-11-08 08:53:33,813 train 100 1.647729e-02 -0.828541
2019-11-08 08:53:43,563 train 150 1.649371e-02 -0.836755
2019-11-08 08:53:53,316 train 200 1.656348e-02 -0.837266
2019-11-08 08:54:03,081 train 250 1.667957e-02 -0.862952
2019-11-08 08:54:12,832 train 300 1.663983e-02 -0.793125
2019-11-08 08:54:22,595 train 350 1.668367e-02 -0.779925
2019-11-08 08:54:32,361 train 400 1.671721e-02 -0.767745
2019-11-08 08:54:42,119 train 450 1.669526e-02 -0.766238
2019-11-08 08:54:51,902 train 500 1.674094e-02 -0.759216
2019-11-08 08:55:01,651 train 550 1.675446e-02 -0.741284
2019-11-08 08:55:11,414 train 600 1.675503e-02 -0.720210
2019-11-08 08:55:21,169 train 650 1.673377e-02 -0.704815
2019-11-08 08:55:30,935 train 700 1.671945e-02 -0.719019
2019-11-08 08:55:40,702 train 750 1.672676e-02 -0.723667
2019-11-08 08:55:50,474 train 800 1.672080e-02 -0.722228
2019-11-08 08:56:00,263 train 850 1.671177e-02 -0.746187
2019-11-08 08:56:03,190 training loss; R2: 1.671011e-02 -0.742350
2019-11-08 08:56:03,815 valid 000 1.620112e-02 0.128357
2019-11-08 08:56:13,212 valid 050 1.488239e-02 -1.322309
2019-11-08 08:56:21,662 validation loss; R2: 1.466547e-02 -1.122536
2019-11-08 08:56:21,726 epoch 897 lr 1.000000e-05
2019-11-08 08:56:22,519 train 000 1.738974e-02 -1.021674
2019-11-08 08:56:32,226 train 050 1.642284e-02 -0.619426
2019-11-08 08:56:41,961 train 100 1.633567e-02 -0.658105
2019-11-08 08:56:51,732 train 150 1.660341e-02 -0.672713
2019-11-08 08:57:01,504 train 200 1.667698e-02 -0.669877
2019-11-08 08:57:11,308 train 250 1.659964e-02 -0.678921
2019-11-08 08:57:21,115 train 300 1.657129e-02 -0.664849
2019-11-08 08:57:30,919 train 350 1.659997e-02 -0.673369
2019-11-08 08:57:40,733 train 400 1.660914e-02 -0.710909
2019-11-08 08:57:50,541 train 450 1.661346e-02 -0.707971
2019-11-08 08:58:00,353 train 500 1.664558e-02 -0.722250
2019-11-08 08:58:10,175 train 550 1.659978e-02 -0.729846
2019-11-08 08:58:19,979 train 600 1.661959e-02 -0.725244
2019-11-08 08:58:29,775 train 650 1.663249e-02 -0.725182
2019-11-08 08:58:39,589 train 700 1.667329e-02 -0.721676
2019-11-08 08:58:49,410 train 750 1.666212e-02 -0.722764
2019-11-08 08:58:59,218 train 800 1.667346e-02 -1.121992
2019-11-08 08:59:09,044 train 850 1.665080e-02 -1.112091
2019-11-08 08:59:11,981 training loss; R2: 1.664341e-02 -1.109581
2019-11-08 08:59:12,616 valid 000 1.741029e-02 -0.700779
2019-11-08 08:59:22,033 valid 050 1.737725e-02 -1.964014
2019-11-08 08:59:30,376 validation loss; R2: 1.720108e-02 -1.898472
2019-11-08 08:59:30,438 epoch 898 lr 1.000000e-05
2019-11-08 08:59:31,178 train 000 2.232458e-02 -1.438963
2019-11-08 08:59:40,928 train 050 1.714681e-02 -0.699067
2019-11-08 08:59:50,712 train 100 1.694288e-02 -0.816370
2019-11-08 09:00:00,500 train 150 1.688941e-02 -0.757632
2019-11-08 09:00:10,300 train 200 1.684278e-02 -0.749971
2019-11-08 09:00:20,098 train 250 1.683116e-02 -0.789831
2019-11-08 09:00:29,895 train 300 1.680239e-02 -0.784782
2019-11-08 09:00:39,692 train 350 1.677951e-02 -0.741532
2019-11-08 09:00:49,482 train 400 1.676722e-02 -0.765356
2019-11-08 09:00:59,272 train 450 1.670068e-02 -0.748090
2019-11-08 09:01:09,075 train 500 1.672497e-02 -0.740139
2019-11-08 09:01:18,895 train 550 1.671025e-02 -0.731887
2019-11-08 09:01:28,695 train 600 1.671416e-02 -0.786993
2019-11-08 09:01:38,492 train 650 1.670477e-02 -0.803850
2019-11-08 09:01:48,310 train 700 1.668431e-02 -0.850022
2019-11-08 09:01:58,111 train 750 1.668826e-02 -0.824030
2019-11-08 09:02:07,940 train 800 1.671406e-02 -0.808634
2019-11-08 09:02:17,755 train 850 1.672016e-02 -0.796372
2019-11-08 09:02:20,693 training loss; R2: 1.673056e-02 -0.790971
2019-11-08 09:02:21,390 valid 000 1.557136e-02 -0.145806
2019-11-08 09:02:30,770 valid 050 1.580439e-02 -1.523006
2019-11-08 09:02:39,081 validation loss; R2: 1.587361e-02 -1.303481
2019-11-08 09:02:39,145 epoch 899 lr 1.000000e-05
2019-11-08 09:02:39,924 train 000 1.666072e-02 -0.392969
2019-11-08 09:02:49,688 train 050 1.693671e-02 -0.520879
2019-11-08 09:02:59,465 train 100 1.686116e-02 -0.819145
2019-11-08 09:03:09,265 train 150 1.676491e-02 -0.730592
2019-11-08 09:03:19,049 train 200 1.678291e-02 -0.914525
2019-11-08 09:03:28,833 train 250 1.677652e-02 -0.876015
2019-11-08 09:03:38,631 train 300 1.680975e-02 -0.859900
2019-11-08 09:03:48,428 train 350 1.683346e-02 -19.103681
2019-11-08 09:03:58,238 train 400 1.678835e-02 -16.811240
2019-11-08 09:04:08,043 train 450 1.675474e-02 -15.045176
2019-11-08 09:04:17,837 train 500 1.675140e-02 -13.606348
2019-11-08 09:04:27,640 train 550 1.675386e-02 -12.427434
2019-11-08 09:04:37,434 train 600 1.675186e-02 -11.435338
2019-11-08 09:04:47,278 train 650 1.675137e-02 -10.607203
2019-11-08 09:04:57,119 train 700 1.674761e-02 -9.899032
2019-11-08 09:05:06,949 train 750 1.672124e-02 -9.283378
2019-11-08 09:05:16,787 train 800 1.673840e-02 -8.772237
2019-11-08 09:05:26,626 train 850 1.672361e-02 -8.313242
2019-11-08 09:05:29,561 training loss; R2: 1.672889e-02 -8.177906
2019-11-08 09:05:30,174 valid 000 3.241198e-02 -1.133614
2019-11-08 09:05:39,584 valid 050 3.624398e-02 -5.616241
2019-11-08 09:05:47,943 validation loss; R2: 3.623535e-02 -5.450280
2019-11-08 09:05:48,007 epoch 900 lr 1.000000e-05
2019-11-08 09:05:48,733 train 000 1.844719e-02 -0.009521
2019-11-08 09:05:58,505 train 050 1.663075e-02 -0.777998
2019-11-08 09:06:08,295 train 100 1.685536e-02 -0.747380
2019-11-08 09:06:18,062 train 150 1.684899e-02 -0.768473
2019-11-08 09:06:27,792 train 200 1.685453e-02 -0.791511
2019-11-08 09:06:37,527 train 250 1.690047e-02 -0.842881
2019-11-08 09:06:47,271 train 300 1.691236e-02 -0.850677
2019-11-08 09:06:57,006 train 350 1.689619e-02 -0.837551
2019-11-08 09:07:06,749 train 400 1.681999e-02 -0.808109
2019-11-08 09:07:16,492 train 450 1.678408e-02 -0.971757
2019-11-08 09:07:26,216 train 500 1.682318e-02 -0.959524
2019-11-08 09:07:35,971 train 550 1.678735e-02 -0.917416
2019-11-08 09:07:45,714 train 600 1.676890e-02 -0.910952
2019-11-08 09:07:55,485 train 650 1.679775e-02 -0.888785
2019-11-08 09:08:05,249 train 700 1.678821e-02 -0.875250
2019-11-08 09:08:15,017 train 750 1.676035e-02 -0.862784
2019-11-08 09:08:24,783 train 800 1.676351e-02 -0.842510
2019-11-08 09:08:34,556 train 850 1.678087e-02 -0.830520
2019-11-08 09:08:37,480 training loss; R2: 1.678287e-02 -0.829289
2019-11-08 09:08:38,074 valid 000 1.525760e-02 -1.769423
2019-11-08 09:08:47,501 valid 050 1.530791e-02 -1.050867
2019-11-08 09:08:55,798 validation loss; R2: 1.526009e-02 -1.090570
2019-11-08 09:08:55,862 epoch 901 lr 1.000000e-05
2019-11-08 09:08:56,610 train 000 1.804833e-02 -1.736581
2019-11-08 09:09:06,318 train 050 1.670166e-02 -0.802125
2019-11-08 09:09:16,031 train 100 1.667934e-02 -0.746950
2019-11-08 09:09:25,771 train 150 1.674474e-02 -0.692323
2019-11-08 09:09:35,495 train 200 1.674417e-02 -0.662428
2019-11-08 09:09:45,226 train 250 1.679140e-02 -0.640598
2019-11-08 09:09:54,951 train 300 1.669660e-02 -0.628797
2019-11-08 09:10:04,678 train 350 1.674863e-02 -1.051392
2019-11-08 09:10:14,402 train 400 1.676252e-02 -1.001475
2019-11-08 09:10:24,179 train 450 1.678050e-02 -0.960084
2019-11-08 09:10:33,981 train 500 1.673794e-02 -0.923670
2019-11-08 09:10:43,782 train 550 1.672840e-02 -1.021746
2019-11-08 09:10:53,580 train 600 1.671690e-02 -1.003153
2019-11-08 09:11:03,397 train 650 1.673446e-02 -0.997226
2019-11-08 09:11:13,212 train 700 1.670391e-02 -0.990371
2019-11-08 09:11:23,019 train 750 1.669018e-02 -0.964755
2019-11-08 09:11:32,832 train 800 1.670011e-02 -1.060991
2019-11-08 09:11:42,639 train 850 1.675044e-02 -1.046001
2019-11-08 09:11:45,580 training loss; R2: 1.674202e-02 -1.040887
2019-11-08 09:11:46,159 valid 000 1.571379e-02 -0.871379
2019-11-08 09:11:55,568 valid 050 1.585329e-02 -1.520482
2019-11-08 09:12:03,896 validation loss; R2: 1.591024e-02 -1.405108
2019-11-08 09:12:03,985 epoch 902 lr 1.000000e-05
2019-11-08 09:12:04,821 train 000 1.422553e-02 -0.154975
2019-11-08 09:12:14,958 train 050 1.641861e-02 -0.664864
2019-11-08 09:12:25,133 train 100 1.653738e-02 -0.677696
2019-11-08 09:12:35,302 train 150 1.668473e-02 -0.689859
2019-11-08 09:12:45,465 train 200 1.666120e-02 -0.719785
2019-11-08 09:12:55,638 train 250 1.666938e-02 -0.783488
2019-11-08 09:13:05,815 train 300 1.664730e-02 -0.779644
2019-11-08 09:13:16,028 train 350 1.669520e-02 -0.751127
2019-11-08 09:13:26,207 train 400 1.666098e-02 -0.746433
2019-11-08 09:13:36,387 train 450 1.665422e-02 -0.737080
2019-11-08 09:13:46,574 train 500 1.663838e-02 -0.729847
2019-11-08 09:13:56,753 train 550 1.666401e-02 -0.757427
2019-11-08 09:14:06,949 train 600 1.667835e-02 -0.749652
2019-11-08 09:14:17,126 train 650 1.665777e-02 -0.755199
2019-11-08 09:14:27,335 train 700 1.666828e-02 -0.744044
2019-11-08 09:14:37,528 train 750 1.668442e-02 -0.734902
2019-11-08 09:14:47,731 train 800 1.669419e-02 -0.723973
2019-11-08 09:14:57,929 train 850 1.667116e-02 -0.715017
2019-11-08 09:15:00,979 training loss; R2: 1.668578e-02 -0.709416
2019-11-08 09:15:01,675 valid 000 1.805815e-02 -0.342010
2019-11-08 09:15:11,045 valid 050 1.449579e-02 -1.553328
2019-11-08 09:15:19,387 validation loss; R2: 1.481559e-02 -1.323486
2019-11-08 09:15:19,455 epoch 903 lr 1.000000e-05
2019-11-08 09:15:20,223 train 000 1.467709e-02 -0.690702
2019-11-08 09:15:30,391 train 050 1.642390e-02 -1.433030
2019-11-08 09:15:40,582 train 100 1.668904e-02 -4.152275
2019-11-08 09:15:50,753 train 150 1.665708e-02 -2.954581
2019-11-08 09:16:00,933 train 200 1.667482e-02 -2.396617
2019-11-08 09:16:11,128 train 250 1.674579e-02 -2.057915
2019-11-08 09:16:21,320 train 300 1.671801e-02 -1.818916
2019-11-08 09:16:31,547 train 350 1.673082e-02 -1.642712
2019-11-08 09:16:41,742 train 400 1.668781e-02 -1.552289
2019-11-08 09:16:51,909 train 450 1.668237e-02 -1.473269
2019-11-08 09:17:02,073 train 500 1.670269e-02 -1.399398
2019-11-08 09:17:12,226 train 550 1.673297e-02 -1.389517
2019-11-08 09:17:22,385 train 600 1.672750e-02 -1.337784
2019-11-08 09:17:32,532 train 650 1.675202e-02 -1.290875
2019-11-08 09:17:42,676 train 700 1.678274e-02 -1.257679
2019-11-08 09:17:52,832 train 750 1.681899e-02 -1.204279
2019-11-08 09:18:02,972 train 800 1.679829e-02 -1.209812
2019-11-08 09:18:13,142 train 850 1.678461e-02 -1.195789
2019-11-08 09:18:16,178 training loss; R2: 1.678933e-02 -1.180128
2019-11-08 09:18:16,806 valid 000 1.258980e-02 -0.872177
2019-11-08 09:18:26,250 valid 050 1.435875e-02 -0.749325
2019-11-08 09:18:34,599 validation loss; R2: 1.433658e-02 -0.818749
2019-11-08 09:18:34,680 epoch 904 lr 1.000000e-05
2019-11-08 09:18:35,493 train 000 1.605096e-02 -2.197460
2019-11-08 09:18:45,261 train 050 1.657722e-02 -1.820903
2019-11-08 09:18:55,044 train 100 1.660260e-02 -1.271709
2019-11-08 09:19:04,811 train 150 1.656545e-02 -1.217543
2019-11-08 09:19:14,586 train 200 1.665532e-02 -1.082242
2019-11-08 09:19:24,346 train 250 1.660131e-02 -1.045050
2019-11-08 09:19:34,131 train 300 1.663936e-02 -1.007685
2019-11-08 09:19:43,892 train 350 1.665908e-02 -0.978341
2019-11-08 09:19:53,663 train 400 1.664794e-02 -0.964561
2019-11-08 09:20:03,447 train 450 1.664427e-02 -0.928109
2019-11-08 09:20:13,229 train 500 1.663405e-02 -0.882324
2019-11-08 09:20:23,004 train 550 1.662080e-02 -0.852172
2019-11-08 09:20:32,796 train 600 1.663634e-02 -0.826458
2019-11-08 09:20:42,606 train 650 1.661905e-02 -0.811101
2019-11-08 09:20:52,403 train 700 1.664789e-02 -0.810538
2019-11-08 09:21:02,218 train 750 1.664121e-02 -1.023017
2019-11-08 09:21:12,019 train 800 1.666694e-02 -1.023442
2019-11-08 09:21:21,830 train 850 1.666117e-02 -1.005958
2019-11-08 09:21:24,765 training loss; R2: 1.667087e-02 -1.001731
2019-11-08 09:21:25,459 valid 000 1.932723e-02 -0.304923
2019-11-08 09:21:34,850 valid 050 2.011371e-02 -1.469065
2019-11-08 09:21:43,275 validation loss; R2: 1.976354e-02 -1.745274
2019-11-08 09:21:43,343 epoch 905 lr 1.000000e-05
2019-11-08 09:21:44,085 train 000 1.886162e-02 0.048144
2019-11-08 09:21:53,848 train 050 1.707420e-02 -0.555353
2019-11-08 09:22:03,611 train 100 1.665346e-02 -0.649003
2019-11-08 09:22:13,375 train 150 1.662787e-02 -0.663544
2019-11-08 09:22:23,187 train 200 1.679327e-02 -0.678647
2019-11-08 09:22:32,981 train 250 1.678011e-02 -0.742106
2019-11-08 09:22:42,771 train 300 1.674902e-02 -0.823179
2019-11-08 09:22:52,557 train 350 1.678032e-02 -0.804103
2019-11-08 09:23:02,332 train 400 1.680123e-02 -0.816948
2019-11-08 09:23:12,125 train 450 1.681187e-02 -0.785261
2019-11-08 09:23:21,925 train 500 1.678732e-02 -0.765820
2019-11-08 09:23:31,746 train 550 1.679400e-02 -0.785184
2019-11-08 09:23:41,539 train 600 1.677062e-02 -0.762544
2019-11-08 09:23:51,336 train 650 1.678390e-02 -0.772484
2019-11-08 09:24:01,145 train 700 1.672820e-02 -0.798553
2019-11-08 09:24:10,947 train 750 1.673593e-02 -0.799168
2019-11-08 09:24:20,757 train 800 1.673893e-02 -0.794761
2019-11-08 09:24:30,570 train 850 1.672449e-02 -0.786491
2019-11-08 09:24:33,508 training loss; R2: 1.672256e-02 -0.783611
2019-11-08 09:24:34,119 valid 000 2.618139e-02 -0.954400
2019-11-08 09:24:43,560 valid 050 2.692655e-02 -3.398814
2019-11-08 09:24:52,028 validation loss; R2: 2.721600e-02 -3.071493
2019-11-08 09:24:52,094 epoch 906 lr 1.000000e-05
2019-11-08 09:24:52,842 train 000 1.432634e-02 -2.315862
2019-11-08 09:25:02,598 train 050 1.686182e-02 -0.918811
2019-11-08 09:25:12,366 train 100 1.663737e-02 -0.861179
2019-11-08 09:25:22,159 train 150 1.657646e-02 -0.851355
2019-11-08 09:25:31,939 train 200 1.660266e-02 -0.843433
2019-11-08 09:25:41,703 train 250 1.662876e-02 -0.817482
2019-11-08 09:25:51,483 train 300 1.667755e-02 -0.777310
2019-11-08 09:26:01,273 train 350 1.670560e-02 -0.751646
2019-11-08 09:26:11,055 train 400 1.672320e-02 -4.423862
2019-11-08 09:26:20,863 train 450 1.671981e-02 -4.225654
2019-11-08 09:26:30,671 train 500 1.673886e-02 -3.864681
2019-11-08 09:26:40,491 train 550 1.670851e-02 -3.597988
2019-11-08 09:26:50,298 train 600 1.673994e-02 -3.348529
2019-11-08 09:27:00,119 train 650 1.673765e-02 -3.265923
2019-11-08 09:27:09,946 train 700 1.673832e-02 -3.099257
2019-11-08 09:27:19,758 train 750 1.670820e-02 -2.934767
2019-11-08 09:27:29,582 train 800 1.671423e-02 -2.790785
2019-11-08 09:27:39,371 train 850 1.669144e-02 -2.666623
2019-11-08 09:27:42,304 training loss; R2: 1.669758e-02 -2.636333
2019-11-08 09:27:42,931 valid 000 1.639664e-02 -0.245008
2019-11-08 09:27:52,368 valid 050 1.542954e-02 -1.281025
2019-11-08 09:28:00,774 validation loss; R2: 1.561066e-02 -1.423612
2019-11-08 09:28:00,833 epoch 907 lr 1.000000e-05
2019-11-08 09:28:01,625 train 000 1.799088e-02 -0.100148
2019-11-08 09:28:11,349 train 050 1.677008e-02 -0.711788
2019-11-08 09:28:21,098 train 100 1.667757e-02 -0.801119
2019-11-08 09:28:30,856 train 150 1.681195e-02 -0.842336
2019-11-08 09:28:40,639 train 200 1.672939e-02 -0.861390
2019-11-08 09:28:50,423 train 250 1.672587e-02 -0.818239
2019-11-08 09:29:00,189 train 300 1.668042e-02 -1.472909
2019-11-08 09:29:09,971 train 350 1.667202e-02 -1.369576
2019-11-08 09:29:19,737 train 400 1.668018e-02 -1.410285
2019-11-08 09:29:29,519 train 450 1.665664e-02 -1.514841
2019-11-08 09:29:39,346 train 500 1.666800e-02 -1.421565
2019-11-08 09:29:49,143 train 550 1.665722e-02 -1.491006
2019-11-08 09:29:58,924 train 600 1.665521e-02 -1.424953
2019-11-08 09:30:08,720 train 650 1.668181e-02 -1.363158
2019-11-08 09:30:18,511 train 700 1.669502e-02 -1.377304
2019-11-08 09:30:28,306 train 750 1.672110e-02 -1.331911
2019-11-08 09:30:38,110 train 800 1.671476e-02 -1.286536
2019-11-08 09:30:47,894 train 850 1.671685e-02 -1.264388
2019-11-08 09:30:50,820 training loss; R2: 1.671271e-02 -1.252115
2019-11-08 09:30:51,456 valid 000 1.548831e-02 -0.139571
2019-11-08 09:31:00,862 valid 050 1.823543e-02 -1.471485
2019-11-08 09:31:09,205 validation loss; R2: 1.840965e-02 -1.889108
2019-11-08 09:31:09,271 epoch 908 lr 1.000000e-05
2019-11-08 09:31:10,020 train 000 1.763722e-02 -0.271303
2019-11-08 09:31:19,770 train 050 1.687021e-02 -0.716616
2019-11-08 09:31:29,503 train 100 1.684677e-02 -0.770019
2019-11-08 09:31:39,273 train 150 1.684669e-02 -0.756168
2019-11-08 09:31:49,025 train 200 1.675577e-02 -0.736677
2019-11-08 09:31:58,792 train 250 1.679114e-02 -0.750723
2019-11-08 09:32:08,567 train 300 1.672484e-02 -0.750239
2019-11-08 09:32:18,339 train 350 1.676368e-02 -0.749084
2019-11-08 09:32:28,110 train 400 1.678084e-02 -0.747964
2019-11-08 09:32:37,890 train 450 1.678131e-02 -0.748928
2019-11-08 09:32:47,685 train 500 1.679971e-02 -0.725875
2019-11-08 09:32:57,463 train 550 1.676909e-02 -0.746959
2019-11-08 09:33:07,244 train 600 1.673914e-02 -0.737093
2019-11-08 09:33:17,012 train 650 1.675434e-02 -0.826813
2019-11-08 09:33:26,775 train 700 1.672542e-02 -0.824686
2019-11-08 09:33:36,536 train 750 1.671913e-02 -0.803327
2019-11-08 09:33:46,297 train 800 1.671314e-02 -0.807308
2019-11-08 09:33:56,065 train 850 1.672256e-02 -0.806352
2019-11-08 09:33:58,981 training loss; R2: 1.672608e-02 -0.808936
2019-11-08 09:33:59,621 valid 000 1.614610e-02 -1.550895
2019-11-08 09:34:09,074 valid 050 1.620419e-02 -1.153073
2019-11-08 09:34:17,392 validation loss; R2: 1.649252e-02 -1.422543
2019-11-08 09:34:17,459 epoch 909 lr 1.000000e-05
2019-11-08 09:34:18,317 train 000 1.564345e-02 -0.382868
2019-11-08 09:34:28,026 train 050 1.667060e-02 -1.287497
2019-11-08 09:34:37,724 train 100 1.672405e-02 -1.078777
2019-11-08 09:34:47,469 train 150 1.674275e-02 -1.022931
2019-11-08 09:34:57,203 train 200 1.677898e-02 -0.920653
2019-11-08 09:35:06,936 train 250 1.683821e-02 -0.909694
2019-11-08 09:35:16,673 train 300 1.675850e-02 -0.912656
2019-11-08 09:35:26,413 train 350 1.672562e-02 -0.950717
2019-11-08 09:35:36,165 train 400 1.669136e-02 -0.916946
2019-11-08 09:35:45,922 train 450 1.667152e-02 -0.922267
2019-11-08 09:35:55,688 train 500 1.673760e-02 -0.891840
2019-11-08 09:36:05,454 train 550 1.673598e-02 -0.883452
2019-11-08 09:36:15,212 train 600 1.672192e-02 -0.872447
2019-11-08 09:36:24,972 train 650 1.670534e-02 -0.835178
2019-11-08 09:36:34,745 train 700 1.670975e-02 -0.834555
2019-11-08 09:36:44,507 train 750 1.671778e-02 -0.819363
2019-11-08 09:36:54,268 train 800 1.672704e-02 -0.817037
2019-11-08 09:37:04,032 train 850 1.672010e-02 -0.805690
2019-11-08 09:37:06,946 training loss; R2: 1.672090e-02 -0.800210
2019-11-08 09:37:07,620 valid 000 1.790935e-02 0.024411
2019-11-08 09:37:17,063 valid 050 1.661381e-02 -1.032260
2019-11-08 09:37:25,355 validation loss; R2: 1.665269e-02 -0.956456
2019-11-08 09:37:25,421 epoch 910 lr 1.000000e-05
2019-11-08 09:37:26,202 train 000 1.605435e-02 -0.716337
2019-11-08 09:37:35,923 train 050 1.707583e-02 -0.719266
2019-11-08 09:37:45,613 train 100 1.697020e-02 -0.775781
2019-11-08 09:37:55,358 train 150 1.691447e-02 -0.792485
2019-11-08 09:38:05,088 train 200 1.682272e-02 -0.786022
2019-11-08 09:38:14,835 train 250 1.675851e-02 -0.773203
2019-11-08 09:38:24,618 train 300 1.668622e-02 -0.773208
2019-11-08 09:38:34,401 train 350 1.663885e-02 -0.860673
2019-11-08 09:38:44,175 train 400 1.670397e-02 -0.857879
2019-11-08 09:38:53,976 train 450 1.673175e-02 -0.874486
2019-11-08 09:39:03,752 train 500 1.672730e-02 -0.852677
2019-11-08 09:39:13,532 train 550 1.669575e-02 -0.852056
2019-11-08 09:39:23,296 train 600 1.669979e-02 -0.831475
2019-11-08 09:39:33,080 train 650 1.673108e-02 -0.832543
2019-11-08 09:39:42,847 train 700 1.673305e-02 -0.815846
2019-11-08 09:39:52,627 train 750 1.669219e-02 -0.813423
2019-11-08 09:40:02,396 train 800 1.668287e-02 -0.803955
2019-11-08 09:40:12,167 train 850 1.669700e-02 -0.792454
2019-11-08 09:40:15,086 training loss; R2: 1.668160e-02 -0.794490
2019-11-08 09:40:15,723 valid 000 1.425220e-02 -0.635484
2019-11-08 09:40:25,155 valid 050 1.498502e-02 -1.804023
2019-11-08 09:40:33,459 validation loss; R2: 1.498016e-02 -1.367602
2019-11-08 09:40:33,522 epoch 911 lr 1.000000e-05
2019-11-08 09:40:34,290 train 000 1.756648e-02 -1.990511
2019-11-08 09:40:44,017 train 050 1.684974e-02 -0.967614
2019-11-08 09:40:53,713 train 100 1.688865e-02 -0.744426
2019-11-08 09:41:03,433 train 150 1.683995e-02 -0.772103
2019-11-08 09:41:13,168 train 200 1.690333e-02 -0.765533
2019-11-08 09:41:22,900 train 250 1.686754e-02 -0.782339
2019-11-08 09:41:32,623 train 300 1.683857e-02 -0.735428
2019-11-08 09:41:42,368 train 350 1.680920e-02 -0.737263
2019-11-08 09:41:52,131 train 400 1.677103e-02 -0.751834
2019-11-08 09:42:01,899 train 450 1.675356e-02 -0.731259
2019-11-08 09:42:11,665 train 500 1.674633e-02 -0.736910
2019-11-08 09:42:21,430 train 550 1.673805e-02 -0.714281
2019-11-08 09:42:31,183 train 600 1.672704e-02 -0.750248
2019-11-08 09:42:40,947 train 650 1.673414e-02 -0.745164
2019-11-08 09:42:50,717 train 700 1.675139e-02 -0.734701
2019-11-08 09:43:00,480 train 750 1.677237e-02 -0.721697
2019-11-08 09:43:10,232 train 800 1.676289e-02 -0.730077
2019-11-08 09:43:20,001 train 850 1.672420e-02 -0.719826
2019-11-08 09:43:22,932 training loss; R2: 1.672168e-02 -0.725767
2019-11-08 09:43:23,552 valid 000 1.430646e-02 -0.191265
2019-11-08 09:43:32,995 valid 050 1.497794e-02 -15.288168
2019-11-08 09:43:41,329 validation loss; R2: 1.488999e-02 -8.625141
2019-11-08 09:43:41,393 epoch 912 lr 1.000000e-05
2019-11-08 09:43:42,131 train 000 1.773719e-02 -0.270522
2019-11-08 09:43:51,892 train 050 1.697950e-02 -0.711450
2019-11-08 09:44:01,667 train 100 1.686135e-02 -0.962944
2019-11-08 09:44:11,454 train 150 1.686761e-02 -0.937969
2019-11-08 09:44:21,234 train 200 1.684805e-02 -1.267879
2019-11-08 09:44:31,036 train 250 1.681539e-02 -1.121690
2019-11-08 09:44:40,831 train 300 1.675019e-02 -1.048713
2019-11-08 09:44:50,646 train 350 1.671775e-02 -0.983679
2019-11-08 09:45:00,503 train 400 1.671097e-02 -0.977636
2019-11-08 09:45:10,689 train 450 1.672898e-02 -0.970109
2019-11-08 09:45:20,888 train 500 1.669489e-02 -0.939468
2019-11-08 09:45:31,101 train 550 1.667785e-02 -0.913900
2019-11-08 09:45:41,302 train 600 1.668450e-02 -0.902402
2019-11-08 09:45:51,476 train 650 1.670697e-02 -0.887929
2019-11-08 09:46:01,663 train 700 1.669569e-02 -0.874637
2019-11-08 09:46:11,848 train 750 1.673329e-02 -0.863819
2019-11-08 09:46:22,028 train 800 1.672112e-02 -0.853670
2019-11-08 09:46:32,238 train 850 1.671587e-02 -0.840429
2019-11-08 09:46:35,273 training loss; R2: 1.673191e-02 -0.841056
2019-11-08 09:46:35,909 valid 000 2.173460e-02 -5.159507
2019-11-08 09:46:45,401 valid 050 2.097226e-02 -2.236983
2019-11-08 09:46:53,740 validation loss; R2: 2.071595e-02 -2.647982
2019-11-08 09:46:53,806 epoch 913 lr 1.000000e-05
2019-11-08 09:46:54,603 train 000 1.492503e-02 -0.441106
2019-11-08 09:47:04,776 train 050 1.657742e-02 -0.635214
2019-11-08 09:47:14,953 train 100 1.657129e-02 -1.005711
2019-11-08 09:47:25,118 train 150 1.660253e-02 -0.950762
2019-11-08 09:47:35,285 train 200 1.669899e-02 -0.959696
2019-11-08 09:47:45,459 train 250 1.673670e-02 -0.908089
2019-11-08 09:47:55,601 train 300 1.670590e-02 -0.867692
2019-11-08 09:48:05,786 train 350 1.673242e-02 -0.918826
2019-11-08 09:48:15,964 train 400 1.674840e-02 -0.952676
2019-11-08 09:48:26,149 train 450 1.671870e-02 -0.954955
2019-11-08 09:48:36,330 train 500 1.674254e-02 -0.935442
2019-11-08 09:48:46,507 train 550 1.668913e-02 -0.915991
2019-11-08 09:48:56,677 train 600 1.668074e-02 -0.899160
2019-11-08 09:49:06,851 train 650 1.667409e-02 -0.872112
2019-11-08 09:49:17,041 train 700 1.667869e-02 -0.881871
2019-11-08 09:49:27,215 train 750 1.669488e-02 -0.880985
2019-11-08 09:49:37,399 train 800 1.668390e-02 -0.859129
2019-11-08 09:49:47,593 train 850 1.668850e-02 -0.852156
2019-11-08 09:49:50,639 training loss; R2: 1.669287e-02 -0.846416
2019-11-08 09:49:51,309 valid 000 2.195492e-02 -0.854707
2019-11-08 09:50:00,720 valid 050 1.985730e-02 -1.956074
2019-11-08 09:50:09,159 validation loss; R2: 2.003385e-02 -1.684433
2019-11-08 09:50:09,228 epoch 914 lr 1.000000e-05
2019-11-08 09:50:10,002 train 000 1.591862e-02 0.015561
2019-11-08 09:50:20,151 train 050 1.717822e-02 -0.542309
2019-11-08 09:50:30,307 train 100 1.711192e-02 -0.890255
2019-11-08 09:50:40,436 train 150 1.687366e-02 -0.865471
2019-11-08 09:50:50,596 train 200 1.680485e-02 -0.863691
2019-11-08 09:51:00,773 train 250 1.676034e-02 -0.826775
2019-11-08 09:51:10,919 train 300 1.685446e-02 -0.765524
2019-11-08 09:51:21,092 train 350 1.685779e-02 -0.744592
2019-11-08 09:51:31,233 train 400 1.680143e-02 -0.707238
2019-11-08 09:51:41,391 train 450 1.676922e-02 -0.717480
2019-11-08 09:51:51,540 train 500 1.674626e-02 -0.710035
2019-11-08 09:52:01,717 train 550 1.673889e-02 -0.717308
2019-11-08 09:52:11,899 train 600 1.673021e-02 -0.751451
2019-11-08 09:52:22,083 train 650 1.671889e-02 -0.734690
2019-11-08 09:52:32,262 train 700 1.670621e-02 -0.732496
2019-11-08 09:52:42,448 train 750 1.671187e-02 -0.734600
2019-11-08 09:52:52,602 train 800 1.673242e-02 -0.776257
2019-11-08 09:53:02,795 train 850 1.673312e-02 -0.759848
2019-11-08 09:53:05,832 training loss; R2: 1.673495e-02 -0.754678
2019-11-08 09:53:06,473 valid 000 1.549381e-02 0.108223
2019-11-08 09:53:15,925 valid 050 1.535304e-02 -1.038994
2019-11-08 09:53:24,233 validation loss; R2: 1.536663e-02 -1.054903
2019-11-08 09:53:24,298 epoch 915 lr 1.000000e-05
2019-11-08 09:53:25,108 train 000 1.442150e-02 -0.021680
2019-11-08 09:53:35,207 train 050 1.689720e-02 -0.454419
2019-11-08 09:53:45,336 train 100 1.673801e-02 -0.480224
2019-11-08 09:53:55,483 train 150 1.679221e-02 -0.547631
2019-11-08 09:54:05,635 train 200 1.664587e-02 -0.641773
2019-11-08 09:54:15,813 train 250 1.665033e-02 -0.653485
2019-11-08 09:54:25,969 train 300 1.659270e-02 -0.769146
2019-11-08 09:54:36,130 train 350 1.660871e-02 -0.794819
2019-11-08 09:54:46,309 train 400 1.664273e-02 -0.781659
2019-11-08 09:54:56,491 train 450 1.666258e-02 -0.798145
2019-11-08 09:55:06,663 train 500 1.669255e-02 -0.778296
2019-11-08 09:55:16,853 train 550 1.667487e-02 -0.867302
2019-11-08 09:55:27,046 train 600 1.666285e-02 -0.852575
2019-11-08 09:55:37,249 train 650 1.663729e-02 -0.843313
2019-11-08 09:55:47,019 train 700 1.666963e-02 -0.838978
2019-11-08 09:55:56,809 train 750 1.666847e-02 -0.834172
2019-11-08 09:56:06,594 train 800 1.668751e-02 -0.835175
2019-11-08 09:56:16,381 train 850 1.672119e-02 -0.845731
2019-11-08 09:56:19,305 training loss; R2: 1.670701e-02 -0.841264
2019-11-08 09:56:19,957 valid 000 1.824168e-02 -1.699135
2019-11-08 09:56:29,375 valid 050 1.677018e-02 -1.559353
2019-11-08 09:56:37,680 validation loss; R2: 1.661055e-02 -1.666117
2019-11-08 09:56:37,746 epoch 916 lr 1.000000e-05
2019-11-08 09:56:38,521 train 000 1.541013e-02 -0.852930
2019-11-08 09:56:48,272 train 050 1.699912e-02 -0.734854
2019-11-08 09:56:58,047 train 100 1.705711e-02 -0.847087
2019-11-08 09:57:07,815 train 150 1.696327e-02 -0.751515
2019-11-08 09:57:17,595 train 200 1.684725e-02 -0.791227
2019-11-08 09:57:27,381 train 250 1.677344e-02 -0.747721
2019-11-08 09:57:37,171 train 300 1.672093e-02 -0.752100
2019-11-08 09:57:46,966 train 350 1.675044e-02 -0.763568
2019-11-08 09:57:56,759 train 400 1.673589e-02 -0.754081
2019-11-08 09:58:06,555 train 450 1.673827e-02 -0.730102
2019-11-08 09:58:16,358 train 500 1.677782e-02 -0.739947
2019-11-08 09:58:26,161 train 550 1.679301e-02 -0.858590
2019-11-08 09:58:35,974 train 600 1.678323e-02 -0.841449
2019-11-08 09:58:45,787 train 650 1.675714e-02 -0.839991
2019-11-08 09:58:55,588 train 700 1.672124e-02 -0.844689
2019-11-08 09:59:05,392 train 750 1.670765e-02 -0.853218
2019-11-08 09:59:15,210 train 800 1.674122e-02 -0.843525
2019-11-08 09:59:25,014 train 850 1.671580e-02 -0.833854
2019-11-08 09:59:27,947 training loss; R2: 1.672924e-02 -0.833311
2019-11-08 09:59:28,577 valid 000 2.087307e-02 -1.547565
2019-11-08 09:59:38,012 valid 050 1.757997e-02 -1.377211
2019-11-08 09:59:46,345 validation loss; R2: 1.760380e-02 -1.613209
2019-11-08 09:59:46,411 epoch 917 lr 1.000000e-05
2019-11-08 09:59:47,199 train 000 1.770408e-02 -0.255539
2019-11-08 09:59:56,956 train 050 1.676475e-02 -0.895706
2019-11-08 10:00:06,695 train 100 1.676933e-02 -0.886474
2019-11-08 10:00:16,448 train 150 1.656371e-02 -0.910700
2019-11-08 10:00:26,213 train 200 1.647939e-02 -0.920911
2019-11-08 10:00:35,999 train 250 1.645015e-02 -0.842970
2019-11-08 10:00:45,770 train 300 1.652963e-02 -0.842015
2019-11-08 10:00:55,523 train 350 1.650953e-02 -0.822735
2019-11-08 10:01:05,300 train 400 1.656804e-02 -0.849646
2019-11-08 10:01:15,068 train 450 1.656729e-02 -0.891913
2019-11-08 10:01:24,822 train 500 1.658549e-02 -0.841079
2019-11-08 10:01:34,594 train 550 1.656881e-02 -0.819220
2019-11-08 10:01:44,373 train 600 1.659117e-02 -0.795860
2019-11-08 10:01:54,155 train 650 1.660024e-02 -0.793967
2019-11-08 10:02:03,982 train 700 1.662915e-02 -0.776725
2019-11-08 10:02:13,815 train 750 1.666275e-02 -0.827353
2019-11-08 10:02:23,635 train 800 1.666949e-02 -0.813820
2019-11-08 10:02:33,461 train 850 1.666924e-02 -0.810825
2019-11-08 10:02:36,395 training loss; R2: 1.667822e-02 -0.805570
2019-11-08 10:02:37,036 valid 000 2.240028e-02 -3.708303
2019-11-08 10:02:46,478 valid 050 2.098459e-02 -2.319018
2019-11-08 10:02:54,861 validation loss; R2: 2.114908e-02 -1.929193
2019-11-08 10:02:54,920 epoch 918 lr 1.000000e-05
2019-11-08 10:02:55,716 train 000 1.797466e-02 -0.860826
2019-11-08 10:03:05,486 train 050 1.688052e-02 -0.914482
2019-11-08 10:03:15,261 train 100 1.671470e-02 -0.862540
2019-11-08 10:03:25,040 train 150 1.662513e-02 -0.800687
2019-11-08 10:03:34,828 train 200 1.661377e-02 -0.859070
2019-11-08 10:03:44,615 train 250 1.669336e-02 -0.816380
2019-11-08 10:03:54,420 train 300 1.666825e-02 -0.796312
2019-11-08 10:04:04,206 train 350 1.663179e-02 -0.790910
2019-11-08 10:04:14,028 train 400 1.668140e-02 -0.782999
2019-11-08 10:04:23,826 train 450 1.668838e-02 -0.782538
2019-11-08 10:04:33,639 train 500 1.673205e-02 -0.766432
2019-11-08 10:04:43,445 train 550 1.672455e-02 -0.777370
2019-11-08 10:04:53,256 train 600 1.670159e-02 -0.783350
2019-11-08 10:05:03,093 train 650 1.671180e-02 -0.814672
2019-11-08 10:05:12,905 train 700 1.672076e-02 -0.806261
2019-11-08 10:05:22,715 train 750 1.672422e-02 -0.799102
2019-11-08 10:05:32,524 train 800 1.668927e-02 -0.829895
2019-11-08 10:05:42,336 train 850 1.670489e-02 -0.807910
2019-11-08 10:05:45,260 training loss; R2: 1.670945e-02 -0.798214
2019-11-08 10:05:45,940 valid 000 1.625515e-02 -0.849383
2019-11-08 10:05:55,395 valid 050 1.610244e-02 -1.375029
2019-11-08 10:06:03,696 validation loss; R2: 1.605739e-02 -1.474902
2019-11-08 10:06:03,759 epoch 919 lr 1.000000e-05
2019-11-08 10:06:04,535 train 000 1.709053e-02 -0.285991
2019-11-08 10:06:14,532 train 050 1.676053e-02 -0.684172
2019-11-08 10:06:24,659 train 100 1.670957e-02 -0.684226
2019-11-08 10:06:34,782 train 150 1.662959e-02 -0.709419
2019-11-08 10:06:44,941 train 200 1.675642e-02 -0.728556
2019-11-08 10:06:55,088 train 250 1.674274e-02 -0.887560
2019-11-08 10:07:05,242 train 300 1.679976e-02 -0.856468
2019-11-08 10:07:15,366 train 350 1.675762e-02 -1.297678
2019-11-08 10:07:25,388 train 400 1.668039e-02 -1.216861
2019-11-08 10:07:35,172 train 450 1.670176e-02 -1.157620
2019-11-08 10:07:44,956 train 500 1.667876e-02 -1.117573
2019-11-08 10:07:54,752 train 550 1.669399e-02 -1.068615
2019-11-08 10:08:04,533 train 600 1.668810e-02 -1.046427
2019-11-08 10:08:14,323 train 650 1.669589e-02 -1.676909
2019-11-08 10:08:24,097 train 700 1.668319e-02 -1.607634
2019-11-08 10:08:33,904 train 750 1.667310e-02 -1.539529
2019-11-08 10:08:43,736 train 800 1.669928e-02 -1.499117
2019-11-08 10:08:53,553 train 850 1.671374e-02 -3.276835
2019-11-08 10:08:56,497 training loss; R2: 1.672163e-02 -3.233417
2019-11-08 10:08:57,124 valid 000 1.426383e-02 -1.600071
2019-11-08 10:09:06,553 valid 050 1.597784e-02 -3.762587
2019-11-08 10:09:14,890 validation loss; R2: 1.591533e-02 -3.258585
2019-11-08 10:09:14,960 epoch 920 lr 1.000000e-05
2019-11-08 10:09:15,694 train 000 1.457438e-02 -0.270325
2019-11-08 10:09:25,514 train 050 1.684427e-02 -0.716684
2019-11-08 10:09:35,280 train 100 1.674935e-02 -0.774397
2019-11-08 10:09:45,071 train 150 1.678150e-02 -1.014766
2019-11-08 10:09:54,848 train 200 1.678732e-02 -0.859198
2019-11-08 10:10:04,627 train 250 1.681137e-02 -0.789693
2019-11-08 10:10:14,415 train 300 1.678924e-02 -0.827879
2019-11-08 10:10:24,165 train 350 1.672666e-02 -0.841847
2019-11-08 10:10:33,955 train 400 1.673315e-02 -0.828553
2019-11-08 10:10:43,741 train 450 1.667475e-02 -0.859019
2019-11-08 10:10:53,519 train 500 1.664768e-02 -0.842064
2019-11-08 10:11:03,319 train 550 1.662034e-02 -0.831519
2019-11-08 10:11:13,129 train 600 1.662083e-02 -0.832293
2019-11-08 10:11:22,932 train 650 1.664440e-02 -0.813376
2019-11-08 10:11:32,729 train 700 1.669096e-02 -0.814738
2019-11-08 10:11:42,539 train 750 1.669780e-02 -0.801451
2019-11-08 10:11:52,337 train 800 1.668394e-02 -0.794694
2019-11-08 10:12:02,148 train 850 1.668644e-02 -0.786606
2019-11-08 10:12:05,078 training loss; R2: 1.669498e-02 -0.782926
2019-11-08 10:12:05,692 valid 000 1.982001e-02 -0.668973
2019-11-08 10:12:15,135 valid 050 1.608020e-02 -1.740097
2019-11-08 10:12:23,472 validation loss; R2: 1.631341e-02 -1.695054
2019-11-08 10:12:23,537 epoch 921 lr 1.000000e-05
2019-11-08 10:12:24,308 train 000 1.686600e-02 -0.682119
2019-11-08 10:12:34,057 train 050 1.615744e-02 -0.711044
2019-11-08 10:12:43,794 train 100 1.638708e-02 -0.740756
2019-11-08 10:12:53,573 train 150 1.654590e-02 -0.752305
2019-11-08 10:13:03,346 train 200 1.663601e-02 -0.712688
2019-11-08 10:13:13,127 train 250 1.663815e-02 -0.691673
2019-11-08 10:13:22,906 train 300 1.662564e-02 -0.711340
2019-11-08 10:13:32,701 train 350 1.666616e-02 -0.676921
2019-11-08 10:13:42,487 train 400 1.668935e-02 -0.641248
2019-11-08 10:13:52,294 train 450 1.668781e-02 -0.636207
2019-11-08 10:14:02,103 train 500 1.669336e-02 -0.627456
2019-11-08 10:14:11,921 train 550 1.668170e-02 -0.657811
2019-11-08 10:14:21,733 train 600 1.666632e-02 -0.655603
2019-11-08 10:14:31,536 train 650 1.668511e-02 -0.656162
2019-11-08 10:14:41,335 train 700 1.666178e-02 -0.671296
2019-11-08 10:14:51,151 train 750 1.667560e-02 -0.688115
2019-11-08 10:15:00,972 train 800 1.668595e-02 -1.084376
2019-11-08 10:15:10,787 train 850 1.670986e-02 -1.077555
2019-11-08 10:15:13,715 training loss; R2: 1.669837e-02 -1.082105
2019-11-08 10:15:14,412 valid 000 1.780121e-02 -0.517996
2019-11-08 10:15:23,792 valid 050 2.097060e-02 -0.876422
2019-11-08 10:15:32,211 validation loss; R2: 2.095099e-02 -0.836023
2019-11-08 10:15:32,277 epoch 922 lr 1.000000e-05
2019-11-08 10:15:33,055 train 000 1.609726e-02 -0.161911
2019-11-08 10:15:42,791 train 050 1.634885e-02 -0.484686
2019-11-08 10:15:52,541 train 100 1.631757e-02 -0.500418
2019-11-08 10:16:02,324 train 150 1.646564e-02 -0.571297
2019-11-08 10:16:12,106 train 200 1.649804e-02 -0.566521
2019-11-08 10:16:21,872 train 250 1.656528e-02 -0.637338
2019-11-08 10:16:31,661 train 300 1.661986e-02 -0.682956
2019-11-08 10:16:41,464 train 350 1.660752e-02 -0.706375
2019-11-08 10:16:51,291 train 400 1.661997e-02 -0.691750
2019-11-08 10:17:01,105 train 450 1.663193e-02 -0.699621
2019-11-08 10:17:10,889 train 500 1.661742e-02 -0.704896
2019-11-08 10:17:20,683 train 550 1.667036e-02 -0.701738
2019-11-08 10:17:30,477 train 600 1.664119e-02 -0.703703
2019-11-08 10:17:40,269 train 650 1.662844e-02 -0.692994
2019-11-08 10:17:50,074 train 700 1.665951e-02 -0.697504
2019-11-08 10:17:59,864 train 750 1.666358e-02 -0.696459
2019-11-08 10:18:09,651 train 800 1.668229e-02 -0.692705
2019-11-08 10:18:19,477 train 850 1.668005e-02 -0.693941
2019-11-08 10:18:22,415 training loss; R2: 1.667590e-02 -0.706545
2019-11-08 10:18:23,083 valid 000 2.157666e-02 -2.826346
2019-11-08 10:18:32,538 valid 050 1.884895e-02 -1.296962
2019-11-08 10:18:40,904 validation loss; R2: 1.847520e-02 -1.678740
2019-11-08 10:18:40,968 epoch 923 lr 1.000000e-05
2019-11-08 10:18:41,695 train 000 1.509925e-02 -0.150309
2019-11-08 10:18:51,456 train 050 1.676959e-02 -0.608389
2019-11-08 10:19:01,216 train 100 1.674046e-02 -0.775754
2019-11-08 10:19:11,004 train 150 1.676611e-02 -0.665257
2019-11-08 10:19:20,775 train 200 1.671540e-02 -0.702808
2019-11-08 10:19:30,543 train 250 1.668041e-02 -0.919750
2019-11-08 10:19:40,314 train 300 1.669086e-02 -0.917898
2019-11-08 10:19:50,079 train 350 1.670823e-02 -0.925456
2019-11-08 10:19:59,854 train 400 1.668240e-02 -0.908857
2019-11-08 10:20:09,639 train 450 1.666773e-02 -1.077143
2019-11-08 10:20:19,427 train 500 1.669104e-02 -1.043068
2019-11-08 10:20:29,233 train 550 1.666407e-02 -1.015557
2019-11-08 10:20:39,054 train 600 1.665830e-02 -0.983678
2019-11-08 10:20:48,893 train 650 1.667902e-02 -0.956181
2019-11-08 10:20:58,712 train 700 1.667376e-02 -0.937745
2019-11-08 10:21:08,552 train 750 1.670701e-02 -0.918314
2019-11-08 10:21:18,375 train 800 1.670218e-02 -0.926517
2019-11-08 10:21:28,222 train 850 1.667371e-02 -0.927261
2019-11-08 10:21:31,164 training loss; R2: 1.667157e-02 -0.921869
2019-11-08 10:21:31,861 valid 000 1.626572e-02 -0.692176
2019-11-08 10:21:41,232 valid 050 1.605216e-02 -0.632370
2019-11-08 10:21:49,711 validation loss; R2: 1.601564e-02 -0.693318
2019-11-08 10:21:49,776 epoch 924 lr 1.000000e-05
2019-11-08 10:21:50,528 train 000 1.661904e-02 -0.296196
2019-11-08 10:22:00,281 train 050 1.677339e-02 -0.518227
2019-11-08 10:22:10,058 train 100 1.669885e-02 -0.526737
2019-11-08 10:22:19,858 train 150 1.666349e-02 -0.536800
2019-11-08 10:22:29,637 train 200 1.663187e-02 -0.540242
2019-11-08 10:22:39,438 train 250 1.660519e-02 -0.606537
2019-11-08 10:22:49,243 train 300 1.659115e-02 -0.591532
2019-11-08 10:22:59,061 train 350 1.662113e-02 -0.579417
2019-11-08 10:23:08,882 train 400 1.665717e-02 -0.623116
2019-11-08 10:23:18,708 train 450 1.666213e-02 -0.637338
2019-11-08 10:23:28,540 train 500 1.669942e-02 -0.652199
2019-11-08 10:23:38,359 train 550 1.669877e-02 -0.655327
2019-11-08 10:23:48,186 train 600 1.671868e-02 -0.649187
2019-11-08 10:23:58,022 train 650 1.671734e-02 -0.679843
2019-11-08 10:24:07,842 train 700 1.669140e-02 -0.695753
2019-11-08 10:24:17,668 train 750 1.668317e-02 -0.694984
2019-11-08 10:24:27,509 train 800 1.670174e-02 -0.690036
2019-11-08 10:24:37,331 train 850 1.670495e-02 -0.685648
2019-11-08 10:24:40,273 training loss; R2: 1.669309e-02 -0.684699
2019-11-08 10:24:40,906 valid 000 1.317239e-02 -0.844013
2019-11-08 10:24:50,331 valid 050 1.456506e-02 -0.739204
2019-11-08 10:24:58,631 validation loss; R2: 1.470304e-02 -0.940243
2019-11-08 10:24:58,696 epoch 925 lr 1.000000e-05
2019-11-08 10:24:59,425 train 000 1.506974e-02 -0.331690
2019-11-08 10:25:09,167 train 050 1.679760e-02 -1.300973
2019-11-08 10:25:18,940 train 100 1.679974e-02 -0.922664
2019-11-08 10:25:28,715 train 150 1.675822e-02 -0.836798
2019-11-08 10:25:38,494 train 200 1.681643e-02 -0.846934
2019-11-08 10:25:48,285 train 250 1.671554e-02 -0.840158
2019-11-08 10:25:58,082 train 300 1.669161e-02 -0.799068
2019-11-08 10:26:07,885 train 350 1.668226e-02 -0.772474
2019-11-08 10:26:17,703 train 400 1.669774e-02 -0.822177
2019-11-08 10:26:27,517 train 450 1.668827e-02 -0.799017
2019-11-08 10:26:37,350 train 500 1.666655e-02 -0.801881
2019-11-08 10:26:47,170 train 550 1.665618e-02 -15.723107
2019-11-08 10:26:56,982 train 600 1.663500e-02 -14.487995
2019-11-08 10:27:06,811 train 650 1.666376e-02 -13.423362
2019-11-08 10:27:16,946 train 700 1.667690e-02 -12.513729
2019-11-08 10:27:27,136 train 750 1.667731e-02 -11.739037
2019-11-08 10:27:37,320 train 800 1.671051e-02 -11.072505
2019-11-08 10:27:47,490 train 850 1.672173e-02 -10.463329
2019-11-08 10:27:50,535 training loss; R2: 1.671539e-02 -10.300759
2019-11-08 10:27:51,188 valid 000 1.375815e-02 -1.387157
2019-11-08 10:28:00,623 valid 050 1.507982e-02 -0.924820
2019-11-08 10:28:08,996 validation loss; R2: 1.498715e-02 -1.143533
2019-11-08 10:28:09,066 epoch 926 lr 1.000000e-05
2019-11-08 10:28:09,873 train 000 1.493088e-02 -0.742818
2019-11-08 10:28:20,006 train 050 1.643120e-02 -0.785668
2019-11-08 10:28:30,154 train 100 1.644750e-02 -0.796247
2019-11-08 10:28:40,316 train 150 1.661734e-02 -0.751007
2019-11-08 10:28:50,449 train 200 1.661507e-02 -0.753732
2019-11-08 10:29:00,587 train 250 1.665727e-02 -0.691513
2019-11-08 10:29:10,716 train 300 1.660861e-02 -0.698460
2019-11-08 10:29:20,869 train 350 1.664139e-02 -0.685770
2019-11-08 10:29:31,017 train 400 1.666566e-02 -0.674932
2019-11-08 10:29:41,180 train 450 1.665253e-02 -0.666624
2019-11-08 10:29:51,371 train 500 1.669751e-02 -0.675266
2019-11-08 10:30:01,565 train 550 1.669844e-02 -0.710151
2019-11-08 10:30:11,733 train 600 1.668454e-02 -0.704204
2019-11-08 10:30:21,911 train 650 1.670396e-02 -0.706190
2019-11-08 10:30:32,087 train 700 1.670053e-02 -0.702020
2019-11-08 10:30:42,270 train 750 1.668992e-02 -0.702988
2019-11-08 10:30:52,452 train 800 1.668253e-02 -0.703954
2019-11-08 10:31:02,640 train 850 1.667854e-02 -0.693413
2019-11-08 10:31:05,676 training loss; R2: 1.668119e-02 -0.704105
2019-11-08 10:31:06,305 valid 000 1.601915e-02 -1.227463
2019-11-08 10:31:15,714 valid 050 1.610476e-02 -1.762045
2019-11-08 10:31:24,050 validation loss; R2: 1.630462e-02 -1.419159
2019-11-08 10:31:24,118 epoch 927 lr 1.000000e-05
2019-11-08 10:31:24,903 train 000 1.513766e-02 -0.525297
2019-11-08 10:31:35,006 train 050 1.639267e-02 -0.651178
2019-11-08 10:31:45,157 train 100 1.656155e-02 -0.593400
2019-11-08 10:31:55,322 train 150 1.660073e-02 -0.755991
2019-11-08 10:32:05,506 train 200 1.657454e-02 -0.741705
2019-11-08 10:32:15,678 train 250 1.664872e-02 -0.748186
2019-11-08 10:32:25,696 train 300 1.663246e-02 -0.741704
2019-11-08 10:32:35,497 train 350 1.658401e-02 -0.724647
2019-11-08 10:32:45,296 train 400 1.660392e-02 -0.717818
2019-11-08 10:32:55,090 train 450 1.664936e-02 -0.724106
2019-11-08 10:33:04,873 train 500 1.665179e-02 -0.733963
2019-11-08 10:33:14,666 train 550 1.665257e-02 -0.731705
2019-11-08 10:33:24,450 train 600 1.669845e-02 -0.722500
2019-11-08 10:33:34,255 train 650 1.668994e-02 -0.736706
2019-11-08 10:33:44,070 train 700 1.671586e-02 -0.772577
2019-11-08 10:33:53,908 train 750 1.668811e-02 -0.780485
2019-11-08 10:34:03,722 train 800 1.670177e-02 -0.775024
2019-11-08 10:34:13,546 train 850 1.671066e-02 -0.774049
2019-11-08 10:34:16,477 training loss; R2: 1.670651e-02 -0.780896
2019-11-08 10:34:17,163 valid 000 2.162213e-02 -0.635718
2019-11-08 10:34:26,567 valid 050 2.037243e-02 -2.229987
2019-11-08 10:34:35,002 validation loss; R2: 2.020191e-02 -2.055157
2019-11-08 10:34:35,071 epoch 928 lr 1.000000e-05
2019-11-08 10:34:35,823 train 000 1.648423e-02 -7.090847
2019-11-08 10:34:45,549 train 050 1.650286e-02 -0.933847
2019-11-08 10:34:55,268 train 100 1.643575e-02 -0.968622
2019-11-08 10:35:05,038 train 150 1.648353e-02 -1.244838
2019-11-08 10:35:14,821 train 200 1.666678e-02 -1.219885
2019-11-08 10:35:24,633 train 250 1.664710e-02 -1.106476
2019-11-08 10:35:34,415 train 300 1.657560e-02 -1.028334
2019-11-08 10:35:44,198 train 350 1.661814e-02 -0.987892
2019-11-08 10:35:53,996 train 400 1.662755e-02 -0.942089
2019-11-08 10:36:03,797 train 450 1.663294e-02 -0.916569
2019-11-08 10:36:13,577 train 500 1.664287e-02 -0.900045
2019-11-08 10:36:23,368 train 550 1.665926e-02 -0.887614
2019-11-08 10:36:33,153 train 600 1.665740e-02 -0.878180
2019-11-08 10:36:42,937 train 650 1.669363e-02 -0.858351
2019-11-08 10:36:52,725 train 700 1.673008e-02 -0.854577
2019-11-08 10:37:02,540 train 750 1.672979e-02 -0.844641
2019-11-08 10:37:12,331 train 800 1.670934e-02 -0.840935
2019-11-08 10:37:22,128 train 850 1.669910e-02 -0.851548
2019-11-08 10:37:25,058 training loss; R2: 1.669932e-02 -0.839760
2019-11-08 10:37:25,758 valid 000 1.679778e-02 -2.247445
2019-11-08 10:37:35,245 valid 050 1.477820e-02 -0.794619
2019-11-08 10:37:43,622 validation loss; R2: 1.477688e-02 -0.867448
2019-11-08 10:37:43,681 epoch 929 lr 1.000000e-05
2019-11-08 10:37:44,459 train 000 1.579051e-02 -0.536599
2019-11-08 10:37:54,192 train 050 1.668789e-02 -1.184187
2019-11-08 10:38:03,911 train 100 1.649914e-02 -0.845839
2019-11-08 10:38:13,676 train 150 1.645843e-02 -0.833183
2019-11-08 10:38:23,435 train 200 1.655854e-02 -0.816625
2019-11-08 10:38:33,211 train 250 1.655496e-02 -18.659184
2019-11-08 10:38:42,995 train 300 1.657246e-02 -15.652746
2019-11-08 10:38:52,792 train 350 1.653386e-02 -13.533633
2019-11-08 10:39:02,586 train 400 1.653781e-02 -12.017594
2019-11-08 10:39:12,376 train 450 1.654400e-02 -10.791332
2019-11-08 10:39:22,161 train 500 1.660183e-02 -10.562678
2019-11-08 10:39:31,946 train 550 1.660839e-02 -9.669327
2019-11-08 10:39:41,744 train 600 1.661093e-02 -8.940542
2019-11-08 10:39:51,532 train 650 1.661082e-02 -8.316525
2019-11-08 10:40:01,333 train 700 1.663065e-02 -7.777041
2019-11-08 10:40:11,129 train 750 1.663967e-02 -7.295790
2019-11-08 10:40:20,929 train 800 1.665267e-02 -6.878879
2019-11-08 10:40:30,741 train 850 1.667558e-02 -6.529243
2019-11-08 10:40:33,682 training loss; R2: 1.668272e-02 -6.432732
2019-11-08 10:40:34,272 valid 000 1.384135e-02 -9.277705
2019-11-08 10:40:43,707 valid 050 1.644640e-02 -1.133329
2019-11-08 10:40:51,990 validation loss; R2: 1.636716e-02 -1.272498
2019-11-08 10:40:52,057 epoch 930 lr 1.000000e-05
2019-11-08 10:40:52,836 train 000 1.756064e-02 -0.035881
2019-11-08 10:41:02,589 train 050 1.663063e-02 -0.630504
2019-11-08 10:41:12,353 train 100 1.674653e-02 -0.637571
2019-11-08 10:41:22,120 train 150 1.666194e-02 -0.617568
2019-11-08 10:41:31,911 train 200 1.660604e-02 -0.655842
2019-11-08 10:41:41,737 train 250 1.661005e-02 -0.631019
2019-11-08 10:41:51,554 train 300 1.664554e-02 -0.682007
2019-11-08 10:42:01,352 train 350 1.673434e-02 -0.665216
2019-11-08 10:42:11,179 train 400 1.676239e-02 -0.661411
2019-11-08 10:42:21,001 train 450 1.672769e-02 -0.686548
2019-11-08 10:42:30,813 train 500 1.675002e-02 -0.671225
2019-11-08 10:42:40,637 train 550 1.674605e-02 -0.659951
2019-11-08 10:42:50,439 train 600 1.672209e-02 -0.668275
2019-11-08 10:43:00,267 train 650 1.666980e-02 -0.910203
2019-11-08 10:43:10,093 train 700 1.665231e-02 -0.909016
2019-11-08 10:43:19,901 train 750 1.667766e-02 -0.902113
2019-11-08 10:43:29,726 train 800 1.665012e-02 -0.899071
2019-11-08 10:43:39,562 train 850 1.662903e-02 -0.905210
2019-11-08 10:43:42,496 training loss; R2: 1.662974e-02 -0.899999
2019-11-08 10:43:43,189 valid 000 1.286203e-02 -2.816785
2019-11-08 10:43:52,589 valid 050 1.435790e-02 -0.916749
2019-11-08 10:44:00,882 validation loss; R2: 1.426457e-02 -0.823844
2019-11-08 10:44:00,950 epoch 931 lr 1.000000e-05
2019-11-08 10:44:01,691 train 000 1.608288e-02 0.078247
2019-11-08 10:44:11,450 train 050 1.657610e-02 -0.651570
2019-11-08 10:44:21,235 train 100 1.666702e-02 -0.654113
2019-11-08 10:44:31,032 train 150 1.667424e-02 -2.075363
2019-11-08 10:44:40,847 train 200 1.661035e-02 -1.748602
2019-11-08 10:44:50,680 train 250 1.668277e-02 -1.534086
2019-11-08 10:45:00,491 train 300 1.667926e-02 -1.366544
2019-11-08 10:45:10,315 train 350 1.666967e-02 -1.250525
2019-11-08 10:45:20,161 train 400 1.667339e-02 -1.204842
2019-11-08 10:45:29,987 train 450 1.667464e-02 -1.184117
2019-11-08 10:45:39,829 train 500 1.665763e-02 -1.118668
2019-11-08 10:45:49,668 train 550 1.665230e-02 -1.077891
2019-11-08 10:45:59,488 train 600 1.665590e-02 -1.067298
2019-11-08 10:46:09,331 train 650 1.666559e-02 -1.036508
2019-11-08 10:46:19,173 train 700 1.666296e-02 -0.999645
2019-11-08 10:46:29,040 train 750 1.668056e-02 -0.984118
2019-11-08 10:46:38,871 train 800 1.668389e-02 -0.953994
2019-11-08 10:46:48,719 train 850 1.668097e-02 -0.947837
2019-11-08 10:46:51,694 training loss; R2: 1.667519e-02 -0.952044
2019-11-08 10:46:52,352 valid 000 1.361190e-02 -0.154609
2019-11-08 10:47:01,844 valid 050 1.457618e-02 -1.062609
2019-11-08 10:47:10,189 validation loss; R2: 1.434493e-02 -1.008975
2019-11-08 10:47:10,269 epoch 932 lr 1.000000e-05
2019-11-08 10:47:11,064 train 000 1.530733e-02 -0.268745
2019-11-08 10:47:20,818 train 050 1.693649e-02 -0.454549
2019-11-08 10:47:30,598 train 100 1.681111e-02 -0.547407
2019-11-08 10:47:40,394 train 150 1.669293e-02 -0.584823
2019-11-08 10:47:50,208 train 200 1.676859e-02 -0.645801
2019-11-08 10:48:00,017 train 250 1.675220e-02 -0.665634
2019-11-08 10:48:09,837 train 300 1.674766e-02 -0.713240
2019-11-08 10:48:19,642 train 350 1.675195e-02 -0.687325
2019-11-08 10:48:29,443 train 400 1.673363e-02 -0.697456
2019-11-08 10:48:39,258 train 450 1.673878e-02 -0.728255
2019-11-08 10:48:49,074 train 500 1.671704e-02 -0.729929
2019-11-08 10:48:58,892 train 550 1.671272e-02 -0.717692
2019-11-08 10:49:08,715 train 600 1.667478e-02 -0.703665
2019-11-08 10:49:18,538 train 650 1.666971e-02 -0.705108
2019-11-08 10:49:28,367 train 700 1.667603e-02 -0.702396
2019-11-08 10:49:38,194 train 750 1.670177e-02 -0.689733
2019-11-08 10:49:48,029 train 800 1.669462e-02 -0.686333
2019-11-08 10:49:57,858 train 850 1.668184e-02 -0.710112
2019-11-08 10:50:00,797 training loss; R2: 1.667814e-02 -0.715787
2019-11-08 10:50:01,458 valid 000 1.410070e-02 -7.595549
2019-11-08 10:50:10,878 valid 050 1.521359e-02 -3.472963
2019-11-08 10:50:19,239 validation loss; R2: 1.544990e-02 -2.193220
2019-11-08 10:50:19,304 epoch 933 lr 1.000000e-05
2019-11-08 10:50:20,098 train 000 2.043431e-02 -0.519367
2019-11-08 10:50:29,834 train 050 1.649631e-02 -0.614432
2019-11-08 10:50:39,611 train 100 1.652829e-02 -0.540818
2019-11-08 10:50:49,403 train 150 1.646461e-02 -0.561393
2019-11-08 10:50:59,205 train 200 1.653569e-02 -0.596263
2019-11-08 10:51:08,993 train 250 1.665460e-02 -0.627146
2019-11-08 10:51:18,778 train 300 1.664634e-02 -0.631442
2019-11-08 10:51:28,580 train 350 1.663625e-02 -0.639776
2019-11-08 10:51:38,386 train 400 1.663529e-02 -0.613703
2019-11-08 10:51:48,191 train 450 1.663970e-02 -0.608845
2019-11-08 10:51:57,998 train 500 1.661665e-02 -0.630720
2019-11-08 10:52:07,788 train 550 1.661995e-02 -1.002170
2019-11-08 10:52:17,617 train 600 1.661744e-02 -0.979426
2019-11-08 10:52:27,428 train 650 1.662717e-02 -0.998879
2019-11-08 10:52:37,237 train 700 1.663979e-02 -0.977035
2019-11-08 10:52:47,031 train 750 1.664647e-02 -0.986291
2019-11-08 10:52:56,817 train 800 1.666094e-02 -0.973356
2019-11-08 10:53:06,607 train 850 1.664231e-02 -0.966836
2019-11-08 10:53:09,533 training loss; R2: 1.664373e-02 -0.968737
2019-11-08 10:53:10,222 valid 000 1.140354e-02 -0.243595
2019-11-08 10:53:19,577 valid 050 1.571701e-02 -0.969428
2019-11-08 10:53:27,995 validation loss; R2: 1.573637e-02 -0.994861
2019-11-08 10:53:28,065 epoch 934 lr 1.000000e-05
2019-11-08 10:53:28,861 train 000 1.932905e-02 -1.645322
2019-11-08 10:53:38,591 train 050 1.649088e-02 -0.585325
2019-11-08 10:53:48,367 train 100 1.656588e-02 -0.707301
2019-11-08 10:53:58,144 train 150 1.660529e-02 -0.681099
2019-11-08 10:54:07,956 train 200 1.657699e-02 -0.633404
2019-11-08 10:54:17,736 train 250 1.667393e-02 -0.593004
2019-11-08 10:54:27,503 train 300 1.667700e-02 -0.604790
2019-11-08 10:54:37,298 train 350 1.670683e-02 -0.604736
2019-11-08 10:54:47,074 train 400 1.666236e-02 -0.589537
2019-11-08 10:54:56,857 train 450 1.670175e-02 -0.591514
2019-11-08 10:55:06,645 train 500 1.670886e-02 -0.583599
2019-11-08 10:55:16,417 train 550 1.670325e-02 -0.577465
2019-11-08 10:55:26,198 train 600 1.669607e-02 -0.596538
2019-11-08 10:55:35,985 train 650 1.664997e-02 -0.610810
2019-11-08 10:55:45,802 train 700 1.663277e-02 -0.628922
2019-11-08 10:55:55,593 train 750 1.665308e-02 -0.633740
2019-11-08 10:56:05,385 train 800 1.666172e-02 -0.655749
2019-11-08 10:56:15,179 train 850 1.664822e-02 -0.670241
2019-11-08 10:56:18,103 training loss; R2: 1.664052e-02 -0.671588
2019-11-08 10:56:18,791 valid 000 1.336317e-02 -0.862209
2019-11-08 10:56:28,108 valid 050 1.437854e-02 -1.370796
2019-11-08 10:56:36,534 validation loss; R2: 1.431027e-02 -1.216974
2019-11-08 10:56:36,599 epoch 935 lr 1.000000e-05
2019-11-08 10:56:37,384 train 000 1.581085e-02 -0.506733
2019-11-08 10:56:47,106 train 050 1.698236e-02 -0.668917
2019-11-08 10:56:56,852 train 100 1.690446e-02 -0.795729
2019-11-08 10:57:06,619 train 150 1.683737e-02 -0.867886
2019-11-08 10:57:16,389 train 200 1.689606e-02 -0.871169
2019-11-08 10:57:26,177 train 250 1.684157e-02 -0.899155
2019-11-08 10:57:35,957 train 300 1.676421e-02 -0.890266
2019-11-08 10:57:45,732 train 350 1.673386e-02 -0.863003
2019-11-08 10:57:55,517 train 400 1.676057e-02 -0.851098
2019-11-08 10:58:05,298 train 450 1.674631e-02 -0.851663
2019-11-08 10:58:15,056 train 500 1.671806e-02 -0.870091
2019-11-08 10:58:24,831 train 550 1.671056e-02 -0.849490
2019-11-08 10:58:34,612 train 600 1.672145e-02 -0.826720
2019-11-08 10:58:44,386 train 650 1.670906e-02 -0.816456
2019-11-08 10:58:54,165 train 700 1.670129e-02 -0.794708
2019-11-08 10:59:03,942 train 750 1.668363e-02 -0.785266
2019-11-08 10:59:13,720 train 800 1.669852e-02 -1.374117
2019-11-08 10:59:23,514 train 850 1.670230e-02 -1.334405
2019-11-08 10:59:26,436 training loss; R2: 1.670253e-02 -1.328802
2019-11-08 10:59:27,024 valid 000 1.499703e-02 -2.799842
2019-11-08 10:59:36,479 valid 050 1.375103e-02 -0.635571
2019-11-08 10:59:44,798 validation loss; R2: 1.393077e-02 -0.854989
2019-11-08 10:59:44,865 epoch 936 lr 1.000000e-05
2019-11-08 10:59:45,641 train 000 1.418256e-02 0.069558
2019-11-08 10:59:55,376 train 050 1.684056e-02 -0.381920
2019-11-08 11:00:05,137 train 100 1.694569e-02 -0.684473
2019-11-08 11:00:14,911 train 150 1.678884e-02 -0.653021
2019-11-08 11:00:24,683 train 200 1.675557e-02 -0.609995
2019-11-08 11:00:34,459 train 250 1.674523e-02 -1.056076
2019-11-08 11:00:44,237 train 300 1.670655e-02 -0.991586
2019-11-08 11:00:54,001 train 350 1.661845e-02 -0.941591
2019-11-08 11:01:03,784 train 400 1.660247e-02 -0.907960
2019-11-08 11:01:13,574 train 450 1.660126e-02 -0.912711
2019-11-08 11:01:23,350 train 500 1.662044e-02 -0.870053
2019-11-08 11:01:33,127 train 550 1.667469e-02 -0.855017
2019-11-08 11:01:42,953 train 600 1.667070e-02 -0.827387
2019-11-08 11:01:52,758 train 650 1.665885e-02 -0.824178
2019-11-08 11:02:02,570 train 700 1.664558e-02 -0.808210
2019-11-08 11:02:12,378 train 750 1.664142e-02 -0.784449
2019-11-08 11:02:22,187 train 800 1.663188e-02 -0.792313
2019-11-08 11:02:32,015 train 850 1.663359e-02 -0.792724
2019-11-08 11:02:34,955 training loss; R2: 1.662868e-02 -0.794006
2019-11-08 11:02:35,653 valid 000 1.527252e-02 -0.488116
2019-11-08 11:02:45,049 valid 050 1.405286e-02 -0.674741
2019-11-08 11:02:53,428 validation loss; R2: 1.409683e-02 -0.830765
2019-11-08 11:02:53,493 epoch 937 lr 1.000000e-05
2019-11-08 11:02:54,221 train 000 1.523261e-02 -0.123143
2019-11-08 11:03:03,969 train 050 1.651730e-02 -0.582852
2019-11-08 11:03:13,745 train 100 1.649454e-02 -0.639366
2019-11-08 11:03:23,535 train 150 1.659243e-02 -0.644406
2019-11-08 11:03:33,329 train 200 1.658575e-02 -0.646365
2019-11-08 11:03:43,132 train 250 1.654628e-02 -0.717188
2019-11-08 11:03:52,944 train 300 1.650572e-02 -0.688717
2019-11-08 11:04:02,755 train 350 1.651385e-02 -0.723657
2019-11-08 11:04:12,562 train 400 1.657306e-02 -0.731044
2019-11-08 11:04:22,363 train 450 1.662255e-02 -0.735229
2019-11-08 11:04:32,171 train 500 1.662016e-02 -0.712168
2019-11-08 11:04:41,990 train 550 1.663533e-02 -0.721416
2019-11-08 11:04:51,822 train 600 1.666240e-02 -0.735871
2019-11-08 11:05:01,672 train 650 1.668004e-02 -0.747492
2019-11-08 11:05:11,511 train 700 1.669712e-02 -0.744081
2019-11-08 11:05:21,351 train 750 1.667510e-02 -0.735182
2019-11-08 11:05:31,194 train 800 1.663122e-02 -0.726870
2019-11-08 11:05:41,028 train 850 1.662767e-02 -0.771030
2019-11-08 11:05:43,972 training loss; R2: 1.663828e-02 -0.772346
2019-11-08 11:05:44,613 valid 000 1.690204e-02 -0.627235
2019-11-08 11:05:54,027 valid 050 1.656896e-02 -1.269783
2019-11-08 11:06:02,330 validation loss; R2: 1.633309e-02 -1.568253
2019-11-08 11:06:02,395 epoch 938 lr 1.000000e-05
2019-11-08 11:06:03,124 train 000 1.584447e-02 -0.224638
2019-11-08 11:06:12,897 train 050 1.701109e-02 -0.817133
2019-11-08 11:06:22,676 train 100 1.680580e-02 -0.775195
2019-11-08 11:06:32,484 train 150 1.684066e-02 -0.722152
2019-11-08 11:06:42,307 train 200 1.670231e-02 -0.627641
2019-11-08 11:06:52,108 train 250 1.659680e-02 -0.693818
2019-11-08 11:07:01,914 train 300 1.664856e-02 -0.688029
2019-11-08 11:07:11,732 train 350 1.667648e-02 -0.689471
2019-11-08 11:07:21,551 train 400 1.667368e-02 -0.707749
2019-11-08 11:07:31,352 train 450 1.662798e-02 -0.711366
2019-11-08 11:07:41,164 train 500 1.661348e-02 -0.702069
2019-11-08 11:07:50,971 train 550 1.664347e-02 -0.717603
2019-11-08 11:08:00,784 train 600 1.661169e-02 -0.719364
2019-11-08 11:08:10,599 train 650 1.663380e-02 -0.708074
2019-11-08 11:08:20,405 train 700 1.665155e-02 -0.735770
2019-11-08 11:08:30,217 train 750 1.665080e-02 -0.742450
2019-11-08 11:08:40,024 train 800 1.664652e-02 -0.742469
2019-11-08 11:08:49,829 train 850 1.665547e-02 -0.737068
2019-11-08 11:08:52,762 training loss; R2: 1.666267e-02 -0.737214
2019-11-08 11:08:53,357 valid 000 1.565422e-02 -0.924944
2019-11-08 11:09:02,808 valid 050 1.487786e-02 -0.787139
2019-11-08 11:09:11,116 validation loss; R2: 1.483150e-02 -1.265397
2019-11-08 11:09:11,182 epoch 939 lr 1.000000e-05
2019-11-08 11:09:11,977 train 000 1.530368e-02 -0.009148
2019-11-08 11:09:21,746 train 050 1.733984e-02 -0.697469
2019-11-08 11:09:31,520 train 100 1.683639e-02 -0.641507
2019-11-08 11:09:41,328 train 150 1.681620e-02 -0.713871
2019-11-08 11:09:51,128 train 200 1.679263e-02 -0.701026
2019-11-08 11:10:00,940 train 250 1.667996e-02 -0.727643
2019-11-08 11:10:10,754 train 300 1.665534e-02 -0.731201
2019-11-08 11:10:20,578 train 350 1.664982e-02 -0.736916
2019-11-08 11:10:30,405 train 400 1.663640e-02 -0.753681
2019-11-08 11:10:40,214 train 450 1.658906e-02 -0.714789
2019-11-08 11:10:50,025 train 500 1.661886e-02 -0.768923
2019-11-08 11:10:59,817 train 550 1.662333e-02 -0.752484
2019-11-08 11:11:09,619 train 600 1.660506e-02 -0.756798
2019-11-08 11:11:19,421 train 650 1.661445e-02 -0.770333
2019-11-08 11:11:29,215 train 700 1.659237e-02 -0.767534
2019-11-08 11:11:39,037 train 750 1.660265e-02 -0.821284
2019-11-08 11:11:48,854 train 800 1.658935e-02 -0.826589
2019-11-08 11:11:58,671 train 850 1.655914e-02 -0.821975
2019-11-08 11:12:01,602 training loss; R2: 1.655518e-02 -0.831620
2019-11-08 11:12:02,290 valid 000 1.303233e-02 -0.959353
2019-11-08 11:12:11,728 valid 050 1.509705e-02 -1.687037
2019-11-08 11:12:20,053 validation loss; R2: 1.548664e-02 -1.626169
2019-11-08 11:12:20,119 epoch 940 lr 1.000000e-05
2019-11-08 11:12:20,891 train 000 1.433884e-02 -0.618221
2019-11-08 11:12:30,654 train 050 1.623057e-02 -1.224402
2019-11-08 11:12:40,453 train 100 1.636559e-02 -0.952822
2019-11-08 11:12:50,273 train 150 1.649234e-02 -0.852426
2019-11-08 11:13:00,087 train 200 1.655273e-02 -0.848299
2019-11-08 11:13:09,895 train 250 1.653724e-02 -0.830611
2019-11-08 11:13:19,701 train 300 1.658291e-02 -0.840858
2019-11-08 11:13:29,497 train 350 1.662931e-02 -0.828953
2019-11-08 11:13:39,329 train 400 1.659256e-02 -0.800286
2019-11-08 11:13:49,149 train 450 1.663550e-02 -0.841180
2019-11-08 11:13:58,977 train 500 1.660368e-02 -0.830477
2019-11-08 11:14:08,802 train 550 1.661007e-02 -0.837553
2019-11-08 11:14:18,585 train 600 1.663983e-02 -0.806770
2019-11-08 11:14:28,357 train 650 1.666949e-02 -1.331884
2019-11-08 11:14:38,121 train 700 1.666463e-02 -1.302359
2019-11-08 11:14:47,905 train 750 1.667454e-02 -1.253185
2019-11-08 11:14:57,655 train 800 1.669043e-02 -1.223829
2019-11-08 11:15:07,420 train 850 1.667992e-02 -1.189127
2019-11-08 11:15:10,337 training loss; R2: 1.668758e-02 -1.176748
2019-11-08 11:15:11,031 valid 000 1.177863e-02 -0.617363
2019-11-08 11:15:20,449 valid 050 1.441482e-02 -1.040475
2019-11-08 11:15:28,816 validation loss; R2: 1.442248e-02 -0.793129
2019-11-08 11:15:28,880 epoch 941 lr 1.000000e-05
2019-11-08 11:15:29,611 train 000 1.626262e-02 -0.004722
2019-11-08 11:15:39,322 train 050 1.673438e-02 -0.870978
2019-11-08 11:15:49,043 train 100 1.661060e-02 -0.787545
2019-11-08 11:15:58,783 train 150 1.658436e-02 -0.789999
2019-11-08 11:16:08,519 train 200 1.653767e-02 -0.756862
2019-11-08 11:16:18,255 train 250 1.649756e-02 -0.779262
2019-11-08 11:16:28,001 train 300 1.652912e-02 -0.794216
2019-11-08 11:16:37,744 train 350 1.656888e-02 -0.757319
2019-11-08 11:16:47,490 train 400 1.665310e-02 -0.738060
2019-11-08 11:16:57,237 train 450 1.663500e-02 -0.743572
2019-11-08 11:17:06,990 train 500 1.665801e-02 -0.730571
2019-11-08 11:17:16,771 train 550 1.667123e-02 -0.774431
2019-11-08 11:17:26,544 train 600 1.665309e-02 -0.772577
2019-11-08 11:17:36,328 train 650 1.665573e-02 -0.768440
2019-11-08 11:17:46,110 train 700 1.666600e-02 -0.793603
2019-11-08 11:17:55,890 train 750 1.662988e-02 -0.790315
2019-11-08 11:18:05,669 train 800 1.662860e-02 -0.783350
2019-11-08 11:18:15,466 train 850 1.665428e-02 -0.793586
2019-11-08 11:18:18,417 training loss; R2: 1.665720e-02 -0.789423
2019-11-08 11:18:19,062 valid 000 1.472169e-02 -0.656344
2019-11-08 11:18:28,462 valid 050 1.518228e-02 -1.065939
2019-11-08 11:18:36,758 validation loss; R2: 1.489835e-02 -1.109564
2019-11-08 11:18:36,845 epoch 942 lr 1.000000e-05
2019-11-08 11:18:37,639 train 000 1.818993e-02 -0.032822
2019-11-08 11:18:47,787 train 050 1.665874e-02 -1.030899
2019-11-08 11:18:57,715 train 100 1.650440e-02 -0.962223
2019-11-08 11:19:07,524 train 150 1.648265e-02 -0.914183
2019-11-08 11:19:17,339 train 200 1.652999e-02 -0.877949
2019-11-08 11:19:27,137 train 250 1.655614e-02 -0.849033
2019-11-08 11:19:36,936 train 300 1.654310e-02 -0.845802
2019-11-08 11:19:46,732 train 350 1.658684e-02 -0.825861
2019-11-08 11:19:56,535 train 400 1.661123e-02 -0.792097
2019-11-08 11:20:06,344 train 450 1.659114e-02 -0.784235
2019-11-08 11:20:16,169 train 500 1.660955e-02 -0.830004
2019-11-08 11:20:25,984 train 550 1.661097e-02 -0.821394
2019-11-08 11:20:35,798 train 600 1.662770e-02 -0.826854
2019-11-08 11:20:45,633 train 650 1.662768e-02 -0.825410
2019-11-08 11:20:55,464 train 700 1.668400e-02 -0.802832
2019-11-08 11:21:05,274 train 750 1.665644e-02 -0.782688
2019-11-08 11:21:15,099 train 800 1.667329e-02 -0.779359
2019-11-08 11:21:24,922 train 850 1.665739e-02 -0.769596
2019-11-08 11:21:27,854 training loss; R2: 1.664728e-02 -0.762750
2019-11-08 11:21:28,534 valid 000 2.176343e-02 -0.733958
2019-11-08 11:21:37,891 valid 050 2.069728e-02 -2.363726
2019-11-08 11:21:46,198 validation loss; R2: 2.039027e-02 -2.310136
2019-11-08 11:21:46,266 epoch 943 lr 1.000000e-05
2019-11-08 11:21:47,046 train 000 1.771783e-02 -0.050856
2019-11-08 11:21:56,811 train 050 1.664940e-02 -0.682260
2019-11-08 11:22:06,599 train 100 1.661806e-02 -11.612929
2019-11-08 11:22:16,374 train 150 1.670584e-02 -8.177260
2019-11-08 11:22:26,141 train 200 1.665076e-02 -6.266954
2019-11-08 11:22:35,924 train 250 1.665617e-02 -5.146880
2019-11-08 11:22:45,722 train 300 1.663601e-02 -4.447107
2019-11-08 11:22:55,505 train 350 1.659648e-02 -3.910091
2019-11-08 11:23:05,305 train 400 1.665908e-02 -3.537575
2019-11-08 11:23:15,111 train 450 1.663059e-02 -3.234631
2019-11-08 11:23:24,925 train 500 1.664223e-02 -2.987671
2019-11-08 11:23:34,745 train 550 1.661958e-02 -2.783265
2019-11-08 11:23:44,548 train 600 1.662448e-02 -2.605020
2019-11-08 11:23:54,367 train 650 1.660279e-02 -2.466078
2019-11-08 11:24:04,169 train 700 1.660335e-02 -2.342331
2019-11-08 11:24:13,990 train 750 1.657598e-02 -2.297451
2019-11-08 11:24:23,821 train 800 1.656612e-02 -2.210649
2019-11-08 11:24:33,660 train 850 1.657389e-02 -2.126476
2019-11-08 11:24:36,591 training loss; R2: 1.657652e-02 -2.103275
2019-11-08 11:24:37,277 valid 000 1.466418e-02 -2.155801
2019-11-08 11:24:46,681 valid 050 1.507573e-02 -1.226120
2019-11-08 11:24:54,961 validation loss; R2: 1.502461e-02 -1.140595
2019-11-08 11:24:55,027 epoch 944 lr 1.000000e-05
2019-11-08 11:24:55,797 train 000 1.945192e-02 -0.007521
2019-11-08 11:25:05,558 train 050 1.645220e-02 -0.868234
2019-11-08 11:25:15,347 train 100 1.657423e-02 -0.758669
2019-11-08 11:25:25,152 train 150 1.659906e-02 -0.775337
2019-11-08 11:25:34,942 train 200 1.669774e-02 -0.780264
2019-11-08 11:25:44,743 train 250 1.663487e-02 -0.783274
2019-11-08 11:25:54,535 train 300 1.662463e-02 -0.764285
2019-11-08 11:26:04,338 train 350 1.660196e-02 -0.765239
2019-11-08 11:26:14,127 train 400 1.657392e-02 -0.794995
2019-11-08 11:26:23,935 train 450 1.655780e-02 -0.782782
2019-11-08 11:26:33,745 train 500 1.660242e-02 -0.798620
2019-11-08 11:26:43,591 train 550 1.659221e-02 -0.788314
2019-11-08 11:26:53,451 train 600 1.659649e-02 -0.793947
2019-11-08 11:27:03,320 train 650 1.663363e-02 -0.815716
2019-11-08 11:27:13,188 train 700 1.660543e-02 -0.859736
2019-11-08 11:27:23,061 train 750 1.659008e-02 -0.856090
2019-11-08 11:27:32,921 train 800 1.659432e-02 -0.849977
2019-11-08 11:27:42,779 train 850 1.659762e-02 -0.845689
2019-11-08 11:27:45,758 training loss; R2: 1.662070e-02 -0.839993
2019-11-08 11:27:46,390 valid 000 1.432285e-02 -1.568077
2019-11-08 11:27:55,799 valid 050 1.476745e-02 -0.901286
2019-11-08 11:28:04,209 validation loss; R2: 1.466904e-02 -2.391124
2019-11-08 11:28:04,289 epoch 945 lr 1.000000e-05
2019-11-08 11:28:05,107 train 000 1.626545e-02 -0.501440
2019-11-08 11:28:14,876 train 050 1.686631e-02 -0.900308
2019-11-08 11:28:24,676 train 100 1.684077e-02 -0.754777
2019-11-08 11:28:34,469 train 150 1.671045e-02 -0.727923
2019-11-08 11:28:44,271 train 200 1.669573e-02 -0.751440
2019-11-08 11:28:54,091 train 250 1.669037e-02 -0.769552
2019-11-08 11:29:03,902 train 300 1.667664e-02 -0.746455
2019-11-08 11:29:13,719 train 350 1.666653e-02 -0.722040
2019-11-08 11:29:23,552 train 400 1.670861e-02 -0.715939
2019-11-08 11:29:33,381 train 450 1.672076e-02 -0.729495
2019-11-08 11:29:43,210 train 500 1.667975e-02 -0.770324
2019-11-08 11:29:53,027 train 550 1.671997e-02 -0.806266
2019-11-08 11:30:02,842 train 600 1.670923e-02 -0.805070
2019-11-08 11:30:12,667 train 650 1.671235e-02 -0.809404
2019-11-08 11:30:22,502 train 700 1.670483e-02 -0.800949
2019-11-08 11:30:32,337 train 750 1.670669e-02 -0.800603
2019-11-08 11:30:42,169 train 800 1.671762e-02 -0.818782
2019-11-08 11:30:51,991 train 850 1.675373e-02 -0.818811
2019-11-08 11:30:54,962 training loss; R2: 1.675762e-02 -0.812941
2019-11-08 11:30:55,613 valid 000 1.344898e-02 0.050943
2019-11-08 11:31:05,027 valid 050 1.455697e-02 -0.856862
2019-11-08 11:31:13,487 validation loss; R2: 1.460968e-02 -0.743972
2019-11-08 11:31:13,574 epoch 946 lr 1.000000e-05
2019-11-08 11:31:14,379 train 000 2.073905e-02 -0.239977
2019-11-08 11:31:24,506 train 050 1.647529e-02 -0.829179
2019-11-08 11:31:34,679 train 100 1.669310e-02 -0.785001
2019-11-08 11:31:44,868 train 150 1.668078e-02 -0.846103
2019-11-08 11:31:55,029 train 200 1.658501e-02 -0.815384
2019-11-08 11:32:05,170 train 250 1.659709e-02 -0.829843
2019-11-08 11:32:15,318 train 300 1.653193e-02 -0.807040
2019-11-08 11:32:25,443 train 350 1.649965e-02 -0.863433
2019-11-08 11:32:35,569 train 400 1.646787e-02 -0.875388
2019-11-08 11:32:45,717 train 450 1.646714e-02 -0.912348
2019-11-08 11:32:55,872 train 500 1.652289e-02 -0.892715
2019-11-08 11:33:06,021 train 550 1.654592e-02 -0.846667
2019-11-08 11:33:16,175 train 600 1.654544e-02 -0.844614
2019-11-08 11:33:26,348 train 650 1.656332e-02 -0.837900
2019-11-08 11:33:36,492 train 700 1.656254e-02 -0.839001
2019-11-08 11:33:46,660 train 750 1.657183e-02 -0.850642
2019-11-08 11:33:56,826 train 800 1.657226e-02 -0.855691
2019-11-08 11:34:06,974 train 850 1.658091e-02 -0.844746
2019-11-08 11:34:10,011 training loss; R2: 1.658201e-02 -0.840250
2019-11-08 11:34:10,701 valid 000 1.446647e-02 -3.468873
2019-11-08 11:34:20,049 valid 050 1.536714e-02 -1.025829
2019-11-08 11:34:28,380 validation loss; R2: 1.519617e-02 -0.970479
2019-11-08 11:34:28,447 epoch 947 lr 1.000000e-05
2019-11-08 11:34:29,178 train 000 1.568119e-02 -0.055893
2019-11-08 11:34:38,938 train 050 1.666649e-02 -0.576517
2019-11-08 11:34:48,748 train 100 1.660034e-02 -0.864434
2019-11-08 11:34:58,544 train 150 1.656513e-02 -0.827419
2019-11-08 11:35:08,376 train 200 1.654601e-02 -0.749534
2019-11-08 11:35:18,186 train 250 1.656641e-02 -0.749809
2019-11-08 11:35:27,985 train 300 1.658419e-02 -0.820684
2019-11-08 11:35:37,789 train 350 1.660407e-02 -0.789660
2019-11-08 11:35:47,606 train 400 1.655181e-02 -0.779721
2019-11-08 11:35:57,406 train 450 1.660348e-02 -0.781499
2019-11-08 11:36:07,211 train 500 1.659930e-02 -0.762651
2019-11-08 11:36:17,005 train 550 1.659275e-02 -0.775799
2019-11-08 11:36:27,141 train 600 1.661789e-02 -0.797956
2019-11-08 11:36:37,280 train 650 1.661689e-02 -0.799202
2019-11-08 11:36:47,407 train 700 1.662386e-02 -0.773328
2019-11-08 11:36:57,565 train 750 1.660908e-02 -0.772765
2019-11-08 11:37:07,509 train 800 1.658765e-02 -0.763960
2019-11-08 11:37:17,289 train 850 1.659096e-02 -0.766566
2019-11-08 11:37:20,210 training loss; R2: 1.658827e-02 -0.762335
2019-11-08 11:37:20,896 valid 000 1.431044e-02 -0.657247
2019-11-08 11:37:30,267 valid 050 1.727143e-02 -1.057563
2019-11-08 11:37:38,586 validation loss; R2: 1.701034e-02 -1.788114
2019-11-08 11:37:38,654 epoch 948 lr 1.000000e-05
2019-11-08 11:37:39,388 train 000 1.426879e-02 -0.990966
2019-11-08 11:37:49,114 train 050 1.642248e-02 -0.626962
2019-11-08 11:37:58,838 train 100 1.652610e-02 -0.769684
2019-11-08 11:38:08,600 train 150 1.655177e-02 -0.693995
2019-11-08 11:38:18,374 train 200 1.655212e-02 -0.670530
2019-11-08 11:38:28,139 train 250 1.653913e-02 -0.834386
2019-11-08 11:38:37,927 train 300 1.659474e-02 -0.860930
2019-11-08 11:38:47,696 train 350 1.656097e-02 -0.873267
2019-11-08 11:38:57,470 train 400 1.663658e-02 -0.840976
2019-11-08 11:39:07,238 train 450 1.663005e-02 -0.835755
2019-11-08 11:39:17,003 train 500 1.661305e-02 -0.842997
2019-11-08 11:39:26,757 train 550 1.662490e-02 -0.826521
2019-11-08 11:39:36,532 train 600 1.664773e-02 -0.819371
2019-11-08 11:39:46,310 train 650 1.665397e-02 -0.798132
2019-11-08 11:39:56,090 train 700 1.664637e-02 -0.784096
2019-11-08 11:40:05,890 train 750 1.665757e-02 -0.778317
2019-11-08 11:40:15,683 train 800 1.666334e-02 -0.762286
2019-11-08 11:40:25,479 train 850 1.664222e-02 -0.759473
2019-11-08 11:40:28,404 training loss; R2: 1.663076e-02 -0.758095
2019-11-08 11:40:29,013 valid 000 1.672305e-02 -1.120578
2019-11-08 11:40:38,447 valid 050 1.553018e-02 -1.114828
2019-11-08 11:40:46,793 validation loss; R2: 1.558950e-02 -0.997056
2019-11-08 11:40:46,860 epoch 949 lr 1.000000e-05
2019-11-08 11:40:47,598 train 000 1.728844e-02 -0.828898
2019-11-08 11:40:57,330 train 050 1.676656e-02 -0.623749
2019-11-08 11:41:07,109 train 100 1.706898e-02 -0.741171
2019-11-08 11:41:16,872 train 150 1.690746e-02 -0.910490
2019-11-08 11:41:26,647 train 200 1.682882e-02 -0.842164
2019-11-08 11:41:36,421 train 250 1.675881e-02 -0.903223
2019-11-08 11:41:46,196 train 300 1.667898e-02 -0.945118
2019-11-08 11:41:55,977 train 350 1.662981e-02 -0.882529
2019-11-08 11:42:05,757 train 400 1.662906e-02 -0.875115
2019-11-08 11:42:15,546 train 450 1.667284e-02 -0.847574
2019-11-08 11:42:25,329 train 500 1.662488e-02 -0.814983
2019-11-08 11:42:35,126 train 550 1.658558e-02 -0.815839
2019-11-08 11:42:44,913 train 600 1.661213e-02 -0.788298
2019-11-08 11:42:54,701 train 650 1.660700e-02 -0.805086
2019-11-08 11:43:04,489 train 700 1.660613e-02 -0.798476
2019-11-08 11:43:14,268 train 750 1.660234e-02 -0.811498
2019-11-08 11:43:24,040 train 800 1.659406e-02 -2.399921
2019-11-08 11:43:33,803 train 850 1.658975e-02 -2.293663
2019-11-08 11:43:36,726 training loss; R2: 1.658019e-02 -2.269403
2019-11-08 11:43:37,325 valid 000 1.401118e-02 -0.259931
2019-11-08 11:43:46,762 valid 050 1.427060e-02 -1.100258
2019-11-08 11:43:55,066 validation loss; R2: 1.432229e-02 -1.019701
2019-11-08 11:43:55,133 epoch 950 lr 1.000000e-05
2019-11-08 11:43:55,872 train 000 1.954373e-02 -0.057649
2019-11-08 11:44:05,608 train 050 1.651965e-02 -1.227363
2019-11-08 11:44:15,352 train 100 1.669312e-02 -0.872818
2019-11-08 11:44:25,115 train 150 1.671786e-02 -2.735027
2019-11-08 11:44:34,864 train 200 1.654819e-02 -2.171079
2019-11-08 11:44:44,635 train 250 1.657039e-02 -1.832359
2019-11-08 11:44:54,404 train 300 1.659250e-02 -1.625304
2019-11-08 11:45:04,174 train 350 1.659388e-02 -1.471976
2019-11-08 11:45:13,938 train 400 1.660551e-02 -1.373064
2019-11-08 11:45:23,723 train 450 1.658282e-02 -1.291825
2019-11-08 11:45:33,499 train 500 1.661710e-02 -1.231398
2019-11-08 11:45:43,282 train 550 1.662709e-02 -1.185998
2019-11-08 11:45:53,059 train 600 1.660875e-02 -1.160861
2019-11-08 11:46:02,834 train 650 1.659825e-02 -1.112405
2019-11-08 11:46:12,603 train 700 1.659295e-02 -1.075334
2019-11-08 11:46:22,369 train 750 1.661300e-02 -1.189504
2019-11-08 11:46:32,152 train 800 1.660536e-02 -1.145361
2019-11-08 11:46:41,924 train 850 1.661296e-02 -1.114558
2019-11-08 11:46:44,852 training loss; R2: 1.660460e-02 -1.110231
2019-11-08 11:46:45,563 valid 000 1.488562e-02 -0.337276
2019-11-08 11:46:54,915 valid 050 1.581006e-02 -1.531671
2019-11-08 11:47:03,357 validation loss; R2: 1.564598e-02 -1.325332
2019-11-08 11:47:03,425 epoch 951 lr 1.000000e-05
2019-11-08 11:47:04,205 train 000 1.556564e-02 -2.309808
2019-11-08 11:47:13,914 train 050 1.698367e-02 -0.706627
2019-11-08 11:47:23,657 train 100 1.674362e-02 -0.686362
2019-11-08 11:47:33,417 train 150 1.664627e-02 -0.703483
2019-11-08 11:47:43,185 train 200 1.661641e-02 -1.564999
2019-11-08 11:47:52,944 train 250 1.654204e-02 -1.405202
2019-11-08 11:48:02,721 train 300 1.655217e-02 -1.282515
2019-11-08 11:48:12,480 train 350 1.653147e-02 -1.217005
2019-11-08 11:48:22,239 train 400 1.653447e-02 -1.185584
2019-11-08 11:48:31,999 train 450 1.653139e-02 -1.139743
2019-11-08 11:48:41,751 train 500 1.650929e-02 -1.107829
2019-11-08 11:48:51,505 train 550 1.650610e-02 -1.063334
2019-11-08 11:49:01,280 train 600 1.650789e-02 -1.029803
2019-11-08 11:49:11,037 train 650 1.653834e-02 -1.000421
2019-11-08 11:49:20,825 train 700 1.654756e-02 -0.984164
2019-11-08 11:49:30,586 train 750 1.656471e-02 -0.959074
2019-11-08 11:49:40,349 train 800 1.657577e-02 -0.974998
2019-11-08 11:49:50,124 train 850 1.657203e-02 -0.948525
2019-11-08 11:49:53,042 training loss; R2: 1.657152e-02 -0.941498
2019-11-08 11:49:53,673 valid 000 1.311499e-02 -1.817049
2019-11-08 11:50:03,077 valid 050 1.490064e-02 -1.185629
2019-11-08 11:50:11,404 validation loss; R2: 1.478269e-02 -1.439898
2019-11-08 11:50:11,470 epoch 952 lr 1.000000e-05
2019-11-08 11:50:12,200 train 000 1.379215e-02 -0.281576
2019-11-08 11:50:21,924 train 050 1.667304e-02 -0.671463
2019-11-08 11:50:31,699 train 100 1.663855e-02 -0.788093
2019-11-08 11:50:41,483 train 150 1.663750e-02 -0.698925
2019-11-08 11:50:51,278 train 200 1.665179e-02 -0.709961
2019-11-08 11:51:01,038 train 250 1.658953e-02 -0.685149
2019-11-08 11:51:10,811 train 300 1.654893e-02 -0.670246
2019-11-08 11:51:20,601 train 350 1.660050e-02 -0.683622
2019-11-08 11:51:30,396 train 400 1.661515e-02 -0.674272
2019-11-08 11:51:40,173 train 450 1.661870e-02 -0.728814
2019-11-08 11:51:49,951 train 500 1.662809e-02 -0.767724
2019-11-08 11:51:59,743 train 550 1.666151e-02 -0.843876
2019-11-08 11:52:09,533 train 600 1.663254e-02 -0.831186
2019-11-08 11:52:19,323 train 650 1.664228e-02 -0.834056
2019-11-08 11:52:29,121 train 700 1.663712e-02 -0.827306
2019-11-08 11:52:38,927 train 750 1.663872e-02 -0.818907
2019-11-08 11:52:48,728 train 800 1.663184e-02 -0.800145
2019-11-08 11:52:58,513 train 850 1.665137e-02 -0.780006
2019-11-08 11:53:01,440 training loss; R2: 1.665783e-02 -0.777496
2019-11-08 11:53:02,120 valid 000 1.164219e-02 -0.114077
2019-11-08 11:53:11,473 valid 050 1.450492e-02 -0.474149
2019-11-08 11:53:19,804 validation loss; R2: 1.461263e-02 -0.682735
2019-11-08 11:53:19,870 epoch 953 lr 1.000000e-05
2019-11-08 11:53:20,599 train 000 1.567585e-02 -1.656668
2019-11-08 11:53:30,335 train 050 1.686568e-02 -0.846150
2019-11-08 11:53:40,104 train 100 1.685575e-02 -0.935861
2019-11-08 11:53:49,868 train 150 1.668853e-02 -0.783792
2019-11-08 11:53:59,636 train 200 1.656014e-02 -0.887327
2019-11-08 11:54:09,411 train 250 1.656544e-02 -0.812320
2019-11-08 11:54:19,184 train 300 1.657297e-02 -0.796772
2019-11-08 11:54:28,961 train 350 1.662961e-02 -0.774706
2019-11-08 11:54:38,735 train 400 1.658875e-02 -0.762609
2019-11-08 11:54:48,510 train 450 1.661226e-02 -0.774258
2019-11-08 11:54:58,271 train 500 1.662264e-02 -0.776786
2019-11-08 11:55:08,056 train 550 1.661931e-02 -0.777959
2019-11-08 11:55:17,832 train 600 1.663110e-02 -0.766069
2019-11-08 11:55:27,611 train 650 1.661650e-02 -0.747010
2019-11-08 11:55:37,400 train 700 1.663376e-02 -0.739429
2019-11-08 11:55:47,195 train 750 1.662846e-02 -0.738547
2019-11-08 11:55:56,997 train 800 1.662442e-02 -0.745601
2019-11-08 11:56:06,798 train 850 1.663357e-02 -0.741236
2019-11-08 11:56:09,721 training loss; R2: 1.662949e-02 -0.747814
2019-11-08 11:56:10,410 valid 000 1.410194e-02 -0.009931
2019-11-08 11:56:19,831 valid 050 1.557257e-02 -1.335824
2019-11-08 11:56:28,150 validation loss; R2: 1.574649e-02 -1.512160
2019-11-08 11:56:28,215 epoch 954 lr 1.000000e-05
2019-11-08 11:56:28,962 train 000 1.662525e-02 -0.714909
2019-11-08 11:56:38,692 train 050 1.634881e-02 -0.593499
2019-11-08 11:56:48,451 train 100 1.660468e-02 -0.532242
2019-11-08 11:56:58,220 train 150 1.667388e-02 -0.555176
2019-11-08 11:57:08,003 train 200 1.670500e-02 -0.621094
2019-11-08 11:57:17,797 train 250 1.665712e-02 -0.638872
2019-11-08 11:57:27,592 train 300 1.667251e-02 -0.666699
2019-11-08 11:57:37,407 train 350 1.662308e-02 -0.658118
2019-11-08 11:57:47,211 train 400 1.662756e-02 -0.818471
2019-11-08 11:57:57,031 train 450 1.665388e-02 -0.821989
2019-11-08 11:58:06,845 train 500 1.668984e-02 -0.800281
2019-11-08 11:58:16,653 train 550 1.663920e-02 -0.838642
2019-11-08 11:58:26,474 train 600 1.661324e-02 -0.807386
2019-11-08 11:58:36,297 train 650 1.661953e-02 -0.800526
2019-11-08 11:58:46,150 train 700 1.663524e-02 -0.893372
2019-11-08 11:58:55,969 train 750 1.665441e-02 -0.880346
2019-11-08 11:59:05,788 train 800 1.663622e-02 -0.905749
2019-11-08 11:59:15,626 train 850 1.659750e-02 -0.905890
2019-11-08 11:59:18,566 training loss; R2: 1.660708e-02 -0.898759
2019-11-08 11:59:19,180 valid 000 1.374485e-02 -0.575228
2019-11-08 11:59:28,590 valid 050 1.430699e-02 -1.503417
2019-11-08 11:59:36,885 validation loss; R2: 1.440313e-02 -1.339312
2019-11-08 11:59:36,949 epoch 955 lr 1.000000e-05
2019-11-08 11:59:37,725 train 000 2.018140e-02 -0.341512
2019-11-08 11:59:47,486 train 050 1.654680e-02 -0.628922
2019-11-08 11:59:57,256 train 100 1.650874e-02 -0.897394
2019-11-08 12:00:07,025 train 150 1.654033e-02 -0.819829
2019-11-08 12:00:16,811 train 200 1.647896e-02 -0.817451
2019-11-08 12:00:26,598 train 250 1.651055e-02 -0.786733
2019-11-08 12:00:36,398 train 300 1.648404e-02 -0.779061
2019-11-08 12:00:46,191 train 350 1.649409e-02 -0.738008
2019-11-08 12:00:55,971 train 400 1.654475e-02 -0.743293
2019-11-08 12:01:05,732 train 450 1.655625e-02 -0.737750
2019-11-08 12:01:15,493 train 500 1.653180e-02 -0.716550
2019-11-08 12:01:25,262 train 550 1.656705e-02 -0.714065
2019-11-08 12:01:35,048 train 600 1.658627e-02 -0.711947
2019-11-08 12:01:44,819 train 650 1.656097e-02 -0.725395
2019-11-08 12:01:54,583 train 700 1.657438e-02 -0.729176
2019-11-08 12:02:04,369 train 750 1.661007e-02 -0.724042
2019-11-08 12:02:14,160 train 800 1.662681e-02 -0.734936
2019-11-08 12:02:23,961 train 850 1.663531e-02 -0.730461
2019-11-08 12:02:26,890 training loss; R2: 1.662507e-02 -0.729930
2019-11-08 12:02:27,465 valid 000 1.257900e-02 0.194751
2019-11-08 12:02:36,911 valid 050 1.541369e-02 -0.639543
2019-11-08 12:02:45,284 validation loss; R2: 1.524132e-02 -0.700929
2019-11-08 12:02:45,352 epoch 956 lr 1.000000e-05
2019-11-08 12:02:46,203 train 000 1.508372e-02 -0.335066
2019-11-08 12:02:55,952 train 050 1.647759e-02 -0.667310
2019-11-08 12:03:05,698 train 100 1.670758e-02 -0.814009
2019-11-08 12:03:15,470 train 150 1.668580e-02 -0.722076
2019-11-08 12:03:25,226 train 200 1.672657e-02 -1.124851
2019-11-08 12:03:34,987 train 250 1.670508e-02 -1.032524
2019-11-08 12:03:44,777 train 300 1.666646e-02 -0.980487
2019-11-08 12:03:54,545 train 350 1.666034e-02 -0.927315
2019-11-08 12:04:04,308 train 400 1.666021e-02 -0.921907
2019-11-08 12:04:14,066 train 450 1.672356e-02 -0.891812
2019-11-08 12:04:23,826 train 500 1.672087e-02 -0.865215
2019-11-08 12:04:33,601 train 550 1.670588e-02 -0.851730
2019-11-08 12:04:43,364 train 600 1.667828e-02 -0.838504
2019-11-08 12:04:53,145 train 650 1.665820e-02 -0.818696
2019-11-08 12:05:02,912 train 700 1.663879e-02 -0.805531
2019-11-08 12:05:12,687 train 750 1.660844e-02 -0.806771
2019-11-08 12:05:22,488 train 800 1.661900e-02 -0.815827
2019-11-08 12:05:32,267 train 850 1.664914e-02 -0.804583
2019-11-08 12:05:35,195 training loss; R2: 1.664191e-02 -0.801324
2019-11-08 12:05:35,872 valid 000 1.781332e-02 -1.196856
2019-11-08 12:05:45,294 valid 050 1.607832e-02 -1.898604
2019-11-08 12:05:53,585 validation loss; R2: 1.614769e-02 -1.680054
2019-11-08 12:05:53,652 epoch 957 lr 1.000000e-05
2019-11-08 12:05:54,394 train 000 1.638032e-02 -0.348822
2019-11-08 12:06:04,134 train 050 1.636704e-02 -0.699764
2019-11-08 12:06:13,874 train 100 1.651366e-02 -0.666589
2019-11-08 12:06:23,614 train 150 1.656107e-02 -0.650835
2019-11-08 12:06:33,365 train 200 1.655524e-02 -0.703397
2019-11-08 12:06:43,117 train 250 1.653592e-02 -0.701429
2019-11-08 12:06:52,850 train 300 1.656112e-02 -0.749634
2019-11-08 12:07:02,589 train 350 1.659407e-02 -0.748700
2019-11-08 12:07:12,321 train 400 1.657056e-02 -0.722593
2019-11-08 12:07:22,076 train 450 1.657057e-02 -0.697704
2019-11-08 12:07:31,827 train 500 1.658340e-02 -0.683318
2019-11-08 12:07:41,597 train 550 1.660144e-02 -0.681666
2019-11-08 12:07:51,368 train 600 1.662523e-02 -0.681019
2019-11-08 12:08:01,145 train 650 1.662228e-02 -0.679242
2019-11-08 12:08:10,929 train 700 1.661123e-02 -0.709016
2019-11-08 12:08:20,708 train 750 1.660473e-02 -0.711487
2019-11-08 12:08:30,480 train 800 1.662750e-02 -0.719944
2019-11-08 12:08:40,249 train 850 1.661730e-02 -0.708369
2019-11-08 12:08:43,171 training loss; R2: 1.662681e-02 -0.710841
2019-11-08 12:08:43,806 valid 000 1.463452e-02 -1.411697
2019-11-08 12:08:53,242 valid 050 1.543368e-02 -0.520307
2019-11-08 12:09:01,547 validation loss; R2: 1.551571e-02 -0.553104
2019-11-08 12:09:01,612 epoch 958 lr 1.000000e-05
2019-11-08 12:09:02,397 train 000 1.764701e-02 -0.143404
2019-11-08 12:09:12,127 train 050 1.719568e-02 -0.473018
2019-11-08 12:09:21,826 train 100 1.700413e-02 -0.804681
2019-11-08 12:09:31,575 train 150 1.674925e-02 -0.833570
2019-11-08 12:09:41,324 train 200 1.671248e-02 -0.839645
2019-11-08 12:09:51,078 train 250 1.665864e-02 -0.795181
2019-11-08 12:10:00,822 train 300 1.667641e-02 -0.818012
2019-11-08 12:10:10,571 train 350 1.669362e-02 -0.827671
2019-11-08 12:10:20,345 train 400 1.667493e-02 -0.832612
2019-11-08 12:10:30,093 train 450 1.667052e-02 -0.823149
2019-11-08 12:10:39,844 train 500 1.665570e-02 -0.824953
2019-11-08 12:10:49,604 train 550 1.667200e-02 -0.815001
2019-11-08 12:10:59,362 train 600 1.664281e-02 -0.792101
2019-11-08 12:11:09,120 train 650 1.663201e-02 -0.792025
2019-11-08 12:11:18,880 train 700 1.663516e-02 -0.786710
2019-11-08 12:11:28,660 train 750 1.662551e-02 -0.771469
2019-11-08 12:11:38,442 train 800 1.662175e-02 -0.765682
2019-11-08 12:11:48,228 train 850 1.665067e-02 -0.760597
2019-11-08 12:11:51,148 training loss; R2: 1.665211e-02 -0.768981
2019-11-08 12:11:51,745 valid 000 1.588152e-02 0.021897
2019-11-08 12:12:01,188 valid 050 1.424603e-02 -0.717422
2019-11-08 12:12:09,478 validation loss; R2: 1.425627e-02 -0.805033
2019-11-08 12:12:09,542 epoch 959 lr 1.000000e-05
2019-11-08 12:12:10,292 train 000 1.619158e-02 -0.887656
2019-11-08 12:12:20,035 train 050 1.657650e-02 -0.545330
2019-11-08 12:12:29,770 train 100 1.654020e-02 -0.570816
2019-11-08 12:12:39,525 train 150 1.663976e-02 -0.612099
2019-11-08 12:12:49,281 train 200 1.662198e-02 -0.654807
2019-11-08 12:12:59,038 train 250 1.655271e-02 -0.631005
2019-11-08 12:13:08,792 train 300 1.649504e-02 -0.625339
2019-11-08 12:13:18,578 train 350 1.653641e-02 -0.666521
2019-11-08 12:13:28,338 train 400 1.658489e-02 -0.667082
2019-11-08 12:13:38,110 train 450 1.657813e-02 -0.657410
2019-11-08 12:13:47,878 train 500 1.660077e-02 -0.662987
2019-11-08 12:13:57,651 train 550 1.659091e-02 -0.654585
2019-11-08 12:14:07,415 train 600 1.659731e-02 -0.666273
2019-11-08 12:14:17,177 train 650 1.660314e-02 -0.660706
2019-11-08 12:14:26,933 train 700 1.658798e-02 -0.659992
2019-11-08 12:14:36,694 train 750 1.658058e-02 -0.673743
2019-11-08 12:14:46,498 train 800 1.659669e-02 -0.674484
2019-11-08 12:14:56,286 train 850 1.659129e-02 -0.702198
2019-11-08 12:14:59,244 training loss; R2: 1.658586e-02 -0.703023
2019-11-08 12:14:59,888 valid 000 1.557231e-02 -0.314684
2019-11-08 12:15:09,279 valid 050 1.530981e-02 -1.226598
2019-11-08 12:15:17,604 validation loss; R2: 1.527512e-02 -1.087536
2019-11-08 12:15:17,680 epoch 960 lr 1.000000e-05
2019-11-08 12:15:18,475 train 000 1.779276e-02 -0.159480
2019-11-08 12:15:28,566 train 050 1.673559e-02 -0.877732
2019-11-08 12:15:38,702 train 100 1.661684e-02 -0.751404
2019-11-08 12:15:48,611 train 150 1.658372e-02 -0.682567
2019-11-08 12:15:58,390 train 200 1.661644e-02 -0.683888
2019-11-08 12:16:08,170 train 250 1.659749e-02 -0.663600
2019-11-08 12:16:17,962 train 300 1.658406e-02 -0.688418
2019-11-08 12:16:27,749 train 350 1.657496e-02 -0.728211
2019-11-08 12:16:37,539 train 400 1.658346e-02 -0.706530
2019-11-08 12:16:47,343 train 450 1.658130e-02 -0.738089
2019-11-08 12:16:57,129 train 500 1.661454e-02 -0.733658
2019-11-08 12:17:06,913 train 550 1.659246e-02 -0.749490
2019-11-08 12:17:16,716 train 600 1.660790e-02 -0.743735
2019-11-08 12:17:26,535 train 650 1.659730e-02 -0.746076
2019-11-08 12:17:36,347 train 700 1.659156e-02 -0.747262
2019-11-08 12:17:46,179 train 750 1.660227e-02 -0.731594
2019-11-08 12:17:55,984 train 800 1.660919e-02 -0.725142
2019-11-08 12:18:05,784 train 850 1.662030e-02 -0.718314
2019-11-08 12:18:08,721 training loss; R2: 1.661689e-02 -0.717809
2019-11-08 12:18:09,401 valid 000 1.592224e-02 -0.628791
2019-11-08 12:18:18,747 valid 050 1.507593e-02 -1.085961
2019-11-08 12:18:27,110 validation loss; R2: 1.529803e-02 -0.999767
2019-11-08 12:18:27,174 epoch 961 lr 1.000000e-05
2019-11-08 12:18:27,950 train 000 1.764234e-02 -0.463157
2019-11-08 12:18:37,734 train 050 1.654216e-02 -0.549820
2019-11-08 12:18:47,560 train 100 1.654296e-02 -0.530661
2019-11-08 12:18:57,382 train 150 1.656814e-02 -0.597624
2019-11-08 12:19:07,192 train 200 1.665812e-02 -0.591480
2019-11-08 12:19:17,028 train 250 1.672304e-02 -0.589669
2019-11-08 12:19:26,839 train 300 1.667682e-02 -0.558927
2019-11-08 12:19:36,663 train 350 1.664797e-02 -0.613178
2019-11-08 12:19:46,497 train 400 1.661908e-02 -0.641014
2019-11-08 12:19:56,331 train 450 1.663938e-02 -0.641891
2019-11-08 12:20:06,171 train 500 1.665076e-02 -0.632955
2019-11-08 12:20:16,018 train 550 1.665139e-02 -0.714476
2019-11-08 12:20:25,857 train 600 1.663927e-02 -0.718448
2019-11-08 12:20:35,688 train 650 1.661917e-02 -0.719817
2019-11-08 12:20:45,534 train 700 1.663105e-02 -0.843165
2019-11-08 12:20:55,388 train 750 1.663288e-02 -0.845815
2019-11-08 12:21:05,246 train 800 1.664255e-02 -0.832141
2019-11-08 12:21:15,108 train 850 1.665889e-02 -0.823942
2019-11-08 12:21:18,050 training loss; R2: 1.665011e-02 -0.820421
2019-11-08 12:21:18,645 valid 000 1.572393e-02 -1.106057
2019-11-08 12:21:28,043 valid 050 1.537234e-02 -1.201419
2019-11-08 12:21:36,423 validation loss; R2: 1.527057e-02 -1.131967
2019-11-08 12:21:36,489 epoch 962 lr 1.000000e-05
2019-11-08 12:21:37,296 train 000 1.616524e-02 0.069820
2019-11-08 12:21:47,054 train 050 1.703461e-02 -0.594534
2019-11-08 12:21:56,842 train 100 1.687761e-02 -0.617048
2019-11-08 12:22:06,628 train 150 1.678752e-02 -0.689169
2019-11-08 12:22:16,410 train 200 1.671864e-02 -0.669405
2019-11-08 12:22:26,213 train 250 1.671126e-02 -0.678501
2019-11-08 12:22:36,034 train 300 1.674512e-02 -0.717287
2019-11-08 12:22:45,854 train 350 1.674393e-02 -0.711304
2019-11-08 12:22:55,666 train 400 1.669648e-02 -0.717597
2019-11-08 12:23:05,499 train 450 1.667192e-02 -0.844274
2019-11-08 12:23:15,299 train 500 1.666843e-02 -0.827449
2019-11-08 12:23:25,115 train 550 1.663942e-02 -0.806709
2019-11-08 12:23:34,939 train 600 1.663916e-02 -0.793724
2019-11-08 12:23:44,742 train 650 1.664582e-02 -0.784048
2019-11-08 12:23:54,544 train 700 1.666051e-02 -0.932470
2019-11-08 12:24:04,350 train 750 1.664793e-02 -0.912829
2019-11-08 12:24:14,155 train 800 1.663758e-02 -0.914058
2019-11-08 12:24:23,970 train 850 1.665399e-02 -0.908242
2019-11-08 12:24:26,903 training loss; R2: 1.665410e-02 -0.900701
2019-11-08 12:24:27,577 valid 000 1.217261e-02 -1.009283
2019-11-08 12:24:36,952 valid 050 1.388143e-02 -1.175353
2019-11-08 12:24:45,347 validation loss; R2: 1.415218e-02 -0.854897
2019-11-08 12:24:45,412 epoch 963 lr 1.000000e-05
2019-11-08 12:24:46,188 train 000 1.807257e-02 -0.752102
2019-11-08 12:24:55,951 train 050 1.660515e-02 -0.738304
2019-11-08 12:25:05,780 train 100 1.666995e-02 -0.936141
2019-11-08 12:25:15,621 train 150 1.671756e-02 -0.854668
2019-11-08 12:25:25,457 train 200 1.677921e-02 -1.816356
2019-11-08 12:25:35,289 train 250 1.674070e-02 -1.566279
2019-11-08 12:25:45,100 train 300 1.664963e-02 -1.448074
2019-11-08 12:25:54,932 train 350 1.662574e-02 -1.322206
2019-11-08 12:26:04,761 train 400 1.661412e-02 -1.338514
2019-11-08 12:26:14,597 train 450 1.663027e-02 -1.269034
2019-11-08 12:26:24,426 train 500 1.655738e-02 -1.190972
2019-11-08 12:26:34,266 train 550 1.655723e-02 -1.158297
2019-11-08 12:26:44,112 train 600 1.656611e-02 -1.125696
2019-11-08 12:26:53,973 train 650 1.657191e-02 -1.097442
2019-11-08 12:27:03,823 train 700 1.656017e-02 -1.682676
2019-11-08 12:27:13,669 train 750 1.656610e-02 -1.632236
2019-11-08 12:27:23,562 train 800 1.657132e-02 -1.585379
2019-11-08 12:27:33,395 train 850 1.657957e-02 -1.556491
2019-11-08 12:27:36,320 training loss; R2: 1.657399e-02 -1.541996
2019-11-08 12:27:36,972 valid 000 1.537183e-02 0.005545
2019-11-08 12:27:46,383 valid 050 1.519484e-02 -1.476771
2019-11-08 12:27:54,694 validation loss; R2: 1.513180e-02 -1.299171
2019-11-08 12:27:54,760 epoch 964 lr 1.000000e-05
2019-11-08 12:27:55,507 train 000 1.801122e-02 -0.505304
2019-11-08 12:28:05,235 train 050 1.660269e-02 -0.849562
2019-11-08 12:28:14,970 train 100 1.657237e-02 -0.792360
2019-11-08 12:28:24,725 train 150 1.656180e-02 -0.710920
2019-11-08 12:28:34,481 train 200 1.650384e-02 -0.691782
2019-11-08 12:28:44,234 train 250 1.646304e-02 -0.655959
2019-11-08 12:28:53,999 train 300 1.655082e-02 -0.651908
2019-11-08 12:29:03,756 train 350 1.660855e-02 -0.642186
2019-11-08 12:29:13,529 train 400 1.659305e-02 -0.637057
2019-11-08 12:29:23,311 train 450 1.657248e-02 -0.629057
2019-11-08 12:29:33,102 train 500 1.658734e-02 -0.665160
2019-11-08 12:29:42,902 train 550 1.656500e-02 -0.668277
2019-11-08 12:29:52,716 train 600 1.658355e-02 -0.673517
2019-11-08 12:30:02,549 train 650 1.658282e-02 -0.715158
2019-11-08 12:30:12,328 train 700 1.659072e-02 -0.733609
2019-11-08 12:30:22,128 train 750 1.657371e-02 -0.759645
2019-11-08 12:30:31,932 train 800 1.657982e-02 -0.749169
2019-11-08 12:30:41,737 train 850 1.659319e-02 -0.748208
2019-11-08 12:30:44,668 training loss; R2: 1.658319e-02 -0.748193
2019-11-08 12:30:45,304 valid 000 1.598570e-02 -1.259892
2019-11-08 12:30:54,720 valid 050 1.402611e-02 -2.810973
2019-11-08 12:31:03,056 validation loss; R2: 1.394301e-02 -1.954738
2019-11-08 12:31:03,123 epoch 965 lr 1.000000e-05
2019-11-08 12:31:03,888 train 000 1.580042e-02 -0.641642
2019-11-08 12:31:13,634 train 050 1.673029e-02 -0.797756
2019-11-08 12:31:23,409 train 100 1.668246e-02 -1.008440
2019-11-08 12:31:33,176 train 150 1.666529e-02 -0.871482
2019-11-08 12:31:42,943 train 200 1.667486e-02 -0.890229
2019-11-08 12:31:52,721 train 250 1.669228e-02 -0.868843
2019-11-08 12:32:02,495 train 300 1.666224e-02 -0.855808
2019-11-08 12:32:12,278 train 350 1.656184e-02 -0.857385
2019-11-08 12:32:22,056 train 400 1.654821e-02 -0.817343
2019-11-08 12:32:31,827 train 450 1.655607e-02 -0.816969
2019-11-08 12:32:41,611 train 500 1.654745e-02 -0.793017
2019-11-08 12:32:51,389 train 550 1.653564e-02 -1.291638
2019-11-08 12:33:01,189 train 600 1.653204e-02 -1.229507
2019-11-08 12:33:10,974 train 650 1.654608e-02 -1.189306
2019-11-08 12:33:20,765 train 700 1.657814e-02 -1.181352
2019-11-08 12:33:30,554 train 750 1.655861e-02 -1.160967
2019-11-08 12:33:40,342 train 800 1.658181e-02 -1.133787
2019-11-08 12:33:50,137 train 850 1.658987e-02 -1.110527
2019-11-08 12:33:53,057 training loss; R2: 1.658897e-02 -1.112190
2019-11-08 12:33:53,657 valid 000 1.782387e-02 -0.385034
2019-11-08 12:34:03,090 valid 050 1.636152e-02 -0.786828
2019-11-08 12:34:11,477 validation loss; R2: 1.638009e-02 -0.948778
2019-11-08 12:34:11,543 epoch 966 lr 1.000000e-05
2019-11-08 12:34:12,334 train 000 1.586659e-02 -0.585953
2019-11-08 12:34:22,061 train 050 1.676268e-02 -0.578290
2019-11-08 12:34:31,829 train 100 1.699849e-02 -0.591451
2019-11-08 12:34:41,588 train 150 1.691402e-02 -0.553636
2019-11-08 12:34:51,363 train 200 1.682603e-02 -0.652448
2019-11-08 12:35:01,117 train 250 1.679835e-02 -0.675364
2019-11-08 12:35:10,884 train 300 1.675701e-02 -0.698856
2019-11-08 12:35:20,660 train 350 1.676537e-02 -0.747238
2019-11-08 12:35:30,423 train 400 1.679668e-02 -0.731365
2019-11-08 12:35:40,199 train 450 1.678435e-02 -0.733260
2019-11-08 12:35:49,966 train 500 1.676779e-02 -0.752916
2019-11-08 12:35:59,719 train 550 1.674571e-02 -0.746675
2019-11-08 12:36:09,505 train 600 1.674040e-02 -0.746424
2019-11-08 12:36:19,288 train 650 1.672093e-02 -0.723026
2019-11-08 12:36:29,088 train 700 1.669551e-02 -0.708710
2019-11-08 12:36:38,882 train 750 1.666716e-02 -0.721579
2019-11-08 12:36:48,677 train 800 1.668388e-02 -0.725098
2019-11-08 12:36:58,467 train 850 1.667627e-02 -0.861334
2019-11-08 12:37:01,397 training loss; R2: 1.668343e-02 -0.870865
2019-11-08 12:37:01,997 valid 000 1.514626e-02 -0.424173
2019-11-08 12:37:11,485 valid 050 1.449469e-02 -1.123735
2019-11-08 12:37:19,815 validation loss; R2: 1.483648e-02 -1.479964
2019-11-08 12:37:19,893 epoch 967 lr 1.000000e-05
2019-11-08 12:37:20,688 train 000 1.656796e-02 -0.329744
2019-11-08 12:37:30,822 train 050 1.658096e-02 -0.880457
2019-11-08 12:37:40,975 train 100 1.644454e-02 -0.861860
2019-11-08 12:37:51,136 train 150 1.649890e-02 -0.789548
2019-11-08 12:38:01,291 train 200 1.646967e-02 -0.767454
2019-11-08 12:38:11,451 train 250 1.649631e-02 -0.799751
2019-11-08 12:38:21,594 train 300 1.647824e-02 -0.817839
2019-11-08 12:38:31,762 train 350 1.646262e-02 -0.814222
2019-11-08 12:38:41,930 train 400 1.646573e-02 -0.778942
2019-11-08 12:38:52,069 train 450 1.649467e-02 -0.780000
2019-11-08 12:39:02,226 train 500 1.647883e-02 -0.965045
2019-11-08 12:39:12,424 train 550 1.651531e-02 -0.932843
2019-11-08 12:39:22,599 train 600 1.656709e-02 -0.904573
2019-11-08 12:39:32,790 train 650 1.658390e-02 -0.904968
2019-11-08 12:39:42,983 train 700 1.657671e-02 -0.880437
2019-11-08 12:39:53,145 train 750 1.655028e-02 -0.876329
2019-11-08 12:40:03,337 train 800 1.654463e-02 -0.854465
2019-11-08 12:40:13,513 train 850 1.657486e-02 -0.843381
2019-11-08 12:40:16,551 training loss; R2: 1.657170e-02 -0.834238
2019-11-08 12:40:17,212 valid 000 1.308481e-02 -0.144917
2019-11-08 12:40:26,706 valid 050 1.491869e-02 -1.481589
2019-11-08 12:40:35,034 validation loss; R2: 1.497520e-02 -1.464742
2019-11-08 12:40:35,105 epoch 968 lr 1.000000e-05
2019-11-08 12:40:35,834 train 000 1.814945e-02 -0.249823
2019-11-08 12:40:45,933 train 050 1.619360e-02 -0.720594
2019-11-08 12:40:56,079 train 100 1.622744e-02 -0.649646
2019-11-08 12:41:06,209 train 150 1.641403e-02 -0.669131
2019-11-08 12:41:16,032 train 200 1.643426e-02 -0.664839
2019-11-08 12:41:25,798 train 250 1.659646e-02 -0.690362
2019-11-08 12:41:35,544 train 300 1.667952e-02 -0.829484
2019-11-08 12:41:45,292 train 350 1.669109e-02 -0.801214
2019-11-08 12:41:55,076 train 400 1.665167e-02 -0.802793
2019-11-08 12:42:04,857 train 450 1.667067e-02 -0.920837
2019-11-08 12:42:14,638 train 500 1.664204e-02 -0.901146
2019-11-08 12:42:24,417 train 550 1.663481e-02 -0.905964
2019-11-08 12:42:34,198 train 600 1.668451e-02 -0.916925
2019-11-08 12:42:43,990 train 650 1.666806e-02 -0.908501
2019-11-08 12:42:53,782 train 700 1.665981e-02 -0.889249
2019-11-08 12:43:03,581 train 750 1.663547e-02 -0.866608
2019-11-08 12:43:13,389 train 800 1.661619e-02 -0.867237
2019-11-08 12:43:23,195 train 850 1.661702e-02 -0.869284
2019-11-08 12:43:26,120 training loss; R2: 1.660909e-02 -0.870982
2019-11-08 12:43:26,783 valid 000 1.175974e-02 -0.636727
2019-11-08 12:43:36,128 valid 050 1.432284e-02 -0.797193
2019-11-08 12:43:44,561 validation loss; R2: 1.447850e-02 -0.891209
2019-11-08 12:43:44,625 epoch 969 lr 1.000000e-05
2019-11-08 12:43:45,379 train 000 1.460008e-02 -0.523120
2019-11-08 12:43:55,107 train 050 1.688047e-02 -0.734518
2019-11-08 12:44:04,853 train 100 1.669701e-02 -0.670391
2019-11-08 12:44:14,621 train 150 1.650040e-02 -0.641071
2019-11-08 12:44:24,403 train 200 1.662224e-02 -0.654887
2019-11-08 12:44:34,205 train 250 1.659755e-02 -0.645156
2019-11-08 12:44:44,010 train 300 1.663375e-02 -0.635307
2019-11-08 12:44:53,825 train 350 1.661423e-02 -0.626720
2019-11-08 12:45:03,627 train 400 1.657642e-02 -0.680521
2019-11-08 12:45:13,432 train 450 1.654074e-02 -0.663153
2019-11-08 12:45:23,263 train 500 1.652891e-02 -0.688348
2019-11-08 12:45:33,075 train 550 1.656787e-02 -0.713296
2019-11-08 12:45:42,891 train 600 1.657261e-02 -0.700886
2019-11-08 12:45:52,728 train 650 1.658326e-02 -0.717948
2019-11-08 12:46:02,548 train 700 1.660460e-02 -0.729222
2019-11-08 12:46:12,366 train 750 1.658998e-02 -0.721947
2019-11-08 12:46:22,180 train 800 1.657029e-02 -0.716950
2019-11-08 12:46:31,999 train 850 1.657078e-02 -0.709123
2019-11-08 12:46:34,933 training loss; R2: 1.656312e-02 -0.705889
2019-11-08 12:46:35,588 valid 000 1.576902e-02 -0.261602
2019-11-08 12:46:44,969 valid 050 1.492008e-02 -0.960583
2019-11-08 12:46:53,376 validation loss; R2: 1.489888e-02 -1.050062
2019-11-08 12:46:53,444 epoch 970 lr 1.000000e-05
2019-11-08 12:46:54,200 train 000 1.394392e-02 -1.656296
2019-11-08 12:47:03,949 train 050 1.679543e-02 -0.867354
2019-11-08 12:47:13,698 train 100 1.667432e-02 -0.908841
2019-11-08 12:47:23,468 train 150 1.653652e-02 -1.295028
2019-11-08 12:47:33,243 train 200 1.645985e-02 -2.377861
2019-11-08 12:47:43,024 train 250 1.650174e-02 -2.060702
2019-11-08 12:47:52,808 train 300 1.656445e-02 -1.847009
2019-11-08 12:48:02,609 train 350 1.656244e-02 -1.718655
2019-11-08 12:48:12,386 train 400 1.651906e-02 -1.595705
2019-11-08 12:48:22,171 train 450 1.651290e-02 -1.500688
2019-11-08 12:48:31,969 train 500 1.654121e-02 -1.417451
2019-11-08 12:48:41,776 train 550 1.657525e-02 -1.337862
2019-11-08 12:48:51,585 train 600 1.656247e-02 -1.307173
2019-11-08 12:49:01,397 train 650 1.652414e-02 -1.267326
2019-11-08 12:49:11,211 train 700 1.654557e-02 -1.243412
2019-11-08 12:49:21,022 train 750 1.655955e-02 -1.205199
2019-11-08 12:49:30,834 train 800 1.656666e-02 -1.164908
2019-11-08 12:49:40,641 train 850 1.655488e-02 -1.134880
2019-11-08 12:49:43,572 training loss; R2: 1.654319e-02 -1.125512
2019-11-08 12:49:44,173 valid 000 1.492556e-02 -4.177454
2019-11-08 12:49:53,641 valid 050 1.444381e-02 -0.975312
2019-11-08 12:50:01,958 validation loss; R2: 1.444947e-02 -1.077557
2019-11-08 12:50:02,023 epoch 971 lr 1.000000e-05
2019-11-08 12:50:02,831 train 000 1.937451e-02 -0.209571
2019-11-08 12:50:12,582 train 050 1.655480e-02 -1.156976
2019-11-08 12:50:22,383 train 100 1.654022e-02 -0.944448
2019-11-08 12:50:32,220 train 150 1.653604e-02 -0.887001
2019-11-08 12:50:42,047 train 200 1.666195e-02 -0.856583
2019-11-08 12:50:51,864 train 250 1.663791e-02 -0.828014
2019-11-08 12:51:01,698 train 300 1.661973e-02 -0.814708
2019-11-08 12:51:11,518 train 350 1.659436e-02 -0.793480
2019-11-08 12:51:21,327 train 400 1.657663e-02 -0.862635
2019-11-08 12:51:31,163 train 450 1.658835e-02 -0.828304
2019-11-08 12:51:40,935 train 500 1.659327e-02 -0.821841
2019-11-08 12:51:50,705 train 550 1.660668e-02 -0.820472
2019-11-08 12:52:00,449 train 600 1.661138e-02 -0.807946
2019-11-08 12:52:10,209 train 650 1.662819e-02 -0.800410
2019-11-08 12:52:19,955 train 700 1.662707e-02 -0.776226
2019-11-08 12:52:29,714 train 750 1.663848e-02 -0.769197
2019-11-08 12:52:39,452 train 800 1.664278e-02 -0.823185
2019-11-08 12:52:49,211 train 850 1.664440e-02 -0.804415
2019-11-08 12:52:52,121 training loss; R2: 1.664862e-02 -0.806618
2019-11-08 12:52:52,751 valid 000 1.511854e-02 -0.114416
2019-11-08 12:53:02,194 valid 050 1.514058e-02 -1.120876
2019-11-08 12:53:10,576 validation loss; R2: 1.519304e-02 -2.180395
2019-11-08 12:53:10,635 epoch 972 lr 1.000000e-05
2019-11-08 12:53:11,410 train 000 1.818916e-02 -0.176999
2019-11-08 12:53:21,124 train 050 1.694839e-02 -1.076076
2019-11-08 12:53:30,864 train 100 1.668899e-02 -0.903495
2019-11-08 12:53:40,594 train 150 1.651899e-02 -0.985805
2019-11-08 12:53:50,336 train 200 1.648145e-02 -0.871790
2019-11-08 12:54:00,073 train 250 1.644265e-02 -0.804302
2019-11-08 12:54:09,810 train 300 1.647002e-02 -0.824086
2019-11-08 12:54:19,541 train 350 1.641603e-02 -0.808062
2019-11-08 12:54:29,306 train 400 1.642886e-02 -0.766937
2019-11-08 12:54:39,085 train 450 1.642772e-02 -0.764438
2019-11-08 12:54:48,854 train 500 1.641010e-02 -0.757290
2019-11-08 12:54:58,619 train 550 1.646857e-02 -0.917424
2019-11-08 12:55:08,391 train 600 1.646643e-02 -0.901253
2019-11-08 12:55:18,148 train 650 1.646722e-02 -0.998369
2019-11-08 12:55:27,921 train 700 1.648502e-02 -0.998266
2019-11-08 12:55:37,694 train 750 1.648476e-02 -0.988317
2019-11-08 12:55:47,454 train 800 1.650876e-02 -1.026527
2019-11-08 12:55:57,217 train 850 1.652489e-02 -1.007465
2019-11-08 12:56:00,133 training loss; R2: 1.652791e-02 -0.996863
2019-11-08 12:56:00,802 valid 000 1.569212e-02 -0.119484
2019-11-08 12:56:10,238 valid 050 1.537418e-02 -1.102381
2019-11-08 12:56:18,560 validation loss; R2: 1.540973e-02 -1.042046
2019-11-08 12:56:18,626 epoch 973 lr 1.000000e-05
2019-11-08 12:56:19,365 train 000 1.966915e-02 -1.494210
2019-11-08 12:56:29,071 train 050 1.635723e-02 -343.831997
2019-11-08 12:56:38,781 train 100 1.641281e-02 -174.020033
2019-11-08 12:56:48,495 train 150 1.645502e-02 -116.684846
2019-11-08 12:56:58,221 train 200 1.647403e-02 -87.822971
2019-11-08 12:57:07,954 train 250 1.652500e-02 -70.451956
2019-11-08 12:57:17,672 train 300 1.645081e-02 -58.864773
2019-11-08 12:57:27,405 train 350 1.642647e-02 -50.578942
2019-11-08 12:57:37,169 train 400 1.645277e-02 -44.351339
2019-11-08 12:57:46,965 train 450 1.649918e-02 -39.508393
2019-11-08 12:57:56,786 train 500 1.650392e-02 -35.614479
2019-11-08 12:58:06,610 train 550 1.646715e-02 -32.460698
2019-11-08 12:58:16,431 train 600 1.650147e-02 -29.811359
2019-11-08 12:58:26,232 train 650 1.647776e-02 -27.578307
2019-11-08 12:58:36,053 train 700 1.648724e-02 -25.656493
2019-11-08 12:58:45,884 train 750 1.650709e-02 -24.010570
2019-11-08 12:58:55,701 train 800 1.648778e-02 -22.573412
2019-11-08 12:59:05,515 train 850 1.650269e-02 -21.281555
2019-11-08 12:59:08,441 training loss; R2: 1.650361e-02 -20.921094
2019-11-08 12:59:09,134 valid 000 1.495639e-02 -4.909540
2019-11-08 12:59:18,556 valid 050 1.634464e-02 -1.774717
2019-11-08 12:59:26,885 validation loss; R2: 1.650037e-02 -1.965752
2019-11-08 12:59:26,951 epoch 974 lr 1.000000e-05
2019-11-08 12:59:27,687 train 000 1.681341e-02 -1.134834
2019-11-08 12:59:37,448 train 050 1.653732e-02 -0.625083
2019-11-08 12:59:47,200 train 100 1.670360e-02 -0.746143
2019-11-08 12:59:56,992 train 150 1.656197e-02 -0.926194
2019-11-08 13:00:06,772 train 200 1.663320e-02 -0.872841
2019-11-08 13:00:16,544 train 250 1.660956e-02 -0.813632
2019-11-08 13:00:26,321 train 300 1.658766e-02 -0.841499
2019-11-08 13:00:36,108 train 350 1.656380e-02 -0.871072
2019-11-08 13:00:45,908 train 400 1.655273e-02 -0.849129
2019-11-08 13:00:55,720 train 450 1.656967e-02 -0.821329
2019-11-08 13:01:05,544 train 500 1.659801e-02 -0.811697
2019-11-08 13:01:15,367 train 550 1.657519e-02 -0.797085
2019-11-08 13:01:25,195 train 600 1.660313e-02 -0.776678
2019-11-08 13:01:35,013 train 650 1.661048e-02 -0.772729
2019-11-08 13:01:44,823 train 700 1.658177e-02 -0.765157
2019-11-08 13:01:54,648 train 750 1.655407e-02 -0.765102
2019-11-08 13:02:04,457 train 800 1.653254e-02 -0.775840
2019-11-08 13:02:14,272 train 850 1.654587e-02 -0.775153
2019-11-08 13:02:17,205 training loss; R2: 1.654661e-02 -0.775388
2019-11-08 13:02:17,795 valid 000 1.645545e-02 -0.333070
2019-11-08 13:02:27,211 valid 050 1.537416e-02 -1.870564
2019-11-08 13:02:35,645 validation loss; R2: 1.527245e-02 -1.720390
2019-11-08 13:02:35,710 epoch 975 lr 1.000000e-05
2019-11-08 13:02:36,466 train 000 1.432853e-02 -0.757342
2019-11-08 13:02:46,232 train 050 1.626720e-02 -1.185913
2019-11-08 13:02:56,010 train 100 1.645558e-02 -1.093408
2019-11-08 13:03:05,817 train 150 1.649941e-02 -1.077006
2019-11-08 13:03:15,630 train 200 1.658513e-02 -0.971831
2019-11-08 13:03:25,429 train 250 1.661512e-02 -0.937224
2019-11-08 13:03:35,230 train 300 1.662749e-02 -0.875844
2019-11-08 13:03:45,040 train 350 1.664713e-02 -0.874020
2019-11-08 13:03:54,846 train 400 1.669955e-02 -0.924341
2019-11-08 13:04:04,677 train 450 1.666639e-02 -0.910172
2019-11-08 13:04:14,516 train 500 1.668459e-02 -0.883043
2019-11-08 13:04:24,321 train 550 1.666522e-02 -0.885099
2019-11-08 13:04:34,156 train 600 1.665380e-02 -0.872552
2019-11-08 13:04:43,984 train 650 1.664790e-02 -0.869534
2019-11-08 13:04:53,806 train 700 1.662190e-02 -0.844893
2019-11-08 13:05:03,629 train 750 1.659823e-02 -0.820164
2019-11-08 13:05:13,445 train 800 1.660243e-02 -0.797121
2019-11-08 13:05:23,266 train 850 1.659081e-02 -0.779406
2019-11-08 13:05:26,203 training loss; R2: 1.658610e-02 -0.790570
2019-11-08 13:05:26,848 valid 000 1.782339e-02 -0.431502
2019-11-08 13:05:36,288 valid 050 1.549456e-02 -1.004290
2019-11-08 13:05:44,620 validation loss; R2: 1.571314e-02 -1.110561
2019-11-08 13:05:44,686 epoch 976 lr 1.000000e-05
2019-11-08 13:05:45,464 train 000 1.753664e-02 -0.811457
2019-11-08 13:05:55,241 train 050 1.684505e-02 -0.871398
2019-11-08 13:06:05,030 train 100 1.677284e-02 -0.634977
2019-11-08 13:06:14,828 train 150 1.675286e-02 -0.606076
2019-11-08 13:06:24,614 train 200 1.663672e-02 -0.751811
2019-11-08 13:06:34,434 train 250 1.661593e-02 -0.806854
2019-11-08 13:06:44,232 train 300 1.656788e-02 -0.847722
2019-11-08 13:06:54,049 train 350 1.656481e-02 -0.809141
2019-11-08 13:07:03,886 train 400 1.657770e-02 -0.792320
2019-11-08 13:07:13,707 train 450 1.659669e-02 -0.760358
2019-11-08 13:07:23,504 train 500 1.656778e-02 -0.798205
2019-11-08 13:07:33,302 train 550 1.657832e-02 -0.779212
2019-11-08 13:07:43,093 train 600 1.658455e-02 -0.782971
2019-11-08 13:07:52,897 train 650 1.656007e-02 -0.796613
2019-11-08 13:08:02,688 train 700 1.653263e-02 -0.766409
2019-11-08 13:08:12,487 train 750 1.656335e-02 -0.746803
2019-11-08 13:08:22,297 train 800 1.657486e-02 -0.745420
2019-11-08 13:08:32,102 train 850 1.658831e-02 -0.732803
2019-11-08 13:08:35,029 training loss; R2: 1.658963e-02 -0.732363
2019-11-08 13:08:35,709 valid 000 1.455408e-02 -0.279293
2019-11-08 13:08:45,071 valid 050 1.380584e-02 -0.918817
2019-11-08 13:08:53,380 validation loss; R2: 1.385818e-02 -1.024202
2019-11-08 13:08:53,448 epoch 977 lr 1.000000e-05
2019-11-08 13:08:54,188 train 000 1.540799e-02 -0.596213
2019-11-08 13:09:03,924 train 050 1.636382e-02 -0.766159
2019-11-08 13:09:13,661 train 100 1.635907e-02 -0.723556
2019-11-08 13:09:23,423 train 150 1.637529e-02 -0.663822
2019-11-08 13:09:33,189 train 200 1.643920e-02 -0.728056
2019-11-08 13:09:42,948 train 250 1.646294e-02 -0.760728
2019-11-08 13:09:52,720 train 300 1.644219e-02 -1.381176
2019-11-08 13:10:02,499 train 350 1.648672e-02 -1.308142
2019-11-08 13:10:12,284 train 400 1.650401e-02 -1.246591
2019-11-08 13:10:22,087 train 450 1.650195e-02 -1.192162
2019-11-08 13:10:31,890 train 500 1.650128e-02 -1.130928
2019-11-08 13:10:41,679 train 550 1.651061e-02 -1.109096
2019-11-08 13:10:51,468 train 600 1.650395e-02 -1.076738
2019-11-08 13:11:01,244 train 650 1.649261e-02 -1.055978
2019-11-08 13:11:11,032 train 700 1.651613e-02 -1.021801
2019-11-08 13:11:20,824 train 750 1.653283e-02 -1.002508
2019-11-08 13:11:30,609 train 800 1.652328e-02 -0.990107
2019-11-08 13:11:40,382 train 850 1.651101e-02 -1.054287
2019-11-08 13:11:43,301 training loss; R2: 1.650966e-02 -1.057105
2019-11-08 13:11:43,985 valid 000 2.785217e-02 -11.042990
2019-11-08 13:11:53,371 valid 050 2.216569e-02 -2.545434
2019-11-08 13:12:01,847 validation loss; R2: 2.206043e-02 -2.338432
2019-11-08 13:12:01,914 epoch 978 lr 1.000000e-05
2019-11-08 13:12:02,673 train 000 2.301891e-02 -0.063224
2019-11-08 13:12:12,416 train 050 1.662049e-02 -0.659802
2019-11-08 13:12:22,149 train 100 1.667395e-02 -0.705972
2019-11-08 13:12:31,985 train 150 1.649192e-02 -0.726062
2019-11-08 13:12:42,112 train 200 1.651140e-02 -0.919510
2019-11-08 13:12:52,232 train 250 1.654108e-02 -0.861173
2019-11-08 13:13:02,378 train 300 1.653610e-02 -0.940264
2019-11-08 13:13:12,522 train 350 1.656694e-02 -0.899824
2019-11-08 13:13:22,666 train 400 1.650785e-02 -0.859211
2019-11-08 13:13:32,784 train 450 1.646064e-02 -0.841979
2019-11-08 13:13:42,932 train 500 1.647289e-02 -0.811994
2019-11-08 13:13:53,071 train 550 1.651555e-02 -0.773275
2019-11-08 13:14:03,215 train 600 1.651038e-02 -0.783753
2019-11-08 13:14:13,365 train 650 1.651241e-02 -0.779026
2019-11-08 13:14:23,522 train 700 1.654741e-02 -0.864978
2019-11-08 13:14:33,696 train 750 1.652783e-02 -0.872792
2019-11-08 13:14:43,617 train 800 1.652946e-02 -0.869453
2019-11-08 13:14:53,405 train 850 1.653951e-02 -0.864644
2019-11-08 13:14:56,324 training loss; R2: 1.655624e-02 -0.854216
2019-11-08 13:14:56,998 valid 000 2.356405e-02 -2.782035
2019-11-08 13:15:06,396 valid 050 2.093316e-02 -2.185466
2019-11-08 13:15:14,725 validation loss; R2: 2.094230e-02 -2.515566
2019-11-08 13:15:14,791 epoch 979 lr 1.000000e-05
2019-11-08 13:15:15,523 train 000 1.499471e-02 -1.686217
2019-11-08 13:15:25,234 train 050 1.701505e-02 -0.824006
2019-11-08 13:15:34,964 train 100 1.680094e-02 -0.742389
2019-11-08 13:15:44,724 train 150 1.664394e-02 -0.707334
2019-11-08 13:15:54,478 train 200 1.657940e-02 -0.691710
2019-11-08 13:16:04,247 train 250 1.655348e-02 -0.693727
2019-11-08 13:16:14,005 train 300 1.650753e-02 -0.758973
2019-11-08 13:16:23,770 train 350 1.650183e-02 -0.769831
2019-11-08 13:16:33,562 train 400 1.651195e-02 -0.761853
2019-11-08 13:16:43,362 train 450 1.652787e-02 -0.745569
2019-11-08 13:16:53,145 train 500 1.653462e-02 -0.758307
2019-11-08 13:17:02,940 train 550 1.650933e-02 -0.770327
2019-11-08 13:17:12,738 train 600 1.650974e-02 -0.783780
2019-11-08 13:17:22,517 train 650 1.651705e-02 -0.805279
2019-11-08 13:17:32,298 train 700 1.652726e-02 -0.789742
2019-11-08 13:17:42,075 train 750 1.650475e-02 -0.800636
2019-11-08 13:17:51,855 train 800 1.652421e-02 -0.795765
2019-11-08 13:18:01,647 train 850 1.654108e-02 -0.785456
2019-11-08 13:18:04,585 training loss; R2: 1.655089e-02 -0.779653
2019-11-08 13:18:05,288 valid 000 1.784187e-02 -3.312988
2019-11-08 13:18:14,652 valid 050 1.499335e-02 -0.897254
2019-11-08 13:18:23,036 validation loss; R2: 1.488646e-02 -0.809000
2019-11-08 13:18:23,097 epoch 980 lr 1.000000e-05
2019-11-08 13:18:23,833 train 000 1.504152e-02 0.026131
2019-11-08 13:18:33,575 train 050 1.661211e-02 -0.814857
2019-11-08 13:18:43,331 train 100 1.659005e-02 -0.811776
2019-11-08 13:18:53,079 train 150 1.664905e-02 -0.753117
2019-11-08 13:19:02,829 train 200 1.653176e-02 -0.772661
2019-11-08 13:19:12,604 train 250 1.646190e-02 -0.743549
2019-11-08 13:19:22,395 train 300 1.645899e-02 -0.758750
2019-11-08 13:19:32,174 train 350 1.646482e-02 -0.750851
2019-11-08 13:19:41,973 train 400 1.648479e-02 -0.750258
2019-11-08 13:19:51,764 train 450 1.643455e-02 -0.744834
2019-11-08 13:20:01,556 train 500 1.645855e-02 -0.762081
2019-11-08 13:20:11,331 train 550 1.646190e-02 -0.732841
2019-11-08 13:20:21,124 train 600 1.647103e-02 -1.204553
2019-11-08 13:20:30,926 train 650 1.649750e-02 -1.176527
2019-11-08 13:20:40,729 train 700 1.650894e-02 -1.155824
2019-11-08 13:20:50,513 train 750 1.649969e-02 -1.134135
2019-11-08 13:21:00,322 train 800 1.648884e-02 -1.116112
2019-11-08 13:21:10,112 train 850 1.648263e-02 -1.106262
2019-11-08 13:21:13,033 training loss; R2: 1.647573e-02 -1.110579
2019-11-08 13:21:13,700 valid 000 1.754924e-02 -0.113471
2019-11-08 13:21:23,154 valid 050 1.975648e-02 -2.441179
2019-11-08 13:21:31,525 validation loss; R2: 1.992182e-02 -2.313370
2019-11-08 13:21:31,590 epoch 981 lr 1.000000e-05
2019-11-08 13:21:32,399 train 000 1.553209e-02 -1.345095
2019-11-08 13:21:42,143 train 050 1.636479e-02 -0.814813
2019-11-08 13:21:51,903 train 100 1.641362e-02 -0.651040
2019-11-08 13:22:01,670 train 150 1.653157e-02 -0.643122
2019-11-08 13:22:11,459 train 200 1.656033e-02 -0.653497
2019-11-08 13:22:21,241 train 250 1.649253e-02 -0.684383
2019-11-08 13:22:31,029 train 300 1.660871e-02 -0.668625
2019-11-08 13:22:40,813 train 350 1.662778e-02 -0.679365
2019-11-08 13:22:50,620 train 400 1.658298e-02 -0.704015
2019-11-08 13:23:00,416 train 450 1.660133e-02 -0.807967
2019-11-08 13:23:10,212 train 500 1.656976e-02 -0.818448
2019-11-08 13:23:19,999 train 550 1.657628e-02 -0.780580
2019-11-08 13:23:29,801 train 600 1.656897e-02 -0.774562
2019-11-08 13:23:39,626 train 650 1.652444e-02 -0.752224
2019-11-08 13:23:49,429 train 700 1.651287e-02 -0.753623
2019-11-08 13:23:59,212 train 750 1.650713e-02 -0.755198
2019-11-08 13:24:09,023 train 800 1.654468e-02 -0.793485
2019-11-08 13:24:18,826 train 850 1.654188e-02 -0.784630
2019-11-08 13:24:21,758 training loss; R2: 1.655048e-02 -0.794385
2019-11-08 13:24:22,442 valid 000 1.442033e-02 -0.138897
2019-11-08 13:24:31,876 valid 050 1.598253e-02 -1.292673
2019-11-08 13:24:40,186 validation loss; R2: 1.629296e-02 -1.358024
2019-11-08 13:24:40,248 epoch 982 lr 1.000000e-05
2019-11-08 13:24:41,038 train 000 1.575494e-02 0.073255
2019-11-08 13:24:50,777 train 050 1.653704e-02 -1.372695
2019-11-08 13:25:00,519 train 100 1.655521e-02 -1.019167
2019-11-08 13:25:10,272 train 150 1.658665e-02 -0.898641
2019-11-08 13:25:20,033 train 200 1.650867e-02 -0.801577
2019-11-08 13:25:29,795 train 250 1.652637e-02 -0.790556
2019-11-08 13:25:39,567 train 300 1.653445e-02 -0.779129
2019-11-08 13:25:49,346 train 350 1.653617e-02 -0.753415
2019-11-08 13:25:59,126 train 400 1.650084e-02 -0.757672
2019-11-08 13:26:08,930 train 450 1.654480e-02 -0.775701
2019-11-08 13:26:18,717 train 500 1.657315e-02 -0.776078
2019-11-08 13:26:28,504 train 550 1.657466e-02 -0.780733
2019-11-08 13:26:38,293 train 600 1.659191e-02 -0.779739
2019-11-08 13:26:48,087 train 650 1.658216e-02 -0.767519
2019-11-08 13:26:57,873 train 700 1.656689e-02 -0.799295
2019-11-08 13:27:07,664 train 750 1.654854e-02 -0.780431
2019-11-08 13:27:17,450 train 800 1.655490e-02 -0.784625
2019-11-08 13:27:27,241 train 850 1.655945e-02 -0.792674
2019-11-08 13:27:30,166 training loss; R2: 1.655296e-02 -0.787114
2019-11-08 13:27:30,783 valid 000 1.327026e-02 -0.562723
2019-11-08 13:27:40,256 valid 050 1.475039e-02 -0.906094
2019-11-08 13:27:48,577 validation loss; R2: 1.497095e-02 -0.962551
2019-11-08 13:27:48,645 epoch 983 lr 1.000000e-05
2019-11-08 13:27:49,397 train 000 1.780993e-02 -0.388354
2019-11-08 13:27:59,135 train 050 1.664424e-02 -0.624727
2019-11-08 13:28:08,880 train 100 1.656527e-02 -0.652279
2019-11-08 13:28:18,627 train 150 1.653517e-02 -0.598843
2019-11-08 13:28:28,385 train 200 1.655590e-02 -0.733797
2019-11-08 13:28:38,156 train 250 1.656351e-02 -0.890541
2019-11-08 13:28:47,933 train 300 1.658288e-02 -0.853354
2019-11-08 13:28:57,719 train 350 1.659612e-02 -0.833647
2019-11-08 13:29:07,506 train 400 1.663137e-02 -0.810652
2019-11-08 13:29:17,293 train 450 1.665648e-02 -0.804409
2019-11-08 13:29:27,074 train 500 1.664976e-02 -0.810857
2019-11-08 13:29:36,855 train 550 1.658830e-02 -1.031075
2019-11-08 13:29:46,655 train 600 1.659570e-02 -2.938458
2019-11-08 13:29:56,430 train 650 1.659062e-02 -2.763800
2019-11-08 13:30:06,220 train 700 1.659925e-02 -2.594431
2019-11-08 13:30:16,014 train 750 1.659738e-02 -2.480750
2019-11-08 13:30:25,807 train 800 1.661264e-02 -2.367743
2019-11-08 13:30:35,615 train 850 1.660042e-02 -2.262748
2019-11-08 13:30:38,545 training loss; R2: 1.659739e-02 -2.230888
2019-11-08 13:30:39,208 valid 000 1.352190e-02 -1.837830
2019-11-08 13:30:48,562 valid 050 1.521288e-02 -0.974604
2019-11-08 13:30:56,940 validation loss; R2: 1.508953e-02 -0.994929
2019-11-08 13:30:57,006 epoch 984 lr 1.000000e-05
2019-11-08 13:30:57,756 train 000 1.551321e-02 0.080357
2019-11-08 13:31:07,481 train 050 1.622913e-02 -0.512945
2019-11-08 13:31:17,213 train 100 1.657602e-02 -0.643666
2019-11-08 13:31:26,972 train 150 1.655597e-02 -0.611166
2019-11-08 13:31:36,728 train 200 1.654602e-02 -0.734780
2019-11-08 13:31:46,495 train 250 1.655945e-02 -0.715953
2019-11-08 13:31:56,265 train 300 1.657878e-02 -0.758263
2019-11-08 13:32:06,066 train 350 1.652081e-02 -0.752227
2019-11-08 13:32:15,849 train 400 1.654870e-02 -0.735513
2019-11-08 13:32:25,633 train 450 1.656307e-02 -0.733735
2019-11-08 13:32:35,418 train 500 1.659776e-02 -0.720136
2019-11-08 13:32:45,205 train 550 1.657549e-02 -0.695921
2019-11-08 13:32:54,997 train 600 1.656155e-02 -0.714722
2019-11-08 13:33:04,800 train 650 1.657176e-02 -0.705512
2019-11-08 13:33:14,595 train 700 1.657210e-02 -0.717648
2019-11-08 13:33:24,386 train 750 1.655848e-02 -0.716337
2019-11-08 13:33:34,176 train 800 1.657538e-02 -0.721288
2019-11-08 13:33:43,952 train 850 1.654121e-02 -0.741986
2019-11-08 13:33:46,884 training loss; R2: 1.653664e-02 -0.764332
2019-11-08 13:33:47,469 valid 000 1.755296e-02 -3.522366
2019-11-08 13:33:56,879 valid 050 1.634529e-02 -1.840717
2019-11-08 13:34:05,242 validation loss; R2: 1.623229e-02 -1.739962
2019-11-08 13:34:05,310 epoch 985 lr 1.000000e-05
2019-11-08 13:34:06,087 train 000 1.720067e-02 -0.167056
2019-11-08 13:34:15,865 train 050 1.652659e-02 -0.536571
2019-11-08 13:34:25,662 train 100 1.662737e-02 -0.722016
2019-11-08 13:34:35,464 train 150 1.657900e-02 -0.627464
2019-11-08 13:34:45,269 train 200 1.650563e-02 -0.667725
2019-11-08 13:34:55,071 train 250 1.645566e-02 -0.677632
2019-11-08 13:35:04,904 train 300 1.646741e-02 -0.659219
2019-11-08 13:35:14,719 train 350 1.650068e-02 -0.654599
2019-11-08 13:35:24,549 train 400 1.650242e-02 -0.649383
2019-11-08 13:35:34,375 train 450 1.652601e-02 -0.672108
2019-11-08 13:35:44,193 train 500 1.651986e-02 -0.719525
2019-11-08 13:35:54,025 train 550 1.651552e-02 -0.740996
2019-11-08 13:36:03,854 train 600 1.653267e-02 -0.753180
2019-11-08 13:36:13,690 train 650 1.654599e-02 -0.770953
2019-11-08 13:36:23,513 train 700 1.657009e-02 -0.772256
2019-11-08 13:36:33,355 train 750 1.656901e-02 -0.762593
2019-11-08 13:36:43,183 train 800 1.657390e-02 -1.099491
2019-11-08 13:36:52,995 train 850 1.656452e-02 -1.115628
2019-11-08 13:36:55,933 training loss; R2: 1.656740e-02 -1.104212
2019-11-08 13:36:56,602 valid 000 1.950413e-02 -13.851298
2019-11-08 13:37:05,963 valid 050 1.991662e-02 -1.934218
2019-11-08 13:37:14,305 validation loss; R2: 2.019327e-02 -2.061911
2019-11-08 13:37:14,371 epoch 986 lr 1.000000e-05
2019-11-08 13:37:15,156 train 000 1.603491e-02 -0.099180
2019-11-08 13:37:24,898 train 050 1.684214e-02 -0.756316
2019-11-08 13:37:34,652 train 100 1.662275e-02 -0.740842
2019-11-08 13:37:44,443 train 150 1.663701e-02 -0.737025
2019-11-08 13:37:54,218 train 200 1.663005e-02 -0.713918
2019-11-08 13:38:03,996 train 250 1.666499e-02 -0.675392
2019-11-08 13:38:13,790 train 300 1.666768e-02 -0.709750
2019-11-08 13:38:23,580 train 350 1.662033e-02 -0.696814
2019-11-08 13:38:33,363 train 400 1.667727e-02 -0.700313
2019-11-08 13:38:43,137 train 450 1.664915e-02 -0.681362
2019-11-08 13:38:52,928 train 500 1.665155e-02 -0.708780
2019-11-08 13:39:02,716 train 550 1.664859e-02 -0.711059
2019-11-08 13:39:12,507 train 600 1.661994e-02 -0.731371
2019-11-08 13:39:22,310 train 650 1.660608e-02 -0.726599
2019-11-08 13:39:32,116 train 700 1.660701e-02 -0.725159
2019-11-08 13:39:41,891 train 750 1.660075e-02 -0.708494
2019-11-08 13:39:51,674 train 800 1.662204e-02 -0.706914
2019-11-08 13:40:01,446 train 850 1.660766e-02 -0.731084
2019-11-08 13:40:04,376 training loss; R2: 1.659719e-02 -0.729324
2019-11-08 13:40:05,088 valid 000 1.252811e-02 -0.302540
2019-11-08 13:40:14,431 valid 050 1.406423e-02 -1.171760
2019-11-08 13:40:22,787 validation loss; R2: 1.437381e-02 -1.327472
2019-11-08 13:40:22,852 epoch 987 lr 1.000000e-05
2019-11-08 13:40:23,611 train 000 1.492452e-02 -0.830916
2019-11-08 13:40:33,328 train 050 1.578807e-02 -1.046386
2019-11-08 13:40:43,048 train 100 1.608370e-02 -0.902922
2019-11-08 13:40:52,800 train 150 1.610678e-02 -2.224330
2019-11-08 13:41:02,571 train 200 1.626555e-02 -1.853371
2019-11-08 13:41:12,347 train 250 1.633917e-02 -1.598824
2019-11-08 13:41:22,120 train 300 1.635296e-02 -1.496508
2019-11-08 13:41:31,886 train 350 1.643428e-02 -1.357787
2019-11-08 13:41:41,650 train 400 1.647266e-02 -1.326691
2019-11-08 13:41:51,425 train 450 1.651034e-02 -1.251099
2019-11-08 13:42:01,196 train 500 1.655252e-02 -1.212001
2019-11-08 13:42:10,965 train 550 1.655437e-02 -1.155700
2019-11-08 13:42:20,745 train 600 1.652184e-02 -1.122142
2019-11-08 13:42:30,511 train 650 1.653034e-02 -1.081856
2019-11-08 13:42:40,280 train 700 1.654466e-02 -1.061105
2019-11-08 13:42:50,056 train 750 1.656329e-02 -1.045491
2019-11-08 13:42:59,826 train 800 1.655444e-02 -1.019614
2019-11-08 13:43:09,595 train 850 1.652928e-02 -0.993744
2019-11-08 13:43:12,511 training loss; R2: 1.653483e-02 -0.991110
2019-11-08 13:43:13,132 valid 000 1.511083e-02 -2.575747
2019-11-08 13:43:22,584 valid 050 1.565427e-02 -1.062800
2019-11-08 13:43:30,926 validation loss; R2: 1.574473e-02 -1.427999
2019-11-08 13:43:30,993 epoch 988 lr 1.000000e-05
2019-11-08 13:43:31,735 train 000 1.900672e-02 -0.836208
2019-11-08 13:43:41,461 train 050 1.677068e-02 -0.782591
2019-11-08 13:43:51,215 train 100 1.674340e-02 -0.747488
2019-11-08 13:44:00,938 train 150 1.673074e-02 -0.740861
2019-11-08 13:44:10,662 train 200 1.677263e-02 -0.704162
2019-11-08 13:44:20,384 train 250 1.667712e-02 -0.717578
2019-11-08 13:44:30,111 train 300 1.658792e-02 -0.728292
2019-11-08 13:44:39,852 train 350 1.661627e-02 -0.704149
2019-11-08 13:44:49,592 train 400 1.664895e-02 -0.718138
2019-11-08 13:44:59,350 train 450 1.661623e-02 -0.695492
2019-11-08 13:45:09,121 train 500 1.657972e-02 -0.730739
2019-11-08 13:45:18,900 train 550 1.656423e-02 -0.754903
2019-11-08 13:45:28,683 train 600 1.658830e-02 -0.767676
2019-11-08 13:45:38,461 train 650 1.656627e-02 -0.768496
2019-11-08 13:45:48,235 train 700 1.657226e-02 -0.769743
2019-11-08 13:45:58,013 train 750 1.657601e-02 -2.278375
2019-11-08 13:46:07,791 train 800 1.659447e-02 -2.193629
2019-11-08 13:46:17,559 train 850 1.659522e-02 -2.114432
2019-11-08 13:46:20,476 training loss; R2: 1.660341e-02 -2.086796
2019-11-08 13:46:21,145 valid 000 1.122685e-02 0.116403
2019-11-08 13:46:30,537 valid 050 1.475823e-02 -0.776953
2019-11-08 13:46:38,855 validation loss; R2: 1.466842e-02 -0.958206
2019-11-08 13:46:38,921 epoch 989 lr 1.000000e-05
2019-11-08 13:46:39,696 train 000 1.450682e-02 -0.854253
2019-11-08 13:46:49,431 train 050 1.640203e-02 -0.543113
2019-11-08 13:46:59,178 train 100 1.649221e-02 -0.586599
2019-11-08 13:47:08,933 train 150 1.656660e-02 -0.665902
2019-11-08 13:47:18,708 train 200 1.659264e-02 -0.621318
2019-11-08 13:47:28,472 train 250 1.667533e-02 -0.812191
2019-11-08 13:47:38,246 train 300 1.664104e-02 -0.772942
2019-11-08 13:47:48,013 train 350 1.655477e-02 -0.767243
2019-11-08 13:47:57,777 train 400 1.652730e-02 -0.774436
2019-11-08 13:48:07,552 train 450 1.655128e-02 -0.767439
2019-11-08 13:48:17,320 train 500 1.657387e-02 -0.817966
2019-11-08 13:48:27,078 train 550 1.655734e-02 -0.808170
2019-11-08 13:48:36,845 train 600 1.654541e-02 -0.783440
2019-11-08 13:48:46,611 train 650 1.655829e-02 -0.782651
2019-11-08 13:48:56,355 train 700 1.657217e-02 -0.787367
2019-11-08 13:49:06,125 train 750 1.657928e-02 -0.772907
2019-11-08 13:49:15,864 train 800 1.657036e-02 -0.776416
2019-11-08 13:49:25,612 train 850 1.655886e-02 -0.763685
2019-11-08 13:49:28,569 training loss; R2: 1.656786e-02 -0.760283
2019-11-08 13:49:29,202 valid 000 1.924803e-02 -1.781544
2019-11-08 13:49:38,639 valid 050 1.942112e-02 -1.892031
2019-11-08 13:49:46,954 validation loss; R2: 1.965753e-02 -1.976582
2019-11-08 13:49:47,035 epoch 990 lr 1.000000e-05
2019-11-08 13:49:47,840 train 000 1.458327e-02 -0.008239
2019-11-08 13:49:57,965 train 050 1.614450e-02 -0.465745
2019-11-08 13:50:08,120 train 100 1.638086e-02 -0.623486
2019-11-08 13:50:18,272 train 150 1.636547e-02 -1.020633
2019-11-08 13:50:28,421 train 200 1.639782e-02 -1.948323
2019-11-08 13:50:38,574 train 250 1.648213e-02 -1.709253
2019-11-08 13:50:48,734 train 300 1.652316e-02 -1.561482
2019-11-08 13:50:58,904 train 350 1.654130e-02 -1.447609
2019-11-08 13:51:09,055 train 400 1.654854e-02 -1.376871
2019-11-08 13:51:19,226 train 450 1.661069e-02 -1.312842
2019-11-08 13:51:29,391 train 500 1.664273e-02 -1.246527
2019-11-08 13:51:39,551 train 550 1.660082e-02 -1.234045
2019-11-08 13:51:49,695 train 600 1.659919e-02 -1.181420
2019-11-08 13:51:59,827 train 650 1.660390e-02 -1.136241
2019-11-08 13:52:09,966 train 700 1.656501e-02 -1.243936
2019-11-08 13:52:20,123 train 750 1.654964e-02 -1.215908
2019-11-08 13:52:29,944 train 800 1.656114e-02 -1.179172
2019-11-08 13:52:39,733 train 850 1.653984e-02 -1.159976
2019-11-08 13:52:42,664 training loss; R2: 1.653125e-02 -1.148249
2019-11-08 13:52:43,265 valid 000 1.419659e-02 -0.965473
2019-11-08 13:52:52,688 valid 050 1.544768e-02 -1.147772
2019-11-08 13:53:01,125 validation loss; R2: 1.575559e-02 -1.231994
2019-11-08 13:53:01,192 epoch 991 lr 1.000000e-05
2019-11-08 13:53:01,987 train 000 1.912501e-02 -0.095564
2019-11-08 13:53:11,686 train 050 1.664682e-02 -0.672737
2019-11-08 13:53:21,414 train 100 1.676879e-02 -0.721536
2019-11-08 13:53:31,157 train 150 1.674499e-02 -0.650286
2019-11-08 13:53:40,896 train 200 1.668348e-02 -0.862044
2019-11-08 13:53:50,677 train 250 1.664646e-02 -0.818093
2019-11-08 13:54:00,445 train 300 1.664169e-02 -0.815599
2019-11-08 13:54:10,225 train 350 1.667947e-02 -0.810389
2019-11-08 13:54:20,002 train 400 1.668195e-02 -0.807818
2019-11-08 13:54:29,804 train 450 1.664875e-02 -0.808712
2019-11-08 13:54:39,601 train 500 1.661083e-02 -1.029648
2019-11-08 13:54:49,398 train 550 1.661378e-02 -1.002989
2019-11-08 13:54:59,181 train 600 1.662166e-02 -0.996320
2019-11-08 13:55:08,969 train 650 1.662952e-02 -0.972389
2019-11-08 13:55:18,763 train 700 1.662358e-02 -0.960231
2019-11-08 13:55:28,544 train 750 1.660344e-02 -0.975403
2019-11-08 13:55:38,333 train 800 1.661980e-02 -0.967401
2019-11-08 13:55:48,108 train 850 1.660841e-02 -0.961005
2019-11-08 13:55:51,028 training loss; R2: 1.661620e-02 -0.951912
2019-11-08 13:55:51,724 valid 000 1.580186e-02 -6.915318
2019-11-08 13:56:01,105 valid 050 1.622123e-02 -1.256854
2019-11-08 13:56:09,440 validation loss; R2: 1.636288e-02 -1.586210
2019-11-08 13:56:09,499 epoch 992 lr 1.000000e-05
2019-11-08 13:56:10,231 train 000 1.313737e-02 0.060228
2019-11-08 13:56:19,975 train 050 1.653353e-02 -0.825593
2019-11-08 13:56:29,721 train 100 1.646470e-02 -0.764851
2019-11-08 13:56:39,497 train 150 1.650385e-02 -0.836293
2019-11-08 13:56:49,275 train 200 1.650282e-02 -0.802373
2019-11-08 13:56:59,048 train 250 1.654993e-02 -0.759625
2019-11-08 13:57:08,826 train 300 1.660609e-02 -0.727776
2019-11-08 13:57:18,595 train 350 1.658667e-02 -0.709052
2019-11-08 13:57:28,377 train 400 1.661218e-02 -0.729831
2019-11-08 13:57:38,160 train 450 1.657002e-02 -0.792807
2019-11-08 13:57:47,934 train 500 1.659349e-02 -0.761660
2019-11-08 13:57:57,712 train 550 1.660428e-02 -0.750869
2019-11-08 13:58:07,493 train 600 1.660760e-02 -0.764400
2019-11-08 13:58:17,268 train 650 1.659732e-02 -0.751490
2019-11-08 13:58:27,064 train 700 1.659264e-02 -0.750398
2019-11-08 13:58:36,869 train 750 1.660497e-02 -0.799355
2019-11-08 13:58:46,651 train 800 1.659688e-02 -0.816319
2019-11-08 13:58:56,445 train 850 1.658577e-02 -0.807745
2019-11-08 13:58:59,368 training loss; R2: 1.659455e-02 -0.813489
2019-11-08 13:58:59,984 valid 000 1.776553e-02 -1.088390
2019-11-08 13:59:09,397 valid 050 1.536718e-02 -0.975948
2019-11-08 13:59:17,717 validation loss; R2: 1.522329e-02 -1.100737
2019-11-08 13:59:17,784 epoch 993 lr 1.000000e-05
2019-11-08 13:59:18,522 train 000 1.507442e-02 0.011085
2019-11-08 13:59:28,268 train 050 1.639072e-02 -0.660337
2019-11-08 13:59:38,028 train 100 1.658932e-02 -0.736857
2019-11-08 13:59:47,787 train 150 1.653657e-02 -0.794177
2019-11-08 13:59:57,564 train 200 1.652307e-02 -0.709279
2019-11-08 14:00:07,337 train 250 1.649786e-02 -0.713594
2019-11-08 14:00:17,111 train 300 1.648270e-02 -0.723141
2019-11-08 14:00:26,894 train 350 1.648123e-02 -0.709760
2019-11-08 14:00:36,666 train 400 1.645844e-02 -0.742161
2019-11-08 14:00:46,439 train 450 1.646809e-02 -0.716452
2019-11-08 14:00:56,217 train 500 1.646666e-02 -0.702409
2019-11-08 14:01:05,995 train 550 1.645363e-02 -0.699867
2019-11-08 14:01:15,793 train 600 1.646554e-02 -0.683397
2019-11-08 14:01:25,586 train 650 1.648643e-02 -0.698697
2019-11-08 14:01:35,383 train 700 1.651948e-02 -0.714395
2019-11-08 14:01:45,185 train 750 1.653694e-02 -0.706244
2019-11-08 14:01:54,979 train 800 1.651890e-02 -0.722638
2019-11-08 14:02:04,796 train 850 1.652799e-02 -0.708262
2019-11-08 14:02:07,754 training loss; R2: 1.653706e-02 -0.793339
2019-11-08 14:02:08,403 valid 000 1.380759e-02 -0.096451
2019-11-08 14:02:17,834 valid 050 1.452780e-02 -1.067316
2019-11-08 14:02:26,162 validation loss; R2: 1.469163e-02 -1.162580
2019-11-08 14:02:26,244 epoch 994 lr 1.000000e-05
2019-11-08 14:02:27,024 train 000 1.858640e-02 -0.369260
2019-11-08 14:02:36,812 train 050 1.633616e-02 -0.597755
2019-11-08 14:02:46,575 train 100 1.637594e-02 -0.709559
2019-11-08 14:02:56,347 train 150 1.646601e-02 -0.742333
2019-11-08 14:03:06,487 train 200 1.657673e-02 -0.721664
2019-11-08 14:03:16,642 train 250 1.660294e-02 -0.852388
2019-11-08 14:03:26,773 train 300 1.655208e-02 -0.844864
2019-11-08 14:03:36,908 train 350 1.654041e-02 -1.442296
2019-11-08 14:03:47,045 train 400 1.656343e-02 -1.373215
2019-11-08 14:03:57,199 train 450 1.650635e-02 -1.316543
2019-11-08 14:04:07,359 train 500 1.649996e-02 -1.243006
2019-11-08 14:04:17,501 train 550 1.648215e-02 -1.179294
2019-11-08 14:04:27,645 train 600 1.644517e-02 -1.165015
2019-11-08 14:04:37,813 train 650 1.650780e-02 -1.122071
2019-11-08 14:04:47,994 train 700 1.649806e-02 -1.092658
2019-11-08 14:04:57,797 train 750 1.649941e-02 -1.057654
2019-11-08 14:05:07,600 train 800 1.649988e-02 -1.054221
2019-11-08 14:05:17,393 train 850 1.650433e-02 -1.035635
2019-11-08 14:05:20,319 training loss; R2: 1.651404e-02 -1.028472
2019-11-08 14:05:20,952 valid 000 1.408617e-02 -1.246630
2019-11-08 14:05:30,359 valid 050 1.416157e-02 -0.570268
2019-11-08 14:05:38,670 validation loss; R2: 1.403909e-02 -0.667831
2019-11-08 14:05:38,735 epoch 995 lr 1.000000e-05
2019-11-08 14:05:39,525 train 000 1.623576e-02 -0.779040
2019-11-08 14:05:49,249 train 050 1.648566e-02 -1.285146
2019-11-08 14:05:59,003 train 100 1.628400e-02 -0.948027
2019-11-08 14:06:08,763 train 150 1.634120e-02 -0.940188
2019-11-08 14:06:18,517 train 200 1.646303e-02 -0.886513
2019-11-08 14:06:28,274 train 250 1.643202e-02 -0.856042
2019-11-08 14:06:38,056 train 300 1.644500e-02 -0.848652
2019-11-08 14:06:47,816 train 350 1.643450e-02 -0.816429
2019-11-08 14:06:57,591 train 400 1.650118e-02 -0.833962
2019-11-08 14:07:07,358 train 450 1.650017e-02 -0.814562
2019-11-08 14:07:17,118 train 500 1.646783e-02 -0.776363
2019-11-08 14:07:26,900 train 550 1.648099e-02 -0.817884
2019-11-08 14:07:36,681 train 600 1.649909e-02 -0.794897
2019-11-08 14:07:46,453 train 650 1.649872e-02 -0.793112
2019-11-08 14:07:56,231 train 700 1.652846e-02 -0.796678
2019-11-08 14:08:06,031 train 750 1.655377e-02 -0.791822
2019-11-08 14:08:15,826 train 800 1.655052e-02 -0.782300
2019-11-08 14:08:25,613 train 850 1.654827e-02 -0.789354
2019-11-08 14:08:28,544 training loss; R2: 1.653926e-02 -0.792967
2019-11-08 14:08:29,220 valid 000 1.535651e-02 -1.213657
2019-11-08 14:08:38,588 valid 050 1.559469e-02 -2.242098
2019-11-08 14:08:46,956 validation loss; R2: 1.563929e-02 -1.778471
2019-11-08 14:08:47,023 epoch 996 lr 1.000000e-05
2019-11-08 14:08:47,807 train 000 1.846959e-02 -0.498034
2019-11-08 14:08:57,554 train 050 1.648888e-02 -0.644898
2019-11-08 14:09:07,309 train 100 1.631884e-02 -0.680467
2019-11-08 14:09:17,082 train 150 1.629890e-02 -0.758470
2019-11-08 14:09:26,836 train 200 1.644033e-02 -0.720193
2019-11-08 14:09:36,628 train 250 1.653674e-02 -0.725584
2019-11-08 14:09:46,408 train 300 1.657519e-02 -0.721719
2019-11-08 14:09:56,158 train 350 1.660898e-02 -0.805030
2019-11-08 14:10:05,916 train 400 1.663909e-02 -0.794123
2019-11-08 14:10:15,673 train 450 1.661212e-02 -0.799357
2019-11-08 14:10:25,443 train 500 1.657285e-02 -0.800523
2019-11-08 14:10:35,198 train 550 1.659465e-02 -0.770397
2019-11-08 14:10:44,949 train 600 1.656716e-02 -0.821452
2019-11-08 14:10:54,725 train 650 1.653591e-02 -0.815042
2019-11-08 14:11:04,499 train 700 1.651059e-02 -0.808055
2019-11-08 14:11:14,271 train 750 1.654086e-02 -0.828279
2019-11-08 14:11:24,044 train 800 1.653323e-02 -0.806097
2019-11-08 14:11:33,822 train 850 1.653170e-02 -0.804413
2019-11-08 14:11:36,781 training loss; R2: 1.652741e-02 -0.805487
2019-11-08 14:11:37,377 valid 000 1.460919e-02 -1.802734
2019-11-08 14:11:46,807 valid 050 1.467834e-02 -3.921847
2019-11-08 14:11:55,157 validation loss; R2: 1.468301e-02 -2.443602
2019-11-08 14:11:55,239 epoch 997 lr 1.000000e-05
2019-11-08 14:11:56,076 train 000 1.699574e-02 -0.548345
2019-11-08 14:12:06,105 train 050 1.664794e-02 -0.504736
2019-11-08 14:12:15,906 train 100 1.674058e-02 -0.572523
2019-11-08 14:12:25,695 train 150 1.677931e-02 -0.644527
2019-11-08 14:12:35,479 train 200 1.667831e-02 -0.635140
2019-11-08 14:12:45,245 train 250 1.660135e-02 -0.638972
2019-11-08 14:12:55,031 train 300 1.659100e-02 -0.682032
2019-11-08 14:13:04,818 train 350 1.660771e-02 -0.677037
2019-11-08 14:13:14,618 train 400 1.655737e-02 -0.695467
2019-11-08 14:13:24,396 train 450 1.657600e-02 -0.713680
2019-11-08 14:13:34,176 train 500 1.660467e-02 -0.711106
2019-11-08 14:13:43,966 train 550 1.656938e-02 -0.706603
2019-11-08 14:13:53,759 train 600 1.656038e-02 -0.722311
2019-11-08 14:14:03,535 train 650 1.653203e-02 -0.717034
2019-11-08 14:14:13,314 train 700 1.652750e-02 -0.708792
2019-11-08 14:14:23,096 train 750 1.652697e-02 -0.694830
2019-11-08 14:14:32,852 train 800 1.652460e-02 -1.020681
2019-11-08 14:14:42,620 train 850 1.652304e-02 -0.988969
2019-11-08 14:14:45,539 training loss; R2: 1.651962e-02 -0.983342
2019-11-08 14:14:46,183 valid 000 1.473602e-02 -1.627445
2019-11-08 14:14:55,596 valid 050 1.547511e-02 -0.983162
2019-11-08 14:15:03,906 validation loss; R2: 1.552510e-02 -2.198911
2019-11-08 14:15:03,973 epoch 998 lr 1.000000e-05
2019-11-08 14:15:04,771 train 000 2.106001e-02 -0.506166
2019-11-08 14:15:14,479 train 050 1.656001e-02 -0.967083
2019-11-08 14:15:24,232 train 100 1.684840e-02 -0.799818
2019-11-08 14:15:33,992 train 150 1.675389e-02 -0.842439
2019-11-08 14:15:43,784 train 200 1.657242e-02 -0.772234
2019-11-08 14:15:53,560 train 250 1.652808e-02 -0.725919
2019-11-08 14:16:03,314 train 300 1.654138e-02 -0.727237
2019-11-08 14:16:13,080 train 350 1.652953e-02 -0.727708
2019-11-08 14:16:22,866 train 400 1.654808e-02 -0.729623
2019-11-08 14:16:32,645 train 450 1.655002e-02 -0.707673
2019-11-08 14:16:42,441 train 500 1.655949e-02 -0.718329
2019-11-08 14:16:52,218 train 550 1.656850e-02 -0.722798
2019-11-08 14:17:02,023 train 600 1.654447e-02 -0.734653
2019-11-08 14:17:11,823 train 650 1.654409e-02 -0.717791
2019-11-08 14:17:21,640 train 700 1.655641e-02 -0.975029
2019-11-08 14:17:31,472 train 750 1.655135e-02 -0.976008
2019-11-08 14:17:41,293 train 800 1.656162e-02 -0.964879
2019-11-08 14:17:51,122 train 850 1.654054e-02 -0.947224
2019-11-08 14:17:54,057 training loss; R2: 1.652601e-02 -0.948141
2019-11-08 14:17:54,676 valid 000 1.733848e-02 -0.117471
2019-11-08 14:18:04,090 valid 050 1.526377e-02 -1.174219
2019-11-08 14:18:12,416 validation loss; R2: 1.514740e-02 -1.279187
2019-11-08 14:18:12,479 epoch 999 lr 1.000000e-05
2019-11-08 14:18:13,194 train 000 1.589551e-02 -0.256607
2019-11-08 14:18:22,932 train 050 1.639902e-02 -1.074419
2019-11-08 14:18:32,692 train 100 1.663701e-02 -1.018613
2019-11-08 14:18:42,451 train 150 1.659329e-02 -0.949632
2019-11-08 14:18:52,218 train 200 1.664391e-02 -1.007067
2019-11-08 14:19:01,990 train 250 1.660474e-02 -0.968689
2019-11-08 14:19:11,753 train 300 1.646874e-02 -0.935147
2019-11-08 14:19:21,530 train 350 1.657940e-02 -1.012538
2019-11-08 14:19:31,307 train 400 1.662055e-02 -0.990965
2019-11-08 14:19:41,076 train 450 1.665867e-02 -0.955439
2019-11-08 14:19:50,830 train 500 1.663315e-02 -0.918953
2019-11-08 14:20:00,608 train 550 1.661507e-02 -0.899938
2019-11-08 14:20:10,386 train 600 1.660060e-02 -0.872954
2019-11-08 14:20:20,173 train 650 1.662369e-02 -0.851185
2019-11-08 14:20:29,948 train 700 1.662022e-02 -0.838574
2019-11-08 14:20:39,727 train 750 1.658366e-02 -0.825158
2019-11-08 14:20:49,498 train 800 1.656908e-02 -0.821663
2019-11-08 14:20:59,272 train 850 1.658803e-02 -0.807904
2019-11-08 14:21:02,237 training loss; R2: 1.658344e-02 -0.801555
2019-11-08 14:21:02,876 valid 000 1.446766e-02 -2.861868
2019-11-08 14:21:12,293 valid 050 1.466941e-02 -1.385687
2019-11-08 14:21:20,654 validation loss; R2: 1.462470e-02 -1.686422
