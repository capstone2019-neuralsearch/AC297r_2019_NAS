2019-11-01 15:51:56,943 gpu device = 2
2019-11-01 15:51:56,944 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=20, cutout=False, cutout_length=16, data='../data', dataset='galaxy-zoo', drop_path_prob=0.3, epochs=50, gpu=2, grad_clip=5, gz_regression=False, init_channels=16, layers=8, learning_rate=0.001, learning_rate_min=0.0001, model_path='saved_models', momentum=0.9, report_freq=50, save='search-GALAXY_ZOO-20191101-155156', seed=2, train_portion=0.5, unrolled=True, weight_decay=0.0003)
2019-11-01 15:52:00,441 param size = 1.937557MB
2019-11-01 15:52:00,453 epoch 0 lr 1.000000e-03
2019-11-01 15:52:00,454 genotype = Genotype(normal=[('dil_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('max_pool_3x3', 0), ('dil_conv_3x3', 0), ('avg_pool_3x3', 2), ('sep_conv_5x5', 3), ('dil_conv_3x3', 2)], normal_concat=range(2, 6), reduce=[('avg_pool_3x3', 1), ('max_pool_3x3', 0), ('dil_conv_3x3', 1), ('sep_conv_5x5', 2), ('max_pool_3x3', 1), ('dil_conv_3x3', 0), ('dil_conv_3x3', 3), ('dil_conv_5x5', 4)], reduce_concat=range(2, 6))
2019-11-01 15:52:00,456 
alphas_normal = Variable containing:
 0.1251  0.1250  0.1249  0.1249  0.1251  0.1251  0.1250  0.1248
 0.1250  0.1248  0.1250  0.1249  0.1250  0.1251  0.1250  0.1252
 0.1248  0.1252  0.1248  0.1251  0.1251  0.1251  0.1250  0.1249
 0.1248  0.1250  0.1248  0.1249  0.1252  0.1253  0.1250  0.1250
 0.1252  0.1250  0.1250  0.1249  0.1251  0.1249  0.1249  0.1250
 0.1250  0.1250  0.1248  0.1250  0.1251  0.1250  0.1253  0.1249
 0.1251  0.1248  0.1250  0.1251  0.1250  0.1250  0.1252  0.1248
 0.1249  0.1250  0.1252  0.1252  0.1251  0.1248  0.1249  0.1251
 0.1250  0.1252  0.1250  0.1251  0.1249  0.1249  0.1249  0.1250
 0.1250  0.1250  0.1251  0.1250  0.1250  0.1249  0.1250  0.1249
 0.1251  0.1251  0.1251  0.1250  0.1248  0.1250  0.1249  0.1251
 0.1251  0.1252  0.1249  0.1249  0.1250  0.1249  0.1252  0.1249
 0.1249  0.1250  0.1250  0.1251  0.1250  0.1253  0.1248  0.1249
 0.1251  0.1250  0.1248  0.1250  0.1251  0.1249  0.1250  0.1251
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 15:52:00,458 
alphas_reduce = Variable containing:
 0.1250  0.1252  0.1249  0.1249  0.1250  0.1251  0.1249  0.1250
 0.1250  0.1249  0.1252  0.1251  0.1249  0.1249  0.1251  0.1250
 0.1252  0.1251  0.1249  0.1250  0.1251  0.1249  0.1249  0.1249
 0.1250  0.1249  0.1250  0.1249  0.1250  0.1249  0.1252  0.1250
 0.1249  0.1250  0.1250  0.1250  0.1248  0.1252  0.1252  0.1250
 0.1251  0.1247  0.1249  0.1250  0.1251  0.1250  0.1252  0.1250
 0.1249  0.1253  0.1248  0.1249  0.1250  0.1250  0.1251  0.1250
 0.1249  0.1250  0.1249  0.1249  0.1250  0.1252  0.1252  0.1250
 0.1251  0.1250  0.1249  0.1250  0.1252  0.1249  0.1251  0.1248
 0.1252  0.1250  0.1249  0.1249  0.1250  0.1250  0.1249  0.1250
 0.1250  0.1250  0.1250  0.1249  0.1251  0.1249  0.1250  0.1251
 0.1251  0.1249  0.1250  0.1250  0.1249  0.1250  0.1252  0.1250
 0.1250  0.1249  0.1249  0.1249  0.1251  0.1249  0.1252  0.1251
 0.1252  0.1250  0.1249  0.1250  0.1247  0.1249  0.1250  0.1252
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 15:52:08,545 train 000 3.635506e-02 -5.241031
2019-11-01 15:54:46,614 train 050 4.093036e-02 -5.890083
2019-11-01 15:57:23,953 train 100 4.117759e-02 -6.561358
2019-11-01 16:00:00,959 train 150 3.999954e-02 -6.303427
2019-11-01 16:02:38,216 train 200 3.952005e-02 -6.309133
2019-11-01 16:05:15,265 train 250 3.925833e-02 -6.073349
2019-11-01 16:07:52,819 train 300 3.884153e-02 -5.873810
2019-11-01 16:10:28,894 train 350 3.850705e-02 -6.133610
2019-11-01 16:13:05,391 train 400 3.805640e-02 -6.067354
2019-11-01 16:15:41,547 train 450 3.756991e-02 -5.985226
2019-11-01 16:18:17,709 train 500 3.723034e-02 -5.850353
2019-11-01 16:20:53,050 train 550 3.687806e-02 -5.784020
2019-11-01 16:23:29,837 train 600 3.644103e-02 -5.663730
2019-11-01 16:26:06,197 train 650 3.610792e-02 -5.595190
2019-11-01 16:28:42,494 train 700 3.583055e-02 -5.585262
2019-11-01 16:31:19,098 train 750 3.551779e-02 -5.673410
2019-11-01 16:33:57,015 train 800 3.519957e-02 -5.554619
2019-11-01 16:36:33,306 train 850 3.493986e-02 -5.608269
2019-11-01 16:39:09,986 train 900 3.472067e-02 -5.633723
2019-11-01 16:41:46,333 train 950 3.449323e-02 -5.582295
2019-11-01 16:44:22,781 train 1000 3.431851e-02 -5.523017
2019-11-01 16:46:59,535 train 1050 3.408025e-02 -5.493036
2019-11-01 16:49:36,147 train 1100 3.386978e-02 -5.424293
2019-11-01 16:52:13,118 train 1150 3.364003e-02 -5.405959
2019-11-01 16:54:50,090 train 1200 3.342100e-02 -5.422497
2019-11-01 16:57:26,631 train 1250 3.321423e-02 -5.508354
2019-11-01 17:00:03,296 train 1300 3.303457e-02 -5.446355
2019-11-01 17:02:39,592 train 1350 3.290106e-02 -5.416700
2019-11-01 17:05:16,027 train 1400 3.276048e-02 -5.387464
2019-11-01 17:07:53,668 train 1450 3.259486e-02 -5.351810
2019-11-01 17:10:31,607 train 1500 3.239971e-02 -5.340751
2019-11-01 17:12:40,253 train_acc (R^2 for regression) -5.403040
2019-11-01 17:12:40,725 valid 000 2.669242e-02 -5.514780
2019-11-01 17:12:49,338 valid 050 2.677834e-02 -3.732244
2019-11-01 17:12:57,964 valid 100 2.646134e-02 -3.895491
2019-11-01 17:13:06,568 valid 150 2.661143e-02 -3.987016
2019-11-01 17:13:15,246 valid 200 2.654203e-02 -3.947379
2019-11-01 17:13:23,883 valid 250 2.657603e-02 -3.888094
2019-11-01 17:13:32,502 valid 300 2.667317e-02 -24.375305
2019-11-01 17:13:41,179 valid 350 2.674205e-02 -21.579055
2019-11-01 17:13:49,857 valid 400 2.670013e-02 -19.436380
2019-11-01 17:13:58,556 valid 450 2.667749e-02 -17.848730
2019-11-01 17:14:07,226 valid 500 2.670335e-02 -16.494240
2019-11-01 17:14:15,876 valid 550 2.674255e-02 -15.310135
2019-11-01 17:14:24,520 valid 600 2.670973e-02 -14.365635
2019-11-01 17:14:33,224 valid 650 2.680646e-02 -13.767392
2019-11-01 17:14:41,852 valid 700 2.682856e-02 -13.056290
2019-11-01 17:14:50,500 valid 750 2.685299e-02 -12.502657
2019-11-01 17:14:59,101 valid 800 2.692365e-02 -11.967323
2019-11-01 17:15:07,702 valid 850 2.691864e-02 -11.513022
2019-11-01 17:15:16,146 valid 900 2.691112e-02 -11.080289
2019-11-01 17:15:24,749 valid 950 2.690396e-02 -10.751228
2019-11-01 17:15:33,505 valid 1000 2.689683e-02 -10.959481
2019-11-01 17:15:42,266 valid 1050 2.691657e-02 -10.714594
2019-11-01 17:15:51,126 valid 1100 2.686251e-02 -10.489156
2019-11-01 17:15:59,890 valid 1150 2.687171e-02 -10.305421
2019-11-01 17:16:08,524 valid 1200 2.682792e-02 -10.051528
2019-11-01 17:16:17,122 valid 1250 2.682779e-02 -10.050784
2019-11-01 17:16:25,673 valid 1300 2.683368e-02 -9.932003
2019-11-01 17:16:34,267 valid 1350 2.683617e-02 -9.710974
2019-11-01 17:16:42,785 valid 1400 2.682836e-02 -9.970057
2019-11-01 17:16:51,320 valid 1450 2.684793e-02 -9.755630
2019-11-01 17:16:59,811 valid 1500 2.684953e-02 -9.557380
2019-11-01 17:17:06,440 valid_acc (R^2 for regression) -9.416378
2019-11-01 17:17:06,572 epoch 1 lr 9.991120e-04
2019-11-01 17:17:06,573 genotype = Genotype(normal=[('avg_pool_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_5x5', 2), ('dil_conv_3x3', 0), ('avg_pool_3x3', 2), ('avg_pool_3x3', 3), ('skip_connect', 4), ('avg_pool_3x3', 1)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('skip_connect', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 2), ('dil_conv_3x3', 1), ('skip_connect', 0), ('sep_conv_3x3', 2)], reduce_concat=range(2, 6))
2019-11-01 17:17:06,574 
alphas_normal = Variable containing:
 0.1237  0.1224  0.1268  0.1231  0.1277  0.1268  0.1227  0.1266
 0.1223  0.1246  0.1303  0.1268  0.1166  0.1217  0.1290  0.1286
 0.1268  0.1223  0.1252  0.1223  0.1215  0.1289  0.1295  0.1235
 0.1219  0.1257  0.1250  0.1233  0.1239  0.1250  0.1293  0.1260
 0.1230  0.1229  0.1233  0.1220  0.1295  0.1311  0.1263  0.1218
 0.1237  0.1241  0.1271  0.1251  0.1279  0.1218  0.1252  0.1251
 0.1221  0.1274  0.1292  0.1275  0.1231  0.1209  0.1246  0.1252
 0.1223  0.1267  0.1301  0.1261  0.1247  0.1195  0.1257  0.1248
 0.1207  0.1283  0.1292  0.1273  0.1224  0.1268  0.1216  0.1237
 0.1228  0.1252  0.1278  0.1261  0.1218  0.1279  0.1254  0.1231
 0.1231  0.1278  0.1303  0.1277  0.1229  0.1230  0.1217  0.1234
 0.1213  0.1275  0.1290  0.1258  0.1198  0.1301  0.1255  0.1211
 0.1207  0.1281  0.1291  0.1280  0.1219  0.1261  0.1250  0.1211
 0.1208  0.1282  0.1295  0.1310  0.1207  0.1211  0.1205  0.1282
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 17:17:06,576 
alphas_reduce = Variable containing:
 0.1247  0.1232  0.1241  0.1273  0.1232  0.1269  0.1256  0.1249
 0.1262  0.1236  0.1243  0.1201  0.1254  0.1335  0.1226  0.1243
 0.1265  0.1224  0.1245  0.1260  0.1233  0.1235  0.1266  0.1272
 0.1262  0.1231  0.1251  0.1262  0.1263  0.1275  0.1231  0.1225
 0.1236  0.1242  0.1266  0.1237  0.1256  0.1273  0.1253  0.1237
 0.1254  0.1233  0.1238  0.1248  0.1244  0.1266  0.1272  0.1246
 0.1255  0.1250  0.1255  0.1268  0.1247  0.1244  0.1273  0.1207
 0.1244  0.1266  0.1262  0.1239  0.1230  0.1286  0.1227  0.1246
 0.1239  0.1257  0.1258  0.1241  0.1246  0.1247  0.1251  0.1262
 0.1252  0.1230  0.1237  0.1284  0.1258  0.1244  0.1241  0.1253
 0.1249  0.1240  0.1242  0.1240  0.1257  0.1267  0.1260  0.1244
 0.1252  0.1249  0.1247  0.1242  0.1272  0.1251  0.1232  0.1255
 0.1247  0.1257  0.1262  0.1244  0.1231  0.1272  0.1236  0.1250
 0.1241  0.1271  0.1256  0.1247  0.1231  0.1248  0.1238  0.1269
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 17:17:10,031 train 000 3.001937e-02 -6.419768
2019-11-01 17:19:52,291 train 050 2.817339e-02 -47.824502
2019-11-01 17:22:34,831 train 100 2.754304e-02 -26.580888
2019-11-01 17:25:16,595 train 150 2.734810e-02 -19.105384
2019-11-01 17:27:58,934 train 200 2.748325e-02 -21.298323
2019-11-01 17:30:41,431 train 250 2.748509e-02 -17.938795
2019-11-01 17:33:23,607 train 300 2.745477e-02 -15.821876
2019-11-01 17:36:06,449 train 350 2.740004e-02 -14.095103
2019-11-01 17:38:48,076 train 400 2.739474e-02 -12.830711
2019-11-01 17:41:30,844 train 450 2.721134e-02 -11.865760
2019-11-01 17:44:13,746 train 500 2.702739e-02 -11.078623
2019-11-01 17:46:57,538 train 550 2.693044e-02 -10.416763
2019-11-01 17:49:40,151 train 600 2.690109e-02 -9.960391
2019-11-01 17:52:22,404 train 650 2.684000e-02 -9.482323
2019-11-01 17:55:04,113 train 700 2.677849e-02 -9.134561
2019-11-01 17:57:47,513 train 750 2.671724e-02 -8.817333
2019-11-01 18:00:31,501 train 800 2.666273e-02 -8.496016
2019-11-01 18:03:14,698 train 850 2.657182e-02 -8.220869
2019-11-01 18:05:58,785 train 900 2.654540e-02 -8.043350
2019-11-01 18:08:40,419 train 950 2.650191e-02 -7.813467
2019-11-01 18:11:24,497 train 1000 2.642835e-02 -8.002806
2019-11-01 18:14:07,351 train 1050 2.638505e-02 -7.818348
2019-11-01 18:16:50,067 train 1100 2.632812e-02 -7.658519
2019-11-01 18:19:32,619 train 1150 2.628529e-02 -7.562181
2019-11-01 18:22:14,857 train 1200 2.620950e-02 -7.428605
2019-11-01 18:24:57,099 train 1250 2.614324e-02 -7.285512
2019-11-01 18:27:41,043 train 1300 2.611845e-02 -7.148152
2019-11-01 18:30:23,894 train 1350 2.608545e-02 -7.031125
2019-11-01 18:33:08,552 train 1400 2.605391e-02 -6.930204
2019-11-01 18:35:55,351 train 1450 2.600661e-02 -7.434505
2019-11-01 18:38:42,489 train 1500 2.594817e-02 -7.346612
2019-11-01 18:40:49,356 train_acc (R^2 for regression) -7.245023
2019-11-01 18:40:49,856 valid 000 2.533122e-02 -11.863620
2019-11-01 18:40:58,468 valid 050 2.392570e-02 -4.014488
2019-11-01 18:41:07,121 valid 100 2.390906e-02 -3.733698
2019-11-01 18:41:15,755 valid 150 2.385480e-02 -3.977184
2019-11-01 18:41:24,280 valid 200 2.358887e-02 -3.830186
2019-11-01 18:41:33,002 valid 250 2.363796e-02 -3.990690
2019-11-01 18:41:41,436 valid 300 2.364415e-02 -3.975239
2019-11-01 18:41:50,003 valid 350 2.359404e-02 -3.881143
2019-11-01 18:41:58,599 valid 400 2.354241e-02 -3.973348
2019-11-01 18:42:07,011 valid 450 2.364801e-02 -4.577859
2019-11-01 18:42:15,579 valid 500 2.373321e-02 -4.456262
2019-11-01 18:42:23,892 valid 550 2.371547e-02 -4.338719
2019-11-01 18:42:32,181 valid 600 2.369881e-02 -4.255400
2019-11-01 18:42:40,502 valid 650 2.370393e-02 -4.161833
2019-11-01 18:42:48,781 valid 700 2.365512e-02 -4.200481
2019-11-01 18:42:57,091 valid 750 2.366570e-02 -4.186382
2019-11-01 18:43:05,399 valid 800 2.362555e-02 -4.199967
2019-11-01 18:43:13,721 valid 850 2.362883e-02 -4.203295
2019-11-01 18:43:22,000 valid 900 2.356986e-02 -4.128303
2019-11-01 18:43:30,284 valid 950 2.359498e-02 -4.143214
2019-11-01 18:43:38,531 valid 1000 2.355183e-02 -4.090934
2019-11-01 18:43:46,802 valid 1050 2.356135e-02 -4.113823
2019-11-01 18:43:55,057 valid 1100 2.354794e-02 -4.119546
2019-11-01 18:44:03,336 valid 1150 2.357670e-02 -4.200993
2019-11-01 18:44:11,556 valid 1200 2.358028e-02 -4.203953
2019-11-01 18:44:19,866 valid 1250 2.359319e-02 -4.232629
2019-11-01 18:44:28,129 valid 1300 2.357922e-02 -4.207806
2019-11-01 18:44:36,415 valid 1350 2.357104e-02 -4.188096
2019-11-01 18:44:44,695 valid 1400 2.355712e-02 -4.167170
2019-11-01 18:44:53,015 valid 1450 2.353207e-02 -4.157450
2019-11-01 18:45:01,294 valid 1500 2.356364e-02 -4.155067
2019-11-01 18:45:07,743 valid_acc (R^2 for regression) -5.956866
2019-11-01 18:45:07,878 epoch 2 lr 9.964516e-04
2019-11-01 18:45:07,879 genotype = Genotype(normal=[('dil_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('max_pool_3x3', 3), ('avg_pool_3x3', 1), ('max_pool_3x3', 3), ('skip_connect', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('dil_conv_3x3', 0), ('skip_connect', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 4), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-01 18:45:07,881 
alphas_normal = Variable containing:
 0.1254  0.1236  0.1214  0.1200  0.1275  0.1288  0.1251  0.1282
 0.1222  0.1265  0.1268  0.1243  0.1177  0.1254  0.1278  0.1293
 0.1261  0.1216  0.1214  0.1196  0.1245  0.1329  0.1296  0.1243
 0.1237  0.1267  0.1223  0.1216  0.1235  0.1241  0.1290  0.1290
 0.1225  0.1253  0.1227  0.1224  0.1301  0.1308  0.1245  0.1217
 0.1236  0.1246  0.1241  0.1236  0.1277  0.1239  0.1254  0.1272
 0.1229  0.1277  0.1277  0.1258  0.1239  0.1233  0.1240  0.1247
 0.1231  0.1257  0.1272  0.1250  0.1249  0.1219  0.1260  0.1262
 0.1228  0.1278  0.1271  0.1260  0.1251  0.1264  0.1219  0.1229
 0.1242  0.1252  0.1258  0.1253  0.1248  0.1264  0.1246  0.1238
 0.1236  0.1281  0.1278  0.1262  0.1230  0.1237  0.1224  0.1252
 0.1221  0.1282  0.1277  0.1253  0.1229  0.1272  0.1252  0.1214
 0.1219  0.1288  0.1271  0.1265  0.1246  0.1261  0.1230  0.1221
 0.1209  0.1281  0.1268  0.1283  0.1211  0.1231  0.1239  0.1278
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 18:45:07,883 
alphas_reduce = Variable containing:
 0.1260  0.1266  0.1249  0.1228  0.1217  0.1293  0.1245  0.1243
 0.1246  0.1233  0.1220  0.1185  0.1251  0.1379  0.1246  0.1241
 0.1255  0.1244  0.1247  0.1252  0.1229  0.1231  0.1280  0.1262
 0.1252  0.1227  0.1237  0.1268  0.1257  0.1295  0.1232  0.1231
 0.1251  0.1244  0.1242  0.1245  0.1271  0.1270  0.1249  0.1229
 0.1253  0.1237  0.1234  0.1259  0.1233  0.1256  0.1266  0.1263
 0.1253  0.1242  0.1236  0.1281  0.1229  0.1273  0.1265  0.1222
 0.1254  0.1263  0.1239  0.1243  0.1241  0.1269  0.1245  0.1245
 0.1247  0.1250  0.1237  0.1232  0.1263  0.1264  0.1255  0.1251
 0.1254  0.1240  0.1239  0.1261  0.1271  0.1233  0.1251  0.1252
 0.1251  0.1238  0.1233  0.1253  0.1255  0.1252  0.1256  0.1262
 0.1248  0.1256  0.1235  0.1243  0.1271  0.1246  0.1250  0.1251
 0.1241  0.1257  0.1248  0.1238  0.1250  0.1275  0.1237  0.1254
 0.1237  0.1276  0.1250  0.1248  0.1224  0.1279  0.1236  0.1250
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 18:45:11,339 train 000 2.455429e-02 -2.135763
2019-11-01 18:47:49,568 train 050 2.429229e-02 -4.410422
2019-11-01 18:50:28,109 train 100 2.436178e-02 -29.755115
2019-11-01 18:53:06,647 train 150 2.452207e-02 -27.605255
2019-11-01 18:55:44,938 train 200 2.474517e-02 -23.153933
2019-11-01 18:58:23,639 train 250 2.466397e-02 -19.364002
2019-11-01 19:01:02,127 train 300 2.448334e-02 -16.745050
2019-11-01 19:03:40,579 train 350 2.434616e-02 -23.039257
2019-11-01 19:06:18,081 train 400 2.434728e-02 -20.905455
2019-11-01 19:08:55,854 train 450 2.418538e-02 -19.046882
2019-11-01 19:11:36,601 train 500 2.412117e-02 -17.796903
2019-11-01 19:14:14,724 train 550 2.401546e-02 -16.588560
2019-11-01 19:16:53,051 train 600 2.392308e-02 -15.464253
2019-11-01 19:19:30,907 train 650 2.391037e-02 -14.511010
2019-11-01 19:22:09,230 train 700 2.384362e-02 -13.770091
2019-11-01 19:24:47,191 train 750 2.378535e-02 -13.089581
2019-11-01 19:27:25,566 train 800 2.377144e-02 -12.499723
2019-11-01 19:30:01,853 train 850 2.376493e-02 -11.958786
2019-11-01 19:32:39,116 train 900 2.373814e-02 -11.445673
2019-11-01 19:35:17,528 train 950 2.365860e-02 -11.528466
2019-11-01 19:37:55,490 train 1000 2.362807e-02 -11.351900
2019-11-01 19:40:33,800 train 1050 2.360393e-02 -11.049208
2019-11-01 19:43:11,682 train 1100 2.356196e-02 -10.703395
2019-11-01 19:45:50,019 train 1150 2.351607e-02 -10.400770
2019-11-01 19:48:28,600 train 1200 2.350925e-02 -11.319275
2019-11-01 19:51:06,784 train 1250 2.350929e-02 -11.004238
2019-11-01 19:53:45,259 train 1300 2.349743e-02 -10.712491
2019-11-01 19:56:23,696 train 1350 2.347715e-02 -10.426373
2019-11-01 19:59:01,565 train 1400 2.345701e-02 -11.146066
2019-11-01 20:01:42,281 train 1450 2.342030e-02 -10.898626
2019-11-01 20:04:27,082 train 1500 2.339531e-02 -10.635667
2019-11-01 20:06:36,029 train_acc (R^2 for regression) -10.454281
2019-11-01 20:06:36,524 valid 000 2.891444e-02 -1.914493
2019-11-01 20:06:45,116 valid 050 2.163566e-02 -2.919834
2019-11-01 20:06:53,744 valid 100 2.150938e-02 -2.921517
2019-11-01 20:07:02,526 valid 150 2.134231e-02 -4.673226
2019-11-01 20:07:11,131 valid 200 2.154355e-02 -4.168072
2019-11-01 20:07:19,421 valid 250 2.170032e-02 -4.429061
2019-11-01 20:07:27,689 valid 300 2.184481e-02 -48.814236
2019-11-01 20:07:35,868 valid 350 2.181772e-02 -42.865775
2019-11-01 20:07:44,057 valid 400 2.172970e-02 -44.943846
2019-11-01 20:07:52,245 valid 450 2.174563e-02 -48.336144
2019-11-01 20:08:00,386 valid 500 2.167500e-02 -43.789053
2019-11-01 20:08:08,571 valid 550 2.166294e-02 -40.272016
2019-11-01 20:08:16,759 valid 600 2.163210e-02 -37.226523
2019-11-01 20:08:24,939 valid 650 2.162037e-02 -34.596397
2019-11-01 20:08:33,103 valid 700 2.165106e-02 -32.428275
2019-11-01 20:08:41,265 valid 750 2.166923e-02 -30.473883
2019-11-01 20:08:49,421 valid 800 2.161291e-02 -28.782245
2019-11-01 20:08:57,578 valid 850 2.162489e-02 -27.260464
2019-11-01 20:09:05,733 valid 900 2.166728e-02 -25.909375
2019-11-01 20:09:13,875 valid 950 2.168280e-02 -24.785400
2019-11-01 20:09:22,045 valid 1000 2.168080e-02 -23.681875
2019-11-01 20:09:30,254 valid 1050 2.167825e-02 -22.702320
2019-11-01 20:09:38,478 valid 1100 2.170495e-02 -21.813852
2019-11-01 20:09:46,676 valid 1150 2.170583e-02 -21.024165
2019-11-01 20:09:54,856 valid 1200 2.170705e-02 -20.312392
2019-11-01 20:10:03,076 valid 1250 2.171709e-02 -19.638898
2019-11-01 20:10:11,224 valid 1300 2.173352e-02 -19.026936
2019-11-01 20:10:19,368 valid 1350 2.174057e-02 -18.449972
2019-11-01 20:10:27,495 valid 1400 2.170482e-02 -17.897182
2019-11-01 20:10:35,709 valid 1450 2.170220e-02 -17.404394
2019-11-01 20:10:43,861 valid 1500 2.169708e-02 -16.934121
2019-11-01 20:10:50,213 valid_acc (R^2 for regression) -16.588998
2019-11-01 20:10:50,344 epoch 3 lr 9.920293e-04
2019-11-01 20:10:50,345 genotype = Genotype(normal=[('dil_conv_3x3', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 0), ('dil_conv_5x5', 1), ('max_pool_3x3', 3), ('max_pool_3x3', 1), ('max_pool_3x3', 2), ('max_pool_3x3', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 2), ('sep_conv_3x3', 3), ('sep_conv_5x5', 3), ('sep_conv_5x5', 4)], reduce_concat=range(2, 6))
2019-11-01 20:10:50,347 
alphas_normal = Variable containing:
 0.1259  0.1251  0.1209  0.1213  0.1245  0.1307  0.1260  0.1256
 0.1224  0.1264  0.1240  0.1229  0.1173  0.1257  0.1320  0.1292
 0.1266  0.1208  0.1188  0.1179  0.1262  0.1339  0.1298  0.1260
 0.1234  0.1258  0.1211  0.1212  0.1233  0.1233  0.1283  0.1336
 0.1233  0.1263  0.1224  0.1217  0.1299  0.1313  0.1233  0.1219
 0.1230  0.1252  0.1240  0.1236  0.1260  0.1265  0.1252  0.1265
 0.1217  0.1292  0.1291  0.1272  0.1238  0.1225  0.1229  0.1236
 0.1225  0.1279  0.1278  0.1258  0.1233  0.1233  0.1236  0.1258
 0.1225  0.1292  0.1279  0.1274  0.1263  0.1266  0.1195  0.1207
 0.1248  0.1247  0.1246  0.1245  0.1258  0.1268  0.1237  0.1250
 0.1238  0.1272  0.1260  0.1249  0.1241  0.1264  0.1226  0.1251
 0.1221  0.1280  0.1269  0.1247  0.1253  0.1249  0.1265  0.1214
 0.1230  0.1271  0.1249  0.1250  0.1247  0.1271  0.1254  0.1228
 0.1230  0.1275  0.1259  0.1265  0.1247  0.1245  0.1235  0.1243
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 20:10:50,348 
alphas_reduce = Variable containing:
 0.1266  0.1257  0.1239  0.1235  0.1205  0.1319  0.1241  0.1237
 0.1239  0.1230  0.1212  0.1185  0.1265  0.1397  0.1226  0.1245
 0.1269  0.1227  0.1231  0.1263  0.1243  0.1247  0.1273  0.1248
 0.1245  0.1236  0.1244  0.1272  0.1236  0.1299  0.1235  0.1234
 0.1245  0.1236  0.1242  0.1240  0.1261  0.1277  0.1264  0.1236
 0.1261  0.1237  0.1237  0.1249  0.1245  0.1258  0.1260  0.1254
 0.1247  0.1248  0.1237  0.1260  0.1244  0.1260  0.1273  0.1232
 0.1251  0.1249  0.1237  0.1246  0.1249  0.1279  0.1241  0.1248
 0.1235  0.1249  0.1237  0.1234  0.1275  0.1259  0.1268  0.1244
 0.1265  0.1229  0.1225  0.1271  0.1251  0.1233  0.1265  0.1260
 0.1247  0.1246  0.1239  0.1249  0.1255  0.1269  0.1245  0.1250
 0.1250  0.1244  0.1226  0.1235  0.1272  0.1270  0.1253  0.1250
 0.1247  0.1257  0.1241  0.1238  0.1242  0.1284  0.1249  0.1241
 0.1243  0.1266  0.1240  0.1238  0.1237  0.1273  0.1245  0.1258
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 20:10:53,859 train 000 2.096840e-02 -1.841304
2019-11-01 20:13:35,064 train 050 2.175523e-02 -3.280992
2019-11-01 20:16:15,992 train 100 2.217250e-02 -3.437541
2019-11-01 20:18:55,124 train 150 2.229895e-02 -12.269293
2019-11-01 20:21:33,561 train 200 2.216003e-02 -10.372713
2019-11-01 20:24:11,727 train 250 2.218055e-02 -9.117176
2019-11-01 20:26:50,360 train 300 2.213523e-02 -8.286219
2019-11-01 20:29:29,139 train 350 2.218611e-02 -7.619160
2019-11-01 20:32:07,532 train 400 2.209476e-02 -12.647602
2019-11-01 20:34:46,027 train 450 2.203937e-02 -11.619272
2019-11-01 20:37:24,753 train 500 2.210693e-02 -11.580052
2019-11-01 20:40:03,568 train 550 2.203282e-02 -10.904043
2019-11-01 20:42:42,514 train 600 2.198647e-02 -11.666977
2019-11-01 20:45:21,007 train 650 2.197916e-02 -11.078157
2019-11-01 20:47:59,827 train 700 2.197829e-02 -10.546513
2019-11-01 20:50:38,557 train 750 2.199078e-02 -10.066067
2019-11-01 20:53:16,493 train 800 2.196108e-02 -10.975393
2019-11-01 20:55:54,938 train 850 2.191138e-02 -10.492079
2019-11-01 20:58:33,937 train 900 2.185358e-02 -10.085676
2019-11-01 21:01:12,930 train 950 2.182744e-02 -9.702829
2019-11-01 21:03:51,958 train 1000 2.180136e-02 -9.362176
2019-11-01 21:06:30,906 train 1050 2.179739e-02 -9.163555
2019-11-01 21:09:09,352 train 1100 2.179586e-02 -8.922961
2019-11-01 21:11:47,775 train 1150 2.178301e-02 -8.705914
2019-11-01 21:14:23,955 train 1200 2.175282e-02 -8.477222
2019-11-01 21:17:00,220 train 1250 2.176658e-02 -8.266819
2019-11-01 21:19:39,597 train 1300 2.174865e-02 -8.065917
2019-11-01 21:22:17,755 train 1350 2.171924e-02 -7.880149
2019-11-01 21:24:56,177 train 1400 2.172170e-02 -7.785996
2019-11-01 21:27:34,871 train 1450 2.171376e-02 -7.645257
2019-11-01 21:30:14,532 train 1500 2.171789e-02 -7.602559
2019-11-01 21:32:20,610 train_acc (R^2 for regression) -7.475967
2019-11-01 21:32:21,177 valid 000 2.252379e-02 -3.761463
2019-11-01 21:32:31,535 valid 050 2.035795e-02 -3.034934
2019-11-01 21:32:41,733 valid 100 2.041965e-02 -3.855510
2019-11-01 21:32:51,802 valid 150 2.044847e-02 -3.669859
2019-11-01 21:33:01,756 valid 200 2.057352e-02 -21.340059
2019-11-01 21:33:11,743 valid 250 2.078588e-02 -17.707719
2019-11-01 21:33:21,480 valid 300 2.089341e-02 -15.239964
2019-11-01 21:33:29,534 valid 350 2.095487e-02 -13.575144
2019-11-01 21:33:37,619 valid 400 2.103635e-02 -12.300589
2019-11-01 21:33:45,738 valid 450 2.100578e-02 -11.440454
2019-11-01 21:33:53,813 valid 500 2.099461e-02 -10.605034
2019-11-01 21:34:01,909 valid 550 2.102302e-02 -9.947078
2019-11-01 21:34:10,016 valid 600 2.106353e-02 -9.439002
2019-11-01 21:34:18,083 valid 650 2.108579e-02 -8.926514
2019-11-01 21:34:26,181 valid 700 2.117284e-02 -8.497370
2019-11-01 21:34:34,288 valid 750 2.117449e-02 -8.154491
2019-11-01 21:34:42,361 valid 800 2.123132e-02 -7.959416
2019-11-01 21:34:50,426 valid 850 2.123098e-02 -8.217430
2019-11-01 21:34:58,518 valid 900 2.127697e-02 -7.955051
2019-11-01 21:35:06,655 valid 950 2.125912e-02 -7.702933
2019-11-01 21:35:14,778 valid 1000 2.124094e-02 -7.466896
2019-11-01 21:35:22,873 valid 1050 2.125485e-02 -7.243968
2019-11-01 21:35:30,943 valid 1100 2.124748e-02 -7.072561
2019-11-01 21:35:39,041 valid 1150 2.119704e-02 -7.131832
2019-11-01 21:35:47,132 valid 1200 2.121602e-02 -7.009327
2019-11-01 21:35:55,193 valid 1250 2.122483e-02 -6.860114
2019-11-01 21:36:03,235 valid 1300 2.118180e-02 -6.736753
2019-11-01 21:36:11,283 valid 1350 2.116411e-02 -6.650297
2019-11-01 21:36:19,358 valid 1400 2.116772e-02 -6.533956
2019-11-01 21:36:27,465 valid 1450 2.115400e-02 -6.426495
2019-11-01 21:36:35,573 valid 1500 2.115322e-02 -6.318348
2019-11-01 21:36:41,901 valid_acc (R^2 for regression) -6.249174
2019-11-01 21:36:42,030 epoch 4 lr 9.858624e-04
2019-11-01 21:36:42,032 genotype = Genotype(normal=[('dil_conv_3x3', 1), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('max_pool_3x3', 3), ('dil_conv_5x5', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 3)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 2), ('dil_conv_3x3', 1), ('sep_conv_5x5', 4), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-01 21:36:42,034 
alphas_normal = Variable containing:
 0.1274  0.1233  0.1200  0.1204  0.1259  0.1288  0.1250  0.1292
 0.1225  0.1245  0.1218  0.1212  0.1186  0.1281  0.1347  0.1285
 0.1278  0.1203  0.1184  0.1183  0.1274  0.1330  0.1274  0.1275
 0.1226  0.1268  0.1234  0.1230  0.1229  0.1246  0.1262  0.1305
 0.1235  0.1252  0.1222  0.1213  0.1300  0.1306  0.1242  0.1229
 0.1228  0.1245  0.1241  0.1234  0.1245  0.1258  0.1259  0.1291
 0.1219  0.1273  0.1276  0.1264  0.1239  0.1236  0.1238  0.1256
 0.1223  0.1275  0.1279  0.1261  0.1220  0.1240  0.1230  0.1273
 0.1238  0.1294  0.1277  0.1270  0.1251  0.1241  0.1204  0.1227
 0.1243  0.1238  0.1242  0.1243  0.1263  0.1281  0.1232  0.1258
 0.1230  0.1273  0.1264  0.1255  0.1232  0.1258  0.1224  0.1263
 0.1224  0.1283  0.1273  0.1254  0.1232  0.1240  0.1290  0.1205
 0.1219  0.1286  0.1264  0.1264  0.1219  0.1287  0.1246  0.1216
 0.1219  0.1282  0.1266  0.1274  0.1256  0.1229  0.1221  0.1253
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 21:36:42,035 
alphas_reduce = Variable containing:
 0.1265  0.1259  0.1243  0.1237  0.1225  0.1301  0.1234  0.1235
 0.1238  0.1222  0.1208  0.1177  0.1282  0.1393  0.1242  0.1237
 0.1257  0.1238  0.1238  0.1258  0.1234  0.1263  0.1266  0.1247
 0.1245  0.1237  0.1246  0.1268  0.1237  0.1291  0.1240  0.1238
 0.1241  0.1243  0.1251  0.1243  0.1257  0.1283  0.1261  0.1221
 0.1256  0.1242  0.1238  0.1259  0.1246  0.1252  0.1253  0.1253
 0.1243  0.1248  0.1244  0.1260  0.1246  0.1253  0.1262  0.1244
 0.1254  0.1259  0.1246  0.1250  0.1238  0.1271  0.1236  0.1245
 0.1241  0.1258  0.1244  0.1242  0.1257  0.1252  0.1255  0.1252
 0.1264  0.1246  0.1240  0.1243  0.1247  0.1248  0.1260  0.1250
 0.1253  0.1231  0.1227  0.1256  0.1248  0.1274  0.1264  0.1247
 0.1252  0.1242  0.1231  0.1233  0.1256  0.1272  0.1263  0.1251
 0.1246  0.1261  0.1247  0.1241  0.1241  0.1276  0.1239  0.1248
 0.1251  0.1256  0.1238  0.1235  0.1239  0.1283  0.1240  0.1257
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 21:36:45,482 train 000 2.097112e-02 -7.808156
2019-11-01 21:39:25,471 train 050 2.119634e-02 -3.493148
2019-11-01 21:42:05,458 train 100 2.095191e-02 -7.163337
2019-11-01 21:44:43,739 train 150 2.079561e-02 -5.638604
2019-11-01 21:47:22,164 train 200 2.061533e-02 -4.916937
2019-11-01 21:50:00,542 train 250 2.060064e-02 -5.019161
2019-11-01 21:52:39,126 train 300 2.064281e-02 -4.689411
2019-11-01 21:55:20,224 train 350 2.061083e-02 -5.177174
2019-11-01 21:58:04,082 train 400 2.052116e-02 -4.854425
2019-11-01 22:00:49,651 train 450 2.051185e-02 -4.648758
2019-11-01 22:03:35,295 train 500 2.053870e-02 -10.448389
2019-11-01 22:06:23,906 train 550 2.055208e-02 -9.823905
2019-11-01 22:09:07,141 train 600 2.043220e-02 -9.225748
2019-11-01 22:11:53,920 train 650 2.043459e-02 -10.374078
2019-11-01 22:14:38,205 train 700 2.037862e-02 -13.852268
2019-11-01 22:17:24,802 train 750 2.040221e-02 -13.360660
2019-11-01 22:20:10,158 train 800 2.041013e-02 -12.702309
2019-11-01 22:22:53,048 train 850 2.040786e-02 -12.100354
2019-11-01 22:25:36,165 train 900 2.043851e-02 -11.597235
2019-11-01 22:28:22,010 train 950 2.046020e-02 -11.402314
2019-11-01 22:31:07,573 train 1000 2.045858e-02 -11.959823
2019-11-01 22:33:51,770 train 1050 2.046215e-02 -11.739296
2019-11-01 22:36:38,087 train 1100 2.047558e-02 -11.659468
2019-11-01 22:39:23,465 train 1150 2.047187e-02 -11.258082
2019-11-01 22:42:10,220 train 1200 2.044727e-02 -10.904187
2019-11-01 22:44:56,586 train 1250 2.043362e-02 -10.590266
2019-11-01 22:47:41,899 train 1300 2.043639e-02 -10.288441
2019-11-01 22:50:26,306 train 1350 2.039909e-02 -10.032012
2019-11-01 22:53:09,939 train 1400 2.041300e-02 -9.761054
2019-11-01 22:55:59,116 train 1450 2.040985e-02 -9.546098
2019-11-01 22:58:48,930 train 1500 2.039589e-02 -10.355196
2019-11-01 23:00:55,601 train_acc (R^2 for regression) -10.175316
2019-11-01 23:00:56,045 valid 000 2.252553e-02 -4.542148
2019-11-01 23:01:04,728 valid 050 2.149327e-02 -5.210113
2019-11-01 23:01:13,380 valid 100 2.147045e-02 -4.250689
2019-11-01 23:01:22,012 valid 150 2.145121e-02 -4.958897
2019-11-01 23:01:30,642 valid 200 2.147221e-02 -4.610062
2019-11-01 23:01:39,277 valid 250 2.145516e-02 -4.487263
2019-11-01 23:01:47,943 valid 300 2.144499e-02 -4.301875
2019-11-01 23:01:56,610 valid 350 2.149759e-02 -4.058230
2019-11-01 23:02:05,264 valid 400 2.150853e-02 -3.953334
2019-11-01 23:02:13,926 valid 450 2.155792e-02 -4.186213
2019-11-01 23:02:22,605 valid 500 2.150140e-02 -4.085294
2019-11-01 23:02:31,245 valid 550 2.156836e-02 -4.003900
2019-11-01 23:02:40,969 valid 600 2.157673e-02 -4.079320
2019-11-01 23:02:51,540 valid 650 2.154834e-02 -4.012352
2019-11-01 23:03:02,039 valid 700 2.154062e-02 -3.920896
2019-11-01 23:03:12,586 valid 750 2.147017e-02 -3.938446
2019-11-01 23:03:23,088 valid 800 2.148508e-02 -3.999787
2019-11-01 23:03:33,634 valid 850 2.149885e-02 -4.043240
2019-11-01 23:03:44,181 valid 900 2.149605e-02 -4.008255
2019-11-01 23:03:54,381 valid 950 2.148732e-02 -4.066718
2019-11-01 23:04:03,043 valid 1000 2.149567e-02 -4.057295
2019-11-01 23:04:11,658 valid 1050 2.151252e-02 -4.020914
2019-11-01 23:04:20,275 valid 1100 2.151553e-02 -3.957769
2019-11-01 23:04:28,887 valid 1150 2.148747e-02 -3.928122
2019-11-01 23:04:37,506 valid 1200 2.149765e-02 -3.932379
2019-11-01 23:04:46,114 valid 1250 2.148997e-02 -4.039397
2019-11-01 23:04:54,729 valid 1300 2.148823e-02 -4.025168
2019-11-01 23:05:03,387 valid 1350 2.147311e-02 -4.033914
2019-11-01 23:05:12,001 valid 1400 2.148830e-02 -4.003640
2019-11-01 23:05:20,590 valid 1450 2.149823e-02 -4.070376
2019-11-01 23:05:29,218 valid 1500 2.151015e-02 -4.028169
2019-11-01 23:05:35,916 valid_acc (R^2 for regression) -4.006945
2019-11-01 23:05:36,042 epoch 5 lr 9.779754e-04
2019-11-01 23:05:36,043 genotype = Genotype(normal=[('dil_conv_3x3', 1), ('dil_conv_5x5', 0), ('dil_conv_5x5', 1), ('dil_conv_5x5', 0), ('avg_pool_3x3', 1), ('dil_conv_5x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 4), ('dil_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-01 23:05:36,045 
alphas_normal = Variable containing:
 0.1262  0.1248  0.1201  0.1210  0.1238  0.1277  0.1248  0.1316
 0.1225  0.1235  0.1199  0.1190  0.1217  0.1312  0.1333  0.1289
 0.1274  0.1226  0.1200  0.1203  0.1252  0.1290  0.1261  0.1294
 0.1246  0.1261  0.1226  0.1221  0.1250  0.1240  0.1248  0.1308
 0.1234  0.1269  0.1236  0.1224  0.1269  0.1283  0.1244  0.1241
 0.1236  0.1246  0.1240  0.1244  0.1250  0.1257  0.1239  0.1287
 0.1223  0.1289  0.1295  0.1275  0.1232  0.1221  0.1226  0.1239
 0.1226  0.1269  0.1274  0.1252  0.1249  0.1242  0.1234  0.1255
 0.1237  0.1284  0.1272  0.1267  0.1269  0.1263  0.1202  0.1206
 0.1238  0.1263  0.1255  0.1260  0.1247  0.1272  0.1233  0.1232
 0.1243  0.1276  0.1258  0.1249  0.1231  0.1263  0.1234  0.1246
 0.1220  0.1294  0.1277  0.1253  0.1234  0.1229  0.1273  0.1219
 0.1218  0.1281  0.1252  0.1254  0.1244  0.1278  0.1241  0.1232
 0.1212  0.1283  0.1260  0.1274  0.1235  0.1245  0.1222  0.1268
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 23:05:36,046 
alphas_reduce = Variable containing:
 0.1286  0.1256  0.1234  0.1236  0.1206  0.1298  0.1246  0.1237
 0.1215  0.1240  0.1214  0.1200  0.1268  0.1374  0.1235  0.1254
 0.1264  0.1242  0.1235  0.1255  0.1241  0.1254  0.1264  0.1246
 0.1243  0.1251  0.1250  0.1238  0.1260  0.1305  0.1224  0.1229
 0.1249  0.1256  0.1251  0.1244  0.1261  0.1269  0.1247  0.1222
 0.1256  0.1235  0.1229  0.1250  0.1250  0.1268  0.1262  0.1251
 0.1242  0.1250  0.1239  0.1253  0.1255  0.1257  0.1266  0.1238
 0.1242  0.1267  0.1246  0.1247  0.1243  0.1272  0.1221  0.1263
 0.1241  0.1258  0.1238  0.1239  0.1259  0.1255  0.1253  0.1257
 0.1265  0.1234  0.1226  0.1257  0.1269  0.1241  0.1251  0.1257
 0.1248  0.1249  0.1243  0.1249  0.1254  0.1264  0.1253  0.1240
 0.1254  0.1262  0.1238  0.1250  0.1249  0.1236  0.1242  0.1268
 0.1245  0.1257  0.1238  0.1237  0.1247  0.1255  0.1246  0.1274
 0.1247  0.1259  0.1244  0.1243  0.1238  0.1285  0.1232  0.1250
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-01 23:05:39,543 train 000 1.879610e-02 -1.675654
2019-11-01 23:08:23,293 train 050 1.985098e-02 -2.291007
2019-11-01 23:11:15,420 train 100 1.996200e-02 -2.791504
2019-11-01 23:13:59,737 train 150 1.988261e-02 -2.801219
2019-11-01 23:16:48,194 train 200 1.971489e-02 -3.987081
2019-11-01 23:19:35,057 train 250 1.980152e-02 -3.666880
2019-11-01 23:22:22,212 train 300 1.972986e-02 -3.522378
2019-11-01 23:25:11,153 train 350 1.981950e-02 -3.409471
2019-11-01 23:28:00,033 train 400 1.983604e-02 -3.302582
2019-11-01 23:30:43,130 train 450 1.986277e-02 -4.709890
2019-11-01 23:33:26,257 train 500 1.982452e-02 -5.126673
2019-11-01 23:36:10,577 train 550 1.979414e-02 -4.928487
2019-11-01 23:38:53,767 train 600 1.969838e-02 -4.803833
2019-11-01 23:41:49,954 train 650 1.966778e-02 -4.689783
2019-11-01 23:44:38,518 train 700 1.970289e-02 -4.547603
2019-11-01 23:47:22,628 train 750 1.968998e-02 -4.477538
2019-11-01 23:50:08,102 train 800 1.969110e-02 -4.436081
2019-11-01 23:53:00,299 train 850 1.966881e-02 -4.343031
2019-11-01 23:55:42,566 train 900 1.970904e-02 -4.220368
2019-11-01 23:58:29,775 train 950 1.962998e-02 -7.147848
2019-11-02 00:01:11,696 train 1000 1.960810e-02 -6.922405
2019-11-02 00:03:56,062 train 1050 1.959881e-02 -6.724878
2019-11-02 00:06:39,391 train 1100 1.962154e-02 -6.559765
2019-11-02 00:09:24,660 train 1150 1.957801e-02 -7.568242
2019-11-02 00:12:07,956 train 1200 1.957181e-02 -7.413890
2019-11-02 00:14:54,799 train 1250 1.958109e-02 -7.230315
2019-11-02 00:17:39,099 train 1300 1.955593e-02 -7.266955
2019-11-02 00:20:23,531 train 1350 1.952153e-02 -7.103279
2019-11-02 00:23:07,449 train 1400 1.950855e-02 -7.442780
2019-11-02 00:26:00,819 train 1450 1.951161e-02 -7.284108
2019-11-02 00:28:47,249 train 1500 1.949388e-02 -7.201696
2019-11-02 00:30:56,337 train_acc (R^2 for regression) -7.095249
2019-11-02 00:30:56,883 valid 000 2.439778e-02 -2.375902
2019-11-02 00:31:05,590 valid 050 2.006333e-02 -2.727970
2019-11-02 00:31:14,287 valid 100 1.961630e-02 -2.716232
2019-11-02 00:31:22,942 valid 150 1.974936e-02 -3.033203
2019-11-02 00:31:31,596 valid 200 1.970390e-02 -3.204558
2019-11-02 00:31:40,251 valid 250 1.964364e-02 -3.587901
2019-11-02 00:31:48,902 valid 300 1.970248e-02 -34.081708
2019-11-02 00:31:57,572 valid 350 1.974162e-02 -30.451619
2019-11-02 00:32:06,258 valid 400 1.970719e-02 -26.985632
2019-11-02 00:32:14,909 valid 450 1.965162e-02 -24.348243
2019-11-02 00:32:23,556 valid 500 1.961970e-02 -22.205188
2019-11-02 00:32:32,205 valid 550 1.967569e-02 -20.605187
2019-11-02 00:32:40,803 valid 600 1.966592e-02 -19.181073
2019-11-02 00:32:49,422 valid 650 1.962885e-02 -17.991704
2019-11-02 00:32:58,030 valid 700 1.959766e-02 -16.958887
2019-11-02 00:33:06,678 valid 750 1.961334e-02 -16.089002
2019-11-02 00:33:15,315 valid 800 1.962987e-02 -15.274011
2019-11-02 00:33:23,936 valid 850 1.961095e-02 -14.558308
2019-11-02 00:33:32,616 valid 900 1.960996e-02 -13.937280
2019-11-02 00:33:41,299 valid 950 1.959256e-02 -13.441312
2019-11-02 00:33:49,950 valid 1000 1.961105e-02 -12.935477
2019-11-02 00:33:58,608 valid 1050 1.965660e-02 -12.476727
2019-11-02 00:34:07,228 valid 1100 1.965859e-02 -12.077707
2019-11-02 00:34:15,852 valid 1150 1.964994e-02 -11.825279
2019-11-02 00:34:24,512 valid 1200 1.967273e-02 -11.461143
2019-11-02 00:34:33,163 valid 1250 1.971288e-02 -11.168841
2019-11-02 00:34:41,839 valid 1300 1.971152e-02 -10.853665
2019-11-02 00:34:50,551 valid 1350 1.972948e-02 -10.613318
2019-11-02 00:34:59,224 valid 1400 1.970394e-02 -10.360978
2019-11-02 00:35:07,877 valid 1450 1.969717e-02 -10.223739
2019-11-02 00:35:16,473 valid 1500 1.968159e-02 -9.979417
2019-11-02 00:35:23,250 valid_acc (R^2 for regression) -9.811782
2019-11-02 00:35:23,386 epoch 6 lr 9.683994e-04
2019-11-02 00:35:23,387 genotype = Genotype(normal=[('dil_conv_3x3', 1), ('dil_conv_5x5', 0), ('dil_conv_5x5', 1), ('sep_conv_5x5', 2), ('avg_pool_3x3', 1), ('max_pool_3x3', 3), ('max_pool_3x3', 4), ('max_pool_3x3', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('dil_conv_3x3', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 4), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-02 00:35:23,389 
alphas_normal = Variable containing:
 0.1257  0.1247  0.1212  0.1218  0.1220  0.1288  0.1238  0.1321
 0.1226  0.1231  0.1192  0.1188  0.1220  0.1320  0.1327  0.1296
 0.1275  0.1215  0.1187  0.1190  0.1265  0.1283  0.1280  0.1304
 0.1225  0.1262  0.1223  0.1217  0.1267  0.1252  0.1247  0.1306
 0.1235  0.1267  0.1235  0.1218  0.1251  0.1304  0.1238  0.1252
 0.1236  0.1246  0.1241  0.1241  0.1253  0.1282  0.1227  0.1274
 0.1219  0.1284  0.1295  0.1279  0.1231  0.1225  0.1230  0.1237
 0.1219  0.1274  0.1278  0.1254  0.1245  0.1234  0.1225  0.1271
 0.1244  0.1293  0.1284  0.1278  0.1271  0.1259  0.1181  0.1191
 0.1249  0.1243  0.1238  0.1246  0.1263  0.1288  0.1239  0.1233
 0.1231  0.1271  0.1257  0.1248  0.1260  0.1259  0.1220  0.1254
 0.1208  0.1290  0.1270  0.1242  0.1250  0.1234  0.1277  0.1228
 0.1222  0.1287  0.1257  0.1260  0.1251  0.1255  0.1249  0.1220
 0.1221  0.1294  0.1266  0.1274  0.1250  0.1248  0.1196  0.1251
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 00:35:23,390 
alphas_reduce = Variable containing:
 0.1256  0.1275  0.1256  0.1233  0.1210  0.1295  0.1238  0.1237
 0.1241  0.1225  0.1205  0.1205  0.1275  0.1371  0.1223  0.1254
 0.1259  0.1248  0.1244  0.1258  0.1259  0.1252  0.1252  0.1228
 0.1239  0.1238  0.1240  0.1256  0.1255  0.1297  0.1225  0.1249
 0.1249  0.1254  0.1248  0.1244  0.1252  0.1292  0.1235  0.1227
 0.1249  0.1245  0.1235  0.1257  0.1247  0.1274  0.1254  0.1238
 0.1243  0.1245  0.1233  0.1250  0.1248  0.1248  0.1276  0.1258
 0.1255  0.1259  0.1236  0.1249  0.1267  0.1262  0.1218  0.1253
 0.1237  0.1263  0.1241  0.1236  0.1261  0.1252  0.1248  0.1262
 0.1270  0.1235  0.1222  0.1255  0.1262  0.1230  0.1275  0.1251
 0.1256  0.1233  0.1224  0.1255  0.1262  0.1269  0.1254  0.1248
 0.1268  0.1236  0.1212  0.1235  0.1263  0.1247  0.1271  0.1268
 0.1240  0.1248  0.1226  0.1224  0.1264  0.1283  0.1241  0.1274
 0.1251  0.1253  0.1226  0.1225  0.1245  0.1295  0.1248  0.1256
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 00:35:26,917 train 000 1.541167e-02 -1.583020
2019-11-02 00:38:11,401 train 050 1.888960e-02 -2.727514
2019-11-02 00:40:55,971 train 100 1.884343e-02 -3.106313
2019-11-02 00:43:43,260 train 150 1.885987e-02 -7.278307
2019-11-02 00:46:31,742 train 200 1.903139e-02 -7.562514
2019-11-02 00:49:14,225 train 250 1.911806e-02 -6.584346
2019-11-02 00:51:58,321 train 300 1.899176e-02 -5.914196
2019-11-02 00:54:41,437 train 350 1.882569e-02 -5.816213
2019-11-02 00:57:25,056 train 400 1.888397e-02 -9.867228
2019-11-02 01:00:07,690 train 450 1.892662e-02 -11.252227
2019-11-02 01:02:52,061 train 500 1.890823e-02 -10.437325
2019-11-02 01:05:37,010 train 550 1.886437e-02 -9.742118
2019-11-02 01:08:19,957 train 600 1.884030e-02 -11.505902
2019-11-02 01:11:03,028 train 650 1.883626e-02 -10.990197
2019-11-02 01:13:46,291 train 700 1.880330e-02 -10.461878
2019-11-02 01:16:34,239 train 750 1.882869e-02 -9.973204
2019-11-02 01:19:17,478 train 800 1.880013e-02 -9.513208
2019-11-02 01:21:59,932 train 850 1.880464e-02 -9.070698
2019-11-02 01:24:44,215 train 900 1.879049e-02 -8.747191
2019-11-02 01:27:34,255 train 950 1.878047e-02 -8.416225
2019-11-02 01:30:20,609 train 1000 1.879972e-02 -8.131614
2019-11-02 01:33:05,667 train 1050 1.880658e-02 -8.168366
2019-11-02 01:35:49,446 train 1100 1.878608e-02 -7.910779
2019-11-02 01:38:32,704 train 1150 1.878079e-02 -7.696806
2019-11-02 01:41:15,049 train 1200 1.876280e-02 -7.520368
2019-11-02 01:43:59,329 train 1250 1.872875e-02 -7.316726
2019-11-02 01:46:44,346 train 1300 1.871813e-02 -7.145742
2019-11-02 01:49:27,594 train 1350 1.870665e-02 -7.009021
2019-11-02 01:52:12,829 train 1400 1.870760e-02 -6.987237
2019-11-02 01:54:58,076 train 1450 1.869785e-02 -6.831934
2019-11-02 01:57:42,785 train 1500 1.871277e-02 -6.673089
2019-11-02 01:59:50,697 train_acc (R^2 for regression) -6.571984
2019-11-02 01:59:51,177 valid 000 1.476137e-02 -1.972643
2019-11-02 01:59:59,845 valid 050 1.749115e-02 -2.973901
2019-11-02 02:00:08,565 valid 100 1.715880e-02 -2.380917
2019-11-02 02:00:17,257 valid 150 1.695300e-02 -18.576451
2019-11-02 02:00:25,906 valid 200 1.685255e-02 -14.579616
2019-11-02 02:00:34,671 valid 250 1.697044e-02 -12.095489
2019-11-02 02:00:43,379 valid 300 1.704304e-02 -11.251815
2019-11-02 02:00:52,112 valid 350 1.710643e-02 -9.956986
2019-11-02 02:01:00,818 valid 400 1.716718e-02 -9.525969
2019-11-02 02:01:09,493 valid 450 1.717772e-02 -8.688857
2019-11-02 02:01:18,142 valid 500 1.719176e-02 -8.260442
2019-11-02 02:01:26,813 valid 550 1.717972e-02 -13.618997
2019-11-02 02:01:35,458 valid 600 1.721906e-02 -12.688260
2019-11-02 02:01:44,094 valid 650 1.720696e-02 -11.919245
2019-11-02 02:01:52,758 valid 700 1.719803e-02 -11.274572
2019-11-02 02:02:01,458 valid 750 1.717233e-02 -10.680405
2019-11-02 02:02:10,128 valid 800 1.721431e-02 -10.189268
2019-11-02 02:02:18,805 valid 850 1.719065e-02 -9.710888
2019-11-02 02:02:27,450 valid 900 1.720339e-02 -9.304917
2019-11-02 02:02:36,099 valid 950 1.722415e-02 -8.958817
2019-11-02 02:02:44,733 valid 1000 1.720540e-02 -8.841029
2019-11-02 02:02:53,462 valid 1050 1.725898e-02 -8.521274
2019-11-02 02:03:02,150 valid 1100 1.725841e-02 -8.282652
2019-11-02 02:03:10,821 valid 1150 1.724582e-02 -8.023424
2019-11-02 02:03:19,493 valid 1200 1.723614e-02 -7.788147
2019-11-02 02:03:28,139 valid 1250 1.725249e-02 -7.571728
2019-11-02 02:03:36,796 valid 1300 1.725021e-02 -7.362873
2019-11-02 02:03:45,484 valid 1350 1.724782e-02 -7.184723
2019-11-02 02:03:54,138 valid 1400 1.725014e-02 -7.013508
2019-11-02 02:04:02,808 valid 1450 1.724836e-02 -6.850486
2019-11-02 02:04:11,445 valid 1500 1.725440e-02 -6.690037
2019-11-02 02:04:18,173 valid_acc (R^2 for regression) -6.577890
2019-11-02 02:04:18,303 epoch 7 lr 9.571722e-04
2019-11-02 02:04:18,304 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('sep_conv_5x5', 2), ('dil_conv_5x5', 0), ('max_pool_3x3', 3), ('avg_pool_3x3', 1), ('max_pool_3x3', 4), ('max_pool_3x3', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('dil_conv_3x3', 1), ('sep_conv_3x3', 1), ('sep_conv_5x5', 4)], reduce_concat=range(2, 6))
2019-11-02 02:04:18,305 
alphas_normal = Variable containing:
 0.1260  0.1250  0.1208  0.1214  0.1211  0.1287  0.1230  0.1341
 0.1221  0.1241  0.1194  0.1189  0.1226  0.1348  0.1319  0.1261
 0.1269  0.1228  0.1195  0.1197  0.1258  0.1277  0.1270  0.1305
 0.1235  0.1268  0.1223  0.1214  0.1272  0.1252  0.1241  0.1295
 0.1225  0.1265  0.1228  0.1211  0.1248  0.1309  0.1260  0.1254
 0.1238  0.1248  0.1246  0.1247  0.1262  0.1257  0.1216  0.1285
 0.1225  0.1282  0.1288  0.1271  0.1230  0.1223  0.1240  0.1240
 0.1223  0.1272  0.1270  0.1246  0.1252  0.1256  0.1228  0.1254
 0.1233  0.1298  0.1289  0.1275  0.1268  0.1264  0.1184  0.1189
 0.1240  0.1254  0.1252  0.1262  0.1259  0.1263  0.1248  0.1221
 0.1254  0.1258  0.1232  0.1232  0.1255  0.1270  0.1235  0.1263
 0.1222  0.1282  0.1259  0.1246  0.1230  0.1242  0.1270  0.1250
 0.1212  0.1277  0.1247  0.1248  0.1256  0.1266  0.1256  0.1239
 0.1224  0.1282  0.1259  0.1268  0.1263  0.1257  0.1202  0.1244
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 02:04:18,307 
alphas_reduce = Variable containing:
 0.1254  0.1283  0.1260  0.1216  0.1221  0.1285  0.1236  0.1246
 0.1243  0.1219  0.1202  0.1203  0.1268  0.1362  0.1239  0.1264
 0.1260  0.1265  0.1257  0.1244  0.1236  0.1232  0.1253  0.1252
 0.1248  0.1230  0.1229  0.1258  0.1267  0.1292  0.1226  0.1249
 0.1236  0.1260  0.1249  0.1240  0.1258  0.1295  0.1241  0.1221
 0.1249  0.1250  0.1233  0.1264  0.1240  0.1276  0.1252  0.1237
 0.1250  0.1226  0.1213  0.1262  0.1253  0.1261  0.1275  0.1261
 0.1253  0.1258  0.1225  0.1243  0.1252  0.1272  0.1224  0.1273
 0.1246  0.1260  0.1232  0.1233  0.1263  0.1252  0.1253  0.1260
 0.1265  0.1242  0.1230  0.1254  0.1261  0.1241  0.1267  0.1240
 0.1254  0.1231  0.1222  0.1258  0.1287  0.1256  0.1247  0.1245
 0.1262  0.1238  0.1214  0.1236  0.1258  0.1260  0.1265  0.1267
 0.1241  0.1249  0.1222  0.1222  0.1255  0.1284  0.1257  0.1271
 0.1249  0.1250  0.1225  0.1227  0.1260  0.1284  0.1248  0.1257
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 02:04:21,900 train 000 2.213712e-02 -5.593930
2019-11-02 02:07:05,279 train 050 1.804152e-02 -2.932748
2019-11-02 02:09:51,170 train 100 1.804824e-02 -219.446523
2019-11-02 02:12:35,474 train 150 1.800612e-02 -154.226382
2019-11-02 02:15:18,563 train 200 1.785538e-02 -116.818316
2019-11-02 02:18:00,611 train 250 1.782300e-02 -94.085667
2019-11-02 02:20:50,186 train 300 1.789862e-02 -81.687851
2019-11-02 02:23:33,935 train 350 1.799761e-02 -70.837303
2019-11-02 02:26:18,836 train 400 1.810860e-02 -62.334752
2019-11-02 02:29:03,275 train 450 1.818054e-02 -55.669154
2019-11-02 02:31:48,535 train 500 1.818435e-02 -50.351014
2019-11-02 02:34:33,432 train 550 1.815517e-02 -46.008880
2019-11-02 02:37:17,450 train 600 1.816977e-02 -42.561967
2019-11-02 02:40:03,052 train 650 1.814633e-02 -45.207205
2019-11-02 02:42:48,710 train 700 1.814247e-02 -42.203274
2019-11-02 02:45:30,652 train 750 1.815744e-02 -39.587174
2019-11-02 02:48:14,456 train 800 1.817051e-02 -37.277801
2019-11-02 02:50:55,742 train 850 1.816688e-02 -37.788061
2019-11-02 02:53:36,390 train 900 1.813782e-02 -36.017973
2019-11-02 02:56:22,439 train 950 1.811012e-02 -34.293213
2019-11-02 02:59:14,464 train 1000 1.809429e-02 -32.891840
2019-11-02 03:01:58,596 train 1050 1.809206e-02 -31.535718
2019-11-02 03:04:43,057 train 1100 1.810714e-02 -30.388751
2019-11-02 03:07:26,989 train 1150 1.811843e-02 -29.206268
2019-11-02 03:10:07,587 train 1200 1.811351e-02 -28.091770
2019-11-02 03:12:48,862 train 1250 1.809535e-02 -27.081093
2019-11-02 03:15:33,210 train 1300 1.807320e-02 -26.349838
2019-11-02 03:18:15,051 train 1350 1.806930e-02 -25.463338
2019-11-02 03:21:01,454 train 1400 1.807626e-02 -24.638681
2019-11-02 03:23:49,875 train 1450 1.806821e-02 -23.899057
2019-11-02 03:26:38,218 train 1500 1.804071e-02 -23.436357
2019-11-02 03:28:45,585 train_acc (R^2 for regression) -22.909211
2019-11-02 03:28:46,080 valid 000 1.685518e-02 -2.609422
2019-11-02 03:28:54,689 valid 050 1.669682e-02 -2.886539
2019-11-02 03:29:03,307 valid 100 1.735156e-02 -2.842697
2019-11-02 03:29:11,909 valid 150 1.734714e-02 -2.654764
2019-11-02 03:29:20,542 valid 200 1.762234e-02 -2.776173
2019-11-02 03:29:29,146 valid 250 1.769674e-02 -2.800248
2019-11-02 03:29:37,743 valid 300 1.780231e-02 -2.762664
2019-11-02 03:29:46,377 valid 350 1.784998e-02 -7.107138
2019-11-02 03:29:54,991 valid 400 1.776821e-02 -6.539446
2019-11-02 03:30:03,611 valid 450 1.779267e-02 -6.204220
2019-11-02 03:30:12,301 valid 500 1.770652e-02 -6.096992
2019-11-02 03:30:20,900 valid 550 1.769006e-02 -5.822373
2019-11-02 03:30:29,547 valid 600 1.772921e-02 -5.655582
2019-11-02 03:30:38,214 valid 650 1.773078e-02 -5.470043
2019-11-02 03:30:46,860 valid 700 1.773781e-02 -5.270125
2019-11-02 03:30:55,549 valid 750 1.772132e-02 -5.084544
2019-11-02 03:31:04,252 valid 800 1.771703e-02 -4.930731
2019-11-02 03:31:12,890 valid 850 1.765971e-02 -4.845629
2019-11-02 03:31:21,613 valid 900 1.764686e-02 -4.784365
2019-11-02 03:31:30,322 valid 950 1.762166e-02 -4.667484
2019-11-02 03:31:39,022 valid 1000 1.757655e-02 -4.575855
2019-11-02 03:31:47,759 valid 1050 1.758303e-02 -4.480995
2019-11-02 03:31:56,478 valid 1100 1.756831e-02 -4.411973
2019-11-02 03:32:05,172 valid 1150 1.757057e-02 -8.330625
2019-11-02 03:32:13,888 valid 1200 1.756719e-02 -8.096631
2019-11-02 03:32:22,558 valid 1250 1.755661e-02 -7.955271
2019-11-02 03:32:31,275 valid 1300 1.757787e-02 -15.938962
2019-11-02 03:32:39,941 valid 1350 1.754852e-02 -15.456408
2019-11-02 03:32:48,573 valid 1400 1.754268e-02 -14.988211
2019-11-02 03:32:57,257 valid 1450 1.753995e-02 -14.572777
2019-11-02 03:33:05,929 valid 1500 1.753050e-02 -14.164217
2019-11-02 03:33:12,645 valid_acc (R^2 for regression) -13.888892
2019-11-02 03:33:12,775 epoch 8 lr 9.443380e-04
2019-11-02 03:33:12,775 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 2), ('max_pool_3x3', 3), ('dil_conv_5x5', 0), ('max_pool_3x3', 4), ('dil_conv_3x3', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 4), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-02 03:33:12,777 
alphas_normal = Variable containing:
 0.1281  0.1236  0.1201  0.1205  0.1227  0.1286  0.1250  0.1314
 0.1225  0.1238  0.1201  0.1196  0.1224  0.1352  0.1301  0.1265
 0.1270  0.1212  0.1187  0.1188  0.1272  0.1283  0.1281  0.1306
 0.1223  0.1276  0.1238  0.1234  0.1243  0.1255  0.1257  0.1273
 0.1229  0.1256  0.1230  0.1220  0.1247  0.1301  0.1251  0.1267
 0.1243  0.1251  0.1241  0.1242  0.1240  0.1267  0.1235  0.1280
 0.1230  0.1271  0.1276  0.1262  0.1249  0.1245  0.1222  0.1245
 0.1228  0.1278  0.1272  0.1260  0.1237  0.1256  0.1217  0.1252
 0.1230  0.1290  0.1278  0.1271  0.1277  0.1238  0.1204  0.1212
 0.1260  0.1229  0.1224  0.1231  0.1265  0.1279  0.1260  0.1252
 0.1225  0.1264  0.1249  0.1243  0.1254  0.1265  0.1233  0.1266
 0.1227  0.1262  0.1250  0.1240  0.1251  0.1244  0.1286  0.1240
 0.1222  0.1269  0.1250  0.1247  0.1256  0.1266  0.1245  0.1245
 0.1235  0.1287  0.1265  0.1267  0.1254  0.1250  0.1197  0.1245
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 03:33:12,779 
alphas_reduce = Variable containing:
 0.1254  0.1265  0.1255  0.1226  0.1235  0.1283  0.1238  0.1243
 0.1243  0.1212  0.1199  0.1199  0.1269  0.1360  0.1253  0.1264
 0.1257  0.1242  0.1242  0.1268  0.1258  0.1229  0.1256  0.1246
 0.1252  0.1245  0.1244  0.1259  0.1244  0.1285  0.1227  0.1244
 0.1238  0.1263  0.1257  0.1243  0.1247  0.1294  0.1233  0.1225
 0.1248  0.1252  0.1245  0.1243  0.1249  0.1263  0.1252  0.1247
 0.1256  0.1233  0.1224  0.1247  0.1252  0.1269  0.1265  0.1253
 0.1249  0.1256  0.1237  0.1239  0.1256  0.1264  0.1235  0.1265
 0.1249  0.1258  0.1242  0.1244  0.1263  0.1251  0.1247  0.1244
 0.1259  0.1251  0.1244  0.1246  0.1246  0.1228  0.1261  0.1263
 0.1255  0.1232  0.1225  0.1264  0.1274  0.1260  0.1250  0.1241
 0.1250  0.1247  0.1229  0.1237  0.1258  0.1265  0.1256  0.1258
 0.1247  0.1257  0.1238  0.1239  0.1245  0.1286  0.1238  0.1249
 0.1246  0.1252  0.1240  0.1241  0.1249  0.1288  0.1238  0.1246
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 03:33:16,321 train 000 1.579447e-02 -2.795404
2019-11-02 03:36:01,765 train 050 1.710681e-02 -2.714769
2019-11-02 03:38:46,415 train 100 1.714428e-02 -2.680756
2019-11-02 03:41:29,558 train 150 1.751656e-02 -3.297432
2019-11-02 03:44:11,738 train 200 1.749427e-02 -3.081447
2019-11-02 03:46:54,916 train 250 1.753376e-02 -2.994057
2019-11-02 03:49:39,080 train 300 1.754860e-02 -4.233332
2019-11-02 03:52:22,145 train 350 1.749855e-02 -3.986628
2019-11-02 03:55:07,767 train 400 1.748830e-02 -3.789704
2019-11-02 03:57:53,923 train 450 1.754912e-02 -7.885458
2019-11-02 04:00:36,609 train 500 1.756585e-02 -7.418485
2019-11-02 04:03:21,707 train 550 1.758955e-02 -7.003217
2019-11-02 04:06:06,545 train 600 1.762173e-02 -6.704449
2019-11-02 04:08:53,007 train 650 1.765360e-02 -6.384983
2019-11-02 04:11:43,446 train 700 1.763657e-02 -53.929495
2019-11-02 04:14:30,839 train 750 1.762717e-02 -50.476199
2019-11-02 04:17:12,834 train 800 1.763267e-02 -47.898008
2019-11-02 04:19:58,897 train 850 1.761629e-02 -45.246189
2019-11-02 04:22:44,618 train 900 1.762987e-02 -42.881958
2019-11-02 04:25:27,493 train 950 1.762458e-02 -40.753193
2019-11-02 04:28:12,159 train 1000 1.765852e-02 -38.838221
2019-11-02 04:30:55,972 train 1050 1.767717e-02 -37.091037
2019-11-02 04:33:41,392 train 1100 1.764503e-02 -35.521759
2019-11-02 04:36:22,623 train 1150 1.762044e-02 -34.068819
2019-11-02 04:39:04,134 train 1200 1.760424e-02 -32.780598
2019-11-02 04:41:48,215 train 1250 1.760788e-02 -31.562934
2019-11-02 04:44:32,614 train 1300 1.759872e-02 -30.475185
2019-11-02 04:47:18,682 train 1350 1.757022e-02 -29.445297
2019-11-02 04:50:08,526 train 1400 1.755965e-02 -28.487505
2019-11-02 04:52:54,417 train 1450 1.756122e-02 -27.597779
2019-11-02 04:55:39,628 train 1500 1.756671e-02 -26.748906
2019-11-02 04:57:46,706 train_acc (R^2 for regression) -26.144599
2019-11-02 04:57:47,164 valid 000 1.561461e-02 -1.659886
2019-11-02 04:57:55,900 valid 050 1.657621e-02 -2.465370
2019-11-02 04:58:04,590 valid 100 1.633361e-02 -2.368393
2019-11-02 04:58:13,286 valid 150 1.624776e-02 -2.141451
2019-11-02 04:58:21,969 valid 200 1.625466e-02 -2.176592
2019-11-02 04:58:30,635 valid 250 1.628468e-02 -2.137978
2019-11-02 04:58:39,293 valid 300 1.632468e-02 -2.129080
2019-11-02 04:58:47,968 valid 350 1.644241e-02 -2.127353
2019-11-02 04:58:56,628 valid 400 1.636625e-02 -2.215981
2019-11-02 04:59:05,253 valid 450 1.630432e-02 -2.655479
2019-11-02 04:59:13,939 valid 500 1.637132e-02 -2.589167
2019-11-02 04:59:22,635 valid 550 1.641600e-02 -2.584494
2019-11-02 04:59:31,291 valid 600 1.640728e-02 -2.607082
2019-11-02 04:59:39,990 valid 650 1.639864e-02 -2.560292
2019-11-02 04:59:48,690 valid 700 1.637172e-02 -2.551376
2019-11-02 04:59:57,359 valid 750 1.636386e-02 -2.555963
2019-11-02 05:00:06,039 valid 800 1.634225e-02 -2.559434
2019-11-02 05:00:14,715 valid 850 1.635097e-02 -2.515045
2019-11-02 05:00:23,374 valid 900 1.635055e-02 -2.503342
2019-11-02 05:00:32,029 valid 950 1.632285e-02 -2.493216
2019-11-02 05:00:40,697 valid 1000 1.631443e-02 -2.492172
2019-11-02 05:00:49,320 valid 1050 1.634707e-02 -2.473379
2019-11-02 05:00:57,963 valid 1100 1.636710e-02 -2.694660
2019-11-02 05:01:06,633 valid 1150 1.634065e-02 -2.820224
2019-11-02 05:01:15,264 valid 1200 1.634555e-02 -2.859249
2019-11-02 05:01:23,943 valid 1250 1.635877e-02 -2.916332
2019-11-02 05:01:32,606 valid 1300 1.635529e-02 -2.906339
2019-11-02 05:01:41,204 valid 1350 1.634499e-02 -2.885372
2019-11-02 05:01:49,870 valid 1400 1.634910e-02 -2.851088
2019-11-02 05:01:58,484 valid 1450 1.637122e-02 -2.816040
2019-11-02 05:02:07,093 valid 1500 1.638147e-02 -2.795069
2019-11-02 05:02:13,820 valid_acc (R^2 for regression) -9.107507
2019-11-02 05:02:13,951 epoch 9 lr 9.299476e-04
2019-11-02 05:02:13,952 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('dil_conv_5x5', 0), ('dil_conv_5x5', 1), ('max_pool_3x3', 3), ('avg_pool_3x3', 1), ('max_pool_3x3', 4), ('dil_conv_3x3', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 0), ('dil_conv_3x3', 1), ('dil_conv_5x5', 0), ('sep_conv_5x5', 4)], reduce_concat=range(2, 6))
2019-11-02 05:02:13,954 
alphas_normal = Variable containing:
 0.1271  0.1235  0.1215  0.1215  0.1220  0.1274  0.1249  0.1321
 0.1233  0.1222  0.1190  0.1183  0.1221  0.1363  0.1316  0.1271
 0.1256  0.1228  0.1204  0.1207  0.1240  0.1298  0.1264  0.1304
 0.1231  0.1252  0.1231  0.1226  0.1257  0.1250  0.1258  0.1294
 0.1234  0.1276  0.1244  0.1227  0.1252  0.1294  0.1229  0.1244
 0.1236  0.1245  0.1252  0.1252  0.1255  0.1261  0.1232  0.1268
 0.1236  0.1269  0.1272  0.1260  0.1251  0.1229  0.1238  0.1246
 0.1225  0.1270  0.1267  0.1250  0.1254  0.1253  0.1235  0.1247
 0.1237  0.1278  0.1268  0.1266  0.1277  0.1258  0.1212  0.1204
 0.1234  0.1245  0.1252  0.1254  0.1250  0.1272  0.1253  0.1239
 0.1249  0.1255  0.1242  0.1238  0.1254  0.1259  0.1248  0.1257
 0.1223  0.1274  0.1263  0.1249  0.1246  0.1238  0.1280  0.1226
 0.1224  0.1272  0.1251  0.1253  0.1239  0.1276  0.1244  0.1240
 0.1223  0.1295  0.1275  0.1281  0.1231  0.1235  0.1210  0.1249
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 05:02:13,955 
alphas_reduce = Variable containing:
 0.1264  0.1243  0.1234  0.1226  0.1223  0.1290  0.1263  0.1256
 0.1236  0.1233  0.1222  0.1204  0.1268  0.1358  0.1239  0.1239
 0.1272  0.1241  0.1239  0.1260  0.1250  0.1243  0.1265  0.1229
 0.1240  0.1252  0.1258  0.1256  0.1255  0.1282  0.1221  0.1237
 0.1240  0.1273  0.1269  0.1249  0.1232  0.1278  0.1237  0.1222
 0.1259  0.1232  0.1227  0.1245  0.1237  0.1280  0.1268  0.1252
 0.1247  0.1246  0.1238  0.1255  0.1241  0.1250  0.1278  0.1245
 0.1250  0.1274  0.1258  0.1252  0.1235  0.1253  0.1219  0.1259
 0.1242  0.1267  0.1250  0.1240  0.1260  0.1256  0.1246  0.1241
 0.1265  0.1224  0.1220  0.1257  0.1258  0.1243  0.1261  0.1272
 0.1244  0.1258  0.1252  0.1251  0.1254  0.1257  0.1245  0.1238
 0.1249  0.1251  0.1238  0.1245  0.1256  0.1263  0.1244  0.1254
 0.1247  0.1266  0.1247  0.1244  0.1248  0.1264  0.1230  0.1254
 0.1239  0.1255  0.1240  0.1242  0.1264  0.1270  0.1242  0.1248
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 05:02:17,675 train 000 1.642196e-02 -1.253233
2019-11-02 05:05:03,518 train 050 1.794786e-02 -2.735857
2019-11-02 05:07:48,231 train 100 1.745707e-02 -2.419236
2019-11-02 05:10:33,225 train 150 1.744182e-02 -2.668983
2019-11-02 05:13:16,950 train 200 1.740021e-02 -3.694853
2019-11-02 05:16:02,748 train 250 1.740081e-02 -3.387193
2019-11-02 05:18:48,064 train 300 1.745107e-02 -6.170533
2019-11-02 05:21:36,548 train 350 1.747683e-02 -5.628554
2019-11-02 05:24:21,196 train 400 1.748043e-02 -5.229301
2019-11-02 05:27:09,671 train 450 1.742043e-02 -4.959579
2019-11-02 05:29:54,473 train 500 1.735853e-02 -11.253862
2019-11-02 05:32:37,436 train 550 1.731545e-02 -10.417618
2019-11-02 05:35:21,818 train 600 1.733028e-02 -9.736499
2019-11-02 05:38:08,723 train 650 1.734450e-02 -9.181961
2019-11-02 05:40:54,718 train 700 1.733748e-02 -8.680196
2019-11-02 05:43:43,473 train 750 1.732087e-02 -8.261831
2019-11-02 05:46:33,711 train 800 1.728939e-02 -7.904827
2019-11-02 05:49:19,108 train 850 1.730033e-02 -8.517756
2019-11-02 05:52:04,752 train 900 1.728196e-02 -8.199120
2019-11-02 05:54:50,629 train 950 1.728227e-02 -7.893367
2019-11-02 05:57:37,188 train 1000 1.725120e-02 -7.602603
2019-11-02 06:00:22,645 train 1050 1.725520e-02 -7.346789
2019-11-02 06:03:11,345 train 1100 1.724524e-02 -7.230098
2019-11-02 06:05:56,463 train 1150 1.724444e-02 -7.024655
2019-11-02 06:08:41,259 train 1200 1.727303e-02 -6.832772
2019-11-02 06:11:25,838 train 1250 1.724389e-02 -6.643960
2019-11-02 06:14:11,583 train 1300 1.723890e-02 -6.737302
2019-11-02 06:16:57,480 train 1350 1.722342e-02 -6.572732
2019-11-02 06:19:43,933 train 1400 1.720763e-02 -6.462035
2019-11-02 06:22:31,558 train 1450 1.721230e-02 -6.379445
2019-11-02 06:25:14,621 train 1500 1.719966e-02 -7.213357
2019-11-02 06:27:21,439 train_acc (R^2 for regression) -7.091664
2019-11-02 06:27:21,945 valid 000 1.564142e-02 -2.499021
2019-11-02 06:27:30,650 valid 050 1.609757e-02 -3.344457
2019-11-02 06:27:39,319 valid 100 1.620751e-02 -3.836510
2019-11-02 06:27:48,023 valid 150 1.633539e-02 -3.212390
2019-11-02 06:27:56,679 valid 200 1.628178e-02 -12.808492
2019-11-02 06:28:05,345 valid 250 1.619345e-02 -10.776752
2019-11-02 06:28:13,978 valid 300 1.619316e-02 -9.365128
2019-11-02 06:28:22,641 valid 350 1.614172e-02 -8.283518
2019-11-02 06:28:31,306 valid 400 1.607273e-02 -7.537409
2019-11-02 06:28:39,958 valid 450 1.603769e-02 -6.927085
2019-11-02 06:28:48,631 valid 500 1.604219e-02 -6.495543
2019-11-02 06:28:57,266 valid 550 1.600573e-02 -6.127972
2019-11-02 06:29:05,918 valid 600 1.603646e-02 -5.771375
2019-11-02 06:29:14,563 valid 650 1.600445e-02 -5.487340
2019-11-02 06:29:23,201 valid 700 1.599436e-02 -5.252977
2019-11-02 06:29:31,884 valid 750 1.597665e-02 -5.200423
2019-11-02 06:29:40,539 valid 800 1.596014e-02 -4.994234
2019-11-02 06:29:49,196 valid 850 1.597472e-02 -4.868347
2019-11-02 06:29:57,857 valid 900 1.596621e-02 -4.722873
2019-11-02 06:30:06,542 valid 950 1.597751e-02 -4.608755
2019-11-02 06:30:15,193 valid 1000 1.597577e-02 -4.489742
2019-11-02 06:30:23,867 valid 1050 1.599525e-02 -4.381541
2019-11-02 06:30:32,523 valid 1100 1.601958e-02 -4.288398
2019-11-02 06:30:41,155 valid 1150 1.604387e-02 -4.189709
2019-11-02 06:30:49,791 valid 1200 1.603089e-02 -4.091007
2019-11-02 06:30:58,421 valid 1250 1.604074e-02 -4.012766
2019-11-02 06:31:07,096 valid 1300 1.605980e-02 -4.095868
2019-11-02 06:31:15,755 valid 1350 1.605104e-02 -4.007917
2019-11-02 06:31:24,421 valid 1400 1.603152e-02 -4.069799
2019-11-02 06:31:33,115 valid 1450 1.604957e-02 -4.003808
2019-11-02 06:31:41,753 valid 1500 1.607300e-02 -3.933035
2019-11-02 06:31:48,502 valid_acc (R^2 for regression) -3.889216
2019-11-02 06:31:48,634 epoch 10 lr 9.140576e-04
2019-11-02 06:31:48,635 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('dil_conv_5x5', 0), ('dil_conv_5x5', 1), ('max_pool_3x3', 3), ('avg_pool_3x3', 1), ('max_pool_3x3', 4), ('dil_conv_3x3', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 2), ('dil_conv_3x3', 1), ('sep_conv_5x5', 4), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-02 06:31:48,637 
alphas_normal = Variable containing:
 0.1252  0.1244  0.1231  0.1226  0.1212  0.1270  0.1225  0.1341
 0.1238  0.1216  0.1178  0.1173  0.1229  0.1380  0.1304  0.1283
 0.1258  0.1230  0.1201  0.1201  0.1271  0.1286  0.1261  0.1292
 0.1237  0.1264  0.1236  0.1229  0.1246  0.1249  0.1254  0.1285
 0.1225  0.1272  0.1240  0.1226  0.1247  0.1285  0.1245  0.1260
 0.1241  0.1254  0.1259  0.1256  0.1253  0.1264  0.1223  0.1250
 0.1233  0.1274  0.1280  0.1267  0.1239  0.1218  0.1243  0.1245
 0.1230  0.1274  0.1272  0.1258  0.1247  0.1253  0.1210  0.1257
 0.1232  0.1288  0.1278  0.1272  0.1268  0.1257  0.1207  0.1199
 0.1251  0.1246  0.1245  0.1250  0.1267  0.1267  0.1240  0.1234
 0.1240  0.1257  0.1244  0.1241  0.1266  0.1255  0.1242  0.1255
 0.1219  0.1266  0.1256  0.1240  0.1256  0.1232  0.1280  0.1251
 0.1220  0.1275  0.1251  0.1250  0.1246  0.1264  0.1255  0.1239
 0.1236  0.1285  0.1262  0.1268  0.1242  0.1261  0.1204  0.1241
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 06:31:48,639 
alphas_reduce = Variable containing:
 0.1247  0.1267  0.1254  0.1218  0.1234  0.1287  0.1247  0.1246
 0.1252  0.1226  0.1213  0.1220  0.1268  0.1323  0.1249  0.1249
 0.1247  0.1253  0.1249  0.1251  0.1256  0.1256  0.1253  0.1235
 0.1252  0.1235  0.1239  0.1255  0.1263  0.1277  0.1236  0.1242
 0.1247  0.1271  0.1259  0.1248  0.1244  0.1271  0.1241  0.1219
 0.1248  0.1248  0.1246  0.1237  0.1247  0.1271  0.1255  0.1249
 0.1258  0.1234  0.1227  0.1239  0.1252  0.1260  0.1275  0.1255
 0.1259  0.1242  0.1224  0.1239  0.1249  0.1275  0.1240  0.1271
 0.1253  0.1248  0.1229  0.1234  0.1268  0.1264  0.1253  0.1250
 0.1249  0.1249  0.1243  0.1247  0.1265  0.1235  0.1261  0.1251
 0.1259  0.1235  0.1233  0.1260  0.1258  0.1260  0.1255  0.1240
 0.1250  0.1245  0.1228  0.1241  0.1252  0.1266  0.1258  0.1260
 0.1245  0.1252  0.1236  0.1240  0.1260  0.1280  0.1239  0.1249
 0.1241  0.1252  0.1234  0.1235  0.1259  0.1284  0.1238  0.1256
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 06:31:52,163 train 000 1.733925e-02 -1.914761
2019-11-02 06:34:35,664 train 050 1.693078e-02 -3.049254
2019-11-02 06:37:19,302 train 100 1.713540e-02 -10.817767
2019-11-02 06:40:06,364 train 150 1.692759e-02 -8.333957
2019-11-02 06:42:52,127 train 200 1.689254e-02 -6.854412
2019-11-02 06:45:36,266 train 250 1.715007e-02 -5.927239
2019-11-02 06:48:17,631 train 300 1.704012e-02 -5.487862
2019-11-02 06:51:02,377 train 350 1.696543e-02 -5.059703
2019-11-02 06:53:45,237 train 400 1.695393e-02 -4.979510
2019-11-02 06:56:30,364 train 450 1.691947e-02 -4.791493
2019-11-02 06:59:11,855 train 500 1.689105e-02 -4.582010
2019-11-02 07:01:56,582 train 550 1.699270e-02 -4.744012
2019-11-02 07:04:38,335 train 600 1.695500e-02 -4.549074
2019-11-02 07:07:22,189 train 650 1.696979e-02 -4.481105
2019-11-02 07:10:05,934 train 700 1.698409e-02 -4.294740
2019-11-02 07:12:49,550 train 750 1.698361e-02 -4.138931
2019-11-02 07:15:34,836 train 800 1.696622e-02 -4.006575
2019-11-02 07:18:22,330 train 850 1.696463e-02 -3.900716
2019-11-02 07:21:05,245 train 900 1.693064e-02 -3.824932
2019-11-02 07:23:50,109 train 950 1.692108e-02 -3.726624
2019-11-02 07:26:35,190 train 1000 1.690846e-02 -3.681961
2019-11-02 07:29:18,771 train 1050 1.689183e-02 -3.604447
2019-11-02 07:32:03,941 train 1100 1.687937e-02 -4.000775
2019-11-02 07:34:47,146 train 1150 1.684873e-02 -4.601250
2019-11-02 07:37:29,068 train 1200 1.683299e-02 -4.620376
2019-11-02 07:40:15,239 train 1250 1.682323e-02 -4.534300
2019-11-02 07:42:59,626 train 1300 1.681791e-02 -4.435131
2019-11-02 07:45:45,253 train 1350 1.680773e-02 -4.359956
2019-11-02 07:48:31,037 train 1400 1.679378e-02 -4.285255
2019-11-02 07:51:15,070 train 1450 1.680646e-02 -4.224433
2019-11-02 07:53:58,156 train 1500 1.680288e-02 -4.151009
2019-11-02 07:56:06,404 train_acc (R^2 for regression) -4.103948
2019-11-02 07:56:06,846 valid 000 1.247666e-02 -1.577299
2019-11-02 07:56:15,488 valid 050 1.519365e-02 -2.523064
2019-11-02 07:56:24,112 valid 100 1.514294e-02 -2.525263
2019-11-02 07:56:32,745 valid 150 1.516762e-02 -2.354803
2019-11-02 07:56:41,387 valid 200 1.522632e-02 -2.311619
2019-11-02 07:56:50,053 valid 250 1.529487e-02 -2.396991
2019-11-02 07:56:58,678 valid 300 1.529205e-02 -2.329747
2019-11-02 07:57:07,332 valid 350 1.535424e-02 -2.272830
2019-11-02 07:57:15,902 valid 400 1.537178e-02 -2.265591
2019-11-02 07:57:24,528 valid 450 1.541585e-02 -2.302666
2019-11-02 07:57:33,140 valid 500 1.544103e-02 -2.279761
2019-11-02 07:57:41,803 valid 550 1.545759e-02 -2.620115
2019-11-02 07:57:50,484 valid 600 1.541046e-02 -2.562891
2019-11-02 07:57:59,159 valid 650 1.543241e-02 -2.512488
2019-11-02 07:58:07,831 valid 700 1.544211e-02 -2.446879
2019-11-02 07:58:16,519 valid 750 1.542981e-02 -2.438287
2019-11-02 07:58:25,166 valid 800 1.541938e-02 -2.514660
2019-11-02 07:58:33,879 valid 850 1.543649e-02 -2.452100
2019-11-02 07:58:42,569 valid 900 1.545089e-02 -2.463272
2019-11-02 07:58:51,252 valid 950 1.548015e-02 -2.425598
2019-11-02 07:58:59,914 valid 1000 1.548059e-02 -2.428032
2019-11-02 07:59:08,552 valid 1050 1.548107e-02 -2.491004
2019-11-02 07:59:17,243 valid 1100 1.546704e-02 -2.608478
2019-11-02 07:59:25,899 valid 1150 1.547878e-02 -2.583346
2019-11-02 07:59:34,599 valid 1200 1.547854e-02 -2.567266
2019-11-02 07:59:43,297 valid 1250 1.549982e-02 -2.708302
2019-11-02 07:59:52,001 valid 1300 1.550393e-02 -2.683965
2019-11-02 08:00:00,706 valid 1350 1.550071e-02 -2.695648
2019-11-02 08:00:09,367 valid 1400 1.549068e-02 -2.680008
2019-11-02 08:00:18,071 valid 1450 1.549141e-02 -5.792389
2019-11-02 08:00:26,761 valid 1500 1.551124e-02 -5.671189
2019-11-02 08:00:33,496 valid_acc (R^2 for regression) -5.735719
2019-11-02 08:00:33,627 epoch 11 lr 8.967310e-04
2019-11-02 08:00:33,628 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('dil_conv_5x5', 1), ('max_pool_3x3', 2), ('max_pool_3x3', 3), ('max_pool_3x3', 1), ('sep_conv_5x5', 3), ('max_pool_3x3', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('max_pool_3x3', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 4), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-02 08:00:33,630 
alphas_normal = Variable containing:
 0.1271  0.1247  0.1223  0.1220  0.1211  0.1288  0.1219  0.1320
 0.1227  0.1217  0.1175  0.1176  0.1266  0.1359  0.1300  0.1280
 0.1266  0.1238  0.1213  0.1213  0.1261  0.1276  0.1252  0.1280
 0.1243  0.1258  0.1237  0.1236  0.1250  0.1238  0.1256  0.1283
 0.1231  0.1282  0.1250  0.1233  0.1244  0.1273  0.1221  0.1266
 0.1247  0.1254  0.1254  0.1252  0.1256  0.1266  0.1235  0.1236
 0.1242  0.1273  0.1272  0.1265  0.1242  0.1217  0.1238  0.1251
 0.1226  0.1271  0.1260  0.1248  0.1247  0.1260  0.1237  0.1251
 0.1244  0.1277  0.1261  0.1259  0.1273  0.1269  0.1200  0.1218
 0.1245  0.1249  0.1239  0.1241  0.1255  0.1267  0.1255  0.1248
 0.1233  0.1263  0.1248  0.1245  0.1247  0.1255  0.1261  0.1248
 0.1220  0.1275  0.1255  0.1243  0.1272  0.1246  0.1259  0.1230
 0.1223  0.1266  0.1240  0.1246  0.1244  0.1288  0.1242  0.1252
 0.1229  0.1279  0.1256  0.1269  0.1242  0.1267  0.1213  0.1243
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 08:00:33,631 
alphas_reduce = Variable containing:
 0.1261  0.1267  0.1249  0.1213  0.1224  0.1291  0.1244  0.1251
 0.1237  0.1227  0.1209  0.1220  0.1260  0.1308  0.1265  0.1274
 0.1255  0.1255  0.1248  0.1222  0.1264  0.1243  0.1265  0.1248
 0.1253  0.1239  0.1243  0.1250  0.1257  0.1273  0.1238  0.1248
 0.1246  0.1270  0.1257  0.1250  0.1243  0.1271  0.1234  0.1229
 0.1251  0.1247  0.1241  0.1249  0.1253  0.1267  0.1252  0.1239
 0.1248  0.1248  0.1237  0.1240  0.1243  0.1262  0.1263  0.1258
 0.1241  0.1277  0.1254  0.1249  0.1252  0.1252  0.1226  0.1249
 0.1243  0.1261  0.1238  0.1241  0.1257  0.1243  0.1253  0.1265
 0.1257  0.1243  0.1235  0.1244  0.1259  0.1246  0.1260  0.1256
 0.1251  0.1249  0.1239  0.1234  0.1266  0.1267  0.1252  0.1242
 0.1252  0.1258  0.1234  0.1245  0.1246  0.1263  0.1245  0.1257
 0.1253  0.1251  0.1230  0.1241  0.1269  0.1271  0.1224  0.1260
 0.1249  0.1254  0.1236  0.1239  0.1261  0.1275  0.1235  0.1251
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 08:00:37,310 train 000 1.418496e-02 -4.622924
2019-11-02 08:03:22,471 train 050 1.634446e-02 -2.423974
2019-11-02 08:06:06,369 train 100 1.608911e-02 -3.418086
2019-11-02 08:08:53,037 train 150 1.613821e-02 -2.935150
2019-11-02 08:11:38,710 train 200 1.633510e-02 -8.638139
2019-11-02 08:14:22,834 train 250 1.633936e-02 -7.341363
2019-11-02 08:17:07,413 train 300 1.643612e-02 -7.435357
2019-11-02 08:19:53,673 train 350 1.643923e-02 -6.704658
2019-11-02 08:22:41,705 train 400 1.648415e-02 -6.122134
2019-11-02 08:25:25,994 train 450 1.649385e-02 -5.660772
2019-11-02 08:28:08,562 train 500 1.648205e-02 -5.286298
2019-11-02 08:30:54,965 train 550 1.647863e-02 -4.970002
2019-11-02 08:33:42,600 train 600 1.644995e-02 -4.903654
2019-11-02 08:36:26,475 train 650 1.643255e-02 -4.691825
2019-11-02 08:39:09,658 train 700 1.644728e-02 -8.891380
2019-11-02 08:42:02,300 train 750 1.647760e-02 -8.411748
2019-11-02 08:44:48,974 train 800 1.646441e-02 -8.024483
2019-11-02 08:47:36,097 train 850 1.648431e-02 -7.714613
2019-11-02 08:50:20,984 train 900 1.646379e-02 -7.396993
2019-11-02 08:53:07,598 train 950 1.647500e-02 -7.252514
2019-11-02 08:55:51,162 train 1000 1.644521e-02 -7.686334
2019-11-02 08:58:35,711 train 1050 1.643800e-02 -8.164100
2019-11-02 09:01:19,153 train 1100 1.644422e-02 -7.873626
2019-11-02 09:04:01,340 train 1150 1.644694e-02 -7.619938
2019-11-02 09:06:43,627 train 1200 1.642090e-02 -7.467194
2019-11-02 09:09:28,979 train 1250 1.643614e-02 -7.361973
2019-11-02 09:12:15,626 train 1300 1.644441e-02 -7.975905
2019-11-02 09:15:01,502 train 1350 1.644207e-02 -7.761304
2019-11-02 09:17:46,517 train 1400 1.643741e-02 -7.576768
2019-11-02 09:20:29,630 train 1450 1.642682e-02 -7.422220
2019-11-02 09:23:11,504 train 1500 1.642642e-02 -7.255981
2019-11-02 09:25:20,939 train_acc (R^2 for regression) -7.128559
2019-11-02 09:25:21,427 valid 000 1.848715e-02 -3.058049
2019-11-02 09:25:30,092 valid 050 1.587428e-02 -2.219328
2019-11-02 09:25:38,758 valid 100 1.573010e-02 -5.215321
2019-11-02 09:25:47,403 valid 150 1.571038e-02 -4.297556
2019-11-02 09:25:56,043 valid 200 1.568641e-02 -3.725685
2019-11-02 09:26:04,650 valid 250 1.571608e-02 -3.378951
2019-11-02 09:26:13,252 valid 300 1.559627e-02 -3.109469
2019-11-02 09:26:21,886 valid 350 1.567328e-02 -3.006004
2019-11-02 09:26:30,551 valid 400 1.564282e-02 -2.842798
2019-11-02 09:26:39,211 valid 450 1.568175e-02 -30.015560
2019-11-02 09:26:47,803 valid 500 1.568119e-02 -27.201139
2019-11-02 09:26:56,435 valid 550 1.569299e-02 -24.893554
2019-11-02 09:27:05,031 valid 600 1.573097e-02 -22.995003
2019-11-02 09:27:13,658 valid 650 1.566906e-02 -21.547805
2019-11-02 09:27:22,321 valid 700 1.566274e-02 -20.187159
2019-11-02 09:27:30,929 valid 750 1.563561e-02 -19.041665
2019-11-02 09:27:39,561 valid 800 1.558472e-02 -17.992480
2019-11-02 09:27:48,233 valid 850 1.555776e-02 -17.059450
2019-11-02 09:27:56,853 valid 900 1.553212e-02 -16.237000
2019-11-02 09:28:05,509 valid 950 1.551562e-02 -15.505600
2019-11-02 09:28:14,148 valid 1000 1.552136e-02 -15.038391
2019-11-02 09:28:22,773 valid 1050 1.554048e-02 -14.426433
2019-11-02 09:28:31,428 valid 1100 1.556637e-02 -13.890345
2019-11-02 09:28:40,046 valid 1150 1.555865e-02 -13.386076
2019-11-02 09:28:48,695 valid 1200 1.555974e-02 -12.943657
2019-11-02 09:28:57,346 valid 1250 1.555650e-02 -12.616672
2019-11-02 09:29:05,944 valid 1300 1.557049e-02 -12.211326
2019-11-02 09:29:14,596 valid 1350 1.553795e-02 -11.860664
2019-11-02 09:29:23,235 valid 1400 1.556416e-02 -11.518433
2019-11-02 09:29:31,839 valid 1450 1.557744e-02 -11.181999
2019-11-02 09:29:40,492 valid 1500 1.556137e-02 -10.873446
2019-11-02 09:29:47,182 valid_acc (R^2 for regression) -10.643333
2019-11-02 09:29:47,309 epoch 12 lr 8.780359e-04
2019-11-02 09:29:47,310 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('dil_conv_5x5', 1), ('max_pool_3x3', 3), ('sep_conv_5x5', 2), ('max_pool_3x3', 4), ('sep_conv_5x5', 0)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 1), ('dil_conv_3x3', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 4), ('sep_conv_5x5', 0)], reduce_concat=range(2, 6))
2019-11-02 09:29:47,312 
alphas_normal = Variable containing:
 0.1269  0.1251  0.1223  0.1218  0.1211  0.1289  0.1234  0.1305
 0.1229  0.1237  0.1197  0.1200  0.1244  0.1342  0.1274  0.1276
 0.1259  0.1232  0.1208  0.1210  0.1266  0.1299  0.1259  0.1266
 0.1237  0.1253  0.1221  0.1222  0.1244  0.1259  0.1273  0.1290
 0.1243  0.1279  0.1248  0.1239  0.1239  0.1275  0.1231  0.1246
 0.1249  0.1253  0.1252  0.1253  0.1231  0.1265  0.1242  0.1255
 0.1245  0.1261  0.1259  0.1255  0.1262  0.1239  0.1247  0.1232
 0.1227  0.1254  0.1247  0.1239  0.1254  0.1268  0.1255  0.1257
 0.1242  0.1282  0.1269  0.1266  0.1266  0.1261  0.1200  0.1214
 0.1245  0.1252  0.1247  0.1246  0.1246  0.1282  0.1241  0.1241
 0.1238  0.1259  0.1243  0.1240  0.1248  0.1250  0.1249  0.1272
 0.1229  0.1281  0.1263  0.1249  0.1270  0.1252  0.1245  0.1212
 0.1221  0.1276  0.1249  0.1247  0.1246  0.1281  0.1238  0.1242
 0.1223  0.1288  0.1263  0.1276  0.1232  0.1253  0.1210  0.1256
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 09:29:47,313 
alphas_reduce = Variable containing:
 0.1247  0.1267  0.1252  0.1226  0.1211  0.1296  0.1253  0.1248
 0.1260  0.1220  0.1204  0.1238  0.1251  0.1284  0.1270  0.1273
 0.1243  0.1260  0.1255  0.1237  0.1266  0.1243  0.1253  0.1242
 0.1251  0.1233  0.1232  0.1262  0.1259  0.1271  0.1243  0.1248
 0.1242  0.1267  0.1259  0.1244  0.1240  0.1272  0.1247  0.1228
 0.1250  0.1247  0.1237  0.1258  0.1242  0.1267  0.1257  0.1243
 0.1255  0.1237  0.1228  0.1247  0.1253  0.1260  0.1269  0.1251
 0.1259  0.1261  0.1244  0.1248  0.1252  0.1245  0.1246  0.1245
 0.1242  0.1263  0.1241  0.1241  0.1259  0.1255  0.1243  0.1256
 0.1250  0.1253  0.1248  0.1232  0.1243  0.1270  0.1258  0.1245
 0.1254  0.1231  0.1228  0.1243  0.1267  0.1268  0.1249  0.1260
 0.1254  0.1252  0.1243  0.1244  0.1238  0.1258  0.1263  0.1248
 0.1244  0.1255  0.1241  0.1239  0.1260  0.1260  0.1238  0.1265
 0.1249  0.1259  0.1243  0.1243  0.1250  0.1273  0.1234  0.1249
[torch.cuda.FloatTensor of size 14x8 (GPU 2)]

2019-11-02 09:29:50,864 train 000 2.132419e-02 -2.365199
2019-11-02 09:32:32,916 train 050 1.613715e-02 -20.356358
