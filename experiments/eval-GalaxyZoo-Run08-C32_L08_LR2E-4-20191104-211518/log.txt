2019-11-04 21:15:18,399 gpu device = 0
2019-11-04 21:15:18,399 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=64, cutout=False, cutout_length=16, data='../data', dataset='GalaxyZoo', drop_path_prob=0.5, epochs=2000, fc1_size=2048, fc2_size=2048, gpu=0, grad_clip=5, init_channels=32, layers=8, learning_rate=0.0002, model_path='saved_models', momentum=0.9, optimizer='Adam', random=False, report_freq=50, save='eval-GalaxyZoo-Run08-C32_L08_LR2E-4-20191104-211518', seed=0, val_portion=0.1, weight_decay=1e-06)
2019-11-04 21:15:21,929 param size = 6.055045MB
2019-11-04 21:15:21,933 epoch 0 lr 2.000000e-04
2019-11-04 21:15:24,513 train 000 4.052252e-02 -1.500630
2019-11-04 21:15:34,904 train 050 3.531424e-02 -816.704891
2019-11-04 21:15:45,689 train 100 3.368075e-02 -412.986258
2019-11-04 21:15:56,526 train 150 3.262958e-02 -276.581214
2019-11-04 21:16:07,211 train 200 3.190029e-02 -207.981457
2019-11-04 21:16:17,974 train 250 3.122091e-02 -166.726187
2019-11-04 21:16:28,842 train 300 3.081343e-02 -139.121555
2019-11-04 21:16:39,594 train 350 3.037764e-02 -119.403799
2019-11-04 21:16:50,343 train 400 2.992643e-02 -104.578948
2019-11-04 21:17:01,097 train 450 2.963409e-02 -93.046087
2019-11-04 21:17:11,706 train 500 2.940672e-02 -83.824463
2019-11-04 21:17:22,455 train 550 2.921519e-02 -76.288533
2019-11-04 21:17:33,247 train 600 2.901202e-02 -70.072316
2019-11-04 21:17:43,928 train 650 2.884399e-02 -64.725588
2019-11-04 21:17:54,663 train 700 2.868741e-02 -60.138653
2019-11-04 21:18:05,477 train 750 2.852732e-02 -56.173337
2019-11-04 21:18:16,135 train 800 2.837224e-02 -52.713508
2019-11-04 21:18:26,892 train 850 2.825809e-02 -49.637285
2019-11-04 21:18:30,771 training loss; R2: 2.822122e-02 -48.788886
2019-11-04 21:18:31,405 valid 000 2.412931e-02 -0.145576
2019-11-04 21:18:42,198 valid 050 2.398841e-02 -0.514055
2019-11-04 21:18:51,817 validation loss; R2: 2.416328e-02 -0.497628
2019-11-04 21:18:51,862 epoch 1 lr 2.000000e-04
2019-11-04 21:18:52,679 train 000 2.526726e-02 -0.492172
2019-11-04 21:19:03,677 train 050 2.623709e-02 -0.455702
2019-11-04 21:19:14,682 train 100 2.609525e-02 -0.599225
2019-11-04 21:19:25,372 train 150 2.609587e-02 -0.524637
2019-11-04 21:19:36,076 train 200 2.607142e-02 -16.522004
2019-11-04 21:19:46,696 train 250 2.606469e-02 -13.321347
2019-11-04 21:19:57,391 train 300 2.592949e-02 -11.195710
2019-11-04 21:20:08,182 train 350 2.586274e-02 -9.723409
2019-11-04 21:20:18,907 train 400 2.575604e-02 -8.583103
2019-11-04 21:20:29,609 train 450 2.565867e-02 -7.691012
2019-11-04 21:20:40,335 train 500 2.559859e-02 -6.964879
2019-11-04 21:20:51,113 train 550 2.558819e-02 -6.373299
2019-11-04 21:21:01,922 train 600 2.560321e-02 -5.893187
2019-11-04 21:21:12,715 train 650 2.557221e-02 -5.506890
2019-11-04 21:21:23,489 train 700 2.553533e-02 -5.153775
2019-11-04 21:21:34,238 train 750 2.551555e-02 -4.845419
2019-11-04 21:21:45,069 train 800 2.553354e-02 -4.571835
2019-11-04 21:21:55,866 train 850 2.550901e-02 -4.339523
2019-11-04 21:21:59,038 training loss; R2: 2.550988e-02 -4.277199
2019-11-04 21:21:59,587 valid 000 2.141335e-02 -1.573447
2019-11-04 21:22:10,289 valid 050 2.321428e-02 -0.585860
2019-11-04 21:22:19,693 validation loss; R2: 2.336704e-02 -0.679666
2019-11-04 21:22:19,753 epoch 2 lr 2.000000e-04
2019-11-04 21:22:20,483 train 000 2.988278e-02 -0.100498
2019-11-04 21:22:31,281 train 050 2.539044e-02 -0.610647
2019-11-04 21:22:42,179 train 100 2.500962e-02 -0.564678
2019-11-04 21:22:52,977 train 150 2.521087e-02 -0.532716
2019-11-04 21:23:03,736 train 200 2.508951e-02 -0.517542
2019-11-04 21:23:14,531 train 250 2.519392e-02 -0.595833
2019-11-04 21:23:25,442 train 300 2.519540e-02 -0.580769
2019-11-04 21:23:36,280 train 350 2.520683e-02 -0.560757
2019-11-04 21:23:47,268 train 400 2.516235e-02 -0.622585
2019-11-04 21:23:58,254 train 450 2.518093e-02 -0.621145
2019-11-04 21:24:09,253 train 500 2.513457e-02 -0.621175
2019-11-04 21:24:20,197 train 550 2.507223e-02 -0.989969
2019-11-04 21:24:31,193 train 600 2.504286e-02 -0.954304
2019-11-04 21:24:42,164 train 650 2.498387e-02 -0.918400
2019-11-04 21:24:53,129 train 700 2.498542e-02 -0.888139
2019-11-04 21:25:04,020 train 750 2.496509e-02 -0.861962
2019-11-04 21:25:14,822 train 800 2.496311e-02 -0.842346
2019-11-04 21:25:25,672 train 850 2.492553e-02 -0.824536
2019-11-04 21:25:28,944 training loss; R2: 2.493025e-02 -0.816394
2019-11-04 21:25:29,510 valid 000 2.303983e-02 -0.184020
2019-11-04 21:25:40,228 valid 050 2.249841e-02 -0.514218
2019-11-04 21:25:49,649 validation loss; R2: 2.280116e-02 -0.584335
2019-11-04 21:25:49,715 epoch 3 lr 2.000000e-04
2019-11-04 21:25:50,398 train 000 2.899339e-02 -0.628557
2019-11-04 21:26:01,228 train 050 2.488626e-02 -0.521345
2019-11-04 21:26:12,122 train 100 2.510628e-02 -0.442006
2019-11-04 21:26:22,906 train 150 2.505046e-02 -0.557506
2019-11-04 21:26:33,606 train 200 2.508306e-02 -0.539696
2019-11-04 21:26:44,427 train 250 2.505829e-02 -0.535185
2019-11-04 21:26:55,294 train 300 2.500906e-02 -0.531534
2019-11-04 21:27:06,148 train 350 2.493082e-02 -0.537380
2019-11-04 21:27:16,876 train 400 2.482580e-02 -0.539538
2019-11-04 21:27:27,577 train 450 2.480942e-02 -0.551273
2019-11-04 21:27:38,316 train 500 2.475831e-02 -0.564992
2019-11-04 21:27:49,121 train 550 2.469319e-02 -0.578178
2019-11-04 21:27:59,918 train 600 2.467804e-02 -0.578876
2019-11-04 21:28:10,718 train 650 2.469765e-02 -0.569352
2019-11-04 21:28:21,406 train 700 2.466179e-02 -0.586303
2019-11-04 21:28:32,272 train 750 2.461535e-02 -0.591688
2019-11-04 21:28:43,010 train 800 2.458050e-02 -0.579359
2019-11-04 21:28:53,849 train 850 2.455989e-02 -0.579081
2019-11-04 21:28:57,034 training loss; R2: 2.455799e-02 -0.575880
2019-11-04 21:28:57,657 valid 000 2.157890e-02 -0.973261
2019-11-04 21:29:08,397 valid 050 2.135287e-02 -0.428192
2019-11-04 21:29:17,849 validation loss; R2: 2.145402e-02 -0.384144
2019-11-04 21:29:17,916 epoch 4 lr 2.000000e-04
2019-11-04 21:29:18,610 train 000 2.304118e-02 -0.235469
2019-11-04 21:29:29,511 train 050 2.390087e-02 -0.478557
2019-11-04 21:29:40,394 train 100 2.433850e-02 -0.450130
2019-11-04 21:29:50,967 train 150 2.427264e-02 -0.487031
2019-11-04 21:30:01,428 train 200 2.410657e-02 -0.600506
2019-11-04 21:30:12,074 train 250 2.411252e-02 -0.589132
2019-11-04 21:30:22,640 train 300 2.401123e-02 -0.574405
2019-11-04 21:30:33,310 train 350 2.395910e-02 -0.582783
2019-11-04 21:30:44,073 train 400 2.386777e-02 -0.609446
2019-11-04 21:30:54,770 train 450 2.381740e-02 -0.581561
2019-11-04 21:31:05,522 train 500 2.383249e-02 -0.581622
2019-11-04 21:31:16,235 train 550 2.388056e-02 -0.568919
2019-11-04 21:31:26,981 train 600 2.390503e-02 -0.570193
2019-11-04 21:31:37,716 train 650 2.387749e-02 -0.573504
2019-11-04 21:31:48,473 train 700 2.388215e-02 -0.582130
2019-11-04 21:31:59,245 train 750 2.390521e-02 -0.594890
2019-11-04 21:32:09,982 train 800 2.389508e-02 -0.595256
2019-11-04 21:32:20,740 train 850 2.385919e-02 -0.594794
2019-11-04 21:32:23,918 training loss; R2: 2.385127e-02 -0.592801
2019-11-04 21:32:24,475 valid 000 2.864999e-02 -1.162602
2019-11-04 21:32:35,104 valid 050 2.262176e-02 -0.680964
2019-11-04 21:32:44,623 validation loss; R2: 2.282760e-02 -0.790776
2019-11-04 21:32:44,699 epoch 5 lr 2.000000e-04
2019-11-04 21:32:45,448 train 000 2.364784e-02 -2.116325
2019-11-04 21:32:56,201 train 050 2.384800e-02 -0.629112
2019-11-04 21:33:07,005 train 100 2.364942e-02 -0.620709
2019-11-04 21:33:17,681 train 150 2.360833e-02 -0.587151
2019-11-04 21:33:28,316 train 200 2.356244e-02 -0.556445
2019-11-04 21:33:39,065 train 250 2.353439e-02 -0.743488
2019-11-04 21:33:49,865 train 300 2.353341e-02 -0.736201
2019-11-04 21:34:00,678 train 350 2.343156e-02 -0.710103
2019-11-04 21:34:11,400 train 400 2.339172e-02 -0.697424
2019-11-04 21:34:22,141 train 450 2.334018e-02 -0.668371
2019-11-04 21:34:32,956 train 500 2.327355e-02 -0.664429
2019-11-04 21:34:43,717 train 550 2.325668e-02 -0.648718
2019-11-04 21:34:54,401 train 600 2.326009e-02 -0.635917
2019-11-04 21:35:05,122 train 650 2.325737e-02 -0.625582
2019-11-04 21:35:15,903 train 700 2.324342e-02 -0.621566
2019-11-04 21:35:26,692 train 750 2.325901e-02 -0.616333
2019-11-04 21:35:37,462 train 800 2.328893e-02 -0.613417
2019-11-04 21:35:48,286 train 850 2.331364e-02 -0.605148
2019-11-04 21:35:51,452 training loss; R2: 2.330092e-02 -0.604579
2019-11-04 21:35:52,050 valid 000 1.765450e-02 -0.500218
2019-11-04 21:36:02,668 valid 050 1.991503e-02 -0.536836
2019-11-04 21:36:12,002 validation loss; R2: 1.963648e-02 -0.649018
2019-11-04 21:36:12,068 epoch 6 lr 2.000000e-04
2019-11-04 21:36:12,801 train 000 2.176411e-02 -0.264880
2019-11-04 21:36:23,583 train 050 2.323853e-02 -0.456064
2019-11-04 21:36:34,362 train 100 2.323082e-02 -0.504262
2019-11-04 21:36:45,166 train 150 2.318556e-02 -0.546140
2019-11-04 21:36:55,944 train 200 2.312297e-02 -0.521824
2019-11-04 21:37:06,945 train 250 2.307521e-02 -0.536968
2019-11-04 21:37:17,847 train 300 2.297934e-02 -0.568987
2019-11-04 21:37:28,701 train 350 2.291018e-02 -0.589115
2019-11-04 21:37:39,621 train 400 2.289303e-02 -0.569796
2019-11-04 21:37:50,460 train 450 2.282615e-02 -0.554968
2019-11-04 21:38:01,323 train 500 2.278026e-02 -0.562826
2019-11-04 21:38:12,199 train 550 2.276648e-02 -0.558373
2019-11-04 21:38:23,096 train 600 2.274779e-02 -0.555803
2019-11-04 21:38:33,969 train 650 2.276081e-02 -0.558623
2019-11-04 21:38:44,794 train 700 2.277058e-02 -0.579555
2019-11-04 21:38:55,680 train 750 2.278435e-02 -0.588459
2019-11-04 21:39:06,536 train 800 2.281737e-02 -0.589802
2019-11-04 21:39:17,421 train 850 2.281670e-02 -0.598773
2019-11-04 21:39:20,636 training loss; R2: 2.282889e-02 -0.597425
2019-11-04 21:39:21,226 valid 000 1.563535e-02 -0.407639
2019-11-04 21:39:31,910 valid 050 1.927701e-02 -0.359401
2019-11-04 21:39:41,285 validation loss; R2: 1.935094e-02 -0.391570
2019-11-04 21:39:41,354 epoch 7 lr 2.000000e-04
2019-11-04 21:39:42,108 train 000 2.011590e-02 -0.447881
2019-11-04 21:39:52,707 train 050 2.234731e-02 -0.446150
2019-11-04 21:40:03,433 train 100 2.244632e-02 -0.540761
2019-11-04 21:40:14,054 train 150 2.259738e-02 -0.567133
2019-11-04 21:40:24,776 train 200 2.256480e-02 -0.571727
2019-11-04 21:40:35,563 train 250 2.259695e-02 -0.541147
2019-11-04 21:40:46,192 train 300 2.258383e-02 -0.552196
2019-11-04 21:40:56,819 train 350 2.259958e-02 -0.539508
2019-11-04 21:41:07,448 train 400 2.257527e-02 -0.545951
2019-11-04 21:41:18,077 train 450 2.254632e-02 -0.539377
2019-11-04 21:41:28,715 train 500 2.250986e-02 -0.556252
2019-11-04 21:41:39,334 train 550 2.249683e-02 -0.583522
2019-11-04 21:41:49,987 train 600 2.249516e-02 -0.576361
2019-11-04 21:42:00,680 train 650 2.249303e-02 -0.586317
2019-11-04 21:42:11,345 train 700 2.249101e-02 -0.584484
2019-11-04 21:42:22,035 train 750 2.247677e-02 -0.590352
2019-11-04 21:42:32,663 train 800 2.247079e-02 -0.579679
2019-11-04 21:42:43,324 train 850 2.248190e-02 -0.574740
2019-11-04 21:42:46,547 training loss; R2: 2.248695e-02 -0.570548
2019-11-04 21:42:47,153 valid 000 1.949398e-02 0.072023
2019-11-04 21:42:57,819 valid 050 1.920578e-02 -0.296800
2019-11-04 21:43:07,560 validation loss; R2: 1.903574e-02 -0.309287
2019-11-04 21:43:07,625 epoch 8 lr 2.000000e-04
2019-11-04 21:43:08,459 train 000 2.099571e-02 -0.512909
2019-11-04 21:43:19,396 train 050 2.249265e-02 -0.474960
2019-11-04 21:43:30,263 train 100 2.249166e-02 -0.522731
2019-11-04 21:43:41,233 train 150 2.240347e-02 -0.479087
2019-11-04 21:43:52,092 train 200 2.244585e-02 -0.557578
2019-11-04 21:44:02,927 train 250 2.236820e-02 -0.545588
2019-11-04 21:44:13,846 train 300 2.239807e-02 -0.532456
2019-11-04 21:44:24,830 train 350 2.232467e-02 -0.539576
2019-11-04 21:44:35,792 train 400 2.225433e-02 -0.560977
2019-11-04 21:44:46,621 train 450 2.226097e-02 -0.566389
2019-11-04 21:44:57,451 train 500 2.224338e-02 -0.618856
2019-11-04 21:45:08,303 train 550 2.224237e-02 -0.603195
2019-11-04 21:45:19,213 train 600 2.218921e-02 -0.588249
2019-11-04 21:45:30,014 train 650 2.219046e-02 -0.611745
2019-11-04 21:45:40,901 train 700 2.216836e-02 -0.607813
2019-11-04 21:45:51,846 train 750 2.213744e-02 -0.600636
2019-11-04 21:46:02,667 train 800 2.216002e-02 -0.603571
2019-11-04 21:46:13,444 train 850 2.213093e-02 -1.044535
2019-11-04 21:46:16,737 training loss; R2: 2.212878e-02 -1.040605
2019-11-04 21:46:17,347 valid 000 1.850502e-02 -2.254362
2019-11-04 21:46:28,024 valid 050 1.858640e-02 -0.421080
2019-11-04 21:46:37,631 validation loss; R2: 1.852434e-02 -0.610868
2019-11-04 21:46:37,700 epoch 9 lr 2.000000e-04
2019-11-04 21:46:38,465 train 000 2.012271e-02 -0.491707
2019-11-04 21:46:49,417 train 050 2.174533e-02 -0.750538
2019-11-04 21:47:00,334 train 100 2.192684e-02 -0.632119
2019-11-04 21:47:11,074 train 150 2.180060e-02 -0.583767
2019-11-04 21:47:21,830 train 200 2.193416e-02 -0.537379
2019-11-04 21:47:32,722 train 250 2.196105e-02 -0.579088
2019-11-04 21:47:43,657 train 300 2.191117e-02 -0.571871
2019-11-04 21:47:54,580 train 350 2.194523e-02 -0.692226
2019-11-04 21:48:05,490 train 400 2.190323e-02 -0.682294
2019-11-04 21:48:16,380 train 450 2.184456e-02 -0.675847
2019-11-04 21:48:27,235 train 500 2.184244e-02 -0.656531
2019-11-04 21:48:38,091 train 550 2.186118e-02 -0.637745
2019-11-04 21:48:48,983 train 600 2.186388e-02 -0.625837
2019-11-04 21:48:59,787 train 650 2.186827e-02 -0.623591
2019-11-04 21:49:10,434 train 700 2.187993e-02 -0.633974
2019-11-04 21:49:21,099 train 750 2.187845e-02 -0.637349
2019-11-04 21:49:31,767 train 800 2.185512e-02 -0.633125
2019-11-04 21:49:42,394 train 850 2.185495e-02 -0.631430
2019-11-04 21:49:45,581 training loss; R2: 2.185519e-02 -0.636709
2019-11-04 21:49:46,184 valid 000 1.566030e-02 -0.314593
2019-11-04 21:49:56,798 valid 050 1.825943e-02 -0.360383
2019-11-04 21:50:06,413 validation loss; R2: 1.824928e-02 -0.451021
2019-11-04 21:50:06,480 epoch 10 lr 2.000000e-04
2019-11-04 21:50:07,231 train 000 2.131562e-02 -0.153519
2019-11-04 21:50:17,955 train 050 2.133686e-02 -0.489854
2019-11-04 21:50:28,825 train 100 2.152001e-02 -2.034646
2019-11-04 21:50:39,556 train 150 2.162075e-02 -1.593432
2019-11-04 21:50:50,275 train 200 2.168780e-02 -1.349456
2019-11-04 21:51:01,034 train 250 2.164417e-02 -1.194881
2019-11-04 21:51:11,768 train 300 2.158876e-02 -1.088831
2019-11-04 21:51:22,595 train 350 2.155271e-02 -1.038641
2019-11-04 21:51:33,275 train 400 2.162085e-02 -0.966880
2019-11-04 21:51:44,072 train 450 2.162262e-02 -0.910911
2019-11-04 21:51:54,787 train 500 2.165843e-02 -0.879990
2019-11-04 21:52:05,603 train 550 2.163838e-02 -0.862253
2019-11-04 21:52:16,451 train 600 2.161334e-02 -0.823737
2019-11-04 21:52:27,198 train 650 2.161417e-02 -0.796001
2019-11-04 21:52:38,008 train 700 2.161217e-02 -0.780249
2019-11-04 21:52:48,782 train 750 2.160309e-02 -0.761705
2019-11-04 21:52:59,609 train 800 2.156487e-02 -0.744121
2019-11-04 21:53:10,431 train 850 2.156362e-02 -0.725766
2019-11-04 21:53:13,600 training loss; R2: 2.155081e-02 -0.719627
2019-11-04 21:53:14,178 valid 000 1.723099e-02 0.030366
2019-11-04 21:53:24,838 valid 050 1.733258e-02 -0.775098
2019-11-04 21:53:34,609 validation loss; R2: 1.750938e-02 -0.718142
2019-11-04 21:53:34,674 epoch 11 lr 2.000000e-04
2019-11-04 21:53:35,399 train 000 1.994630e-02 -0.093139
2019-11-04 21:53:46,247 train 050 2.133693e-02 -0.886945
2019-11-04 21:53:57,157 train 100 2.145114e-02 -0.837663
2019-11-04 21:54:07,737 train 150 2.145409e-02 -0.801170
2019-11-04 21:54:18,325 train 200 2.137851e-02 -0.819818
2019-11-04 21:54:29,081 train 250 2.135275e-02 -0.750407
2019-11-04 21:54:39,770 train 300 2.132075e-02 -1.978760
2019-11-04 21:54:50,449 train 350 2.134018e-02 -1.774679
2019-11-04 21:55:01,192 train 400 2.139494e-02 -1.618501
2019-11-04 21:55:11,916 train 450 2.138731e-02 -1.506533
2019-11-04 21:55:22,625 train 500 2.139422e-02 -1.412444
2019-11-04 21:55:33,376 train 550 2.139653e-02 -1.330593
2019-11-04 21:55:44,138 train 600 2.139051e-02 -1.256179
2019-11-04 21:55:54,890 train 650 2.138405e-02 -1.192450
2019-11-04 21:56:05,626 train 700 2.138601e-02 -1.159392
2019-11-04 21:56:16,397 train 750 2.137497e-02 -1.117168
2019-11-04 21:56:27,142 train 800 2.136696e-02 -1.085392
2019-11-04 21:56:37,850 train 850 2.135847e-02 -1.063422
2019-11-04 21:56:41,066 training loss; R2: 2.134561e-02 -1.058505
2019-11-04 21:56:41,622 valid 000 1.864007e-02 -0.082849
2019-11-04 21:56:52,211 valid 050 1.790797e-02 -0.687305
2019-11-04 21:57:01,536 validation loss; R2: 1.751449e-02 -0.809864
2019-11-04 21:57:01,604 epoch 12 lr 2.000000e-04
2019-11-04 21:57:02,342 train 000 1.981567e-02 -0.399816
2019-11-04 21:57:13,127 train 050 2.122812e-02 -0.530808
2019-11-04 21:57:23,870 train 100 2.139212e-02 -0.598342
2019-11-04 21:57:34,630 train 150 2.141449e-02 -0.582349
2019-11-04 21:57:45,376 train 200 2.119303e-02 -0.576715
2019-11-04 21:57:56,231 train 250 2.117954e-02 -0.585640
2019-11-04 21:58:06,954 train 300 2.113737e-02 -0.591290
2019-11-04 21:58:17,845 train 350 2.109242e-02 -0.608036
2019-11-04 21:58:28,651 train 400 2.112211e-02 -0.611066
2019-11-04 21:58:39,362 train 450 2.117164e-02 -0.582228
2019-11-04 21:58:50,175 train 500 2.110543e-02 -0.572020
2019-11-04 21:59:00,972 train 550 2.112805e-02 -0.587148
2019-11-04 21:59:11,732 train 600 2.114770e-02 -0.589981
2019-11-04 21:59:22,500 train 650 2.114658e-02 -0.598869
2019-11-04 21:59:33,245 train 700 2.114442e-02 -0.589895
2019-11-04 21:59:44,032 train 750 2.112509e-02 -0.609287
2019-11-04 21:59:54,863 train 800 2.112709e-02 -0.602623
2019-11-04 22:00:05,669 train 850 2.109858e-02 -0.602337
2019-11-04 22:00:08,916 training loss; R2: 2.109448e-02 -0.599326
2019-11-04 22:00:09,515 valid 000 1.789437e-02 0.006553
2019-11-04 22:00:20,263 valid 050 1.757204e-02 -0.406189
2019-11-04 22:00:29,725 validation loss; R2: 1.740736e-02 -0.396126
2019-11-04 22:00:29,792 epoch 13 lr 2.000000e-04
2019-11-04 22:00:30,533 train 000 1.994018e-02 -0.147924
2019-11-04 22:00:41,514 train 050 2.082915e-02 -0.380666
2019-11-04 22:00:52,453 train 100 2.082216e-02 -0.451134
2019-11-04 22:01:02,969 train 150 2.104458e-02 -0.525844
2019-11-04 22:01:13,455 train 200 2.104087e-02 -0.537638
2019-11-04 22:01:23,939 train 250 2.108333e-02 -0.557871
2019-11-04 22:01:34,621 train 300 2.103115e-02 -0.557778
2019-11-04 22:01:45,364 train 350 2.105069e-02 -0.573105
2019-11-04 22:01:55,934 train 400 2.105922e-02 -0.610035
2019-11-04 22:02:06,493 train 450 2.098572e-02 -0.593155
2019-11-04 22:02:17,190 train 500 2.093294e-02 -0.603594
2019-11-04 22:02:27,948 train 550 2.096029e-02 -0.586621
2019-11-04 22:02:38,688 train 600 2.095114e-02 -0.597119
2019-11-04 22:02:49,439 train 650 2.100133e-02 -0.588547
2019-11-04 22:03:00,190 train 700 2.099454e-02 -0.670133
2019-11-04 22:03:10,937 train 750 2.097866e-02 -0.664972
2019-11-04 22:03:21,674 train 800 2.098784e-02 -0.663123
2019-11-04 22:03:32,401 train 850 2.097334e-02 -0.649559
2019-11-04 22:03:35,623 training loss; R2: 2.097610e-02 -0.645351
2019-11-04 22:03:36,257 valid 000 1.652195e-02 -0.101840
2019-11-04 22:03:46,768 valid 050 1.712990e-02 -0.721738
2019-11-04 22:03:56,269 validation loss; R2: 1.701915e-02 -0.584677
2019-11-04 22:03:56,336 epoch 14 lr 2.000000e-04
2019-11-04 22:03:57,052 train 000 2.048628e-02 -0.707348
2019-11-04 22:04:08,014 train 050 2.104506e-02 -0.562320
2019-11-04 22:04:18,869 train 100 2.078660e-02 -0.687046
2019-11-04 22:04:29,503 train 150 2.085802e-02 -0.631151
2019-11-04 22:04:40,089 train 200 2.078959e-02 -0.615334
2019-11-04 22:04:50,916 train 250 2.072578e-02 -0.951679
2019-11-04 22:05:01,819 train 300 2.069081e-02 -0.892387
2019-11-04 22:05:12,747 train 350 2.063718e-02 -0.846911
2019-11-04 22:05:23,600 train 400 2.069379e-02 -0.815753
2019-11-04 22:05:34,545 train 450 2.071012e-02 -0.783895
2019-11-04 22:05:45,509 train 500 2.074267e-02 -0.750824
2019-11-04 22:05:56,450 train 550 2.075918e-02 -0.737449
2019-11-04 22:06:07,383 train 600 2.071947e-02 -0.714784
2019-11-04 22:06:18,320 train 650 2.073166e-02 -0.695670
2019-11-04 22:06:29,251 train 700 2.073658e-02 -0.679045
2019-11-04 22:06:40,081 train 750 2.078120e-02 -0.673964
2019-11-04 22:06:50,922 train 800 2.075573e-02 -0.679460
2019-11-04 22:07:01,773 train 850 2.077490e-02 -0.673312
2019-11-04 22:07:05,018 training loss; R2: 2.077565e-02 -0.668310
2019-11-04 22:07:05,582 valid 000 1.682823e-02 -0.177895
2019-11-04 22:07:16,238 valid 050 1.740093e-02 -0.728614
2019-11-04 22:07:25,664 validation loss; R2: 1.728164e-02 -0.711544
2019-11-04 22:07:25,745 epoch 15 lr 2.000000e-04
2019-11-04 22:07:26,520 train 000 2.123626e-02 -1.287074
2019-11-04 22:07:37,459 train 050 2.085802e-02 -0.897460
2019-11-04 22:07:48,422 train 100 2.083012e-02 -0.922582
2019-11-04 22:07:59,063 train 150 2.078179e-02 -0.798865
2019-11-04 22:08:09,603 train 200 2.078574e-02 -0.748173
2019-11-04 22:08:20,133 train 250 2.076079e-02 -0.721552
2019-11-04 22:08:30,655 train 300 2.076155e-02 -0.711501
2019-11-04 22:08:41,264 train 350 2.071557e-02 -0.684554
2019-11-04 22:08:51,815 train 400 2.073872e-02 -0.717880
2019-11-04 22:09:02,354 train 450 2.073288e-02 -0.712888
2019-11-04 22:09:12,893 train 500 2.074301e-02 -0.695458
2019-11-04 22:09:23,434 train 550 2.074547e-02 -0.694550
2019-11-04 22:09:34,149 train 600 2.072358e-02 -0.673114
2019-11-04 22:09:44,794 train 650 2.069502e-02 -0.690839
2019-11-04 22:09:55,605 train 700 2.066817e-02 -0.670904
2019-11-04 22:10:06,178 train 750 2.067368e-02 -0.664088
2019-11-04 22:10:16,838 train 800 2.068307e-02 -0.666225
2019-11-04 22:10:27,384 train 850 2.065773e-02 -0.661451
2019-11-04 22:10:30,524 training loss; R2: 2.065301e-02 -0.659803
2019-11-04 22:10:31,076 valid 000 1.866459e-02 -0.283471
2019-11-04 22:10:41,583 valid 050 1.797528e-02 -0.352436
2019-11-04 22:10:50,872 validation loss; R2: 1.816311e-02 -0.348798
2019-11-04 22:10:50,945 epoch 16 lr 2.000000e-04
2019-11-04 22:10:51,666 train 000 2.059837e-02 0.031428
2019-11-04 22:11:02,426 train 050 2.088075e-02 -0.511041
2019-11-04 22:11:13,187 train 100 2.059099e-02 -0.548630
2019-11-04 22:11:23,836 train 150 2.043185e-02 -0.656538
2019-11-04 22:11:34,395 train 200 2.043491e-02 -0.640216
2019-11-04 22:11:45,110 train 250 2.050276e-02 -0.663200
2019-11-04 22:11:55,983 train 300 2.045859e-02 -0.643632
2019-11-04 22:12:06,830 train 350 2.054457e-02 -0.619233
2019-11-04 22:12:17,681 train 400 2.048750e-02 -0.621823
2019-11-04 22:12:28,576 train 450 2.050950e-02 -0.612892
2019-11-04 22:12:39,511 train 500 2.052897e-02 -0.616560
2019-11-04 22:12:50,403 train 550 2.051876e-02 -0.630766
2019-11-04 22:13:01,281 train 600 2.050910e-02 -0.616173
2019-11-04 22:13:12,147 train 650 2.048630e-02 -0.614488
2019-11-04 22:13:22,999 train 700 2.048219e-02 -0.605841
2019-11-04 22:13:33,854 train 750 2.044382e-02 -0.603573
2019-11-04 22:13:44,720 train 800 2.041045e-02 -0.613875
2019-11-04 22:13:55,623 train 850 2.040962e-02 -0.611404
2019-11-04 22:13:58,874 training loss; R2: 2.042242e-02 -0.607973
2019-11-04 22:13:59,475 valid 000 1.742709e-02 -0.212506
2019-11-04 22:14:10,117 valid 050 1.672631e-02 -0.463687
2019-11-04 22:14:19,648 validation loss; R2: 1.673956e-02 -0.592866
2019-11-04 22:14:19,729 epoch 17 lr 2.000000e-04
2019-11-04 22:14:20,497 train 000 1.760391e-02 -0.202660
2019-11-04 22:14:31,359 train 050 2.037289e-02 -0.545951
2019-11-04 22:14:42,268 train 100 2.036697e-02 -0.531713
2019-11-04 22:14:52,952 train 150 2.041579e-02 -0.539774
2019-11-04 22:15:03,529 train 200 2.033881e-02 -0.603574
2019-11-04 22:15:14,039 train 250 2.046225e-02 -0.613305
2019-11-04 22:15:24,564 train 300 2.046701e-02 -0.594831
2019-11-04 22:15:35,101 train 350 2.038920e-02 -0.600497
2019-11-04 22:15:45,611 train 400 2.033456e-02 -0.578613
2019-11-04 22:15:56,082 train 450 2.031929e-02 -0.601829
2019-11-04 22:16:06,705 train 500 2.032248e-02 -0.597428
2019-11-04 22:16:17,293 train 550 2.030564e-02 -0.594500
2019-11-04 22:16:27,962 train 600 2.027771e-02 -0.615375
2019-11-04 22:16:38,588 train 650 2.027324e-02 -0.636967
2019-11-04 22:16:49,229 train 700 2.030596e-02 -0.620734
2019-11-04 22:16:59,884 train 750 2.029348e-02 -0.686165
2019-11-04 22:17:10,445 train 800 2.025939e-02 -0.678283
2019-11-04 22:17:21,166 train 850 2.022659e-02 -0.667534
2019-11-04 22:17:24,435 training loss; R2: 2.023742e-02 -0.665872
2019-11-04 22:17:25,009 valid 000 1.455343e-02 -1.339945
2019-11-04 22:17:35,614 valid 050 1.636184e-02 -0.785426
2019-11-04 22:17:44,930 validation loss; R2: 1.653172e-02 -0.757484
2019-11-04 22:17:45,003 epoch 18 lr 2.000000e-04
2019-11-04 22:17:45,735 train 000 2.294732e-02 -0.033865
2019-11-04 22:17:56,418 train 050 1.976085e-02 -0.625509
2019-11-04 22:18:07,125 train 100 1.990637e-02 -0.574895
2019-11-04 22:18:17,794 train 150 1.992033e-02 -0.582489
2019-11-04 22:18:28,344 train 200 2.004829e-02 -0.568004
2019-11-04 22:18:38,853 train 250 2.011846e-02 -0.579327
2019-11-04 22:18:49,634 train 300 2.014759e-02 -0.539302
2019-11-04 22:19:00,419 train 350 2.022591e-02 -0.536848
2019-11-04 22:19:11,178 train 400 2.020801e-02 -0.549396
2019-11-04 22:19:21,808 train 450 2.020540e-02 -1.887168
2019-11-04 22:19:32,455 train 500 2.024737e-02 -1.764289
2019-11-04 22:19:43,150 train 550 2.026214e-02 -1.652866
2019-11-04 22:19:53,887 train 600 2.021301e-02 -1.558061
2019-11-04 22:20:04,671 train 650 2.021999e-02 -1.519285
2019-11-04 22:20:15,409 train 700 2.021345e-02 -1.452566
2019-11-04 22:20:26,129 train 750 2.022408e-02 -1.430461
2019-11-04 22:20:36,888 train 800 2.019004e-02 -1.384818
2019-11-04 22:20:47,643 train 850 2.016185e-02 -1.337329
2019-11-04 22:20:50,883 training loss; R2: 2.014884e-02 -1.327094
2019-11-04 22:20:51,455 valid 000 1.355417e-02 -0.097907
2019-11-04 22:21:02,100 valid 050 1.562404e-02 -0.893816
2019-11-04 22:21:11,480 validation loss; R2: 1.557242e-02 -0.927044
2019-11-04 22:21:11,547 epoch 19 lr 2.000000e-04
2019-11-04 22:21:12,305 train 000 1.982775e-02 -1.037103
2019-11-04 22:21:23,040 train 050 1.966443e-02 -0.697330
2019-11-04 22:21:33,842 train 100 1.972096e-02 -0.747677
2019-11-04 22:21:44,623 train 150 1.977511e-02 -0.737334
2019-11-04 22:21:55,311 train 200 1.986468e-02 -0.719435
2019-11-04 22:22:05,876 train 250 1.990377e-02 -0.678499
2019-11-04 22:22:16,535 train 300 1.993042e-02 -0.685925
2019-11-04 22:22:27,283 train 350 1.993656e-02 -0.693124
2019-11-04 22:22:38,065 train 400 1.991699e-02 -0.698627
2019-11-04 22:22:48,836 train 450 1.991724e-02 -0.681914
2019-11-04 22:22:59,609 train 500 1.996596e-02 -0.677422
2019-11-04 22:23:10,364 train 550 2.003086e-02 -0.687789
2019-11-04 22:23:21,088 train 600 2.005085e-02 -0.666090
2019-11-04 22:23:31,820 train 650 2.000914e-02 -0.667804
2019-11-04 22:23:42,562 train 700 2.001362e-02 -0.656104
2019-11-04 22:23:53,307 train 750 2.000429e-02 -0.687851
2019-11-04 22:24:04,071 train 800 1.998563e-02 -0.686733
2019-11-04 22:24:14,833 train 850 1.998112e-02 -0.684441
2019-11-04 22:24:18,062 training loss; R2: 1.998003e-02 -0.679909
2019-11-04 22:24:18,620 valid 000 1.847043e-02 -0.160354
2019-11-04 22:24:29,177 valid 050 1.780864e-02 -1.392505
2019-11-04 22:24:38,526 validation loss; R2: 1.780251e-02 -2.315089
2019-11-04 22:24:38,595 epoch 20 lr 2.000000e-04
2019-11-04 22:24:39,325 train 000 2.089623e-02 0.026907
2019-11-04 22:24:50,052 train 050 1.982586e-02 -0.505280
2019-11-04 22:25:00,805 train 100 1.993801e-02 -0.665529
2019-11-04 22:25:11,565 train 150 1.982232e-02 -0.659569
2019-11-04 22:25:22,397 train 200 1.981663e-02 -0.642376
2019-11-04 22:25:33,091 train 250 1.993387e-02 -0.638965
2019-11-04 22:25:43,839 train 300 1.994725e-02 -0.630306
2019-11-04 22:25:54,685 train 350 1.995319e-02 -0.583475
2019-11-04 22:26:05,583 train 400 1.999857e-02 -0.587155
2019-11-04 22:26:16,220 train 450 2.000134e-02 -0.579248
2019-11-04 22:26:26,997 train 500 2.001322e-02 -0.618064
2019-11-04 22:26:37,778 train 550 2.000761e-02 -0.639136
2019-11-04 22:26:48,659 train 600 1.999044e-02 -0.643817
2019-11-04 22:26:59,520 train 650 1.995209e-02 -0.631448
2019-11-04 22:27:10,377 train 700 1.994624e-02 -0.627001
2019-11-04 22:27:21,189 train 750 1.992970e-02 -0.627599
2019-11-04 22:27:32,029 train 800 1.991183e-02 -0.624614
2019-11-04 22:27:42,839 train 850 1.988809e-02 -0.631791
2019-11-04 22:27:46,127 training loss; R2: 1.988409e-02 -0.629751
2019-11-04 22:27:46,744 valid 000 1.542477e-02 -0.090974
2019-11-04 22:27:57,338 valid 050 1.541037e-02 -0.773033
2019-11-04 22:28:07,021 validation loss; R2: 1.565457e-02 -0.911646
2019-11-04 22:28:07,094 epoch 21 lr 2.000000e-04
2019-11-04 22:28:07,822 train 000 1.755329e-02 -0.415398
2019-11-04 22:28:18,822 train 050 1.940260e-02 -0.640268
2019-11-04 22:28:29,947 train 100 1.964269e-02 -0.573733
2019-11-04 22:28:40,989 train 150 1.981468e-02 -0.609021
2019-11-04 22:28:51,869 train 200 1.987264e-02 -0.717707
2019-11-04 22:29:02,814 train 250 1.981155e-02 -0.687099
2019-11-04 22:29:13,828 train 300 1.981200e-02 -0.663940
2019-11-04 22:29:24,967 train 350 1.983856e-02 -0.652114
2019-11-04 22:29:35,931 train 400 1.982748e-02 -0.670456
2019-11-04 22:29:46,988 train 450 1.985287e-02 -0.679398
2019-11-04 22:29:58,009 train 500 1.985180e-02 -0.650750
2019-11-04 22:30:08,941 train 550 1.986959e-02 -0.647833
2019-11-04 22:30:19,840 train 600 1.993983e-02 -0.632818
2019-11-04 22:30:30,734 train 650 1.987284e-02 -0.628621
2019-11-04 22:30:41,653 train 700 1.989083e-02 -5.146397
2019-11-04 22:30:52,539 train 750 1.986558e-02 -4.834182
2019-11-04 22:31:03,468 train 800 1.985145e-02 -4.570196
2019-11-04 22:31:14,369 train 850 1.981445e-02 -4.340738
2019-11-04 22:31:17,632 training loss; R2: 1.980857e-02 -4.281189
2019-11-04 22:31:18,203 valid 000 1.516079e-02 -1.215761
2019-11-04 22:31:29,183 valid 050 1.557119e-02 -0.607613
2019-11-04 22:31:39,051 validation loss; R2: 1.550091e-02 -0.590731
2019-11-04 22:31:39,130 epoch 22 lr 2.000000e-04
2019-11-04 22:31:39,883 train 000 1.963333e-02 -0.400946
2019-11-04 22:31:50,837 train 050 1.967271e-02 -0.424860
2019-11-04 22:32:01,687 train 100 1.970998e-02 -0.459358
2019-11-04 22:32:12,483 train 150 1.957970e-02 -0.576686
2019-11-04 22:32:23,185 train 200 1.948658e-02 -0.656386
2019-11-04 22:32:33,860 train 250 1.958721e-02 -0.651794
2019-11-04 22:32:44,733 train 300 1.965209e-02 -0.673092
2019-11-04 22:32:55,629 train 350 1.964978e-02 -0.704085
2019-11-04 22:33:06,337 train 400 1.964029e-02 -0.706989
2019-11-04 22:33:16,896 train 450 1.961135e-02 -0.696271
2019-11-04 22:33:27,599 train 500 1.956584e-02 -0.698751
2019-11-04 22:33:38,390 train 550 1.955143e-02 -0.688459
2019-11-04 22:33:49,090 train 600 1.960451e-02 -0.673065
2019-11-04 22:33:59,791 train 650 1.962019e-02 -0.660109
2019-11-04 22:34:10,507 train 700 1.961467e-02 -0.667614
2019-11-04 22:34:21,203 train 750 1.959191e-02 -0.660766
2019-11-04 22:34:31,892 train 800 1.960452e-02 -0.674677
2019-11-04 22:34:42,616 train 850 1.961458e-02 -0.670289
2019-11-04 22:34:45,776 training loss; R2: 1.961827e-02 -0.668710
2019-11-04 22:34:46,333 valid 000 1.633457e-02 -1.154509
2019-11-04 22:34:56,926 valid 050 1.577213e-02 -0.681600
2019-11-04 22:35:06,245 validation loss; R2: 1.570546e-02 -0.737270
2019-11-04 22:35:06,308 epoch 23 lr 2.000000e-04
2019-11-04 22:35:06,997 train 000 2.102429e-02 -0.499908
2019-11-04 22:35:17,742 train 050 1.911497e-02 -0.539794
2019-11-04 22:35:28,386 train 100 1.923251e-02 -0.649857
2019-11-04 22:35:39,105 train 150 1.934761e-02 -0.640273
2019-11-04 22:35:49,691 train 200 1.929719e-02 -0.658194
2019-11-04 22:36:00,221 train 250 1.940637e-02 -0.637687
2019-11-04 22:36:11,122 train 300 1.943880e-02 -0.667937
2019-11-04 22:36:21,835 train 350 1.938708e-02 -0.681112
2019-11-04 22:36:32,468 train 400 1.944214e-02 -0.668828
2019-11-04 22:36:43,016 train 450 1.943435e-02 -0.648748
2019-11-04 22:36:53,706 train 500 1.947357e-02 -0.636680
2019-11-04 22:37:04,377 train 550 1.946517e-02 -0.623205
2019-11-04 22:37:15,032 train 600 1.947564e-02 -0.618237
2019-11-04 22:37:25,744 train 650 1.950467e-02 -0.608580
2019-11-04 22:37:36,470 train 700 1.948393e-02 -0.619682
2019-11-04 22:37:47,211 train 750 1.950814e-02 -0.620396
2019-11-04 22:37:57,961 train 800 1.950452e-02 -0.607581
2019-11-04 22:38:08,675 train 850 1.950468e-02 -0.609525
2019-11-04 22:38:11,916 training loss; R2: 1.951138e-02 -0.619888
2019-11-04 22:38:12,483 valid 000 1.649330e-02 0.060302
2019-11-04 22:38:23,127 valid 050 1.566828e-02 -3.190101
2019-11-04 22:38:32,472 validation loss; R2: 1.558413e-02 -2.186257
2019-11-04 22:38:32,548 epoch 24 lr 2.000000e-04
2019-11-04 22:38:33,238 train 000 1.984153e-02 -1.134536
2019-11-04 22:38:44,006 train 050 1.942293e-02 -0.741934
2019-11-04 22:38:54,711 train 100 1.955846e-02 -0.656363
2019-11-04 22:39:05,376 train 150 1.966533e-02 -0.630274
2019-11-04 22:39:16,056 train 200 1.963330e-02 -0.614421
2019-11-04 22:39:26,700 train 250 1.948914e-02 -0.571036
2019-11-04 22:39:37,527 train 300 1.950209e-02 -0.578385
2019-11-04 22:39:48,372 train 350 1.950699e-02 -0.584131
2019-11-04 22:39:59,186 train 400 1.955532e-02 -0.581529
2019-11-04 22:40:09,839 train 450 1.954326e-02 -0.569147
2019-11-04 22:40:20,542 train 500 1.955489e-02 -0.606426
2019-11-04 22:40:31,219 train 550 1.957087e-02 -0.624800
2019-11-04 22:40:41,932 train 600 1.957876e-02 -0.634640
2019-11-04 22:40:52,661 train 650 1.955277e-02 -0.644216
2019-11-04 22:41:03,410 train 700 1.950921e-02 -0.646937
2019-11-04 22:41:14,111 train 750 1.950324e-02 -0.805295
2019-11-04 22:41:24,823 train 800 1.950704e-02 -0.783610
2019-11-04 22:41:35,527 train 850 1.948930e-02 -0.782868
2019-11-04 22:41:38,692 training loss; R2: 1.948812e-02 -0.780646
2019-11-04 22:41:39,248 valid 000 2.319103e-02 0.044833
2019-11-04 22:41:49,852 valid 050 1.963631e-02 -3.207968
2019-11-04 22:41:59,259 validation loss; R2: 1.996295e-02 -1.774019
2019-11-04 22:41:59,339 epoch 25 lr 2.000000e-04
2019-11-04 22:42:00,038 train 000 1.781110e-02 -1.235494
2019-11-04 22:42:10,867 train 050 1.944365e-02 -0.553141
2019-11-04 22:42:21,587 train 100 1.938675e-02 -0.510903
2019-11-04 22:42:32,315 train 150 1.947595e-02 -0.502427
2019-11-04 22:42:42,959 train 200 1.952036e-02 -0.574683
2019-11-04 22:42:53,596 train 250 1.940994e-02 -0.552990
2019-11-04 22:43:04,447 train 300 1.936353e-02 -0.539541
2019-11-04 22:43:15,360 train 350 1.936792e-02 -0.553852
2019-11-04 22:43:26,097 train 400 1.936354e-02 -0.604094
2019-11-04 22:43:36,803 train 450 1.936465e-02 -0.598699
2019-11-04 22:43:47,471 train 500 1.937920e-02 -0.602981
2019-11-04 22:43:58,129 train 550 1.939185e-02 -0.607976
2019-11-04 22:44:08,795 train 600 1.939840e-02 -0.601782
2019-11-04 22:44:19,471 train 650 1.942061e-02 -0.587717
2019-11-04 22:44:30,114 train 700 1.941586e-02 -0.586280
2019-11-04 22:44:40,785 train 750 1.938053e-02 -0.579813
2019-11-04 22:44:51,483 train 800 1.941297e-02 -0.574042
2019-11-04 22:45:02,155 train 850 1.939406e-02 -0.570935
2019-11-04 22:45:05,357 training loss; R2: 1.939664e-02 -0.567397
2019-11-04 22:45:06,006 valid 000 1.398698e-02 -0.291514
2019-11-04 22:45:16,686 valid 050 1.534060e-02 -0.532185
2019-11-04 22:45:26,306 validation loss; R2: 1.511901e-02 -0.568177
2019-11-04 22:45:26,376 epoch 26 lr 2.000000e-04
2019-11-04 22:45:27,196 train 000 2.376147e-02 -0.802205
2019-11-04 22:45:37,912 train 050 1.929150e-02 -0.583841
2019-11-04 22:45:48,693 train 100 1.915427e-02 -0.656577
2019-11-04 22:45:59,438 train 150 1.913958e-02 -0.656582
2019-11-04 22:46:10,136 train 200 1.911283e-02 -0.610593
2019-11-04 22:46:20,801 train 250 1.919457e-02 -0.590656
2019-11-04 22:46:31,598 train 300 1.912896e-02 -0.634417
2019-11-04 22:46:42,239 train 350 1.912541e-02 -0.619182
2019-11-04 22:46:53,077 train 400 1.919480e-02 -0.611041
2019-11-04 22:47:03,743 train 450 1.923296e-02 -0.605211
2019-11-04 22:47:14,364 train 500 1.925080e-02 -0.622486
2019-11-04 22:47:25,072 train 550 1.925192e-02 -0.625892
2019-11-04 22:47:35,795 train 600 1.927694e-02 -0.639720
2019-11-04 22:47:46,558 train 650 1.924840e-02 -0.642545
2019-11-04 22:47:57,275 train 700 1.925130e-02 -0.645410
2019-11-04 22:48:07,993 train 750 1.925101e-02 -0.662907
2019-11-04 22:48:18,756 train 800 1.927699e-02 -0.661458
2019-11-04 22:48:29,499 train 850 1.930469e-02 -0.648729
2019-11-04 22:48:32,660 training loss; R2: 1.929318e-02 -0.650523
2019-11-04 22:48:33,279 valid 000 1.452735e-02 -0.219619
2019-11-04 22:48:44,008 valid 050 1.576322e-02 -2.035702
2019-11-04 22:48:53,515 validation loss; R2: 1.586499e-02 -1.377186
2019-11-04 22:48:53,590 epoch 27 lr 2.000000e-04
2019-11-04 22:48:54,291 train 000 1.728800e-02 -0.182220
2019-11-04 22:49:05,238 train 050 1.923753e-02 -0.686577
2019-11-04 22:49:16,193 train 100 1.933877e-02 -0.588787
2019-11-04 22:49:27,129 train 150 1.958590e-02 -0.569008
2019-11-04 22:49:37,675 train 200 1.953428e-02 -0.584399
2019-11-04 22:49:48,199 train 250 1.937056e-02 -0.736357
2019-11-04 22:49:58,804 train 300 1.934698e-02 -0.733005
2019-11-04 22:50:09,510 train 350 1.929424e-02 -0.759655
2019-11-04 22:50:20,126 train 400 1.933787e-02 -0.749178
2019-11-04 22:50:30,950 train 450 1.931130e-02 -0.714262
2019-11-04 22:50:41,786 train 500 1.927609e-02 -0.707337
2019-11-04 22:50:52,576 train 550 1.928719e-02 -0.714156
2019-11-04 22:51:03,345 train 600 1.931043e-02 -0.693784
2019-11-04 22:51:14,180 train 650 1.931755e-02 -0.810135
2019-11-04 22:51:24,986 train 700 1.932020e-02 -0.823345
2019-11-04 22:51:35,772 train 750 1.931312e-02 -0.812010
2019-11-04 22:51:46,597 train 800 1.931722e-02 -0.787269
2019-11-04 22:51:57,426 train 850 1.929669e-02 -0.770910
2019-11-04 22:52:00,613 training loss; R2: 1.929959e-02 -0.767285
2019-11-04 22:52:01,164 valid 000 1.532250e-02 -3.245594
2019-11-04 22:52:11,877 valid 050 1.440466e-02 -2.150287
2019-11-04 22:52:21,303 validation loss; R2: 1.472250e-02 -1.502899
2019-11-04 22:52:21,370 epoch 28 lr 2.000000e-04
2019-11-04 22:52:22,068 train 000 1.899354e-02 -0.269042
2019-11-04 22:52:32,973 train 050 1.911396e-02 -0.776255
2019-11-04 22:52:43,809 train 100 1.919340e-02 -1.360259
2019-11-04 22:52:54,636 train 150 1.916209e-02 -1.206081
2019-11-04 22:53:05,095 train 200 1.914162e-02 -1.028987
2019-11-04 22:53:15,538 train 250 1.913500e-02 -0.927497
2019-11-04 22:53:26,021 train 300 1.910816e-02 -0.892387
2019-11-04 22:53:36,514 train 350 1.910152e-02 -1.089272
2019-11-04 22:53:47,136 train 400 1.907715e-02 -1.007713
2019-11-04 22:53:57,920 train 450 1.906657e-02 -0.979189
2019-11-04 22:54:08,802 train 500 1.908145e-02 -0.932302
2019-11-04 22:54:19,635 train 550 1.911540e-02 -0.913021
2019-11-04 22:54:30,574 train 600 1.915469e-02 -0.898822
2019-11-04 22:54:41,415 train 650 1.914443e-02 -0.915021
2019-11-04 22:54:52,032 train 700 1.916565e-02 -0.889477
2019-11-04 22:55:02,598 train 750 1.916113e-02 -0.876251
2019-11-04 22:55:13,196 train 800 1.916068e-02 -0.858278
2019-11-04 22:55:23,857 train 850 1.916766e-02 -0.854808
2019-11-04 22:55:27,048 training loss; R2: 1.917504e-02 -0.847469
2019-11-04 22:55:27,727 valid 000 1.725885e-02 -0.465598
2019-11-04 22:55:38,382 valid 050 1.506783e-02 -0.822176
2019-11-04 22:55:47,872 validation loss; R2: 1.519001e-02 -0.788656
2019-11-04 22:55:47,942 epoch 29 lr 2.000000e-04
2019-11-04 22:55:48,659 train 000 1.555707e-02 -0.274858
2019-11-04 22:55:59,590 train 050 1.968030e-02 -0.630126
2019-11-04 22:56:10,512 train 100 1.966194e-02 -0.940031
2019-11-04 22:56:21,348 train 150 1.951756e-02 -0.874784
2019-11-04 22:56:32,062 train 200 1.941477e-02 -0.796608
2019-11-04 22:56:42,781 train 250 1.944543e-02 -0.737199
2019-11-04 22:56:53,582 train 300 1.941114e-02 -0.731184
2019-11-04 22:57:04,363 train 350 1.940214e-02 -0.703592
2019-11-04 22:57:15,200 train 400 1.939683e-02 -0.732486
2019-11-04 22:57:25,927 train 450 1.939300e-02 -0.720127
2019-11-04 22:57:36,665 train 500 1.938356e-02 -0.699732
2019-11-04 22:57:47,438 train 550 1.937079e-02 -0.693249
2019-11-04 22:57:58,265 train 600 1.936261e-02 -0.675767
2019-11-04 22:58:08,973 train 650 1.934538e-02 -0.661672
2019-11-04 22:58:19,750 train 700 1.936318e-02 -0.655781
2019-11-04 22:58:30,571 train 750 1.936130e-02 -0.651703
2019-11-04 22:58:41,379 train 800 1.934564e-02 -0.650246
2019-11-04 22:58:52,185 train 850 1.932753e-02 -0.637776
2019-11-04 22:58:55,368 training loss; R2: 1.932416e-02 -0.638428
2019-11-04 22:58:55,996 valid 000 1.573150e-02 -0.618103
2019-11-04 22:59:06,838 valid 050 1.527002e-02 -1.078477
2019-11-04 22:59:16,785 validation loss; R2: 1.526774e-02 -1.771349
2019-11-04 22:59:16,852 epoch 30 lr 2.000000e-04
2019-11-04 22:59:17,596 train 000 1.625610e-02 -0.695621
2019-11-04 22:59:28,333 train 050 1.893613e-02 -0.624073
2019-11-04 22:59:39,139 train 100 1.888658e-02 -0.756115
2019-11-04 22:59:49,925 train 150 1.890368e-02 -0.678304
2019-11-04 23:00:00,405 train 200 1.902691e-02 -0.676563
2019-11-04 23:00:10,854 train 250 1.904605e-02 -0.672325
2019-11-04 23:00:21,437 train 300 1.904075e-02 -0.668092
2019-11-04 23:00:32,087 train 350 1.910947e-02 -0.746586
2019-11-04 23:00:42,768 train 400 1.913692e-02 -0.734655
2019-11-04 23:00:53,488 train 450 1.912899e-02 -0.713946
2019-11-04 23:01:04,202 train 500 1.915336e-02 -0.697734
2019-11-04 23:01:14,937 train 550 1.914922e-02 -0.690417
2019-11-04 23:01:25,638 train 600 1.913064e-02 -0.685668
2019-11-04 23:01:36,341 train 650 1.914550e-02 -0.691937
2019-11-04 23:01:47,075 train 700 1.914897e-02 -0.690002
2019-11-04 23:01:57,832 train 750 1.916093e-02 -0.689470
2019-11-04 23:02:08,615 train 800 1.918349e-02 -0.682285
2019-11-04 23:02:19,368 train 850 1.918764e-02 -0.677483
2019-11-04 23:02:22,538 training loss; R2: 1.918859e-02 -0.677940
2019-11-04 23:02:23,121 valid 000 1.492656e-02 -0.303279
2019-11-04 23:02:33,766 valid 050 1.473073e-02 -0.754237
2019-11-04 23:02:43,129 validation loss; R2: 1.457950e-02 -0.788154
2019-11-04 23:02:43,213 epoch 31 lr 2.000000e-04
2019-11-04 23:02:43,919 train 000 1.934056e-02 -0.123578
2019-11-04 23:02:54,746 train 050 1.952656e-02 -0.767469
2019-11-04 23:03:05,536 train 100 1.950064e-02 -0.795697
2019-11-04 23:03:16,336 train 150 1.933724e-02 -0.712155
2019-11-04 23:03:26,999 train 200 1.926833e-02 -0.714964
2019-11-04 23:03:37,487 train 250 1.923574e-02 -0.697033
2019-11-04 23:03:48,335 train 300 1.925540e-02 -0.729584
2019-11-04 23:03:59,246 train 350 1.923998e-02 -0.720790
2019-11-04 23:04:10,160 train 400 1.923538e-02 -0.694488
2019-11-04 23:04:21,044 train 450 1.920363e-02 -0.701616
2019-11-04 23:04:31,930 train 500 1.917957e-02 -0.706583
2019-11-04 23:04:42,830 train 550 1.917446e-02 -0.720656
2019-11-04 23:04:53,703 train 600 1.916615e-02 -0.701491
2019-11-04 23:05:04,505 train 650 1.916896e-02 -0.721346
2019-11-04 23:05:15,324 train 700 1.919979e-02 -0.723375
2019-11-04 23:05:26,163 train 750 1.920401e-02 -0.711632
2019-11-04 23:05:37,017 train 800 1.919970e-02 -0.693959
2019-11-04 23:05:47,891 train 850 1.922026e-02 -0.682952
2019-11-04 23:05:51,081 training loss; R2: 1.921582e-02 -0.680186
2019-11-04 23:05:51,653 valid 000 1.695690e-02 -0.000720
2019-11-04 23:06:02,370 valid 050 1.550782e-02 -1.261295
2019-11-04 23:06:11,942 validation loss; R2: 1.564383e-02 -1.383096
2019-11-04 23:06:12,003 epoch 32 lr 2.000000e-04
2019-11-04 23:06:12,706 train 000 2.109381e-02 -0.260430
2019-11-04 23:06:23,598 train 050 1.899987e-02 -0.700519
2019-11-04 23:06:34,463 train 100 1.883162e-02 -0.672106
2019-11-04 23:06:45,302 train 150 1.909315e-02 -0.599497
2019-11-04 23:06:55,999 train 200 1.910435e-02 -0.583975
2019-11-04 23:07:06,847 train 250 1.914194e-02 -0.558503
2019-11-04 23:07:17,680 train 300 1.911111e-02 -0.610137
2019-11-04 23:07:28,417 train 350 1.918054e-02 -0.618302
2019-11-04 23:07:39,178 train 400 1.918133e-02 -0.627045
2019-11-04 23:07:49,945 train 450 1.918795e-02 -0.639997
2019-11-04 23:08:00,661 train 500 1.917417e-02 -0.654886
2019-11-04 23:08:11,429 train 550 1.923083e-02 -0.653134
2019-11-04 23:08:22,185 train 600 1.929991e-02 -0.708180
2019-11-04 23:08:32,932 train 650 1.929058e-02 -0.706337
2019-11-04 23:08:43,649 train 700 1.931025e-02 -0.688391
2019-11-04 23:08:54,329 train 750 1.934994e-02 -0.755686
2019-11-04 23:09:05,014 train 800 1.937293e-02 -0.755333
2019-11-04 23:09:15,729 train 850 1.937880e-02 -0.741649
2019-11-04 23:09:18,890 training loss; R2: 1.938146e-02 -0.739041
2019-11-04 23:09:19,453 valid 000 1.571060e-02 -2.115471
2019-11-04 23:09:30,047 valid 050 1.530221e-02 -0.947354
2019-11-04 23:09:39,481 validation loss; R2: 1.519909e-02 -1.119574
2019-11-04 23:09:39,564 epoch 33 lr 2.000000e-04
2019-11-04 23:09:40,267 train 000 2.219807e-02 -0.176896
2019-11-04 23:09:51,143 train 050 2.026572e-02 -0.558444
2019-11-04 23:10:01,961 train 100 1.979351e-02 -0.636544
2019-11-04 23:10:12,829 train 150 1.973315e-02 -0.605889
2019-11-04 23:10:23,653 train 200 1.986774e-02 -0.674410
2019-11-04 23:10:34,247 train 250 1.980605e-02 -0.668270
2019-11-04 23:10:44,949 train 300 1.987442e-02 -0.677558
2019-11-04 23:10:55,763 train 350 1.984660e-02 -0.690740
2019-11-04 23:11:06,529 train 400 1.985059e-02 -0.878163
2019-11-04 23:11:17,281 train 450 1.984676e-02 -0.862685
2019-11-04 23:11:27,995 train 500 1.983888e-02 -0.842169
2019-11-04 23:11:38,739 train 550 1.987278e-02 -0.856279
2019-11-04 23:11:49,500 train 600 1.991419e-02 -0.850979
2019-11-04 23:12:00,318 train 650 1.996408e-02 -0.813199
2019-11-04 23:12:11,148 train 700 2.007366e-02 -0.848692
2019-11-04 23:12:21,957 train 750 2.018246e-02 -0.823358
2019-11-04 23:12:32,738 train 800 2.024471e-02 -0.803339
2019-11-04 23:12:43,494 train 850 2.025025e-02 -0.781362
2019-11-04 23:12:46,668 training loss; R2: 2.024234e-02 -0.777489
2019-11-04 23:12:47,253 valid 000 1.522871e-02 -5.451874
2019-11-04 23:12:58,085 valid 050 1.753153e-02 -1.288067
2019-11-04 23:13:07,605 validation loss; R2: 1.758423e-02 -1.124268
2019-11-04 23:13:07,687 epoch 34 lr 2.000000e-04
2019-11-04 23:13:08,428 train 000 1.993303e-02 -3.014859
2019-11-04 23:13:19,403 train 050 2.056434e-02 -0.727437
2019-11-04 23:13:30,338 train 100 2.067007e-02 -0.652260
2019-11-04 23:13:41,240 train 150 2.067460e-02 -0.617753
2019-11-04 23:13:51,901 train 200 2.078626e-02 -0.656217
2019-11-04 23:14:02,469 train 250 2.077968e-02 -0.686691
2019-11-04 23:14:13,091 train 300 2.083294e-02 -0.638721
2019-11-04 23:14:23,914 train 350 2.084971e-02 -0.642604
2019-11-04 23:14:34,673 train 400 2.084812e-02 -0.643653
2019-11-04 23:14:45,418 train 450 2.086909e-02 -0.633591
2019-11-04 23:14:56,173 train 500 2.086242e-02 -0.640964
2019-11-04 23:15:06,938 train 550 2.083093e-02 -0.630846
2019-11-04 23:15:17,714 train 600 2.087476e-02 -0.627989
2019-11-04 23:15:28,462 train 650 2.090295e-02 -0.649823
2019-11-04 23:15:39,173 train 700 2.093821e-02 -0.653395
2019-11-04 23:15:49,898 train 750 2.089553e-02 -0.637209
2019-11-04 23:16:00,623 train 800 2.087258e-02 -0.676416
2019-11-04 23:16:11,374 train 850 2.089774e-02 -0.672689
2019-11-04 23:16:14,558 training loss; R2: 2.090309e-02 -0.674223
2019-11-04 23:16:15,124 valid 000 1.517067e-02 -0.360709
2019-11-04 23:16:25,749 valid 050 1.728246e-02 -3.885400
2019-11-04 23:16:35,137 validation loss; R2: 1.742072e-02 -2.370747
2019-11-04 23:16:35,206 epoch 35 lr 2.000000e-04
2019-11-04 23:16:35,900 train 000 2.476866e-02 -0.142187
2019-11-04 23:16:46,596 train 050 2.118487e-02 -0.605327
2019-11-04 23:16:57,272 train 100 2.070634e-02 -0.610601
2019-11-04 23:17:08,071 train 150 2.064550e-02 -0.629758
2019-11-04 23:17:18,682 train 200 2.071111e-02 -0.638333
2019-11-04 23:17:29,275 train 250 2.078702e-02 -0.596952
2019-11-04 23:17:40,134 train 300 2.076849e-02 -0.605933
2019-11-04 23:17:50,990 train 350 2.074864e-02 -0.620197
2019-11-04 23:18:01,816 train 400 2.078103e-02 -0.604821
2019-11-04 23:18:12,681 train 450 2.072290e-02 -0.610939
2019-11-04 23:18:23,623 train 500 2.071669e-02 -0.600336
2019-11-04 23:18:34,414 train 550 2.069502e-02 -0.610229
2019-11-04 23:18:45,125 train 600 2.067302e-02 -0.605041
2019-11-04 23:18:55,950 train 650 2.069397e-02 -0.614212
2019-11-04 23:19:06,845 train 700 2.066183e-02 -0.646244
2019-11-04 23:19:17,560 train 750 2.066775e-02 -0.638315
2019-11-04 23:19:28,256 train 800 2.067055e-02 -0.625580
2019-11-04 23:19:38,964 train 850 2.064949e-02 -0.617160
2019-11-04 23:19:42,102 training loss; R2: 2.063969e-02 -0.619411
2019-11-04 23:19:42,698 valid 000 1.604099e-02 -0.257497
2019-11-04 23:19:53,313 valid 050 1.688864e-02 -0.766608
2019-11-04 23:20:02,961 validation loss; R2: 1.675508e-02 -0.696595
2019-11-04 23:20:03,026 epoch 36 lr 2.000000e-04
2019-11-04 23:20:03,749 train 000 2.295831e-02 -0.085029
2019-11-04 23:20:14,644 train 050 2.083600e-02 -0.401921
2019-11-04 23:20:25,472 train 100 2.070558e-02 -0.470086
2019-11-04 23:20:36,269 train 150 2.044906e-02 -0.645702
2019-11-04 23:20:47,063 train 200 2.044930e-02 -0.639675
2019-11-04 23:20:57,580 train 250 2.050150e-02 -0.637954
2019-11-04 23:21:08,347 train 300 2.062912e-02 -0.612031
2019-11-04 23:21:19,109 train 350 2.066228e-02 -0.594968
2019-11-04 23:21:29,903 train 400 2.063000e-02 -0.617110
2019-11-04 23:21:40,640 train 450 2.058552e-02 -0.608162
2019-11-04 23:21:51,435 train 500 2.061739e-02 -0.619244
2019-11-04 23:22:02,200 train 550 2.060008e-02 -0.638631
2019-11-04 23:22:13,018 train 600 2.064040e-02 -0.629586
2019-11-04 23:22:23,793 train 650 2.060622e-02 -0.618255
2019-11-04 23:22:34,525 train 700 2.058594e-02 -0.622282
2019-11-04 23:22:45,306 train 750 2.061213e-02 -0.651659
2019-11-04 23:22:56,061 train 800 2.060292e-02 -0.645621
2019-11-04 23:23:06,860 train 850 2.059560e-02 -0.650410
2019-11-04 23:23:10,029 training loss; R2: 2.058249e-02 -0.655032
2019-11-04 23:23:10,669 valid 000 1.711675e-02 -0.638147
2019-11-04 23:23:21,301 valid 050 1.616579e-02 -0.612921
2019-11-04 23:23:31,040 validation loss; R2: 1.595145e-02 -0.557362
2019-11-04 23:23:31,107 epoch 37 lr 2.000000e-04
2019-11-04 23:23:31,843 train 000 1.833006e-02 -1.544306
2019-11-04 23:23:42,699 train 050 2.006448e-02 -0.540961
2019-11-04 23:23:53,489 train 100 2.016478e-02 -0.581888
2019-11-04 23:24:04,270 train 150 2.034167e-02 -0.567213
2019-11-04 23:24:14,945 train 200 2.036371e-02 -0.555919
2019-11-04 23:24:25,669 train 250 2.037996e-02 -0.559646
2019-11-04 23:24:36,341 train 300 2.040919e-02 -0.543838
2019-11-04 23:24:47,023 train 350 2.046074e-02 -0.531065
2019-11-04 23:24:57,741 train 400 2.043851e-02 -0.534665
2019-11-04 23:25:08,506 train 450 2.041606e-02 -0.545043
2019-11-04 23:25:19,183 train 500 2.042204e-02 -0.579599
2019-11-04 23:25:29,888 train 550 2.048813e-02 -0.602216
2019-11-04 23:25:40,591 train 600 2.053565e-02 -0.601156
2019-11-04 23:25:51,458 train 650 2.058806e-02 -0.610132
2019-11-04 23:26:02,169 train 700 2.067479e-02 -0.599547
2019-11-04 23:26:12,857 train 750 2.075298e-02 -0.607535
2019-11-04 23:26:23,611 train 800 2.081129e-02 -0.611813
2019-11-04 23:26:34,309 train 850 2.083243e-02 -0.612046
2019-11-04 23:26:37,522 training loss; R2: 2.084138e-02 -0.619565
2019-11-04 23:26:38,134 valid 000 2.083586e-02 -3.109084
2019-11-04 23:26:49,053 valid 050 1.801211e-02 -1.037075
2019-11-04 23:26:59,031 validation loss; R2: 1.797762e-02 -1.107559
2019-11-04 23:26:59,116 epoch 38 lr 2.000000e-04
2019-11-04 23:26:59,827 train 000 1.900709e-02 -0.132582
2019-11-04 23:27:10,741 train 050 2.109620e-02 -0.695946
2019-11-04 23:27:21,825 train 100 2.104204e-02 -0.602675
2019-11-04 23:27:32,819 train 150 2.096525e-02 -0.568704
2019-11-04 23:27:43,426 train 200 2.092585e-02 -0.580613
2019-11-04 23:27:54,167 train 250 2.075606e-02 -0.548427
2019-11-04 23:28:05,072 train 300 2.066737e-02 -0.576165
2019-11-04 23:28:15,937 train 350 2.064073e-02 -0.605319
2019-11-04 23:28:26,813 train 400 2.066127e-02 -0.626148
2019-11-04 23:28:37,689 train 450 2.059510e-02 -0.653668
2019-11-04 23:28:48,338 train 500 2.060938e-02 -0.694684
2019-11-04 23:28:58,973 train 550 2.060635e-02 -0.681548
2019-11-04 23:29:09,635 train 600 2.060055e-02 -0.668021
2019-11-04 23:29:20,308 train 650 2.061833e-02 -0.671105
2019-11-04 23:29:30,930 train 700 2.062289e-02 -0.668548
2019-11-04 23:29:41,601 train 750 2.062879e-02 -0.665306
2019-11-04 23:29:52,230 train 800 2.061587e-02 -0.656635
2019-11-04 23:30:02,860 train 850 2.058003e-02 -0.646787
2019-11-04 23:30:06,012 training loss; R2: 2.057085e-02 -0.641391
2019-11-04 23:30:06,675 valid 000 1.771872e-02 -0.164879
2019-11-04 23:30:17,330 valid 050 1.582860e-02 -0.874615
2019-11-04 23:30:27,013 validation loss; R2: 1.565054e-02 -0.877305
2019-11-04 23:30:27,093 epoch 39 lr 2.000000e-04
2019-11-04 23:30:27,804 train 000 2.153573e-02 -0.336476
2019-11-04 23:30:38,750 train 050 2.044515e-02 -0.594427
2019-11-04 23:30:49,553 train 100 2.075172e-02 -0.502877
2019-11-04 23:31:00,330 train 150 2.071605e-02 -0.527450
2019-11-04 23:31:11,138 train 200 2.050631e-02 -0.576016
2019-11-04 23:31:21,853 train 250 2.049086e-02 -0.587396
2019-11-04 23:31:32,640 train 300 2.056901e-02 -0.571340
2019-11-04 23:31:43,453 train 350 2.056007e-02 -0.581411
2019-11-04 23:31:54,135 train 400 2.054216e-02 -0.583624
2019-11-04 23:32:04,918 train 450 2.047223e-02 -0.600335
2019-11-04 23:32:15,624 train 500 2.048987e-02 -0.600090
2019-11-04 23:32:26,416 train 550 2.047712e-02 -0.599249
2019-11-04 23:32:37,173 train 600 2.044218e-02 -0.591794
2019-11-04 23:32:47,912 train 650 2.043827e-02 -0.597638
2019-11-04 23:32:58,662 train 700 2.042901e-02 -0.602529
2019-11-04 23:33:09,444 train 750 2.040532e-02 -0.604815
2019-11-04 23:33:20,203 train 800 2.041406e-02 -0.610608
2019-11-04 23:33:30,994 train 850 2.041581e-02 -0.705528
2019-11-04 23:33:34,270 training loss; R2: 2.042781e-02 -0.699524
2019-11-04 23:33:34,913 valid 000 1.355221e-02 -4.248500
2019-11-04 23:33:45,559 valid 050 1.617538e-02 -1.033341
2019-11-04 23:33:55,270 validation loss; R2: 1.622224e-02 -1.026549
2019-11-04 23:33:55,339 epoch 40 lr 2.000000e-04
2019-11-04 23:33:56,117 train 000 2.288696e-02 -1.101238
2019-11-04 23:34:06,872 train 050 2.052436e-02 -0.874220
2019-11-04 23:34:17,546 train 100 2.032081e-02 -0.685938
2019-11-04 23:34:28,299 train 150 2.046858e-02 -0.737745
2019-11-04 23:34:38,979 train 200 2.045580e-02 -0.734392
2019-11-04 23:34:49,736 train 250 2.055057e-02 -0.690101
2019-11-04 23:35:00,685 train 300 2.050652e-02 -0.665757
2019-11-04 23:35:11,523 train 350 2.060224e-02 -0.652669
2019-11-04 23:35:22,322 train 400 2.069173e-02 -0.712970
2019-11-04 23:35:33,076 train 450 2.066135e-02 -0.734810
2019-11-04 23:35:43,827 train 500 2.073077e-02 -0.724752
2019-11-04 23:35:54,557 train 550 2.073702e-02 -3.006267
2019-11-04 23:36:05,281 train 600 2.074179e-02 -2.789454
2019-11-04 23:36:16,045 train 650 2.080403e-02 -2.625447
2019-11-04 23:36:26,811 train 700 2.081151e-02 -2.477191
2019-11-04 23:36:37,592 train 750 2.084481e-02 -2.353290
2019-11-04 23:36:48,339 train 800 2.091643e-02 -2.247087
2019-11-04 23:36:59,101 train 850 2.100518e-02 -2.145453
2019-11-04 23:37:02,355 training loss; R2: 2.103599e-02 -2.115705
2019-11-04 23:37:02,935 valid 000 1.888048e-02 -1.280130
2019-11-04 23:37:13,565 valid 050 1.829070e-02 -0.849683
2019-11-04 23:37:22,951 validation loss; R2: 1.831094e-02 -0.875377
2019-11-04 23:37:23,025 epoch 41 lr 2.000000e-04
2019-11-04 23:37:23,721 train 000 3.623620e-02 -0.405253
2019-11-04 23:37:34,587 train 050 2.195736e-02 -0.494576
2019-11-04 23:37:45,405 train 100 2.193847e-02 -1.328008
2019-11-04 23:37:56,229 train 150 2.183093e-02 -1.066049
2019-11-04 23:38:07,035 train 200 2.209954e-02 -0.898359
2019-11-04 23:38:17,784 train 250 2.207412e-02 -0.834177
2019-11-04 23:38:28,623 train 300 2.189590e-02 -0.810048
2019-11-04 23:38:39,444 train 350 2.186816e-02 -0.780680
2019-11-04 23:38:50,262 train 400 2.179557e-02 -0.738564
2019-11-04 23:39:01,065 train 450 2.172917e-02 -0.770355
2019-11-04 23:39:11,933 train 500 2.164156e-02 -0.758078
2019-11-04 23:39:22,729 train 550 2.161177e-02 -0.759566
2019-11-04 23:39:33,573 train 600 2.154811e-02 -0.795900
2019-11-04 23:39:44,379 train 650 2.149546e-02 -0.773850
2019-11-04 23:39:55,181 train 700 2.148110e-02 -0.758984
2019-11-04 23:40:06,019 train 750 2.144156e-02 -0.758203
2019-11-04 23:40:16,861 train 800 2.142559e-02 -0.732134
2019-11-04 23:40:27,697 train 850 2.139538e-02 -0.716430
2019-11-04 23:40:30,966 training loss; R2: 2.140129e-02 -0.708263
2019-11-04 23:40:31,598 valid 000 1.796529e-02 -5.747845
2019-11-04 23:40:42,183 valid 050 1.692672e-02 -0.546552
2019-11-04 23:40:51,868 validation loss; R2: 1.683223e-02 -0.605861
2019-11-04 23:40:51,931 epoch 42 lr 2.000000e-04
2019-11-04 23:40:52,674 train 000 2.243071e-02 -0.174487
2019-11-04 23:41:03,467 train 050 2.084366e-02 -0.463962
2019-11-04 23:41:14,205 train 100 2.096423e-02 -0.474317
2019-11-04 23:41:24,969 train 150 2.083979e-02 -0.490407
2019-11-04 23:41:35,740 train 200 2.082496e-02 -0.525682
2019-11-04 23:41:46,397 train 250 2.083362e-02 -0.531034
2019-11-04 23:41:57,151 train 300 2.080304e-02 -0.540407
2019-11-04 23:42:07,884 train 350 2.085512e-02 -0.524748
2019-11-04 23:42:18,672 train 400 2.091368e-02 -0.522482
2019-11-04 23:42:29,457 train 450 2.087225e-02 -0.548710
2019-11-04 23:42:40,248 train 500 2.083685e-02 -0.533576
2019-11-04 23:42:50,996 train 550 2.082598e-02 -0.532750
2019-11-04 23:43:01,762 train 600 2.080042e-02 -0.542174
2019-11-04 23:43:12,524 train 650 2.079794e-02 -0.556383
2019-11-04 23:43:23,251 train 700 2.084369e-02 -0.554448
2019-11-04 23:43:34,013 train 750 2.086119e-02 -0.558503
2019-11-04 23:43:44,749 train 800 2.088004e-02 -0.557448
2019-11-04 23:43:55,491 train 850 2.090488e-02 -0.554472
2019-11-04 23:43:58,666 training loss; R2: 2.090984e-02 -0.551555
2019-11-04 23:43:59,259 valid 000 1.894803e-02 -0.310401
2019-11-04 23:44:09,923 valid 050 1.781789e-02 -0.906029
2019-11-04 23:44:19,635 validation loss; R2: 1.773934e-02 -0.883311
2019-11-04 23:44:19,704 epoch 43 lr 2.000000e-04
2019-11-04 23:44:20,476 train 000 1.854082e-02 -0.056710
2019-11-04 23:44:31,515 train 050 2.069964e-02 -0.640044
2019-11-04 23:44:42,403 train 100 2.100904e-02 -0.557340
2019-11-04 23:44:53,232 train 150 2.104621e-02 -0.557569
2019-11-04 23:45:04,031 train 200 2.088928e-02 -0.597612
2019-11-04 23:45:14,730 train 250 2.091910e-02 -0.603072
2019-11-04 23:45:25,601 train 300 2.091996e-02 -0.624578
2019-11-04 23:45:36,496 train 350 2.094240e-02 -0.626970
2019-11-04 23:45:47,284 train 400 2.093363e-02 -0.652599
2019-11-04 23:45:58,065 train 450 2.092183e-02 -0.638480
2019-11-04 23:46:08,868 train 500 2.086613e-02 -1.038673
2019-11-04 23:46:19,729 train 550 2.091411e-02 -0.997740
2019-11-04 23:46:30,808 train 600 2.094818e-02 -0.990357
2019-11-04 23:46:41,800 train 650 2.095413e-02 -0.952361
2019-11-04 23:46:52,901 train 700 2.094991e-02 -0.922137
2019-11-04 23:47:03,911 train 750 2.097228e-02 -0.913950
2019-11-04 23:47:15,018 train 800 2.094666e-02 -0.886813
2019-11-04 23:47:25,883 train 850 2.092553e-02 -0.865295
2019-11-04 23:47:29,112 training loss; R2: 2.090906e-02 -0.854639
2019-11-04 23:47:29,732 valid 000 1.509953e-02 0.073778
2019-11-04 23:47:40,381 valid 050 1.691584e-02 -1.031014
2019-11-04 23:47:49,878 validation loss; R2: 1.662960e-02 -0.844583
2019-11-04 23:47:49,961 epoch 44 lr 2.000000e-04
2019-11-04 23:47:50,717 train 000 2.101358e-02 -0.051891
2019-11-04 23:48:01,742 train 050 2.125280e-02 -4.057435
2019-11-04 23:48:12,869 train 100 2.087774e-02 -2.368192
2019-11-04 23:48:23,598 train 150 2.057018e-02 -1.785397
2019-11-04 23:48:34,127 train 200 2.055742e-02 -1.495366
2019-11-04 23:48:44,579 train 250 2.047822e-02 -1.371832
2019-11-04 23:48:55,077 train 300 2.047072e-02 -1.244559
2019-11-04 23:49:05,518 train 350 2.051313e-02 -1.140914
2019-11-04 23:49:16,106 train 400 2.054821e-02 -1.073442
2019-11-04 23:49:26,665 train 450 2.052293e-02 -1.030823
2019-11-04 23:49:37,253 train 500 2.053754e-02 -0.981005
2019-11-04 23:49:47,730 train 550 2.053206e-02 -0.960741
2019-11-04 23:49:58,363 train 600 2.048935e-02 -0.948569
2019-11-04 23:50:09,261 train 650 2.050162e-02 -0.928505
2019-11-04 23:50:20,007 train 700 2.048135e-02 -0.890762
2019-11-04 23:50:30,701 train 750 2.048453e-02 -0.883599
2019-11-04 23:50:41,458 train 800 2.045247e-02 -0.882596
2019-11-04 23:50:52,189 train 850 2.047128e-02 -0.858605
2019-11-04 23:50:55,375 training loss; R2: 2.047638e-02 -0.861264
2019-11-04 23:50:55,991 valid 000 1.951400e-02 -0.098563
2019-11-04 23:51:06,847 valid 050 1.774574e-02 -0.762441
2019-11-04 23:51:16,500 validation loss; R2: 1.766354e-02 -0.653843
2019-11-04 23:51:16,572 epoch 45 lr 2.000000e-04
2019-11-04 23:51:17,284 train 000 2.290372e-02 -0.175422
2019-11-04 23:51:28,230 train 050 2.057702e-02 -0.627954
2019-11-04 23:51:39,209 train 100 2.033555e-02 -0.650024
2019-11-04 23:51:50,115 train 150 2.042553e-02 -0.717756
2019-11-04 23:52:00,783 train 200 2.051355e-02 -2.285129
2019-11-04 23:52:11,418 train 250 2.062314e-02 -1.918390
2019-11-04 23:52:22,164 train 300 2.072765e-02 -1.683475
2019-11-04 23:52:32,928 train 350 2.072494e-02 -1.531623
2019-11-04 23:52:43,621 train 400 2.090229e-02 -1.453313
2019-11-04 23:52:54,249 train 450 2.087839e-02 -1.355793
2019-11-04 23:53:05,303 train 500 2.084390e-02 -1.281683
2019-11-04 23:53:16,075 train 550 2.090262e-02 -1.223049
2019-11-04 23:53:27,348 train 600 2.089540e-02 -1.189704
2019-11-04 23:53:38,401 train 650 2.086869e-02 -1.150493
2019-11-04 23:53:49,277 train 700 2.087440e-02 -1.116146
2019-11-04 23:54:00,145 train 750 2.086797e-02 -1.073350
2019-11-04 23:54:10,957 train 800 2.085347e-02 -1.034823
2019-11-04 23:54:21,783 train 850 2.083823e-02 -1.004492
2019-11-04 23:54:24,976 training loss; R2: 2.084441e-02 -0.995604
2019-11-04 23:54:25,582 valid 000 1.710547e-02 -0.850098
2019-11-04 23:54:36,474 valid 050 1.670056e-02 -0.594762
2019-11-04 23:54:46,129 validation loss; R2: 1.665503e-02 -0.587165
2019-11-04 23:54:46,204 epoch 46 lr 2.000000e-04
2019-11-04 23:54:46,953 train 000 2.042343e-02 -1.029374
2019-11-04 23:54:57,913 train 050 2.007811e-02 -0.729160
2019-11-04 23:55:08,629 train 100 2.034694e-02 -0.629967
2019-11-04 23:55:19,314 train 150 2.031209e-02 -0.605975
2019-11-04 23:55:29,976 train 200 2.037317e-02 -0.569732
2019-11-04 23:55:40,701 train 250 2.037565e-02 -0.593917
2019-11-04 23:55:51,352 train 300 2.033852e-02 -0.632520
2019-11-04 23:56:02,105 train 350 2.032603e-02 -0.630694
2019-11-04 23:56:13,136 train 400 2.034609e-02 -0.641605
2019-11-04 23:56:23,998 train 450 2.044126e-02 -0.629289
2019-11-04 23:56:34,867 train 500 2.044768e-02 -0.621527
2019-11-04 23:56:45,631 train 550 2.044626e-02 -0.607713
2019-11-04 23:56:56,266 train 600 2.046106e-02 -0.605485
2019-11-04 23:57:07,065 train 650 2.043152e-02 -0.614906
2019-11-04 23:57:17,812 train 700 2.045643e-02 -0.623034
2019-11-04 23:57:28,664 train 750 2.042398e-02 -0.618861
2019-11-04 23:57:39,363 train 800 2.044630e-02 -0.620075
2019-11-04 23:57:50,085 train 850 2.046255e-02 -0.626625
2019-11-04 23:57:53,337 training loss; R2: 2.045338e-02 -0.626808
2019-11-04 23:57:53,917 valid 000 1.408224e-02 -1.064317
2019-11-04 23:58:04,714 valid 050 1.589715e-02 -0.650479
2019-11-04 23:58:14,220 validation loss; R2: 1.605578e-02 -0.665409
2019-11-04 23:58:14,288 epoch 47 lr 2.000000e-04
2019-11-04 23:58:15,025 train 000 1.857325e-02 -0.257051
2019-11-04 23:58:25,976 train 050 1.971386e-02 -0.620200
2019-11-04 23:58:36,864 train 100 2.004251e-02 -0.551544
2019-11-04 23:58:47,564 train 150 2.016374e-02 -0.567028
2019-11-04 23:58:58,056 train 200 2.018290e-02 -0.577946
2019-11-04 23:59:08,604 train 250 2.024055e-02 -0.591592
2019-11-04 23:59:19,141 train 300 2.027539e-02 -0.623760
2019-11-04 23:59:29,663 train 350 2.022819e-02 -0.625810
2019-11-04 23:59:40,228 train 400 2.024040e-02 -0.640548
2019-11-04 23:59:50,735 train 450 2.021664e-02 -0.652683
2019-11-05 00:00:01,241 train 500 2.018563e-02 -0.670814
2019-11-05 00:00:11,719 train 550 2.019743e-02 -0.664479
2019-11-05 00:00:22,241 train 600 2.021385e-02 -0.646664
2019-11-05 00:00:32,761 train 650 2.023795e-02 -0.635447
2019-11-05 00:00:43,418 train 700 2.026578e-02 -0.637295
2019-11-05 00:00:54,020 train 750 2.030557e-02 -1.071966
2019-11-05 00:01:04,626 train 800 2.027250e-02 -1.063909
2019-11-05 00:01:15,215 train 850 2.030090e-02 -1.041649
2019-11-05 00:01:18,325 training loss; R2: 2.030540e-02 -1.032972
2019-11-05 00:01:18,930 valid 000 1.508904e-02 -0.663785
2019-11-05 00:01:29,480 valid 050 1.561782e-02 -0.588962
2019-11-05 00:01:38,793 validation loss; R2: 1.564945e-02 -0.730815
2019-11-05 00:01:38,859 epoch 48 lr 2.000000e-04
2019-11-05 00:01:39,539 train 000 1.969029e-02 -0.136764
2019-11-05 00:01:50,338 train 050 2.012581e-02 -0.649313
2019-11-05 00:02:00,996 train 100 2.031840e-02 -0.537951
2019-11-05 00:02:11,488 train 150 2.026051e-02 -1.170272
2019-11-05 00:02:21,932 train 200 2.024943e-02 -1.009631
2019-11-05 00:02:32,559 train 250 2.054721e-02 -0.918238
2019-11-05 00:02:43,429 train 300 2.059687e-02 -0.873849
2019-11-05 00:02:54,351 train 350 2.078412e-02 -0.835229
2019-11-05 00:03:05,190 train 400 2.101468e-02 -0.809709
2019-11-05 00:03:16,017 train 450 2.104997e-02 -0.770454
2019-11-05 00:03:26,836 train 500 2.113435e-02 -0.770681
2019-11-05 00:03:37,619 train 550 2.117369e-02 -0.816527
2019-11-05 00:03:48,534 train 600 2.114874e-02 -0.800079
2019-11-05 00:03:59,395 train 650 2.113862e-02 -0.788000
2019-11-05 00:04:10,278 train 700 2.112351e-02 -0.783818
2019-11-05 00:04:21,072 train 750 2.115375e-02 -0.762643
2019-11-05 00:04:31,909 train 800 2.115894e-02 -0.754034
2019-11-05 00:04:42,773 train 850 2.114771e-02 -0.772863
2019-11-05 00:04:46,057 training loss; R2: 2.113320e-02 -0.765688
2019-11-05 00:04:46,607 valid 000 1.710261e-02 -0.558296
2019-11-05 00:04:57,217 valid 050 1.822203e-02 -0.577739
2019-11-05 00:05:06,636 validation loss; R2: 1.822617e-02 -0.604490
2019-11-05 00:05:06,707 epoch 49 lr 2.000000e-04
2019-11-05 00:05:07,401 train 000 2.248856e-02 -0.355743
2019-11-05 00:05:18,282 train 050 2.089267e-02 -0.513401
2019-11-05 00:05:29,143 train 100 2.108592e-02 -0.561853
2019-11-05 00:05:40,023 train 150 2.114587e-02 -0.610970
2019-11-05 00:05:50,785 train 200 2.092358e-02 -0.623171
2019-11-05 00:06:01,570 train 250 2.087627e-02 -0.618382
2019-11-05 00:06:12,417 train 300 2.081309e-02 -0.620669
2019-11-05 00:06:23,195 train 350 2.077994e-02 -0.613479
2019-11-05 00:06:33,885 train 400 2.072628e-02 -0.607017
2019-11-05 00:06:44,621 train 450 2.069112e-02 -0.601371
2019-11-05 00:06:55,337 train 500 2.074525e-02 -0.605888
2019-11-05 00:07:06,137 train 550 2.076501e-02 -0.602420
2019-11-05 00:07:16,826 train 600 2.074830e-02 -0.599529
2019-11-05 00:07:27,600 train 650 2.075036e-02 -0.593761
2019-11-05 00:07:38,300 train 700 2.073858e-02 -0.600172
2019-11-05 00:07:49,077 train 750 2.072874e-02 -0.598961
2019-11-05 00:07:59,786 train 800 2.070033e-02 -0.608598
2019-11-05 00:08:10,622 train 850 2.067016e-02 -0.621045
2019-11-05 00:08:13,869 training loss; R2: 2.067677e-02 -0.622066
2019-11-05 00:08:14,505 valid 000 2.121629e-02 -0.321962
2019-11-05 00:08:25,332 valid 050 1.700978e-02 -0.615893
2019-11-05 00:08:35,057 validation loss; R2: 1.698931e-02 -0.547302
2019-11-05 00:08:35,125 epoch 50 lr 2.000000e-04
2019-11-05 00:08:35,862 train 000 2.273108e-02 -0.168162
2019-11-05 00:08:46,699 train 050 2.041653e-02 -0.494600
2019-11-05 00:08:57,430 train 100 2.026507e-02 -0.520443
2019-11-05 00:09:08,314 train 150 2.024507e-02 -0.512828
2019-11-05 00:09:18,944 train 200 2.040321e-02 -0.503863
2019-11-05 00:09:29,696 train 250 2.038008e-02 -0.509323
2019-11-05 00:09:40,463 train 300 2.038397e-02 -0.524746
2019-11-05 00:09:51,330 train 350 2.039086e-02 -0.544524
2019-11-05 00:10:02,091 train 400 2.039034e-02 -0.546779
2019-11-05 00:10:12,778 train 450 2.042598e-02 -0.544797
2019-11-05 00:10:23,587 train 500 2.046451e-02 -0.557272
2019-11-05 00:10:34,261 train 550 2.048583e-02 -0.563616
2019-11-05 00:10:45,023 train 600 2.045062e-02 -0.562046
2019-11-05 00:10:55,822 train 650 2.046596e-02 -0.575279
2019-11-05 00:11:06,644 train 700 2.049061e-02 -0.581488
2019-11-05 00:11:17,448 train 750 2.061232e-02 -0.594989
2019-11-05 00:11:28,309 train 800 2.062884e-02 -0.610771
2019-11-05 00:11:39,033 train 850 2.067284e-02 -0.607788
2019-11-05 00:11:42,204 training loss; R2: 2.066799e-02 -0.603729
2019-11-05 00:11:42,846 valid 000 1.523527e-02 -0.712533
2019-11-05 00:11:53,595 valid 050 1.697448e-02 -0.835663
2019-11-05 00:12:03,229 validation loss; R2: 1.647818e-02 -0.836966
2019-11-05 00:12:03,300 epoch 51 lr 2.000000e-04
2019-11-05 00:12:04,061 train 000 2.052715e-02 -1.903541
2019-11-05 00:12:14,925 train 050 2.035801e-02 -0.449692
2019-11-05 00:12:25,808 train 100 2.067666e-02 -0.461793
2019-11-05 00:12:36,573 train 150 2.046837e-02 -0.552716
2019-11-05 00:12:47,170 train 200 2.052931e-02 -0.620464
2019-11-05 00:12:57,891 train 250 2.051758e-02 -0.650822
2019-11-05 00:13:08,763 train 300 2.041752e-02 -0.682505
2019-11-05 00:13:19,596 train 350 2.040146e-02 -0.666230
2019-11-05 00:13:30,434 train 400 2.035385e-02 -0.697293
2019-11-05 00:13:41,263 train 450 2.026514e-02 -0.690286
2019-11-05 00:13:52,009 train 500 2.026904e-02 -0.682591
2019-11-05 00:14:02,687 train 550 2.028256e-02 -0.672284
2019-11-05 00:14:13,397 train 600 2.029012e-02 -0.664305
2019-11-05 00:14:24,184 train 650 2.027129e-02 -0.657031
2019-11-05 00:14:34,986 train 700 2.028824e-02 -0.655397
2019-11-05 00:14:45,744 train 750 2.026059e-02 -0.638073
2019-11-05 00:14:56,575 train 800 2.023269e-02 -0.680254
2019-11-05 00:15:07,339 train 850 2.022304e-02 -0.670829
2019-11-05 00:15:10,586 training loss; R2: 2.022042e-02 -0.664698
2019-11-05 00:15:11,176 valid 000 1.735903e-02 -1.168367
2019-11-05 00:15:21,975 valid 050 1.635064e-02 -1.123194
2019-11-05 00:15:31,478 validation loss; R2: 1.647824e-02 -0.949781
2019-11-05 00:15:31,561 epoch 52 lr 2.000000e-04
2019-11-05 00:15:32,261 train 000 1.936731e-02 -0.038946
2019-11-05 00:15:43,152 train 050 2.020081e-02 -0.400770
2019-11-05 00:15:54,035 train 100 2.079291e-02 -0.472248
2019-11-05 00:16:04,864 train 150 2.082271e-02 -0.466227
2019-11-05 00:16:15,612 train 200 2.098484e-02 -0.501830
2019-11-05 00:16:26,330 train 250 2.092935e-02 -0.502667
2019-11-05 00:16:37,235 train 300 2.091759e-02 -0.519539
2019-11-05 00:16:48,130 train 350 2.092795e-02 -0.520916
2019-11-05 00:16:59,053 train 400 2.084314e-02 -0.531382
2019-11-05 00:17:09,927 train 450 2.086329e-02 -0.537245
2019-11-05 00:17:20,856 train 500 2.082115e-02 -0.560086
2019-11-05 00:17:31,901 train 550 2.078766e-02 -2.655268
2019-11-05 00:17:42,899 train 600 2.071040e-02 -2.482319
2019-11-05 00:17:53,989 train 650 2.073171e-02 -2.342320
2019-11-05 00:18:04,844 train 700 2.068353e-02 -2.225522
2019-11-05 00:18:15,675 train 750 2.069315e-02 -2.220515
2019-11-05 00:18:26,527 train 800 2.071577e-02 -2.121242
2019-11-05 00:18:37,408 train 850 2.068332e-02 -2.042051
2019-11-05 00:18:40,654 training loss; R2: 2.067978e-02 -2.018305
2019-11-05 00:18:41,289 valid 000 2.225084e-02 0.028724
2019-11-05 00:18:51,835 valid 050 1.798035e-02 -0.888700
2019-11-05 00:19:01,432 validation loss; R2: 1.781901e-02 -0.767502
2019-11-05 00:19:01,504 epoch 53 lr 2.000000e-04
2019-11-05 00:19:02,265 train 000 2.102005e-02 0.001056
2019-11-05 00:19:12,986 train 050 1.995672e-02 -0.497048
2019-11-05 00:19:23,823 train 100 2.029197e-02 -0.639858
2019-11-05 00:19:34,516 train 150 2.049272e-02 -0.607034
2019-11-05 00:19:45,164 train 200 2.036134e-02 -0.567046
2019-11-05 00:19:55,985 train 250 2.036663e-02 -0.678477
2019-11-05 00:20:06,758 train 300 2.028012e-02 -0.670820
2019-11-05 00:20:17,508 train 350 2.023339e-02 -0.654727
2019-11-05 00:20:28,335 train 400 2.025468e-02 -0.676150
2019-11-05 00:20:39,144 train 450 2.025141e-02 -0.660397
2019-11-05 00:20:49,882 train 500 2.025145e-02 -0.679880
2019-11-05 00:21:00,622 train 550 2.020681e-02 -0.669259
2019-11-05 00:21:11,422 train 600 2.018578e-02 -0.651744
2019-11-05 00:21:22,220 train 650 2.018223e-02 -0.651761
2019-11-05 00:21:32,955 train 700 2.022538e-02 -0.653362
2019-11-05 00:21:43,711 train 750 2.019279e-02 -0.659345
2019-11-05 00:21:54,464 train 800 2.014784e-02 -0.662470
2019-11-05 00:22:05,244 train 850 2.013794e-02 -0.659084
2019-11-05 00:22:08,499 training loss; R2: 2.014342e-02 -0.656326
2019-11-05 00:22:09,091 valid 000 1.438383e-02 -1.717165
2019-11-05 00:22:19,817 valid 050 1.617591e-02 -0.495019
2019-11-05 00:22:29,303 validation loss; R2: 1.610870e-02 -0.648991
2019-11-05 00:22:29,362 epoch 54 lr 2.000000e-04
2019-11-05 00:22:30,077 train 000 2.033020e-02 -0.018096
2019-11-05 00:22:40,982 train 050 2.015471e-02 -0.478359
2019-11-05 00:22:51,766 train 100 2.061676e-02 -0.615352
2019-11-05 00:23:02,397 train 150 2.046453e-02 -0.606394
2019-11-05 00:23:12,916 train 200 2.045953e-02 -0.561776
2019-11-05 00:23:23,560 train 250 2.064865e-02 -0.583097
2019-11-05 00:23:34,228 train 300 2.079011e-02 -0.602728
2019-11-05 00:23:44,863 train 350 2.073458e-02 -0.600664
2019-11-05 00:23:55,525 train 400 2.069010e-02 -4.021234
2019-11-05 00:24:06,158 train 450 2.068199e-02 -3.656636
2019-11-05 00:24:16,844 train 500 2.065378e-02 -3.353230
2019-11-05 00:24:27,548 train 550 2.059863e-02 -3.098554
2019-11-05 00:24:38,274 train 600 2.055358e-02 -2.886314
2019-11-05 00:24:48,988 train 650 2.051006e-02 -2.721162
2019-11-05 00:24:59,749 train 700 2.047303e-02 -2.561726
2019-11-05 00:25:10,410 train 750 2.044363e-02 -2.437219
2019-11-05 00:25:21,097 train 800 2.041671e-02 -2.325336
2019-11-05 00:25:31,782 train 850 2.041264e-02 -2.233245
2019-11-05 00:25:34,938 training loss; R2: 2.040121e-02 -2.204055
2019-11-05 00:25:35,546 valid 000 1.902128e-02 -0.069754
2019-11-05 00:25:46,101 valid 050 1.687709e-02 -0.881839
2019-11-05 00:25:55,499 validation loss; R2: 1.678364e-02 -0.713854
2019-11-05 00:25:55,569 epoch 55 lr 2.000000e-04
2019-11-05 00:25:56,265 train 000 1.914191e-02 -0.515620
2019-11-05 00:26:07,036 train 050 2.049410e-02 -0.548840
2019-11-05 00:26:17,775 train 100 2.009090e-02 -1.582519
2019-11-05 00:26:28,533 train 150 2.002568e-02 -1.214563
2019-11-05 00:26:39,252 train 200 2.017197e-02 -1.067918
2019-11-05 00:26:50,055 train 250 2.012741e-02 -0.986652
2019-11-05 00:27:00,939 train 300 2.011653e-02 -0.942047
2019-11-05 00:27:11,810 train 350 2.014547e-02 -0.919965
2019-11-05 00:27:22,684 train 400 2.007940e-02 -0.852705
2019-11-05 00:27:33,583 train 450 2.003205e-02 -0.816772
2019-11-05 00:27:44,431 train 500 1.997549e-02 -0.790459
2019-11-05 00:27:55,286 train 550 1.996393e-02 -0.789970
2019-11-05 00:28:06,158 train 600 1.997438e-02 -0.817863
2019-11-05 00:28:17,030 train 650 1.997975e-02 -0.814718
2019-11-05 00:28:27,867 train 700 1.992683e-02 -0.842604
2019-11-05 00:28:38,716 train 750 1.990625e-02 -0.834726
2019-11-05 00:28:49,603 train 800 1.991317e-02 -0.815575
2019-11-05 00:29:00,413 train 850 1.993042e-02 -0.790143
2019-11-05 00:29:03,676 training loss; R2: 1.994113e-02 -0.787498
2019-11-05 00:29:04,322 valid 000 1.890730e-02 -0.151949
2019-11-05 00:29:14,958 valid 050 1.702473e-02 -0.756302
2019-11-05 00:29:24,638 validation loss; R2: 1.703550e-02 -1.147208
2019-11-05 00:29:24,730 epoch 56 lr 2.000000e-04
2019-11-05 00:29:25,489 train 000 1.710529e-02 -2.744995
2019-11-05 00:29:36,399 train 050 2.045443e-02 -1.093797
2019-11-05 00:29:47,258 train 100 2.071246e-02 -0.921359
2019-11-05 00:29:57,980 train 150 2.194235e-02 -0.825612
2019-11-05 00:30:08,764 train 200 2.256378e-02 -0.762288
2019-11-05 00:30:19,429 train 250 2.270038e-02 -1.805354
2019-11-05 00:30:30,277 train 300 2.255930e-02 -1.641527
2019-11-05 00:30:41,040 train 350 2.252167e-02 -1.474721
2019-11-05 00:30:51,853 train 400 2.236711e-02 -1.375568
2019-11-05 00:31:02,642 train 450 2.217159e-02 -1.291163
2019-11-05 00:31:13,372 train 500 2.203956e-02 -1.210058
2019-11-05 00:31:24,081 train 550 2.188323e-02 -1.152780
2019-11-05 00:31:34,842 train 600 2.179526e-02 -1.086576
2019-11-05 00:31:45,629 train 650 2.171197e-02 -1.110755
2019-11-05 00:31:56,399 train 700 2.158864e-02 -1.061865
2019-11-05 00:32:07,243 train 750 2.155895e-02 -1.042977
2019-11-05 00:32:18,022 train 800 2.151043e-02 -1.040555
2019-11-05 00:32:28,814 train 850 2.145196e-02 -1.030317
2019-11-05 00:32:31,946 training loss; R2: 2.144634e-02 -1.017761
2019-11-05 00:32:32,597 valid 000 1.885857e-02 -0.745665
2019-11-05 00:32:43,161 valid 050 1.709227e-02 -0.935401
2019-11-05 00:32:52,909 validation loss; R2: 1.716760e-02 -6.501061
2019-11-05 00:32:52,981 epoch 57 lr 2.000000e-04
2019-11-05 00:32:53,724 train 000 1.935801e-02 -6.389514
2019-11-05 00:33:04,554 train 050 2.052147e-02 -0.627168
2019-11-05 00:33:15,360 train 100 2.032412e-02 -0.688636
2019-11-05 00:33:25,921 train 150 2.028857e-02 -0.660793
2019-11-05 00:33:36,371 train 200 2.030989e-02 -0.608877
2019-11-05 00:33:46,942 train 250 2.023771e-02 -0.598135
2019-11-05 00:33:57,669 train 300 2.019454e-02 -0.588041
2019-11-05 00:34:08,401 train 350 2.017740e-02 -0.606883
2019-11-05 00:34:19,128 train 400 2.012666e-02 -0.601607
2019-11-05 00:34:29,818 train 450 2.010400e-02 -0.614706
2019-11-05 00:34:40,282 train 500 2.012236e-02 -0.601727
2019-11-05 00:34:51,049 train 550 2.008470e-02 -0.587949
2019-11-05 00:35:01,760 train 600 2.008582e-02 -0.700282
2019-11-05 00:35:12,505 train 650 2.008440e-02 -0.680739
2019-11-05 00:35:23,319 train 700 2.011960e-02 -0.664371
2019-11-05 00:35:34,035 train 750 2.013180e-02 -0.655040
2019-11-05 00:35:44,805 train 800 2.013611e-02 -0.644880
2019-11-05 00:35:55,555 train 850 2.013243e-02 -0.657126
2019-11-05 00:35:58,720 training loss; R2: 2.012671e-02 -0.656690
2019-11-05 00:35:59,320 valid 000 1.706720e-02 0.008734
2019-11-05 00:36:09,902 valid 050 1.597785e-02 -0.616387
2019-11-05 00:36:19,283 validation loss; R2: 1.606996e-02 -0.908547
2019-11-05 00:36:19,352 epoch 58 lr 2.000000e-04
2019-11-05 00:36:20,088 train 000 1.888637e-02 -0.783253
2019-11-05 00:36:30,976 train 050 1.953027e-02 -0.592150
2019-11-05 00:36:41,840 train 100 1.994127e-02 -0.587478
2019-11-05 00:36:52,675 train 150 1.992196e-02 -0.533041
2019-11-05 00:37:03,297 train 200 1.987075e-02 -0.517711
2019-11-05 00:37:14,059 train 250 1.987532e-02 -0.528782
2019-11-05 00:37:24,866 train 300 1.988512e-02 -0.516421
2019-11-05 00:37:35,695 train 350 1.994952e-02 -0.547986
2019-11-05 00:37:46,537 train 400 1.992199e-02 -0.540308
2019-11-05 00:37:57,361 train 450 1.997353e-02 -0.553607
2019-11-05 00:38:08,140 train 500 1.995038e-02 -0.549777
2019-11-05 00:38:18,875 train 550 1.992582e-02 -0.555990
2019-11-05 00:38:29,706 train 600 1.990298e-02 -0.591916
2019-11-05 00:38:40,450 train 650 1.992996e-02 -0.595402
2019-11-05 00:38:51,310 train 700 1.992786e-02 -0.597274
2019-11-05 00:39:02,260 train 750 1.993308e-02 -0.600972
2019-11-05 00:39:13,083 train 800 1.992628e-02 -0.605756
2019-11-05 00:39:23,917 train 850 1.991306e-02 -0.613078
2019-11-05 00:39:27,170 training loss; R2: 1.991309e-02 -0.608410
2019-11-05 00:39:27,738 valid 000 1.318025e-02 -0.223806
2019-11-05 00:39:38,337 valid 050 1.571487e-02 -0.916052
2019-11-05 00:39:47,753 validation loss; R2: 1.571452e-02 -0.926586
2019-11-05 00:39:47,829 epoch 59 lr 2.000000e-04
2019-11-05 00:39:48,532 train 000 2.034959e-02 -0.834688
2019-11-05 00:39:59,513 train 050 1.992178e-02 -0.445450
2019-11-05 00:40:10,585 train 100 2.003820e-02 -0.550183
2019-11-05 00:40:21,340 train 150 2.005900e-02 -0.530507
2019-11-05 00:40:32,003 train 200 1.998927e-02 -0.531932
2019-11-05 00:40:42,811 train 250 1.995993e-02 -0.566915
2019-11-05 00:40:53,608 train 300 1.988025e-02 -0.550758
2019-11-05 00:41:04,385 train 350 1.984643e-02 -0.547008
2019-11-05 00:41:15,205 train 400 1.983317e-02 -0.563666
2019-11-05 00:41:25,987 train 450 1.989968e-02 -0.595467
2019-11-05 00:41:36,745 train 500 2.005716e-02 -0.598498
2019-11-05 00:41:47,543 train 550 2.015469e-02 -0.590375
2019-11-05 00:41:58,262 train 600 2.019026e-02 -0.588995
2019-11-05 00:42:09,006 train 650 2.018775e-02 -0.678773
2019-11-05 00:42:19,760 train 700 2.020519e-02 -0.671219
2019-11-05 00:42:30,482 train 750 2.021274e-02 -0.728402
2019-11-05 00:42:41,366 train 800 2.020298e-02 -0.731229
2019-11-05 00:42:52,159 train 850 2.016593e-02 -0.730429
2019-11-05 00:42:55,316 training loss; R2: 2.017006e-02 -9.332233
2019-11-05 00:42:55,937 valid 000 1.809602e-02 0.077116
2019-11-05 00:43:06,709 valid 050 1.672631e-02 -0.637667
2019-11-05 00:43:16,280 validation loss; R2: 1.669818e-02 -0.656811
2019-11-05 00:43:16,348 epoch 60 lr 2.000000e-04
2019-11-05 00:43:17,197 train 000 2.058739e-02 -0.302708
2019-11-05 00:43:28,213 train 050 2.023035e-02 -0.638597
2019-11-05 00:43:39,287 train 100 2.010651e-02 -0.592031
2019-11-05 00:43:50,030 train 150 2.004661e-02 -0.647712
2019-11-05 00:44:00,688 train 200 2.007432e-02 -0.649694
2019-11-05 00:44:11,625 train 250 2.011251e-02 -0.641522
2019-11-05 00:44:22,484 train 300 2.009728e-02 -0.598556
2019-11-05 00:44:33,268 train 350 2.010866e-02 -0.657288
2019-11-05 00:44:44,006 train 400 2.011994e-02 -0.662744
2019-11-05 00:44:54,744 train 450 2.011425e-02 -0.627238
2019-11-05 00:45:05,465 train 500 2.005770e-02 -0.646768
2019-11-05 00:45:16,193 train 550 2.002790e-02 -0.654853
2019-11-05 00:45:26,857 train 600 2.004478e-02 -0.658270
2019-11-05 00:45:37,526 train 650 2.004018e-02 -0.682999
2019-11-05 00:45:48,425 train 700 2.009966e-02 -0.678952
2019-11-05 00:45:59,322 train 750 2.007407e-02 -0.670750
2019-11-05 00:46:10,213 train 800 2.006592e-02 -0.675512
2019-11-05 00:46:21,107 train 850 2.004590e-02 -0.670029
2019-11-05 00:46:24,314 training loss; R2: 2.005198e-02 -0.667195
2019-11-05 00:46:24,901 valid 000 1.515037e-02 -0.693864
2019-11-05 00:46:35,913 valid 050 1.599701e-02 -0.678808
2019-11-05 00:46:45,608 validation loss; R2: 1.603985e-02 -0.585472
2019-11-05 00:46:45,680 epoch 61 lr 2.000000e-04
2019-11-05 00:46:46,444 train 000 2.026181e-02 0.043549
2019-11-05 00:46:57,367 train 050 2.032309e-02 -0.558143
2019-11-05 00:47:08,318 train 100 2.034164e-02 -0.510971
2019-11-05 00:47:19,126 train 150 2.019363e-02 -0.578752
2019-11-05 00:47:29,933 train 200 2.006410e-02 -0.621618
2019-11-05 00:47:40,708 train 250 1.997295e-02 -0.677830
2019-11-05 00:47:51,649 train 300 2.000942e-02 -0.643152
2019-11-05 00:48:02,431 train 350 2.003308e-02 -0.694246
2019-11-05 00:48:13,328 train 400 2.008187e-02 -0.691981
2019-11-05 00:48:24,375 train 450 2.002634e-02 -0.669650
2019-11-05 00:48:35,263 train 500 2.001103e-02 -0.668494
2019-11-05 00:48:46,012 train 550 2.008315e-02 -0.664284
2019-11-05 00:48:56,817 train 600 2.010605e-02 -0.658210
2019-11-05 00:49:07,619 train 650 2.011807e-02 -0.658408
2019-11-05 00:49:18,480 train 700 2.013581e-02 -0.644388
2019-11-05 00:49:29,391 train 750 2.014871e-02 -0.655630
2019-11-05 00:49:40,129 train 800 2.015672e-02 -0.660121
2019-11-05 00:49:50,981 train 850 2.014864e-02 -0.673209
2019-11-05 00:49:54,278 training loss; R2: 2.014192e-02 -0.675266
2019-11-05 00:49:54,872 valid 000 1.778423e-02 -0.440825
2019-11-05 00:50:05,571 valid 050 1.582502e-02 -0.868697
2019-11-05 00:50:15,361 validation loss; R2: 1.612448e-02 -0.773517
2019-11-05 00:50:15,432 epoch 62 lr 2.000000e-04
2019-11-05 00:50:16,174 train 000 2.291039e-02 -0.145988
2019-11-05 00:50:27,257 train 050 2.003475e-02 -0.525418
2019-11-05 00:50:38,171 train 100 2.023235e-02 -0.577067
2019-11-05 00:50:48,872 train 150 2.028559e-02 -0.590212
2019-11-05 00:50:59,494 train 200 2.022398e-02 -0.630015
2019-11-05 00:51:10,146 train 250 2.017063e-02 -0.648974
2019-11-05 00:51:20,803 train 300 2.019305e-02 -0.648921
2019-11-05 00:51:31,499 train 350 2.021124e-02 -0.637633
2019-11-05 00:51:42,193 train 400 2.015090e-02 -0.630027
2019-11-05 00:51:52,898 train 450 2.010400e-02 -0.612712
2019-11-05 00:52:03,588 train 500 2.008857e-02 -0.607111
2019-11-05 00:52:14,085 train 550 2.010654e-02 -0.631069
2019-11-05 00:52:24,648 train 600 2.010273e-02 -0.634528
2019-11-05 00:52:35,400 train 650 2.009297e-02 -0.622321
2019-11-05 00:52:46,204 train 700 2.005461e-02 -0.626398
2019-11-05 00:52:57,013 train 750 2.002337e-02 -0.627709
2019-11-05 00:53:07,811 train 800 2.000542e-02 -0.628952
2019-11-05 00:53:18,600 train 850 2.006770e-02 -0.625968
2019-11-05 00:53:21,803 training loss; R2: 2.007201e-02 -0.627396
2019-11-05 00:53:22,369 valid 000 1.709931e-02 -0.482121
2019-11-05 00:53:33,078 valid 050 1.682097e-02 -1.880119
2019-11-05 00:53:42,566 validation loss; R2: 1.662948e-02 -1.228305
2019-11-05 00:53:42,623 epoch 63 lr 2.000000e-04
2019-11-05 00:53:43,360 train 000 2.085477e-02 -1.069610
2019-11-05 00:53:54,247 train 050 2.020999e-02 -0.560133
2019-11-05 00:54:05,049 train 100 1.996614e-02 -0.487011
2019-11-05 00:54:15,816 train 150 1.993434e-02 -0.633410
2019-11-05 00:54:26,600 train 200 1.988596e-02 -0.629738
2019-11-05 00:54:37,402 train 250 1.995117e-02 -0.594383
2019-11-05 00:54:48,466 train 300 1.998334e-02 -0.585180
2019-11-05 00:54:59,536 train 350 2.000597e-02 -0.578621
2019-11-05 00:55:10,447 train 400 2.004590e-02 -0.567509
2019-11-05 00:55:21,335 train 450 2.001564e-02 -0.609932
2019-11-05 00:55:32,363 train 500 2.002687e-02 -0.619097
2019-11-05 00:55:43,219 train 550 1.998665e-02 -0.609772
2019-11-05 00:55:54,109 train 600 2.001303e-02 -0.703614
2019-11-05 00:56:05,036 train 650 1.996218e-02 -0.697649
2019-11-05 00:56:16,013 train 700 1.995435e-02 -0.694168
2019-11-05 00:56:26,976 train 750 1.994270e-02 -0.691332
2019-11-05 00:56:37,893 train 800 1.994481e-02 -0.688699
2019-11-05 00:56:48,753 train 850 1.993753e-02 -0.693677
2019-11-05 00:56:52,028 training loss; R2: 1.991697e-02 -0.689482
2019-11-05 00:56:52,604 valid 000 1.794939e-02 -0.180515
2019-11-05 00:57:03,423 valid 050 1.710257e-02 -0.955580
2019-11-05 00:57:12,946 validation loss; R2: 1.704865e-02 -1.316669
2019-11-05 00:57:13,009 epoch 64 lr 2.000000e-04
2019-11-05 00:57:13,746 train 000 1.922200e-02 -0.651385
2019-11-05 00:57:24,732 train 050 2.026108e-02 -0.493585
2019-11-05 00:57:35,711 train 100 2.001223e-02 -1.090740
2019-11-05 00:57:46,418 train 150 1.992295e-02 -0.995542
2019-11-05 00:57:57,023 train 200 1.992931e-02 -0.886273
2019-11-05 00:58:07,830 train 250 2.012881e-02 -0.852146
2019-11-05 00:58:18,805 train 300 2.017707e-02 -0.833464
2019-11-05 00:58:29,785 train 350 2.031291e-02 -0.817760
2019-11-05 00:58:40,806 train 400 2.039224e-02 -0.823872
2019-11-05 00:58:51,757 train 450 2.044516e-02 -0.795577
2019-11-05 00:59:02,810 train 500 2.042787e-02 -0.775591
2019-11-05 00:59:13,836 train 550 2.038765e-02 -0.766261
2019-11-05 00:59:24,836 train 600 2.034847e-02 -0.758780
2019-11-05 00:59:35,895 train 650 2.033978e-02 -0.747879
2019-11-05 00:59:46,886 train 700 2.031629e-02 -0.746106
2019-11-05 00:59:57,897 train 750 2.031808e-02 -0.731843
2019-11-05 01:00:08,879 train 800 2.028801e-02 -0.750164
2019-11-05 01:00:19,880 train 850 2.026636e-02 -0.741898
2019-11-05 01:00:23,111 training loss; R2: 2.025263e-02 -0.738425
2019-11-05 01:00:23,693 valid 000 1.478782e-02 -2.419200
2019-11-05 01:00:34,606 valid 050 1.626538e-02 -1.045343
2019-11-05 01:00:44,228 validation loss; R2: 1.627074e-02 -1.148151
2019-11-05 01:00:44,291 epoch 65 lr 2.000000e-04
2019-11-05 01:00:45,007 train 000 1.937401e-02 -0.226137
2019-11-05 01:00:56,034 train 050 2.001264e-02 -0.586066
2019-11-05 01:01:06,895 train 100 1.998252e-02 -0.612405
2019-11-05 01:01:17,449 train 150 2.011870e-02 -0.598371
2019-11-05 01:01:28,053 train 200 2.001014e-02 -0.597451
2019-11-05 01:01:38,721 train 250 1.990667e-02 -0.589172
2019-11-05 01:01:49,418 train 300 1.999710e-02 -0.594633
2019-11-05 01:02:00,110 train 350 1.999759e-02 -0.655247
2019-11-05 01:02:10,808 train 400 1.991381e-02 -0.745257
2019-11-05 01:02:21,769 train 450 1.993962e-02 -0.735097
2019-11-05 01:02:32,723 train 500 1.993334e-02 -0.719825
2019-11-05 01:02:43,490 train 550 1.999311e-02 -0.699844
2019-11-05 01:02:54,127 train 600 1.998741e-02 -0.690014
2019-11-05 01:03:04,789 train 650 1.999031e-02 -0.696998
2019-11-05 01:03:15,479 train 700 1.999649e-02 -0.679288
2019-11-05 01:03:26,084 train 750 1.997623e-02 -0.669153
2019-11-05 01:03:36,728 train 800 1.999825e-02 -0.678536
2019-11-05 01:03:47,369 train 850 2.000297e-02 -0.668740
2019-11-05 01:03:50,528 training loss; R2: 1.998114e-02 -0.665616
2019-11-05 01:03:51,097 valid 000 1.762038e-02 -0.136008
2019-11-05 01:04:01,885 valid 050 1.705949e-02 -0.402234
2019-11-05 01:04:11,353 validation loss; R2: 1.697573e-02 -0.497355
2019-11-05 01:04:11,417 epoch 66 lr 2.000000e-04
2019-11-05 01:04:12,129 train 000 2.327065e-02 -0.178188
2019-11-05 01:04:23,080 train 050 1.981090e-02 -0.606043
2019-11-05 01:04:34,013 train 100 1.977275e-02 -0.512223
2019-11-05 01:04:45,047 train 150 1.984654e-02 -0.593637
2019-11-05 01:04:56,066 train 200 1.991754e-02 -0.623841
2019-11-05 01:05:06,902 train 250 2.000861e-02 -0.600249
2019-11-05 01:05:17,807 train 300 2.003683e-02 -0.590873
2019-11-05 01:05:28,642 train 350 2.003385e-02 -0.589849
2019-11-05 01:05:39,307 train 400 2.002102e-02 -0.581970
2019-11-05 01:05:50,168 train 450 2.002691e-02 -0.569200
2019-11-05 01:06:00,852 train 500 2.003824e-02 -0.598771
2019-11-05 01:06:11,592 train 550 2.005463e-02 -0.618972
2019-11-05 01:06:22,329 train 600 2.005339e-02 -0.607732
2019-11-05 01:06:33,192 train 650 2.003496e-02 -0.595856
2019-11-05 01:06:43,929 train 700 2.006059e-02 -0.592345
2019-11-05 01:06:54,700 train 750 2.010899e-02 -0.634945
2019-11-05 01:07:05,576 train 800 2.007758e-02 -0.649166
2019-11-05 01:07:16,487 train 850 2.007089e-02 -0.646151
2019-11-05 01:07:19,786 training loss; R2: 2.006452e-02 -0.649260
2019-11-05 01:07:20,398 valid 000 1.612986e-02 -7.401000
2019-11-05 01:07:31,008 valid 050 1.615206e-02 -0.980107
2019-11-05 01:07:40,740 validation loss; R2: 1.600166e-02 -0.903663
2019-11-05 01:07:40,819 epoch 67 lr 2.000000e-04
2019-11-05 01:07:41,567 train 000 2.234413e-02 -0.334834
2019-11-05 01:07:52,510 train 050 2.005877e-02 -0.666314
2019-11-05 01:08:03,309 train 100 2.008494e-02 -0.668198
2019-11-05 01:08:13,795 train 150 1.989775e-02 -0.600320
2019-11-05 01:08:24,559 train 200 2.004339e-02 -0.616114
2019-11-05 01:08:35,352 train 250 2.003862e-02 -0.645398
2019-11-05 01:08:45,922 train 300 2.003640e-02 -0.639810
2019-11-05 01:08:56,613 train 350 2.002680e-02 -0.629789
2019-11-05 01:09:07,336 train 400 2.042387e-02 -0.646648
2019-11-05 01:09:17,890 train 450 2.066057e-02 -0.631818
2019-11-05 01:09:28,437 train 500 2.067436e-02 -0.637892
2019-11-05 01:09:39,037 train 550 2.068087e-02 -0.636989
2019-11-05 01:09:49,670 train 600 2.066115e-02 -0.670136
2019-11-05 01:10:00,298 train 650 2.063326e-02 -0.649047
2019-11-05 01:10:10,943 train 700 2.059168e-02 -0.642356
2019-11-05 01:10:21,640 train 750 2.057927e-02 -0.653549
2019-11-05 01:10:32,267 train 800 2.054112e-02 -0.639741
2019-11-05 01:10:42,917 train 850 2.048137e-02 -0.784949
2019-11-05 01:10:46,121 training loss; R2: 2.047260e-02 -0.781090
2019-11-05 01:10:46,714 valid 000 1.661493e-02 -0.176268
2019-11-05 01:10:57,196 valid 050 1.646927e-02 -0.707541
2019-11-05 01:11:06,681 validation loss; R2: 1.606805e-02 -0.952759
2019-11-05 01:11:06,742 epoch 68 lr 2.000000e-04
2019-11-05 01:11:07,500 train 000 1.841355e-02 -0.436402
2019-11-05 01:11:18,344 train 050 1.989819e-02 -0.548066
2019-11-05 01:11:29,230 train 100 1.997152e-02 -0.575114
2019-11-05 01:11:39,921 train 150 2.010793e-02 -0.603021
2019-11-05 01:11:50,733 train 200 1.996395e-02 -0.566112
2019-11-05 01:12:01,609 train 250 1.986473e-02 -0.605420
2019-11-05 01:12:12,403 train 300 1.985614e-02 -0.626619
2019-11-05 01:12:23,175 train 350 1.985114e-02 -0.634126
2019-11-05 01:12:33,969 train 400 1.988891e-02 -0.639079
2019-11-05 01:12:44,689 train 450 1.990708e-02 -0.641352
2019-11-05 01:12:55,331 train 500 1.986644e-02 -0.636842
2019-11-05 01:13:06,036 train 550 1.984732e-02 -0.635401
2019-11-05 01:13:16,792 train 600 1.990358e-02 -0.634401
2019-11-05 01:13:27,489 train 650 1.989304e-02 -0.638440
2019-11-05 01:13:38,260 train 700 1.991275e-02 -0.631466
2019-11-05 01:13:49,076 train 750 1.990678e-02 -0.624861
2019-11-05 01:13:59,886 train 800 1.990634e-02 -0.632075
2019-11-05 01:14:10,708 train 850 1.991300e-02 -0.641600
2019-11-05 01:14:13,934 training loss; R2: 1.989183e-02 -0.643649
2019-11-05 01:14:14,530 valid 000 1.438254e-02 -7.869362
2019-11-05 01:14:25,145 valid 050 1.582244e-02 -1.051703
2019-11-05 01:14:34,970 validation loss; R2: 1.601893e-02 -0.913791
2019-11-05 01:14:35,034 epoch 69 lr 2.000000e-04
2019-11-05 01:14:35,774 train 000 2.466450e-02 -0.131878
2019-11-05 01:14:46,615 train 050 1.975754e-02 -0.478008
2019-11-05 01:14:57,439 train 100 1.982781e-02 -0.567174
2019-11-05 01:15:08,081 train 150 1.980336e-02 -0.969946
2019-11-05 01:15:18,793 train 200 1.978296e-02 -1.214918
2019-11-05 01:15:29,534 train 250 1.975841e-02 -1.086859
2019-11-05 01:15:40,296 train 300 1.994339e-02 -1.009131
2019-11-05 01:15:51,238 train 350 2.001223e-02 -1.146869
2019-11-05 01:16:02,021 train 400 2.007193e-02 -1.080396
2019-11-05 01:16:12,773 train 450 2.005788e-02 -1.252444
2019-11-05 01:16:23,429 train 500 2.010978e-02 -1.187911
2019-11-05 01:16:34,103 train 550 2.012371e-02 -1.138928
2019-11-05 01:16:44,952 train 600 2.013432e-02 -1.100448
2019-11-05 01:16:55,738 train 650 2.015071e-02 -1.057507
2019-11-05 01:17:06,534 train 700 2.016708e-02 -1.021885
2019-11-05 01:17:17,377 train 750 2.019891e-02 -0.990768
2019-11-05 01:17:28,104 train 800 2.022261e-02 -0.978080
2019-11-05 01:17:38,953 train 850 2.023854e-02 -0.959203
2019-11-05 01:17:42,189 training loss; R2: 2.024559e-02 -0.952132
2019-11-05 01:17:42,809 valid 000 1.492841e-02 -6.210505
2019-11-05 01:17:53,606 valid 050 1.749838e-02 -0.996750
2019-11-05 01:18:03,391 validation loss; R2: 1.807194e-02 -1.027096
2019-11-05 01:18:03,458 epoch 70 lr 2.000000e-04
2019-11-05 01:18:04,199 train 000 2.230161e-02 -0.292673
2019-11-05 01:18:15,229 train 050 2.065970e-02 -0.603907
2019-11-05 01:18:26,114 train 100 2.049835e-02 -0.610596
2019-11-05 01:18:36,734 train 150 2.047991e-02 -0.604778
2019-11-05 01:18:47,340 train 200 2.039610e-02 -0.601691
2019-11-05 01:18:57,964 train 250 2.035024e-02 -0.585092
2019-11-05 01:19:08,605 train 300 2.025005e-02 -0.573009
2019-11-05 01:19:19,198 train 350 2.020037e-02 -0.551298
2019-11-05 01:19:29,812 train 400 2.016372e-02 -0.592436
2019-11-05 01:19:40,465 train 450 2.014733e-02 -0.609517
2019-11-05 01:19:51,276 train 500 2.013511e-02 -0.608698
2019-11-05 01:20:02,049 train 550 2.009735e-02 -0.606261
2019-11-05 01:20:12,802 train 600 2.009308e-02 -0.596222
2019-11-05 01:20:23,458 train 650 2.004441e-02 -0.589606
2019-11-05 01:20:34,086 train 700 2.003378e-02 -0.592895
2019-11-05 01:20:44,742 train 750 2.003069e-02 -0.605143
2019-11-05 01:20:55,377 train 800 2.005455e-02 -0.599344
2019-11-05 01:21:06,047 train 850 2.003129e-02 -0.606016
2019-11-05 01:21:09,276 training loss; R2: 2.004241e-02 -0.609904
2019-11-05 01:21:09,934 valid 000 1.494828e-02 -1.590820
2019-11-05 01:21:20,599 valid 050 1.623310e-02 -0.812629
2019-11-05 01:21:30,305 validation loss; R2: 1.603131e-02 -0.991105
2019-11-05 01:21:30,373 epoch 71 lr 2.000000e-04
2019-11-05 01:21:31,118 train 000 1.813986e-02 -0.325121
2019-11-05 01:21:41,989 train 050 1.978946e-02 -0.595095
2019-11-05 01:21:52,854 train 100 1.957586e-02 -0.553973
2019-11-05 01:22:03,705 train 150 1.966016e-02 -0.648770
2019-11-05 01:22:14,403 train 200 1.973382e-02 -0.657595
2019-11-05 01:22:25,146 train 250 1.977503e-02 -0.642001
2019-11-05 01:22:35,937 train 300 1.987776e-02 -0.636480
2019-11-05 01:22:46,649 train 350 1.994499e-02 -0.624762
2019-11-05 01:22:57,426 train 400 1.998065e-02 -0.613282
2019-11-05 01:23:08,152 train 450 1.999712e-02 -0.617019
2019-11-05 01:23:18,901 train 500 2.003366e-02 -0.635073
2019-11-05 01:23:29,652 train 550 2.010459e-02 -0.651527
2019-11-05 01:23:40,445 train 600 2.045402e-02 -0.656226
2019-11-05 01:23:51,224 train 650 2.059049e-02 -0.678765
2019-11-05 01:24:01,993 train 700 2.060899e-02 -0.669214
2019-11-05 01:24:12,766 train 750 2.061607e-02 -0.666559
2019-11-05 01:24:23,423 train 800 2.061001e-02 -0.659814
2019-11-05 01:24:34,183 train 850 2.062579e-02 -0.652005
2019-11-05 01:24:37,485 training loss; R2: 2.061499e-02 -0.652424
2019-11-05 01:24:38,081 valid 000 1.341908e-02 -0.561150
2019-11-05 01:24:49,067 valid 050 1.569908e-02 -0.845607
2019-11-05 01:24:59,008 validation loss; R2: 1.605214e-02 -0.972852
2019-11-05 01:24:59,076 epoch 72 lr 2.000000e-04
2019-11-05 01:24:59,788 train 000 1.903795e-02 -0.177898
2019-11-05 01:25:10,865 train 050 2.115935e-02 -0.598859
2019-11-05 01:25:21,795 train 100 2.077743e-02 -0.777331
2019-11-05 01:25:32,355 train 150 2.072568e-02 -0.734071
2019-11-05 01:25:42,971 train 200 2.078395e-02 -0.646676
2019-11-05 01:25:53,825 train 250 2.063671e-02 -1.858705
2019-11-05 01:26:04,696 train 300 2.056729e-02 -1.614544
2019-11-05 01:26:15,568 train 350 2.055961e-02 -1.450632
2019-11-05 01:26:26,427 train 400 2.053470e-02 -1.418495
2019-11-05 01:26:37,314 train 450 2.049201e-02 -1.338610
2019-11-05 01:26:48,177 train 500 2.045509e-02 -1.277607
2019-11-05 01:26:59,007 train 550 2.040877e-02 -1.214827
2019-11-05 01:27:09,823 train 600 2.040547e-02 -1.177077
2019-11-05 01:27:20,700 train 650 2.039411e-02 -3.006624
2019-11-05 01:27:31,541 train 700 2.041831e-02 -2.830434
2019-11-05 01:27:42,476 train 750 2.041292e-02 -2.683135
2019-11-05 01:27:53,349 train 800 2.043565e-02 -2.553410
2019-11-05 01:28:04,354 train 850 2.040208e-02 -2.443737
2019-11-05 01:28:07,624 training loss; R2: 2.040220e-02 -2.410930
2019-11-05 01:28:08,209 valid 000 1.707523e-02 -1.006868
2019-11-05 01:28:18,907 valid 050 1.614200e-02 -0.556750
2019-11-05 01:28:28,347 validation loss; R2: 1.622450e-02 -0.725716
2019-11-05 01:28:28,411 epoch 73 lr 2.000000e-04
2019-11-05 01:28:29,164 train 000 1.895638e-02 -0.226343
2019-11-05 01:28:39,939 train 050 2.024192e-02 -0.489644
2019-11-05 01:28:50,851 train 100 1.999709e-02 -0.580806
2019-11-05 01:29:01,645 train 150 2.017583e-02 -0.578683
2019-11-05 01:29:12,559 train 200 2.028592e-02 -0.561871
2019-11-05 01:29:23,520 train 250 2.033088e-02 -0.534972
2019-11-05 01:29:34,475 train 300 2.024525e-02 -0.590052
2019-11-05 01:29:45,402 train 350 2.018272e-02 -0.619136
2019-11-05 01:29:56,409 train 400 2.013538e-02 -0.636656
2019-11-05 01:30:07,369 train 450 2.015415e-02 -0.625301
2019-11-05 01:30:18,141 train 500 2.013976e-02 -0.634173
2019-11-05 01:30:28,902 train 550 2.016004e-02 -0.653194
2019-11-05 01:30:39,784 train 600 2.015499e-02 -0.634654
2019-11-05 01:30:50,654 train 650 2.016862e-02 -0.697905
2019-11-05 01:31:01,317 train 700 2.018349e-02 -0.694536
2019-11-05 01:31:11,966 train 750 2.020508e-02 -0.691400
2019-11-05 01:31:22,633 train 800 2.019673e-02 -0.674492
2019-11-05 01:31:33,267 train 850 2.020358e-02 -0.659446
2019-11-05 01:31:36,466 training loss; R2: 2.021160e-02 -0.655516
2019-11-05 01:31:37,070 valid 000 1.942834e-02 -1.218056
2019-11-05 01:31:47,865 valid 050 1.804039e-02 -0.624790
2019-11-05 01:31:57,405 validation loss; R2: 1.775608e-02 -0.557557
2019-11-05 01:31:57,466 epoch 74 lr 2.000000e-04
2019-11-05 01:31:58,164 train 000 1.824334e-02 -1.076250
2019-11-05 01:32:09,176 train 050 2.022031e-02 -0.645633
2019-11-05 01:32:20,107 train 100 2.051244e-02 -0.516933
2019-11-05 01:32:31,066 train 150 2.055314e-02 -0.618250
2019-11-05 01:32:41,835 train 200 2.057469e-02 -0.576313
2019-11-05 01:32:52,452 train 250 2.058214e-02 -0.537559
2019-11-05 01:33:03,068 train 300 2.049505e-02 -0.578897
2019-11-05 01:33:13,741 train 350 2.045908e-02 -0.572892
2019-11-05 01:33:24,401 train 400 2.060632e-02 -0.585290
2019-11-05 01:33:35,332 train 450 2.070331e-02 -0.602597
2019-11-05 01:33:46,276 train 500 2.097163e-02 -0.583782
2019-11-05 01:33:57,166 train 550 2.101098e-02 -0.579108
2019-11-05 01:34:08,106 train 600 2.097067e-02 -0.562517
2019-11-05 01:34:19,101 train 650 2.094874e-02 -0.572650
2019-11-05 01:34:30,103 train 700 2.086771e-02 -0.567545
2019-11-05 01:34:41,138 train 750 2.081477e-02 -0.560066
2019-11-05 01:34:52,144 train 800 2.080427e-02 -0.554098
2019-11-05 01:35:03,200 train 850 2.078596e-02 -0.575873
2019-11-05 01:35:06,444 training loss; R2: 2.078588e-02 -0.577246
2019-11-05 01:35:07,016 valid 000 1.490008e-02 0.018308
2019-11-05 01:35:17,829 valid 050 1.586683e-02 -0.935844
2019-11-05 01:35:27,335 validation loss; R2: 1.581079e-02 -0.842469
2019-11-05 01:35:27,420 epoch 75 lr 2.000000e-04
2019-11-05 01:35:28,122 train 000 1.823054e-02 -0.204422
2019-11-05 01:35:39,050 train 050 2.036251e-02 -0.502656
2019-11-05 01:35:49,818 train 100 2.025264e-02 -0.527819
2019-11-05 01:36:00,595 train 150 2.017361e-02 -0.527243
2019-11-05 01:36:11,357 train 200 2.013814e-02 -0.523079
2019-11-05 01:36:22,125 train 250 2.015331e-02 -0.643849
2019-11-05 01:36:32,783 train 300 2.010806e-02 -0.611584
2019-11-05 01:36:43,487 train 350 2.007026e-02 -0.662571
2019-11-05 01:36:54,197 train 400 2.010042e-02 -0.636934
2019-11-05 01:37:04,860 train 450 2.013588e-02 -0.630570
2019-11-05 01:37:15,588 train 500 2.018940e-02 -0.625109
2019-11-05 01:37:26,320 train 550 2.015939e-02 -0.624569
2019-11-05 01:37:36,999 train 600 2.020677e-02 -0.624813
2019-11-05 01:37:47,714 train 650 2.018831e-02 -0.618368
2019-11-05 01:37:58,420 train 700 2.018009e-02 -0.608589
2019-11-05 01:38:09,135 train 750 2.015973e-02 -0.611089
2019-11-05 01:38:19,891 train 800 2.015740e-02 -0.612133
2019-11-05 01:38:30,779 train 850 2.017096e-02 -0.606508
2019-11-05 01:38:34,018 training loss; R2: 2.017753e-02 -0.606754
2019-11-05 01:38:34,680 valid 000 1.604596e-02 -1.295252
2019-11-05 01:38:45,396 valid 050 1.597480e-02 -0.770781
2019-11-05 01:38:54,881 validation loss; R2: 1.582525e-02 -0.828573
2019-11-05 01:38:54,957 epoch 76 lr 2.000000e-04
2019-11-05 01:38:55,708 train 000 1.858868e-02 -0.449653
2019-11-05 01:39:06,577 train 050 1.974805e-02 -0.649521
2019-11-05 01:39:17,423 train 100 2.009995e-02 -0.624612
2019-11-05 01:39:28,138 train 150 2.001831e-02 -0.593037
2019-11-05 01:39:38,909 train 200 2.009740e-02 -0.618297
2019-11-05 01:39:49,662 train 250 2.008558e-02 -0.654607
2019-11-05 01:40:00,481 train 300 2.008879e-02 -0.649179
2019-11-05 01:40:11,311 train 350 2.008970e-02 -0.672808
2019-11-05 01:40:22,068 train 400 2.002973e-02 -0.675380
2019-11-05 01:40:32,838 train 450 2.007791e-02 -0.674399
2019-11-05 01:40:43,498 train 500 2.005642e-02 -0.665158
2019-11-05 01:40:54,378 train 550 2.006428e-02 -0.666889
2019-11-05 01:41:05,208 train 600 2.011073e-02 -0.711397
2019-11-05 01:41:16,029 train 650 2.011733e-02 -0.704442
2019-11-05 01:41:26,858 train 700 2.011606e-02 -0.723772
2019-11-05 01:41:37,781 train 750 2.011901e-02 -0.714409
2019-11-05 01:41:48,597 train 800 2.014053e-02 -0.715117
2019-11-05 01:41:59,546 train 850 2.013617e-02 -0.708352
2019-11-05 01:42:02,858 training loss; R2: 2.012951e-02 -0.705552
2019-11-05 01:42:03,448 valid 000 1.448623e-02 0.038839
2019-11-05 01:42:14,216 valid 050 1.488725e-02 -0.737712
2019-11-05 01:42:23,686 validation loss; R2: 1.489138e-02 -0.999150
2019-11-05 01:42:23,757 epoch 77 lr 2.000000e-04
2019-11-05 01:42:24,457 train 000 1.737483e-02 -0.590494
2019-11-05 01:42:35,366 train 050 2.049770e-02 -0.582683
2019-11-05 01:42:45,877 train 100 2.055857e-02 -0.630747
2019-11-05 01:42:56,401 train 150 2.048942e-02 -0.569059
2019-11-05 01:43:07,104 train 200 2.039500e-02 -0.567262
2019-11-05 01:43:17,800 train 250 2.040417e-02 -0.533102
2019-11-05 01:43:28,562 train 300 2.030990e-02 -0.581383
2019-11-05 01:43:39,279 train 350 2.022633e-02 -0.751182
2019-11-05 01:43:50,015 train 400 2.021270e-02 -0.741414
2019-11-05 01:44:00,765 train 450 2.018244e-02 -0.709949
2019-11-05 01:44:11,539 train 500 2.014395e-02 -0.705695
2019-11-05 01:44:22,216 train 550 2.010803e-02 -0.694269
2019-11-05 01:44:32,916 train 600 2.009204e-02 -0.670847
2019-11-05 01:44:43,634 train 650 2.008427e-02 -0.670079
2019-11-05 01:44:54,340 train 700 2.006719e-02 -0.658136
2019-11-05 01:45:05,057 train 750 2.012323e-02 -0.669961
2019-11-05 01:45:15,794 train 800 2.013305e-02 -0.659599
2019-11-05 01:45:26,516 train 850 2.010664e-02 -0.650283
2019-11-05 01:45:29,721 training loss; R2: 2.009455e-02 -0.644703
2019-11-05 01:45:30,285 valid 000 1.484035e-02 -0.157200
2019-11-05 01:45:40,859 valid 050 1.633172e-02 -0.508414
2019-11-05 01:45:50,262 validation loss; R2: 1.631758e-02 -0.681420
2019-11-05 01:45:50,331 epoch 78 lr 2.000000e-04
2019-11-05 01:45:51,045 train 000 1.874099e-02 -0.071052
2019-11-05 01:46:01,862 train 050 2.003899e-02 -0.655121
2019-11-05 01:46:12,781 train 100 2.026534e-02 -0.615741
2019-11-05 01:46:23,507 train 150 2.043670e-02 -0.633563
2019-11-05 01:46:34,253 train 200 2.041718e-02 -0.598423
2019-11-05 01:46:45,046 train 250 2.040498e-02 -0.623271
2019-11-05 01:46:55,967 train 300 2.033474e-02 -0.631445
2019-11-05 01:47:06,822 train 350 2.025688e-02 -0.641474
2019-11-05 01:47:17,709 train 400 2.023987e-02 -0.626111
2019-11-05 01:47:28,467 train 450 2.026022e-02 -0.648359
2019-11-05 01:47:39,285 train 500 2.025602e-02 -0.641792
2019-11-05 01:47:49,976 train 550 2.028159e-02 -0.668997
2019-11-05 01:48:00,591 train 600 2.022057e-02 -0.671517
2019-11-05 01:48:11,454 train 650 2.019580e-02 -0.684326
2019-11-05 01:48:22,389 train 700 2.020759e-02 -0.689454
2019-11-05 01:48:33,308 train 750 2.017258e-02 -0.681987
2019-11-05 01:48:44,167 train 800 2.016805e-02 -0.675946
2019-11-05 01:48:55,005 train 850 2.017041e-02 -0.674941
2019-11-05 01:48:58,287 training loss; R2: 2.017351e-02 -0.672266
2019-11-05 01:48:58,915 valid 000 1.724593e-02 -1.497836
2019-11-05 01:49:09,615 valid 050 1.546327e-02 -0.737405
2019-11-05 01:49:19,379 validation loss; R2: 1.549444e-02 -0.940695
2019-11-05 01:49:19,446 epoch 79 lr 2.000000e-04
2019-11-05 01:49:20,245 train 000 1.763462e-02 0.004938
2019-11-05 01:49:31,145 train 050 1.991304e-02 -0.495756
2019-11-05 01:49:41,890 train 100 1.998930e-02 -0.662985
2019-11-05 01:49:52,640 train 150 1.999751e-02 -0.983999
2019-11-05 01:50:03,579 train 200 1.994878e-02 -0.878312
2019-11-05 01:50:14,503 train 250 1.999623e-02 -0.829407
2019-11-05 01:50:25,422 train 300 1.999413e-02 -0.778033
2019-11-05 01:50:36,345 train 350 1.990085e-02 -0.753746
2019-11-05 01:50:47,273 train 400 1.991341e-02 -0.728371
2019-11-05 01:50:58,215 train 450 1.991301e-02 -0.725376
2019-11-05 01:51:09,178 train 500 1.991105e-02 -0.717222
2019-11-05 01:51:20,312 train 550 1.993601e-02 -0.709238
2019-11-05 01:51:31,216 train 600 1.993978e-02 -0.699454
2019-11-05 01:51:42,138 train 650 1.996922e-02 -0.694205
2019-11-05 01:51:53,043 train 700 1.998226e-02 -0.683863
2019-11-05 01:52:03,919 train 750 1.998199e-02 -0.683402
2019-11-05 01:52:14,751 train 800 1.999154e-02 -0.675084
2019-11-05 01:52:25,590 train 850 1.999402e-02 -0.670429
2019-11-05 01:52:28,795 training loss; R2: 2.001004e-02 -0.668036
2019-11-05 01:52:29,370 valid 000 1.428442e-02 0.148955
2019-11-05 01:52:40,001 valid 050 1.566284e-02 -0.562384
2019-11-05 01:52:49,682 validation loss; R2: 1.550543e-02 -0.645335
2019-11-05 01:52:49,751 epoch 80 lr 2.000000e-04
2019-11-05 01:52:50,506 train 000 1.754761e-02 0.007828
2019-11-05 01:53:01,338 train 050 2.041369e-02 -1.499875
2019-11-05 01:53:12,065 train 100 1.994706e-02 -1.105141
2019-11-05 01:53:22,758 train 150 1.984983e-02 -0.907892
2019-11-05 01:53:33,528 train 200 1.978783e-02 -0.799646
2019-11-05 01:53:44,294 train 250 1.987927e-02 -0.742019
2019-11-05 01:53:55,038 train 300 1.996545e-02 -0.741615
2019-11-05 01:54:05,828 train 350 2.000778e-02 -0.730402
2019-11-05 01:54:16,589 train 400 2.000307e-02 -0.713544
2019-11-05 01:54:27,354 train 450 2.003617e-02 -0.698911
2019-11-05 01:54:38,109 train 500 2.002629e-02 -0.726163
2019-11-05 01:54:48,834 train 550 2.002937e-02 -0.728510
2019-11-05 01:54:59,673 train 600 1.998354e-02 -0.703542
2019-11-05 01:55:10,476 train 650 1.998707e-02 -0.695619
2019-11-05 01:55:21,275 train 700 2.001434e-02 -0.697823
2019-11-05 01:55:32,010 train 750 2.000510e-02 -0.700160
2019-11-05 01:55:42,762 train 800 1.998897e-02 -0.740546
2019-11-05 01:55:53,545 train 850 1.998400e-02 -0.728685
2019-11-05 01:55:56,766 training loss; R2: 1.997612e-02 -0.724222
2019-11-05 01:55:57,422 valid 000 1.685029e-02 0.038241
2019-11-05 01:56:08,072 valid 050 1.617474e-02 -0.950216
2019-11-05 01:56:17,803 validation loss; R2: 1.627301e-02 -0.901420
2019-11-05 01:56:17,873 epoch 81 lr 2.000000e-04
2019-11-05 01:56:18,628 train 000 1.876036e-02 0.000066
2019-11-05 01:56:29,474 train 050 1.948539e-02 -0.495795
2019-11-05 01:56:40,153 train 100 1.974129e-02 -0.588205
2019-11-05 01:56:50,949 train 150 1.981390e-02 -0.550742
2019-11-05 01:57:01,825 train 200 1.999328e-02 -0.531902
2019-11-05 01:57:12,709 train 250 2.013052e-02 -0.549943
2019-11-05 01:57:23,587 train 300 2.023885e-02 -0.544053
2019-11-05 01:57:34,462 train 350 2.032216e-02 -0.541363
2019-11-05 01:57:45,275 train 400 2.025693e-02 -0.617058
2019-11-05 01:57:56,166 train 450 2.031154e-02 -0.619383
2019-11-05 01:58:07,011 train 500 2.030798e-02 -0.655623
2019-11-05 01:58:17,727 train 550 2.030833e-02 -0.650384
2019-11-05 01:58:28,572 train 600 2.027632e-02 -0.664700
2019-11-05 01:58:39,415 train 650 2.031233e-02 -0.659941
2019-11-05 01:58:50,229 train 700 2.026069e-02 -0.679888
2019-11-05 01:59:01,066 train 750 2.024631e-02 -0.675537
2019-11-05 01:59:11,929 train 800 2.020362e-02 -0.677837
2019-11-05 01:59:22,782 train 850 2.017675e-02 -0.667497
2019-11-05 01:59:26,053 training loss; R2: 2.017228e-02 -0.669839
2019-11-05 01:59:26,682 valid 000 1.782388e-02 -1.142343
2019-11-05 01:59:37,420 valid 050 1.636050e-02 -1.541732
2019-11-05 01:59:47,081 validation loss; R2: 1.623882e-02 -1.297261
2019-11-05 01:59:47,146 epoch 82 lr 2.000000e-04
2019-11-05 01:59:47,902 train 000 2.174141e-02 -1.004645
2019-11-05 01:59:58,908 train 050 1.996532e-02 -0.701058
2019-11-05 02:00:09,541 train 100 1.975688e-02 -0.600381
2019-11-05 02:00:20,309 train 150 1.996588e-02 -0.642329
2019-11-05 02:00:31,096 train 200 2.002790e-02 -0.608778
2019-11-05 02:00:41,880 train 250 2.003399e-02 -0.636742
2019-11-05 02:00:52,669 train 300 2.021975e-02 -0.626526
2019-11-05 02:01:03,472 train 350 2.027698e-02 -0.652942
2019-11-05 02:01:14,246 train 400 2.026111e-02 -0.654557
2019-11-05 02:01:24,962 train 450 2.023917e-02 -0.658945
2019-11-05 02:01:35,682 train 500 2.025807e-02 -0.651917
2019-11-05 02:01:46,447 train 550 2.020573e-02 -0.640831
2019-11-05 02:01:57,225 train 600 2.020055e-02 -0.686080
2019-11-05 02:02:07,998 train 650 2.021608e-02 -0.687858
2019-11-05 02:02:18,768 train 700 2.018924e-02 -0.675381
2019-11-05 02:02:29,501 train 750 2.016171e-02 -0.669075
2019-11-05 02:02:40,234 train 800 2.014772e-02 -0.659635
2019-11-05 02:02:50,993 train 850 2.015832e-02 -0.662623
2019-11-05 02:02:54,151 training loss; R2: 2.014032e-02 -0.661267
2019-11-05 02:02:54,765 valid 000 1.559559e-02 -0.488746
2019-11-05 02:03:05,435 valid 050 1.563361e-02 -0.773307
2019-11-05 02:03:15,063 validation loss; R2: 1.560822e-02 -1.057905
2019-11-05 02:03:15,123 epoch 83 lr 2.000000e-04
2019-11-05 02:03:15,874 train 000 1.686668e-02 0.051355
2019-11-05 02:03:26,610 train 050 1.988251e-02 -0.532698
2019-11-05 02:03:37,287 train 100 1.996321e-02 -0.584868
2019-11-05 02:03:48,099 train 150 1.989851e-02 -0.627900
2019-11-05 02:03:58,986 train 200 1.992915e-02 -0.633673
2019-11-05 02:04:09,870 train 250 1.985564e-02 -0.628847
2019-11-05 02:04:20,667 train 300 1.981032e-02 -0.636329
2019-11-05 02:04:31,519 train 350 1.986220e-02 -0.636762
2019-11-05 02:04:42,433 train 400 1.986795e-02 -0.652990
2019-11-05 02:04:53,305 train 450 1.985243e-02 -0.675671
2019-11-05 02:05:04,159 train 500 1.987697e-02 -0.666109
2019-11-05 02:05:15,006 train 550 1.990480e-02 -0.651298
2019-11-05 02:05:25,838 train 600 1.992620e-02 -0.655651
2019-11-05 02:05:36,678 train 650 1.993467e-02 -0.651761
2019-11-05 02:05:47,489 train 700 1.994693e-02 -0.670435
2019-11-05 02:05:58,333 train 750 1.993433e-02 -0.675467
2019-11-05 02:06:09,174 train 800 1.992122e-02 -0.675460
2019-11-05 02:06:20,017 train 850 1.991444e-02 -0.805053
2019-11-05 02:06:23,207 training loss; R2: 1.991392e-02 -0.800211
2019-11-05 02:06:23,859 valid 000 1.896153e-02 -1.635214
2019-11-05 02:06:34,447 valid 050 1.809472e-02 -0.630894
2019-11-05 02:06:44,153 validation loss; R2: 1.804631e-02 -0.860610
2019-11-05 02:06:44,219 epoch 84 lr 2.000000e-04
2019-11-05 02:06:44,988 train 000 2.375366e-02 -0.527953
2019-11-05 02:06:55,656 train 050 2.055249e-02 -0.490313
2019-11-05 02:07:06,265 train 100 2.046992e-02 -0.504507
2019-11-05 02:07:16,990 train 150 2.026508e-02 -0.509640
2019-11-05 02:07:27,881 train 200 2.014957e-02 -0.563196
2019-11-05 02:07:38,677 train 250 2.007440e-02 -0.562051
2019-11-05 02:07:49,532 train 300 2.007804e-02 -0.558745
2019-11-05 02:08:00,440 train 350 2.010045e-02 -0.565815
2019-11-05 02:08:11,380 train 400 2.017919e-02 -0.564125
2019-11-05 02:08:22,296 train 450 2.018847e-02 -0.559027
2019-11-05 02:08:33,208 train 500 2.020059e-02 -0.594143
2019-11-05 02:08:44,027 train 550 2.017113e-02 -0.593722
2019-11-05 02:08:54,825 train 600 2.015818e-02 -0.601566
2019-11-05 02:09:05,623 train 650 2.011414e-02 -0.604077
2019-11-05 02:09:16,462 train 700 2.010535e-02 -0.602726
2019-11-05 02:09:27,403 train 750 2.008880e-02 -0.604542
2019-11-05 02:09:38,215 train 800 2.005564e-02 -0.604290
2019-11-05 02:09:49,095 train 850 2.003374e-02 -0.602492
2019-11-05 02:09:52,293 training loss; R2: 2.003498e-02 -0.600645
2019-11-05 02:09:52,877 valid 000 1.416007e-02 -0.640793
2019-11-05 02:10:03,528 valid 050 1.584630e-02 -0.850248
2019-11-05 02:10:13,170 validation loss; R2: 1.612506e-02 -1.295371
2019-11-05 02:10:13,240 epoch 85 lr 2.000000e-04
2019-11-05 02:10:14,020 train 000 1.831339e-02 -0.603079
2019-11-05 02:10:24,822 train 050 1.968244e-02 -0.779795
2019-11-05 02:10:35,574 train 100 1.987018e-02 -0.773842
2019-11-05 02:10:46,368 train 150 2.011563e-02 -0.698071
2019-11-05 02:10:57,264 train 200 2.015780e-02 -0.686995
2019-11-05 02:11:08,024 train 250 2.011998e-02 -0.664620
2019-11-05 02:11:18,798 train 300 2.010352e-02 -0.673936
2019-11-05 02:11:29,571 train 350 2.012205e-02 -0.790817
2019-11-05 02:11:40,345 train 400 2.005399e-02 -0.754404
2019-11-05 02:11:51,113 train 450 2.007836e-02 -0.741429
2019-11-05 02:12:01,942 train 500 2.009077e-02 -0.726397
2019-11-05 02:12:12,740 train 550 2.008365e-02 -0.715977
2019-11-05 02:12:23,529 train 600 2.007423e-02 -0.741814
2019-11-05 02:12:34,340 train 650 2.007236e-02 -0.735250
2019-11-05 02:12:45,075 train 700 2.010934e-02 -0.735052
2019-11-05 02:12:55,879 train 750 2.008706e-02 -0.793325
2019-11-05 02:13:06,696 train 800 2.006398e-02 -0.785805
2019-11-05 02:13:17,496 train 850 2.003747e-02 -0.768353
2019-11-05 02:13:20,774 training loss; R2: 2.004588e-02 -0.762125
2019-11-05 02:13:21,398 valid 000 2.349975e-02 -2.193503
2019-11-05 02:13:32,105 valid 050 2.410954e-02 -0.664043
2019-11-05 02:13:41,772 validation loss; R2: 2.383633e-02 -0.679432
2019-11-05 02:13:41,843 epoch 86 lr 2.000000e-04
2019-11-05 02:13:42,571 train 000 2.288168e-02 -0.237147
2019-11-05 02:13:53,368 train 050 2.023808e-02 -0.563876
2019-11-05 02:14:04,042 train 100 2.007175e-02 -0.681417
2019-11-05 02:14:14,873 train 150 2.005662e-02 -0.630776
2019-11-05 02:14:25,717 train 200 2.004985e-02 -0.639139
2019-11-05 02:14:36,573 train 250 2.006379e-02 -0.594940
2019-11-05 02:14:47,403 train 300 2.010116e-02 -0.599781
2019-11-05 02:14:58,274 train 350 2.007517e-02 -0.656459
2019-11-05 02:15:09,158 train 400 2.011320e-02 -0.653550
2019-11-05 02:15:19,938 train 450 2.010707e-02 -0.640981
2019-11-05 02:15:30,805 train 500 2.010017e-02 -0.641557
2019-11-05 02:15:41,687 train 550 2.007577e-02 -0.633670
2019-11-05 02:15:52,582 train 600 2.007493e-02 -0.626288
2019-11-05 02:16:03,483 train 650 2.004948e-02 -0.629616
2019-11-05 02:16:14,377 train 700 2.002468e-02 -0.642062
2019-11-05 02:16:25,239 train 750 2.000361e-02 -0.661750
2019-11-05 02:16:36,144 train 800 2.000575e-02 -0.660142
2019-11-05 02:16:47,025 train 850 1.999645e-02 -0.710566
2019-11-05 02:16:50,231 training loss; R2: 2.001497e-02 -0.708950
2019-11-05 02:16:50,860 valid 000 1.647142e-02 -7.402694
2019-11-05 02:17:01,516 valid 050 1.586019e-02 -1.367629
2019-11-05 02:17:11,195 validation loss; R2: 1.582941e-02 -1.177588
2019-11-05 02:17:11,256 epoch 87 lr 2.000000e-04
2019-11-05 02:17:11,972 train 000 1.905077e-02 -0.113943
2019-11-05 02:17:22,678 train 050 1.965054e-02 -0.636134
2019-11-05 02:17:33,363 train 100 1.972259e-02 -0.681415
2019-11-05 02:17:44,306 train 150 1.973773e-02 -0.653194
2019-11-05 02:17:55,239 train 200 1.997126e-02 -0.647321
2019-11-05 02:18:06,164 train 250 1.990770e-02 -0.671984
2019-11-05 02:18:17,093 train 300 1.995248e-02 -0.645039
2019-11-05 02:18:28,012 train 350 2.003624e-02 -0.634809
2019-11-05 02:18:38,918 train 400 2.006833e-02 -0.648027
2019-11-05 02:18:49,758 train 450 2.006627e-02 -0.636953
2019-11-05 02:19:00,624 train 500 2.009671e-02 -0.654078
2019-11-05 02:19:11,533 train 550 2.014711e-02 -0.640688
2019-11-05 02:19:22,400 train 600 2.017302e-02 -0.617383
2019-11-05 02:19:33,277 train 650 2.016170e-02 -0.616404
2019-11-05 02:19:44,157 train 700 2.012936e-02 -0.621595
2019-11-05 02:19:55,008 train 750 2.011979e-02 -0.637295
2019-11-05 02:20:05,906 train 800 2.012300e-02 -0.635728
2019-11-05 02:20:16,816 train 850 2.011225e-02 -0.630264
2019-11-05 02:20:20,112 training loss; R2: 2.011958e-02 -0.636861
2019-11-05 02:20:20,692 valid 000 1.711104e-02 -2.906821
2019-11-05 02:20:31,388 valid 050 1.652175e-02 -0.835901
2019-11-05 02:20:41,023 validation loss; R2: 1.625689e-02 -0.875328
2019-11-05 02:20:41,087 epoch 88 lr 2.000000e-04
2019-11-05 02:20:41,801 train 000 2.037356e-02 -0.156462
2019-11-05 02:20:52,477 train 050 1.989784e-02 -1.344459
2019-11-05 02:21:03,188 train 100 2.011221e-02 -0.917621
2019-11-05 02:21:14,130 train 150 2.003155e-02 -0.741123
2019-11-05 02:21:24,971 train 200 2.007715e-02 -1.025675
2019-11-05 02:21:35,698 train 250 1.999376e-02 -0.961554
2019-11-05 02:21:46,583 train 300 2.002362e-02 -0.921504
2019-11-05 02:21:57,289 train 350 1.995910e-02 -0.862777
2019-11-05 02:22:07,995 train 400 1.997847e-02 -0.840103
2019-11-05 02:22:18,792 train 450 1.995517e-02 -0.842492
2019-11-05 02:22:29,515 train 500 1.997697e-02 -0.819043
2019-11-05 02:22:40,326 train 550 1.993897e-02 -0.791872
2019-11-05 02:22:51,034 train 600 1.993678e-02 -0.761540
2019-11-05 02:23:01,764 train 650 1.996536e-02 -0.745852
2019-11-05 02:23:12,557 train 700 1.994663e-02 -0.742912
2019-11-05 02:23:23,360 train 750 1.996270e-02 -0.740569
2019-11-05 02:23:34,173 train 800 1.995784e-02 -0.725322
2019-11-05 02:23:44,944 train 850 1.998585e-02 -0.717418
2019-11-05 02:23:48,099 training loss; R2: 2.000552e-02 -0.734279
2019-11-05 02:23:48,732 valid 000 1.766169e-02 -5.388634
2019-11-05 02:23:59,298 valid 050 1.633435e-02 -0.490668
2019-11-05 02:24:08,918 validation loss; R2: 1.626345e-02 -0.729220
2019-11-05 02:24:08,986 epoch 89 lr 2.000000e-04
2019-11-05 02:24:09,723 train 000 2.126414e-02 -0.063323
2019-11-05 02:24:20,320 train 050 2.049663e-02 -0.612094
2019-11-05 02:24:31,068 train 100 2.022788e-02 -0.579815
2019-11-05 02:24:41,845 train 150 2.010913e-02 -0.614201
2019-11-05 02:24:52,629 train 200 1.998723e-02 -0.612652
2019-11-05 02:25:03,402 train 250 1.995627e-02 -0.622566
2019-11-05 02:25:14,213 train 300 1.988436e-02 -0.700267
2019-11-05 02:25:24,965 train 350 1.990910e-02 -0.660611
2019-11-05 02:25:35,757 train 400 1.991605e-02 -0.661737
2019-11-05 02:25:46,606 train 450 1.997495e-02 -0.666780
2019-11-05 02:25:57,516 train 500 1.999903e-02 -0.666670
2019-11-05 02:26:08,368 train 550 2.004771e-02 -0.667578
2019-11-05 02:26:19,179 train 600 2.005997e-02 -0.651699
2019-11-05 02:26:30,005 train 650 2.003540e-02 -0.664630
2019-11-05 02:26:40,813 train 700 2.003926e-02 -0.660714
2019-11-05 02:26:51,616 train 750 2.004520e-02 -0.648251
2019-11-05 02:27:02,403 train 800 2.005308e-02 -0.639699
2019-11-05 02:27:13,196 train 850 2.004568e-02 -0.643705
2019-11-05 02:27:16,356 training loss; R2: 2.004476e-02 -0.643481
2019-11-05 02:27:16,996 valid 000 1.635304e-02 -0.010594
2019-11-05 02:27:27,612 valid 050 1.529400e-02 -0.611569
2019-11-05 02:27:37,249 validation loss; R2: 1.504775e-02 -0.792795
2019-11-05 02:27:37,324 epoch 90 lr 2.000000e-04
2019-11-05 02:27:38,056 train 000 2.261275e-02 -0.457472
2019-11-05 02:27:48,780 train 050 2.082579e-02 -0.520841
2019-11-05 02:27:59,502 train 100 2.034913e-02 -0.587992
2019-11-05 02:28:10,393 train 150 2.012220e-02 -0.641841
2019-11-05 02:28:21,213 train 200 2.012091e-02 -0.623458
2019-11-05 02:28:32,028 train 250 2.004153e-02 -0.602843
2019-11-05 02:28:42,983 train 300 2.006902e-02 -0.606570
2019-11-05 02:28:53,889 train 350 2.002506e-02 -0.620621
2019-11-05 02:29:04,761 train 400 1.999905e-02 -0.619292
2019-11-05 02:29:15,573 train 450 1.997920e-02 -0.597200
2019-11-05 02:29:26,453 train 500 1.996732e-02 -0.585940
2019-11-05 02:29:37,289 train 550 1.993963e-02 -0.570833
2019-11-05 02:29:48,121 train 600 1.991810e-02 -0.567923
2019-11-05 02:29:58,972 train 650 1.992066e-02 -0.592149
2019-11-05 02:30:09,793 train 700 1.990545e-02 -0.591933
2019-11-05 02:30:20,658 train 750 1.990633e-02 -0.614725
2019-11-05 02:30:31,550 train 800 1.991857e-02 -0.613105
2019-11-05 02:30:42,409 train 850 1.993639e-02 -0.713666
2019-11-05 02:30:45,671 training loss; R2: 1.996329e-02 -0.715359
2019-11-05 02:30:46,279 valid 000 1.919643e-02 -0.492287
2019-11-05 02:30:56,952 valid 050 2.170189e-02 -0.456639
2019-11-05 02:31:06,378 validation loss; R2: 2.181637e-02 -0.397811
2019-11-05 02:31:06,446 epoch 91 lr 2.000000e-04
2019-11-05 02:31:07,160 train 000 1.962507e-02 -0.292032
2019-11-05 02:31:17,781 train 050 1.979462e-02 -0.495651
2019-11-05 02:31:28,388 train 100 1.983571e-02 -0.501388
2019-11-05 02:31:39,043 train 150 1.983735e-02 -0.611400
2019-11-05 02:31:49,724 train 200 1.989793e-02 -0.564062
2019-11-05 02:32:00,446 train 250 1.987040e-02 -0.583928
2019-11-05 02:32:11,190 train 300 1.985127e-02 -0.602341
2019-11-05 02:32:21,875 train 350 1.978707e-02 -0.627111
2019-11-05 02:32:32,598 train 400 1.979342e-02 -0.608896
2019-11-05 02:32:43,332 train 450 1.978303e-02 -0.721585
2019-11-05 02:32:53,986 train 500 1.982983e-02 -0.701773
2019-11-05 02:33:04,660 train 550 1.981789e-02 -0.678861
2019-11-05 02:33:15,385 train 600 1.996099e-02 -0.660372
2019-11-05 02:33:26,104 train 650 1.995854e-02 -0.638880
2019-11-05 02:33:36,819 train 700 2.000082e-02 -0.641835
2019-11-05 02:33:47,606 train 750 1.998899e-02 -0.686212
2019-11-05 02:33:58,312 train 800 1.996863e-02 -0.669746
2019-11-05 02:34:08,964 train 850 1.999412e-02 -0.678447
2019-11-05 02:34:12,109 training loss; R2: 1.999642e-02 -0.696248
2019-11-05 02:34:12,726 valid 000 1.523853e-02 0.039282
2019-11-05 02:34:23,291 valid 050 1.697172e-02 -0.749399
2019-11-05 02:34:32,615 validation loss; R2: 1.710283e-02 -0.619179
2019-11-05 02:34:32,696 epoch 92 lr 2.000000e-04
2019-11-05 02:34:33,414 train 000 1.979700e-02 0.047846
2019-11-05 02:34:44,007 train 050 2.018274e-02 -0.624552
2019-11-05 02:34:54,680 train 100 2.017821e-02 -0.822236
2019-11-05 02:35:05,506 train 150 2.014756e-02 -0.771633
2019-11-05 02:35:16,373 train 200 2.012172e-02 -0.751275
2019-11-05 02:35:27,386 train 250 2.014802e-02 -0.691602
2019-11-05 02:35:38,510 train 300 2.003458e-02 -0.675423
2019-11-05 02:35:49,474 train 350 2.002836e-02 -0.679903
2019-11-05 02:36:00,559 train 400 2.001745e-02 -0.655276
2019-11-05 02:36:11,325 train 450 1.997304e-02 -0.658132
2019-11-05 02:36:22,405 train 500 1.993586e-02 -0.652030
2019-11-05 02:36:33,349 train 550 1.991653e-02 -0.643054
2019-11-05 02:36:44,405 train 600 1.993066e-02 -0.643093
2019-11-05 02:36:55,234 train 650 1.989219e-02 -0.655735
2019-11-05 02:37:05,984 train 700 1.988357e-02 -0.658273
2019-11-05 02:37:16,749 train 750 1.989437e-02 -0.648585
2019-11-05 02:37:27,558 train 800 1.988224e-02 -0.639242
2019-11-05 02:37:38,395 train 850 1.987202e-02 -0.645585
2019-11-05 02:37:41,605 training loss; R2: 1.986243e-02 -0.645268
2019-11-05 02:37:42,228 valid 000 1.748589e-02 0.050372
2019-11-05 02:37:52,823 valid 050 2.022967e-02 -0.818349
2019-11-05 02:38:02,464 validation loss; R2: 2.024036e-02 -0.969937
2019-11-05 02:38:02,541 epoch 93 lr 2.000000e-04
2019-11-05 02:38:03,264 train 000 2.035955e-02 -0.916795
2019-11-05 02:38:13,905 train 050 2.010829e-02 -0.610665
2019-11-05 02:38:24,716 train 100 1.994041e-02 -0.644260
2019-11-05 02:38:35,497 train 150 1.998720e-02 -0.710276
2019-11-05 02:38:46,349 train 200 1.979093e-02 -0.677181
2019-11-05 02:38:57,206 train 250 1.992591e-02 -0.670066
2019-11-05 02:39:07,946 train 300 1.992747e-02 -0.643145
2019-11-05 02:39:18,697 train 350 2.000916e-02 -0.628958
2019-11-05 02:39:29,410 train 400 1.998250e-02 -0.663715
2019-11-05 02:39:40,178 train 450 2.000490e-02 -0.632362
2019-11-05 02:39:50,920 train 500 2.000072e-02 -0.621536
2019-11-05 02:40:01,626 train 550 1.996027e-02 -0.602545
2019-11-05 02:40:12,388 train 600 1.991814e-02 -0.591354
2019-11-05 02:40:23,191 train 650 1.988764e-02 -0.634699
2019-11-05 02:40:33,987 train 700 1.989084e-02 -0.630002
2019-11-05 02:40:44,806 train 750 1.996572e-02 -0.630674
2019-11-05 02:40:55,616 train 800 2.006060e-02 -0.619174
2019-11-05 02:41:06,441 train 850 2.010583e-02 -0.616732
2019-11-05 02:41:09,697 training loss; R2: 2.009628e-02 -0.622292
2019-11-05 02:41:10,319 valid 000 1.382613e-02 -1.568649
2019-11-05 02:41:21,302 valid 050 1.498899e-02 -0.743061
2019-11-05 02:41:30,880 validation loss; R2: 1.535190e-02 -0.908232
2019-11-05 02:41:30,948 epoch 94 lr 2.000000e-04
2019-11-05 02:41:31,705 train 000 2.188352e-02 -0.612390
2019-11-05 02:41:42,335 train 050 1.979887e-02 -0.593819
2019-11-05 02:41:53,095 train 100 2.000750e-02 -0.522874
2019-11-05 02:42:04,030 train 150 1.993494e-02 -0.534811
2019-11-05 02:42:14,932 train 200 2.002938e-02 -0.559521
2019-11-05 02:42:25,794 train 250 2.006026e-02 -0.555988
2019-11-05 02:42:36,613 train 300 2.008218e-02 -0.536011
2019-11-05 02:42:47,370 train 350 2.001040e-02 -0.553769
2019-11-05 02:42:58,174 train 400 2.002226e-02 -0.578546
2019-11-05 02:43:08,984 train 450 1.998166e-02 -0.551788
2019-11-05 02:43:19,864 train 500 1.996871e-02 -0.564909
2019-11-05 02:43:30,700 train 550 1.999665e-02 -0.582828
2019-11-05 02:43:41,593 train 600 1.996753e-02 -0.571400
2019-11-05 02:43:52,482 train 650 1.996301e-02 -0.571419
2019-11-05 02:44:03,330 train 700 1.995185e-02 -0.570358
2019-11-05 02:44:14,220 train 750 1.994141e-02 -0.566507
2019-11-05 02:44:25,064 train 800 1.991307e-02 -0.573365
2019-11-05 02:44:35,988 train 850 1.990149e-02 -0.587870
2019-11-05 02:44:39,188 training loss; R2: 1.989932e-02 -0.588958
2019-11-05 02:44:39,747 valid 000 1.505486e-02 -1.289750
2019-11-05 02:44:50,467 valid 050 1.593377e-02 -13.829082
2019-11-05 02:44:59,702 validation loss; R2: 1.562374e-02 -7.710087
2019-11-05 02:44:59,771 epoch 95 lr 2.000000e-04
2019-11-05 02:45:00,464 train 000 1.826106e-02 -0.102789
2019-11-05 02:45:11,047 train 050 1.970928e-02 -0.841886
2019-11-05 02:45:21,681 train 100 1.985402e-02 -0.608907
2019-11-05 02:45:32,497 train 150 1.982438e-02 -0.623501
2019-11-05 02:45:43,199 train 200 1.983607e-02 -0.783272
2019-11-05 02:45:53,977 train 250 1.995966e-02 -0.756002
2019-11-05 02:46:04,812 train 300 1.995176e-02 -0.744025
2019-11-05 02:46:15,566 train 350 1.999063e-02 -0.732611
2019-11-05 02:46:26,300 train 400 1.994723e-02 -0.733122
2019-11-05 02:46:36,989 train 450 1.989416e-02 -0.706780
2019-11-05 02:46:47,675 train 500 1.986951e-02 -0.701261
2019-11-05 02:46:58,437 train 550 1.994286e-02 -0.690589
2019-11-05 02:47:09,178 train 600 1.993372e-02 -0.673065
2019-11-05 02:47:19,941 train 650 1.991333e-02 -0.658981
2019-11-05 02:47:30,679 train 700 1.995509e-02 -0.648418
2019-11-05 02:47:41,396 train 750 1.999664e-02 -0.642129
2019-11-05 02:47:52,181 train 800 1.999559e-02 -0.634118
2019-11-05 02:48:02,904 train 850 1.997181e-02 -0.626167
2019-11-05 02:48:06,062 training loss; R2: 1.998341e-02 -0.623246
2019-11-05 02:48:06,683 valid 000 1.454688e-02 -0.160634
2019-11-05 02:48:17,149 valid 050 1.624291e-02 -0.502143
2019-11-05 02:48:26,350 validation loss; R2: 1.643374e-02 -0.533080
2019-11-05 02:48:26,418 epoch 96 lr 2.000000e-04
2019-11-05 02:48:27,096 train 000 1.856117e-02 -0.113517
2019-11-05 02:48:37,759 train 050 1.992142e-02 -0.640470
2019-11-05 02:48:48,659 train 100 1.983692e-02 -0.601877
2019-11-05 02:48:59,614 train 150 2.000254e-02 -0.640252
2019-11-05 02:49:10,541 train 200 2.002723e-02 -0.641664
2019-11-05 02:49:21,400 train 250 2.001260e-02 -0.625410
2019-11-05 02:49:32,387 train 300 1.998492e-02 -0.722325
2019-11-05 02:49:43,266 train 350 1.993026e-02 -0.705300
2019-11-05 02:49:54,138 train 400 1.989245e-02 -0.692353
2019-11-05 02:50:05,029 train 450 1.989809e-02 -0.676746
2019-11-05 02:50:15,942 train 500 1.993810e-02 -0.662595
2019-11-05 02:50:26,825 train 550 1.990619e-02 -0.652932
2019-11-05 02:50:37,716 train 600 1.988964e-02 -0.657176
2019-11-05 02:50:48,531 train 650 1.991417e-02 -0.644073
2019-11-05 02:50:59,352 train 700 1.989654e-02 -0.627903
2019-11-05 02:51:10,178 train 750 1.988633e-02 -0.619194
2019-11-05 02:51:21,105 train 800 1.988112e-02 -0.641890
2019-11-05 02:51:31,939 train 850 1.986183e-02 -0.650104
2019-11-05 02:51:35,114 training loss; R2: 1.985532e-02 -0.648923
2019-11-05 02:51:35,688 valid 000 1.497386e-02 -0.906132
2019-11-05 02:51:46,435 valid 050 1.547893e-02 -0.800264
2019-11-05 02:51:55,659 validation loss; R2: 1.533281e-02 -0.918645
2019-11-05 02:51:55,728 epoch 97 lr 2.000000e-04
2019-11-05 02:51:56,413 train 000 1.971895e-02 -0.860949
2019-11-05 02:52:06,981 train 050 1.949264e-02 -0.828633
2019-11-05 02:52:17,553 train 100 1.992913e-02 -0.761193
2019-11-05 02:52:28,159 train 150 1.981007e-02 -0.688607
2019-11-05 02:52:38,686 train 200 1.972954e-02 -0.691547
2019-11-05 02:52:49,433 train 250 1.975185e-02 -0.671826
2019-11-05 02:53:00,150 train 300 1.983905e-02 -0.690171
2019-11-05 02:53:10,850 train 350 1.987008e-02 -0.679850
2019-11-05 02:53:21,546 train 400 1.989736e-02 -0.696356
2019-11-05 02:53:32,351 train 450 1.994219e-02 -0.676168
2019-11-05 02:53:43,135 train 500 1.994845e-02 -0.668020
2019-11-05 02:53:53,928 train 550 1.992314e-02 -0.690647
2019-11-05 02:54:04,708 train 600 1.987734e-02 -0.717527
2019-11-05 02:54:15,472 train 650 1.987111e-02 -0.701553
2019-11-05 02:54:26,222 train 700 1.986764e-02 -0.684551
2019-11-05 02:54:36,979 train 750 1.985727e-02 -0.680919
2019-11-05 02:54:47,742 train 800 1.982559e-02 -0.686547
2019-11-05 02:54:58,453 train 850 1.983264e-02 -0.675342
2019-11-05 02:55:01,674 training loss; R2: 1.981897e-02 -0.667729
2019-11-05 02:55:02,279 valid 000 1.585190e-02 0.159154
2019-11-05 02:55:12,822 valid 050 1.552975e-02 -0.572577
2019-11-05 02:55:22,274 validation loss; R2: 1.544833e-02 -0.621813
2019-11-05 02:55:22,343 epoch 98 lr 2.000000e-04
2019-11-05 02:55:23,082 train 000 2.010074e-02 -0.767940
2019-11-05 02:55:33,928 train 050 1.988345e-02 -0.593237
2019-11-05 02:55:44,766 train 100 1.979902e-02 -0.470715
2019-11-05 02:55:55,491 train 150 1.983704e-02 -0.546143
2019-11-05 02:56:06,193 train 200 1.983432e-02 -0.563788
2019-11-05 02:56:17,028 train 250 1.978059e-02 -0.579795
2019-11-05 02:56:27,767 train 300 1.987129e-02 -0.603220
2019-11-05 02:56:38,551 train 350 1.988613e-02 -0.596131
2019-11-05 02:56:49,272 train 400 1.993230e-02 -0.605445
2019-11-05 02:57:00,041 train 450 1.993702e-02 -0.592383
2019-11-05 02:57:10,791 train 500 1.995610e-02 -0.581079
2019-11-05 02:57:21,479 train 550 1.996193e-02 -0.561135
2019-11-05 02:57:32,219 train 600 1.996388e-02 -0.558153
2019-11-05 02:57:43,084 train 650 1.994190e-02 -0.572572
2019-11-05 02:57:53,848 train 700 1.998144e-02 -0.598935
2019-11-05 02:58:04,765 train 750 1.998890e-02 -0.598552
2019-11-05 02:58:15,531 train 800 2.001081e-02 -7.021843
2019-11-05 02:58:26,241 train 850 2.000880e-02 -6.646838
2019-11-05 02:58:29,476 training loss; R2: 2.000353e-02 -6.541354
2019-11-05 02:58:30,121 valid 000 1.817681e-02 -0.511640
2019-11-05 02:58:40,844 valid 050 1.534587e-02 -0.892389
2019-11-05 02:58:50,196 validation loss; R2: 1.516819e-02 -0.863559
2019-11-05 02:58:50,278 epoch 99 lr 2.000000e-04
2019-11-05 02:58:51,023 train 000 2.136359e-02 -0.955101
2019-11-05 02:59:01,596 train 050 2.002606e-02 -0.620017
2019-11-05 02:59:12,328 train 100 2.011418e-02 -0.531156
2019-11-05 02:59:23,074 train 150 2.002962e-02 -0.494883
2019-11-05 02:59:33,833 train 200 2.003533e-02 -0.528848
2019-11-05 02:59:44,591 train 250 1.994674e-02 -0.542505
2019-11-05 02:59:55,341 train 300 1.990048e-02 -0.540992
2019-11-05 03:00:06,050 train 350 1.985665e-02 -0.560842
2019-11-05 03:00:16,838 train 400 1.983145e-02 -0.548726
2019-11-05 03:00:27,522 train 450 1.984795e-02 -0.553430
2019-11-05 03:00:38,236 train 500 1.989343e-02 -0.570176
2019-11-05 03:00:48,967 train 550 1.986828e-02 -0.570572
2019-11-05 03:00:59,694 train 600 1.986922e-02 -0.600289
2019-11-05 03:01:10,387 train 650 1.984647e-02 -0.603887
2019-11-05 03:01:21,118 train 700 1.983143e-02 -0.665092
2019-11-05 03:01:31,854 train 750 1.979176e-02 -0.664879
2019-11-05 03:01:42,581 train 800 1.977645e-02 -0.667322
2019-11-05 03:01:53,312 train 850 1.975825e-02 -0.667149
2019-11-05 03:01:56,484 training loss; R2: 1.976268e-02 -0.662435
2019-11-05 03:01:57,084 valid 000 1.289311e-02 0.111361
2019-11-05 03:02:07,552 valid 050 1.536008e-02 -0.469164
2019-11-05 03:02:17,039 validation loss; R2: 1.544704e-02 -0.575387
2019-11-05 03:02:17,107 epoch 100 lr 2.000000e-04
2019-11-05 03:02:17,807 train 000 2.384776e-02 -0.421512
2019-11-05 03:02:28,686 train 050 2.087608e-02 -0.541001
2019-11-05 03:02:39,330 train 100 2.059661e-02 -0.679840
2019-11-05 03:02:50,002 train 150 2.021546e-02 -0.725177
2019-11-05 03:03:00,641 train 200 2.015728e-02 -0.680344
2019-11-05 03:03:11,338 train 250 2.002147e-02 -0.676101
2019-11-05 03:03:22,127 train 300 1.996485e-02 -0.651258
2019-11-05 03:03:32,889 train 350 1.998308e-02 -0.644552
2019-11-05 03:03:43,645 train 400 1.999760e-02 -0.637916
2019-11-05 03:03:54,406 train 450 2.004231e-02 -0.619784
2019-11-05 03:04:05,117 train 500 1.996505e-02 -0.622196
2019-11-05 03:04:15,806 train 550 1.995219e-02 -0.613486
2019-11-05 03:04:26,519 train 600 1.995953e-02 -0.622854
2019-11-05 03:04:37,277 train 650 1.995094e-02 -0.623756
2019-11-05 03:04:47,991 train 700 1.994528e-02 -0.610594
2019-11-05 03:04:58,687 train 750 1.995925e-02 -0.601980
2019-11-05 03:05:09,421 train 800 1.994437e-02 -0.593477
2019-11-05 03:05:20,103 train 850 1.989957e-02 -0.600582
2019-11-05 03:05:23,258 training loss; R2: 1.990402e-02 -0.600276
2019-11-05 03:05:23,829 valid 000 1.718313e-02 -0.729281
2019-11-05 03:05:34,462 valid 050 1.647184e-02 -1.251896
2019-11-05 03:05:43,893 validation loss; R2: 1.638742e-02 -1.002811
2019-11-05 03:05:43,962 epoch 101 lr 2.000000e-04
2019-11-05 03:05:44,658 train 000 2.442511e-02 -0.053487
2019-11-05 03:05:55,431 train 050 1.992112e-02 -0.811084
2019-11-05 03:06:06,278 train 100 1.978477e-02 -0.668694
2019-11-05 03:06:17,201 train 150 1.979462e-02 -0.664237
2019-11-05 03:06:28,131 train 200 1.989604e-02 -0.647058
2019-11-05 03:06:39,047 train 250 1.977888e-02 -0.716187
2019-11-05 03:06:49,958 train 300 1.969338e-02 -0.693742
2019-11-05 03:07:00,816 train 350 1.974153e-02 -0.690186
2019-11-05 03:07:11,679 train 400 1.968399e-02 -0.723744
2019-11-05 03:07:22,425 train 450 1.971196e-02 -0.707293
2019-11-05 03:07:33,193 train 500 1.972814e-02 -0.690384
2019-11-05 03:07:43,959 train 550 1.976450e-02 -0.677843
2019-11-05 03:07:54,738 train 600 1.978368e-02 -0.767285
2019-11-05 03:08:05,550 train 650 1.979006e-02 -0.742988
2019-11-05 03:08:16,323 train 700 1.981743e-02 -0.732169
2019-11-05 03:08:27,155 train 750 1.977101e-02 -0.721266
2019-11-05 03:08:37,974 train 800 1.976658e-02 -0.707326
2019-11-05 03:08:48,900 train 850 1.976384e-02 -0.705866
2019-11-05 03:08:52,113 training loss; R2: 1.975124e-02 -0.722595
2019-11-05 03:08:52,727 valid 000 1.609311e-02 -0.763865
2019-11-05 03:09:03,425 valid 050 1.517345e-02 -0.661273
2019-11-05 03:09:13,113 validation loss; R2: 1.536578e-02 -0.802397
2019-11-05 03:09:13,172 epoch 102 lr 2.000000e-04
2019-11-05 03:09:13,936 train 000 1.975748e-02 -0.386207
2019-11-05 03:09:24,647 train 050 1.975561e-02 -0.480344
2019-11-05 03:09:35,496 train 100 1.990697e-02 -0.526416
2019-11-05 03:09:46,396 train 150 1.994990e-02 -0.581348
2019-11-05 03:09:57,248 train 200 1.995011e-02 -0.659546
2019-11-05 03:10:08,143 train 250 1.989467e-02 -0.648854
2019-11-05 03:10:19,023 train 300 1.987897e-02 -0.651521
2019-11-05 03:10:29,785 train 350 1.993072e-02 -0.653007
2019-11-05 03:10:40,572 train 400 2.000437e-02 -0.650850
2019-11-05 03:10:51,340 train 450 1.997536e-02 -0.645808
2019-11-05 03:11:02,109 train 500 1.995563e-02 -0.627508
2019-11-05 03:11:12,940 train 550 1.997432e-02 -0.773835
2019-11-05 03:11:23,787 train 600 2.000928e-02 -0.752903
2019-11-05 03:11:34,633 train 650 1.998930e-02 -0.734877
2019-11-05 03:11:45,476 train 700 1.998415e-02 -0.746371
2019-11-05 03:11:56,216 train 750 1.993966e-02 -0.755466
2019-11-05 03:12:06,868 train 800 1.993950e-02 -0.741240
2019-11-05 03:12:17,747 train 850 1.992799e-02 -0.742683
2019-11-05 03:12:20,945 training loss; R2: 1.991919e-02 -0.741774
2019-11-05 03:12:21,550 valid 000 1.462567e-02 -1.603658
2019-11-05 03:12:32,443 valid 050 1.517677e-02 -0.441818
2019-11-05 03:12:42,013 validation loss; R2: 1.504074e-02 -0.447903
2019-11-05 03:12:42,096 epoch 103 lr 2.000000e-04
2019-11-05 03:12:42,784 train 000 2.126117e-02 -0.808370
2019-11-05 03:12:53,641 train 050 1.968808e-02 -0.567869
2019-11-05 03:13:04,381 train 100 1.995198e-02 -0.630802
2019-11-05 03:13:15,211 train 150 1.999283e-02 -0.629815
2019-11-05 03:13:26,021 train 200 1.991312e-02 -0.623172
2019-11-05 03:13:36,899 train 250 1.984708e-02 -0.681737
2019-11-05 03:13:47,850 train 300 1.975826e-02 -0.829958
2019-11-05 03:13:58,718 train 350 1.980245e-02 -0.776793
2019-11-05 03:14:09,607 train 400 1.982771e-02 -0.768206
2019-11-05 03:14:20,262 train 450 1.979801e-02 -0.793446
2019-11-05 03:14:31,179 train 500 1.979221e-02 -0.796774
2019-11-05 03:14:42,110 train 550 1.984840e-02 -0.794443
2019-11-05 03:14:53,038 train 600 1.987981e-02 -0.769881
2019-11-05 03:15:03,943 train 650 1.988681e-02 -0.764432
2019-11-05 03:15:14,839 train 700 1.986990e-02 -0.744389
2019-11-05 03:15:25,782 train 750 1.990218e-02 -0.736455
2019-11-05 03:15:36,708 train 800 1.987706e-02 -0.728915
2019-11-05 03:15:47,662 train 850 1.987836e-02 -0.713485
2019-11-05 03:15:50,968 training loss; R2: 1.986595e-02 -0.728348
2019-11-05 03:15:51,533 valid 000 1.454198e-02 -0.116623
2019-11-05 03:16:02,406 valid 050 1.458519e-02 -0.563322
2019-11-05 03:16:12,125 validation loss; R2: 1.478504e-02 -0.674546
2019-11-05 03:16:12,194 epoch 104 lr 2.000000e-04
2019-11-05 03:16:12,930 train 000 1.892915e-02 -0.649967
2019-11-05 03:16:23,733 train 050 1.948716e-02 -0.701879
2019-11-05 03:16:34,774 train 100 1.970058e-02 -0.617017
2019-11-05 03:16:45,643 train 150 1.976224e-02 -0.631343
2019-11-05 03:16:56,458 train 200 1.973351e-02 -0.620925
2019-11-05 03:17:07,296 train 250 1.980103e-02 -0.630889
2019-11-05 03:17:17,995 train 300 1.976331e-02 -0.633656
2019-11-05 03:17:28,701 train 350 1.975737e-02 -0.642403
2019-11-05 03:17:39,368 train 400 1.971697e-02 -0.639802
2019-11-05 03:17:50,110 train 450 1.970676e-02 -0.677282
2019-11-05 03:18:00,926 train 500 1.975267e-02 -0.669878
2019-11-05 03:18:11,769 train 550 1.975289e-02 -0.663211
2019-11-05 03:18:22,567 train 600 1.977232e-02 -0.648914
2019-11-05 03:18:33,419 train 650 1.979748e-02 -0.639665
2019-11-05 03:18:44,200 train 700 1.978284e-02 -0.633267
2019-11-05 03:18:54,990 train 750 1.977045e-02 -0.624994
2019-11-05 03:19:05,671 train 800 1.977315e-02 -0.633696
2019-11-05 03:19:16,464 train 850 1.976729e-02 -0.639868
2019-11-05 03:19:19,684 training loss; R2: 1.976716e-02 -0.634019
2019-11-05 03:19:20,284 valid 000 1.830516e-02 0.103775
2019-11-05 03:19:30,875 valid 050 1.570421e-02 -0.760872
2019-11-05 03:19:40,413 validation loss; R2: 1.581079e-02 -0.700062
2019-11-05 03:19:40,482 epoch 105 lr 2.000000e-04
2019-11-05 03:19:41,204 train 000 1.955579e-02 -0.979038
2019-11-05 03:19:52,111 train 050 1.986060e-02 -0.925499
2019-11-05 03:20:03,078 train 100 1.979190e-02 -0.741051
2019-11-05 03:20:13,901 train 150 1.977622e-02 -0.681888
2019-11-05 03:20:24,743 train 200 1.963614e-02 -0.768549
2019-11-05 03:20:35,571 train 250 1.974142e-02 -0.686165
2019-11-05 03:20:46,387 train 300 1.971705e-02 -0.633839
2019-11-05 03:20:57,167 train 350 1.975734e-02 -0.629125
2019-11-05 03:21:07,945 train 400 1.976003e-02 -0.620212
2019-11-05 03:21:18,710 train 450 1.976575e-02 -0.614546
2019-11-05 03:21:29,523 train 500 1.974839e-02 -0.615126
2019-11-05 03:21:40,267 train 550 1.977228e-02 -0.602279
2019-11-05 03:21:51,004 train 600 1.975786e-02 -0.587670
2019-11-05 03:22:01,743 train 650 1.980250e-02 -0.584160
2019-11-05 03:22:12,484 train 700 1.978526e-02 -0.584661
2019-11-05 03:22:23,200 train 750 1.976537e-02 -0.579020
2019-11-05 03:22:33,920 train 800 1.975750e-02 -0.579920
2019-11-05 03:22:44,673 train 850 1.973844e-02 -0.576632
2019-11-05 03:22:47,821 training loss; R2: 1.973102e-02 -0.582164
2019-11-05 03:22:48,387 valid 000 1.874987e-02 -0.164570
2019-11-05 03:22:59,072 valid 050 2.103196e-02 -0.577878
2019-11-05 03:23:08,569 validation loss; R2: 2.109770e-02 -0.566714
2019-11-05 03:23:08,649 epoch 106 lr 2.000000e-04
2019-11-05 03:23:09,392 train 000 1.779480e-02 -1.698291
2019-11-05 03:23:20,104 train 050 1.993747e-02 -0.660238
2019-11-05 03:23:31,224 train 100 1.967606e-02 -0.556104
2019-11-05 03:23:42,060 train 150 1.973229e-02 -0.593332
2019-11-05 03:23:52,820 train 200 1.979419e-02 -0.658313
2019-11-05 03:24:03,595 train 250 1.979555e-02 -0.625588
2019-11-05 03:24:14,405 train 300 1.987683e-02 -0.639996
2019-11-05 03:24:25,219 train 350 1.993004e-02 -0.655251
2019-11-05 03:24:36,014 train 400 1.985982e-02 -0.679106
2019-11-05 03:24:46,845 train 450 1.986941e-02 -0.693781
2019-11-05 03:24:57,635 train 500 1.980939e-02 -0.685236
2019-11-05 03:25:08,382 train 550 1.977816e-02 -0.703063
2019-11-05 03:25:19,174 train 600 1.981517e-02 -0.681588
2019-11-05 03:25:29,992 train 650 1.982903e-02 -0.685980
2019-11-05 03:25:40,819 train 700 1.982972e-02 -0.690576
2019-11-05 03:25:51,646 train 750 1.983503e-02 -0.677420
2019-11-05 03:26:02,453 train 800 1.982892e-02 -0.679182
2019-11-05 03:26:13,234 train 850 1.981171e-02 -0.676200
2019-11-05 03:26:16,424 training loss; R2: 1.980895e-02 -0.672006
2019-11-05 03:26:17,043 valid 000 1.807376e-02 -3.336263
2019-11-05 03:26:27,643 valid 050 1.926692e-02 -0.599675
2019-11-05 03:26:36,852 validation loss; R2: 1.925248e-02 -0.993979
2019-11-05 03:26:36,927 epoch 107 lr 2.000000e-04
2019-11-05 03:26:37,636 train 000 2.287995e-02 -0.396504
2019-11-05 03:26:48,357 train 050 1.979728e-02 -0.608376
2019-11-05 03:26:59,098 train 100 1.995217e-02 -0.600414
2019-11-05 03:27:09,854 train 150 1.996990e-02 -0.603006
2019-11-05 03:27:20,572 train 200 1.991439e-02 -0.647820
2019-11-05 03:27:31,281 train 250 1.983875e-02 -0.639776
2019-11-05 03:27:41,985 train 300 1.984027e-02 -0.618315
2019-11-05 03:27:52,741 train 350 1.973894e-02 -0.656461
2019-11-05 03:28:03,412 train 400 1.975489e-02 -0.656399
2019-11-05 03:28:14,136 train 450 1.976675e-02 -0.629282
2019-11-05 03:28:24,787 train 500 1.971103e-02 -0.639602
2019-11-05 03:28:35,529 train 550 1.971049e-02 -0.627657
2019-11-05 03:28:46,164 train 600 1.970145e-02 -0.622528
2019-11-05 03:28:56,824 train 650 1.966408e-02 -0.617733
2019-11-05 03:29:07,545 train 700 1.970354e-02 -0.620102
2019-11-05 03:29:18,251 train 750 1.975076e-02 -0.613166
2019-11-05 03:29:28,923 train 800 1.978546e-02 -0.614305
2019-11-05 03:29:39,592 train 850 1.979179e-02 -0.635459
2019-11-05 03:29:42,798 training loss; R2: 1.979761e-02 -0.634954
2019-11-05 03:29:43,431 valid 000 1.463118e-02 -0.109837
2019-11-05 03:29:54,008 valid 050 1.555799e-02 -0.560677
2019-11-05 03:30:03,446 validation loss; R2: 1.553050e-02 -1.163255
2019-11-05 03:30:03,513 epoch 108 lr 2.000000e-04
2019-11-05 03:30:04,222 train 000 2.046472e-02 -0.468702
2019-11-05 03:30:14,952 train 050 1.980718e-02 -0.530892
2019-11-05 03:30:25,613 train 100 2.002309e-02 -0.449257
2019-11-05 03:30:36,142 train 150 1.993192e-02 -0.450791
2019-11-05 03:30:46,697 train 200 1.983076e-02 -0.546013
2019-11-05 03:30:57,223 train 250 1.977629e-02 -0.531781
2019-11-05 03:31:07,787 train 300 1.976042e-02 -0.635095
2019-11-05 03:31:18,391 train 350 1.977411e-02 -0.638405
2019-11-05 03:31:28,896 train 400 1.975842e-02 -0.623924
2019-11-05 03:31:39,473 train 450 1.983059e-02 -0.685123
2019-11-05 03:31:50,290 train 500 1.983434e-02 -0.677306
2019-11-05 03:32:01,111 train 550 1.980526e-02 -0.680135
2019-11-05 03:32:11,933 train 600 1.981368e-02 -0.704889
2019-11-05 03:32:22,773 train 650 1.982068e-02 -0.693436
2019-11-05 03:32:33,586 train 700 1.983045e-02 -0.688306
2019-11-05 03:32:44,351 train 750 1.989168e-02 -0.707646
2019-11-05 03:32:55,188 train 800 1.993446e-02 -0.708144
2019-11-05 03:33:06,022 train 850 1.994491e-02 -0.738361
2019-11-05 03:33:09,200 training loss; R2: 1.992785e-02 -0.735620
2019-11-05 03:33:09,817 valid 000 1.709152e-02 -0.534125
2019-11-05 03:33:20,421 valid 050 1.557214e-02 -1.638343
2019-11-05 03:33:29,985 validation loss; R2: 1.538709e-02 -1.303707
2019-11-05 03:33:30,049 epoch 109 lr 2.000000e-04
2019-11-05 03:33:30,743 train 000 2.323223e-02 -0.375712
2019-11-05 03:33:41,687 train 050 2.026447e-02 -0.742997
2019-11-05 03:33:52,686 train 100 1.976392e-02 -0.736157
2019-11-05 03:34:03,642 train 150 1.970819e-02 -0.767012
2019-11-05 03:34:14,563 train 200 1.962752e-02 -0.812289
2019-11-05 03:34:25,415 train 250 1.966836e-02 -0.774089
2019-11-05 03:34:36,261 train 300 1.971853e-02 -0.750481
2019-11-05 03:34:47,080 train 350 1.972612e-02 -0.763734
2019-11-05 03:34:57,742 train 400 1.971903e-02 -0.729585
2019-11-05 03:35:08,323 train 450 1.969884e-02 -0.740659
2019-11-05 03:35:19,083 train 500 1.969040e-02 -0.719813
2019-11-05 03:35:29,769 train 550 1.968014e-02 -0.739594
2019-11-05 03:35:40,452 train 600 1.970901e-02 -0.718575
2019-11-05 03:35:51,117 train 650 1.966567e-02 -0.703069
2019-11-05 03:36:01,665 train 700 1.967369e-02 -0.682294
2019-11-05 03:36:12,312 train 750 1.965170e-02 -0.702985
2019-11-05 03:36:22,968 train 800 1.966484e-02 -0.703057
2019-11-05 03:36:33,591 train 850 1.967683e-02 -0.905849
2019-11-05 03:36:36,733 training loss; R2: 1.968490e-02 -0.898327
2019-11-05 03:36:37,360 valid 000 1.197762e-02 -0.595220
2019-11-05 03:36:48,170 valid 050 1.504694e-02 -0.699104
2019-11-05 03:36:57,746 validation loss; R2: 1.502641e-02 -0.575620
2019-11-05 03:36:57,814 epoch 110 lr 2.000000e-04
2019-11-05 03:36:58,535 train 000 2.186071e-02 -0.006341
2019-11-05 03:37:09,376 train 050 2.020693e-02 -0.646288
2019-11-05 03:37:20,105 train 100 1.979777e-02 -0.648719
2019-11-05 03:37:30,739 train 150 1.969757e-02 -0.654054
2019-11-05 03:37:41,399 train 200 1.965976e-02 -0.616415
2019-11-05 03:37:52,039 train 250 1.966633e-02 -0.594890
2019-11-05 03:38:02,702 train 300 1.968314e-02 -0.563572
2019-11-05 03:38:13,368 train 350 1.967082e-02 -0.582359
2019-11-05 03:38:24,285 train 400 1.962015e-02 -0.629878
2019-11-05 03:38:35,287 train 450 1.966715e-02 -0.773519
2019-11-05 03:38:46,253 train 500 1.968306e-02 -0.755692
2019-11-05 03:38:57,040 train 550 1.971520e-02 -0.742823
2019-11-05 03:39:07,809 train 600 1.971876e-02 -0.731920
2019-11-05 03:39:18,595 train 650 1.971194e-02 -0.710264
2019-11-05 03:39:29,408 train 700 1.969422e-02 -0.707952
2019-11-05 03:39:40,363 train 750 1.968485e-02 -0.697569
2019-11-05 03:39:51,508 train 800 1.969644e-02 -0.700562
2019-11-05 03:40:02,513 train 850 1.970085e-02 -0.701661
2019-11-05 03:40:05,730 training loss; R2: 1.968846e-02 -0.701298
2019-11-05 03:40:06,305 valid 000 1.762844e-02 -0.235752
2019-11-05 03:40:17,169 valid 050 1.614731e-02 -0.904799
2019-11-05 03:40:26,640 validation loss; R2: 1.584119e-02 -0.953961
2019-11-05 03:40:26,710 epoch 111 lr 2.000000e-04
2019-11-05 03:40:27,415 train 000 1.677778e-02 -1.071435
2019-11-05 03:40:38,309 train 050 1.991668e-02 -0.929125
2019-11-05 03:40:49,209 train 100 1.971938e-02 -0.745490
2019-11-05 03:41:00,175 train 150 1.972468e-02 -0.667457
2019-11-05 03:41:11,088 train 200 1.973871e-02 -0.632372
2019-11-05 03:41:22,111 train 250 1.968409e-02 -0.734862
2019-11-05 03:41:33,021 train 300 1.966365e-02 -0.727609
2019-11-05 03:41:43,795 train 350 1.968632e-02 -0.699564
2019-11-05 03:41:54,505 train 400 1.977134e-02 -0.719298
2019-11-05 03:42:05,159 train 450 1.980745e-02 -0.704431
2019-11-05 03:42:15,919 train 500 1.981240e-02 -0.704138
2019-11-05 03:42:26,598 train 550 1.979176e-02 -0.706507
2019-11-05 03:42:37,246 train 600 1.975421e-02 -0.695376
2019-11-05 03:42:47,844 train 650 1.976661e-02 -0.722257
2019-11-05 03:42:58,511 train 700 1.977558e-02 -0.710696
2019-11-05 03:43:09,194 train 750 1.975817e-02 -0.687131
2019-11-05 03:43:20,054 train 800 1.975512e-02 -0.691215
2019-11-05 03:43:30,800 train 850 1.975665e-02 -0.677906
2019-11-05 03:43:33,945 training loss; R2: 1.974691e-02 -0.685394
2019-11-05 03:43:34,513 valid 000 1.401651e-02 -0.233153
2019-11-05 03:43:45,268 valid 050 1.451969e-02 -0.792986
2019-11-05 03:43:54,589 validation loss; R2: 1.453370e-02 -0.674990
2019-11-05 03:43:54,656 epoch 112 lr 2.000000e-04
2019-11-05 03:43:55,359 train 000 1.702791e-02 -0.377682
2019-11-05 03:44:06,136 train 050 1.975871e-02 -0.446603
2019-11-05 03:44:16,862 train 100 1.953258e-02 -0.484053
2019-11-05 03:44:27,569 train 150 1.961962e-02 -0.483097
2019-11-05 03:44:38,256 train 200 1.955931e-02 -0.510198
2019-11-05 03:44:48,946 train 250 1.954929e-02 -0.511571
2019-11-05 03:44:59,615 train 300 1.956696e-02 -0.565427
2019-11-05 03:45:10,341 train 350 1.958685e-02 -0.570376
2019-11-05 03:45:21,287 train 400 1.956674e-02 -0.568234
2019-11-05 03:45:32,379 train 450 1.959518e-02 -0.575519
2019-11-05 03:45:43,459 train 500 1.959352e-02 -0.581582
2019-11-05 03:45:54,477 train 550 1.965669e-02 -0.594539
2019-11-05 03:46:05,429 train 600 1.968655e-02 -0.602058
2019-11-05 03:46:16,257 train 650 1.970009e-02 -0.600740
2019-11-05 03:46:27,074 train 700 1.970803e-02 -0.609935
2019-11-05 03:46:37,908 train 750 1.976000e-02 -0.622955
2019-11-05 03:46:48,745 train 800 1.974704e-02 -0.614025
2019-11-05 03:46:59,527 train 850 1.974352e-02 -0.621438
2019-11-05 03:47:02,737 training loss; R2: 1.974946e-02 -0.615565
2019-11-05 03:47:03,352 valid 000 1.716500e-02 -0.556243
2019-11-05 03:47:14,017 valid 050 1.517133e-02 -0.654221
2019-11-05 03:47:23,549 validation loss; R2: 1.535785e-02 -0.690315
2019-11-05 03:47:23,621 epoch 113 lr 2.000000e-04
2019-11-05 03:47:24,376 train 000 1.972406e-02 -1.515350
2019-11-05 03:47:35,017 train 050 1.933549e-02 -0.846627
2019-11-05 03:47:45,823 train 100 1.956171e-02 -0.686046
2019-11-05 03:47:56,573 train 150 1.955269e-02 -0.825998
2019-11-05 03:48:07,341 train 200 1.962763e-02 -0.760017
2019-11-05 03:48:18,210 train 250 1.972157e-02 -0.750072
2019-11-05 03:48:28,957 train 300 1.976403e-02 -0.729375
2019-11-05 03:48:39,800 train 350 1.978900e-02 -0.771100
2019-11-05 03:48:50,690 train 400 1.973409e-02 -0.743198
2019-11-05 03:49:01,476 train 450 1.973439e-02 -0.719464
2019-11-05 03:49:12,233 train 500 1.974108e-02 -0.692794
2019-11-05 03:49:23,051 train 550 1.972779e-02 -0.703537
2019-11-05 03:49:33,910 train 600 1.973715e-02 -0.700802
2019-11-05 03:49:44,566 train 650 1.976305e-02 -0.697768
2019-11-05 03:49:55,286 train 700 1.979911e-02 -0.771718
2019-11-05 03:50:06,129 train 750 1.979663e-02 -0.749831
2019-11-05 03:50:16,812 train 800 1.979429e-02 -0.731985
2019-11-05 03:50:27,602 train 850 1.979644e-02 -0.723697
2019-11-05 03:50:30,778 training loss; R2: 1.978875e-02 -0.718363
2019-11-05 03:50:31,409 valid 000 1.523342e-02 -0.534768
2019-11-05 03:50:42,022 valid 050 1.506579e-02 -0.834236
2019-11-05 03:50:51,474 validation loss; R2: 1.494717e-02 -0.863006
2019-11-05 03:50:51,538 epoch 114 lr 2.000000e-04
2019-11-05 03:50:52,285 train 000 2.105623e-02 -2.680208
2019-11-05 03:51:03,350 train 050 2.008782e-02 -0.729950
2019-11-05 03:51:14,315 train 100 2.005409e-02 -0.596466
2019-11-05 03:51:25,217 train 150 1.990899e-02 -2.557627
2019-11-05 03:51:36,069 train 200 1.980734e-02 -2.026911
2019-11-05 03:51:46,900 train 250 1.986147e-02 -2.115072
2019-11-05 03:51:57,736 train 300 1.976089e-02 -1.879540
2019-11-05 03:52:08,628 train 350 1.979743e-02 -1.695168
2019-11-05 03:52:19,427 train 400 1.975671e-02 -1.630946
2019-11-05 03:52:30,195 train 450 1.977180e-02 -1.531272
2019-11-05 03:52:41,026 train 500 1.979475e-02 -1.431451
2019-11-05 03:52:51,914 train 550 1.977426e-02 -1.356313
2019-11-05 03:53:02,777 train 600 1.976911e-02 -1.297573
2019-11-05 03:53:13,524 train 650 1.973181e-02 -1.259113
2019-11-05 03:53:24,331 train 700 1.969729e-02 -1.209941
2019-11-05 03:53:35,161 train 750 1.966222e-02 -1.196109
2019-11-05 03:53:45,922 train 800 1.967949e-02 -1.243787
2019-11-05 03:53:56,795 train 850 1.972227e-02 -1.193184
2019-11-05 03:54:00,010 training loss; R2: 1.971957e-02 -1.199000
2019-11-05 03:54:00,602 valid 000 1.415866e-02 -2.344659
2019-11-05 03:54:11,230 valid 050 1.553520e-02 -0.647720
2019-11-05 03:54:20,739 validation loss; R2: 1.538019e-02 -1.311998
2019-11-05 03:54:20,801 epoch 115 lr 2.000000e-04
2019-11-05 03:54:21,528 train 000 2.021059e-02 0.022212
2019-11-05 03:54:32,412 train 050 2.013037e-02 -0.579556
2019-11-05 03:54:43,320 train 100 1.972848e-02 -0.635973
2019-11-05 03:54:54,201 train 150 1.969800e-02 -1.811438
2019-11-05 03:55:05,055 train 200 1.969970e-02 -1.478691
2019-11-05 03:55:15,883 train 250 1.964878e-02 -1.290981
2019-11-05 03:55:26,718 train 300 1.967465e-02 -1.192131
2019-11-05 03:55:37,517 train 350 1.963691e-02 -1.129387
2019-11-05 03:55:48,282 train 400 1.963318e-02 -1.101679
2019-11-05 03:55:58,975 train 450 1.966101e-02 -1.049168
2019-11-05 03:56:09,734 train 500 1.963965e-02 -1.007272
2019-11-05 03:56:20,546 train 550 1.965233e-02 -0.963806
2019-11-05 03:56:31,299 train 600 1.965925e-02 -0.933531
2019-11-05 03:56:42,003 train 650 1.966349e-02 -0.921538
2019-11-05 03:56:52,775 train 700 1.965942e-02 -0.915613
2019-11-05 03:57:03,571 train 750 1.966714e-02 -0.891634
2019-11-05 03:57:14,376 train 800 1.971027e-02 -0.875074
2019-11-05 03:57:25,150 train 850 1.973816e-02 -0.863334
2019-11-05 03:57:28,304 training loss; R2: 1.972516e-02 -0.855155
2019-11-05 03:57:28,893 valid 000 1.792660e-02 -0.770134
2019-11-05 03:57:39,776 valid 050 1.481189e-02 -0.682422
2019-11-05 03:57:49,249 validation loss; R2: 1.481726e-02 -0.601286
2019-11-05 03:57:49,319 epoch 116 lr 2.000000e-04
2019-11-05 03:57:50,074 train 000 1.737634e-02 0.048946
2019-11-05 03:58:00,873 train 050 2.009538e-02 -0.415844
2019-11-05 03:58:11,672 train 100 1.996993e-02 -0.416636
2019-11-05 03:58:22,349 train 150 1.985546e-02 -0.428452
2019-11-05 03:58:33,162 train 200 1.983128e-02 -0.449526
2019-11-05 03:58:43,905 train 250 1.993634e-02 -0.531105
2019-11-05 03:58:54,633 train 300 1.988564e-02 -0.781939
2019-11-05 03:59:05,370 train 350 1.984463e-02 -0.732514
2019-11-05 03:59:16,066 train 400 1.986428e-02 -0.712669
2019-11-05 03:59:26,764 train 450 1.980392e-02 -0.729858
2019-11-05 03:59:37,474 train 500 1.978947e-02 -0.713541
2019-11-05 03:59:48,338 train 550 1.976602e-02 -0.731505
2019-11-05 03:59:59,095 train 600 1.974165e-02 -0.760986
2019-11-05 04:00:09,861 train 650 1.974999e-02 -0.747246
2019-11-05 04:00:20,661 train 700 1.975397e-02 -0.735486
2019-11-05 04:00:31,539 train 750 1.976697e-02 -0.711750
2019-11-05 04:00:42,341 train 800 1.977857e-02 -0.701018
2019-11-05 04:00:53,088 train 850 1.974069e-02 -0.697360
2019-11-05 04:00:56,360 training loss; R2: 1.974274e-02 -0.723885
2019-11-05 04:00:57,001 valid 000 1.433433e-02 -0.367202
2019-11-05 04:01:07,506 valid 050 1.569589e-02 -0.705792
2019-11-05 04:01:17,098 validation loss; R2: 1.588777e-02 -0.816268
2019-11-05 04:01:17,167 epoch 117 lr 2.000000e-04
2019-11-05 04:01:17,890 train 000 1.944084e-02 -0.202664
2019-11-05 04:01:28,894 train 050 1.936046e-02 -0.866367
2019-11-05 04:01:39,623 train 100 1.953229e-02 -0.780632
2019-11-05 04:01:50,294 train 150 1.963058e-02 -0.742544
2019-11-05 04:02:00,899 train 200 1.969630e-02 -0.707833
2019-11-05 04:02:11,503 train 250 1.976369e-02 -0.713120
2019-11-05 04:02:22,072 train 300 1.969807e-02 -0.784568
2019-11-05 04:02:32,923 train 350 1.970204e-02 -0.720795
2019-11-05 04:02:43,684 train 400 1.967878e-02 -0.714550
2019-11-05 04:02:54,444 train 450 1.974260e-02 -0.721639
2019-11-05 04:03:05,188 train 500 1.972389e-02 -0.699884
2019-11-05 04:03:15,961 train 550 1.968727e-02 -0.704466
2019-11-05 04:03:26,735 train 600 1.967236e-02 -2.276743
2019-11-05 04:03:37,542 train 650 1.964112e-02 -2.163564
2019-11-05 04:03:48,363 train 700 1.965616e-02 -2.072493
2019-11-05 04:03:59,158 train 750 1.966458e-02 -1.985089
2019-11-05 04:04:09,959 train 800 1.969070e-02 -1.909675
2019-11-05 04:04:20,739 train 850 1.968749e-02 -1.843446
2019-11-05 04:04:23,869 training loss; R2: 1.969440e-02 -1.820078
2019-11-05 04:04:24,491 valid 000 1.537034e-02 0.180608
2019-11-05 04:04:34,921 valid 050 1.474633e-02 -0.626671
2019-11-05 04:04:44,189 validation loss; R2: 1.471112e-02 -0.706681
2019-11-05 04:04:44,261 epoch 118 lr 2.000000e-04
2019-11-05 04:04:44,997 train 000 2.228988e-02 -0.293239
2019-11-05 04:04:55,639 train 050 2.026472e-02 -0.639451
2019-11-05 04:05:06,351 train 100 2.005341e-02 -0.623526
2019-11-05 04:05:17,078 train 150 1.976863e-02 -0.665711
2019-11-05 04:05:27,785 train 200 1.974329e-02 -0.648562
2019-11-05 04:05:38,506 train 250 1.975491e-02 -0.697677
2019-11-05 04:05:49,225 train 300 1.975725e-02 -0.672704
2019-11-05 04:05:59,953 train 350 1.973521e-02 -0.672703
2019-11-05 04:06:10,668 train 400 1.970080e-02 -0.649361
2019-11-05 04:06:21,393 train 450 1.967000e-02 -0.645074
2019-11-05 04:06:32,114 train 500 1.961885e-02 -0.647319
2019-11-05 04:06:42,807 train 550 1.958480e-02 -0.667029
2019-11-05 04:06:53,511 train 600 1.960260e-02 -0.659161
2019-11-05 04:07:04,414 train 650 1.960627e-02 -0.665442
2019-11-05 04:07:15,347 train 700 1.965239e-02 -0.738399
2019-11-05 04:07:26,064 train 750 1.965085e-02 -0.736511
2019-11-05 04:07:36,820 train 800 1.963685e-02 -0.716484
2019-11-05 04:07:47,576 train 850 1.965204e-02 -0.724849
2019-11-05 04:07:50,689 training loss; R2: 1.966419e-02 -0.720680
2019-11-05 04:07:51,312 valid 000 1.434392e-02 -0.725995
2019-11-05 04:08:01,925 valid 050 1.504917e-02 -0.563339
2019-11-05 04:08:11,316 validation loss; R2: 1.495244e-02 -0.650560
2019-11-05 04:08:11,384 epoch 119 lr 2.000000e-04
2019-11-05 04:08:12,148 train 000 2.142113e-02 -0.110535
2019-11-05 04:08:22,897 train 050 1.964361e-02 -0.501965
2019-11-05 04:08:33,702 train 100 1.948202e-02 -0.549278
2019-11-05 04:08:44,501 train 150 1.964274e-02 -0.600114
2019-11-05 04:08:55,377 train 200 1.970899e-02 -0.575647
2019-11-05 04:09:06,174 train 250 1.975881e-02 -0.601240
2019-11-05 04:09:16,898 train 300 1.972324e-02 -0.617571
2019-11-05 04:09:27,708 train 350 1.970255e-02 -0.611226
2019-11-05 04:09:38,431 train 400 1.962334e-02 -0.645382
2019-11-05 04:09:49,289 train 450 1.968481e-02 -0.702076
2019-11-05 04:09:59,938 train 500 1.981441e-02 -0.708118
2019-11-05 04:10:10,651 train 550 1.982074e-02 -0.687914
2019-11-05 04:10:21,385 train 600 1.984937e-02 -0.664039
2019-11-05 04:10:32,149 train 650 1.985300e-02 -0.669128
2019-11-05 04:10:42,764 train 700 1.982444e-02 -0.665353
2019-11-05 04:10:53,510 train 750 1.981363e-02 -0.671019
2019-11-05 04:11:04,278 train 800 1.980347e-02 -0.668781
2019-11-05 04:11:15,003 train 850 1.978101e-02 -0.671706
2019-11-05 04:11:18,309 training loss; R2: 1.978887e-02 -0.671075
2019-11-05 04:11:18,884 valid 000 1.412811e-02 -1.367069
2019-11-05 04:11:29,985 valid 050 1.467152e-02 -1.049095
2019-11-05 04:11:39,837 validation loss; R2: 1.477326e-02 -0.758466
2019-11-05 04:11:39,908 epoch 120 lr 2.000000e-04
2019-11-05 04:11:40,669 train 000 2.235945e-02 -1.577861
2019-11-05 04:11:51,681 train 050 1.914958e-02 -0.663091
2019-11-05 04:12:02,793 train 100 1.948105e-02 -0.583299
2019-11-05 04:12:13,684 train 150 1.955245e-02 -0.630621
2019-11-05 04:12:24,500 train 200 1.948426e-02 -0.585594
2019-11-05 04:12:35,264 train 250 1.953250e-02 -0.639158
2019-11-05 04:12:46,076 train 300 1.948929e-02 -0.650538
2019-11-05 04:12:56,873 train 350 1.950613e-02 -0.665044
2019-11-05 04:13:07,646 train 400 1.948938e-02 -0.655480
2019-11-05 04:13:18,482 train 450 1.943580e-02 -0.664226
2019-11-05 04:13:29,285 train 500 1.941597e-02 -0.650299
2019-11-05 04:13:40,041 train 550 1.948801e-02 -0.652134
2019-11-05 04:13:50,859 train 600 1.950689e-02 -0.672320
2019-11-05 04:14:01,661 train 650 1.952878e-02 -0.671193
2019-11-05 04:14:12,481 train 700 1.955393e-02 -0.660303
2019-11-05 04:14:23,292 train 750 1.959886e-02 -0.665447
2019-11-05 04:14:34,164 train 800 1.961750e-02 -0.662341
2019-11-05 04:14:45,020 train 850 1.961121e-02 -0.669676
2019-11-05 04:14:48,300 training loss; R2: 1.961170e-02 -0.670096
2019-11-05 04:14:48,936 valid 000 1.772513e-02 -0.719947
2019-11-05 04:14:59,864 valid 050 1.632637e-02 -1.231960
2019-11-05 04:15:09,503 validation loss; R2: 1.646169e-02 -1.230062
2019-11-05 04:15:09,573 epoch 121 lr 2.000000e-04
2019-11-05 04:15:10,305 train 000 2.009919e-02 -0.363816
2019-11-05 04:15:21,194 train 050 2.010884e-02 -0.460247
2019-11-05 04:15:32,028 train 100 2.001427e-02 -0.529116
2019-11-05 04:15:42,846 train 150 1.976341e-02 -0.585016
2019-11-05 04:15:53,607 train 200 1.974786e-02 -0.594302
2019-11-05 04:16:04,341 train 250 1.968870e-02 -0.646548
2019-11-05 04:16:15,119 train 300 1.973221e-02 -0.634231
2019-11-05 04:16:25,913 train 350 1.973885e-02 -0.631523
2019-11-05 04:16:36,692 train 400 1.972389e-02 -0.605194
2019-11-05 04:16:47,402 train 450 1.971845e-02 -0.586580
2019-11-05 04:16:58,161 train 500 1.972755e-02 -0.595043
2019-11-05 04:17:09,006 train 550 1.978400e-02 -0.595073
2019-11-05 04:17:19,872 train 600 1.977970e-02 -0.602512
2019-11-05 04:17:30,689 train 650 1.976051e-02 -0.641580
2019-11-05 04:17:41,556 train 700 1.971218e-02 -0.648624
2019-11-05 04:17:52,434 train 750 1.969575e-02 -0.659409
2019-11-05 04:18:03,302 train 800 1.968285e-02 -0.658308
2019-11-05 04:18:14,131 train 850 1.968399e-02 -0.651880
2019-11-05 04:18:17,369 training loss; R2: 1.968066e-02 -0.652603
2019-11-05 04:18:17,925 valid 000 1.217164e-02 -0.328666
2019-11-05 04:18:28,510 valid 050 1.453898e-02 -0.253179
2019-11-05 04:18:38,193 validation loss; R2: 1.471821e-02 -0.813184
2019-11-05 04:18:38,263 epoch 122 lr 2.000000e-04
2019-11-05 04:18:39,030 train 000 2.128336e-02 -0.914814
2019-11-05 04:18:50,039 train 050 1.927214e-02 -0.772757
2019-11-05 04:19:00,714 train 100 1.969859e-02 -0.603260
2019-11-05 04:19:11,416 train 150 1.965598e-02 -0.573052
2019-11-05 04:19:22,136 train 200 1.962682e-02 -0.656031
2019-11-05 04:19:32,838 train 250 1.957377e-02 -0.682293
2019-11-05 04:19:43,543 train 300 1.954989e-02 -0.662732
2019-11-05 04:19:54,221 train 350 1.954958e-02 -0.651397
2019-11-05 04:20:04,716 train 400 1.945675e-02 -0.653803
2019-11-05 04:20:15,206 train 450 1.943856e-02 -0.655591
2019-11-05 04:20:25,850 train 500 1.947611e-02 -0.671466
2019-11-05 04:20:36,582 train 550 1.946029e-02 -0.653133
2019-11-05 04:20:47,315 train 600 1.951672e-02 -0.634272
2019-11-05 04:20:58,029 train 650 1.948455e-02 -0.637843
2019-11-05 04:21:08,741 train 700 1.952689e-02 -0.622828
2019-11-05 04:21:19,458 train 750 1.953301e-02 -0.617688
2019-11-05 04:21:30,147 train 800 1.960073e-02 -0.621638
2019-11-05 04:21:40,857 train 850 1.962752e-02 -0.625025
2019-11-05 04:21:43,997 training loss; R2: 1.962713e-02 -0.632886
2019-11-05 04:21:44,617 valid 000 1.658297e-02 -0.834538
2019-11-05 04:21:55,484 valid 050 1.590275e-02 -1.178866
2019-11-05 04:22:05,036 validation loss; R2: 1.585660e-02 -1.074753
2019-11-05 04:22:05,098 epoch 123 lr 2.000000e-04
2019-11-05 04:22:05,798 train 000 2.155447e-02 -0.244276
2019-11-05 04:22:16,855 train 050 2.026233e-02 -220.123049
2019-11-05 04:22:27,875 train 100 1.980915e-02 -111.399402
2019-11-05 04:22:38,884 train 150 1.974238e-02 -74.703653
2019-11-05 04:22:49,895 train 200 1.977415e-02 -56.278576
2019-11-05 04:23:00,896 train 250 1.982988e-02 -45.184386
2019-11-05 04:23:11,846 train 300 1.985163e-02 -37.766351
2019-11-05 04:23:22,752 train 350 1.983589e-02 -32.457452
2019-11-05 04:23:33,716 train 400 1.986091e-02 -28.468333
2019-11-05 04:23:44,654 train 450 1.980890e-02 -25.400384
2019-11-05 04:23:55,745 train 500 1.977485e-02 -22.947112
2019-11-05 04:24:06,754 train 550 1.975901e-02 -20.931935
2019-11-05 04:24:17,742 train 600 1.974922e-02 -19.252981
2019-11-05 04:24:28,678 train 650 1.973853e-02 -17.825994
2019-11-05 04:24:39,669 train 700 1.968351e-02 -16.605748
2019-11-05 04:24:50,598 train 750 1.967884e-02 -15.534784
2019-11-05 04:25:01,496 train 800 1.967930e-02 -14.590600
2019-11-05 04:25:12,497 train 850 1.966102e-02 -13.776504
2019-11-05 04:25:15,691 training loss; R2: 1.965610e-02 -13.557160
2019-11-05 04:25:16,322 valid 000 2.151230e-02 -0.197429
2019-11-05 04:25:27,080 valid 050 1.623618e-02 -1.012488
2019-11-05 04:25:36,954 validation loss; R2: 1.605966e-02 -1.017696
2019-11-05 04:25:37,024 epoch 124 lr 2.000000e-04
2019-11-05 04:25:37,785 train 000 1.864432e-02 -0.744551
2019-11-05 04:25:48,829 train 050 1.978036e-02 -0.920312
2019-11-05 04:25:59,738 train 100 1.969615e-02 -0.751906
2019-11-05 04:26:10,492 train 150 1.971062e-02 -1.044969
2019-11-05 04:26:21,300 train 200 1.982636e-02 -0.913639
2019-11-05 04:26:32,036 train 250 1.989421e-02 -0.830202
2019-11-05 04:26:42,823 train 300 1.993243e-02 -0.774702
2019-11-05 04:26:53,677 train 350 1.985040e-02 -0.789025
2019-11-05 04:27:04,347 train 400 1.980671e-02 -0.759839
2019-11-05 04:27:15,220 train 450 1.986071e-02 -0.756200
2019-11-05 04:27:25,913 train 500 1.984045e-02 -0.746488
2019-11-05 04:27:36,686 train 550 1.989471e-02 -0.717095
2019-11-05 04:27:47,561 train 600 1.986399e-02 -0.703917
2019-11-05 04:27:58,304 train 650 1.982577e-02 -3.346249
2019-11-05 04:28:09,067 train 700 1.983272e-02 -3.149120
2019-11-05 04:28:19,783 train 750 1.979746e-02 -2.983218
2019-11-05 04:28:30,537 train 800 1.977946e-02 -2.835102
2019-11-05 04:28:41,335 train 850 1.978027e-02 -2.717958
2019-11-05 04:28:44,496 training loss; R2: 1.979062e-02 -2.676612
2019-11-05 04:28:45,076 valid 000 1.569999e-02 -0.216365
2019-11-05 04:28:55,798 valid 050 1.484565e-02 -0.383566
2019-11-05 04:29:05,454 validation loss; R2: 1.492660e-02 -0.413286
2019-11-05 04:29:05,528 epoch 125 lr 2.000000e-04
2019-11-05 04:29:06,300 train 000 2.034600e-02 -0.452562
2019-11-05 04:29:17,245 train 050 1.986489e-02 -0.701976
2019-11-05 04:29:28,163 train 100 1.967376e-02 -0.654480
2019-11-05 04:29:39,061 train 150 1.961869e-02 -0.644047
2019-11-05 04:29:49,964 train 200 1.954225e-02 -0.626041
2019-11-05 04:30:00,835 train 250 1.956687e-02 -3.453459
2019-11-05 04:30:11,712 train 300 1.956338e-02 -3.030039
2019-11-05 04:30:22,369 train 350 1.955666e-02 -2.700152
2019-11-05 04:30:32,912 train 400 1.955580e-02 -2.458095
2019-11-05 04:30:43,456 train 450 1.954409e-02 -2.234984
2019-11-05 04:30:54,096 train 500 1.954166e-02 -2.070303
2019-11-05 04:31:04,731 train 550 1.951927e-02 -1.941476
2019-11-05 04:31:15,338 train 600 1.954878e-02 -1.816485
2019-11-05 04:31:25,940 train 650 1.958277e-02 -1.719294
2019-11-05 04:31:36,537 train 700 1.958848e-02 -1.650628
2019-11-05 04:31:47,150 train 750 1.960923e-02 -1.574754
2019-11-05 04:31:57,757 train 800 1.959787e-02 -1.534261
2019-11-05 04:32:08,377 train 850 1.958833e-02 -1.488763
2019-11-05 04:32:11,515 training loss; R2: 1.958877e-02 -1.470461
2019-11-05 04:32:12,156 valid 000 1.337943e-02 -0.258255
2019-11-05 04:32:22,712 valid 050 1.531863e-02 -0.959427
2019-11-05 04:32:31,984 validation loss; R2: 1.536628e-02 -0.711438
2019-11-05 04:32:32,058 epoch 126 lr 2.000000e-04
2019-11-05 04:32:32,747 train 000 2.832869e-02 -3.430477
2019-11-05 04:32:43,665 train 050 1.964840e-02 -0.840829
2019-11-05 04:32:54,319 train 100 1.965735e-02 -0.698202
2019-11-05 04:33:04,952 train 150 1.957270e-02 -0.634737
2019-11-05 04:33:15,586 train 200 1.949604e-02 -0.677352
2019-11-05 04:33:26,203 train 250 1.949111e-02 -0.693011
2019-11-05 04:33:36,833 train 300 1.948646e-02 -0.664735
2019-11-05 04:33:47,450 train 350 1.946352e-02 -0.674999
2019-11-05 04:33:57,956 train 400 1.943338e-02 -0.644885
2019-11-05 04:34:08,692 train 450 1.947396e-02 -1.260377
2019-11-05 04:34:19,562 train 500 1.950537e-02 -1.214281
2019-11-05 04:34:30,353 train 550 1.951415e-02 -1.147301
2019-11-05 04:34:41,246 train 600 1.951393e-02 -1.089346
2019-11-05 04:34:52,055 train 650 1.947871e-02 -1.040599
2019-11-05 04:35:02,925 train 700 1.951657e-02 -1.023836
2019-11-05 04:35:13,678 train 750 1.952463e-02 -0.979405
2019-11-05 04:35:24,484 train 800 1.952900e-02 -0.955620
2019-11-05 04:35:35,233 train 850 1.949722e-02 -0.937124
2019-11-05 04:35:38,450 training loss; R2: 1.949313e-02 -0.929385
2019-11-05 04:35:39,076 valid 000 1.539541e-02 -0.719676
2019-11-05 04:35:49,969 valid 050 1.519323e-02 -0.606167
2019-11-05 04:35:59,499 validation loss; R2: 1.505043e-02 -0.573106
2019-11-05 04:35:59,573 epoch 127 lr 2.000000e-04
2019-11-05 04:36:00,291 train 000 1.763935e-02 -3.648393
2019-11-05 04:36:11,220 train 050 1.972685e-02 -0.738714
2019-11-05 04:36:21,985 train 100 1.948728e-02 -0.630500
2019-11-05 04:36:32,734 train 150 1.938827e-02 -0.633720
2019-11-05 04:36:43,453 train 200 1.940527e-02 -0.639925
2019-11-05 04:36:54,173 train 250 1.948579e-02 -0.685688
2019-11-05 04:37:04,868 train 300 1.948810e-02 -0.790975
2019-11-05 04:37:15,495 train 350 1.947470e-02 -0.798040
2019-11-05 04:37:26,096 train 400 1.944649e-02 -0.778802
2019-11-05 04:37:36,775 train 450 1.942635e-02 -0.776231
2019-11-05 04:37:47,589 train 500 1.943682e-02 -0.749219
2019-11-05 04:37:58,323 train 550 1.947156e-02 -0.745847
2019-11-05 04:38:09,055 train 600 1.950678e-02 -0.734130
2019-11-05 04:38:19,788 train 650 1.948285e-02 -0.717279
2019-11-05 04:38:30,531 train 700 1.946519e-02 -0.711906
2019-11-05 04:38:41,237 train 750 1.945032e-02 -0.698583
2019-11-05 04:38:51,931 train 800 1.945624e-02 -0.694533
2019-11-05 04:39:02,578 train 850 1.946655e-02 -0.685001
2019-11-05 04:39:05,716 training loss; R2: 1.947627e-02 -0.682306
2019-11-05 04:39:06,298 valid 000 1.345100e-02 -0.548040
2019-11-05 04:39:17,004 valid 050 1.434437e-02 -0.711379
2019-11-05 04:39:26,495 validation loss; R2: 1.431089e-02 -0.499520
2019-11-05 04:39:26,565 epoch 128 lr 2.000000e-04
2019-11-05 04:39:27,318 train 000 1.574853e-02 -0.279193
2019-11-05 04:39:38,267 train 050 1.958377e-02 -0.699494
2019-11-05 04:39:49,196 train 100 1.948326e-02 -0.780550
2019-11-05 04:40:00,073 train 150 1.946773e-02 -0.765797
2019-11-05 04:40:10,961 train 200 1.940300e-02 -0.715766
2019-11-05 04:40:21,713 train 250 1.958331e-02 -0.782796
2019-11-05 04:40:32,548 train 300 1.973475e-02 -0.745336
2019-11-05 04:40:43,229 train 350 1.976717e-02 -0.720453
2019-11-05 04:40:53,986 train 400 1.978443e-02 -0.697414
2019-11-05 04:41:04,719 train 450 1.972546e-02 -1.413411
2019-11-05 04:41:15,535 train 500 1.972922e-02 -1.331322
2019-11-05 04:41:26,258 train 550 1.975433e-02 -1.278216
2019-11-05 04:41:37,069 train 600 1.968474e-02 -1.211554
2019-11-05 04:41:47,788 train 650 1.968900e-02 -1.153167
2019-11-05 04:41:58,526 train 700 1.964728e-02 -1.115645
2019-11-05 04:42:09,314 train 750 1.964449e-02 -1.086433
2019-11-05 04:42:20,085 train 800 1.961395e-02 -1.054650
2019-11-05 04:42:30,918 train 850 1.962733e-02 -1.029870
2019-11-05 04:42:34,065 training loss; R2: 1.962632e-02 -1.019194
2019-11-05 04:42:34,658 valid 000 1.384674e-02 -1.825814
2019-11-05 04:42:45,178 valid 050 1.454571e-02 -0.770682
2019-11-05 04:42:54,823 validation loss; R2: 1.448784e-02 -0.821471
2019-11-05 04:42:54,884 epoch 129 lr 2.000000e-04
2019-11-05 04:42:55,604 train 000 1.998432e-02 -0.113125
2019-11-05 04:43:06,441 train 050 1.972538e-02 -0.622774
2019-11-05 04:43:17,192 train 100 1.952945e-02 -0.598642
2019-11-05 04:43:27,866 train 150 1.931651e-02 -0.573364
2019-11-05 04:43:38,534 train 200 1.941099e-02 -0.594138
2019-11-05 04:43:49,201 train 250 1.931014e-02 -0.606825
2019-11-05 04:44:00,128 train 300 1.937685e-02 -0.582168
2019-11-05 04:44:10,744 train 350 1.932320e-02 -0.596596
2019-11-05 04:44:21,352 train 400 1.934354e-02 -0.614954
2019-11-05 04:44:32,040 train 450 1.938952e-02 -0.597823
2019-11-05 04:44:42,784 train 500 1.938477e-02 -0.634701
2019-11-05 04:44:53,531 train 550 1.935496e-02 -0.640272
2019-11-05 04:45:04,295 train 600 1.936508e-02 -0.669102
2019-11-05 04:45:15,010 train 650 1.939549e-02 -0.654826
2019-11-05 04:45:25,722 train 700 1.940260e-02 -0.672718
2019-11-05 04:45:36,405 train 750 1.943659e-02 -0.662955
2019-11-05 04:45:47,147 train 800 1.946898e-02 -0.674656
2019-11-05 04:45:57,822 train 850 1.945545e-02 -0.658989
2019-11-05 04:46:01,045 training loss; R2: 1.945909e-02 -0.660638
2019-11-05 04:46:01,668 valid 000 1.206398e-02 -1.335250
2019-11-05 04:46:12,367 valid 050 1.492932e-02 -1.040579
2019-11-05 04:46:21,742 validation loss; R2: 1.490156e-02 -0.904274
2019-11-05 04:46:21,803 epoch 130 lr 2.000000e-04
2019-11-05 04:46:22,526 train 000 1.916522e-02 -1.314941
2019-11-05 04:46:33,377 train 050 1.923301e-02 -0.689482
2019-11-05 04:46:44,206 train 100 1.937631e-02 -0.715981
2019-11-05 04:46:55,011 train 150 1.955588e-02 -0.644489
2019-11-05 04:47:05,847 train 200 1.952056e-02 -0.588042
2019-11-05 04:47:16,665 train 250 1.959225e-02 -0.602867
2019-11-05 04:47:27,558 train 300 1.957386e-02 -0.629997
2019-11-05 04:47:38,419 train 350 1.974203e-02 -0.639677
2019-11-05 04:47:49,286 train 400 1.978183e-02 -0.665414
2019-11-05 04:48:00,115 train 450 1.971641e-02 -0.662524
2019-11-05 04:48:10,878 train 500 1.972989e-02 -0.664207
2019-11-05 04:48:21,678 train 550 1.971043e-02 -0.647846
2019-11-05 04:48:32,520 train 600 1.969937e-02 -0.630972
2019-11-05 04:48:43,337 train 650 1.967924e-02 -0.877321
2019-11-05 04:48:54,113 train 700 1.963633e-02 -0.869885
2019-11-05 04:49:04,919 train 750 1.963815e-02 -0.857751
2019-11-05 04:49:15,722 train 800 1.968282e-02 -0.837111
2019-11-05 04:49:26,535 train 850 1.967947e-02 -0.830547
2019-11-05 04:49:29,795 training loss; R2: 1.967454e-02 -0.825109
2019-11-05 04:49:30,352 valid 000 1.182678e-02 0.152767
2019-11-05 04:49:41,086 valid 050 1.517200e-02 -0.830936
2019-11-05 04:49:50,692 validation loss; R2: 1.554644e-02 -0.631454
2019-11-05 04:49:50,760 epoch 131 lr 2.000000e-04
2019-11-05 04:49:51,515 train 000 2.206444e-02 -0.396058
2019-11-05 04:50:02,435 train 050 1.988770e-02 -0.742122
2019-11-05 04:50:13,198 train 100 1.966447e-02 -0.571172
2019-11-05 04:50:23,943 train 150 1.970926e-02 -0.622879
2019-11-05 04:50:34,723 train 200 1.969181e-02 -0.599732
2019-11-05 04:50:45,532 train 250 1.963760e-02 -0.564437
2019-11-05 04:50:56,405 train 300 1.962871e-02 -0.576356
2019-11-05 04:51:07,147 train 350 1.959022e-02 -0.597476
2019-11-05 04:51:17,971 train 400 1.961739e-02 -0.622388
2019-11-05 04:51:28,790 train 450 1.962941e-02 -0.627523
2019-11-05 04:51:39,589 train 500 1.961047e-02 -0.626641
2019-11-05 04:51:50,367 train 550 1.962671e-02 -0.612861
2019-11-05 04:52:01,143 train 600 1.961070e-02 -0.630497
2019-11-05 04:52:11,878 train 650 1.958079e-02 -0.635291
2019-11-05 04:52:22,656 train 700 1.955186e-02 -0.633546
2019-11-05 04:52:33,421 train 750 1.950720e-02 -0.654183
2019-11-05 04:52:44,208 train 800 1.951928e-02 -0.748074
2019-11-05 04:52:54,967 train 850 1.950672e-02 -0.764951
2019-11-05 04:52:58,157 training loss; R2: 1.951033e-02 -0.758237
2019-11-05 04:52:58,728 valid 000 1.518114e-02 0.081550
2019-11-05 04:53:09,490 valid 050 1.472709e-02 -0.279362
2019-11-05 04:53:19,080 validation loss; R2: 1.464536e-02 -0.448125
2019-11-05 04:53:19,142 epoch 132 lr 2.000000e-04
2019-11-05 04:53:19,876 train 000 1.761809e-02 0.126130
2019-11-05 04:53:30,719 train 050 1.949524e-02 -0.602209
2019-11-05 04:53:41,735 train 100 1.956886e-02 -0.615851
2019-11-05 04:53:52,715 train 150 1.947772e-02 -0.672619
2019-11-05 04:54:03,584 train 200 1.948809e-02 -0.678406
2019-11-05 04:54:14,494 train 250 1.948423e-02 -0.686962
2019-11-05 04:54:25,445 train 300 1.947838e-02 -0.745093
2019-11-05 04:54:36,363 train 350 1.957040e-02 -0.829267
2019-11-05 04:54:47,336 train 400 1.962206e-02 -0.791052
2019-11-05 04:54:58,293 train 450 1.967496e-02 -0.759549
2019-11-05 04:55:09,256 train 500 1.967324e-02 -0.744865
2019-11-05 04:55:20,200 train 550 1.960937e-02 -0.730228
2019-11-05 04:55:31,136 train 600 1.960944e-02 -7.676994
2019-11-05 04:55:42,078 train 650 1.961921e-02 -7.145464
2019-11-05 04:55:53,161 train 700 1.956867e-02 -6.669938
2019-11-05 04:56:04,116 train 750 1.957054e-02 -6.258672
2019-11-05 04:56:15,076 train 800 1.960497e-02 -5.917266
2019-11-05 04:56:26,007 train 850 1.960787e-02 -5.602065
2019-11-05 04:56:29,241 training loss; R2: 1.961065e-02 -5.513384
2019-11-05 04:56:29,860 valid 000 1.610264e-02 0.069755
2019-11-05 04:56:40,357 valid 050 1.462754e-02 -0.451110
2019-11-05 04:56:50,015 validation loss; R2: 1.445915e-02 -0.403150
2019-11-05 04:56:50,085 epoch 133 lr 2.000000e-04
2019-11-05 04:56:50,855 train 000 1.930061e-02 -0.376632
2019-11-05 04:57:01,726 train 050 1.909720e-02 -245.256329
2019-11-05 04:57:12,514 train 100 1.939458e-02 -124.604248
2019-11-05 04:57:23,272 train 150 1.952396e-02 -85.308708
2019-11-05 04:57:33,988 train 200 1.957348e-02 -64.241058
2019-11-05 04:57:44,666 train 250 1.951485e-02 -51.541256
2019-11-05 04:57:55,298 train 300 1.949314e-02 -43.139170
2019-11-05 04:58:05,927 train 350 1.944832e-02 -37.075034
2019-11-05 04:58:16,567 train 400 1.948654e-02 -32.559692
2019-11-05 04:58:27,232 train 450 1.948626e-02 -29.032748
2019-11-05 04:58:37,900 train 500 1.944858e-02 -26.213805
2019-11-05 04:58:48,558 train 550 1.942409e-02 -23.881003
2019-11-05 04:58:59,261 train 600 1.950677e-02 -21.944687
2019-11-05 04:59:09,958 train 650 1.950193e-02 -20.305309
2019-11-05 04:59:20,668 train 700 1.947494e-02 -18.900371
2019-11-05 04:59:31,372 train 750 1.949066e-02 -17.678376
2019-11-05 04:59:42,076 train 800 1.946498e-02 -16.622705
2019-11-05 04:59:52,781 train 850 1.942772e-02 -15.676081
2019-11-05 04:59:55,933 training loss; R2: 1.942559e-02 -15.435098
2019-11-05 04:59:56,515 valid 000 1.391400e-02 -0.103269
2019-11-05 05:00:07,016 valid 050 1.587934e-02 -1.026746
2019-11-05 05:00:16,611 validation loss; R2: 1.587828e-02 -1.137141
2019-11-05 05:00:16,680 epoch 134 lr 2.000000e-04
2019-11-05 05:00:17,432 train 000 1.495372e-02 -0.139530
2019-11-05 05:00:28,361 train 050 1.924196e-02 -0.520575
2019-11-05 05:00:39,395 train 100 1.927964e-02 -0.544606
2019-11-05 05:00:50,125 train 150 1.912335e-02 -0.567393
2019-11-05 05:01:01,003 train 200 1.910166e-02 -0.574929
2019-11-05 05:01:11,647 train 250 1.912765e-02 -0.551687
2019-11-05 05:01:22,411 train 300 1.923904e-02 -1.026576
2019-11-05 05:01:33,177 train 350 1.926881e-02 -0.955064
2019-11-05 05:01:44,035 train 400 1.928615e-02 -0.887436
2019-11-05 05:01:54,724 train 450 1.933311e-02 -0.876921
2019-11-05 05:02:05,518 train 500 1.935200e-02 -0.848588
2019-11-05 05:02:16,346 train 550 1.928593e-02 -0.843967
2019-11-05 05:02:27,110 train 600 1.926159e-02 -0.831967
2019-11-05 05:02:37,800 train 650 1.925390e-02 -0.815594
2019-11-05 05:02:48,714 train 700 1.926310e-02 -0.815794
2019-11-05 05:02:59,435 train 750 1.926095e-02 -0.852541
2019-11-05 05:03:10,159 train 800 1.926430e-02 -0.835948
2019-11-05 05:03:20,964 train 850 1.929404e-02 -0.821919
2019-11-05 05:03:24,184 training loss; R2: 1.930060e-02 -0.825131
2019-11-05 05:03:24,775 valid 000 1.602811e-02 -0.174741
2019-11-05 05:03:35,522 valid 050 1.576463e-02 -0.698598
2019-11-05 05:03:45,027 validation loss; R2: 1.567936e-02 -0.714485
2019-11-05 05:03:45,095 epoch 135 lr 2.000000e-04
2019-11-05 05:03:45,862 train 000 1.940363e-02 -2.210177
2019-11-05 05:03:56,514 train 050 1.945096e-02 -0.738708
2019-11-05 05:04:07,108 train 100 1.928838e-02 -0.694885
2019-11-05 05:04:17,834 train 150 1.920131e-02 -0.648543
2019-11-05 05:04:28,645 train 200 1.921867e-02 -0.606256
2019-11-05 05:04:39,406 train 250 1.935796e-02 -0.642123
2019-11-05 05:04:50,232 train 300 1.932504e-02 -0.611158
2019-11-05 05:05:01,066 train 350 1.931425e-02 -0.598439
2019-11-05 05:05:11,885 train 400 1.931147e-02 -0.641360
2019-11-05 05:05:22,701 train 450 1.931604e-02 -0.648192
2019-11-05 05:05:33,537 train 500 1.936907e-02 -0.635680
2019-11-05 05:05:44,374 train 550 1.939596e-02 -0.638414
2019-11-05 05:05:55,192 train 600 1.938492e-02 -0.639104
2019-11-05 05:06:06,041 train 650 1.939283e-02 -0.653088
2019-11-05 05:06:16,872 train 700 1.940159e-02 -0.655999
2019-11-05 05:06:27,666 train 750 1.941181e-02 -0.652130
2019-11-05 05:06:38,477 train 800 1.940602e-02 -0.646873
2019-11-05 05:06:49,262 train 850 1.942181e-02 -0.637778
2019-11-05 05:06:52,446 training loss; R2: 1.943742e-02 -0.642646
2019-11-05 05:06:53,006 valid 000 1.599543e-02 -0.693894
2019-11-05 05:07:03,846 valid 050 1.607961e-02 -0.904953
2019-11-05 05:07:13,489 validation loss; R2: 1.573309e-02 -0.843991
2019-11-05 05:07:13,564 epoch 136 lr 2.000000e-04
2019-11-05 05:07:14,299 train 000 2.187982e-02 -0.192802
2019-11-05 05:07:25,259 train 050 1.993743e-02 -0.385175
2019-11-05 05:07:36,140 train 100 1.953750e-02 -0.424602
2019-11-05 05:07:46,843 train 150 1.959700e-02 -0.554619
2019-11-05 05:07:57,667 train 200 1.965772e-02 -0.535991
2019-11-05 05:08:08,520 train 250 1.958251e-02 -0.616380
2019-11-05 05:08:19,328 train 300 1.957698e-02 -0.600459
2019-11-05 05:08:30,095 train 350 1.959905e-02 -0.651314
2019-11-05 05:08:40,779 train 400 1.959485e-02 -0.650577
2019-11-05 05:08:51,496 train 450 1.954658e-02 -0.635618
2019-11-05 05:09:02,209 train 500 1.954793e-02 -0.638090
2019-11-05 05:09:12,939 train 550 1.955397e-02 -0.660962
2019-11-05 05:09:23,749 train 600 1.956889e-02 -0.665566
2019-11-05 05:09:34,506 train 650 1.954174e-02 -0.647998
2019-11-05 05:09:45,226 train 700 1.951885e-02 -0.640800
2019-11-05 05:09:55,968 train 750 1.951466e-02 -0.632418
2019-11-05 05:10:06,838 train 800 1.949586e-02 -0.635368
2019-11-05 05:10:17,624 train 850 1.948499e-02 -0.630058
2019-11-05 05:10:20,873 training loss; R2: 1.950228e-02 -0.623444
2019-11-05 05:10:21,507 valid 000 1.516426e-02 0.081384
2019-11-05 05:10:32,126 valid 050 1.511130e-02 -0.578075
2019-11-05 05:10:41,605 validation loss; R2: 1.524571e-02 -1.013688
2019-11-05 05:10:41,681 epoch 137 lr 2.000000e-04
2019-11-05 05:10:42,437 train 000 1.821846e-02 -0.013561
2019-11-05 05:10:53,184 train 050 1.966902e-02 -0.629004
2019-11-05 05:11:04,006 train 100 1.966191e-02 -0.652024
2019-11-05 05:11:14,811 train 150 1.976845e-02 -0.636426
2019-11-05 05:11:25,579 train 200 1.965532e-02 -0.633702
2019-11-05 05:11:36,277 train 250 1.956995e-02 -0.628169
2019-11-05 05:11:46,977 train 300 1.950925e-02 -0.648775
2019-11-05 05:11:57,754 train 350 1.953851e-02 -0.653352
2019-11-05 05:12:08,554 train 400 1.948485e-02 -0.661859
2019-11-05 05:12:19,282 train 450 1.954224e-02 -0.687482
2019-11-05 05:12:30,089 train 500 1.949894e-02 -0.688125
2019-11-05 05:12:40,923 train 550 1.949931e-02 -0.688516
2019-11-05 05:12:51,732 train 600 1.949699e-02 -0.672354
2019-11-05 05:13:02,496 train 650 1.947712e-02 -0.668663
2019-11-05 05:13:13,271 train 700 1.949255e-02 -0.665288
2019-11-05 05:13:24,040 train 750 1.948463e-02 -0.672919
2019-11-05 05:13:34,859 train 800 1.952742e-02 -0.688474
2019-11-05 05:13:45,606 train 850 1.951902e-02 -0.683865
2019-11-05 05:13:48,773 training loss; R2: 1.951779e-02 -0.679304
2019-11-05 05:13:49,359 valid 000 1.638814e-02 -0.232485
2019-11-05 05:13:59,844 valid 050 1.513125e-02 -0.858098
2019-11-05 05:14:09,108 validation loss; R2: 1.521174e-02 -0.905730
2019-11-05 05:14:09,177 epoch 138 lr 2.000000e-04
2019-11-05 05:14:09,894 train 000 1.879311e-02 -0.222450
2019-11-05 05:14:20,535 train 050 1.891026e-02 -2.447906
2019-11-05 05:14:31,270 train 100 1.912369e-02 -1.643468
2019-11-05 05:14:41,984 train 150 1.911555e-02 -1.271128
2019-11-05 05:14:52,708 train 200 1.924542e-02 -1.105383
2019-11-05 05:15:03,651 train 250 1.936335e-02 -0.997879
2019-11-05 05:15:14,567 train 300 1.929880e-02 -1.132374
2019-11-05 05:15:25,594 train 350 1.933070e-02 -1.079021
2019-11-05 05:15:36,594 train 400 1.940624e-02 -1.018836
2019-11-05 05:15:47,554 train 450 1.936805e-02 -0.984743
2019-11-05 05:15:58,483 train 500 1.932271e-02 -0.941575
2019-11-05 05:16:09,371 train 550 1.929750e-02 -1.054972
2019-11-05 05:16:20,271 train 600 1.929361e-02 -1.000351
2019-11-05 05:16:31,146 train 650 1.932724e-02 -0.981569
2019-11-05 05:16:42,090 train 700 1.932476e-02 -0.951802
2019-11-05 05:16:53,062 train 750 1.933405e-02 -0.939991
2019-11-05 05:17:04,029 train 800 1.935110e-02 -0.922761
2019-11-05 05:17:14,920 train 850 1.935498e-02 -0.894161
2019-11-05 05:17:18,081 training loss; R2: 1.933471e-02 -0.886949
2019-11-05 05:17:18,661 valid 000 1.552221e-02 -0.807701
2019-11-05 05:17:29,356 valid 050 1.485898e-02 -1.505482
2019-11-05 05:17:38,896 validation loss; R2: 1.510268e-02 -1.202715
2019-11-05 05:17:38,956 epoch 139 lr 2.000000e-04
2019-11-05 05:17:39,637 train 000 1.952745e-02 -0.174196
2019-11-05 05:17:50,649 train 050 1.913414e-02 -0.462963
2019-11-05 05:18:01,630 train 100 1.935949e-02 -0.601660
2019-11-05 05:18:12,566 train 150 1.944532e-02 -0.621265
2019-11-05 05:18:23,448 train 200 1.938373e-02 -0.646774
2019-11-05 05:18:34,383 train 250 1.950908e-02 -0.669179
2019-11-05 05:18:45,428 train 300 1.950754e-02 -0.679828
2019-11-05 05:18:56,174 train 350 1.952273e-02 -0.676039
2019-11-05 05:19:06,993 train 400 1.956600e-02 -0.683075
2019-11-05 05:19:17,767 train 450 1.951352e-02 -0.653886
2019-11-05 05:19:28,553 train 500 1.948273e-02 -0.655854
2019-11-05 05:19:39,352 train 550 1.946708e-02 -0.638077
2019-11-05 05:19:50,120 train 600 1.946551e-02 -0.634484
2019-11-05 05:20:00,897 train 650 1.946794e-02 -0.634806
2019-11-05 05:20:11,752 train 700 1.946933e-02 -0.649328
2019-11-05 05:20:22,466 train 750 1.950407e-02 -0.644593
2019-11-05 05:20:33,280 train 800 1.950293e-02 -0.647063
2019-11-05 05:20:44,179 train 850 1.947821e-02 -0.644474
2019-11-05 05:20:47,420 training loss; R2: 1.947426e-02 -0.646592
2019-11-05 05:20:48,037 valid 000 1.336207e-02 -3.540411
2019-11-05 05:20:58,540 valid 050 1.450871e-02 -0.507668
2019-11-05 05:21:08,341 validation loss; R2: 1.448014e-02 -0.786255
2019-11-05 05:21:08,409 epoch 140 lr 2.000000e-04
2019-11-05 05:21:09,134 train 000 1.840947e-02 -0.508500
2019-11-05 05:21:19,851 train 050 1.947965e-02 -0.694718
2019-11-05 05:21:30,610 train 100 1.944008e-02 -0.627271
2019-11-05 05:21:41,318 train 150 1.941645e-02 -0.579205
2019-11-05 05:21:52,050 train 200 1.951972e-02 -0.619723
2019-11-05 05:22:02,634 train 250 1.948670e-02 -0.695258
2019-11-05 05:22:13,394 train 300 1.941601e-02 -0.659450
2019-11-05 05:22:24,113 train 350 1.938100e-02 -0.703522
2019-11-05 05:22:34,919 train 400 1.938437e-02 -0.665057
2019-11-05 05:22:45,565 train 450 1.945397e-02 -0.660142
2019-11-05 05:22:56,242 train 500 1.944992e-02 -0.654430
2019-11-05 05:23:06,988 train 550 1.944015e-02 -0.690282
2019-11-05 05:23:17,675 train 600 1.940675e-02 -0.685446
2019-11-05 05:23:28,468 train 650 1.942572e-02 -0.684908
2019-11-05 05:23:39,238 train 700 1.942581e-02 -0.661472
2019-11-05 05:23:49,929 train 750 1.941489e-02 -0.659220
2019-11-05 05:24:00,582 train 800 1.941617e-02 -0.659358
2019-11-05 05:24:11,281 train 850 1.944095e-02 -0.686306
2019-11-05 05:24:14,467 training loss; R2: 1.947400e-02 -0.690313
2019-11-05 05:24:15,049 valid 000 1.516896e-02 -0.031483
2019-11-05 05:24:25,684 valid 050 1.534887e-02 -0.859574
2019-11-05 05:24:35,192 validation loss; R2: 1.546198e-02 -0.647438
2019-11-05 05:24:35,254 epoch 141 lr 2.000000e-04
2019-11-05 05:24:35,979 train 000 1.836032e-02 -0.594087
2019-11-05 05:24:46,875 train 050 2.008097e-02 -0.665459
2019-11-05 05:24:57,623 train 100 1.977305e-02 -0.679126
2019-11-05 05:25:08,466 train 150 1.951141e-02 -0.687560
2019-11-05 05:25:19,195 train 200 1.955301e-02 -0.691869
2019-11-05 05:25:29,940 train 250 1.958520e-02 -0.668155
2019-11-05 05:25:40,745 train 300 1.953623e-02 -0.688058
2019-11-05 05:25:51,525 train 350 1.948602e-02 -0.712708
2019-11-05 05:26:02,326 train 400 1.951736e-02 -0.701369
2019-11-05 05:26:13,138 train 450 1.953723e-02 -0.677673
2019-11-05 05:26:23,918 train 500 1.948184e-02 -0.680391
2019-11-05 05:26:34,733 train 550 1.946044e-02 -0.659900
2019-11-05 05:26:45,431 train 600 1.945775e-02 -0.667857
2019-11-05 05:26:56,240 train 650 1.943997e-02 -0.669984
2019-11-05 05:27:07,055 train 700 1.941411e-02 -0.654751
2019-11-05 05:27:17,717 train 750 1.940102e-02 -0.653259
2019-11-05 05:27:28,549 train 800 1.939260e-02 -0.646895
2019-11-05 05:27:39,245 train 850 1.939840e-02 -0.647253
2019-11-05 05:27:42,434 training loss; R2: 1.939676e-02 -0.645812
2019-11-05 05:27:43,034 valid 000 1.934615e-02 -0.191773
2019-11-05 05:27:53,879 valid 050 1.969738e-02 -0.540102
2019-11-05 05:28:03,348 validation loss; R2: 1.937730e-02 -0.421759
2019-11-05 05:28:03,427 epoch 142 lr 2.000000e-04
2019-11-05 05:28:04,144 train 000 1.828927e-02 -0.519358
2019-11-05 05:28:14,925 train 050 1.951983e-02 -0.523079
2019-11-05 05:28:25,750 train 100 1.954754e-02 -1.027989
2019-11-05 05:28:36,572 train 150 1.951486e-02 -0.893636
2019-11-05 05:28:47,438 train 200 1.951182e-02 -0.890172
2019-11-05 05:28:58,316 train 250 1.947190e-02 -0.793185
2019-11-05 05:29:09,190 train 300 1.953482e-02 -0.754471
2019-11-05 05:29:20,138 train 350 1.949180e-02 -0.745621
2019-11-05 05:29:30,960 train 400 1.944201e-02 -0.719124
2019-11-05 05:29:41,755 train 450 1.953490e-02 -0.673510
2019-11-05 05:29:52,555 train 500 1.951766e-02 -0.770523
2019-11-05 05:30:03,366 train 550 1.951890e-02 -0.750316
2019-11-05 05:30:14,199 train 600 1.953516e-02 -0.740982
2019-11-05 05:30:25,008 train 650 1.949681e-02 -1.382042
2019-11-05 05:30:35,930 train 700 1.949803e-02 -1.325372
2019-11-05 05:30:46,761 train 750 1.944335e-02 -1.288107
2019-11-05 05:30:57,603 train 800 1.944680e-02 -1.248183
2019-11-05 05:31:08,441 train 850 1.943949e-02 -1.204849
2019-11-05 05:31:11,704 training loss; R2: 1.943706e-02 -1.196298
2019-11-05 05:31:12,308 valid 000 1.537661e-02 -0.328387
2019-11-05 05:31:23,150 valid 050 1.469622e-02 -0.619657
2019-11-05 05:31:32,876 validation loss; R2: 1.470115e-02 -0.541431
2019-11-05 05:31:32,950 epoch 143 lr 2.000000e-04
2019-11-05 05:31:33,670 train 000 1.681017e-02 -0.428653
2019-11-05 05:31:44,451 train 050 1.921805e-02 -50.281856
2019-11-05 05:31:55,213 train 100 1.931544e-02 -25.700739
2019-11-05 05:32:05,914 train 150 1.926583e-02 -17.422739
2019-11-05 05:32:16,671 train 200 1.929638e-02 -13.200805
2019-11-05 05:32:27,409 train 250 1.924763e-02 -10.745109
2019-11-05 05:32:38,109 train 300 1.937563e-02 -9.185459
2019-11-05 05:32:48,791 train 350 1.940627e-02 -7.957088
2019-11-05 05:32:59,485 train 400 1.943728e-02 -7.028248
2019-11-05 05:33:10,185 train 450 1.940857e-02 -6.313800
2019-11-05 05:33:20,898 train 500 1.939563e-02 -5.743256
2019-11-05 05:33:31,611 train 550 1.938424e-02 -5.357111
2019-11-05 05:33:42,317 train 600 1.937417e-02 -4.956347
2019-11-05 05:33:53,046 train 650 1.935479e-02 -5.077558
2019-11-05 05:34:03,747 train 700 1.938548e-02 -4.765695
2019-11-05 05:34:14,441 train 750 1.935273e-02 -4.498747
2019-11-05 05:34:25,196 train 800 1.935194e-02 -4.258226
2019-11-05 05:34:35,928 train 850 1.936953e-02 -4.036062
2019-11-05 05:34:39,074 training loss; R2: 1.937743e-02 -3.974358
2019-11-05 05:34:39,690 valid 000 1.593924e-02 -2.718401
2019-11-05 05:34:50,452 valid 050 1.605952e-02 -0.974569
2019-11-05 05:35:00,046 validation loss; R2: 1.585150e-02 -0.978753
2019-11-05 05:35:00,115 epoch 144 lr 2.000000e-04
2019-11-05 05:35:00,861 train 000 2.095597e-02 -0.869705
2019-11-05 05:35:11,831 train 050 1.927610e-02 -0.853402
2019-11-05 05:35:22,645 train 100 1.914761e-02 -0.767190
2019-11-05 05:35:33,429 train 150 1.905706e-02 -0.736349
2019-11-05 05:35:44,226 train 200 1.930871e-02 -0.678437
2019-11-05 05:35:55,011 train 250 1.930898e-02 -0.697291
2019-11-05 05:36:05,800 train 300 1.932055e-02 -0.675182
2019-11-05 05:36:16,539 train 350 1.934586e-02 -0.666510
2019-11-05 05:36:27,368 train 400 1.933138e-02 -4.902155
2019-11-05 05:36:38,219 train 450 1.938746e-02 -4.411362
2019-11-05 05:36:48,955 train 500 1.940185e-02 -4.056716
2019-11-05 05:36:59,718 train 550 1.939818e-02 -3.752631
2019-11-05 05:37:10,563 train 600 1.942884e-02 -3.495031
2019-11-05 05:37:21,454 train 650 1.939031e-02 -3.270427
2019-11-05 05:37:32,297 train 700 1.942395e-02 -3.079524
2019-11-05 05:37:43,057 train 750 1.946960e-02 -2.906993
2019-11-05 05:37:53,785 train 800 1.945477e-02 -2.762762
2019-11-05 05:38:04,516 train 850 1.943706e-02 -2.640088
2019-11-05 05:38:07,751 training loss; R2: 1.942848e-02 -2.602304
2019-11-05 05:38:08,356 valid 000 1.546447e-02 0.060111
2019-11-05 05:38:19,071 valid 050 1.472172e-02 -0.573794
2019-11-05 05:38:28,525 validation loss; R2: 1.462940e-02 -0.529041
2019-11-05 05:38:28,594 epoch 145 lr 2.000000e-04
2019-11-05 05:38:29,334 train 000 2.074222e-02 -0.256044
2019-11-05 05:38:40,117 train 050 1.975578e-02 -0.710784
2019-11-05 05:38:50,948 train 100 1.964534e-02 -0.773863
2019-11-05 05:39:01,796 train 150 2.021793e-02 -0.708528
2019-11-05 05:39:12,582 train 200 2.009933e-02 -0.733642
2019-11-05 05:39:23,393 train 250 1.991338e-02 -0.708119
2019-11-05 05:39:34,152 train 300 1.982974e-02 -0.767816
2019-11-05 05:39:44,886 train 350 1.985528e-02 -0.748826
2019-11-05 05:39:55,671 train 400 1.977023e-02 -0.723207
2019-11-05 05:40:06,471 train 450 1.976361e-02 -0.713266
2019-11-05 05:40:17,269 train 500 1.967772e-02 -0.702444
2019-11-05 05:40:28,072 train 550 1.966779e-02 -0.676446
2019-11-05 05:40:38,889 train 600 1.964362e-02 -0.667601
2019-11-05 05:40:49,717 train 650 1.962840e-02 -0.663701
2019-11-05 05:41:00,509 train 700 1.962083e-02 -0.655410
2019-11-05 05:41:11,246 train 750 1.962564e-02 -0.651561
2019-11-05 05:41:22,013 train 800 1.960872e-02 -0.656391
2019-11-05 05:41:32,744 train 850 1.957298e-02 -0.760288
2019-11-05 05:41:35,987 training loss; R2: 1.955942e-02 -0.754277
2019-11-05 05:41:36,604 valid 000 1.403511e-02 -2.060787
2019-11-05 05:41:47,076 valid 050 1.461254e-02 -0.608514
2019-11-05 05:41:56,852 validation loss; R2: 1.442853e-02 -0.618290
2019-11-05 05:41:56,927 epoch 146 lr 2.000000e-04
2019-11-05 05:41:57,680 train 000 2.245658e-02 -1.052284
2019-11-05 05:42:08,597 train 050 1.946540e-02 -0.647485
2019-11-05 05:42:19,686 train 100 1.937028e-02 -0.599905
2019-11-05 05:42:30,483 train 150 1.936948e-02 -0.660894
2019-11-05 05:42:41,382 train 200 1.923674e-02 -0.686496
2019-11-05 05:42:52,183 train 250 1.925584e-02 -0.670501
2019-11-05 05:43:03,045 train 300 1.927134e-02 -0.721731
2019-11-05 05:43:13,844 train 350 1.929598e-02 -0.681136
2019-11-05 05:43:24,748 train 400 1.929645e-02 -0.642670
2019-11-05 05:43:35,538 train 450 1.926955e-02 -0.652253
2019-11-05 05:43:46,448 train 500 1.928965e-02 -0.629826
2019-11-05 05:43:57,220 train 550 1.928766e-02 -0.627595
2019-11-05 05:44:08,010 train 600 1.931090e-02 -0.635128
2019-11-05 05:44:18,785 train 650 1.930633e-02 -0.638798
2019-11-05 05:44:29,641 train 700 1.931703e-02 -0.644097
2019-11-05 05:44:40,442 train 750 1.930571e-02 -0.660082
2019-11-05 05:44:51,325 train 800 1.929197e-02 -0.648125
2019-11-05 05:45:02,081 train 850 1.932613e-02 -0.635339
2019-11-05 05:45:05,339 training loss; R2: 1.933809e-02 -0.632245
2019-11-05 05:45:05,956 valid 000 1.329029e-02 -0.459106
2019-11-05 05:45:16,759 valid 050 1.461872e-02 -0.588850
2019-11-05 05:45:26,279 validation loss; R2: 1.469653e-02 -0.513202
2019-11-05 05:45:26,340 epoch 147 lr 2.000000e-04
2019-11-05 05:45:27,075 train 000 1.906885e-02 -0.530566
2019-11-05 05:45:38,128 train 050 1.923615e-02 -0.490497
2019-11-05 05:45:49,340 train 100 1.933888e-02 -0.584815
2019-11-05 05:46:00,376 train 150 1.927523e-02 -0.854673
2019-11-05 05:46:11,285 train 200 1.927927e-02 -0.771781
2019-11-05 05:46:22,162 train 250 1.926168e-02 -0.765543
2019-11-05 05:46:33,094 train 300 1.928809e-02 -0.725983
2019-11-05 05:46:44,030 train 350 1.931556e-02 -0.740537
2019-11-05 05:46:54,954 train 400 1.931125e-02 -0.769186
2019-11-05 05:47:05,892 train 450 1.929180e-02 -0.736367
2019-11-05 05:47:16,823 train 500 1.926788e-02 -0.717483
2019-11-05 05:47:27,764 train 550 1.931496e-02 -0.697242
2019-11-05 05:47:38,704 train 600 1.931689e-02 -0.701608
2019-11-05 05:47:49,661 train 650 1.934215e-02 -0.689297
2019-11-05 05:48:00,544 train 700 1.936170e-02 -0.690992
2019-11-05 05:48:11,419 train 750 1.936233e-02 -0.672982
2019-11-05 05:48:22,282 train 800 1.937087e-02 -0.666507
2019-11-05 05:48:32,789 train 850 1.936012e-02 -0.662838
2019-11-05 05:48:35,947 training loss; R2: 1.937453e-02 -0.665928
2019-11-05 05:48:36,495 valid 000 1.365362e-02 -0.259391
2019-11-05 05:48:46,926 valid 050 1.469940e-02 -0.818957
2019-11-05 05:48:56,408 validation loss; R2: 1.479060e-02 -0.770877
2019-11-05 05:48:56,476 epoch 148 lr 2.000000e-04
2019-11-05 05:48:57,224 train 000 2.323831e-02 -0.520894
2019-11-05 05:49:08,148 train 050 1.966395e-02 -0.488949
2019-11-05 05:49:19,062 train 100 1.961111e-02 -0.660880
2019-11-05 05:49:29,958 train 150 1.948840e-02 -0.622451
2019-11-05 05:49:40,805 train 200 1.942682e-02 -0.657763
2019-11-05 05:49:51,664 train 250 1.939123e-02 -0.723914
2019-11-05 05:50:02,486 train 300 1.937684e-02 -0.704522
2019-11-05 05:50:13,298 train 350 1.933088e-02 -0.706211
2019-11-05 05:50:24,146 train 400 1.930353e-02 -0.689178
2019-11-05 05:50:34,997 train 450 1.939098e-02 -0.673002
2019-11-05 05:50:45,766 train 500 1.939241e-02 -0.707310
2019-11-05 05:50:56,560 train 550 1.937663e-02 -0.698439
2019-11-05 05:51:07,150 train 600 1.933502e-02 -0.674502
2019-11-05 05:51:17,956 train 650 1.932682e-02 -0.685754
2019-11-05 05:51:28,766 train 700 1.933185e-02 -0.711402
2019-11-05 05:51:39,579 train 750 1.936474e-02 -0.706899
2019-11-05 05:51:50,391 train 800 1.937746e-02 -0.710184
2019-11-05 05:52:00,855 train 850 1.940269e-02 -0.698073
2019-11-05 05:52:03,941 training loss; R2: 1.940955e-02 -0.690602
2019-11-05 05:52:04,503 valid 000 1.826953e-02 -0.062811
2019-11-05 05:52:15,035 valid 050 1.513107e-02 -0.254458
2019-11-05 05:52:24,465 validation loss; R2: 1.520120e-02 -0.330182
2019-11-05 05:52:24,526 epoch 149 lr 2.000000e-04
2019-11-05 05:52:25,237 train 000 2.041001e-02 -0.118903
2019-11-05 05:52:36,085 train 050 1.933540e-02 -0.630052
2019-11-05 05:52:46,985 train 100 1.937710e-02 -0.538446
2019-11-05 05:52:57,827 train 150 1.938024e-02 -0.553807
2019-11-05 05:53:08,640 train 200 1.927227e-02 -0.524995
2019-11-05 05:53:19,449 train 250 1.939057e-02 -0.582353
2019-11-05 05:53:30,274 train 300 1.942022e-02 -0.568144
2019-11-05 05:53:41,119 train 350 1.940145e-02 -0.578602
2019-11-05 05:53:51,950 train 400 1.944595e-02 -0.623935
2019-11-05 05:54:02,759 train 450 1.941249e-02 -0.630537
2019-11-05 05:54:13,632 train 500 1.939480e-02 -0.632650
2019-11-05 05:54:24,501 train 550 1.940982e-02 -0.637804
2019-11-05 05:54:35,353 train 600 1.937739e-02 -0.646480
2019-11-05 05:54:46,230 train 650 1.942935e-02 -0.637407
2019-11-05 05:54:57,109 train 700 1.944205e-02 -0.635215
2019-11-05 05:55:07,973 train 750 1.944196e-02 -0.633657
2019-11-05 05:55:18,820 train 800 1.944978e-02 -0.657617
2019-11-05 05:55:29,319 train 850 1.944032e-02 -0.651989
2019-11-05 05:55:32,473 training loss; R2: 1.942761e-02 -0.650365
2019-11-05 05:55:33,107 valid 000 1.461035e-02 -0.457412
2019-11-05 05:55:43,581 valid 050 1.460963e-02 -0.494017
2019-11-05 05:55:53,238 validation loss; R2: 1.465498e-02 -0.479356
2019-11-05 05:55:53,308 epoch 150 lr 2.000000e-04
2019-11-05 05:55:54,043 train 000 1.885643e-02 -0.028870
2019-11-05 05:56:05,026 train 050 1.907361e-02 -0.765941
2019-11-05 05:56:16,022 train 100 1.930692e-02 -0.658625
2019-11-05 05:56:26,949 train 150 1.926816e-02 -0.784591
2019-11-05 05:56:37,864 train 200 1.916384e-02 -0.689061
2019-11-05 05:56:48,760 train 250 1.914173e-02 -0.655915
2019-11-05 05:56:59,665 train 300 1.917144e-02 -0.628287
2019-11-05 05:57:10,541 train 350 1.918676e-02 -0.634252
2019-11-05 05:57:21,420 train 400 1.917771e-02 -0.658171
2019-11-05 05:57:32,313 train 450 1.919789e-02 -20.162301
2019-11-05 05:57:43,150 train 500 1.921159e-02 -18.202611
2019-11-05 05:57:53,984 train 550 1.919595e-02 -16.641402
2019-11-05 05:58:04,837 train 600 1.921747e-02 -15.305828
2019-11-05 05:58:15,672 train 650 1.921547e-02 -14.211805
2019-11-05 05:58:26,559 train 700 1.923863e-02 -13.252692
2019-11-05 05:58:37,446 train 750 1.922594e-02 -12.401006
2019-11-05 05:58:48,371 train 800 1.923410e-02 -11.657685
2019-11-05 05:58:58,988 train 850 1.924362e-02 -11.005398
2019-11-05 05:59:02,200 training loss; R2: 1.923691e-02 -10.822003
2019-11-05 05:59:02,797 valid 000 1.668682e-02 -0.698546
2019-11-05 05:59:13,552 valid 050 1.812582e-02 -0.207187
2019-11-05 05:59:22,927 validation loss; R2: 1.776099e-02 -0.239825
2019-11-05 05:59:22,993 epoch 151 lr 2.000000e-04
2019-11-05 05:59:23,729 train 000 1.816802e-02 -0.746818
2019-11-05 05:59:34,571 train 050 1.903475e-02 -0.845035
2019-11-05 05:59:45,440 train 100 1.912137e-02 -0.585723
2019-11-05 05:59:56,233 train 150 1.908202e-02 -0.589816
2019-11-05 06:00:06,973 train 200 1.901958e-02 -0.617499
2019-11-05 06:00:17,824 train 250 1.900691e-02 -1.730293
2019-11-05 06:00:28,531 train 300 1.908480e-02 -1.569122
2019-11-05 06:00:39,233 train 350 1.911368e-02 -1.451578
2019-11-05 06:00:49,971 train 400 1.908626e-02 -1.341493
2019-11-05 06:01:00,711 train 450 1.904010e-02 -1.250004
2019-11-05 06:01:11,423 train 500 1.905361e-02 -1.177414
2019-11-05 06:01:22,182 train 550 1.908233e-02 -1.126948
2019-11-05 06:01:32,904 train 600 1.913456e-02 -1.078478
2019-11-05 06:01:43,642 train 650 1.919015e-02 -1.059680
2019-11-05 06:01:54,364 train 700 1.920302e-02 -1.032786
2019-11-05 06:02:05,111 train 750 1.923577e-02 -0.997895
2019-11-05 06:02:15,779 train 800 1.926926e-02 -0.963173
2019-11-05 06:02:26,475 train 850 1.926912e-02 -0.946784
2019-11-05 06:02:29,602 training loss; R2: 1.928183e-02 -0.940935
2019-11-05 06:02:30,214 valid 000 1.801021e-02 -0.240790
2019-11-05 06:02:40,821 valid 050 2.038918e-02 -0.578628
2019-11-05 06:02:50,695 validation loss; R2: 2.044010e-02 -0.467396
2019-11-05 06:02:50,777 epoch 152 lr 2.000000e-04
2019-11-05 06:02:51,501 train 000 2.097968e-02 -0.694303
2019-11-05 06:03:02,354 train 050 1.969935e-02 -0.933523
2019-11-05 06:03:13,111 train 100 1.958812e-02 -0.963894
2019-11-05 06:03:23,831 train 150 1.999396e-02 -0.845846
2019-11-05 06:03:34,628 train 200 2.017232e-02 -0.764588
2019-11-05 06:03:45,512 train 250 2.005947e-02 -0.739241
2019-11-05 06:03:56,224 train 300 1.995932e-02 -0.713672
2019-11-05 06:04:07,058 train 350 1.990582e-02 -0.743477
2019-11-05 06:04:17,890 train 400 1.984406e-02 -0.758299
2019-11-05 06:04:28,669 train 450 1.987766e-02 -0.744753
2019-11-05 06:04:39,512 train 500 1.977807e-02 -0.719272
2019-11-05 06:04:50,326 train 550 1.971012e-02 -0.800865
2019-11-05 06:05:01,225 train 600 1.967595e-02 -0.796059
2019-11-05 06:05:12,049 train 650 1.963540e-02 -0.780004
2019-11-05 06:05:22,735 train 700 1.963574e-02 -0.768357
2019-11-05 06:05:33,521 train 750 1.960862e-02 -0.764843
2019-11-05 06:05:44,276 train 800 1.958816e-02 -0.756790
2019-11-05 06:05:54,987 train 850 1.957066e-02 -0.746125
2019-11-05 06:05:58,199 training loss; R2: 1.957275e-02 -0.736810
2019-11-05 06:05:58,831 valid 000 1.685788e-02 -1.381807
2019-11-05 06:06:09,568 valid 050 1.601762e-02 -1.243426
2019-11-05 06:06:19,080 validation loss; R2: 1.586817e-02 -1.123624
2019-11-05 06:06:19,150 epoch 153 lr 2.000000e-04
2019-11-05 06:06:19,893 train 000 1.902611e-02 -0.477657
2019-11-05 06:06:30,893 train 050 1.934996e-02 -0.617471
2019-11-05 06:06:41,853 train 100 1.941938e-02 -0.670268
2019-11-05 06:06:53,007 train 150 1.950631e-02 -0.611591
2019-11-05 06:07:03,976 train 200 1.948326e-02 -0.613894
2019-11-05 06:07:14,924 train 250 1.944311e-02 -0.581884
2019-11-05 06:07:25,802 train 300 1.931685e-02 -0.642694
2019-11-05 06:07:36,743 train 350 1.934340e-02 -0.643000
2019-11-05 06:07:47,691 train 400 1.935438e-02 -0.626382
2019-11-05 06:07:58,624 train 450 1.933115e-02 -12.148800
2019-11-05 06:08:09,588 train 500 1.933282e-02 -11.007566
2019-11-05 06:08:20,517 train 550 1.932453e-02 -10.060599
2019-11-05 06:08:31,329 train 600 1.932271e-02 -9.268659
2019-11-05 06:08:42,217 train 650 1.933180e-02 -8.830687
2019-11-05 06:08:53,118 train 700 1.934191e-02 -8.244281
2019-11-05 06:09:03,986 train 750 1.934798e-02 -7.729125
2019-11-05 06:09:14,884 train 800 1.934298e-02 -7.302455
2019-11-05 06:09:25,573 train 850 1.935483e-02 -6.902964
2019-11-05 06:09:28,800 training loss; R2: 1.935835e-02 -6.791049
2019-11-05 06:09:29,393 valid 000 1.318669e-02 -0.310306
2019-11-05 06:09:39,763 valid 050 1.486786e-02 -0.421555
2019-11-05 06:09:49,059 validation loss; R2: 1.478486e-02 -0.318086
2019-11-05 06:09:49,127 epoch 154 lr 2.000000e-04
2019-11-05 06:09:49,814 train 000 1.928319e-02 -0.741248
2019-11-05 06:10:00,589 train 050 1.958432e-02 -0.836980
2019-11-05 06:10:11,397 train 100 1.963173e-02 -1.335592
2019-11-05 06:10:22,174 train 150 1.971375e-02 -1.101772
2019-11-05 06:10:32,935 train 200 1.949801e-02 -0.973798
2019-11-05 06:10:43,266 train 250 1.954709e-02 -0.892741
2019-11-05 06:10:53,570 train 300 1.946468e-02 -1.058863
2019-11-05 06:11:03,853 train 350 1.943885e-02 -1.001963
2019-11-05 06:11:14,094 train 400 1.937870e-02 -0.928309
2019-11-05 06:11:24,355 train 450 1.936747e-02 -0.888269
2019-11-05 06:11:34,591 train 500 1.934495e-02 -0.890203
2019-11-05 06:11:44,935 train 550 1.931668e-02 -0.871544
2019-11-05 06:11:55,195 train 600 1.933015e-02 -0.871479
2019-11-05 06:12:05,412 train 650 1.929917e-02 -0.855281
2019-11-05 06:12:15,640 train 700 1.932784e-02 -0.827308
2019-11-05 06:12:25,875 train 750 1.933161e-02 -0.818044
2019-11-05 06:12:36,087 train 800 1.932703e-02 -0.808376
2019-11-05 06:12:46,032 train 850 1.932158e-02 -0.798426
2019-11-05 06:12:48,969 training loss; R2: 1.933083e-02 -0.792674
2019-11-05 06:12:49,549 valid 000 1.772367e-02 -0.476846
2019-11-05 06:12:59,241 valid 050 1.560394e-02 -0.664142
2019-11-05 06:13:08,112 validation loss; R2: 1.556305e-02 -0.628825
2019-11-05 06:13:08,182 epoch 155 lr 2.000000e-04
2019-11-05 06:13:08,828 train 000 1.734559e-02 0.003164
2019-11-05 06:13:18,940 train 050 1.892310e-02 -0.562491
2019-11-05 06:13:29,063 train 100 1.909062e-02 -0.508238
2019-11-05 06:13:39,131 train 150 1.918896e-02 -5.399586
2019-11-05 06:13:49,220 train 200 1.940426e-02 -4.228156
2019-11-05 06:13:59,292 train 250 1.945645e-02 -3.548476
2019-11-05 06:14:09,392 train 300 1.942837e-02 -3.030396
2019-11-05 06:14:19,438 train 350 1.942522e-02 -2.697792
2019-11-05 06:14:29,430 train 400 1.940567e-02 -2.453677
2019-11-05 06:14:39,399 train 450 1.942419e-02 -2.241105
2019-11-05 06:14:49,517 train 500 1.942570e-02 -2.111605
2019-11-05 06:14:59,519 train 550 1.936309e-02 -1.964210
2019-11-05 06:15:09,622 train 600 1.931263e-02 -1.860214
2019-11-05 06:15:19,609 train 650 1.932036e-02 -1.761929
2019-11-05 06:15:29,655 train 700 1.934761e-02 -1.687865
2019-11-05 06:15:39,742 train 750 1.938105e-02 -1.619635
2019-11-05 06:15:49,850 train 800 1.937106e-02 -1.552067
2019-11-05 06:15:59,923 train 850 1.937115e-02 -1.510863
2019-11-05 06:16:02,956 training loss; R2: 1.939685e-02 -1.492259
2019-11-05 06:16:03,500 valid 000 1.692346e-02 -0.106168
2019-11-05 06:16:13,309 valid 050 1.572852e-02 -0.477712
2019-11-05 06:16:21,915 validation loss; R2: 1.562329e-02 -0.536602
2019-11-05 06:16:21,983 epoch 156 lr 2.000000e-04
2019-11-05 06:16:22,648 train 000 2.295668e-02 -0.469331
2019-11-05 06:16:32,718 train 050 1.926221e-02 -0.768418
2019-11-05 06:16:42,755 train 100 1.938057e-02 -0.706010
2019-11-05 06:16:52,744 train 150 1.934170e-02 -0.669949
2019-11-05 06:17:02,780 train 200 1.936416e-02 -0.628140
2019-11-05 06:17:12,867 train 250 1.939260e-02 -0.629235
2019-11-05 06:17:22,933 train 300 1.928530e-02 -0.621364
2019-11-05 06:17:32,996 train 350 1.924890e-02 -0.653636
2019-11-05 06:17:43,080 train 400 1.927435e-02 -0.666723
2019-11-05 06:17:53,200 train 450 1.929495e-02 -0.691543
2019-11-05 06:18:03,288 train 500 1.931982e-02 -0.706605
2019-11-05 06:18:13,376 train 550 1.933660e-02 -0.699131
2019-11-05 06:18:23,447 train 600 1.931356e-02 -0.689568
2019-11-05 06:18:33,557 train 650 1.931641e-02 -0.675027
2019-11-05 06:18:43,590 train 700 1.933408e-02 -0.683986
2019-11-05 06:18:53,658 train 750 1.933212e-02 -0.671667
2019-11-05 06:19:03,699 train 800 1.932465e-02 -0.663797
2019-11-05 06:19:13,726 train 850 1.936586e-02 -1.963370
2019-11-05 06:19:16,748 training loss; R2: 1.936273e-02 -1.940020
2019-11-05 06:19:17,325 valid 000 1.394796e-02 0.010574
2019-11-05 06:19:27,368 valid 050 1.561050e-02 -0.645660
2019-11-05 06:19:36,074 validation loss; R2: 1.569215e-02 -0.516377
2019-11-05 06:19:36,142 epoch 157 lr 2.000000e-04
2019-11-05 06:19:36,853 train 000 1.970246e-02 -5.139189
2019-11-05 06:19:47,026 train 050 1.883892e-02 -0.565509
2019-11-05 06:19:57,271 train 100 1.894829e-02 -1.094253
2019-11-05 06:20:07,601 train 150 1.900793e-02 -0.900767
2019-11-05 06:20:17,904 train 200 1.903918e-02 -0.815781
2019-11-05 06:20:28,246 train 250 1.908178e-02 -0.755054
2019-11-05 06:20:38,485 train 300 1.920274e-02 -0.712307
2019-11-05 06:20:48,804 train 350 1.918607e-02 -0.770820
2019-11-05 06:20:59,062 train 400 1.919177e-02 -0.830164
2019-11-05 06:21:09,331 train 450 1.917521e-02 -0.803265
2019-11-05 06:21:19,635 train 500 1.918058e-02 -0.823244
2019-11-05 06:21:29,947 train 550 1.922301e-02 -0.795220
2019-11-05 06:21:40,242 train 600 1.921980e-02 -0.770957
2019-11-05 06:21:50,619 train 650 1.922576e-02 -0.764517
2019-11-05 06:22:00,993 train 700 1.920971e-02 -0.755914
2019-11-05 06:22:11,345 train 750 1.923620e-02 -0.753676
2019-11-05 06:22:21,645 train 800 1.926220e-02 -0.734478
2019-11-05 06:22:31,912 train 850 1.926352e-02 -0.714991
2019-11-05 06:22:35,001 training loss; R2: 1.926379e-02 -0.714858
2019-11-05 06:22:35,606 valid 000 1.573496e-02 -1.848518
2019-11-05 06:22:45,704 valid 050 1.661914e-02 -0.893083
2019-11-05 06:22:54,800 validation loss; R2: 1.671552e-02 -0.894029
2019-11-05 06:22:54,868 epoch 158 lr 2.000000e-04
2019-11-05 06:22:55,551 train 000 2.060936e-02 -1.079835
2019-11-05 06:23:05,883 train 050 1.949584e-02 -0.540383
2019-11-05 06:23:16,422 train 100 1.939304e-02 -0.576186
2019-11-05 06:23:26,703 train 150 1.923580e-02 -0.603224
2019-11-05 06:23:36,916 train 200 1.919389e-02 -0.591334
2019-11-05 06:23:47,139 train 250 1.911540e-02 -0.585698
2019-11-05 06:23:57,406 train 300 1.916157e-02 -0.574034
2019-11-05 06:24:07,640 train 350 1.918710e-02 -0.589670
2019-11-05 06:24:17,850 train 400 1.925368e-02 -0.606718
2019-11-05 06:24:28,098 train 450 1.930008e-02 -0.605860
2019-11-05 06:24:38,265 train 500 1.926390e-02 -0.601548
2019-11-05 06:24:48,498 train 550 1.925704e-02 -0.605308
2019-11-05 06:24:58,700 train 600 1.922189e-02 -0.588605
2019-11-05 06:25:08,915 train 650 1.923956e-02 -0.605739
2019-11-05 06:25:19,140 train 700 1.925126e-02 -0.616833
2019-11-05 06:25:29,318 train 750 1.927226e-02 -0.636348
2019-11-05 06:25:39,535 train 800 1.930041e-02 -0.628202
2019-11-05 06:25:49,748 train 850 1.932755e-02 -0.624057
2019-11-05 06:25:52,804 training loss; R2: 1.933756e-02 -0.633484
2019-11-05 06:25:53,441 valid 000 1.311764e-02 -0.050944
2019-11-05 06:26:03,526 valid 050 1.441903e-02 -0.399015
2019-11-05 06:26:12,268 validation loss; R2: 1.450466e-02 -0.346492
2019-11-05 06:26:12,337 epoch 159 lr 2.000000e-04
2019-11-05 06:26:13,056 train 000 2.067706e-02 -0.396837
2019-11-05 06:26:23,222 train 050 1.972783e-02 -0.439906
2019-11-05 06:26:33,545 train 100 1.946408e-02 -0.527526
2019-11-05 06:26:43,874 train 150 1.929930e-02 -0.526203
2019-11-05 06:26:54,215 train 200 1.926224e-02 -0.505679
2019-11-05 06:27:04,573 train 250 1.933709e-02 -4.085740
2019-11-05 06:27:14,876 train 300 1.933218e-02 -3.591118
2019-11-05 06:27:25,193 train 350 1.936156e-02 -3.144071
2019-11-05 06:27:35,536 train 400 1.935261e-02 -2.834274
2019-11-05 06:27:45,862 train 450 1.936890e-02 -2.603254
2019-11-05 06:27:56,196 train 500 1.934270e-02 -2.392812
2019-11-05 06:28:06,522 train 550 1.933295e-02 -2.229852
2019-11-05 06:28:16,821 train 600 1.938429e-02 -2.109520
2019-11-05 06:28:27,060 train 650 1.955685e-02 -2.001119
2019-11-05 06:28:37,326 train 700 1.955565e-02 -1.899549
2019-11-05 06:28:47,609 train 750 1.955599e-02 -1.827706
2019-11-05 06:28:57,875 train 800 1.954256e-02 -1.753864
2019-11-05 06:29:08,169 train 850 1.953172e-02 -1.670210
2019-11-05 06:29:11,211 training loss; R2: 1.952841e-02 -1.659578
2019-11-05 06:29:11,807 valid 000 1.714361e-02 -0.662489
2019-11-05 06:29:22,103 valid 050 1.763917e-02 -0.434687
2019-11-05 06:29:31,308 validation loss; R2: 1.766998e-02 -0.626479
2019-11-05 06:29:31,379 epoch 160 lr 2.000000e-04
2019-11-05 06:29:32,130 train 000 2.038437e-02 -0.522667
2019-11-05 06:29:42,305 train 050 1.930243e-02 -0.744648
2019-11-05 06:29:52,681 train 100 1.946297e-02 -0.739598
2019-11-05 06:30:02,997 train 150 1.934350e-02 -0.839427
2019-11-05 06:30:13,337 train 200 1.942320e-02 -0.748235
2019-11-05 06:30:23,668 train 250 1.935108e-02 -0.746261
2019-11-05 06:30:34,055 train 300 1.932434e-02 -0.727017
2019-11-05 06:30:44,403 train 350 1.934258e-02 -0.731412
2019-11-05 06:30:54,762 train 400 1.929377e-02 -0.695286
2019-11-05 06:31:04,974 train 450 1.929628e-02 -0.667229
2019-11-05 06:31:15,302 train 500 1.927396e-02 -0.691989
2019-11-05 06:31:25,663 train 550 1.932463e-02 -0.680245
2019-11-05 06:31:36,087 train 600 1.937007e-02 -0.673414
2019-11-05 06:31:46,442 train 650 1.940815e-02 -0.680720
2019-11-05 06:31:56,733 train 700 1.938118e-02 -0.652306
2019-11-05 06:32:07,015 train 750 1.937819e-02 -0.641811
2019-11-05 06:32:17,339 train 800 1.937682e-02 -0.643910
2019-11-05 06:32:27,739 train 850 1.941614e-02 -0.637742
2019-11-05 06:32:30,851 training loss; R2: 1.941264e-02 -0.644876
2019-11-05 06:32:31,483 valid 000 1.480266e-02 -0.120376
2019-11-05 06:32:41,876 valid 050 1.523004e-02 -0.734147
2019-11-05 06:32:50,959 validation loss; R2: 1.506989e-02 -0.827638
2019-11-05 06:32:51,028 epoch 161 lr 2.000000e-04
2019-11-05 06:32:51,721 train 000 2.202181e-02 -0.144548
2019-11-05 06:33:02,080 train 050 1.928079e-02 -0.734822
2019-11-05 06:33:12,386 train 100 1.931661e-02 -0.631241
2019-11-05 06:33:22,680 train 150 1.935903e-02 -2.150886
2019-11-05 06:33:32,852 train 200 1.927441e-02 -1.733649
2019-11-05 06:33:43,153 train 250 1.927269e-02 -1.523740
2019-11-05 06:33:53,508 train 300 1.931134e-02 -1.408816
2019-11-05 06:34:03,880 train 350 1.934797e-02 -1.300017
2019-11-05 06:34:14,241 train 400 1.931796e-02 -1.218951
2019-11-05 06:34:24,583 train 450 1.933089e-02 -1.260656
2019-11-05 06:34:34,962 train 500 1.933977e-02 -1.187664
2019-11-05 06:34:45,368 train 550 1.934998e-02 -1.129037
2019-11-05 06:34:55,680 train 600 1.934693e-02 -1.095375
2019-11-05 06:35:06,020 train 650 1.939280e-02 -1.039057
2019-11-05 06:35:16,363 train 700 1.940390e-02 -1.035163
2019-11-05 06:35:26,695 train 750 1.937714e-02 -1.015019
2019-11-05 06:35:37,063 train 800 1.936513e-02 -1.004176
2019-11-05 06:35:47,419 train 850 1.935078e-02 -0.975430
2019-11-05 06:35:50,464 training loss; R2: 1.935629e-02 -0.966962
2019-11-05 06:35:51,057 valid 000 1.479493e-02 -0.770079
2019-11-05 06:36:01,123 valid 050 1.527462e-02 -0.812619
2019-11-05 06:36:09,910 validation loss; R2: 1.535938e-02 -0.872452
2019-11-05 06:36:09,968 epoch 162 lr 2.000000e-04
2019-11-05 06:36:10,653 train 000 2.017918e-02 -0.028512
2019-11-05 06:36:20,866 train 050 1.941335e-02 -0.696871
2019-11-05 06:36:31,330 train 100 1.947031e-02 -0.783669
2019-11-05 06:36:41,698 train 150 1.946800e-02 -0.758476
2019-11-05 06:36:52,098 train 200 1.933991e-02 -0.775793
2019-11-05 06:37:02,533 train 250 1.939628e-02 -0.754022
2019-11-05 06:37:12,878 train 300 1.939084e-02 -0.737535
2019-11-05 06:37:23,249 train 350 1.930907e-02 -0.722697
2019-11-05 06:37:33,631 train 400 1.930721e-02 -0.703883
2019-11-05 06:37:44,013 train 450 1.926409e-02 -0.669809
2019-11-05 06:37:54,407 train 500 1.926051e-02 -0.680492
2019-11-05 06:38:04,782 train 550 1.928071e-02 -0.689391
2019-11-05 06:38:15,141 train 600 1.931464e-02 -0.677336
2019-11-05 06:38:25,468 train 650 1.932802e-02 -0.679723
2019-11-05 06:38:35,780 train 700 1.929846e-02 -0.749189
2019-11-05 06:38:46,141 train 750 1.931800e-02 -0.761600
2019-11-05 06:38:56,513 train 800 1.930985e-02 -0.821378
2019-11-05 06:39:06,894 train 850 1.927769e-02 -0.807161
2019-11-05 06:39:09,960 training loss; R2: 1.927379e-02 -0.804430
2019-11-05 06:39:10,571 valid 000 1.507954e-02 0.104155
2019-11-05 06:39:20,877 valid 050 1.579422e-02 -0.709916
2019-11-05 06:39:30,016 validation loss; R2: 1.590493e-02 -0.937934
2019-11-05 06:39:30,098 epoch 163 lr 2.000000e-04
2019-11-05 06:39:30,831 train 000 1.854491e-02 -0.276274
2019-11-05 06:39:41,137 train 050 1.928375e-02 -0.381960
2019-11-05 06:39:51,466 train 100 1.916309e-02 -0.645941
2019-11-05 06:40:01,845 train 150 1.925161e-02 -0.680281
2019-11-05 06:40:12,292 train 200 1.929877e-02 -0.638497
2019-11-05 06:40:22,638 train 250 1.924074e-02 -0.624295
2019-11-05 06:40:33,036 train 300 1.925393e-02 -0.677552
2019-11-05 06:40:43,445 train 350 1.922817e-02 -0.691508
2019-11-05 06:40:53,807 train 400 1.933821e-02 -0.699148
2019-11-05 06:41:04,145 train 450 1.936521e-02 -0.684488
2019-11-05 06:41:14,521 train 500 1.931680e-02 -0.701419
2019-11-05 06:41:24,897 train 550 1.933858e-02 -0.713146
2019-11-05 06:41:35,273 train 600 1.931328e-02 -0.688307
2019-11-05 06:41:45,609 train 650 1.930473e-02 -0.685291
2019-11-05 06:41:55,969 train 700 1.930198e-02 -0.676011
2019-11-05 06:42:06,357 train 750 1.936421e-02 -0.670160
2019-11-05 06:42:16,728 train 800 1.942062e-02 -0.661372
2019-11-05 06:42:27,050 train 850 1.943211e-02 -0.668316
2019-11-05 06:42:30,154 training loss; R2: 1.943086e-02 -0.676596
2019-11-05 06:42:30,757 valid 000 1.495558e-02 0.155199
2019-11-05 06:42:40,957 valid 050 1.503911e-02 -0.722856
2019-11-05 06:42:49,734 validation loss; R2: 1.492185e-02 -0.641843
2019-11-05 06:42:49,802 epoch 164 lr 2.000000e-04
2019-11-05 06:42:50,526 train 000 2.070807e-02 -0.402590
2019-11-05 06:43:00,804 train 050 1.958622e-02 -327.848286
2019-11-05 06:43:11,176 train 100 1.949371e-02 -165.970171
2019-11-05 06:43:21,491 train 150 1.929145e-02 -111.313822
2019-11-05 06:43:31,885 train 200 1.923878e-02 -83.734747
2019-11-05 06:43:42,283 train 250 1.923756e-02 -67.182529
2019-11-05 06:43:52,642 train 300 1.930006e-02 -56.138276
2019-11-05 06:44:03,020 train 350 1.926224e-02 -48.229185
2019-11-05 06:44:13,366 train 400 1.924057e-02 -42.284726
2019-11-05 06:44:23,704 train 450 1.924282e-02 -37.646593
2019-11-05 06:44:34,100 train 500 1.926093e-02 -33.955015
2019-11-05 06:44:44,482 train 550 1.931331e-02 -30.961945
2019-11-05 06:44:54,883 train 600 1.931465e-02 -28.442764
2019-11-05 06:45:05,218 train 650 1.932032e-02 -26.306220
2019-11-05 06:45:15,557 train 700 1.931295e-02 -24.468704
2019-11-05 06:45:25,864 train 750 1.929324e-02 -23.321281
2019-11-05 06:45:36,207 train 800 1.931662e-02 -21.915070
2019-11-05 06:45:46,557 train 850 1.932018e-02 -20.656901
2019-11-05 06:45:49,658 training loss; R2: 1.932978e-02 -20.314038
2019-11-05 06:45:50,207 valid 000 1.797335e-02 -0.637135
2019-11-05 06:46:00,419 valid 050 1.586375e-02 -0.493529
2019-11-05 06:46:09,536 validation loss; R2: 1.554890e-02 -0.552352
2019-11-05 06:46:09,602 epoch 165 lr 2.000000e-04
2019-11-05 06:46:10,286 train 000 1.631414e-02 -0.061288
2019-11-05 06:46:20,751 train 050 1.900808e-02 -0.420640
2019-11-05 06:46:31,059 train 100 1.880778e-02 -0.448120
2019-11-05 06:46:41,424 train 150 1.898969e-02 -0.552346
2019-11-05 06:46:51,768 train 200 1.903365e-02 -0.608904
2019-11-05 06:47:02,131 train 250 1.911676e-02 -0.609569
2019-11-05 06:47:12,486 train 300 1.912891e-02 -0.602323
2019-11-05 06:47:22,835 train 350 1.916046e-02 -0.599570
2019-11-05 06:47:33,163 train 400 1.916624e-02 -0.604888
2019-11-05 06:47:43,515 train 450 1.916266e-02 -0.601953
2019-11-05 06:47:53,854 train 500 1.915163e-02 -0.601061
2019-11-05 06:48:04,188 train 550 1.914653e-02 -0.580257
2019-11-05 06:48:14,496 train 600 1.915811e-02 -0.592499
2019-11-05 06:48:24,760 train 650 1.918577e-02 -0.597516
2019-11-05 06:48:35,081 train 700 1.920695e-02 -0.591725
2019-11-05 06:48:45,428 train 750 1.920133e-02 -0.601432
2019-11-05 06:48:55,709 train 800 1.922364e-02 -0.595186
2019-11-05 06:49:06,025 train 850 1.921355e-02 -0.726264
2019-11-05 06:49:09,112 training loss; R2: 1.921513e-02 -0.718564
2019-11-05 06:49:09,704 valid 000 1.386205e-02 -0.293010
2019-11-05 06:49:19,926 valid 050 1.443217e-02 -0.733827
2019-11-05 06:49:29,076 validation loss; R2: 1.433210e-02 -0.682835
2019-11-05 06:49:29,145 epoch 166 lr 2.000000e-04
2019-11-05 06:49:29,875 train 000 1.891007e-02 -0.820596
2019-11-05 06:49:40,171 train 050 1.901047e-02 -0.590939
2019-11-05 06:49:50,525 train 100 1.952421e-02 -0.455796
2019-11-05 06:50:00,787 train 150 1.962918e-02 -0.519426
2019-11-05 06:50:11,176 train 200 1.968350e-02 -0.533385
2019-11-05 06:50:21,542 train 250 1.966467e-02 -0.560793
2019-11-05 06:50:31,890 train 300 1.954368e-02 -0.566104
2019-11-05 06:50:42,237 train 350 1.953182e-02 -0.615788
2019-11-05 06:50:52,550 train 400 1.950698e-02 -0.619275
2019-11-05 06:51:02,880 train 450 1.942916e-02 -0.629600
2019-11-05 06:51:13,205 train 500 1.942403e-02 -0.614757
2019-11-05 06:51:23,566 train 550 1.940410e-02 -0.629034
2019-11-05 06:51:33,932 train 600 1.935361e-02 -0.653176
2019-11-05 06:51:44,248 train 650 1.938751e-02 -0.653792
2019-11-05 06:51:54,563 train 700 1.938596e-02 -0.650685
2019-11-05 06:52:04,893 train 750 1.936296e-02 -0.709420
2019-11-05 06:52:15,243 train 800 1.933570e-02 -0.708247
2019-11-05 06:52:25,596 train 850 1.932775e-02 -0.696545
2019-11-05 06:52:28,635 training loss; R2: 1.932194e-02 -0.705756
2019-11-05 06:52:29,277 valid 000 1.695180e-02 -0.092139
2019-11-05 06:52:39,584 valid 050 1.919457e-02 -0.215634
2019-11-05 06:52:48,724 validation loss; R2: 1.943325e-02 -0.306182
2019-11-05 06:52:48,795 epoch 167 lr 2.000000e-04
2019-11-05 06:52:49,546 train 000 2.191202e-02 -0.146199
2019-11-05 06:52:59,786 train 050 1.959085e-02 -0.544254
2019-11-05 06:53:10,238 train 100 1.937128e-02 -0.971435
2019-11-05 06:53:20,498 train 150 1.951938e-02 -0.893276
2019-11-05 06:53:30,895 train 200 1.946215e-02 -0.851612
2019-11-05 06:53:41,139 train 250 1.945314e-02 -0.797532
2019-11-05 06:53:51,469 train 300 1.942262e-02 -0.753238
2019-11-05 06:54:01,718 train 350 1.937525e-02 -0.716234
2019-11-05 06:54:12,049 train 400 1.935460e-02 -0.736038
2019-11-05 06:54:22,361 train 450 1.937205e-02 -0.714289
2019-11-05 06:54:32,721 train 500 1.934454e-02 -0.692942
2019-11-05 06:54:43,013 train 550 1.932654e-02 -0.686274
2019-11-05 06:54:53,381 train 600 1.931523e-02 -0.704708
2019-11-05 06:55:03,589 train 650 1.929831e-02 -0.792069
2019-11-05 06:55:13,911 train 700 1.932128e-02 -0.780688
2019-11-05 06:55:24,294 train 750 1.934671e-02 -0.757818
2019-11-05 06:55:34,587 train 800 1.933918e-02 -0.755394
2019-11-05 06:55:44,917 train 850 1.937383e-02 -0.746849
2019-11-05 06:55:47,948 training loss; R2: 1.937094e-02 -0.752038
2019-11-05 06:55:48,595 valid 000 1.465182e-02 0.150366
2019-11-05 06:55:58,803 valid 050 1.453960e-02 -0.769826
2019-11-05 06:56:07,818 validation loss; R2: 1.451651e-02 -0.706150
2019-11-05 06:56:07,889 epoch 168 lr 2.000000e-04
2019-11-05 06:56:08,593 train 000 1.977667e-02 -0.036607
2019-11-05 06:56:19,035 train 050 2.001567e-02 -0.567355
2019-11-05 06:56:29,477 train 100 1.954504e-02 -0.606646
2019-11-05 06:56:39,686 train 150 1.952132e-02 -0.771793
2019-11-05 06:56:49,898 train 200 1.939320e-02 -0.713018
2019-11-05 06:57:00,108 train 250 1.945010e-02 -0.724229
2019-11-05 06:57:10,310 train 300 1.951248e-02 -0.690693
2019-11-05 06:57:20,514 train 350 1.962623e-02 -0.677053
2019-11-05 06:57:30,709 train 400 1.959281e-02 -0.670945
2019-11-05 06:57:40,907 train 450 1.958588e-02 -0.667997
2019-11-05 06:57:51,126 train 500 1.963315e-02 -0.658832
2019-11-05 06:58:01,329 train 550 1.958218e-02 -0.662687
2019-11-05 06:58:11,544 train 600 1.951608e-02 -0.663839
2019-11-05 06:58:21,736 train 650 1.949091e-02 -0.660374
2019-11-05 06:58:31,948 train 700 1.945269e-02 -0.655430
2019-11-05 06:58:42,157 train 750 1.943337e-02 -0.663171
2019-11-05 06:58:52,309 train 800 1.940287e-02 -0.661504
2019-11-05 06:59:02,508 train 850 1.941089e-02 -2.526135
2019-11-05 06:59:05,584 training loss; R2: 1.940671e-02 -2.490676
2019-11-05 06:59:06,191 valid 000 1.415741e-02 -0.053822
2019-11-05 06:59:16,376 valid 050 1.481343e-02 -0.328587
2019-11-05 06:59:25,429 validation loss; R2: 1.468247e-02 -0.299885
2019-11-05 06:59:25,494 epoch 169 lr 2.000000e-04
2019-11-05 06:59:26,233 train 000 2.163066e-02 -0.596210
2019-11-05 06:59:36,421 train 050 1.947275e-02 -0.607612
2019-11-05 06:59:46,746 train 100 1.933553e-02 -0.578303
2019-11-05 06:59:57,133 train 150 1.930338e-02 -0.590940
2019-11-05 07:00:07,456 train 200 1.940275e-02 -0.617065
2019-11-05 07:00:17,865 train 250 1.931996e-02 -0.613753
2019-11-05 07:00:28,206 train 300 1.932643e-02 -0.619046
2019-11-05 07:00:38,470 train 350 1.931344e-02 -0.651258
2019-11-05 07:00:48,844 train 400 1.928298e-02 -0.642693
2019-11-05 07:00:59,273 train 450 1.928669e-02 -0.628590
2019-11-05 07:01:09,519 train 500 1.922626e-02 -0.610146
2019-11-05 07:01:19,898 train 550 1.919716e-02 -0.633636
2019-11-05 07:01:30,257 train 600 1.921018e-02 -0.634540
2019-11-05 07:01:40,595 train 650 1.920386e-02 -0.622055
2019-11-05 07:01:50,839 train 700 1.921363e-02 -0.625648
2019-11-05 07:02:01,192 train 750 1.921399e-02 -0.695475
2019-11-05 07:02:11,565 train 800 1.926687e-02 -0.686315
2019-11-05 07:02:21,802 train 850 1.926946e-02 -0.675386
2019-11-05 07:02:24,859 training loss; R2: 1.926517e-02 -0.671918
2019-11-05 07:02:25,480 valid 000 1.613881e-02 -0.794377
2019-11-05 07:02:35,691 valid 050 1.524284e-02 -0.653592
2019-11-05 07:02:44,747 validation loss; R2: 1.507706e-02 -0.903925
2019-11-05 07:02:44,809 epoch 170 lr 2.000000e-04
2019-11-05 07:02:45,539 train 000 2.037683e-02 -0.834915
2019-11-05 07:02:55,787 train 050 1.982576e-02 -0.526247
2019-11-05 07:03:06,101 train 100 1.951427e-02 -0.584287
2019-11-05 07:03:16,490 train 150 1.931270e-02 -0.582783
2019-11-05 07:03:26,874 train 200 1.923302e-02 -0.583021
2019-11-05 07:03:37,120 train 250 1.915406e-02 -0.567585
2019-11-05 07:03:47,542 train 300 1.918334e-02 -0.533227
2019-11-05 07:03:57,919 train 350 1.919281e-02 -0.527394
2019-11-05 07:04:08,269 train 400 1.916339e-02 -0.547869
2019-11-05 07:04:18,582 train 450 1.914582e-02 -0.564927
2019-11-05 07:04:28,867 train 500 1.914777e-02 -0.601691
2019-11-05 07:04:39,097 train 550 1.915568e-02 -0.602611
2019-11-05 07:04:49,397 train 600 1.917725e-02 -0.598037
2019-11-05 07:04:59,780 train 650 1.919167e-02 -0.612694
2019-11-05 07:05:09,989 train 700 1.919623e-02 -0.640533
2019-11-05 07:05:20,281 train 750 1.918231e-02 -0.643601
2019-11-05 07:05:30,581 train 800 1.918004e-02 -0.642025
2019-11-05 07:05:40,911 train 850 1.921318e-02 -0.637819
2019-11-05 07:05:43,993 training loss; R2: 1.920540e-02 -0.648088
2019-11-05 07:05:44,559 valid 000 1.830405e-02 0.173692
2019-11-05 07:05:54,667 valid 050 1.466800e-02 -0.733570
2019-11-05 07:06:03,839 validation loss; R2: 1.488035e-02 -0.859977
2019-11-05 07:06:03,918 epoch 171 lr 2.000000e-04
2019-11-05 07:06:04,659 train 000 1.884163e-02 -0.290735
2019-11-05 07:06:14,955 train 050 1.959544e-02 -0.630806
2019-11-05 07:06:25,315 train 100 1.955842e-02 -0.578390
2019-11-05 07:06:35,644 train 150 1.951944e-02 -0.640267
2019-11-05 07:06:45,940 train 200 1.948637e-02 -0.599163
2019-11-05 07:06:56,298 train 250 1.944753e-02 -0.570753
2019-11-05 07:07:06,596 train 300 1.938782e-02 -0.575849
2019-11-05 07:07:16,903 train 350 1.928495e-02 -0.614406
2019-11-05 07:07:27,232 train 400 1.921196e-02 -0.641549
2019-11-05 07:07:37,555 train 450 1.918820e-02 -0.659999
2019-11-05 07:07:47,902 train 500 1.918495e-02 -0.682670
2019-11-05 07:07:58,250 train 550 1.919264e-02 -0.664059
2019-11-05 07:08:08,631 train 600 1.920591e-02 -0.654515
2019-11-05 07:08:18,949 train 650 1.923794e-02 -0.645035
2019-11-05 07:08:29,286 train 700 1.927664e-02 -0.651148
2019-11-05 07:08:39,642 train 750 1.931735e-02 -0.655810
2019-11-05 07:08:49,985 train 800 1.930033e-02 -0.657962
2019-11-05 07:09:00,371 train 850 1.928786e-02 -0.648588
2019-11-05 07:09:03,391 training loss; R2: 1.928852e-02 -0.646031
2019-11-05 07:09:03,971 valid 000 1.301702e-02 -0.057964
2019-11-05 07:09:14,097 valid 050 1.404002e-02 -0.549996
2019-11-05 07:09:23,095 validation loss; R2: 1.411508e-02 -0.558477
2019-11-05 07:09:23,162 epoch 172 lr 2.000000e-04
2019-11-05 07:09:23,870 train 000 1.960284e-02 -0.071405
2019-11-05 07:09:34,107 train 050 1.892352e-02 -0.610670
2019-11-05 07:09:44,380 train 100 1.909961e-02 -0.616019
2019-11-05 07:09:54,768 train 150 1.920030e-02 -0.693016
2019-11-05 07:10:05,029 train 200 1.914856e-02 -0.665472
2019-11-05 07:10:15,247 train 250 1.909924e-02 -0.707912
2019-11-05 07:10:25,525 train 300 1.920742e-02 -0.701965
2019-11-05 07:10:35,751 train 350 1.925091e-02 -0.676981
2019-11-05 07:10:46,089 train 400 1.926823e-02 -0.694197
2019-11-05 07:10:56,408 train 450 1.926386e-02 -0.671472
2019-11-05 07:11:06,810 train 500 1.924430e-02 -0.682319
2019-11-05 07:11:17,057 train 550 1.922003e-02 -0.658710
2019-11-05 07:11:27,425 train 600 1.925420e-02 -0.646896
2019-11-05 07:11:37,763 train 650 1.929897e-02 -0.632701
2019-11-05 07:11:48,104 train 700 1.938384e-02 -0.630030
2019-11-05 07:11:58,423 train 750 1.936743e-02 -0.620268
2019-11-05 07:12:08,717 train 800 1.939058e-02 -0.626515
2019-11-05 07:12:19,077 train 850 1.937953e-02 -0.620819
2019-11-05 07:12:22,145 training loss; R2: 1.937801e-02 -0.620178
2019-11-05 07:12:22,722 valid 000 1.539811e-02 0.075408
2019-11-05 07:12:32,867 valid 050 1.502786e-02 -0.545774
2019-11-05 07:12:42,084 validation loss; R2: 1.481850e-02 -0.541687
2019-11-05 07:12:42,148 epoch 173 lr 2.000000e-04
2019-11-05 07:12:42,860 train 000 1.932893e-02 -1.115287
2019-11-05 07:12:53,568 train 050 1.956003e-02 -0.477897
2019-11-05 07:13:04,377 train 100 1.933735e-02 -0.448626
2019-11-05 07:13:14,990 train 150 1.931417e-02 -0.469236
2019-11-05 07:13:25,645 train 200 1.939761e-02 -0.516022
2019-11-05 07:13:36,162 train 250 1.938297e-02 -0.563466
2019-11-05 07:13:46,621 train 300 1.936086e-02 -0.575333
2019-11-05 07:13:57,018 train 350 1.932119e-02 -0.564608
2019-11-05 07:14:07,272 train 400 1.936491e-02 -0.559475
2019-11-05 07:14:17,495 train 450 1.937440e-02 -0.557916
2019-11-05 07:14:27,747 train 500 1.935340e-02 -0.564273
2019-11-05 07:14:38,007 train 550 1.935804e-02 -0.589505
2019-11-05 07:14:48,263 train 600 1.936636e-02 -0.615444
2019-11-05 07:14:58,540 train 650 1.936401e-02 -0.618004
2019-11-05 07:15:08,835 train 700 1.936093e-02 -0.629826
2019-11-05 07:15:19,138 train 750 1.936483e-02 -0.630674
2019-11-05 07:15:29,434 train 800 1.937039e-02 -0.622358
2019-11-05 07:15:39,695 train 850 1.935138e-02 -0.625621
2019-11-05 07:15:42,744 training loss; R2: 1.935124e-02 -0.629035
2019-11-05 07:15:43,352 valid 000 1.360438e-02 -1.271122
2019-11-05 07:15:53,391 valid 050 1.428153e-02 -0.637317
2019-11-05 07:16:02,474 validation loss; R2: 1.422384e-02 -0.790419
2019-11-05 07:16:02,544 epoch 174 lr 2.000000e-04
2019-11-05 07:16:03,292 train 000 1.864851e-02 -0.215677
2019-11-05 07:16:13,558 train 050 1.934821e-02 -0.614361
2019-11-05 07:16:24,003 train 100 1.925124e-02 -0.624725
2019-11-05 07:16:34,310 train 150 1.926075e-02 -0.591390
2019-11-05 07:16:44,646 train 200 1.922179e-02 -0.602819
2019-11-05 07:16:54,913 train 250 1.915828e-02 -0.626491
2019-11-05 07:17:05,247 train 300 1.917023e-02 -0.645298
2019-11-05 07:17:15,635 train 350 1.924358e-02 -0.630841
2019-11-05 07:17:25,843 train 400 1.924283e-02 -0.615645
2019-11-05 07:17:36,141 train 450 1.928710e-02 -0.619178
2019-11-05 07:17:46,516 train 500 1.933882e-02 -0.618186
2019-11-05 07:17:56,805 train 550 1.934348e-02 -0.667188
2019-11-05 07:18:07,149 train 600 1.936229e-02 -0.658368
2019-11-05 07:18:17,348 train 650 1.936473e-02 -0.661750
2019-11-05 07:18:27,652 train 700 1.934487e-02 -0.672659
2019-11-05 07:18:38,075 train 750 1.931098e-02 -0.670781
2019-11-05 07:18:48,292 train 800 1.926600e-02 -0.682265
2019-11-05 07:18:58,583 train 850 1.926989e-02 -0.684948
2019-11-05 07:19:01,665 training loss; R2: 1.927459e-02 -0.677922
2019-11-05 07:19:02,274 valid 000 1.473767e-02 0.111727
2019-11-05 07:19:12,663 valid 050 1.451407e-02 -0.467136
2019-11-05 07:19:21,874 validation loss; R2: 1.455032e-02 -0.460407
2019-11-05 07:19:21,943 epoch 175 lr 2.000000e-04
2019-11-05 07:19:22,635 train 000 1.763534e-02 -1.099074
2019-11-05 07:19:33,060 train 050 1.954804e-02 -0.817100
2019-11-05 07:19:43,460 train 100 1.941543e-02 -0.694594
2019-11-05 07:19:53,819 train 150 1.928684e-02 -0.631478
2019-11-05 07:20:04,096 train 200 1.936887e-02 -0.623808
2019-11-05 07:20:14,368 train 250 1.932193e-02 -0.593268
2019-11-05 07:20:24,703 train 300 1.927744e-02 -0.592223
2019-11-05 07:20:35,040 train 350 1.930277e-02 -0.606868
2019-11-05 07:20:45,372 train 400 1.932643e-02 -0.619128
2019-11-05 07:20:55,719 train 450 1.936679e-02 -0.667166
2019-11-05 07:21:06,074 train 500 1.933847e-02 -0.674951
2019-11-05 07:21:16,374 train 550 1.932852e-02 -1.126388
2019-11-05 07:21:26,673 train 600 1.931033e-02 -1.080031
2019-11-05 07:21:37,016 train 650 1.932516e-02 -1.051873
2019-11-05 07:21:47,349 train 700 1.930690e-02 -1.021820
2019-11-05 07:21:57,676 train 750 1.931402e-02 -1.301124
2019-11-05 07:22:08,003 train 800 1.929648e-02 -1.266187
2019-11-05 07:22:18,329 train 850 1.927643e-02 -1.225090
2019-11-05 07:22:21,371 training loss; R2: 1.927235e-02 -1.211347
2019-11-05 07:22:22,027 valid 000 1.317780e-02 -1.004488
2019-11-05 07:22:31,981 valid 050 1.485851e-02 -0.451513
2019-11-05 07:22:41,017 validation loss; R2: 1.496150e-02 -0.471487
2019-11-05 07:22:41,088 epoch 176 lr 2.000000e-04
2019-11-05 07:22:41,833 train 000 1.858483e-02 -0.123389
2019-11-05 07:22:52,079 train 050 1.925668e-02 -0.677492
2019-11-05 07:23:02,433 train 100 1.919045e-02 -0.601679
2019-11-05 07:23:12,755 train 150 1.916517e-02 -0.610577
2019-11-05 07:23:23,126 train 200 1.907651e-02 -0.637865
2019-11-05 07:23:33,514 train 250 1.911526e-02 -0.630183
2019-11-05 07:23:43,869 train 300 1.923694e-02 -0.648528
2019-11-05 07:23:54,194 train 350 1.928538e-02 -0.638050
2019-11-05 07:24:04,489 train 400 1.931260e-02 -0.624267
2019-11-05 07:24:14,848 train 450 1.931930e-02 -0.606619
2019-11-05 07:24:25,189 train 500 1.928225e-02 -0.617490
2019-11-05 07:24:35,517 train 550 1.928744e-02 -0.618562
2019-11-05 07:24:45,848 train 600 1.930110e-02 -0.607869
2019-11-05 07:24:56,198 train 650 1.928277e-02 -0.598222
2019-11-05 07:25:06,515 train 700 1.927565e-02 -0.595047
2019-11-05 07:25:16,843 train 750 1.929078e-02 -0.593194
2019-11-05 07:25:27,179 train 800 1.928142e-02 -0.584716
2019-11-05 07:25:37,495 train 850 1.929478e-02 -0.596894
2019-11-05 07:25:40,535 training loss; R2: 1.929667e-02 -0.595587
2019-11-05 07:25:41,142 valid 000 1.582786e-02 -0.748653
2019-11-05 07:25:51,624 valid 050 1.517172e-02 -0.751839
2019-11-05 07:26:00,743 validation loss; R2: 1.500668e-02 -0.771625
2019-11-05 07:26:00,810 epoch 177 lr 2.000000e-04
2019-11-05 07:26:01,509 train 000 2.116696e-02 -0.526614
2019-11-05 07:26:11,813 train 050 1.916347e-02 -0.647727
2019-11-05 07:26:22,234 train 100 1.947180e-02 -0.588473
2019-11-05 07:26:32,568 train 150 1.944272e-02 -0.593710
2019-11-05 07:26:42,924 train 200 1.936886e-02 -0.591732
2019-11-05 07:26:53,237 train 250 1.935095e-02 -0.610766
2019-11-05 07:27:03,512 train 300 1.937132e-02 -0.650645
2019-11-05 07:27:13,824 train 350 1.934478e-02 -0.770538
2019-11-05 07:27:24,149 train 400 1.931834e-02 -0.742972
2019-11-05 07:27:34,523 train 450 1.930676e-02 -0.725253
2019-11-05 07:27:44,846 train 500 1.927587e-02 -0.723891
2019-11-05 07:27:55,183 train 550 1.923633e-02 -0.720596
2019-11-05 07:28:05,503 train 600 1.927097e-02 -0.694910
2019-11-05 07:28:15,844 train 650 1.929360e-02 -0.683853
2019-11-05 07:28:26,249 train 700 1.928248e-02 -0.707301
2019-11-05 07:28:36,615 train 750 1.926575e-02 -0.695173
2019-11-05 07:28:46,976 train 800 1.925684e-02 -0.683068
2019-11-05 07:28:57,377 train 850 1.930524e-02 -0.679410
2019-11-05 07:29:00,494 training loss; R2: 1.932595e-02 -0.675164
2019-11-05 07:29:01,079 valid 000 1.548421e-02 -0.253083
2019-11-05 07:29:10,955 valid 050 1.596184e-02 -0.314828
2019-11-05 07:29:19,671 validation loss; R2: 1.570961e-02 -0.447527
2019-11-05 07:29:19,737 epoch 178 lr 2.000000e-04
2019-11-05 07:29:20,480 train 000 2.124070e-02 -0.151427
2019-11-05 07:29:30,932 train 050 2.008465e-02 -0.528816
2019-11-05 07:29:41,524 train 100 1.941363e-02 -0.698270
2019-11-05 07:29:51,961 train 150 1.936888e-02 -0.626832
2019-11-05 07:30:02,540 train 200 1.943477e-02 -0.650986
2019-11-05 07:30:13,000 train 250 1.936386e-02 -0.680750
2019-11-05 07:30:23,450 train 300 1.937651e-02 -0.673646
2019-11-05 07:30:33,813 train 350 1.937894e-02 -0.669772
2019-11-05 07:30:44,169 train 400 1.933806e-02 -0.654729
2019-11-05 07:30:54,535 train 450 1.930682e-02 -0.647418
2019-11-05 07:31:04,894 train 500 1.927597e-02 -0.629379
2019-11-05 07:31:15,195 train 550 1.927284e-02 -0.622864
2019-11-05 07:31:25,484 train 600 1.927083e-02 -0.645550
2019-11-05 07:31:35,782 train 650 1.932117e-02 -0.652093
2019-11-05 07:31:46,059 train 700 1.932466e-02 -0.671775
2019-11-05 07:31:56,322 train 750 1.930255e-02 -0.682559
2019-11-05 07:32:06,599 train 800 1.925839e-02 -0.681725
2019-11-05 07:32:16,885 train 850 1.925154e-02 -0.690325
2019-11-05 07:32:19,970 training loss; R2: 1.924244e-02 -0.692365
2019-11-05 07:32:20,589 valid 000 1.346526e-02 -0.183733
2019-11-05 07:32:30,929 valid 050 1.408704e-02 -0.709947
2019-11-05 07:32:40,064 validation loss; R2: 1.411377e-02 -0.648381
2019-11-05 07:32:40,134 epoch 179 lr 2.000000e-04
2019-11-05 07:32:40,862 train 000 1.406502e-02 -0.270789
2019-11-05 07:32:51,220 train 050 1.889934e-02 -0.582021
2019-11-05 07:33:01,635 train 100 1.881084e-02 -0.577509
2019-11-05 07:33:11,852 train 150 1.904904e-02 -0.591349
2019-11-05 07:33:22,151 train 200 1.898950e-02 -0.590864
2019-11-05 07:33:32,539 train 250 1.902976e-02 -0.601387
2019-11-05 07:33:42,794 train 300 1.905226e-02 -0.594144
2019-11-05 07:33:53,049 train 350 1.907005e-02 -0.622955
2019-11-05 07:34:03,433 train 400 1.906918e-02 -0.639531
2019-11-05 07:34:13,604 train 450 1.905452e-02 -0.653010
2019-11-05 07:34:23,923 train 500 1.910643e-02 -0.644717
2019-11-05 07:34:34,273 train 550 1.915853e-02 -0.638137
2019-11-05 07:34:44,641 train 600 1.917886e-02 -0.631370
2019-11-05 07:34:55,026 train 650 1.915635e-02 -0.625379
2019-11-05 07:35:05,375 train 700 1.918475e-02 -0.622164
2019-11-05 07:35:15,710 train 750 1.924185e-02 -0.614570
2019-11-05 07:35:26,036 train 800 1.927730e-02 -0.874815
2019-11-05 07:35:36,394 train 850 1.928491e-02 -0.856430
2019-11-05 07:35:39,520 training loss; R2: 1.929600e-02 -0.854665
2019-11-05 07:35:40,093 valid 000 1.433668e-02 -0.563441
2019-11-05 07:35:50,741 valid 050 1.414266e-02 -0.419871
2019-11-05 07:36:00,081 validation loss; R2: 1.418950e-02 -0.751152
2019-11-05 07:36:00,149 epoch 180 lr 2.000000e-04
2019-11-05 07:36:00,931 train 000 2.146957e-02 -0.054441
2019-11-05 07:36:11,322 train 050 1.935121e-02 -0.623656
2019-11-05 07:36:21,823 train 100 1.952662e-02 -0.574923
2019-11-05 07:36:32,262 train 150 1.939515e-02 -0.628507
2019-11-05 07:36:42,764 train 200 1.937145e-02 -0.675793
2019-11-05 07:36:53,096 train 250 1.926711e-02 -0.655975
2019-11-05 07:37:03,564 train 300 1.923056e-02 -0.657590
2019-11-05 07:37:13,958 train 350 1.925381e-02 -0.688325
2019-11-05 07:37:24,404 train 400 1.921798e-02 -0.705581
2019-11-05 07:37:34,892 train 450 1.922151e-02 -0.680922
2019-11-05 07:37:45,223 train 500 1.924619e-02 -0.666770
2019-11-05 07:37:55,638 train 550 1.919581e-02 -0.651503
2019-11-05 07:38:06,042 train 600 1.921361e-02 -0.668872
2019-11-05 07:38:16,449 train 650 1.923738e-02 -0.651780
2019-11-05 07:38:26,860 train 700 1.924026e-02 -0.649308
2019-11-05 07:38:37,183 train 750 1.924164e-02 -0.654160
2019-11-05 07:38:47,641 train 800 1.926065e-02 -0.687932
2019-11-05 07:38:57,986 train 850 1.926986e-02 -0.681170
2019-11-05 07:39:01,094 training loss; R2: 1.926737e-02 -0.679086
2019-11-05 07:39:01,670 valid 000 1.204440e-02 -0.394505
2019-11-05 07:39:11,871 valid 050 1.500332e-02 -0.678241
2019-11-05 07:39:21,071 validation loss; R2: 1.488107e-02 -0.673027
2019-11-05 07:39:21,155 epoch 181 lr 2.000000e-04
2019-11-05 07:39:21,830 train 000 2.102787e-02 -0.206035
2019-11-05 07:39:32,405 train 050 1.938361e-02 -0.672659
2019-11-05 07:39:42,943 train 100 1.903314e-02 -0.573796
2019-11-05 07:39:53,482 train 150 1.907945e-02 -0.666832
2019-11-05 07:40:03,966 train 200 1.912828e-02 -0.644230
2019-11-05 07:40:14,447 train 250 1.910086e-02 -0.640415
2019-11-05 07:40:24,988 train 300 1.912962e-02 -0.631284
2019-11-05 07:40:35,533 train 350 1.911958e-02 -0.627610
2019-11-05 07:40:46,088 train 400 1.914055e-02 -0.605536
2019-11-05 07:40:56,640 train 450 1.914555e-02 -0.613039
2019-11-05 07:41:07,164 train 500 1.912607e-02 -0.647088
2019-11-05 07:41:17,710 train 550 1.912206e-02 -0.651956
2019-11-05 07:41:28,223 train 600 1.912810e-02 -0.662697
2019-11-05 07:41:38,788 train 650 1.911922e-02 -0.647567
2019-11-05 07:41:49,408 train 700 1.910991e-02 -0.730578
2019-11-05 07:41:59,978 train 750 1.911519e-02 -0.720046
2019-11-05 07:42:10,571 train 800 1.910551e-02 -0.725021
2019-11-05 07:42:21,050 train 850 1.911019e-02 -0.724054
2019-11-05 07:42:24,135 training loss; R2: 1.910858e-02 -0.718871
2019-11-05 07:42:24,748 valid 000 1.770676e-02 -0.490162
2019-11-05 07:42:34,822 valid 050 1.473773e-02 -0.275947
2019-11-05 07:42:43,931 validation loss; R2: 1.469302e-02 -0.367980
2019-11-05 07:42:44,008 epoch 182 lr 2.000000e-04
2019-11-05 07:42:44,727 train 000 1.712274e-02 -0.598762
2019-11-05 07:42:55,172 train 050 1.855372e-02 -0.725559
2019-11-05 07:43:05,400 train 100 1.887424e-02 -0.738156
2019-11-05 07:43:15,737 train 150 1.892307e-02 -0.710869
2019-11-05 07:43:26,101 train 200 1.911721e-02 -0.661979
2019-11-05 07:43:36,378 train 250 1.901639e-02 -0.668980
2019-11-05 07:43:46,724 train 300 1.911112e-02 -0.642649
2019-11-05 07:43:56,986 train 350 1.923398e-02 -0.651318
2019-11-05 07:44:07,289 train 400 1.924040e-02 -0.653799
2019-11-05 07:44:17,619 train 450 1.928043e-02 -0.750280
2019-11-05 07:44:27,939 train 500 1.929919e-02 -0.727370
2019-11-05 07:44:38,282 train 550 1.930314e-02 -0.706813
2019-11-05 07:44:48,537 train 600 1.931136e-02 -0.706633
2019-11-05 07:44:58,847 train 650 1.930071e-02 -0.716895
2019-11-05 07:45:09,269 train 700 1.932731e-02 -0.709286
2019-11-05 07:45:19,508 train 750 1.930826e-02 -0.723836
2019-11-05 07:45:29,847 train 800 1.929357e-02 -0.718282
2019-11-05 07:45:40,125 train 850 1.928080e-02 -0.697930
2019-11-05 07:45:43,139 training loss; R2: 1.928140e-02 -0.693793
2019-11-05 07:45:43,698 valid 000 1.601730e-02 -2.327469
2019-11-05 07:45:54,145 valid 050 1.598317e-02 -1.416863
2019-11-05 07:46:03,349 validation loss; R2: 1.595801e-02 -1.254692
2019-11-05 07:46:03,429 epoch 183 lr 2.000000e-04
2019-11-05 07:46:04,127 train 000 1.939315e-02 -0.012078
2019-11-05 07:46:14,740 train 050 1.889104e-02 -0.626988
2019-11-05 07:46:25,317 train 100 1.901932e-02 -0.594171
2019-11-05 07:46:35,894 train 150 1.890653e-02 -0.663296
2019-11-05 07:46:46,428 train 200 1.899434e-02 -0.643691
2019-11-05 07:46:57,054 train 250 1.905484e-02 -1.346336
2019-11-05 07:47:07,623 train 300 1.914888e-02 -1.219710
2019-11-05 07:47:18,147 train 350 1.911174e-02 -1.116995
2019-11-05 07:47:28,611 train 400 1.911748e-02 -1.036332
2019-11-05 07:47:38,978 train 450 1.906260e-02 -0.998469
2019-11-05 07:47:49,566 train 500 1.905496e-02 -0.947281
2019-11-05 07:48:00,182 train 550 1.906067e-02 -0.909244
2019-11-05 07:48:10,795 train 600 1.909383e-02 -0.885676
2019-11-05 07:48:21,361 train 650 1.910573e-02 -0.860706
2019-11-05 07:48:31,984 train 700 1.913697e-02 -0.848479
2019-11-05 07:48:42,589 train 750 1.912942e-02 -0.851638
2019-11-05 07:48:53,109 train 800 1.915834e-02 -0.833837
2019-11-05 07:49:03,335 train 850 1.918215e-02 -0.821577
2019-11-05 07:49:06,334 training loss; R2: 1.919314e-02 -0.817935
2019-11-05 07:49:06,936 valid 000 1.905327e-02 -0.537673
2019-11-05 07:49:17,350 valid 050 1.974083e-02 -0.290716
2019-11-05 07:49:26,554 validation loss; R2: 1.948977e-02 -0.375549
2019-11-05 07:49:26,629 epoch 184 lr 2.000000e-04
2019-11-05 07:49:27,309 train 000 1.900738e-02 -0.244049
2019-11-05 07:49:37,859 train 050 1.952844e-02 -0.440216
2019-11-05 07:49:48,290 train 100 1.950243e-02 -0.545147
2019-11-05 07:49:58,696 train 150 1.946436e-02 -0.540714
2019-11-05 07:50:09,079 train 200 1.950507e-02 -0.559617
2019-11-05 07:50:19,433 train 250 1.948320e-02 -0.571777
2019-11-05 07:50:29,763 train 300 1.948033e-02 -0.557810
2019-11-05 07:50:40,106 train 350 1.949355e-02 -0.556707
2019-11-05 07:50:50,469 train 400 1.948075e-02 -0.561193
2019-11-05 07:51:00,779 train 450 1.944415e-02 -0.582852
2019-11-05 07:51:11,111 train 500 1.948376e-02 -0.603226
2019-11-05 07:51:21,394 train 550 1.950235e-02 -0.602162
2019-11-05 07:51:31,727 train 600 1.947109e-02 -0.618944
2019-11-05 07:51:42,015 train 650 1.944083e-02 -0.649408
2019-11-05 07:51:52,337 train 700 1.943040e-02 -0.644322
2019-11-05 07:52:02,646 train 750 1.946345e-02 -0.633204
2019-11-05 07:52:12,892 train 800 1.947413e-02 -2.557558
2019-11-05 07:52:23,157 train 850 1.943310e-02 -2.440500
2019-11-05 07:52:26,197 training loss; R2: 1.942739e-02 -2.407954
2019-11-05 07:52:26,750 valid 000 1.464729e-02 -0.509773
2019-11-05 07:52:37,137 valid 050 1.372098e-02 -0.513660
2019-11-05 07:52:46,265 validation loss; R2: 1.378380e-02 -0.472886
2019-11-05 07:52:46,334 epoch 185 lr 2.000000e-04
2019-11-05 07:52:47,091 train 000 1.674079e-02 -0.228443
2019-11-05 07:52:57,405 train 050 1.937984e-02 -1.127286
2019-11-05 07:53:07,778 train 100 1.902150e-02 -0.794787
2019-11-05 07:53:18,119 train 150 1.900792e-02 -0.688988
2019-11-05 07:53:28,400 train 200 1.903342e-02 -0.724539
2019-11-05 07:53:38,703 train 250 1.905895e-02 -0.678384
2019-11-05 07:53:49,013 train 300 1.909931e-02 -0.656505
2019-11-05 07:53:59,305 train 350 1.917226e-02 -0.630370
2019-11-05 07:54:09,604 train 400 1.920181e-02 -0.603507
2019-11-05 07:54:19,888 train 450 1.920753e-02 -0.615211
2019-11-05 07:54:30,132 train 500 1.926952e-02 -0.617344
2019-11-05 07:54:40,466 train 550 1.926503e-02 -0.631546
2019-11-05 07:54:50,791 train 600 1.922089e-02 -0.625142
2019-11-05 07:55:01,018 train 650 1.922305e-02 -0.641378
2019-11-05 07:55:11,257 train 700 1.925881e-02 -0.650392
2019-11-05 07:55:21,544 train 750 1.926847e-02 -0.652828
2019-11-05 07:55:31,790 train 800 1.922724e-02 -0.648743
2019-11-05 07:55:42,096 train 850 1.922273e-02 -0.662536
2019-11-05 07:55:45,145 training loss; R2: 1.922934e-02 -0.660091
2019-11-05 07:55:45,752 valid 000 1.324662e-02 -2.316681
2019-11-05 07:55:55,860 valid 050 1.468499e-02 -0.351787
2019-11-05 07:56:05,187 validation loss; R2: 1.449265e-02 -0.431516
2019-11-05 07:56:05,261 epoch 186 lr 2.000000e-04
2019-11-05 07:56:06,020 train 000 1.820725e-02 -0.106291
2019-11-05 07:56:16,579 train 050 1.881344e-02 -0.628643
2019-11-05 07:56:26,913 train 100 1.894799e-02 -0.773949
2019-11-05 07:56:37,252 train 150 1.887354e-02 -0.753647
2019-11-05 07:56:47,520 train 200 1.900286e-02 -0.779167
2019-11-05 07:56:57,785 train 250 1.905188e-02 -0.719989
2019-11-05 07:57:08,006 train 300 1.897438e-02 -0.741581
2019-11-05 07:57:18,254 train 350 1.900787e-02 -0.707008
2019-11-05 07:57:28,474 train 400 1.900715e-02 -0.703699
2019-11-05 07:57:38,716 train 450 1.905706e-02 -0.706632
2019-11-05 07:57:48,935 train 500 1.910215e-02 -0.701064
2019-11-05 07:57:59,167 train 550 1.915748e-02 -0.702284
2019-11-05 07:58:09,371 train 600 1.926054e-02 -0.695720
2019-11-05 07:58:19,593 train 650 1.934082e-02 -0.684724
2019-11-05 07:58:29,806 train 700 1.935012e-02 -0.676782
2019-11-05 07:58:40,061 train 750 1.936496e-02 -0.684911
2019-11-05 07:58:50,307 train 800 1.936377e-02 -0.696735
2019-11-05 07:59:00,526 train 850 1.934538e-02 -0.700459
2019-11-05 07:59:03,589 training loss; R2: 1.934416e-02 -0.696764
2019-11-05 07:59:04,183 valid 000 1.489495e-02 -0.632561
2019-11-05 07:59:14,477 valid 050 1.423010e-02 -1.266021
2019-11-05 07:59:23,632 validation loss; R2: 1.410112e-02 -0.959215
2019-11-05 07:59:23,702 epoch 187 lr 2.000000e-04
2019-11-05 07:59:24,444 train 000 1.847220e-02 -0.048134
2019-11-05 07:59:34,824 train 050 1.917890e-02 -0.451831
2019-11-05 07:59:45,271 train 100 1.946342e-02 -0.633470
2019-11-05 07:59:55,561 train 150 1.941076e-02 -0.612169
2019-11-05 08:00:05,942 train 200 1.928999e-02 -0.582305
2019-11-05 08:00:16,181 train 250 1.919901e-02 -0.596648
2019-11-05 08:00:26,537 train 300 1.926121e-02 -0.719821
2019-11-05 08:00:36,871 train 350 1.935402e-02 -0.713454
2019-11-05 08:00:47,181 train 400 1.934802e-02 -0.673930
2019-11-05 08:00:57,553 train 450 1.934747e-02 -0.691861
2019-11-05 08:01:07,942 train 500 1.937125e-02 -0.701418
2019-11-05 08:01:18,230 train 550 1.938805e-02 -0.677737
2019-11-05 08:01:28,606 train 600 1.935640e-02 -0.665794
2019-11-05 08:01:38,890 train 650 1.931286e-02 -0.662766
2019-11-05 08:01:49,286 train 700 1.929705e-02 -0.647381
2019-11-05 08:01:59,557 train 750 1.930945e-02 -0.643654
2019-11-05 08:02:09,918 train 800 1.931119e-02 -0.657600
2019-11-05 08:02:20,043 train 850 1.931158e-02 -0.646504
2019-11-05 08:02:23,139 training loss; R2: 1.930766e-02 -0.656448
2019-11-05 08:02:23,699 valid 000 1.284242e-02 -1.006631
2019-11-05 08:02:34,137 valid 050 1.544885e-02 -0.979822
2019-11-05 08:02:43,303 validation loss; R2: 1.533140e-02 -1.221181
2019-11-05 08:02:43,371 epoch 188 lr 2.000000e-04
2019-11-05 08:02:44,043 train 000 2.052693e-02 -0.080866
2019-11-05 08:02:54,682 train 050 1.940085e-02 -0.450734
2019-11-05 08:03:05,252 train 100 1.932927e-02 -0.552017
2019-11-05 08:03:15,806 train 150 1.936583e-02 -0.614208
2019-11-05 08:03:26,343 train 200 1.934707e-02 -0.605637
2019-11-05 08:03:36,851 train 250 1.925881e-02 -0.625889
2019-11-05 08:03:47,396 train 300 1.925601e-02 -0.592959
2019-11-05 08:03:57,947 train 350 1.920348e-02 -0.609964
2019-11-05 08:04:08,457 train 400 1.912793e-02 -0.634640
2019-11-05 08:04:18,974 train 450 1.913597e-02 -0.644898
2019-11-05 08:04:29,611 train 500 1.913287e-02 -0.624806
2019-11-05 08:04:40,158 train 550 1.915747e-02 -0.633759
2019-11-05 08:04:50,758 train 600 1.918791e-02 -0.636789
2019-11-05 08:05:01,396 train 650 1.922213e-02 -0.615317
2019-11-05 08:05:11,948 train 700 1.926573e-02 -0.684197
2019-11-05 08:05:22,468 train 750 1.923823e-02 -0.678200
2019-11-05 08:05:32,840 train 800 1.921952e-02 -0.675529
2019-11-05 08:05:43,210 train 850 1.922132e-02 -0.668296
2019-11-05 08:05:46,330 training loss; R2: 1.922641e-02 -0.663886
2019-11-05 08:05:46,928 valid 000 1.562202e-02 -0.132414
2019-11-05 08:05:57,269 valid 050 1.402891e-02 -0.759041
2019-11-05 08:06:06,507 validation loss; R2: 1.390722e-02 -0.873984
2019-11-05 08:06:06,575 epoch 189 lr 2.000000e-04
2019-11-05 08:06:07,244 train 000 1.668101e-02 -1.243376
2019-11-05 08:06:17,844 train 050 1.936098e-02 -0.974807
2019-11-05 08:06:28,390 train 100 1.938224e-02 -1.060636
2019-11-05 08:06:38,860 train 150 1.931191e-02 -0.964500
2019-11-05 08:06:49,316 train 200 1.919412e-02 -0.908884
2019-11-05 08:06:59,839 train 250 1.918150e-02 -0.865187
2019-11-05 08:07:10,292 train 300 1.919772e-02 -0.826515
2019-11-05 08:07:20,688 train 350 1.920596e-02 -0.792592
2019-11-05 08:07:31,153 train 400 1.922741e-02 -0.781297
2019-11-05 08:07:41,600 train 450 1.922377e-02 -0.775944
2019-11-05 08:07:52,096 train 500 1.921177e-02 -0.753588
2019-11-05 08:08:02,497 train 550 1.919201e-02 -0.733664
2019-11-05 08:08:12,879 train 600 1.920610e-02 -0.712638
2019-11-05 08:08:23,351 train 650 1.917725e-02 -0.705320
2019-11-05 08:08:33,762 train 700 1.919651e-02 -0.699136
2019-11-05 08:08:44,080 train 750 1.920389e-02 -0.684036
2019-11-05 08:08:54,403 train 800 1.920663e-02 -0.674756
2019-11-05 08:09:04,731 train 850 1.918598e-02 -0.677962
2019-11-05 08:09:07,813 training loss; R2: 1.917602e-02 -0.673411
2019-11-05 08:09:08,441 valid 000 1.304148e-02 -0.468929
2019-11-05 08:09:18,677 valid 050 1.396666e-02 -0.426974
2019-11-05 08:09:27,910 validation loss; R2: 1.399794e-02 -0.313327
2019-11-05 08:09:27,980 epoch 190 lr 2.000000e-04
2019-11-05 08:09:28,734 train 000 1.703822e-02 -0.302049
2019-11-05 08:09:39,083 train 050 1.926592e-02 -0.523195
2019-11-05 08:09:49,483 train 100 1.896654e-02 -0.622234
2019-11-05 08:09:59,856 train 150 1.904082e-02 -0.643975
2019-11-05 08:10:10,172 train 200 1.903259e-02 -0.609038
2019-11-05 08:10:20,443 train 250 1.910366e-02 -0.580526
2019-11-05 08:10:30,685 train 300 1.909757e-02 -0.585489
2019-11-05 08:10:40,949 train 350 1.912856e-02 -0.576160
2019-11-05 08:10:51,222 train 400 1.915089e-02 -1.493209
2019-11-05 08:11:01,494 train 450 1.918050e-02 -1.397548
2019-11-05 08:11:11,759 train 500 1.913430e-02 -1.299752
2019-11-05 08:11:22,125 train 550 1.914722e-02 -1.233720
2019-11-05 08:11:32,473 train 600 1.917083e-02 -1.166751
2019-11-05 08:11:42,847 train 650 1.918160e-02 -1.152429
2019-11-05 08:11:53,227 train 700 1.917472e-02 -1.110984
2019-11-05 08:12:03,588 train 750 1.916463e-02 -1.090870
2019-11-05 08:12:13,899 train 800 1.918210e-02 -1.114910
2019-11-05 08:12:24,190 train 850 1.918879e-02 -1.090149
2019-11-05 08:12:27,288 training loss; R2: 1.919566e-02 -1.076822
2019-11-05 08:12:27,910 valid 000 1.569626e-02 -0.420593
2019-11-05 08:12:38,138 valid 050 1.423116e-02 -0.474144
2019-11-05 08:12:47,542 validation loss; R2: 1.439505e-02 -0.501999
2019-11-05 08:12:47,609 epoch 191 lr 2.000000e-04
2019-11-05 08:12:48,382 train 000 2.000503e-02 -1.106310
2019-11-05 08:12:58,757 train 050 1.897381e-02 -0.390623
2019-11-05 08:13:09,113 train 100 1.901538e-02 -0.493742
2019-11-05 08:13:19,438 train 150 1.899963e-02 -0.513491
2019-11-05 08:13:29,771 train 200 1.899920e-02 -0.595501
2019-11-05 08:13:40,162 train 250 1.907068e-02 -0.569656
2019-11-05 08:13:50,541 train 300 1.934103e-02 -0.607923
2019-11-05 08:14:00,897 train 350 1.939792e-02 -0.641605
2019-11-05 08:14:11,247 train 400 1.934479e-02 -0.636730
2019-11-05 08:14:21,582 train 450 1.933813e-02 -0.640415
2019-11-05 08:14:31,913 train 500 1.934581e-02 -0.639097
2019-11-05 08:14:42,257 train 550 1.931157e-02 -0.635280
2019-11-05 08:14:52,564 train 600 1.929325e-02 -0.645967
2019-11-05 08:15:02,873 train 650 1.928797e-02 -0.645512
2019-11-05 08:15:13,214 train 700 1.930430e-02 -0.651632
2019-11-05 08:15:23,577 train 750 1.930546e-02 -0.641059
2019-11-05 08:15:33,941 train 800 1.927388e-02 -0.635829
2019-11-05 08:15:44,287 train 850 1.926561e-02 -0.621879
2019-11-05 08:15:47,346 training loss; R2: 1.926306e-02 -0.619507
2019-11-05 08:15:47,932 valid 000 1.451328e-02 -4.035293
2019-11-05 08:15:58,058 valid 050 1.452963e-02 -0.660598
2019-11-05 08:16:07,555 validation loss; R2: 1.456610e-02 -0.524086
2019-11-05 08:16:07,630 epoch 192 lr 2.000000e-04
2019-11-05 08:16:08,389 train 000 2.071737e-02 -0.129643
2019-11-05 08:16:18,671 train 050 1.913285e-02 -0.780938
2019-11-05 08:16:29,037 train 100 1.926695e-02 -0.747657
2019-11-05 08:16:39,432 train 150 1.904952e-02 -0.707474
2019-11-05 08:16:49,790 train 200 1.902249e-02 -0.709977
2019-11-05 08:17:00,107 train 250 1.907510e-02 -0.677606
2019-11-05 08:17:10,445 train 300 1.904893e-02 -0.657901
2019-11-05 08:17:20,786 train 350 1.908791e-02 -0.666757
2019-11-05 08:17:31,083 train 400 1.915933e-02 -0.645579
2019-11-05 08:17:41,472 train 450 1.921213e-02 -0.680971
2019-11-05 08:17:51,760 train 500 1.920449e-02 -0.678722
2019-11-05 08:18:02,083 train 550 1.923522e-02 -0.659801
2019-11-05 08:18:12,506 train 600 1.921682e-02 -0.641251
2019-11-05 08:18:22,746 train 650 1.924009e-02 -0.669813
2019-11-05 08:18:33,054 train 700 1.925220e-02 -0.666054
2019-11-05 08:18:43,418 train 750 1.925015e-02 -0.651846
2019-11-05 08:18:53,579 train 800 1.924542e-02 -0.648635
2019-11-05 08:19:03,787 train 850 1.924366e-02 -0.644313
2019-11-05 08:19:06,888 training loss; R2: 1.923508e-02 -0.642810
2019-11-05 08:19:07,466 valid 000 1.882010e-02 -0.352848
2019-11-05 08:19:17,633 valid 050 1.563553e-02 -0.180054
2019-11-05 08:19:26,905 validation loss; R2: 1.563862e-02 -0.197222
2019-11-05 08:19:26,976 epoch 193 lr 2.000000e-04
2019-11-05 08:19:27,671 train 000 2.166412e-02 -0.163268
2019-11-05 08:19:38,058 train 050 1.956761e-02 -0.661981
2019-11-05 08:19:48,399 train 100 1.934042e-02 -0.589867
2019-11-05 08:19:58,695 train 150 1.941076e-02 -0.598038
2019-11-05 08:20:09,019 train 200 1.937981e-02 -0.669777
2019-11-05 08:20:19,432 train 250 1.929890e-02 -0.618316
2019-11-05 08:20:29,732 train 300 1.924917e-02 -0.643223
2019-11-05 08:20:40,071 train 350 1.924341e-02 -0.656553
2019-11-05 08:20:50,352 train 400 1.918564e-02 -0.658063
2019-11-05 08:21:00,624 train 450 1.916195e-02 -0.659289
2019-11-05 08:21:11,007 train 500 1.914325e-02 -0.680469
2019-11-05 08:21:21,343 train 550 1.915850e-02 -0.662927
2019-11-05 08:21:31,647 train 600 1.917321e-02 -0.660378
2019-11-05 08:21:41,913 train 650 1.913130e-02 -0.686231
2019-11-05 08:21:52,187 train 700 1.912538e-02 -0.662889
2019-11-05 08:22:02,431 train 750 1.915174e-02 -0.672051
2019-11-05 08:22:12,570 train 800 1.915202e-02 -0.668215
2019-11-05 08:22:22,875 train 850 1.915905e-02 -0.671026
2019-11-05 08:22:25,968 training loss; R2: 1.915910e-02 -0.672188
2019-11-05 08:22:26,541 valid 000 1.567303e-02 -1.503139
2019-11-05 08:22:36,956 valid 050 1.645269e-02 -0.805526
2019-11-05 08:22:46,118 validation loss; R2: 1.670431e-02 -0.643861
2019-11-05 08:22:46,198 epoch 194 lr 2.000000e-04
2019-11-05 08:22:46,911 train 000 1.643873e-02 -0.603528
2019-11-05 08:22:57,445 train 050 1.905133e-02 -0.691811
2019-11-05 08:23:07,970 train 100 1.920149e-02 -0.651328
2019-11-05 08:23:18,522 train 150 1.931609e-02 -0.647432
2019-11-05 08:23:29,081 train 200 1.929218e-02 -0.591432
2019-11-05 08:23:39,607 train 250 1.932610e-02 -0.556034
2019-11-05 08:23:50,142 train 300 1.926038e-02 -0.575127
2019-11-05 08:24:00,700 train 350 1.929328e-02 -0.620361
2019-11-05 08:24:11,268 train 400 1.925723e-02 -1.403077
2019-11-05 08:24:21,807 train 450 1.922432e-02 -1.782283
2019-11-05 08:24:32,351 train 500 1.921210e-02 -1.649134
2019-11-05 08:24:42,953 train 550 1.920791e-02 -1.565974
2019-11-05 08:24:53,571 train 600 1.921082e-02 -1.468984
2019-11-05 08:25:04,123 train 650 1.923069e-02 -1.421942
2019-11-05 08:25:14,550 train 700 1.923472e-02 -1.371486
2019-11-05 08:25:24,810 train 750 1.922242e-02 -1.323021
2019-11-05 08:25:35,142 train 800 1.920105e-02 -1.264949
2019-11-05 08:25:45,461 train 850 1.923629e-02 -1.227455
2019-11-05 08:25:48,510 training loss; R2: 1.923984e-02 -1.216293
2019-11-05 08:25:49,129 valid 000 1.283524e-02 0.026513
2019-11-05 08:25:59,353 valid 050 1.396741e-02 -0.516484
2019-11-05 08:26:08,791 validation loss; R2: 1.403056e-02 -0.481738
2019-11-05 08:26:08,866 epoch 195 lr 2.000000e-04
2019-11-05 08:26:09,615 train 000 1.730641e-02 -0.508390
2019-11-05 08:26:20,004 train 050 1.912108e-02 -0.485139
2019-11-05 08:26:30,350 train 100 1.919866e-02 -0.580023
2019-11-05 08:26:40,674 train 150 1.914882e-02 -0.614861
2019-11-05 08:26:50,986 train 200 1.910527e-02 -0.612080
2019-11-05 08:27:01,311 train 250 1.908344e-02 -0.613751
2019-11-05 08:27:11,592 train 300 1.912573e-02 -0.612788
2019-11-05 08:27:21,873 train 350 1.915042e-02 -0.623025
2019-11-05 08:27:32,140 train 400 1.915910e-02 -0.619933
2019-11-05 08:27:42,439 train 450 1.914471e-02 -0.621860
2019-11-05 08:27:52,723 train 500 1.916969e-02 -0.621420
2019-11-05 08:28:03,022 train 550 1.916089e-02 -0.641935
2019-11-05 08:28:13,326 train 600 1.915940e-02 -0.646348
2019-11-05 08:28:23,574 train 650 1.915062e-02 -0.651129
2019-11-05 08:28:33,795 train 700 1.912895e-02 -0.650159
2019-11-05 08:28:44,090 train 750 1.912452e-02 -0.646056
2019-11-05 08:28:54,367 train 800 1.914843e-02 -0.641769
2019-11-05 08:29:04,675 train 850 1.916283e-02 -0.634711
2019-11-05 08:29:07,770 training loss; R2: 1.915257e-02 -0.638735
2019-11-05 08:29:08,383 valid 000 1.390589e-02 -0.290193
2019-11-05 08:29:18,763 valid 050 1.354681e-02 -0.542394
2019-11-05 08:29:27,917 validation loss; R2: 1.352010e-02 -0.545650
2019-11-05 08:29:27,986 epoch 196 lr 2.000000e-04
2019-11-05 08:29:28,676 train 000 1.935180e-02 -0.229447
2019-11-05 08:29:39,202 train 050 1.891951e-02 -0.489402
2019-11-05 08:29:49,732 train 100 1.917387e-02 -0.578001
2019-11-05 08:30:00,217 train 150 1.918768e-02 -0.650805
2019-11-05 08:30:10,670 train 200 1.925504e-02 -0.629758
2019-11-05 08:30:21,130 train 250 1.922124e-02 -0.613044
2019-11-05 08:30:31,599 train 300 1.922230e-02 -0.616855
2019-11-05 08:30:42,040 train 350 1.922381e-02 -0.612620
2019-11-05 08:30:52,475 train 400 1.917360e-02 -0.603891
2019-11-05 08:31:02,900 train 450 1.915433e-02 -0.609184
2019-11-05 08:31:13,341 train 500 1.916631e-02 -0.630177
2019-11-05 08:31:23,770 train 550 1.919996e-02 -0.639412
2019-11-05 08:31:34,243 train 600 1.918774e-02 -0.632858
2019-11-05 08:31:44,758 train 650 1.922811e-02 -0.621870
2019-11-05 08:31:55,093 train 700 1.919312e-02 -0.629061
2019-11-05 08:32:05,515 train 750 1.915761e-02 -0.664710
2019-11-05 08:32:15,682 train 800 1.915122e-02 -0.653498
2019-11-05 08:32:25,758 train 850 1.912491e-02 -0.641531
2019-11-05 08:32:28,782 training loss; R2: 1.913493e-02 -0.639144
2019-11-05 08:32:29,372 valid 000 1.846317e-02 0.138336
2019-11-05 08:32:39,312 valid 050 1.399718e-02 -0.468562
2019-11-05 08:32:48,343 validation loss; R2: 1.414619e-02 -0.615730
2019-11-05 08:32:48,412 epoch 197 lr 2.000000e-04
2019-11-05 08:32:49,132 train 000 2.189275e-02 0.146143
2019-11-05 08:32:59,438 train 050 1.898126e-02 -0.626644
2019-11-05 08:33:09,726 train 100 1.877888e-02 -0.610802
2019-11-05 08:33:20,040 train 150 1.884457e-02 -0.563416
2019-11-05 08:33:30,390 train 200 1.889837e-02 -0.573770
2019-11-05 08:33:40,653 train 250 1.902586e-02 -0.612167
2019-11-05 08:33:50,969 train 300 1.906209e-02 -0.621362
2019-11-05 08:34:01,351 train 350 1.907880e-02 -0.621755
2019-11-05 08:34:11,730 train 400 1.904426e-02 -0.600195
2019-11-05 08:34:21,985 train 450 1.908782e-02 -0.630200
2019-11-05 08:34:32,256 train 500 1.911012e-02 -0.621208
2019-11-05 08:34:42,556 train 550 1.907913e-02 -0.609276
2019-11-05 08:34:52,918 train 600 1.906613e-02 -0.617165
2019-11-05 08:35:03,174 train 650 1.907581e-02 -0.610310
2019-11-05 08:35:13,527 train 700 1.907742e-02 -0.623728
2019-11-05 08:35:23,743 train 750 1.909242e-02 -0.622028
2019-11-05 08:35:34,135 train 800 1.908245e-02 -0.635641
2019-11-05 08:35:44,446 train 850 1.911877e-02 -0.637747
2019-11-05 08:35:47,484 training loss; R2: 1.911904e-02 -0.635818
2019-11-05 08:35:48,037 valid 000 1.813207e-02 -1.082837
2019-11-05 08:35:58,261 valid 050 1.448947e-02 -0.502703
2019-11-05 08:36:07,283 validation loss; R2: 1.454366e-02 -0.516559
2019-11-05 08:36:07,356 epoch 198 lr 2.000000e-04
2019-11-05 08:36:08,089 train 000 1.510103e-02 -0.071939
2019-11-05 08:36:18,362 train 050 1.878001e-02 -0.709020
2019-11-05 08:36:28,683 train 100 1.912308e-02 -0.674317
2019-11-05 08:36:39,020 train 150 1.917271e-02 -0.660167
2019-11-05 08:36:49,361 train 200 1.920506e-02 -0.676689
2019-11-05 08:36:59,745 train 250 1.927575e-02 -0.658502
2019-11-05 08:37:10,118 train 300 1.920501e-02 -0.635959
2019-11-05 08:37:20,451 train 350 1.923695e-02 -0.615848
2019-11-05 08:37:30,770 train 400 1.918478e-02 -0.609455
2019-11-05 08:37:41,009 train 450 1.917616e-02 -0.609141
2019-11-05 08:37:51,311 train 500 1.916851e-02 -0.622297
2019-11-05 08:38:01,634 train 550 1.915909e-02 -0.635404
2019-11-05 08:38:11,970 train 600 1.913557e-02 -0.653503
2019-11-05 08:38:22,302 train 650 1.914496e-02 -0.651016
2019-11-05 08:38:32,580 train 700 1.914425e-02 -0.645094
2019-11-05 08:38:42,856 train 750 1.913999e-02 -0.651993
2019-11-05 08:38:53,213 train 800 1.915094e-02 -0.645165
2019-11-05 08:39:03,634 train 850 1.914262e-02 -0.648020
2019-11-05 08:39:06,693 training loss; R2: 1.916702e-02 -0.644170
2019-11-05 08:39:07,241 valid 000 1.487841e-02 -0.631367
2019-11-05 08:39:17,471 valid 050 1.429026e-02 -0.254084
2019-11-05 08:39:26,509 validation loss; R2: 1.428734e-02 -0.389255
2019-11-05 08:39:26,591 epoch 199 lr 2.000000e-04
2019-11-05 08:39:27,317 train 000 1.827088e-02 -0.120020
2019-11-05 08:39:37,749 train 050 2.020103e-02 -0.679968
2019-11-05 08:39:48,168 train 100 1.984423e-02 -0.666923
2019-11-05 08:39:58,497 train 150 1.957338e-02 -0.621397
2019-11-05 08:40:08,838 train 200 1.956723e-02 -0.624882
2019-11-05 08:40:19,217 train 250 1.945522e-02 -0.646727
2019-11-05 08:40:29,630 train 300 1.945621e-02 -0.708702
2019-11-05 08:40:39,996 train 350 1.944315e-02 -0.722170
2019-11-05 08:40:50,352 train 400 1.939628e-02 -0.694871
2019-11-05 08:41:00,743 train 450 1.928906e-02 -0.684176
2019-11-05 08:41:11,166 train 500 1.933485e-02 -0.657950
2019-11-05 08:41:21,510 train 550 1.939456e-02 -0.667519
2019-11-05 08:41:31,857 train 600 1.935465e-02 -0.654822
2019-11-05 08:41:42,248 train 650 1.936249e-02 -0.651776
2019-11-05 08:41:52,565 train 700 1.934213e-02 -0.652128
2019-11-05 08:42:02,833 train 750 1.932850e-02 -0.648099
2019-11-05 08:42:13,252 train 800 1.931400e-02 -0.647780
2019-11-05 08:42:23,625 train 850 1.932628e-02 -0.636555
2019-11-05 08:42:26,677 training loss; R2: 1.931996e-02 -0.633408
2019-11-05 08:42:27,307 valid 000 1.468366e-02 -2.706478
2019-11-05 08:42:37,699 valid 050 1.445551e-02 -0.879685
2019-11-05 08:42:46,879 validation loss; R2: 1.449194e-02 -1.023501
2019-11-05 08:42:46,939 epoch 200 lr 2.000000e-04
2019-11-05 08:42:47,668 train 000 1.943741e-02 -0.543780
2019-11-05 08:42:58,250 train 050 1.944279e-02 -4.638252
2019-11-05 08:43:08,817 train 100 1.916368e-02 -2.632676
2019-11-05 08:43:19,347 train 150 1.925041e-02 -1.921205
2019-11-05 08:43:29,860 train 200 1.926066e-02 -1.575097
2019-11-05 08:43:40,359 train 250 1.927527e-02 -1.548111
2019-11-05 08:43:50,857 train 300 1.927447e-02 -1.413286
2019-11-05 08:44:01,320 train 350 1.920659e-02 -1.296942
2019-11-05 08:44:11,802 train 400 1.925567e-02 -1.189406
2019-11-05 08:44:22,300 train 450 1.920381e-02 -1.151929
2019-11-05 08:44:32,795 train 500 1.926137e-02 -1.075356
2019-11-05 08:44:43,278 train 550 1.926063e-02 -1.035289
2019-11-05 08:44:53,756 train 600 1.923625e-02 -0.998390
2019-11-05 08:45:04,237 train 650 1.923034e-02 -0.970233
2019-11-05 08:45:14,593 train 700 1.921291e-02 -0.953809
2019-11-05 08:45:24,802 train 750 1.921332e-02 -0.927647
2019-11-05 08:45:34,872 train 800 1.917390e-02 -0.907645
2019-11-05 08:45:44,930 train 850 1.915783e-02 -0.892627
2019-11-05 08:45:47,896 training loss; R2: 1.916702e-02 -0.884082
2019-11-05 08:45:48,443 valid 000 1.475658e-02 -0.283722
2019-11-05 08:45:58,646 valid 050 1.469899e-02 -0.267829
2019-11-05 08:46:07,648 validation loss; R2: 1.474734e-02 -0.503613
2019-11-05 08:46:07,717 epoch 201 lr 2.000000e-04
2019-11-05 08:46:08,457 train 000 1.780266e-02 -0.416427
2019-11-05 08:46:18,758 train 050 1.851217e-02 -0.565915
2019-11-05 08:46:29,016 train 100 1.874408e-02 -0.573882
2019-11-05 08:46:39,434 train 150 1.872169e-02 -0.617096
2019-11-05 08:46:49,857 train 200 1.885294e-02 -0.642980
2019-11-05 08:47:00,338 train 250 1.897967e-02 -0.598069
2019-11-05 08:47:10,618 train 300 1.901524e-02 -0.621525
2019-11-05 08:47:20,876 train 350 1.897972e-02 -0.620582
2019-11-05 08:47:31,061 train 400 1.901187e-02 -0.610365
2019-11-05 08:47:41,151 train 450 1.903923e-02 -0.602258
2019-11-05 08:47:51,255 train 500 1.902943e-02 -0.602945
2019-11-05 08:48:01,358 train 550 1.913054e-02 -0.598524
2019-11-05 08:48:11,436 train 600 1.916379e-02 -0.591835
2019-11-05 08:48:21,521 train 650 1.923278e-02 -0.582635
2019-11-05 08:48:31,612 train 700 1.923263e-02 -0.592891
2019-11-05 08:48:41,688 train 750 1.923213e-02 -0.610916
2019-11-05 08:48:51,785 train 800 1.921951e-02 -0.599997
2019-11-05 08:49:01,897 train 850 1.919631e-02 -0.600121
2019-11-05 08:49:04,918 training loss; R2: 1.920620e-02 -0.598164
2019-11-05 08:49:05,509 valid 000 1.296450e-02 0.024811
2019-11-05 08:49:15,718 valid 050 1.421406e-02 -0.208454
2019-11-05 08:49:24,788 validation loss; R2: 1.427802e-02 -0.260839
2019-11-05 08:49:24,858 epoch 202 lr 2.000000e-04
2019-11-05 08:49:25,593 train 000 1.653626e-02 0.048901
2019-11-05 08:49:36,014 train 050 1.877882e-02 -0.765346
2019-11-05 08:49:46,465 train 100 1.877405e-02 -1.277614
2019-11-05 08:49:56,875 train 150 1.870048e-02 -1.041583
2019-11-05 08:50:07,273 train 200 1.876129e-02 -0.925728
2019-11-05 08:50:17,681 train 250 1.881664e-02 -0.878973
2019-11-05 08:50:28,035 train 300 1.887937e-02 -0.835556
2019-11-05 08:50:38,430 train 350 1.889218e-02 -0.793861
2019-11-05 08:50:48,854 train 400 1.893607e-02 -0.757318
2019-11-05 08:50:59,237 train 450 1.890275e-02 -0.767018
2019-11-05 08:51:09,621 train 500 1.897083e-02 -0.757148
2019-11-05 08:51:19,979 train 550 1.902814e-02 -0.750445
2019-11-05 08:51:30,373 train 600 1.904255e-02 -0.716169
2019-11-05 08:51:40,797 train 650 1.904631e-02 -0.703567
2019-11-05 08:51:51,057 train 700 1.908834e-02 -0.704695
2019-11-05 08:52:01,211 train 750 1.907910e-02 -0.709389
2019-11-05 08:52:11,533 train 800 1.908771e-02 -0.701776
2019-11-05 08:52:21,909 train 850 1.908041e-02 -0.695004
2019-11-05 08:52:24,974 training loss; R2: 1.909951e-02 -0.693583
2019-11-05 08:52:25,576 valid 000 2.000767e-02 0.095971
2019-11-05 08:52:35,741 valid 050 1.820781e-02 -0.196497
2019-11-05 08:52:44,689 validation loss; R2: 1.832757e-02 -0.200672
2019-11-05 08:52:44,756 epoch 203 lr 2.000000e-04
2019-11-05 08:52:45,470 train 000 2.103813e-02 -0.286085
2019-11-05 08:52:55,814 train 050 1.857831e-02 -0.854304
2019-11-05 08:53:06,113 train 100 1.857490e-02 -0.759066
2019-11-05 08:53:16,504 train 150 1.871334e-02 -0.691905
2019-11-05 08:53:26,796 train 200 1.871053e-02 -0.735526
2019-11-05 08:53:37,034 train 250 1.883545e-02 -0.716828
2019-11-05 08:53:47,405 train 300 1.888481e-02 -0.686610
2019-11-05 08:53:57,741 train 350 1.886151e-02 -0.689193
2019-11-05 08:54:07,956 train 400 1.889451e-02 -0.666054
2019-11-05 08:54:18,176 train 450 1.893846e-02 -0.675142
2019-11-05 08:54:28,508 train 500 1.895758e-02 -2.119849
2019-11-05 08:54:38,782 train 550 1.897774e-02 -2.004771
2019-11-05 08:54:49,050 train 600 1.897550e-02 -1.910472
2019-11-05 08:54:59,416 train 650 1.894344e-02 -1.808510
2019-11-05 08:55:09,836 train 700 1.896588e-02 -1.716523
2019-11-05 08:55:20,182 train 750 1.898207e-02 -1.647082
2019-11-05 08:55:30,608 train 800 1.901048e-02 -1.574058
2019-11-05 08:55:41,003 train 850 1.900356e-02 -1.520183
2019-11-05 08:55:44,082 training loss; R2: 1.900254e-02 -1.510390
2019-11-05 08:55:44,672 valid 000 1.398802e-02 -0.356895
2019-11-05 08:55:55,073 valid 050 1.379943e-02 -0.564182
2019-11-05 08:56:04,270 validation loss; R2: 1.375928e-02 -0.482164
2019-11-05 08:56:04,329 epoch 204 lr 2.000000e-04
2019-11-05 08:56:05,023 train 000 1.725271e-02 -0.252648
2019-11-05 08:56:15,604 train 050 1.887018e-02 -0.561072
2019-11-05 08:56:26,195 train 100 1.881578e-02 -0.582198
2019-11-05 08:56:36,793 train 150 1.894465e-02 -0.911815
2019-11-05 08:56:47,364 train 200 1.893397e-02 -0.805968
2019-11-05 08:56:57,946 train 250 1.890851e-02 -0.780344
2019-11-05 08:57:08,487 train 300 1.896670e-02 -0.731499
2019-11-05 08:57:19,009 train 350 1.897148e-02 -0.734261
2019-11-05 08:57:29,533 train 400 1.902895e-02 -0.734960
2019-11-05 08:57:40,115 train 450 1.905527e-02 -0.715931
2019-11-05 08:57:50,672 train 500 1.906439e-02 -0.704792
2019-11-05 08:58:01,275 train 550 1.912918e-02 -0.798517
2019-11-05 08:58:11,754 train 600 1.916805e-02 -0.787680
2019-11-05 08:58:22,255 train 650 1.919863e-02 -0.790028
2019-11-05 08:58:32,462 train 700 1.918042e-02 -0.779429
2019-11-05 08:58:42,821 train 750 1.919984e-02 -0.763022
2019-11-05 08:58:53,145 train 800 1.923992e-02 -0.747494
2019-11-05 08:59:03,510 train 850 1.922780e-02 -0.735433
2019-11-05 08:59:06,578 training loss; R2: 1.921035e-02 -0.731630
2019-11-05 08:59:07,190 valid 000 1.622155e-02 -0.001778
2019-11-05 08:59:17,575 valid 050 1.558595e-02 -0.281118
2019-11-05 08:59:26,763 validation loss; R2: 1.566076e-02 -0.287721
2019-11-05 08:59:26,834 epoch 205 lr 2.000000e-04
2019-11-05 08:59:27,519 train 000 1.733293e-02 -0.951788
2019-11-05 08:59:38,079 train 050 1.928053e-02 -0.685524
2019-11-05 08:59:48,592 train 100 1.921415e-02 -0.605695
2019-11-05 08:59:59,097 train 150 1.919635e-02 -0.734838
2019-11-05 09:00:09,625 train 200 1.929594e-02 -0.679212
2019-11-05 09:00:20,117 train 250 1.928044e-02 -1.001210
2019-11-05 09:00:30,568 train 300 1.921719e-02 -0.912437
2019-11-05 09:00:41,071 train 350 1.919975e-02 -0.876635
2019-11-05 09:00:51,621 train 400 1.916227e-02 -0.853559
2019-11-05 09:01:02,139 train 450 1.913858e-02 -0.813965
2019-11-05 09:01:12,631 train 500 1.909346e-02 -0.783586
2019-11-05 09:01:23,119 train 550 1.909960e-02 -0.759457
2019-11-05 09:01:33,635 train 600 1.911438e-02 -0.747677
2019-11-05 09:01:43,998 train 650 1.910637e-02 -0.724551
2019-11-05 09:01:54,353 train 700 1.912943e-02 -0.719036
2019-11-05 09:02:04,774 train 750 1.910886e-02 -0.712829
2019-11-05 09:02:15,107 train 800 1.910555e-02 -0.711038
2019-11-05 09:02:25,401 train 850 1.913383e-02 -0.703042
2019-11-05 09:02:28,467 training loss; R2: 1.913087e-02 -0.699644
2019-11-05 09:02:29,089 valid 000 1.238218e-02 0.009643
2019-11-05 09:02:39,365 valid 050 1.449403e-02 -0.559651
2019-11-05 09:02:48,670 validation loss; R2: 1.471766e-02 -0.519902
2019-11-05 09:02:48,742 epoch 206 lr 2.000000e-04
2019-11-05 09:02:49,493 train 000 1.799411e-02 -3.558765
2019-11-05 09:02:59,807 train 050 1.932190e-02 -0.755564
2019-11-05 09:03:10,128 train 100 1.916772e-02 -1.357472
2019-11-05 09:03:20,406 train 150 1.919556e-02 -1.307277
2019-11-05 09:03:30,683 train 200 1.915880e-02 -1.120408
2019-11-05 09:03:40,949 train 250 1.918350e-02 -1.026314
2019-11-05 09:03:51,254 train 300 1.916741e-02 -0.951555
2019-11-05 09:04:01,587 train 350 1.918291e-02 -0.904789
2019-11-05 09:04:11,961 train 400 1.916239e-02 -0.878444
2019-11-05 09:04:22,312 train 450 1.913914e-02 -0.849555
2019-11-05 09:04:32,672 train 500 1.912846e-02 -0.829346
2019-11-05 09:04:43,004 train 550 1.916359e-02 -0.808997
2019-11-05 09:04:53,374 train 600 1.915052e-02 -0.846641
2019-11-05 09:05:03,721 train 650 1.913339e-02 -0.812257
2019-11-05 09:05:14,084 train 700 1.913032e-02 -0.853836
2019-11-05 09:05:24,421 train 750 1.910475e-02 -0.831905
2019-11-05 09:05:34,757 train 800 1.909167e-02 -0.832802
2019-11-05 09:05:45,108 train 850 1.909288e-02 -0.828004
2019-11-05 09:05:48,247 training loss; R2: 1.909544e-02 -0.830030
2019-11-05 09:05:48,850 valid 000 1.451443e-02 0.036453
2019-11-05 09:05:59,061 valid 050 1.495008e-02 -0.497342
2019-11-05 09:06:08,528 validation loss; R2: 1.502261e-02 -0.507637
2019-11-05 09:06:08,599 epoch 207 lr 2.000000e-04
2019-11-05 09:06:09,352 train 000 2.382596e-02 -0.460233
2019-11-05 09:06:19,709 train 050 1.903903e-02 -0.441015
2019-11-05 09:06:30,115 train 100 1.925387e-02 -0.499310
2019-11-05 09:06:40,530 train 150 1.918907e-02 -0.896118
2019-11-05 09:06:50,943 train 200 1.922650e-02 -0.799255
2019-11-05 09:07:01,305 train 250 1.911332e-02 -0.712410
2019-11-05 09:07:11,692 train 300 1.907461e-02 -0.746485
2019-11-05 09:07:22,083 train 350 1.904388e-02 -0.716146
2019-11-05 09:07:32,449 train 400 1.902041e-02 -0.674545
2019-11-05 09:07:42,813 train 450 1.905161e-02 -0.684632
2019-11-05 09:07:53,137 train 500 1.911202e-02 -0.677472
2019-11-05 09:08:03,458 train 550 1.913621e-02 -0.673687
2019-11-05 09:08:13,804 train 600 1.915237e-02 -0.677218
2019-11-05 09:08:24,117 train 650 1.913110e-02 -0.687135
2019-11-05 09:08:34,423 train 700 1.911373e-02 -0.685347
2019-11-05 09:08:44,714 train 750 1.914927e-02 -0.685881
2019-11-05 09:08:54,992 train 800 1.913273e-02 -0.668374
2019-11-05 09:09:05,245 train 850 1.913714e-02 -0.657552
2019-11-05 09:09:08,266 training loss; R2: 1.914048e-02 -0.657993
2019-11-05 09:09:08,888 valid 000 1.483794e-02 -2.146183
2019-11-05 09:09:19,225 valid 050 1.482453e-02 -0.831736
2019-11-05 09:09:28,383 validation loss; R2: 1.482762e-02 -0.950035
2019-11-05 09:09:28,464 epoch 208 lr 2.000000e-04
2019-11-05 09:09:29,146 train 000 1.774330e-02 -1.753641
2019-11-05 09:09:39,615 train 050 1.941461e-02 -0.525969
2019-11-05 09:09:50,060 train 100 1.969788e-02 -0.616317
2019-11-05 09:10:00,490 train 150 1.954169e-02 -0.756895
2019-11-05 09:10:10,865 train 200 1.948651e-02 -0.711398
2019-11-05 09:10:21,294 train 250 1.941995e-02 -0.671292
2019-11-05 09:10:31,734 train 300 1.936368e-02 -0.632284
2019-11-05 09:10:42,172 train 350 1.928572e-02 -0.640897
2019-11-05 09:10:52,629 train 400 1.928538e-02 -0.645722
2019-11-05 09:11:03,063 train 450 1.921255e-02 -0.644155
2019-11-05 09:11:13,476 train 500 1.920124e-02 -0.636283
2019-11-05 09:11:23,891 train 550 1.919260e-02 -0.685518
2019-11-05 09:11:34,255 train 600 1.915112e-02 -0.692624
2019-11-05 09:11:44,420 train 650 1.912889e-02 -0.698151
2019-11-05 09:11:54,599 train 700 1.912158e-02 -0.691527
2019-11-05 09:12:04,885 train 750 1.912342e-02 -0.800271
2019-11-05 09:12:15,152 train 800 1.911624e-02 -0.808914
2019-11-05 09:12:25,355 train 850 1.912835e-02 -0.794176
2019-11-05 09:12:28,359 training loss; R2: 1.914155e-02 -0.787444
2019-11-05 09:12:28,937 valid 000 1.353994e-02 -0.180304
2019-11-05 09:12:39,055 valid 050 1.497864e-02 -0.595887
2019-11-05 09:12:48,392 validation loss; R2: 1.476677e-02 -0.692637
2019-11-05 09:12:48,468 epoch 209 lr 2.000000e-04
2019-11-05 09:12:49,220 train 000 2.106745e-02 -0.070981
2019-11-05 09:12:59,533 train 050 1.897174e-02 -0.532511
2019-11-05 09:13:09,900 train 100 1.895506e-02 -0.553515
2019-11-05 09:13:20,196 train 150 1.891235e-02 -0.681254
2019-11-05 09:13:30,690 train 200 1.896758e-02 -0.726449
2019-11-05 09:13:41,061 train 250 1.904083e-02 -0.736349
2019-11-05 09:13:51,591 train 300 1.914351e-02 -0.727794
2019-11-05 09:14:01,982 train 350 1.916622e-02 -0.711417
2019-11-05 09:14:12,376 train 400 1.918040e-02 -0.720338
2019-11-05 09:14:22,780 train 450 1.920679e-02 -0.722459
2019-11-05 09:14:33,136 train 500 1.911518e-02 -0.725346
2019-11-05 09:14:43,643 train 550 1.911946e-02 -0.717546
2019-11-05 09:14:53,974 train 600 1.914397e-02 -0.699339
2019-11-05 09:15:04,453 train 650 1.912242e-02 -0.708510
2019-11-05 09:15:14,785 train 700 1.911084e-02 -0.700139
2019-11-05 09:15:25,126 train 750 1.910661e-02 -0.694141
2019-11-05 09:15:35,641 train 800 1.916498e-02 -0.693931
2019-11-05 09:15:46,161 train 850 1.919000e-02 -0.682766
2019-11-05 09:15:49,280 training loss; R2: 1.918186e-02 -0.677770
2019-11-05 09:15:49,911 valid 000 1.206494e-02 -0.020122
2019-11-05 09:16:00,326 valid 050 1.412641e-02 -0.823461
2019-11-05 09:16:09,494 validation loss; R2: 1.433369e-02 -0.631607
2019-11-05 09:16:09,559 epoch 210 lr 2.000000e-04
2019-11-05 09:16:10,267 train 000 1.924610e-02 -0.051204
2019-11-05 09:16:20,738 train 050 1.953345e-02 -0.867432
2019-11-05 09:16:31,091 train 100 1.965343e-02 -0.740919
2019-11-05 09:16:41,530 train 150 1.950607e-02 -0.845098
2019-11-05 09:16:52,039 train 200 1.943091e-02 -0.774510
2019-11-05 09:17:02,655 train 250 1.932531e-02 -0.732963
2019-11-05 09:17:13,218 train 300 1.929174e-02 -0.725714
