2019-11-05 09:41:05,189 gpu device = 2
2019-11-05 09:41:05,189 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=64, cutout=False, cutout_length=16, data='../data', dataset='GalaxyZoo', drop_path_prob=0.5, epochs=2000, fc1_size=2048, fc2_size=2048, gpu=2, grad_clip=5, init_channels=32, layers=8, learning_rate=0.0001, model_path='saved_models', momentum=0.9, optimizer='Adam', random=False, report_freq=50, save='eval-GalaxyZoo-Run10-C32_L08_FC2048_LR1E04_DROP50_BS64-20191105-094105', seed=0, val_portion=0.1, weight_decay=1e-06)
2019-11-05 09:41:08,630 param size = 6.272069MB
2019-11-05 09:41:08,635 epoch 0 lr 1.000000e-04
2019-11-05 09:41:11,261 train 000 4.222655e-02 -12.006182
2019-11-05 09:41:21,550 train 050 3.292575e-02 -1.717171
2019-11-05 09:41:31,970 train 100 3.159406e-02 -1.409891
2019-11-05 09:41:42,410 train 150 3.023710e-02 -1.185245
2019-11-05 09:41:52,683 train 200 2.980917e-02 -1.012320
2019-11-05 09:42:02,872 train 250 2.941398e-02 -0.926718
2019-11-05 09:42:13,053 train 300 2.899497e-02 -0.858745
2019-11-05 09:42:23,274 train 350 2.877876e-02 -0.791739
2019-11-05 09:42:33,537 train 400 2.853135e-02 -0.762263
2019-11-05 09:42:43,765 train 450 2.832073e-02 -0.719704
2019-11-05 09:42:53,994 train 500 2.817062e-02 -0.695623
2019-11-05 09:43:04,242 train 550 2.801222e-02 -0.680141
2019-11-05 09:43:14,486 train 600 2.786250e-02 -0.668579
2019-11-05 09:43:24,687 train 650 2.770721e-02 -0.654463
2019-11-05 09:43:34,931 train 700 2.758813e-02 -0.652984
2019-11-05 09:43:45,118 train 750 2.753005e-02 -0.637849
2019-11-05 09:43:55,283 train 800 2.744338e-02 -0.625372
2019-11-05 09:44:05,495 train 850 2.734353e-02 -0.614648
2019-11-05 09:44:09,318 training loss; R2: 2.733529e-02 -0.611997
2019-11-05 09:44:09,866 valid 000 2.549105e-02 -0.079441
2019-11-05 09:44:19,851 valid 050 2.733713e-02 -0.338033
2019-11-05 09:44:28,956 validation loss; R2: 2.730296e-02 -0.342469
2019-11-05 09:44:29,007 epoch 1 lr 1.000000e-04
2019-11-05 09:44:29,816 train 000 2.944921e-02 -0.637338
2019-11-05 09:44:40,063 train 050 2.598543e-02 -0.564985
2019-11-05 09:44:50,331 train 100 2.596219e-02 -0.459273
2019-11-05 09:45:00,572 train 150 2.583246e-02 -0.493619
2019-11-05 09:45:10,815 train 200 2.579670e-02 -0.518416
2019-11-05 09:45:20,998 train 250 2.569995e-02 -0.512827
2019-11-05 09:45:31,281 train 300 2.576802e-02 -0.495979
2019-11-05 09:45:41,457 train 350 2.575241e-02 -0.517255
2019-11-05 09:45:51,664 train 400 2.570339e-02 -0.512820
2019-11-05 09:46:01,843 train 450 2.563764e-02 -0.535546
2019-11-05 09:46:12,031 train 500 2.561886e-02 -0.548866
2019-11-05 09:46:22,187 train 550 2.557612e-02 -0.551930
2019-11-05 09:46:32,369 train 600 2.554344e-02 -0.539605
2019-11-05 09:46:42,550 train 650 2.551243e-02 -0.532953
2019-11-05 09:46:52,763 train 700 2.550779e-02 -0.537066
2019-11-05 09:47:02,955 train 750 2.545905e-02 -0.545524
2019-11-05 09:47:13,058 train 800 2.542059e-02 -0.549032
2019-11-05 09:47:23,158 train 850 2.541476e-02 -0.548820
2019-11-05 09:47:26,189 training loss; R2: 2.541710e-02 -0.547080
2019-11-05 09:47:26,763 valid 000 2.361820e-02 -0.606334
2019-11-05 09:47:36,800 valid 050 2.375556e-02 -1.299454
2019-11-05 09:47:45,683 validation loss; R2: 2.359416e-02 -1.034278
2019-11-05 09:47:45,754 epoch 2 lr 1.000000e-04
2019-11-05 09:47:46,495 train 000 2.663156e-02 -0.179654
2019-11-05 09:47:56,611 train 050 2.521135e-02 -0.510909
2019-11-05 09:48:06,389 train 100 2.512021e-02 -0.577488
2019-11-05 09:48:16,171 train 150 2.506723e-02 -0.550593
2019-11-05 09:48:25,955 train 200 2.494510e-02 -0.525533
2019-11-05 09:48:35,774 train 250 2.491658e-02 -0.553275
2019-11-05 09:48:45,591 train 300 2.483459e-02 -0.545142
2019-11-05 09:48:55,414 train 350 2.470533e-02 -0.537925
2019-11-05 09:49:05,237 train 400 2.461175e-02 -0.526793
2019-11-05 09:49:15,063 train 450 2.456455e-02 -0.512845
2019-11-05 09:49:24,893 train 500 2.453390e-02 -0.537857
2019-11-05 09:49:34,754 train 550 2.452565e-02 -0.528647
2019-11-05 09:49:44,655 train 600 2.445928e-02 -0.523991
2019-11-05 09:49:54,754 train 650 2.442042e-02 -0.532481
2019-11-05 09:50:05,072 train 700 2.440343e-02 -0.530275
2019-11-05 09:50:15,416 train 750 2.436022e-02 -0.516103
2019-11-05 09:50:25,781 train 800 2.428927e-02 -0.519999
2019-11-05 09:50:36,123 train 850 2.426745e-02 -0.520726
2019-11-05 09:50:39,210 training loss; R2: 2.427193e-02 -0.521070
2019-11-05 09:50:39,803 valid 000 2.392821e-02 -0.271366
2019-11-05 09:50:50,053 valid 050 2.242499e-02 -0.618400
2019-11-05 09:50:59,293 validation loss; R2: 2.252812e-02 -0.591164
2019-11-05 09:50:59,361 epoch 3 lr 1.000000e-04
2019-11-05 09:51:00,085 train 000 2.542497e-02 -0.177789
2019-11-05 09:51:10,360 train 050 2.345987e-02 -0.674916
2019-11-05 09:51:20,514 train 100 2.383007e-02 -0.535556
2019-11-05 09:51:30,735 train 150 2.378647e-02 -0.617370
2019-11-05 09:51:40,931 train 200 2.364043e-02 -0.611136
2019-11-05 09:51:51,057 train 250 2.355069e-02 -0.576810
2019-11-05 09:52:01,343 train 300 2.363136e-02 -0.899585
2019-11-05 09:52:11,537 train 350 2.368564e-02 -0.856218
2019-11-05 09:52:21,710 train 400 2.378006e-02 -0.822519
2019-11-05 09:52:31,823 train 450 2.379981e-02 -0.796841
2019-11-05 09:52:41,999 train 500 2.378906e-02 -0.753416
2019-11-05 09:52:52,058 train 550 2.375719e-02 -0.737787
2019-11-05 09:53:02,224 train 600 2.369205e-02 -0.717658
2019-11-05 09:53:12,384 train 650 2.364154e-02 -0.697381
2019-11-05 09:53:22,715 train 700 2.360738e-02 -0.700588
2019-11-05 09:53:33,075 train 750 2.357207e-02 -0.693390
2019-11-05 09:53:43,315 train 800 2.354524e-02 -0.685141
2019-11-05 09:53:53,491 train 850 2.353302e-02 -0.681866
2019-11-05 09:53:56,544 training loss; R2: 2.351795e-02 -0.677640
2019-11-05 09:53:57,090 valid 000 2.097299e-02 -0.047699
2019-11-05 09:54:07,106 valid 050 2.076672e-02 -0.556991
2019-11-05 09:54:16,049 validation loss; R2: 2.077308e-02 -0.828967
2019-11-05 09:54:16,121 epoch 4 lr 1.000000e-04
2019-11-05 09:54:16,942 train 000 2.449802e-02 -0.024940
2019-11-05 09:54:27,543 train 050 2.291055e-02 -0.379450
2019-11-05 09:54:37,903 train 100 2.318842e-02 -0.615820
2019-11-05 09:54:48,229 train 150 2.331488e-02 -0.542590
2019-11-05 09:54:58,527 train 200 2.323136e-02 -0.548741
2019-11-05 09:55:08,823 train 250 2.315597e-02 -0.553208
2019-11-05 09:55:19,128 train 300 2.307736e-02 -0.552746
2019-11-05 09:55:29,424 train 350 2.305544e-02 -0.573163
2019-11-05 09:55:39,725 train 400 2.310184e-02 -0.549994
2019-11-05 09:55:50,013 train 450 2.306322e-02 -0.564579
2019-11-05 09:56:00,311 train 500 2.304310e-02 -0.563983
2019-11-05 09:56:10,635 train 550 2.303542e-02 -0.560514
2019-11-05 09:56:20,953 train 600 2.306073e-02 -0.555512
2019-11-05 09:56:31,221 train 650 2.304872e-02 -0.559263
2019-11-05 09:56:41,523 train 700 2.300384e-02 -0.563350
2019-11-05 09:56:51,847 train 750 2.299770e-02 -0.556466
2019-11-05 09:57:02,183 train 800 2.298783e-02 -0.555406
2019-11-05 09:57:12,520 train 850 2.298341e-02 -0.552903
2019-11-05 09:57:15,592 training loss; R2: 2.296623e-02 -0.556599
2019-11-05 09:57:16,165 valid 000 1.924759e-02 -0.312563
2019-11-05 09:57:26,169 valid 050 2.068263e-02 -0.523579
2019-11-05 09:57:35,055 validation loss; R2: 2.056012e-02 -0.522378
2019-11-05 09:57:35,125 epoch 5 lr 1.000000e-04
2019-11-05 09:57:35,922 train 000 2.370569e-02 -0.055585
2019-11-05 09:57:46,279 train 050 2.257698e-02 -0.478717
2019-11-05 09:57:56,639 train 100 2.264613e-02 -0.412659
2019-11-05 09:58:06,976 train 150 2.264452e-02 -0.419884
2019-11-05 09:58:17,305 train 200 2.260698e-02 -0.433548
2019-11-05 09:58:27,640 train 250 2.260573e-02 -0.454753
2019-11-05 09:58:37,968 train 300 2.266289e-02 -0.471486
2019-11-05 09:58:48,307 train 350 2.273436e-02 -0.464718
2019-11-05 09:58:58,613 train 400 2.279921e-02 -0.449399
2019-11-05 09:59:08,899 train 450 2.273185e-02 -0.469946
2019-11-05 09:59:19,188 train 500 2.275931e-02 -0.463892
2019-11-05 09:59:29,567 train 550 2.280660e-02 -0.473497
2019-11-05 09:59:39,802 train 600 2.280724e-02 -0.486842
2019-11-05 09:59:50,095 train 650 2.278692e-02 -0.480762
2019-11-05 10:00:00,502 train 700 2.276229e-02 -0.484762
2019-11-05 10:00:10,839 train 750 2.273462e-02 -0.482141
2019-11-05 10:00:21,137 train 800 2.271587e-02 -0.501048
2019-11-05 10:00:31,447 train 850 2.268255e-02 -0.497294
2019-11-05 10:00:34,514 training loss; R2: 2.267413e-02 -0.504277
2019-11-05 10:00:35,112 valid 000 1.916744e-02 -0.007362
2019-11-05 10:00:45,419 valid 050 2.057370e-02 -1.232428
2019-11-05 10:00:54,520 validation loss; R2: 2.093600e-02 -1.126685
2019-11-05 10:00:54,591 epoch 6 lr 1.000000e-04
2019-11-05 10:00:55,333 train 000 2.050285e-02 -0.013717
2019-11-05 10:01:05,691 train 050 2.294639e-02 -0.648183
2019-11-05 10:01:15,962 train 100 2.274249e-02 -0.604277
2019-11-05 10:01:26,261 train 150 2.256036e-02 -0.628019
2019-11-05 10:01:36,512 train 200 2.258181e-02 -0.611859
2019-11-05 10:01:46,753 train 250 2.256508e-02 -0.622635
2019-11-05 10:01:57,015 train 300 2.257613e-02 -0.666563
2019-11-05 10:02:07,265 train 350 2.256181e-02 -0.664579
2019-11-05 10:02:17,522 train 400 2.248974e-02 -0.643323
2019-11-05 10:02:27,777 train 450 2.243017e-02 -0.626722
2019-11-05 10:02:38,044 train 500 2.239963e-02 -0.616523
2019-11-05 10:02:48,307 train 550 2.241658e-02 -0.626119
2019-11-05 10:02:58,443 train 600 2.238144e-02 -0.615165
2019-11-05 10:03:08,470 train 650 2.238561e-02 -0.609660
2019-11-05 10:03:18,676 train 700 2.239337e-02 -0.610201
2019-11-05 10:03:28,871 train 750 2.235941e-02 -0.609471
2019-11-05 10:03:39,135 train 800 2.236283e-02 -0.603866
2019-11-05 10:03:49,434 train 850 2.236075e-02 -0.602081
2019-11-05 10:03:52,514 training loss; R2: 2.237175e-02 -0.600374
2019-11-05 10:03:53,058 valid 000 2.053552e-02 0.018314
2019-11-05 10:04:03,135 valid 050 2.080763e-02 -0.528903
2019-11-05 10:04:12,025 validation loss; R2: 2.090347e-02 -0.625846
2019-11-05 10:04:12,093 epoch 7 lr 1.000000e-04
2019-11-05 10:04:12,771 train 000 1.975970e-02 -3.562427
2019-11-05 10:04:23,229 train 050 2.216317e-02 -0.600968
2019-11-05 10:04:33,586 train 100 2.209197e-02 -0.707819
2019-11-05 10:04:43,930 train 150 2.213157e-02 -0.585317
2019-11-05 10:04:54,308 train 200 2.223202e-02 -0.592477
2019-11-05 10:05:04,655 train 250 2.219378e-02 -0.585744
2019-11-05 10:05:15,011 train 300 2.232458e-02 -0.561388
2019-11-05 10:05:25,345 train 350 2.231233e-02 -0.531492
2019-11-05 10:05:35,685 train 400 2.226009e-02 -0.513256
2019-11-05 10:05:46,007 train 450 2.226105e-02 -0.510380
2019-11-05 10:05:56,354 train 500 2.222949e-02 -0.510995
2019-11-05 10:06:06,692 train 550 2.224938e-02 -0.509592
2019-11-05 10:06:16,916 train 600 2.217872e-02 -0.508510
2019-11-05 10:06:27,146 train 650 2.219030e-02 -0.502047
2019-11-05 10:06:37,620 train 700 2.220714e-02 -0.516257
2019-11-05 10:06:48,009 train 750 2.219946e-02 -0.524594
2019-11-05 10:06:58,354 train 800 2.219115e-02 -0.536855
2019-11-05 10:07:08,688 train 850 2.220162e-02 -0.525635
2019-11-05 10:07:11,754 training loss; R2: 2.220528e-02 -0.525273
2019-11-05 10:07:12,353 valid 000 2.358247e-02 -0.173168
2019-11-05 10:07:22,353 valid 050 2.052458e-02 -0.435596
2019-11-05 10:07:31,313 validation loss; R2: 2.055324e-02 -0.523332
2019-11-05 10:07:31,380 epoch 8 lr 1.000000e-04
2019-11-05 10:07:32,153 train 000 1.911851e-02 -0.217899
2019-11-05 10:07:42,473 train 050 2.219260e-02 -0.532614
2019-11-05 10:07:52,932 train 100 2.204907e-02 -0.437567
2019-11-05 10:08:03,324 train 150 2.212239e-02 -0.393291
2019-11-05 10:08:13,769 train 200 2.215865e-02 -0.401732
2019-11-05 10:08:24,140 train 250 2.219424e-02 -0.423735
2019-11-05 10:08:34,604 train 300 2.224546e-02 -0.450946
2019-11-05 10:08:44,983 train 350 2.219108e-02 -24.910195
2019-11-05 10:08:55,358 train 400 2.218654e-02 -21.885197
2019-11-05 10:09:05,707 train 450 2.218491e-02 -19.521864
2019-11-05 10:09:16,043 train 500 2.221227e-02 -17.611145
2019-11-05 10:09:26,387 train 550 2.220536e-02 -16.039858
2019-11-05 10:09:36,768 train 600 2.212549e-02 -14.754949
2019-11-05 10:09:47,183 train 650 2.210688e-02 -13.687560
2019-11-05 10:09:57,590 train 700 2.210245e-02 -12.743533
2019-11-05 10:10:07,978 train 750 2.212018e-02 -11.946858
2019-11-05 10:10:18,378 train 800 2.209300e-02 -11.234622
2019-11-05 10:10:28,735 train 850 2.210366e-02 -10.606038
2019-11-05 10:10:31,854 training loss; R2: 2.207902e-02 -10.432859
2019-11-05 10:10:32,498 valid 000 1.901574e-02 -0.941002
2019-11-05 10:10:42,496 valid 050 1.999585e-02 -0.206201
2019-11-05 10:10:51,588 validation loss; R2: 1.980358e-02 -0.308580
2019-11-05 10:10:51,668 epoch 9 lr 1.000000e-04
2019-11-05 10:10:52,491 train 000 2.270681e-02 -1.116633
2019-11-05 10:11:02,824 train 050 2.250524e-02 -0.419766
2019-11-05 10:11:13,154 train 100 2.235110e-02 -0.435923
2019-11-05 10:11:23,485 train 150 2.208065e-02 -0.569859
2019-11-05 10:11:33,824 train 200 2.211678e-02 -0.527946
2019-11-05 10:11:44,136 train 250 2.204360e-02 -0.510083
2019-11-05 10:11:54,550 train 300 2.200153e-02 -0.555175
2019-11-05 10:12:04,845 train 350 2.201799e-02 -0.559861
2019-11-05 10:12:15,185 train 400 2.196043e-02 -0.564375
2019-11-05 10:12:25,486 train 450 2.190772e-02 -0.574292
2019-11-05 10:12:35,839 train 500 2.193564e-02 -0.548267
2019-11-05 10:12:46,104 train 550 2.191385e-02 -0.544310
2019-11-05 10:12:56,512 train 600 2.195969e-02 -0.534791
2019-11-05 10:13:06,755 train 650 2.192292e-02 -0.536285
2019-11-05 10:13:17,024 train 700 2.194252e-02 -0.538011
2019-11-05 10:13:27,405 train 750 2.195216e-02 -0.546086
2019-11-05 10:13:37,673 train 800 2.194348e-02 -0.555091
2019-11-05 10:13:48,058 train 850 2.193408e-02 -0.546032
2019-11-05 10:13:51,112 training loss; R2: 2.193065e-02 -0.541761
2019-11-05 10:13:51,722 valid 000 2.136538e-02 -0.174472
2019-11-05 10:14:02,001 valid 050 1.922952e-02 -1.276890
2019-11-05 10:14:11,189 validation loss; R2: 1.912229e-02 -1.018188
2019-11-05 10:14:11,264 epoch 10 lr 1.000000e-04
2019-11-05 10:14:11,985 train 000 2.046672e-02 -0.160597
2019-11-05 10:14:22,416 train 050 2.166235e-02 -0.474290
2019-11-05 10:14:32,748 train 100 2.190380e-02 -0.590744
2019-11-05 10:14:43,011 train 150 2.178318e-02 -0.618406
2019-11-05 10:14:53,342 train 200 2.188216e-02 -0.597221
2019-11-05 10:15:03,631 train 250 2.182122e-02 -0.591619
2019-11-05 10:15:13,891 train 300 2.183831e-02 -0.595672
2019-11-05 10:15:24,130 train 350 2.183072e-02 -0.587220
2019-11-05 10:15:34,410 train 400 2.185055e-02 -0.573146
2019-11-05 10:15:44,706 train 450 2.186458e-02 -0.553009
2019-11-05 10:15:55,043 train 500 2.188181e-02 -0.575353
2019-11-05 10:16:05,241 train 550 2.191665e-02 -0.649148
2019-11-05 10:16:15,350 train 600 2.184383e-02 -0.645323
2019-11-05 10:16:25,360 train 650 2.181802e-02 -0.646904
2019-11-05 10:16:35,655 train 700 2.180875e-02 -0.635093
2019-11-05 10:16:45,905 train 750 2.180197e-02 -0.632212
2019-11-05 10:16:56,095 train 800 2.179493e-02 -0.614026
2019-11-05 10:17:06,404 train 850 2.180268e-02 -0.612387
2019-11-05 10:17:09,438 training loss; R2: 2.178663e-02 -0.616015
2019-11-05 10:17:09,959 valid 000 2.022949e-02 -0.986985
2019-11-05 10:17:20,031 valid 050 1.946453e-02 -1.062773
2019-11-05 10:17:28,948 validation loss; R2: 1.960182e-02 -0.860078
2019-11-05 10:17:29,032 epoch 11 lr 1.000000e-04
2019-11-05 10:17:29,809 train 000 2.458139e-02 -0.358318
2019-11-05 10:17:40,148 train 050 2.172584e-02 -0.460335
2019-11-05 10:17:50,580 train 100 2.162144e-02 -0.425083
2019-11-05 10:18:00,941 train 150 2.187256e-02 -0.448684
2019-11-05 10:18:11,347 train 200 2.195293e-02 -0.480838
2019-11-05 10:18:21,700 train 250 2.184486e-02 -0.492450
2019-11-05 10:18:32,077 train 300 2.185225e-02 -0.538154
2019-11-05 10:18:42,387 train 350 2.180759e-02 -0.536208
2019-11-05 10:18:52,714 train 400 2.175878e-02 -0.527847
2019-11-05 10:19:03,028 train 450 2.170794e-02 -0.509724
2019-11-05 10:19:13,367 train 500 2.170473e-02 -0.507624
2019-11-05 10:19:23,721 train 550 2.171269e-02 -0.529891
2019-11-05 10:19:34,023 train 600 2.168754e-02 -0.543033
2019-11-05 10:19:44,278 train 650 2.172718e-02 -0.543746
2019-11-05 10:19:54,657 train 700 2.170587e-02 -0.537438
2019-11-05 10:20:05,021 train 750 2.167638e-02 -0.546574
2019-11-05 10:20:15,381 train 800 2.167955e-02 -0.536325
2019-11-05 10:20:25,728 train 850 2.164838e-02 -0.534577
2019-11-05 10:20:28,831 training loss; R2: 2.163979e-02 -0.533917
2019-11-05 10:20:29,382 valid 000 2.091169e-02 0.005572
2019-11-05 10:20:39,482 valid 050 1.896704e-02 -0.677973
2019-11-05 10:20:48,407 validation loss; R2: 1.897973e-02 -0.707959
2019-11-05 10:20:48,480 epoch 12 lr 1.000000e-04
2019-11-05 10:20:49,236 train 000 1.855105e-02 -0.645999
2019-11-05 10:20:59,604 train 050 2.134095e-02 -0.537851
2019-11-05 10:21:10,021 train 100 2.149786e-02 -0.589340
2019-11-05 10:21:20,369 train 150 2.146976e-02 -0.588110
2019-11-05 10:21:30,728 train 200 2.158213e-02 -0.620485
2019-11-05 10:21:41,044 train 250 2.165756e-02 -0.623437
2019-11-05 10:21:51,351 train 300 2.164067e-02 -0.595514
2019-11-05 10:22:01,623 train 350 2.164960e-02 -0.561943
2019-11-05 10:22:11,912 train 400 2.163739e-02 -0.564217
2019-11-05 10:22:22,201 train 450 2.165869e-02 -0.551218
2019-11-05 10:22:32,531 train 500 2.165366e-02 -0.542689
2019-11-05 10:22:42,815 train 550 2.164769e-02 -0.554037
2019-11-05 10:22:53,171 train 600 2.164978e-02 -0.545588
2019-11-05 10:23:03,460 train 650 2.162342e-02 -0.546949
2019-11-05 10:23:13,846 train 700 2.159204e-02 -0.534573
2019-11-05 10:23:24,230 train 750 2.161233e-02 -0.547840
2019-11-05 10:23:34,643 train 800 2.163263e-02 -0.546368
2019-11-05 10:23:45,043 train 850 2.165007e-02 -0.543828
2019-11-05 10:23:48,156 training loss; R2: 2.165347e-02 -0.548313
2019-11-05 10:23:48,760 valid 000 2.434834e-02 -0.029600
2019-11-05 10:23:58,876 valid 050 2.053115e-02 -0.337960
2019-11-05 10:24:08,007 validation loss; R2: 2.044606e-02 -0.403629
2019-11-05 10:24:08,103 epoch 13 lr 1.000000e-04
2019-11-05 10:24:08,823 train 000 2.074558e-02 -0.465373
2019-11-05 10:24:19,257 train 050 2.145865e-02 -0.448489
2019-11-05 10:24:29,576 train 100 2.172459e-02 -0.530534
2019-11-05 10:24:39,899 train 150 2.182645e-02 -0.512809
2019-11-05 10:24:50,216 train 200 2.180930e-02 -0.491296
2019-11-05 10:25:00,527 train 250 2.176506e-02 -0.618860
2019-11-05 10:25:10,886 train 300 2.175808e-02 -0.632473
2019-11-05 10:25:21,206 train 350 2.171449e-02 -0.632043
2019-11-05 10:25:31,558 train 400 2.170537e-02 -0.609663
2019-11-05 10:25:41,891 train 450 2.180538e-02 -0.589534
2019-11-05 10:25:52,238 train 500 2.181220e-02 -0.632734
2019-11-05 10:26:02,534 train 550 2.182468e-02 -0.635246
2019-11-05 10:26:12,840 train 600 2.180758e-02 -0.629417
2019-11-05 10:26:23,165 train 650 2.176792e-02 -0.621857
2019-11-05 10:26:33,555 train 700 2.177313e-02 -0.631381
2019-11-05 10:26:43,928 train 750 2.179165e-02 -0.622336
2019-11-05 10:26:54,302 train 800 2.179070e-02 -0.613022
2019-11-05 10:27:04,652 train 850 2.176137e-02 -0.611313
2019-11-05 10:27:07,754 training loss; R2: 2.175504e-02 -0.610330
2019-11-05 10:27:08,369 valid 000 2.143004e-02 -0.100547
2019-11-05 10:27:18,378 valid 050 1.949072e-02 -0.399951
2019-11-05 10:27:27,667 validation loss; R2: 1.967302e-02 -0.441850
2019-11-05 10:27:27,742 epoch 14 lr 1.000000e-04
2019-11-05 10:27:28,555 train 000 2.354547e-02 -0.120393
2019-11-05 10:27:38,891 train 050 2.216675e-02 -0.595423
2019-11-05 10:27:49,168 train 100 2.193870e-02 -0.530114
2019-11-05 10:27:59,476 train 150 2.178785e-02 -0.573916
2019-11-05 10:28:09,742 train 200 2.171951e-02 -0.526989
2019-11-05 10:28:20,079 train 250 2.169407e-02 -0.535506
2019-11-05 10:28:30,340 train 300 2.174001e-02 -0.512513
2019-11-05 10:28:40,652 train 350 2.171491e-02 -0.515693
2019-11-05 10:28:50,961 train 400 2.168297e-02 -0.618737
2019-11-05 10:29:01,261 train 450 2.173917e-02 -0.596534
2019-11-05 10:29:11,583 train 500 2.175205e-02 -0.582945
2019-11-05 10:29:21,817 train 550 2.178398e-02 -0.600272
2019-11-05 10:29:32,158 train 600 2.179629e-02 -0.581378
2019-11-05 10:29:42,396 train 650 2.176551e-02 -0.571087
2019-11-05 10:29:52,748 train 700 2.175779e-02 -0.583093
2019-11-05 10:30:03,079 train 750 2.177877e-02 -0.581126
2019-11-05 10:30:13,440 train 800 2.175957e-02 -0.584303
2019-11-05 10:30:23,747 train 850 2.175766e-02 -0.589650
2019-11-05 10:30:26,830 training loss; R2: 2.176418e-02 -0.588829
2019-11-05 10:30:27,437 valid 000 1.724648e-02 -0.342876
2019-11-05 10:30:37,612 valid 050 1.922759e-02 -0.545109
2019-11-05 10:30:47,124 validation loss; R2: 1.952161e-02 -0.673865
2019-11-05 10:30:47,194 epoch 15 lr 1.000000e-04
2019-11-05 10:30:47,911 train 000 2.251635e-02 -0.143260
2019-11-05 10:30:58,413 train 050 2.174755e-02 -0.482858
2019-11-05 10:31:08,877 train 100 2.173265e-02 -0.524384
2019-11-05 10:31:19,295 train 150 2.179014e-02 -0.518443
2019-11-05 10:31:29,703 train 200 2.191344e-02 -0.502231
2019-11-05 10:31:40,098 train 250 2.178777e-02 -0.591127
2019-11-05 10:31:50,492 train 300 2.181245e-02 -0.565151
2019-11-05 10:32:00,881 train 350 2.183294e-02 -0.548748
2019-11-05 10:32:11,247 train 400 2.183088e-02 -0.587204
2019-11-05 10:32:21,638 train 450 2.181327e-02 -0.594100
2019-11-05 10:32:32,030 train 500 2.182719e-02 -0.580916
2019-11-05 10:32:42,414 train 550 2.182049e-02 -0.577517
2019-11-05 10:32:52,830 train 600 2.179340e-02 -0.582053
2019-11-05 10:33:03,238 train 650 2.178477e-02 -0.566214
2019-11-05 10:33:13,632 train 700 2.177308e-02 -0.564767
2019-11-05 10:33:23,986 train 750 2.182529e-02 -0.563498
2019-11-05 10:33:34,331 train 800 2.183634e-02 -0.557089
2019-11-05 10:33:44,680 train 850 2.181948e-02 -0.577145
2019-11-05 10:33:47,776 training loss; R2: 2.182372e-02 -0.575310
2019-11-05 10:33:48,377 valid 000 1.721521e-02 -0.005854
2019-11-05 10:33:58,592 valid 050 1.876582e-02 -0.638679
2019-11-05 10:34:07,960 validation loss; R2: 1.914210e-02 -0.539724
2019-11-05 10:34:08,039 epoch 16 lr 1.000000e-04
2019-11-05 10:34:08,832 train 000 2.791303e-02 -0.463569
2019-11-05 10:34:19,185 train 050 2.185622e-02 -0.710552
2019-11-05 10:34:29,569 train 100 2.195072e-02 -0.634286
2019-11-05 10:34:39,927 train 150 2.194869e-02 -0.593435
2019-11-05 10:34:50,239 train 200 2.199001e-02 -0.541310
2019-11-05 10:35:00,509 train 250 2.197488e-02 -0.515563
2019-11-05 10:35:10,783 train 300 2.195005e-02 -0.542713
2019-11-05 10:35:21,056 train 350 2.197967e-02 -0.529932
2019-11-05 10:35:31,393 train 400 2.194904e-02 -0.539825
2019-11-05 10:35:41,694 train 450 2.200816e-02 -0.544880
2019-11-05 10:35:52,019 train 500 2.191657e-02 -0.551903
2019-11-05 10:36:02,309 train 550 2.195039e-02 -0.555359
2019-11-05 10:36:12,624 train 600 2.187964e-02 -0.546040
2019-11-05 10:36:22,906 train 650 2.187068e-02 -0.547608
2019-11-05 10:36:33,217 train 700 2.181726e-02 -0.556131
2019-11-05 10:36:43,512 train 750 2.180143e-02 -0.543620
2019-11-05 10:36:53,811 train 800 2.179648e-02 -0.549356
2019-11-05 10:37:04,106 train 850 2.176718e-02 -0.541752
2019-11-05 10:37:07,195 training loss; R2: 2.176560e-02 -0.538035
2019-11-05 10:37:07,788 valid 000 1.606506e-02 -0.164704
2019-11-05 10:37:18,111 valid 050 1.941921e-02 -1.675664
2019-11-05 10:37:27,354 validation loss; R2: 1.932836e-02 -1.180392
2019-11-05 10:37:27,432 epoch 17 lr 1.000000e-04
2019-11-05 10:37:28,217 train 000 2.056578e-02 -0.052252
2019-11-05 10:37:38,505 train 050 2.152632e-02 -0.676397
2019-11-05 10:37:48,876 train 100 2.161802e-02 -1.836635
2019-11-05 10:37:59,145 train 150 2.165951e-02 -3.123803
2019-11-05 10:38:09,483 train 200 2.171168e-02 -2.517065
2019-11-05 10:38:19,663 train 250 2.168047e-02 -2.090289
2019-11-05 10:38:30,046 train 300 2.163336e-02 -1.861941
2019-11-05 10:38:40,295 train 350 2.172180e-02 -1.644162
2019-11-05 10:38:50,560 train 400 2.164953e-02 -1.509447
2019-11-05 10:39:00,792 train 450 2.162456e-02 -1.392436
2019-11-05 10:39:11,127 train 500 2.163954e-02 -1.295185
2019-11-05 10:39:21,339 train 550 2.161705e-02 -1.257359
2019-11-05 10:39:31,544 train 600 2.158787e-02 -1.194656
2019-11-05 10:39:41,767 train 650 2.158254e-02 -1.142956
2019-11-05 10:39:52,049 train 700 2.162277e-02 -1.094084
2019-11-05 10:40:02,305 train 750 2.162918e-02 -1.062138
2019-11-05 10:40:12,640 train 800 2.161179e-02 -1.030128
2019-11-05 10:40:22,831 train 850 2.159491e-02 -0.996089
2019-11-05 10:40:25,930 training loss; R2: 2.159241e-02 -0.991064
2019-11-05 10:40:26,538 valid 000 1.883052e-02 -2.546270
2019-11-05 10:40:36,870 valid 050 1.880218e-02 -0.711143
2019-11-05 10:40:46,005 validation loss; R2: 1.890155e-02 -1.824808
2019-11-05 10:40:46,068 epoch 18 lr 1.000000e-04
2019-11-05 10:40:46,773 train 000 2.082372e-02 -0.182150
2019-11-05 10:40:57,091 train 050 2.185243e-02 -0.408783
2019-11-05 10:41:07,637 train 100 2.162085e-02 -0.509312
2019-11-05 10:41:17,867 train 150 2.177946e-02 -0.490598
2019-11-05 10:41:28,140 train 200 2.172824e-02 -0.465537
2019-11-05 10:41:38,384 train 250 2.170799e-02 -0.528154
2019-11-05 10:41:48,640 train 300 2.167187e-02 -0.525865
2019-11-05 10:41:58,891 train 350 2.163789e-02 -0.535887
2019-11-05 10:42:09,162 train 400 2.165288e-02 -0.541236
2019-11-05 10:42:19,422 train 450 2.157615e-02 -0.553949
2019-11-05 10:42:29,676 train 500 2.154627e-02 -0.559580
2019-11-05 10:42:39,912 train 550 2.154192e-02 -0.550488
2019-11-05 10:42:50,198 train 600 2.149904e-02 -0.543328
2019-11-05 10:43:00,484 train 650 2.146646e-02 -0.555720
2019-11-05 10:43:10,762 train 700 2.143540e-02 -0.549012
2019-11-05 10:43:21,005 train 750 2.143527e-02 -0.549598
2019-11-05 10:43:31,274 train 800 2.143748e-02 -0.549191
2019-11-05 10:43:41,535 train 850 2.138545e-02 -0.555225
2019-11-05 10:43:44,617 training loss; R2: 2.139493e-02 -0.551401
2019-11-05 10:43:45,164 valid 000 1.853859e-02 -0.569620
2019-11-05 10:43:55,435 valid 050 1.909406e-02 -0.565289
2019-11-05 10:44:04,462 validation loss; R2: 1.932569e-02 -0.633398
2019-11-05 10:44:04,534 epoch 19 lr 1.000000e-04
2019-11-05 10:44:05,301 train 000 2.274826e-02 -0.325371
2019-11-05 10:44:15,583 train 050 2.111734e-02 -0.493716
2019-11-05 10:44:25,851 train 100 2.107219e-02 -0.501781
2019-11-05 10:44:36,115 train 150 2.117454e-02 -0.933328
2019-11-05 10:44:46,411 train 200 2.115054e-02 -0.815762
2019-11-05 10:44:56,642 train 250 2.120881e-02 -0.739620
2019-11-05 10:45:06,911 train 300 2.129073e-02 -0.706392
2019-11-05 10:45:17,180 train 350 2.129903e-02 -0.707733
2019-11-05 10:45:27,456 train 400 2.131111e-02 -0.680636
2019-11-05 10:45:37,759 train 450 2.127300e-02 -0.669577
2019-11-05 10:45:48,035 train 500 2.127562e-02 -0.649377
2019-11-05 10:45:58,332 train 550 2.123632e-02 -0.649225
2019-11-05 10:46:08,668 train 600 2.122527e-02 -0.652726
2019-11-05 10:46:18,916 train 650 2.122613e-02 -0.642948
2019-11-05 10:46:29,213 train 700 2.118604e-02 -0.633202
2019-11-05 10:46:39,509 train 750 2.114946e-02 -2.108890
2019-11-05 10:46:49,789 train 800 2.117477e-02 -2.030694
2019-11-05 10:47:00,095 train 850 2.118361e-02 -1.958829
2019-11-05 10:47:03,172 training loss; R2: 2.119076e-02 -1.940863
2019-11-05 10:47:03,768 valid 000 1.948424e-02 -1.054244
2019-11-05 10:47:13,847 valid 050 1.942495e-02 -0.799963
2019-11-05 10:47:22,994 validation loss; R2: 1.946260e-02 -0.749285
2019-11-05 10:47:23,064 epoch 20 lr 1.000000e-04
2019-11-05 10:47:23,855 train 000 2.369445e-02 -0.495606
2019-11-05 10:47:34,284 train 050 2.124947e-02 -0.491049
2019-11-05 10:47:44,661 train 100 2.143911e-02 -0.477824
2019-11-05 10:47:54,951 train 150 2.120602e-02 -0.529043
2019-11-05 10:48:05,344 train 200 2.130535e-02 -0.545756
2019-11-05 10:48:15,628 train 250 2.127452e-02 -0.559307
2019-11-05 10:48:26,021 train 300 2.115237e-02 -0.591201
2019-11-05 10:48:36,346 train 350 2.121084e-02 -0.563445
2019-11-05 10:48:46,652 train 400 2.114847e-02 -0.548284
2019-11-05 10:48:57,051 train 450 2.117618e-02 -0.571088
2019-11-05 10:49:07,366 train 500 2.113370e-02 -0.574262
2019-11-05 10:49:17,695 train 550 2.113310e-02 -0.560678
2019-11-05 10:49:28,045 train 600 2.110634e-02 -0.561429
2019-11-05 10:49:38,192 train 650 2.107392e-02 -0.547134
2019-11-05 10:49:48,543 train 700 2.103451e-02 -0.559570
2019-11-05 10:49:58,784 train 750 2.103393e-02 -0.553874
2019-11-05 10:50:09,168 train 800 2.102599e-02 -0.567327
2019-11-05 10:50:19,363 train 850 2.100488e-02 -0.581544
2019-11-05 10:50:22,449 training loss; R2: 2.100241e-02 -0.583998
2019-11-05 10:50:23,044 valid 000 1.924001e-02 -0.687139
2019-11-05 10:50:33,510 valid 050 1.821355e-02 -0.819389
2019-11-05 10:50:43,032 validation loss; R2: 1.837869e-02 -0.927826
2019-11-05 10:50:43,098 epoch 21 lr 1.000000e-04
2019-11-05 10:50:43,857 train 000 2.313080e-02 -0.193475
2019-11-05 10:50:54,515 train 050 2.078866e-02 -0.287460
2019-11-05 10:51:05,337 train 100 2.118192e-02 -0.363692
2019-11-05 10:51:15,946 train 150 2.111170e-02 -0.364761
2019-11-05 10:51:26,739 train 200 2.114766e-02 -0.396465
2019-11-05 10:51:37,330 train 250 2.111640e-02 -0.443667
2019-11-05 10:51:48,097 train 300 2.106782e-02 -0.473494
2019-11-05 10:51:58,747 train 350 2.102620e-02 -0.490693
2019-11-05 10:52:09,448 train 400 2.104057e-02 -0.520268
2019-11-05 10:52:20,090 train 450 2.104100e-02 -0.544074
2019-11-05 10:52:30,819 train 500 2.098338e-02 -0.536315
2019-11-05 10:52:41,507 train 550 2.096151e-02 -0.560432
2019-11-05 10:52:51,988 train 600 2.097443e-02 -0.553741
2019-11-05 10:53:02,565 train 650 2.095456e-02 -0.549179
2019-11-05 10:53:13,174 train 700 2.093082e-02 -0.561259
2019-11-05 10:53:23,824 train 750 2.092088e-02 -0.566316
2019-11-05 10:53:34,377 train 800 2.091587e-02 -0.576864
2019-11-05 10:53:45,017 train 850 2.092074e-02 -0.562112
2019-11-05 10:53:48,201 training loss; R2: 2.092337e-02 -0.559903
2019-11-05 10:53:48,809 valid 000 1.930350e-02 -5.446398
2019-11-05 10:53:58,901 valid 050 1.989022e-02 -1.123455
2019-11-05 10:54:08,108 validation loss; R2: 1.994687e-02 -1.027978
2019-11-05 10:54:08,180 epoch 22 lr 1.000000e-04
2019-11-05 10:54:08,908 train 000 1.940434e-02 -0.148801
2019-11-05 10:54:19,470 train 050 2.078026e-02 -0.611340
2019-11-05 10:54:29,900 train 100 2.110033e-02 -1.630991
2019-11-05 10:54:40,310 train 150 2.114480e-02 -1.251379
2019-11-05 10:54:50,770 train 200 2.101060e-02 -1.070382
2019-11-05 10:55:01,268 train 250 2.097051e-02 -0.947248
2019-11-05 10:55:11,796 train 300 2.101656e-02 -0.874510
2019-11-05 10:55:22,313 train 350 2.107011e-02 -0.810626
2019-11-05 10:55:32,756 train 400 2.100712e-02 -0.770931
2019-11-05 10:55:43,059 train 450 2.099040e-02 -0.733006
2019-11-05 10:55:53,415 train 500 2.096402e-02 -0.712113
2019-11-05 10:56:03,728 train 550 2.093670e-02 -0.692082
2019-11-05 10:56:14,018 train 600 2.091942e-02 -0.691650
2019-11-05 10:56:24,360 train 650 2.092551e-02 -0.685000
2019-11-05 10:56:34,718 train 700 2.088133e-02 -0.668313
2019-11-05 10:56:45,106 train 750 2.090233e-02 -0.657723
2019-11-05 10:56:55,495 train 800 2.089052e-02 -0.655786
2019-11-05 10:57:05,867 train 850 2.087465e-02 -0.662294
2019-11-05 10:57:08,945 training loss; R2: 2.087423e-02 -0.655361
2019-11-05 10:57:09,544 valid 000 1.925970e-02 -0.334777
2019-11-05 10:57:19,649 valid 050 1.859742e-02 -1.000650
2019-11-05 10:57:28,865 validation loss; R2: 1.861835e-02 -0.900209
2019-11-05 10:57:28,944 epoch 23 lr 1.000000e-04
2019-11-05 10:57:29,686 train 000 2.257676e-02 -0.359211
2019-11-05 10:57:40,106 train 050 2.081999e-02 -0.716491
2019-11-05 10:57:50,390 train 100 2.105140e-02 -0.720901
2019-11-05 10:58:00,760 train 150 2.109326e-02 -0.647686
2019-11-05 10:58:11,161 train 200 2.108474e-02 -0.591041
2019-11-05 10:58:21,420 train 250 2.104293e-02 -0.891904
2019-11-05 10:58:31,706 train 300 2.100442e-02 -0.816367
2019-11-05 10:58:42,048 train 350 2.092359e-02 -0.799405
2019-11-05 10:58:52,374 train 400 2.093485e-02 -0.775845
2019-11-05 10:59:02,713 train 450 2.083536e-02 -0.745874
2019-11-05 10:59:13,058 train 500 2.082450e-02 -0.716174
2019-11-05 10:59:23,224 train 550 2.080439e-02 -0.700620
2019-11-05 10:59:33,550 train 600 2.078278e-02 -0.689745
2019-11-05 10:59:43,830 train 650 2.078377e-02 -0.686103
2019-11-05 10:59:54,116 train 700 2.074188e-02 -0.727711
2019-11-05 11:00:04,448 train 750 2.072486e-02 -0.714049
2019-11-05 11:00:14,809 train 800 2.071779e-02 -0.713161
2019-11-05 11:00:25,025 train 850 2.072918e-02 -0.716997
2019-11-05 11:00:28,129 training loss; R2: 2.071907e-02 -0.712496
2019-11-05 11:00:28,673 valid 000 2.002764e-02 -0.679159
2019-11-05 11:00:38,972 valid 050 1.956667e-02 -0.867714
2019-11-05 11:00:48,054 validation loss; R2: 1.960372e-02 -0.801973
2019-11-05 11:00:48,129 epoch 24 lr 1.000000e-04
2019-11-05 11:00:48,868 train 000 1.746122e-02 -0.422345
2019-11-05 11:00:59,118 train 050 2.054796e-02 -0.503975
2019-11-05 11:01:09,336 train 100 2.053555e-02 -0.518482
2019-11-05 11:01:19,550 train 150 2.055171e-02 -0.501187
2019-11-05 11:01:29,635 train 200 2.061060e-02 -0.530713
2019-11-05 11:01:39,789 train 250 2.068491e-02 -0.563450
2019-11-05 11:01:50,032 train 300 2.074989e-02 -0.532124
2019-11-05 11:02:00,259 train 350 2.074622e-02 -0.532603
2019-11-05 11:02:10,442 train 400 2.074921e-02 -0.511124
2019-11-05 11:02:20,636 train 450 2.071436e-02 -0.578363
2019-11-05 11:02:30,629 train 500 2.068271e-02 -0.567459
2019-11-05 11:02:40,703 train 550 2.064297e-02 -0.565498
2019-11-05 11:02:50,878 train 600 2.059105e-02 -0.558958
2019-11-05 11:03:01,069 train 650 2.064695e-02 -0.551821
2019-11-05 11:03:11,275 train 700 2.064000e-02 -0.542830
2019-11-05 11:03:21,396 train 750 2.063644e-02 -0.540117
2019-11-05 11:03:31,587 train 800 2.063194e-02 -0.541331
2019-11-05 11:03:41,667 train 850 2.060868e-02 -0.535011
2019-11-05 11:03:44,710 training loss; R2: 2.062442e-02 -0.535019
2019-11-05 11:03:45,318 valid 000 1.674216e-02 -0.961974
2019-11-05 11:03:55,301 valid 050 1.838156e-02 -0.691585
2019-11-05 11:04:04,187 validation loss; R2: 1.855566e-02 -0.861124
2019-11-05 11:04:04,256 epoch 25 lr 1.000000e-04
2019-11-05 11:04:04,968 train 000 2.261629e-02 -1.076557
2019-11-05 11:04:15,374 train 050 2.043018e-02 -22.105603
2019-11-05 11:04:25,698 train 100 2.017855e-02 -11.620586
2019-11-05 11:04:35,978 train 150 2.020610e-02 -7.971298
2019-11-05 11:04:46,287 train 200 2.032246e-02 -6.136129
2019-11-05 11:04:56,547 train 250 2.039598e-02 -4.988857
2019-11-05 11:05:06,878 train 300 2.040657e-02 -4.238569
2019-11-05 11:05:17,174 train 350 2.040552e-02 -3.718597
2019-11-05 11:05:27,511 train 400 2.041110e-02 -3.341928
2019-11-05 11:05:37,822 train 450 2.043239e-02 -3.013565
2019-11-05 11:05:48,143 train 500 2.046099e-02 -2.758188
2019-11-05 11:05:58,456 train 550 2.046842e-02 -2.543037
2019-11-05 11:06:08,772 train 600 2.048381e-02 -2.367703
2019-11-05 11:06:19,114 train 650 2.049947e-02 -2.222936
2019-11-05 11:06:29,540 train 700 2.048546e-02 -2.101262
2019-11-05 11:06:39,897 train 750 2.044733e-02 -1.997954
2019-11-05 11:06:50,283 train 800 2.040021e-02 -1.946470
2019-11-05 11:07:00,607 train 850 2.040396e-02 -1.887068
2019-11-05 11:07:03,705 training loss; R2: 2.040777e-02 -1.859917
2019-11-05 11:07:04,240 valid 000 1.786015e-02 -5.507286
2019-11-05 11:07:14,305 valid 050 1.883206e-02 -0.664280
2019-11-05 11:07:23,175 validation loss; R2: 1.896345e-02 -0.715381
2019-11-05 11:07:23,243 epoch 26 lr 1.000000e-04
2019-11-05 11:07:23,930 train 000 2.102635e-02 -0.624899
2019-11-05 11:07:34,296 train 050 2.002549e-02 -0.550643
2019-11-05 11:07:44,660 train 100 2.014809e-02 -0.630611
2019-11-05 11:07:54,985 train 150 2.026165e-02 -0.581149
2019-11-05 11:08:05,308 train 200 2.029305e-02 -0.579449
2019-11-05 11:08:15,604 train 250 2.028312e-02 -0.561263
2019-11-05 11:08:25,974 train 300 2.030813e-02 -0.545513
2019-11-05 11:08:36,283 train 350 2.034270e-02 -0.565278
2019-11-05 11:08:46,621 train 400 2.030917e-02 -0.566599
2019-11-05 11:08:56,880 train 450 2.036916e-02 -0.587428
2019-11-05 11:09:07,175 train 500 2.036836e-02 -0.568377
2019-11-05 11:09:17,425 train 550 2.034872e-02 -0.557928
2019-11-05 11:09:27,730 train 600 2.035516e-02 -0.568508
2019-11-05 11:09:38,038 train 650 2.034025e-02 -0.574922
2019-11-05 11:09:48,417 train 700 2.033689e-02 -0.593103
2019-11-05 11:09:58,678 train 750 2.033722e-02 -0.590018
2019-11-05 11:10:09,101 train 800 2.032299e-02 -0.585664
2019-11-05 11:10:19,351 train 850 2.032672e-02 -0.579993
2019-11-05 11:10:22,445 training loss; R2: 2.031757e-02 -0.576210
2019-11-05 11:10:23,040 valid 000 1.734849e-02 0.071145
2019-11-05 11:10:33,130 valid 050 1.864765e-02 -0.904672
2019-11-05 11:10:42,290 validation loss; R2: 1.857217e-02 -0.745957
2019-11-05 11:10:42,368 epoch 27 lr 1.000000e-04
2019-11-05 11:10:43,119 train 000 1.966722e-02 -0.555273
2019-11-05 11:10:53,436 train 050 2.022333e-02 -0.608603
2019-11-05 11:11:03,815 train 100 2.024450e-02 -0.525150
2019-11-05 11:11:14,146 train 150 2.010531e-02 -0.585527
2019-11-05 11:11:24,478 train 200 2.018813e-02 -0.568067
2019-11-05 11:11:34,770 train 250 2.020829e-02 -0.606722
2019-11-05 11:11:45,099 train 300 2.021674e-02 -0.592955
2019-11-05 11:11:55,422 train 350 2.027415e-02 -0.580865
2019-11-05 11:12:05,757 train 400 2.023256e-02 -0.589085
2019-11-05 11:12:16,074 train 450 2.023603e-02 -0.571458
2019-11-05 11:12:26,507 train 500 2.025614e-02 -0.573047
2019-11-05 11:12:36,864 train 550 2.029008e-02 -0.599048
2019-11-05 11:12:47,239 train 600 2.026886e-02 -0.596104
2019-11-05 11:12:57,549 train 650 2.031366e-02 -0.587237
2019-11-05 11:13:07,879 train 700 2.033224e-02 -0.574563
2019-11-05 11:13:18,246 train 750 2.028048e-02 -0.578486
2019-11-05 11:13:28,554 train 800 2.026889e-02 -0.568927
2019-11-05 11:13:38,883 train 850 2.025771e-02 -0.567770
2019-11-05 11:13:41,975 training loss; R2: 2.026062e-02 -0.569664
2019-11-05 11:13:42,589 valid 000 2.234626e-02 -0.708103
2019-11-05 11:13:52,898 valid 050 1.919884e-02 -2.792543
2019-11-05 11:14:02,075 validation loss; R2: 1.917940e-02 -1.909817
2019-11-05 11:14:02,146 epoch 28 lr 1.000000e-04
2019-11-05 11:14:02,917 train 000 2.215720e-02 -0.088811
2019-11-05 11:14:13,275 train 050 1.997720e-02 -1.005861
2019-11-05 11:14:23,679 train 100 2.020600e-02 -0.802876
2019-11-05 11:14:34,070 train 150 2.020598e-02 -0.726909
2019-11-05 11:14:44,455 train 200 2.022899e-02 -0.633354
2019-11-05 11:14:54,766 train 250 2.016247e-02 -0.652226
2019-11-05 11:15:05,125 train 300 2.015692e-02 -0.651516
2019-11-05 11:15:15,434 train 350 2.021239e-02 -0.652885
2019-11-05 11:15:25,792 train 400 2.020241e-02 -0.733466
2019-11-05 11:15:36,134 train 450 2.019738e-02 -0.728326
2019-11-05 11:15:46,461 train 500 2.020780e-02 -0.714471
2019-11-05 11:15:56,782 train 550 2.021451e-02 -2.402982
2019-11-05 11:16:07,050 train 600 2.019268e-02 -2.243585
2019-11-05 11:16:17,325 train 650 2.018536e-02 -2.113329
2019-11-05 11:16:27,563 train 700 2.016983e-02 -2.025498
2019-11-05 11:16:37,961 train 750 2.016493e-02 -1.931551
2019-11-05 11:16:48,249 train 800 2.017142e-02 -1.847804
2019-11-05 11:16:58,505 train 850 2.015069e-02 -1.771573
2019-11-05 11:17:01,595 training loss; R2: 2.014147e-02 -1.753567
2019-11-05 11:17:02,152 valid 000 1.729104e-02 -2.287153
2019-11-05 11:17:12,602 valid 050 1.884444e-02 -0.844706
2019-11-05 11:17:21,790 validation loss; R2: 1.887726e-02 -0.804966
2019-11-05 11:17:21,857 epoch 29 lr 1.000000e-04
2019-11-05 11:17:22,598 train 000 1.761849e-02 -0.291216
2019-11-05 11:17:33,033 train 050 1.990123e-02 -0.678078
2019-11-05 11:17:43,417 train 100 1.981082e-02 -0.546191
2019-11-05 11:17:53,748 train 150 1.987677e-02 -0.576852
2019-11-05 11:18:04,071 train 200 1.993759e-02 -0.548284
2019-11-05 11:18:14,350 train 250 1.992435e-02 -0.566118
2019-11-05 11:18:24,618 train 300 1.985327e-02 -0.595300
2019-11-05 11:18:34,923 train 350 1.991680e-02 -0.603344
2019-11-05 11:18:45,259 train 400 1.993486e-02 -0.572708
2019-11-05 11:18:55,551 train 450 2.000055e-02 -0.556130
2019-11-05 11:19:05,874 train 500 2.001842e-02 -0.566366
2019-11-05 11:19:16,223 train 550 1.998092e-02 -0.570703
2019-11-05 11:19:26,518 train 600 1.999746e-02 -0.563699
2019-11-05 11:19:36,832 train 650 2.000742e-02 -0.563451
2019-11-05 11:19:47,165 train 700 2.000148e-02 -0.572288
2019-11-05 11:19:57,472 train 750 2.002340e-02 -0.603367
2019-11-05 11:20:07,815 train 800 2.002932e-02 -0.596164
2019-11-05 11:20:18,142 train 850 2.004234e-02 -0.594588
2019-11-05 11:20:21,211 training loss; R2: 2.004314e-02 -0.592479
2019-11-05 11:20:21,761 valid 000 1.541899e-02 -0.414115
2019-11-05 11:20:32,204 valid 050 1.837002e-02 -0.756092
2019-11-05 11:20:41,419 validation loss; R2: 1.816310e-02 -0.745946
2019-11-05 11:20:41,490 epoch 30 lr 1.000000e-04
2019-11-05 11:20:42,280 train 000 1.643301e-02 -0.067516
2019-11-05 11:20:52,674 train 050 2.016809e-02 -0.506169
2019-11-05 11:21:03,056 train 100 2.022104e-02 -0.572957
2019-11-05 11:21:13,387 train 150 2.028678e-02 -0.596909
2019-11-05 11:21:23,681 train 200 2.014395e-02 -0.620874
2019-11-05 11:21:33,974 train 250 2.024324e-02 -0.612718
2019-11-05 11:21:44,259 train 300 2.018971e-02 -0.588266
2019-11-05 11:21:54,569 train 350 2.017787e-02 -0.562238
2019-11-05 11:22:04,904 train 400 2.013789e-02 -0.575871
2019-11-05 11:22:15,240 train 450 2.007172e-02 -0.589944
2019-11-05 11:22:25,580 train 500 2.004679e-02 -0.599905
2019-11-05 11:22:35,940 train 550 1.999980e-02 -0.597325
2019-11-05 11:22:46,258 train 600 1.999328e-02 -0.598095
2019-11-05 11:22:56,560 train 650 2.000241e-02 -0.596067
2019-11-05 11:23:06,903 train 700 1.997804e-02 -0.593573
2019-11-05 11:23:17,223 train 750 1.998440e-02 -0.596585
2019-11-05 11:23:27,511 train 800 1.998271e-02 -0.607886
2019-11-05 11:23:37,763 train 850 1.999792e-02 -0.616544
2019-11-05 11:23:40,840 training loss; R2: 1.999511e-02 -0.618097
2019-11-05 11:23:41,408 valid 000 1.784476e-02 -0.310621
2019-11-05 11:23:51,671 valid 050 1.843019e-02 -1.502918
2019-11-05 11:24:01,025 validation loss; R2: 1.834375e-02 -1.150932
2019-11-05 11:24:01,098 epoch 31 lr 1.000000e-04
2019-11-05 11:24:01,844 train 000 1.858611e-02 -0.870986
2019-11-05 11:24:12,246 train 050 1.961724e-02 -0.586179
2019-11-05 11:24:22,614 train 100 1.987033e-02 -0.675691
2019-11-05 11:24:32,912 train 150 1.988944e-02 -0.741640
2019-11-05 11:24:43,280 train 200 1.984830e-02 -0.720374
2019-11-05 11:24:53,598 train 250 1.980526e-02 -0.713088
2019-11-05 11:25:03,942 train 300 1.987486e-02 -0.777851
2019-11-05 11:25:14,254 train 350 1.987087e-02 -0.731645
2019-11-05 11:25:24,563 train 400 1.987444e-02 -0.712515
2019-11-05 11:25:34,827 train 450 1.989652e-02 -0.703997
2019-11-05 11:25:45,146 train 500 1.986491e-02 -0.680041
2019-11-05 11:25:55,459 train 550 1.987456e-02 -0.686313
2019-11-05 11:26:05,783 train 600 1.987516e-02 -0.679245
2019-11-05 11:26:16,172 train 650 1.987436e-02 -0.663944
2019-11-05 11:26:26,530 train 700 1.989302e-02 -0.648854
2019-11-05 11:26:36,851 train 750 1.991521e-02 -0.642819
2019-11-05 11:26:47,187 train 800 1.990624e-02 -0.645660
2019-11-05 11:26:57,562 train 850 1.988960e-02 -0.654081
2019-11-05 11:27:00,645 training loss; R2: 1.988878e-02 -0.650970
2019-11-05 11:27:01,240 valid 000 1.770299e-02 0.054596
2019-11-05 11:27:11,434 valid 050 1.775102e-02 -0.605557
2019-11-05 11:27:20,709 validation loss; R2: 1.774406e-02 -0.812086
2019-11-05 11:27:20,780 epoch 32 lr 1.000000e-04
2019-11-05 11:27:21,514 train 000 2.032531e-02 -0.409007
2019-11-05 11:27:31,878 train 050 1.958854e-02 -0.469515
2019-11-05 11:27:42,185 train 100 1.947843e-02 -0.481296
2019-11-05 11:27:52,553 train 150 1.951127e-02 -0.461410
2019-11-05 11:28:02,821 train 200 1.950604e-02 -0.475275
2019-11-05 11:28:13,183 train 250 1.952308e-02 -0.543371
2019-11-05 11:28:23,483 train 300 1.954717e-02 -0.577236
2019-11-05 11:28:33,752 train 350 1.966207e-02 -0.564066
2019-11-05 11:28:44,134 train 400 1.974003e-02 -0.596975
2019-11-05 11:28:54,441 train 450 1.976464e-02 -0.587502
2019-11-05 11:29:04,729 train 500 1.977859e-02 -0.598595
2019-11-05 11:29:15,041 train 550 1.978246e-02 -1.139983
2019-11-05 11:29:25,260 train 600 1.974378e-02 -1.107738
2019-11-05 11:29:35,510 train 650 1.973462e-02 -1.072350
2019-11-05 11:29:45,776 train 700 1.976568e-02 -1.032524
2019-11-05 11:29:56,112 train 750 1.977994e-02 -0.996624
2019-11-05 11:30:06,532 train 800 1.978414e-02 -0.960274
2019-11-05 11:30:16,774 train 850 1.978903e-02 -0.941399
2019-11-05 11:30:19,832 training loss; R2: 1.978898e-02 -0.942283
2019-11-05 11:30:20,439 valid 000 1.510543e-02 -0.622094
2019-11-05 11:30:30,743 valid 050 1.757492e-02 -0.529214
2019-11-05 11:30:39,922 validation loss; R2: 1.777281e-02 -0.632288
2019-11-05 11:30:39,998 epoch 33 lr 1.000000e-04
2019-11-05 11:30:40,727 train 000 1.903485e-02 -3.570027
2019-11-05 11:30:51,076 train 050 1.942099e-02 -0.607698
2019-11-05 11:31:01,302 train 100 1.946156e-02 -0.584493
2019-11-05 11:31:11,466 train 150 1.971105e-02 -0.569732
2019-11-05 11:31:21,677 train 200 1.970272e-02 -0.561913
2019-11-05 11:31:31,836 train 250 1.972417e-02 -0.553385
2019-11-05 11:31:42,055 train 300 1.982524e-02 -0.551211
2019-11-05 11:31:52,214 train 350 1.978444e-02 -0.553426
2019-11-05 11:32:02,424 train 400 1.974770e-02 -0.560236
2019-11-05 11:32:12,600 train 450 1.983451e-02 -0.571591
2019-11-05 11:32:22,775 train 500 1.985737e-02 -0.550274
2019-11-05 11:32:32,948 train 550 1.981922e-02 -0.548787
2019-11-05 11:32:43,119 train 600 1.980900e-02 -0.553983
2019-11-05 11:32:53,284 train 650 1.980671e-02 -0.568326
2019-11-05 11:33:03,516 train 700 1.977280e-02 -0.569828
2019-11-05 11:33:13,722 train 750 1.977180e-02 -0.570993
2019-11-05 11:33:23,953 train 800 1.974870e-02 -0.579835
2019-11-05 11:33:34,140 train 850 1.975067e-02 -0.590746
2019-11-05 11:33:37,205 training loss; R2: 1.973504e-02 -0.586741
2019-11-05 11:33:37,722 valid 000 2.090400e-02 -0.634333
2019-11-05 11:33:47,736 valid 050 1.929069e-02 -1.229335
2019-11-05 11:33:56,657 validation loss; R2: 1.905242e-02 -1.271936
2019-11-05 11:33:56,727 epoch 34 lr 1.000000e-04
2019-11-05 11:33:57,477 train 000 1.744667e-02 -0.036320
2019-11-05 11:34:07,887 train 050 1.973173e-02 -0.878815
2019-11-05 11:34:18,285 train 100 1.960493e-02 -0.713656
2019-11-05 11:34:28,621 train 150 1.965531e-02 -0.678001
2019-11-05 11:34:38,997 train 200 1.964509e-02 -0.730399
2019-11-05 11:34:49,348 train 250 1.960485e-02 -0.696009
2019-11-05 11:34:59,738 train 300 1.958498e-02 -0.700043
2019-11-05 11:35:10,118 train 350 1.950856e-02 -0.668140
2019-11-05 11:35:20,473 train 400 1.955458e-02 -0.666969
2019-11-05 11:35:30,812 train 450 1.952249e-02 -0.686593
2019-11-05 11:35:41,181 train 500 1.955161e-02 -0.669981
2019-11-05 11:35:51,536 train 550 1.956120e-02 -0.684849
2019-11-05 11:36:01,768 train 600 1.957200e-02 -0.678353
2019-11-05 11:36:12,047 train 650 1.955770e-02 -0.690695
2019-11-05 11:36:22,547 train 700 1.955848e-02 -0.680119
2019-11-05 11:36:32,893 train 750 1.956126e-02 -0.677134
2019-11-05 11:36:43,257 train 800 1.954996e-02 -0.665603
2019-11-05 11:36:53,550 train 850 1.956948e-02 -0.658996
2019-11-05 11:36:56,631 training loss; R2: 1.958544e-02 -0.652859
2019-11-05 11:36:57,182 valid 000 2.071729e-02 -5.823019
2019-11-05 11:37:07,209 valid 050 1.850640e-02 -0.957202
2019-11-05 11:37:16,112 validation loss; R2: 1.889877e-02 -0.973713
2019-11-05 11:37:16,183 epoch 35 lr 1.000000e-04
2019-11-05 11:37:16,941 train 000 2.033847e-02 -0.480780
2019-11-05 11:37:27,302 train 050 1.959258e-02 -0.656067
2019-11-05 11:37:37,729 train 100 1.946583e-02 -1.357394
2019-11-05 11:37:48,109 train 150 1.953274e-02 -1.123447
2019-11-05 11:37:58,511 train 200 1.942838e-02 -1.061320
2019-11-05 11:38:08,896 train 250 1.945781e-02 -0.944844
2019-11-05 11:38:19,297 train 300 1.949474e-02 -0.864602
2019-11-05 11:38:29,635 train 350 1.952508e-02 -0.830581
2019-11-05 11:38:39,990 train 400 1.957306e-02 -0.853257
2019-11-05 11:38:50,287 train 450 1.956672e-02 -0.827226
2019-11-05 11:39:00,647 train 500 1.962381e-02 -0.791944
2019-11-05 11:39:10,980 train 550 1.961941e-02 -0.779821
2019-11-05 11:39:21,234 train 600 1.964741e-02 -0.767540
2019-11-05 11:39:31,493 train 650 1.962360e-02 -0.750180
2019-11-05 11:39:41,902 train 700 1.959809e-02 -0.739508
2019-11-05 11:39:52,294 train 750 1.955450e-02 -0.734453
2019-11-05 11:40:02,694 train 800 1.952118e-02 -0.720667
2019-11-05 11:40:13,082 train 850 1.952745e-02 -0.721121
2019-11-05 11:40:16,182 training loss; R2: 1.952455e-02 -0.717401
2019-11-05 11:40:16,784 valid 000 1.759022e-02 0.018006
2019-11-05 11:40:26,841 valid 050 1.754275e-02 -0.782477
2019-11-05 11:40:35,977 validation loss; R2: 1.761567e-02 -0.774677
2019-11-05 11:40:36,059 epoch 36 lr 1.000000e-04
2019-11-05 11:40:36,808 train 000 1.947998e-02 -2.510171
2019-11-05 11:40:47,169 train 050 1.932047e-02 -0.687508
2019-11-05 11:40:57,502 train 100 1.933296e-02 -0.694421
2019-11-05 11:41:07,782 train 150 1.940925e-02 -0.779112
2019-11-05 11:41:18,063 train 200 1.941763e-02 -0.743611
2019-11-05 11:41:28,314 train 250 1.943716e-02 -0.718969
2019-11-05 11:41:38,634 train 300 1.943422e-02 -0.769030
2019-11-05 11:41:48,946 train 350 1.949292e-02 -0.780619
2019-11-05 11:41:59,277 train 400 1.945530e-02 -0.779448
2019-11-05 11:42:09,543 train 450 1.943698e-02 -0.749871
2019-11-05 11:42:19,798 train 500 1.943438e-02 -0.750495
2019-11-05 11:42:30,119 train 550 1.944125e-02 -0.734017
2019-11-05 11:42:40,411 train 600 1.946865e-02 -0.720290
2019-11-05 11:42:50,745 train 650 1.944507e-02 -0.706955
2019-11-05 11:43:00,978 train 700 1.943393e-02 -0.738008
2019-11-05 11:43:11,316 train 750 1.942764e-02 -0.726713
2019-11-05 11:43:21,702 train 800 1.943374e-02 -0.718325
2019-11-05 11:43:31,949 train 850 1.942697e-02 -0.707241
2019-11-05 11:43:35,028 training loss; R2: 1.942520e-02 -0.707970
2019-11-05 11:43:35,582 valid 000 1.545419e-02 -1.851863
2019-11-05 11:43:45,798 valid 050 1.742669e-02 -0.739803
2019-11-05 11:43:54,985 validation loss; R2: 1.757845e-02 -0.989093
2019-11-05 11:43:55,062 epoch 37 lr 1.000000e-04
2019-11-05 11:43:55,860 train 000 1.822014e-02 -1.290374
2019-11-05 11:44:06,343 train 050 2.003918e-02 -0.409772
2019-11-05 11:44:16,825 train 100 1.967187e-02 -0.509782
2019-11-05 11:44:27,238 train 150 1.956080e-02 -0.558311
2019-11-05 11:44:37,689 train 200 1.949597e-02 -0.523186
2019-11-05 11:44:48,108 train 250 1.943695e-02 -0.554537
2019-11-05 11:44:58,557 train 300 1.942938e-02 -0.563204
2019-11-05 11:45:08,934 train 350 1.938891e-02 -0.652235
2019-11-05 11:45:19,323 train 400 1.935602e-02 -0.672329
2019-11-05 11:45:29,690 train 450 1.935536e-02 -0.673053
2019-11-05 11:45:40,083 train 500 1.933672e-02 -0.681206
2019-11-05 11:45:50,435 train 550 1.935133e-02 -0.686474
2019-11-05 11:46:00,790 train 600 1.935801e-02 -0.665356
2019-11-05 11:46:11,053 train 650 1.932680e-02 -0.671271
2019-11-05 11:46:21,386 train 700 1.932247e-02 -0.668984
2019-11-05 11:46:31,664 train 750 1.933140e-02 -3.993792
2019-11-05 11:46:41,986 train 800 1.934411e-02 -3.788629
2019-11-05 11:46:52,295 train 850 1.936451e-02 -3.599661
2019-11-05 11:46:55,366 training loss; R2: 1.935579e-02 -3.552581
2019-11-05 11:46:55,918 valid 000 1.711080e-02 -5.308245
2019-11-05 11:47:06,369 valid 050 1.804729e-02 -2.695092
2019-11-05 11:47:15,631 validation loss; R2: 1.810422e-02 -1.850790
2019-11-05 11:47:15,696 epoch 38 lr 1.000000e-04
2019-11-05 11:47:16,439 train 000 2.136874e-02 0.030696
2019-11-05 11:47:26,802 train 050 1.907644e-02 -1.140577
2019-11-05 11:47:37,103 train 100 1.897437e-02 -0.850657
2019-11-05 11:47:47,352 train 150 1.899605e-02 -0.725233
2019-11-05 11:47:57,757 train 200 1.922084e-02 -0.780973
2019-11-05 11:48:08,066 train 250 1.932895e-02 -0.727183
2019-11-05 11:48:18,358 train 300 1.928760e-02 -0.771854
2019-11-05 11:48:28,631 train 350 1.926212e-02 -0.760640
2019-11-05 11:48:38,926 train 400 1.930184e-02 -0.724130
2019-11-05 11:48:49,241 train 450 1.932764e-02 -0.716483
2019-11-05 11:48:59,572 train 500 1.932765e-02 -0.733249
2019-11-05 11:49:09,793 train 550 1.932801e-02 -0.729659
2019-11-05 11:49:20,052 train 600 1.932597e-02 -0.710958
2019-11-05 11:49:30,295 train 650 1.935227e-02 -0.709065
2019-11-05 11:49:40,552 train 700 1.936064e-02 -0.710234
2019-11-05 11:49:50,873 train 750 1.936754e-02 -0.689107
2019-11-05 11:50:01,161 train 800 1.937641e-02 -0.698004
2019-11-05 11:50:11,427 train 850 1.938252e-02 -0.686287
2019-11-05 11:50:14,504 training loss; R2: 1.937837e-02 -0.682741
2019-11-05 11:50:15,103 valid 000 2.191589e-02 -0.109772
2019-11-05 11:50:25,532 valid 050 1.794474e-02 -0.745088
2019-11-05 11:50:34,716 validation loss; R2: 1.789906e-02 -0.930398
2019-11-05 11:50:34,769 epoch 39 lr 1.000000e-04
2019-11-05 11:50:35,496 train 000 1.633052e-02 0.007078
2019-11-05 11:50:45,904 train 050 1.901268e-02 -0.805091
2019-11-05 11:50:56,159 train 100 1.926659e-02 -0.691990
2019-11-05 11:51:06,358 train 150 1.935648e-02 -0.613311
2019-11-05 11:51:16,541 train 200 1.927890e-02 -0.629502
2019-11-05 11:51:26,714 train 250 1.920490e-02 -0.619601
2019-11-05 11:51:36,840 train 300 1.919971e-02 -0.608832
2019-11-05 11:51:47,011 train 350 1.918750e-02 -0.628222
2019-11-05 11:51:57,208 train 400 1.918466e-02 -0.633668
2019-11-05 11:52:07,410 train 450 1.914636e-02 -0.631363
2019-11-05 11:52:17,615 train 500 1.915686e-02 -0.645610
2019-11-05 11:52:27,778 train 550 1.919034e-02 -0.639958
2019-11-05 11:52:38,011 train 600 1.920988e-02 -0.622860
2019-11-05 11:52:48,222 train 650 1.921098e-02 -0.609810
2019-11-05 11:52:58,409 train 700 1.918387e-02 -0.614240
2019-11-05 11:53:08,616 train 750 1.925164e-02 -0.602287
2019-11-05 11:53:18,872 train 800 1.926440e-02 -0.600845
2019-11-05 11:53:29,079 train 850 1.924361e-02 -0.600667
2019-11-05 11:53:32,137 training loss; R2: 1.924882e-02 -0.616791
2019-11-05 11:53:32,663 valid 000 1.700876e-02 0.090782
2019-11-05 11:53:42,703 valid 050 1.732410e-02 -0.852464
2019-11-05 11:53:51,507 validation loss; R2: 1.726836e-02 -1.895750
2019-11-05 11:53:51,577 epoch 40 lr 1.000000e-04
2019-11-05 11:53:52,324 train 000 2.129803e-02 -0.008886
2019-11-05 11:54:02,587 train 050 1.913559e-02 -0.904370
2019-11-05 11:54:12,896 train 100 1.918759e-02 -0.746492
2019-11-05 11:54:23,125 train 150 1.917836e-02 -0.672328
2019-11-05 11:54:33,315 train 200 1.925781e-02 -0.652161
2019-11-05 11:54:43,466 train 250 1.928045e-02 -0.644268
2019-11-05 11:54:53,644 train 300 1.927657e-02 -0.614372
2019-11-05 11:55:03,785 train 350 1.920341e-02 -0.617143
2019-11-05 11:55:13,983 train 400 1.917999e-02 -0.633002
2019-11-05 11:55:24,196 train 450 1.916960e-02 -0.644931
2019-11-05 11:55:34,398 train 500 1.919715e-02 -0.660303
2019-11-05 11:55:44,580 train 550 1.921727e-02 -0.659881
2019-11-05 11:55:54,766 train 600 1.924467e-02 -0.634544
2019-11-05 11:56:04,954 train 650 1.922927e-02 -0.627417
2019-11-05 11:56:15,151 train 700 1.923477e-02 -0.638137
2019-11-05 11:56:25,352 train 750 1.925640e-02 -0.668682
2019-11-05 11:56:35,564 train 800 1.923090e-02 -0.655284
2019-11-05 11:56:45,748 train 850 1.923568e-02 -0.645080
2019-11-05 11:56:48,787 training loss; R2: 1.923871e-02 -0.643460
2019-11-05 11:56:49,375 valid 000 1.624006e-02 -0.000828
2019-11-05 11:56:59,327 valid 050 1.861304e-02 -1.684994
2019-11-05 11:57:08,245 validation loss; R2: 1.833485e-02 -1.612310
2019-11-05 11:57:08,306 epoch 41 lr 1.000000e-04
2019-11-05 11:57:09,026 train 000 1.735405e-02 -0.487549
2019-11-05 11:57:19,400 train 050 1.854522e-02 -0.550592
2019-11-05 11:57:29,661 train 100 1.879813e-02 -0.815850
2019-11-05 11:57:39,980 train 150 1.895742e-02 -0.749486
2019-11-05 11:57:50,315 train 200 1.894779e-02 -0.758556
2019-11-05 11:58:00,645 train 250 1.902693e-02 -0.751243
2019-11-05 11:58:11,000 train 300 1.896235e-02 -0.709758
2019-11-05 11:58:21,377 train 350 1.900492e-02 -0.670114
2019-11-05 11:58:31,764 train 400 1.907613e-02 -0.661937
2019-11-05 11:58:42,116 train 450 1.909111e-02 -0.733202
2019-11-05 11:58:52,480 train 500 1.906228e-02 -0.730198
2019-11-05 11:59:02,784 train 550 1.906372e-02 -0.699907
2019-11-05 11:59:13,101 train 600 1.907564e-02 -0.685658
2019-11-05 11:59:23,307 train 650 1.908052e-02 -0.703621
2019-11-05 11:59:33,547 train 700 1.910039e-02 -0.681863
2019-11-05 11:59:43,894 train 750 1.910532e-02 -0.696759
2019-11-05 11:59:54,196 train 800 1.910100e-02 -0.705631
2019-11-05 12:00:04,540 train 850 1.913142e-02 -0.699325
2019-11-05 12:00:07,625 training loss; R2: 1.913336e-02 -0.690154
2019-11-05 12:00:08,192 valid 000 1.716264e-02 -5.336457
2019-11-05 12:00:18,167 valid 050 1.700495e-02 -1.080223
2019-11-05 12:00:27,000 validation loss; R2: 1.723165e-02 -0.982792
2019-11-05 12:00:27,065 epoch 42 lr 1.000000e-04
2019-11-05 12:00:27,771 train 000 2.109897e-02 -0.264724
2019-11-05 12:00:38,175 train 050 1.899340e-02 -0.407434
2019-11-05 12:00:48,552 train 100 1.915821e-02 -0.614635
2019-11-05 12:00:58,852 train 150 1.928227e-02 -0.659786
2019-11-05 12:01:09,221 train 200 1.923425e-02 -0.617613
2019-11-05 12:01:19,555 train 250 1.918457e-02 -0.622723
2019-11-05 12:01:29,861 train 300 1.917930e-02 -0.624159
2019-11-05 12:01:40,191 train 350 1.915252e-02 -0.601848
2019-11-05 12:01:50,550 train 400 1.916138e-02 -0.583213
2019-11-05 12:02:00,861 train 450 1.912199e-02 -0.595648
2019-11-05 12:02:11,184 train 500 1.914527e-02 -0.596623
2019-11-05 12:02:21,526 train 550 1.912087e-02 -0.593076
2019-11-05 12:02:31,867 train 600 1.910001e-02 -0.602868
2019-11-05 12:02:42,191 train 650 1.910989e-02 -0.600262
2019-11-05 12:02:52,459 train 700 1.908379e-02 -0.604690
2019-11-05 12:03:02,800 train 750 1.907505e-02 -0.595774
2019-11-05 12:03:13,139 train 800 1.905655e-02 -0.626173
2019-11-05 12:03:23,534 train 850 1.909206e-02 -0.618264
2019-11-05 12:03:26,643 training loss; R2: 1.908902e-02 -0.619534
2019-11-05 12:03:27,243 valid 000 1.921795e-02 -0.761627
2019-11-05 12:03:37,586 valid 050 1.721843e-02 -1.099815
2019-11-05 12:03:46,631 validation loss; R2: 1.746436e-02 -0.896763
2019-11-05 12:03:46,704 epoch 43 lr 1.000000e-04
2019-11-05 12:03:47,500 train 000 1.899005e-02 -0.050681
2019-11-05 12:03:57,886 train 050 1.919349e-02 -0.612821
2019-11-05 12:04:08,227 train 100 1.891415e-02 -1.114345
2019-11-05 12:04:18,559 train 150 1.882414e-02 -0.932717
2019-11-05 12:04:28,948 train 200 1.896997e-02 -2.315583
2019-11-05 12:04:39,289 train 250 1.897934e-02 -1.938072
2019-11-05 12:04:49,600 train 300 1.899899e-02 -1.722876
2019-11-05 12:04:59,928 train 350 1.898638e-02 -1.657036
2019-11-05 12:05:10,246 train 400 1.898575e-02 -1.556031
2019-11-05 12:05:20,557 train 450 1.899188e-02 -1.466787
2019-11-05 12:05:30,828 train 500 1.898776e-02 -1.396816
2019-11-05 12:05:41,132 train 550 1.899494e-02 -1.339138
2019-11-05 12:05:51,400 train 600 1.902478e-02 -1.273979
2019-11-05 12:06:01,765 train 650 1.901678e-02 -1.220278
2019-11-05 12:06:12,026 train 700 1.902901e-02 -1.173884
2019-11-05 12:06:22,307 train 750 1.902243e-02 -1.118808
2019-11-05 12:06:32,579 train 800 1.901468e-02 -1.075285
2019-11-05 12:06:42,916 train 850 1.898606e-02 -1.055366
2019-11-05 12:06:46,029 training loss; R2: 1.897818e-02 -1.047204
2019-11-05 12:06:46,579 valid 000 1.494875e-02 -3.853779
2019-11-05 12:06:56,964 valid 050 1.637738e-02 -0.797394
2019-11-05 12:07:06,443 validation loss; R2: 1.654126e-02 -0.864649
2019-11-05 12:07:06,513 epoch 44 lr 1.000000e-04
2019-11-05 12:07:07,280 train 000 2.042160e-02 -0.131926
2019-11-05 12:07:17,645 train 050 1.904166e-02 -0.744669
2019-11-05 12:07:27,955 train 100 1.894242e-02 -0.706533
2019-11-05 12:07:38,231 train 150 1.910681e-02 -0.659786
2019-11-05 12:07:48,527 train 200 1.900295e-02 -0.656717
2019-11-05 12:07:58,791 train 250 1.907487e-02 -0.704625
2019-11-05 12:08:09,056 train 300 1.909150e-02 -0.692685
2019-11-05 12:08:19,323 train 350 1.907396e-02 -0.724667
2019-11-05 12:08:29,646 train 400 1.909645e-02 -0.686482
2019-11-05 12:08:39,970 train 450 1.906318e-02 -0.678024
2019-11-05 12:08:50,289 train 500 1.904629e-02 -0.661818
2019-11-05 12:09:00,613 train 550 1.903752e-02 -0.663581
2019-11-05 12:09:10,994 train 600 1.901791e-02 -0.662041
2019-11-05 12:09:21,298 train 650 1.901659e-02 -0.643863
2019-11-05 12:09:31,625 train 700 1.903222e-02 -0.647617
2019-11-05 12:09:41,912 train 750 1.903275e-02 -0.642125
2019-11-05 12:09:52,280 train 800 1.903705e-02 -0.642572
2019-11-05 12:10:02,606 train 850 1.902007e-02 -0.686778
2019-11-05 12:10:05,704 training loss; R2: 1.902404e-02 -0.689085
2019-11-05 12:10:06,252 valid 000 1.708719e-02 -1.125964
2019-11-05 12:10:16,640 valid 050 1.716568e-02 -0.843580
2019-11-05 12:10:25,892 validation loss; R2: 1.711526e-02 -0.900186
2019-11-05 12:10:25,962 epoch 45 lr 1.000000e-04
2019-11-05 12:10:26,707 train 000 1.696132e-02 0.016734
2019-11-05 12:10:36,992 train 050 1.915612e-02 -0.609956
2019-11-05 12:10:47,390 train 100 1.909439e-02 -0.634562
2019-11-05 12:10:57,698 train 150 1.915011e-02 -0.658933
2019-11-05 12:11:07,981 train 200 1.910970e-02 -0.639139
2019-11-05 12:11:18,338 train 250 1.901535e-02 -0.606674
2019-11-05 12:11:28,675 train 300 1.911522e-02 -0.655947
2019-11-05 12:11:38,919 train 350 1.909300e-02 -0.642672
2019-11-05 12:11:49,250 train 400 1.906448e-02 -0.686187
2019-11-05 12:11:59,509 train 450 1.902513e-02 -0.704581
2019-11-05 12:12:09,855 train 500 1.903328e-02 -0.684746
2019-11-05 12:12:20,150 train 550 1.901302e-02 -0.680518
2019-11-05 12:12:30,457 train 600 1.901375e-02 -0.674061
2019-11-05 12:12:40,695 train 650 1.900228e-02 -0.665151
2019-11-05 12:12:50,979 train 700 1.900024e-02 -0.662366
2019-11-05 12:13:01,213 train 750 1.899240e-02 -0.662763
2019-11-05 12:13:11,452 train 800 1.898902e-02 -0.674822
2019-11-05 12:13:21,694 train 850 1.897399e-02 -0.682570
2019-11-05 12:13:24,769 training loss; R2: 1.896704e-02 -0.680459
2019-11-05 12:13:25,320 valid 000 1.654721e-02 -0.201049
2019-11-05 12:13:35,769 valid 050 1.789814e-02 -1.000657
2019-11-05 12:13:44,985 validation loss; R2: 1.794023e-02 -1.256116
2019-11-05 12:13:45,052 epoch 46 lr 1.000000e-04
2019-11-05 12:13:45,861 train 000 1.757545e-02 -1.491816
2019-11-05 12:13:56,164 train 050 1.898264e-02 -0.599718
2019-11-05 12:14:06,487 train 100 1.912796e-02 -0.552962
2019-11-05 12:14:16,790 train 150 1.916573e-02 -0.597363
2019-11-05 12:14:27,167 train 200 1.915860e-02 -0.622086
2019-11-05 12:14:37,524 train 250 1.911645e-02 -0.684730
2019-11-05 12:14:47,901 train 300 1.902691e-02 -0.751456
2019-11-05 12:14:58,252 train 350 1.906022e-02 -0.802892
2019-11-05 12:15:08,611 train 400 1.901051e-02 -0.746250
2019-11-05 12:15:18,923 train 450 1.897572e-02 -0.744355
2019-11-05 12:15:29,241 train 500 1.898198e-02 -0.721704
2019-11-05 12:15:39,542 train 550 1.899597e-02 -0.750309
2019-11-05 12:15:49,895 train 600 1.897752e-02 -0.735197
2019-11-05 12:16:00,172 train 650 1.900459e-02 -0.737305
2019-11-05 12:16:10,494 train 700 1.896202e-02 -0.730042
2019-11-05 12:16:20,799 train 750 1.894556e-02 -0.722016
2019-11-05 12:16:31,107 train 800 1.889666e-02 -0.725506
2019-11-05 12:16:41,457 train 850 1.889548e-02 -0.709174
2019-11-05 12:16:44,554 training loss; R2: 1.889494e-02 -0.707904
2019-11-05 12:16:45,149 valid 000 1.764451e-02 0.007940
2019-11-05 12:16:55,545 valid 050 1.722653e-02 -1.014724
2019-11-05 12:17:04,793 validation loss; R2: 1.732923e-02 -1.039224
2019-11-05 12:17:04,873 epoch 47 lr 1.000000e-04
2019-11-05 12:17:05,646 train 000 1.738396e-02 -0.626324
2019-11-05 12:17:16,041 train 050 1.899039e-02 -0.609394
2019-11-05 12:17:26,425 train 100 1.888638e-02 -0.556803
2019-11-05 12:17:36,747 train 150 1.884807e-02 -0.732340
2019-11-05 12:17:47,084 train 200 1.879561e-02 -0.663604
2019-11-05 12:17:57,394 train 250 1.876714e-02 -0.692170
2019-11-05 12:18:07,643 train 300 1.884390e-02 -0.719825
2019-11-05 12:18:17,940 train 350 1.885948e-02 -0.710082
2019-11-05 12:18:28,250 train 400 1.888670e-02 -0.704988
2019-11-05 12:18:38,508 train 450 1.892724e-02 -0.702442
2019-11-05 12:18:48,796 train 500 1.887722e-02 -0.684711
2019-11-05 12:18:59,071 train 550 1.890173e-02 -0.681079
2019-11-05 12:19:09,383 train 600 1.889639e-02 -0.665670
2019-11-05 12:19:19,665 train 650 1.890644e-02 -0.648268
2019-11-05 12:19:30,009 train 700 1.888040e-02 -0.662542
2019-11-05 12:19:40,267 train 750 1.885997e-02 -0.650328
2019-11-05 12:19:50,556 train 800 1.882486e-02 -0.642309
2019-11-05 12:20:00,831 train 850 1.881733e-02 -0.651118
2019-11-05 12:20:03,918 training loss; R2: 1.883047e-02 -0.649324
2019-11-05 12:20:04,521 valid 000 1.651870e-02 -1.417420
2019-11-05 12:20:14,850 valid 050 1.657088e-02 -1.271105
2019-11-05 12:20:24,007 validation loss; R2: 1.688910e-02 -1.139736
2019-11-05 12:20:24,071 epoch 48 lr 1.000000e-04
2019-11-05 12:20:24,840 train 000 1.889681e-02 -0.589175
2019-11-05 12:20:35,216 train 050 1.873649e-02 -0.491911
2019-11-05 12:20:45,567 train 100 1.888636e-02 -0.493091
2019-11-05 12:20:55,883 train 150 1.878026e-02 -0.648585
2019-11-05 12:21:06,279 train 200 1.890552e-02 -0.658869
2019-11-05 12:21:16,612 train 250 1.888582e-02 -0.617762
2019-11-05 12:21:26,910 train 300 1.883806e-02 -0.598951
2019-11-05 12:21:37,215 train 350 1.884940e-02 -0.603363
2019-11-05 12:21:47,521 train 400 1.881157e-02 -0.593805
2019-11-05 12:21:57,857 train 450 1.874326e-02 -0.676401
2019-11-05 12:22:08,199 train 500 1.874038e-02 -0.648731
2019-11-05 12:22:18,567 train 550 1.875603e-02 -0.647867
2019-11-05 12:22:28,821 train 600 1.874750e-02 -0.662241
2019-11-05 12:22:39,040 train 650 1.877998e-02 -0.663699
2019-11-05 12:22:49,346 train 700 1.879147e-02 -0.652469
2019-11-05 12:22:59,705 train 750 1.879755e-02 -0.640875
2019-11-05 12:23:09,982 train 800 1.878024e-02 -0.660873
2019-11-05 12:23:20,271 train 850 1.877176e-02 -1.142964
2019-11-05 12:23:23,392 training loss; R2: 1.877834e-02 -1.146739
2019-11-05 12:23:23,943 valid 000 1.351100e-02 0.004330
2019-11-05 12:23:34,119 valid 050 1.695705e-02 -3.694377
2019-11-05 12:23:43,283 validation loss; R2: 1.693048e-02 -2.468040
2019-11-05 12:23:43,372 epoch 49 lr 1.000000e-04
2019-11-05 12:23:44,159 train 000 2.240295e-02 -0.466728
2019-11-05 12:23:54,554 train 050 1.895109e-02 -0.714233
2019-11-05 12:24:04,844 train 100 1.880048e-02 -0.627591
2019-11-05 12:24:15,135 train 150 1.876182e-02 -0.650233
2019-11-05 12:24:25,520 train 200 1.880443e-02 -0.611777
2019-11-05 12:24:35,882 train 250 1.876886e-02 -0.591694
2019-11-05 12:24:46,212 train 300 1.873190e-02 -0.607375
2019-11-05 12:24:56,458 train 350 1.879547e-02 -0.580620
2019-11-05 12:25:06,757 train 400 1.881655e-02 -0.594598
2019-11-05 12:25:17,046 train 450 1.880862e-02 -0.597031
2019-11-05 12:25:27,385 train 500 1.881239e-02 -0.602767
2019-11-05 12:25:37,696 train 550 1.878220e-02 -0.591460
2019-11-05 12:25:48,014 train 600 1.880092e-02 -0.600255
2019-11-05 12:25:58,236 train 650 1.879662e-02 -0.601553
2019-11-05 12:26:08,486 train 700 1.878639e-02 -0.611333
2019-11-05 12:26:18,759 train 750 1.880076e-02 -0.599221
2019-11-05 12:26:29,113 train 800 1.877275e-02 -0.601103
2019-11-05 12:26:39,410 train 850 1.876128e-02 -0.596709
2019-11-05 12:26:42,444 training loss; R2: 1.876094e-02 -0.596899
2019-11-05 12:26:43,046 valid 000 1.625801e-02 -0.737778
2019-11-05 12:26:53,343 valid 050 1.756935e-02 -1.613238
2019-11-05 12:27:02,544 validation loss; R2: 1.733933e-02 -2.949541
2019-11-05 12:27:02,618 epoch 50 lr 1.000000e-04
2019-11-05 12:27:03,418 train 000 1.869289e-02 -0.011552
2019-11-05 12:27:13,748 train 050 1.897139e-02 -0.552254
2019-11-05 12:27:24,137 train 100 1.894521e-02 -0.504300
2019-11-05 12:27:34,491 train 150 1.888165e-02 -0.535017
2019-11-05 12:27:44,820 train 200 1.899356e-02 -1.827120
2019-11-05 12:27:55,166 train 250 1.901665e-02 -1.565981
2019-11-05 12:28:05,505 train 300 1.893573e-02 -1.432730
2019-11-05 12:28:15,862 train 350 1.892987e-02 -1.316344
2019-11-05 12:28:26,230 train 400 1.895897e-02 -1.229633
2019-11-05 12:28:36,545 train 450 1.892841e-02 -1.182996
2019-11-05 12:28:46,928 train 500 1.886492e-02 -1.117280
2019-11-05 12:28:57,319 train 550 1.885236e-02 -1.056433
2019-11-05 12:29:07,765 train 600 1.885352e-02 -1.031907
2019-11-05 12:29:18,114 train 650 1.882633e-02 -1.001348
2019-11-05 12:29:28,499 train 700 1.875829e-02 -0.983622
2019-11-05 12:29:39,055 train 750 1.873724e-02 -0.955268
2019-11-05 12:29:49,609 train 800 1.872261e-02 -0.925825
2019-11-05 12:30:00,129 train 850 1.872066e-02 -0.910154
2019-11-05 12:30:03,261 training loss; R2: 1.871003e-02 -0.944624
2019-11-05 12:30:03,845 valid 000 1.784143e-02 -0.089533
2019-11-05 12:30:14,304 valid 050 1.676338e-02 -0.976516
2019-11-05 12:30:23,532 validation loss; R2: 1.655577e-02 -0.982274
2019-11-05 12:30:23,599 epoch 51 lr 1.000000e-04
2019-11-05 12:30:24,305 train 000 1.817213e-02 -0.277919
2019-11-05 12:30:34,869 train 050 1.854525e-02 -0.903534
2019-11-05 12:30:45,304 train 100 1.853904e-02 -0.762299
2019-11-05 12:30:55,612 train 150 1.861721e-02 -0.759230
2019-11-05 12:31:05,939 train 200 1.865448e-02 -0.819360
2019-11-05 12:31:16,248 train 250 1.849164e-02 -0.754263
2019-11-05 12:31:26,556 train 300 1.856300e-02 -0.740643
2019-11-05 12:31:36,863 train 350 1.861222e-02 -0.731050
2019-11-05 12:31:47,216 train 400 1.862770e-02 -0.697512
2019-11-05 12:31:57,552 train 450 1.861787e-02 -0.716444
2019-11-05 12:32:07,923 train 500 1.859937e-02 -0.692343
2019-11-05 12:32:18,296 train 550 1.862517e-02 -0.683232
2019-11-05 12:32:28,710 train 600 1.862715e-02 -0.709164
2019-11-05 12:32:39,080 train 650 1.862802e-02 -0.711018
2019-11-05 12:32:49,505 train 700 1.862765e-02 -0.694250
2019-11-05 12:32:59,916 train 750 1.862035e-02 -0.699233
2019-11-05 12:33:10,341 train 800 1.860955e-02 -0.682776
2019-11-05 12:33:20,746 train 850 1.860042e-02 -0.692960
2019-11-05 12:33:23,844 training loss; R2: 1.860664e-02 -0.690793
2019-11-05 12:33:24,456 valid 000 1.652117e-02 -0.484973
2019-11-05 12:33:34,639 valid 050 1.628975e-02 -0.898388
2019-11-05 12:33:43,987 validation loss; R2: 1.626083e-02 -0.754732
2019-11-05 12:33:44,068 epoch 52 lr 1.000000e-04
2019-11-05 12:33:44,841 train 000 1.980303e-02 -14.791890
2019-11-05 12:33:55,275 train 050 1.851463e-02 -0.808254
2019-11-05 12:34:05,648 train 100 1.851755e-02 -0.716700
2019-11-05 12:34:16,036 train 150 1.858802e-02 -0.662583
2019-11-05 12:34:26,428 train 200 1.854822e-02 -0.664617
2019-11-05 12:34:36,713 train 250 1.857495e-02 -0.688296
2019-11-05 12:34:47,022 train 300 1.858679e-02 -0.683143
2019-11-05 12:34:57,377 train 350 1.856938e-02 -0.838251
2019-11-05 12:35:07,713 train 400 1.859371e-02 -1.151749
2019-11-05 12:35:17,997 train 450 1.864761e-02 -1.074080
2019-11-05 12:35:28,281 train 500 1.860482e-02 -1.021009
2019-11-05 12:35:38,650 train 550 1.859536e-02 -0.999818
2019-11-05 12:35:48,839 train 600 1.861792e-02 -0.996729
2019-11-05 12:35:59,037 train 650 1.863401e-02 -0.953044
2019-11-05 12:36:09,321 train 700 1.864311e-02 -0.931306
2019-11-05 12:36:19,703 train 750 1.863018e-02 -0.915665
2019-11-05 12:36:30,040 train 800 1.864948e-02 -0.903850
2019-11-05 12:36:40,290 train 850 1.864834e-02 -0.904148
2019-11-05 12:36:43,367 training loss; R2: 1.864566e-02 -0.895641
2019-11-05 12:36:43,953 valid 000 1.737912e-02 -0.378297
2019-11-05 12:36:54,373 valid 050 1.664235e-02 -1.135923
2019-11-05 12:37:03,628 validation loss; R2: 1.689326e-02 -1.105911
2019-11-05 12:37:03,692 epoch 53 lr 1.000000e-04
2019-11-05 12:37:04,392 train 000 1.735802e-02 -0.627915
2019-11-05 12:37:14,883 train 050 1.897777e-02 -0.362909
2019-11-05 12:37:25,262 train 100 1.869791e-02 -0.444733
2019-11-05 12:37:35,538 train 150 1.854404e-02 -0.481178
2019-11-05 12:37:45,818 train 200 1.852337e-02 -0.610472
2019-11-05 12:37:56,010 train 250 1.847852e-02 -0.590652
2019-11-05 12:38:06,213 train 300 1.849678e-02 -0.568612
2019-11-05 12:38:16,374 train 350 1.849065e-02 -0.622442
2019-11-05 12:38:26,643 train 400 1.857088e-02 -0.620008
2019-11-05 12:38:36,833 train 450 1.855468e-02 -0.617036
2019-11-05 12:38:47,037 train 500 1.856157e-02 -0.608274
2019-11-05 12:38:57,194 train 550 1.852648e-02 -0.622832
2019-11-05 12:39:07,383 train 600 1.850524e-02 -0.629573
2019-11-05 12:39:17,533 train 650 1.852335e-02 -0.662656
2019-11-05 12:39:27,721 train 700 1.852469e-02 -0.653149
2019-11-05 12:39:37,858 train 750 1.851790e-02 -0.644499
2019-11-05 12:39:48,050 train 800 1.851762e-02 -0.637852
2019-11-05 12:39:58,279 train 850 1.853709e-02 -0.645489
2019-11-05 12:40:01,359 training loss; R2: 1.853867e-02 -0.645045
2019-11-05 12:40:01,951 valid 000 1.753165e-02 -1.302668
2019-11-05 12:40:12,007 valid 050 1.724030e-02 -1.132572
2019-11-05 12:40:20,883 validation loss; R2: 1.703241e-02 -1.184582
2019-11-05 12:40:20,946 epoch 54 lr 1.000000e-04
2019-11-05 12:40:21,705 train 000 1.636598e-02 -0.075669
2019-11-05 12:40:32,017 train 050 1.818126e-02 -0.450538
2019-11-05 12:40:42,464 train 100 1.835073e-02 -0.554652
2019-11-05 12:40:52,822 train 150 1.830093e-02 -0.530860
2019-11-05 12:41:03,226 train 200 1.843415e-02 -0.535437
2019-11-05 12:41:13,606 train 250 1.846109e-02 -0.591078
2019-11-05 12:41:23,969 train 300 1.845570e-02 -0.628068
2019-11-05 12:41:34,340 train 350 1.850200e-02 -0.640775
2019-11-05 12:41:44,714 train 400 1.850805e-02 -0.652335
2019-11-05 12:41:55,047 train 450 1.850100e-02 -0.673884
2019-11-05 12:42:05,382 train 500 1.846504e-02 -0.659799
2019-11-05 12:42:15,611 train 550 1.848903e-02 -0.639405
2019-11-05 12:42:25,947 train 600 1.853699e-02 -0.641652
2019-11-05 12:42:36,245 train 650 1.853057e-02 -0.635781
2019-11-05 12:42:46,672 train 700 1.853536e-02 -0.632095
2019-11-05 12:42:57,044 train 750 1.853646e-02 -0.658787
2019-11-05 12:43:07,437 train 800 1.851760e-02 -0.657200
2019-11-05 12:43:17,818 train 850 1.850947e-02 -0.659892
2019-11-05 12:43:20,903 training loss; R2: 1.851602e-02 -0.662163
2019-11-05 12:43:21,424 valid 000 1.550934e-02 -0.812409
2019-11-05 12:43:31,401 valid 050 1.716863e-02 -0.931838
2019-11-05 12:43:40,452 validation loss; R2: 1.691187e-02 -1.024803
2019-11-05 12:43:40,527 epoch 55 lr 1.000000e-04
2019-11-05 12:43:41,204 train 000 1.771905e-02 -0.068012
2019-11-05 12:43:51,672 train 050 1.878657e-02 -0.721722
2019-11-05 12:44:02,107 train 100 1.879942e-02 -0.687913
2019-11-05 12:44:12,501 train 150 1.865318e-02 -0.663991
2019-11-05 12:44:22,861 train 200 1.868858e-02 -0.674139
2019-11-05 12:44:33,210 train 250 1.858781e-02 -0.642144
2019-11-05 12:44:43,536 train 300 1.849835e-02 -1.560628
2019-11-05 12:44:53,863 train 350 1.847730e-02 -1.440327
2019-11-05 12:45:04,202 train 400 1.844815e-02 -1.348973
2019-11-05 12:45:14,496 train 450 1.845990e-02 -1.282458
2019-11-05 12:45:24,797 train 500 1.847513e-02 -1.220639
2019-11-05 12:45:35,058 train 550 1.843523e-02 -1.218155
2019-11-05 12:45:45,404 train 600 1.845747e-02 -1.170990
2019-11-05 12:45:55,564 train 650 1.848830e-02 -1.138135
2019-11-05 12:46:05,902 train 700 1.849609e-02 -1.401802
2019-11-05 12:46:16,223 train 750 1.849128e-02 -1.369806
2019-11-05 12:46:26,569 train 800 1.851432e-02 -1.312401
2019-11-05 12:46:36,893 train 850 1.851486e-02 -1.268744
2019-11-05 12:46:40,003 training loss; R2: 1.851519e-02 -1.259669
2019-11-05 12:46:40,599 valid 000 1.554490e-02 -0.279155
2019-11-05 12:46:51,025 valid 050 1.623052e-02 -0.789748
2019-11-05 12:47:00,296 validation loss; R2: 1.608543e-02 -0.949657
2019-11-05 12:47:00,353 epoch 56 lr 1.000000e-04
2019-11-05 12:47:01,131 train 000 2.025258e-02 -0.135288
2019-11-05 12:47:11,405 train 050 1.833619e-02 -0.453279
2019-11-05 12:47:21,717 train 100 1.855346e-02 -1.469026
2019-11-05 12:47:31,973 train 150 1.838759e-02 -5.756526
2019-11-05 12:47:42,258 train 200 1.838635e-02 -4.544864
2019-11-05 12:47:52,555 train 250 1.830664e-02 -3.766572
2019-11-05 12:48:02,862 train 300 1.832853e-02 -3.462458
2019-11-05 12:48:13,149 train 350 1.836767e-02 -3.081243
2019-11-05 12:48:23,420 train 400 1.844540e-02 -2.769919
2019-11-05 12:48:33,714 train 450 1.845625e-02 -2.522062
2019-11-05 12:48:44,034 train 500 1.844529e-02 -2.332149
2019-11-05 12:48:54,308 train 550 1.843735e-02 -2.172443
2019-11-05 12:49:04,553 train 600 1.846038e-02 -2.070905
2019-11-05 12:49:14,818 train 650 1.846109e-02 -1.970880
2019-11-05 12:49:24,941 train 700 1.849956e-02 -1.877722
2019-11-05 12:49:35,155 train 750 1.849163e-02 -1.782880
2019-11-05 12:49:45,426 train 800 1.848723e-02 -1.722254
2019-11-05 12:49:55,657 train 850 1.850679e-02 -1.653833
2019-11-05 12:49:58,729 training loss; R2: 1.850634e-02 -1.637278
2019-11-05 12:49:59,331 valid 000 1.226494e-02 -1.627611
2019-11-05 12:50:09,404 valid 050 1.648323e-02 -1.162182
2019-11-05 12:50:18,330 validation loss; R2: 1.668956e-02 -1.105232
2019-11-05 12:50:18,407 epoch 57 lr 1.000000e-04
2019-11-05 12:50:19,111 train 000 1.689649e-02 -0.345552
2019-11-05 12:50:29,477 train 050 1.852536e-02 -0.606163
2019-11-05 12:50:39,792 train 100 1.852174e-02 -0.750223
2019-11-05 12:50:50,094 train 150 1.849239e-02 -0.730136
2019-11-05 12:51:00,429 train 200 1.844501e-02 -0.785950
2019-11-05 12:51:10,756 train 250 1.846351e-02 -0.726429
2019-11-05 12:51:21,076 train 300 1.845113e-02 -0.725424
2019-11-05 12:51:31,387 train 350 1.839709e-02 -0.733774
2019-11-05 12:51:41,718 train 400 1.842645e-02 -0.748889
2019-11-05 12:51:52,067 train 450 1.842119e-02 -0.737631
2019-11-05 12:52:02,430 train 500 1.846452e-02 -0.716543
2019-11-05 12:52:12,767 train 550 1.849360e-02 -0.712139
2019-11-05 12:52:23,116 train 600 1.848292e-02 -0.697661
2019-11-05 12:52:33,366 train 650 1.847420e-02 -0.683958
2019-11-05 12:52:43,790 train 700 1.847048e-02 -0.675218
2019-11-05 12:52:54,249 train 750 1.846342e-02 -0.660947
2019-11-05 12:53:04,749 train 800 1.846483e-02 -0.659402
2019-11-05 12:53:15,153 train 850 1.843985e-02 -0.655177
2019-11-05 12:53:18,265 training loss; R2: 1.844221e-02 -0.661368
2019-11-05 12:53:18,877 valid 000 1.467673e-02 -4.087243
2019-11-05 12:53:29,121 valid 050 1.685378e-02 -1.183559
2019-11-05 12:53:38,029 validation loss; R2: 1.700535e-02 -1.328325
2019-11-05 12:53:38,097 epoch 58 lr 1.000000e-04
2019-11-05 12:53:38,773 train 000 1.838804e-02 -0.047207
2019-11-05 12:53:49,212 train 050 1.872624e-02 -0.493797
2019-11-05 12:53:59,685 train 100 1.863277e-02 -0.546491
2019-11-05 12:54:10,044 train 150 1.848287e-02 -0.661000
2019-11-05 12:54:19,861 train 200 1.846363e-02 -0.612827
2019-11-05 12:54:29,662 train 250 1.849109e-02 -0.659642
2019-11-05 12:54:39,492 train 300 1.851624e-02 -0.654750
2019-11-05 12:54:49,290 train 350 1.851598e-02 -0.641478
2019-11-05 12:54:59,055 train 400 1.846794e-02 -0.632352
2019-11-05 12:55:08,887 train 450 1.848935e-02 -0.618405
2019-11-05 12:55:18,708 train 500 1.844292e-02 -0.646617
2019-11-05 12:55:28,499 train 550 1.844015e-02 -0.659281
2019-11-05 12:55:38,294 train 600 1.846783e-02 -0.669432
2019-11-05 12:55:48,492 train 650 1.846791e-02 -0.663496
2019-11-05 12:55:58,354 train 700 1.846879e-02 -0.675133
2019-11-05 12:56:08,158 train 750 1.844581e-02 -0.668070
2019-11-05 12:56:18,033 train 800 1.842235e-02 -0.660006
2019-11-05 12:56:27,858 train 850 1.844373e-02 -0.667590
2019-11-05 12:56:30,800 training loss; R2: 1.845268e-02 -0.660198
2019-11-05 12:56:31,370 valid 000 1.826795e-02 -1.162233
2019-11-05 12:56:41,148 valid 050 1.605120e-02 -1.436267
2019-11-05 12:56:49,748 validation loss; R2: 1.616555e-02 -1.312226
2019-11-05 12:56:49,813 epoch 59 lr 1.000000e-04
2019-11-05 12:56:50,550 train 000 1.726559e-02 -0.012766
2019-11-05 12:57:00,299 train 050 1.815204e-02 -1.245426
2019-11-05 12:57:10,249 train 100 1.820961e-02 -0.963348
2019-11-05 12:57:20,553 train 150 1.835704e-02 -1.673039
2019-11-05 12:57:30,844 train 200 1.841456e-02 -1.374024
2019-11-05 12:57:41,154 train 250 1.843281e-02 -1.203326
2019-11-05 12:57:51,426 train 300 1.850209e-02 -1.136385
2019-11-05 12:58:01,786 train 350 1.849481e-02 -1.031684
2019-11-05 12:58:12,054 train 400 1.844208e-02 -0.980983
2019-11-05 12:58:22,379 train 450 1.843889e-02 -0.920765
2019-11-05 12:58:32,624 train 500 1.839611e-02 -0.918316
2019-11-05 12:58:42,830 train 550 1.839749e-02 -0.871861
2019-11-05 12:58:53,175 train 600 1.839931e-02 -1.440599
2019-11-05 12:59:03,409 train 650 1.840017e-02 -1.377970
2019-11-05 12:59:13,652 train 700 1.836660e-02 -1.339227
2019-11-05 12:59:24,048 train 750 1.836576e-02 -1.297298
2019-11-05 12:59:34,292 train 800 1.836928e-02 -1.261602
2019-11-05 12:59:44,507 train 850 1.837002e-02 -1.229285
2019-11-05 12:59:47,563 training loss; R2: 1.836366e-02 -1.216696
2019-11-05 12:59:48,094 valid 000 1.353025e-02 -0.054260
2019-11-05 12:59:57,926 valid 050 1.626955e-02 -1.342752
2019-11-05 13:00:06,714 validation loss; R2: 1.615785e-02 -1.328834
2019-11-05 13:00:06,785 epoch 60 lr 1.000000e-04
2019-11-05 13:00:07,498 train 000 1.809588e-02 -0.152213
2019-11-05 13:00:17,754 train 050 1.827949e-02 -0.871533
2019-11-05 13:00:27,997 train 100 1.828064e-02 -0.773864
2019-11-05 13:00:38,184 train 150 1.822923e-02 -0.869037
2019-11-05 13:00:48,394 train 200 1.840042e-02 -0.747230
2019-11-05 13:00:58,593 train 250 1.846350e-02 -0.726034
2019-11-05 13:01:08,789 train 300 1.843176e-02 -0.708543
2019-11-05 13:01:18,955 train 350 1.844516e-02 -0.698718
2019-11-05 13:01:29,148 train 400 1.843094e-02 -0.667006
2019-11-05 13:01:39,329 train 450 1.837107e-02 -0.677581
2019-11-05 13:01:49,554 train 500 1.831929e-02 -0.685705
2019-11-05 13:01:59,754 train 550 1.833012e-02 -0.683663
2019-11-05 13:02:09,977 train 600 1.833383e-02 -0.689282
2019-11-05 13:02:20,202 train 650 1.833321e-02 -0.687846
2019-11-05 13:02:30,428 train 700 1.832070e-02 -0.678439
2019-11-05 13:02:40,618 train 750 1.834747e-02 -0.666743
2019-11-05 13:02:50,748 train 800 1.835121e-02 -0.694304
2019-11-05 13:03:00,855 train 850 1.836046e-02 -0.692680
2019-11-05 13:03:03,915 training loss; R2: 1.836414e-02 -0.692099
2019-11-05 13:03:04,434 valid 000 1.508634e-02 -2.501911
2019-11-05 13:03:14,336 valid 050 1.631352e-02 -1.385100
2019-11-05 13:03:23,039 validation loss; R2: 1.651094e-02 -1.444399
2019-11-05 13:03:23,104 epoch 61 lr 1.000000e-04
2019-11-05 13:03:23,821 train 000 2.053337e-02 -0.568456
2019-11-05 13:03:34,082 train 050 1.859071e-02 -0.522029
2019-11-05 13:03:44,286 train 100 1.843027e-02 -1.329545
2019-11-05 13:03:54,450 train 150 1.829056e-02 -1.084487
2019-11-05 13:04:04,624 train 200 1.838273e-02 -0.932423
2019-11-05 13:04:14,783 train 250 1.835467e-02 -0.898714
2019-11-05 13:04:24,928 train 300 1.834830e-02 -0.908693
2019-11-05 13:04:35,097 train 350 1.835069e-02 -0.874772
2019-11-05 13:04:45,217 train 400 1.829069e-02 -0.866866
2019-11-05 13:04:55,396 train 450 1.831999e-02 -0.861270
2019-11-05 13:05:05,530 train 500 1.828808e-02 -0.823816
2019-11-05 13:05:15,701 train 550 1.827113e-02 -0.803941
2019-11-05 13:05:25,846 train 600 1.833507e-02 -0.798123
2019-11-05 13:05:36,012 train 650 1.830160e-02 -0.787889
2019-11-05 13:05:46,160 train 700 1.834568e-02 -0.764804
2019-11-05 13:05:56,320 train 750 1.831847e-02 -0.751737
2019-11-05 13:06:06,466 train 800 1.833171e-02 -0.746340
2019-11-05 13:06:16,653 train 850 1.836934e-02 -0.733353
2019-11-05 13:06:19,692 training loss; R2: 1.838553e-02 -0.727508
2019-11-05 13:06:20,209 valid 000 1.623264e-02 0.101865
2019-11-05 13:06:30,029 valid 050 1.623432e-02 -0.951174
2019-11-05 13:06:38,738 validation loss; R2: 1.647725e-02 -0.965458
2019-11-05 13:06:38,801 epoch 62 lr 1.000000e-04
2019-11-05 13:06:39,547 train 000 2.116787e-02 -0.279490
2019-11-05 13:06:49,767 train 050 1.871676e-02 -0.498051
2019-11-05 13:06:59,968 train 100 1.836562e-02 -0.641256
2019-11-05 13:07:10,162 train 150 1.833292e-02 -0.764678
2019-11-05 13:07:20,347 train 200 1.829068e-02 -0.744834
2019-11-05 13:07:30,492 train 250 1.830916e-02 -0.773415
2019-11-05 13:07:40,673 train 300 1.836662e-02 -0.794149
2019-11-05 13:07:50,817 train 350 1.840774e-02 -0.738731
2019-11-05 13:08:00,969 train 400 1.840535e-02 -0.735842
2019-11-05 13:08:11,079 train 450 1.838802e-02 -0.714526
2019-11-05 13:08:21,217 train 500 1.840013e-02 -0.718295
2019-11-05 13:08:31,340 train 550 1.842312e-02 -0.700449
2019-11-05 13:08:41,488 train 600 1.842818e-02 -0.694174
2019-11-05 13:08:51,624 train 650 1.843879e-02 -0.708871
2019-11-05 13:09:01,756 train 700 1.845259e-02 -0.700616
2019-11-05 13:09:11,898 train 750 1.843851e-02 -0.719322
2019-11-05 13:09:22,048 train 800 1.847861e-02 -0.716549
2019-11-05 13:09:32,219 train 850 1.851455e-02 -0.708518
2019-11-05 13:09:35,244 training loss; R2: 1.851661e-02 -0.700656
2019-11-05 13:09:35,829 valid 000 1.495867e-02 0.011414
2019-11-05 13:09:45,653 valid 050 1.670255e-02 -1.264059
2019-11-05 13:09:54,341 validation loss; R2: 1.669026e-02 -1.244558
2019-11-05 13:09:54,410 epoch 63 lr 1.000000e-04
2019-11-05 13:09:55,128 train 000 1.702848e-02 -0.292015
2019-11-05 13:10:05,357 train 050 1.834942e-02 -0.608186
2019-11-05 13:10:15,548 train 100 1.848734e-02 -0.597689
2019-11-05 13:10:25,734 train 150 1.849620e-02 -0.661747
2019-11-05 13:10:35,902 train 200 1.862465e-02 -0.693276
2019-11-05 13:10:46,081 train 250 1.852836e-02 -0.683120
2019-11-05 13:10:56,242 train 300 1.856276e-02 -0.691549
2019-11-05 13:11:06,430 train 350 1.852952e-02 -0.683160
2019-11-05 13:11:16,574 train 400 1.851278e-02 -0.651208
2019-11-05 13:11:26,749 train 450 1.850713e-02 -0.654598
2019-11-05 13:11:36,918 train 500 1.852827e-02 -0.645691
2019-11-05 13:11:47,107 train 550 1.852549e-02 -0.668769
2019-11-05 13:11:57,310 train 600 1.857550e-02 -0.664394
2019-11-05 13:12:07,478 train 650 1.856177e-02 -0.664449
2019-11-05 13:12:17,644 train 700 1.855329e-02 -0.677239
2019-11-05 13:12:27,799 train 750 1.852703e-02 -0.688233
2019-11-05 13:12:37,966 train 800 1.850821e-02 -0.675833
2019-11-05 13:12:48,116 train 850 1.851592e-02 -0.671913
2019-11-05 13:12:51,150 training loss; R2: 1.849844e-02 -0.665104
2019-11-05 13:12:51,741 valid 000 1.403515e-02 -0.391759
2019-11-05 13:13:01,470 valid 050 1.575320e-02 -0.880389
2019-11-05 13:13:10,136 validation loss; R2: 1.579339e-02 -1.128731
2019-11-05 13:13:10,213 epoch 64 lr 1.000000e-04
2019-11-05 13:13:10,937 train 000 1.873828e-02 -0.037538
2019-11-05 13:13:21,073 train 050 1.844463e-02 -0.981135
2019-11-05 13:13:31,201 train 100 1.861615e-02 -0.775836
2019-11-05 13:13:41,368 train 150 1.867636e-02 -0.823544
2019-11-05 13:13:51,509 train 200 1.861891e-02 -0.885468
2019-11-05 13:14:01,580 train 250 1.862864e-02 -0.857123
2019-11-05 13:14:11,674 train 300 1.859180e-02 -0.829576
2019-11-05 13:14:21,793 train 350 1.852547e-02 -0.803070
2019-11-05 13:14:31,967 train 400 1.853311e-02 -0.760098
2019-11-05 13:14:42,095 train 450 1.855341e-02 -0.754284
2019-11-05 13:14:52,284 train 500 1.858567e-02 -0.736899
2019-11-05 13:15:02,432 train 550 1.860967e-02 -0.731002
2019-11-05 13:15:12,578 train 600 1.859591e-02 -0.733737
2019-11-05 13:15:22,710 train 650 1.858812e-02 -0.724777
2019-11-05 13:15:32,842 train 700 1.855037e-02 -0.720211
2019-11-05 13:15:42,996 train 750 1.856068e-02 -0.704251
2019-11-05 13:15:53,159 train 800 1.855339e-02 -0.714101
2019-11-05 13:16:03,383 train 850 1.850964e-02 -0.726754
2019-11-05 13:16:06,453 training loss; R2: 1.849791e-02 -0.724663
2019-11-05 13:16:06,968 valid 000 1.774050e-02 -0.831692
2019-11-05 13:16:16,778 valid 050 1.645605e-02 -1.067721
2019-11-05 13:16:25,461 validation loss; R2: 1.649862e-02 -1.033556
2019-11-05 13:16:25,524 epoch 65 lr 1.000000e-04
2019-11-05 13:16:26,228 train 000 1.964570e-02 -0.239223
2019-11-05 13:16:36,476 train 050 1.809160e-02 -0.852102
2019-11-05 13:16:46,679 train 100 1.829659e-02 -0.662598
2019-11-05 13:16:56,857 train 150 1.824493e-02 -0.591287
2019-11-05 13:17:07,044 train 200 1.826334e-02 -0.593399
2019-11-05 13:17:17,199 train 250 1.839274e-02 -0.571337
2019-11-05 13:17:27,374 train 300 1.841023e-02 -0.560758
2019-11-05 13:17:37,532 train 350 1.848553e-02 -0.568059
2019-11-05 13:17:47,711 train 400 1.848102e-02 -0.575774
2019-11-05 13:17:57,872 train 450 1.847264e-02 -0.563142
2019-11-05 13:18:08,038 train 500 1.841123e-02 -0.592440
2019-11-05 13:18:18,151 train 550 1.842887e-02 -0.620059
2019-11-05 13:18:28,253 train 600 1.840053e-02 -0.610952
2019-11-05 13:18:38,361 train 650 1.840274e-02 -0.604487
2019-11-05 13:18:48,428 train 700 1.841465e-02 -0.646541
2019-11-05 13:18:58,551 train 750 1.840845e-02 -0.787627
2019-11-05 13:19:08,733 train 800 1.840907e-02 -0.769597
2019-11-05 13:19:18,901 train 850 1.840549e-02 -0.759360
2019-11-05 13:19:21,934 training loss; R2: 1.839454e-02 -0.766104
2019-11-05 13:19:22,506 valid 000 1.788594e-02 -0.844515
2019-11-05 13:19:32,360 valid 050 1.619921e-02 -1.164108
2019-11-05 13:19:41,027 validation loss; R2: 1.620234e-02 -1.286304
2019-11-05 13:19:41,095 epoch 66 lr 1.000000e-04
2019-11-05 13:19:41,875 train 000 1.780266e-02 -3.163768
2019-11-05 13:19:52,047 train 050 1.832959e-02 -0.733401
2019-11-05 13:20:02,205 train 100 1.832830e-02 -0.747054
2019-11-05 13:20:12,284 train 150 1.836881e-02 -0.662668
2019-11-05 13:20:22,502 train 200 1.834681e-02 -0.637679
2019-11-05 13:20:32,621 train 250 1.833316e-02 -0.637596
2019-11-05 13:20:42,710 train 300 1.836113e-02 -0.607757
2019-11-05 13:20:52,926 train 350 1.832783e-02 -0.636977
2019-11-05 13:21:03,041 train 400 1.832236e-02 -0.662155
2019-11-05 13:21:13,155 train 450 1.839974e-02 -0.631964
2019-11-05 13:21:23,323 train 500 1.840140e-02 -0.632380
2019-11-05 13:21:33,515 train 550 1.839741e-02 -0.645795
2019-11-05 13:21:43,676 train 600 1.843888e-02 -0.663109
2019-11-05 13:21:53,863 train 650 1.845372e-02 -0.667770
2019-11-05 13:22:04,055 train 700 1.844212e-02 -0.682081
2019-11-05 13:22:14,250 train 750 1.843095e-02 -0.679078
2019-11-05 13:22:24,455 train 800 1.845138e-02 -0.672201
2019-11-05 13:22:34,674 train 850 1.845557e-02 -0.662446
2019-11-05 13:22:37,728 training loss; R2: 1.845543e-02 -0.665919
2019-11-05 13:22:38,324 valid 000 1.667491e-02 -0.004858
2019-11-05 13:22:48,249 valid 050 1.622630e-02 -0.785661
2019-11-05 13:22:56,940 validation loss; R2: 1.638204e-02 -0.785388
2019-11-05 13:22:57,003 epoch 67 lr 1.000000e-04
2019-11-05 13:22:57,674 train 000 1.602532e-02 -4.558240
2019-11-05 13:23:08,082 train 050 1.852299e-02 -0.914380
2019-11-05 13:23:18,468 train 100 1.834788e-02 -0.749911
2019-11-05 13:23:28,831 train 150 1.825954e-02 -0.673282
2019-11-05 13:23:39,192 train 200 1.814856e-02 -0.634186
2019-11-05 13:23:49,406 train 250 1.823728e-02 -0.664375
2019-11-05 13:23:59,585 train 300 1.828787e-02 -0.701065
2019-11-05 13:24:09,774 train 350 1.827237e-02 -0.697018
2019-11-05 13:24:19,997 train 400 1.830401e-02 -0.668705
2019-11-05 13:24:30,178 train 450 1.833602e-02 -0.652582
2019-11-05 13:24:40,331 train 500 1.830439e-02 -0.627701
2019-11-05 13:24:50,532 train 550 1.827475e-02 -0.618592
2019-11-05 13:25:00,699 train 600 1.825806e-02 -0.635379
2019-11-05 13:25:10,845 train 650 1.826998e-02 -0.646033
2019-11-05 13:25:20,991 train 700 1.830048e-02 -0.644632
2019-11-05 13:25:31,159 train 750 1.829597e-02 -0.630303
2019-11-05 13:25:41,317 train 800 1.828640e-02 -0.641490
2019-11-05 13:25:51,482 train 850 1.827835e-02 -0.638302
2019-11-05 13:25:54,506 training loss; R2: 1.828086e-02 -0.652871
2019-11-05 13:25:55,022 valid 000 1.751336e-02 -0.260251
2019-11-05 13:26:04,955 valid 050 1.564178e-02 -1.347891
2019-11-05 13:26:13,653 validation loss; R2: 1.561080e-02 -1.177810
2019-11-05 13:26:13,728 epoch 68 lr 1.000000e-04
2019-11-05 13:26:14,490 train 000 2.134640e-02 -0.271032
2019-11-05 13:26:24,592 train 050 1.803049e-02 -0.567707
2019-11-05 13:26:34,830 train 100 1.794397e-02 -0.592976
2019-11-05 13:26:45,019 train 150 1.809781e-02 -0.624441
2019-11-05 13:26:55,163 train 200 1.823415e-02 -0.665285
2019-11-05 13:27:05,450 train 250 1.828089e-02 -0.636823
2019-11-05 13:27:15,670 train 300 1.835540e-02 -0.729128
2019-11-05 13:27:25,792 train 350 1.831420e-02 -0.723362
2019-11-05 13:27:36,051 train 400 1.829791e-02 -0.784423
2019-11-05 13:27:46,278 train 450 1.827760e-02 -0.771294
2019-11-05 13:27:56,510 train 500 1.826578e-02 -0.750050
2019-11-05 13:28:06,758 train 550 1.823181e-02 -0.755197
2019-11-05 13:28:17,002 train 600 1.824883e-02 -0.762707
2019-11-05 13:28:27,235 train 650 1.823443e-02 -0.796202
2019-11-05 13:28:37,449 train 700 1.826490e-02 -0.774501
2019-11-05 13:28:47,681 train 750 1.828521e-02 -0.762489
2019-11-05 13:28:57,871 train 800 1.828005e-02 -0.763497
2019-11-05 13:29:07,997 train 850 1.830247e-02 -0.753143
2019-11-05 13:29:11,034 training loss; R2: 1.830922e-02 -0.752978
2019-11-05 13:29:11,552 valid 000 1.811772e-02 -1.003452
2019-11-05 13:29:21,409 valid 050 1.648335e-02 -1.369472
2019-11-05 13:29:30,033 validation loss; R2: 1.643361e-02 -1.220592
2019-11-05 13:29:30,098 epoch 69 lr 1.000000e-04
2019-11-05 13:29:30,828 train 000 1.792130e-02 -0.257790
2019-11-05 13:29:41,112 train 050 1.835991e-02 -0.764536
2019-11-05 13:29:51,334 train 100 1.829694e-02 -1.927124
2019-11-05 13:30:01,572 train 150 1.839501e-02 -1.483166
2019-11-05 13:30:11,812 train 200 1.846637e-02 -1.235849
2019-11-05 13:30:22,044 train 250 1.839008e-02 -1.164540
2019-11-05 13:30:32,205 train 300 1.833138e-02 -1.052718
2019-11-05 13:30:42,398 train 350 1.839196e-02 -1.032453
2019-11-05 13:30:52,562 train 400 1.839302e-02 -0.970297
2019-11-05 13:31:02,728 train 450 1.836675e-02 -0.910106
2019-11-05 13:31:12,867 train 500 1.834270e-02 -0.887704
2019-11-05 13:31:23,033 train 550 1.831727e-02 -0.843092
2019-11-05 13:31:33,167 train 600 1.830941e-02 -0.819529
2019-11-05 13:31:43,356 train 650 1.831632e-02 -0.818533
2019-11-05 13:31:53,510 train 700 1.828896e-02 -0.787692
2019-11-05 13:32:03,756 train 750 1.825007e-02 -0.778378
2019-11-05 13:32:13,970 train 800 1.822703e-02 -0.762161
2019-11-05 13:32:24,189 train 850 1.822423e-02 -0.780295
2019-11-05 13:32:27,230 training loss; R2: 1.823789e-02 -0.776853
2019-11-05 13:32:27,792 valid 000 1.779576e-02 -0.476065
2019-11-05 13:32:37,619 valid 050 1.644374e-02 -1.396945
2019-11-05 13:32:46,313 validation loss; R2: 1.658373e-02 -1.413687
2019-11-05 13:32:46,384 epoch 70 lr 1.000000e-04
2019-11-05 13:32:47,137 train 000 1.962329e-02 -0.342541
2019-11-05 13:32:57,248 train 050 1.851504e-02 -0.524137
2019-11-05 13:33:07,401 train 100 1.816736e-02 -0.610963
2019-11-05 13:33:17,572 train 150 1.806660e-02 -0.678670
2019-11-05 13:33:27,725 train 200 1.807995e-02 -0.706142
2019-11-05 13:33:37,855 train 250 1.805873e-02 -0.690446
2019-11-05 13:33:48,036 train 300 1.804519e-02 -0.668549
2019-11-05 13:33:58,182 train 350 1.806389e-02 -0.642295
2019-11-05 13:34:08,338 train 400 1.809673e-02 -0.649975
2019-11-05 13:34:18,483 train 450 1.807951e-02 -0.644061
2019-11-05 13:34:28,628 train 500 1.813629e-02 -0.647502
2019-11-05 13:34:38,770 train 550 1.815569e-02 -0.700089
2019-11-05 13:34:49,000 train 600 1.818212e-02 -0.687333
2019-11-05 13:34:59,214 train 650 1.819080e-02 -0.689198
2019-11-05 13:35:09,422 train 700 1.817777e-02 -0.699039
2019-11-05 13:35:19,636 train 750 1.816383e-02 -0.693509
2019-11-05 13:35:29,819 train 800 1.816549e-02 -0.690445
2019-11-05 13:35:39,999 train 850 1.815830e-02 -0.684006
2019-11-05 13:35:43,030 training loss; R2: 1.815521e-02 -0.680974
2019-11-05 13:35:43,549 valid 000 1.546985e-02 -1.025907
2019-11-05 13:35:53,393 valid 050 1.581630e-02 -2.230330
2019-11-05 13:36:02,052 validation loss; R2: 1.592386e-02 -1.828845
2019-11-05 13:36:02,114 epoch 71 lr 1.000000e-04
2019-11-05 13:36:02,783 train 000 1.774897e-02 0.070393
2019-11-05 13:36:13,033 train 050 1.795638e-02 -0.666788
2019-11-05 13:36:23,234 train 100 1.787140e-02 -0.599163
2019-11-05 13:36:33,433 train 150 1.792370e-02 -0.695890
2019-11-05 13:36:43,625 train 200 1.789017e-02 -0.636390
2019-11-05 13:36:53,787 train 250 1.792859e-02 -0.639877
2019-11-05 13:37:03,885 train 300 1.795861e-02 -0.716745
2019-11-05 13:37:14,033 train 350 1.800326e-02 -0.671178
2019-11-05 13:37:24,120 train 400 1.804634e-02 -0.672296
2019-11-05 13:37:34,198 train 450 1.802743e-02 -0.682068
2019-11-05 13:37:44,269 train 500 1.801337e-02 -0.721558
2019-11-05 13:37:54,349 train 550 1.800797e-02 -0.712091
2019-11-05 13:38:04,397 train 600 1.802642e-02 -0.718724
2019-11-05 13:38:14,517 train 650 1.803029e-02 -0.746393
2019-11-05 13:38:24,668 train 700 1.803324e-02 -0.757675
2019-11-05 13:38:34,833 train 750 1.804209e-02 -0.772079
2019-11-05 13:38:44,984 train 800 1.801527e-02 -0.773568
2019-11-05 13:38:55,135 train 850 1.802354e-02 -0.759249
2019-11-05 13:38:58,175 training loss; R2: 1.802226e-02 -0.761620
2019-11-05 13:38:58,736 valid 000 1.486911e-02 -4.746847
2019-11-05 13:39:08,560 valid 050 1.584727e-02 -0.973444
2019-11-05 13:39:17,222 validation loss; R2: 1.621091e-02 -1.453129
2019-11-05 13:39:17,286 epoch 72 lr 1.000000e-04
2019-11-05 13:39:18,035 train 000 1.829664e-02 -0.089046
2019-11-05 13:39:28,117 train 050 1.815827e-02 -0.595144
2019-11-05 13:39:38,332 train 100 1.817733e-02 -0.628877
2019-11-05 13:39:48,492 train 150 1.809978e-02 -0.700529
2019-11-05 13:39:58,633 train 200 1.800946e-02 -0.715284
2019-11-05 13:40:08,723 train 250 1.795691e-02 -0.678330
2019-11-05 13:40:18,844 train 300 1.807013e-02 -0.682050
2019-11-05 13:40:28,974 train 350 1.806707e-02 -0.650758
2019-11-05 13:40:39,129 train 400 1.805046e-02 -0.673586
2019-11-05 13:40:49,246 train 450 1.807042e-02 -0.647720
2019-11-05 13:40:59,409 train 500 1.805026e-02 -0.675321
2019-11-05 13:41:09,526 train 550 1.802367e-02 -0.660960
2019-11-05 13:41:19,689 train 600 1.799540e-02 -0.642892
2019-11-05 13:41:29,852 train 650 1.800591e-02 -0.650592
2019-11-05 13:41:39,998 train 700 1.801558e-02 -0.674588
2019-11-05 13:41:50,154 train 750 1.801371e-02 -0.669217
2019-11-05 13:42:00,311 train 800 1.799627e-02 -0.692225
2019-11-05 13:42:10,516 train 850 1.799631e-02 -0.674198
2019-11-05 13:42:13,544 training loss; R2: 1.800503e-02 -0.691623
2019-11-05 13:42:14,141 valid 000 1.383217e-02 -0.830812
2019-11-05 13:42:23,984 valid 050 1.543306e-02 -0.825202
2019-11-05 13:42:32,657 validation loss; R2: 1.570250e-02 -0.824194
2019-11-05 13:42:32,725 epoch 73 lr 1.000000e-04
2019-11-05 13:42:33,455 train 000 1.943055e-02 -0.938755
2019-11-05 13:42:43,676 train 050 1.813760e-02 -0.515510
2019-11-05 13:42:53,834 train 100 1.794224e-02 -0.586161
2019-11-05 13:43:04,087 train 150 1.804204e-02 -0.561267
2019-11-05 13:43:14,258 train 200 1.792095e-02 -0.604793
2019-11-05 13:43:24,387 train 250 1.796671e-02 -0.594366
2019-11-05 13:43:34,607 train 300 1.802529e-02 -0.610122
2019-11-05 13:43:44,815 train 350 1.806727e-02 -0.640033
2019-11-05 13:43:54,923 train 400 1.800686e-02 -0.623868
2019-11-05 13:44:05,117 train 450 1.798386e-02 -0.620752
2019-11-05 13:44:15,305 train 500 1.797185e-02 -0.647867
2019-11-05 13:44:25,407 train 550 1.798321e-02 -0.648805
2019-11-05 13:44:35,575 train 600 1.798234e-02 -0.658021
2019-11-05 13:44:45,758 train 650 1.797862e-02 -0.653299
2019-11-05 13:44:55,884 train 700 1.796291e-02 -0.667885
2019-11-05 13:45:05,964 train 750 1.797849e-02 -0.661893
2019-11-05 13:45:16,167 train 800 1.796571e-02 -0.651994
2019-11-05 13:45:26,310 train 850 1.798051e-02 -0.660969
2019-11-05 13:45:29,330 training loss; R2: 1.799432e-02 -0.657666
2019-11-05 13:45:29,906 valid 000 1.537031e-02 -0.081744
2019-11-05 13:45:39,704 valid 050 1.546344e-02 -0.840077
2019-11-05 13:45:48,344 validation loss; R2: 1.573636e-02 -0.873407
2019-11-05 13:45:48,406 epoch 74 lr 1.000000e-04
2019-11-05 13:45:49,075 train 000 1.672572e-02 0.034986
2019-11-05 13:45:59,294 train 050 1.873509e-02 -0.522102
2019-11-05 13:46:09,484 train 100 1.834362e-02 -0.610034
2019-11-05 13:46:19,659 train 150 1.823254e-02 -0.596633
2019-11-05 13:46:29,828 train 200 1.796907e-02 -0.634134
2019-11-05 13:46:39,972 train 250 1.797943e-02 -0.660433
2019-11-05 13:46:50,118 train 300 1.799869e-02 -0.622122
2019-11-05 13:47:00,266 train 350 1.798537e-02 -0.669381
2019-11-05 13:47:10,386 train 400 1.794743e-02 -0.688823
2019-11-05 13:47:20,543 train 450 1.796183e-02 -0.662304
2019-11-05 13:47:30,688 train 500 1.796171e-02 -0.671124
2019-11-05 13:47:40,839 train 550 1.796885e-02 -0.673335
2019-11-05 13:47:50,958 train 600 1.795587e-02 -0.659869
2019-11-05 13:48:01,153 train 650 1.795250e-02 -0.691148
2019-11-05 13:48:11,333 train 700 1.796274e-02 -0.696008
2019-11-05 13:48:21,517 train 750 1.796478e-02 -0.697792
2019-11-05 13:48:31,702 train 800 1.794219e-02 -0.701091
2019-11-05 13:48:41,917 train 850 1.793867e-02 -0.698581
2019-11-05 13:48:44,959 training loss; R2: 1.793664e-02 -0.695923
2019-11-05 13:48:45,476 valid 000 1.304205e-02 -0.003528
2019-11-05 13:48:55,335 valid 050 1.527831e-02 -1.014921
2019-11-05 13:49:04,010 validation loss; R2: 1.520364e-02 -1.036978
2019-11-05 13:49:04,067 epoch 75 lr 1.000000e-04
2019-11-05 13:49:04,784 train 000 1.869063e-02 -5.118245
2019-11-05 13:49:15,029 train 050 1.769427e-02 -0.802903
2019-11-05 13:49:25,252 train 100 1.808066e-02 -0.679340
2019-11-05 13:49:35,459 train 150 1.795049e-02 -1.074227
2019-11-05 13:49:45,665 train 200 1.792231e-02 -0.937816
2019-11-05 13:49:55,859 train 250 1.792016e-02 -0.833751
2019-11-05 13:50:06,003 train 300 1.795898e-02 -0.785364
2019-11-05 13:50:16,135 train 350 1.792578e-02 -0.771415
2019-11-05 13:50:26,273 train 400 1.791700e-02 -0.765364
2019-11-05 13:50:36,394 train 450 1.791326e-02 -0.735593
2019-11-05 13:50:46,560 train 500 1.792537e-02 -0.756208
2019-11-05 13:50:56,730 train 550 1.789682e-02 -0.741300
2019-11-05 13:51:06,951 train 600 1.786246e-02 -0.724581
2019-11-05 13:51:17,162 train 650 1.789722e-02 -0.740678
2019-11-05 13:51:27,361 train 700 1.790603e-02 -0.741658
2019-11-05 13:51:37,585 train 750 1.791529e-02 -0.731819
2019-11-05 13:51:47,785 train 800 1.793702e-02 -0.734764
2019-11-05 13:51:57,946 train 850 1.793850e-02 -0.727049
2019-11-05 13:52:00,980 training loss; R2: 1.794918e-02 -0.722406
2019-11-05 13:52:01,501 valid 000 1.468511e-02 -0.049666
2019-11-05 13:52:11,297 valid 050 1.601081e-02 -0.973289
2019-11-05 13:52:19,942 validation loss; R2: 1.578684e-02 -0.946520
2019-11-05 13:52:20,006 epoch 76 lr 1.000000e-04
2019-11-05 13:52:20,701 train 000 1.879800e-02 -2.435977
2019-11-05 13:52:30,956 train 050 1.814011e-02 -0.520202
2019-11-05 13:52:41,172 train 100 1.818029e-02 -0.540327
2019-11-05 13:52:51,358 train 150 1.812570e-02 -0.622716
2019-11-05 13:53:01,581 train 200 1.808084e-02 -0.603094
2019-11-05 13:53:11,794 train 250 1.801338e-02 -0.576777
2019-11-05 13:53:22,020 train 300 1.805485e-02 -0.619286
2019-11-05 13:53:32,250 train 350 1.808573e-02 -1.267164
2019-11-05 13:53:42,420 train 400 1.804453e-02 -1.191235
2019-11-05 13:53:52,604 train 450 1.801774e-02 -1.129893
2019-11-05 13:54:02,756 train 500 1.799012e-02 -1.115305
2019-11-05 13:54:12,966 train 550 1.798813e-02 -1.091094
2019-11-05 13:54:23,135 train 600 1.794766e-02 -1.161650
2019-11-05 13:54:33,324 train 650 1.792540e-02 -1.121085
2019-11-05 13:54:43,516 train 700 1.790869e-02 -1.087173
2019-11-05 13:54:53,721 train 750 1.790366e-02 -1.047774
2019-11-05 13:55:03,902 train 800 1.788678e-02 -1.020309
2019-11-05 13:55:14,113 train 850 1.786333e-02 -1.001318
2019-11-05 13:55:17,157 training loss; R2: 1.786793e-02 -0.993690
2019-11-05 13:55:17,752 valid 000 1.487351e-02 -0.199373
2019-11-05 13:55:27,609 valid 050 1.544980e-02 -0.897702
2019-11-05 13:55:36,613 validation loss; R2: 1.519297e-02 -1.119996
2019-11-05 13:55:36,697 epoch 77 lr 1.000000e-04
2019-11-05 13:55:37,600 train 000 2.098687e-02 -0.541946
2019-11-05 13:55:48,621 train 050 1.797600e-02 -0.667618
2019-11-05 13:55:59,341 train 100 1.784422e-02 -0.733425
2019-11-05 13:56:09,999 train 150 1.786341e-02 -0.688556
2019-11-05 13:56:20,314 train 200 1.779114e-02 -0.650996
2019-11-05 13:56:31,034 train 250 1.771562e-02 -0.659066
2019-11-05 13:56:41,278 train 300 1.777294e-02 -0.633629
2019-11-05 13:56:51,843 train 350 1.781981e-02 -0.635748
2019-11-05 13:57:02,858 train 400 1.787540e-02 -0.647726
2019-11-05 13:57:13,116 train 450 1.786070e-02 -0.765168
2019-11-05 13:57:23,427 train 500 1.786702e-02 -0.755958
2019-11-05 13:57:34,948 train 550 1.785184e-02 -0.739260
2019-11-05 13:57:45,470 train 600 1.785601e-02 -0.715437
2019-11-05 13:57:55,797 train 650 1.784657e-02 -0.701869
2019-11-05 13:58:06,040 train 700 1.784119e-02 -0.704401
2019-11-05 13:58:16,243 train 750 1.783894e-02 -0.705376
2019-11-05 13:58:26,456 train 800 1.781896e-02 -0.707462
2019-11-05 13:58:36,870 train 850 1.780480e-02 -0.715679
2019-11-05 13:58:40,051 training loss; R2: 1.779888e-02 -0.719649
2019-11-05 13:58:40,672 valid 000 1.413067e-02 -4.159170
2019-11-05 13:58:50,793 valid 050 1.506295e-02 -0.749952
2019-11-05 13:58:59,481 validation loss; R2: 1.497292e-02 -0.586444
2019-11-05 13:58:59,549 epoch 78 lr 1.000000e-04
2019-11-05 13:59:00,269 train 000 1.779430e-02 -0.174491
2019-11-05 13:59:10,499 train 050 1.729090e-02 -0.612595
2019-11-05 13:59:20,686 train 100 1.755191e-02 -0.652640
2019-11-05 13:59:30,962 train 150 1.769795e-02 -0.607855
2019-11-05 13:59:41,304 train 200 1.771947e-02 -0.668648
2019-11-05 13:59:51,567 train 250 1.767795e-02 -0.679727
2019-11-05 14:00:01,929 train 300 1.774567e-02 -0.662934
2019-11-05 14:00:12,097 train 350 1.780081e-02 -0.686473
2019-11-05 14:00:22,251 train 400 1.778446e-02 -0.702261
2019-11-05 14:00:32,410 train 450 1.776294e-02 -0.690035
2019-11-05 14:00:42,598 train 500 1.774474e-02 -0.747622
2019-11-05 14:00:52,815 train 550 1.780740e-02 -0.718838
2019-11-05 14:01:02,999 train 600 1.783878e-02 -1.160585
2019-11-05 14:01:13,174 train 650 1.787507e-02 -1.119285
2019-11-05 14:01:23,349 train 700 1.786371e-02 -1.108604
2019-11-05 14:01:33,514 train 750 1.787473e-02 -1.080017
2019-11-05 14:01:43,684 train 800 1.786241e-02 -1.075404
2019-11-05 14:01:53,850 train 850 1.788309e-02 -1.042004
2019-11-05 14:01:56,876 training loss; R2: 1.788047e-02 -1.030545
2019-11-05 14:01:57,404 valid 000 1.883501e-02 -8.923721
2019-11-05 14:02:07,196 valid 050 1.593960e-02 -1.128173
2019-11-05 14:02:15,856 validation loss; R2: 1.571207e-02 -1.171798
2019-11-05 14:02:15,926 epoch 79 lr 1.000000e-04
2019-11-05 14:02:16,675 train 000 1.805645e-02 -1.841596
2019-11-05 14:02:26,922 train 050 1.784720e-02 -0.617453
2019-11-05 14:02:37,170 train 100 1.791086e-02 -0.620581
2019-11-05 14:02:47,366 train 150 1.788579e-02 -0.617613
2019-11-05 14:02:57,548 train 200 1.779300e-02 -0.708867
2019-11-05 14:03:07,731 train 250 1.779454e-02 -0.719856
2019-11-05 14:03:17,893 train 300 1.787688e-02 -0.705937
2019-11-05 14:03:28,053 train 350 1.788303e-02 -0.687721
2019-11-05 14:03:38,202 train 400 1.791935e-02 -0.716204
2019-11-05 14:03:48,358 train 450 1.793886e-02 -0.738674
2019-11-05 14:03:58,558 train 500 1.792844e-02 -0.779069
2019-11-05 14:04:08,759 train 550 1.789899e-02 -0.795164
2019-11-05 14:04:18,946 train 600 1.787348e-02 -0.854836
2019-11-05 14:04:29,125 train 650 1.788803e-02 -0.835565
2019-11-05 14:04:39,296 train 700 1.788941e-02 -0.816893
2019-11-05 14:04:49,452 train 750 1.790152e-02 -0.792437
2019-11-05 14:04:59,618 train 800 1.789285e-02 -0.791690
2019-11-05 14:05:09,778 train 850 1.787927e-02 -0.783858
2019-11-05 14:05:12,811 training loss; R2: 1.787567e-02 -0.777737
2019-11-05 14:05:13,332 valid 000 1.516764e-02 -0.976212
2019-11-05 14:05:23,172 valid 050 1.544530e-02 -1.061569
2019-11-05 14:05:31,814 validation loss; R2: 1.545103e-02 -1.350949
2019-11-05 14:05:31,879 epoch 80 lr 1.000000e-04
2019-11-05 14:05:32,589 train 000 1.842504e-02 -0.471186
2019-11-05 14:05:42,775 train 050 1.898348e-02 -1.877434
2019-11-05 14:05:52,992 train 100 1.835408e-02 -1.438722
2019-11-05 14:06:03,230 train 150 1.802713e-02 -1.246433
2019-11-05 14:06:13,318 train 200 1.796529e-02 -1.097416
2019-11-05 14:06:23,490 train 250 1.792374e-02 -0.945501
2019-11-05 14:06:33,721 train 300 1.792777e-02 -0.879474
2019-11-05 14:06:43,838 train 350 1.785071e-02 -0.851529
2019-11-05 14:06:54,002 train 400 1.786741e-02 -0.812442
2019-11-05 14:07:04,219 train 450 1.782702e-02 -0.817994
2019-11-05 14:07:14,325 train 500 1.780587e-02 -0.967303
2019-11-05 14:07:24,485 train 550 1.783330e-02 -0.929715
2019-11-05 14:07:34,713 train 600 1.782922e-02 -0.897113
2019-11-05 14:07:44,801 train 650 1.779767e-02 -0.893988
2019-11-05 14:07:54,885 train 700 1.781192e-02 -0.873883
2019-11-05 14:08:05,060 train 750 1.780212e-02 -0.857262
2019-11-05 14:08:15,145 train 800 1.779534e-02 -0.850913
2019-11-05 14:08:25,263 train 850 1.779263e-02 -0.844104
2019-11-05 14:08:28,315 training loss; R2: 1.780257e-02 -0.840031
2019-11-05 14:08:28,836 valid 000 1.586490e-02 -1.267896
2019-11-05 14:08:38,650 valid 050 1.651725e-02 -1.430767
2019-11-05 14:08:47,294 validation loss; R2: 1.654321e-02 -3.135256
2019-11-05 14:08:47,358 epoch 81 lr 1.000000e-04
2019-11-05 14:08:48,049 train 000 1.722944e-02 -0.378591
2019-11-05 14:08:58,222 train 050 1.781668e-02 -0.653488
2019-11-05 14:09:08,380 train 100 1.771225e-02 -0.700752
2019-11-05 14:09:18,550 train 150 1.783575e-02 -0.682284
2019-11-05 14:09:28,706 train 200 1.793297e-02 -0.669521
2019-11-05 14:09:38,868 train 250 1.790342e-02 -0.733115
2019-11-05 14:09:49,014 train 300 1.796124e-02 -0.731632
2019-11-05 14:09:59,157 train 350 1.798577e-02 -0.735187
2019-11-05 14:10:09,291 train 400 1.796425e-02 -0.729093
2019-11-05 14:10:19,427 train 450 1.792066e-02 -0.708867
2019-11-05 14:10:29,587 train 500 1.791227e-02 -0.686147
2019-11-05 14:10:39,736 train 550 1.788053e-02 -0.711754
2019-11-05 14:10:49,894 train 600 1.787859e-02 -0.697464
2019-11-05 14:11:00,074 train 650 1.786727e-02 -0.679248
2019-11-05 14:11:10,257 train 700 1.786313e-02 -0.675487
2019-11-05 14:11:20,437 train 750 1.787918e-02 -0.677079
2019-11-05 14:11:30,578 train 800 1.786198e-02 -0.681269
2019-11-05 14:11:40,747 train 850 1.782697e-02 -0.683108
2019-11-05 14:11:43,786 training loss; R2: 1.782069e-02 -0.686088
2019-11-05 14:11:44,324 valid 000 1.911654e-02 -0.237430
2019-11-05 14:11:54,262 valid 050 1.603768e-02 -1.224616
2019-11-05 14:12:03,106 validation loss; R2: 1.625812e-02 -1.360219
2019-11-05 14:12:03,182 epoch 82 lr 1.000000e-04
2019-11-05 14:12:03,943 train 000 1.660086e-02 -0.985017
2019-11-05 14:12:14,329 train 050 1.761311e-02 -0.469243
2019-11-05 14:12:24,563 train 100 1.774546e-02 -0.610614
2019-11-05 14:12:34,738 train 150 1.766102e-02 -0.632077
2019-11-05 14:12:44,910 train 200 1.772435e-02 -0.656145
2019-11-05 14:12:55,063 train 250 1.768610e-02 -0.628052
2019-11-05 14:13:05,222 train 300 1.767258e-02 -0.649765
2019-11-05 14:13:15,366 train 350 1.771591e-02 -0.651892
2019-11-05 14:13:25,541 train 400 1.771853e-02 -0.623005
2019-11-05 14:13:35,691 train 450 1.771549e-02 -0.648735
2019-11-05 14:13:45,853 train 500 1.768221e-02 -0.668268
2019-11-05 14:13:56,036 train 550 1.772630e-02 -0.673839
2019-11-05 14:14:06,458 train 600 1.774259e-02 -0.665661
2019-11-05 14:14:16,573 train 650 1.772875e-02 -0.686211
2019-11-05 14:14:26,687 train 700 1.772713e-02 -0.691507
2019-11-05 14:14:36,799 train 750 1.772490e-02 -0.683277
2019-11-05 14:14:47,003 train 800 1.775056e-02 -0.673886
2019-11-05 14:14:57,199 train 850 1.779168e-02 -0.669977
2019-11-05 14:15:00,256 training loss; R2: 1.778474e-02 -0.674203
2019-11-05 14:15:00,778 valid 000 1.781882e-02 -1.458008
2019-11-05 14:15:10,633 valid 050 1.567311e-02 -1.691392
2019-11-05 14:15:19,407 validation loss; R2: 1.569701e-02 -1.518780
2019-11-05 14:15:19,470 epoch 83 lr 1.000000e-04
2019-11-05 14:15:20,140 train 000 1.723650e-02 -0.606811
2019-11-05 14:15:30,498 train 050 1.751596e-02 -0.722567
2019-11-05 14:15:40,754 train 100 1.782673e-02 -0.629671
2019-11-05 14:15:50,929 train 150 1.778861e-02 -0.655469
2019-11-05 14:16:01,059 train 200 1.781898e-02 -0.697121
2019-11-05 14:16:11,223 train 250 1.778173e-02 -0.675890
2019-11-05 14:16:21,390 train 300 1.770907e-02 -0.728841
2019-11-05 14:16:31,546 train 350 1.772366e-02 -0.848988
2019-11-05 14:16:41,717 train 400 1.775015e-02 -0.856775
2019-11-05 14:16:51,903 train 450 1.773033e-02 -0.826504
2019-11-05 14:17:02,057 train 500 1.771639e-02 -0.823599
2019-11-05 14:17:12,218 train 550 1.776498e-02 -0.885641
2019-11-05 14:17:22,386 train 600 1.779225e-02 -0.864519
2019-11-05 14:17:32,547 train 650 1.779867e-02 -0.836917
2019-11-05 14:17:42,724 train 700 1.776978e-02 -0.843295
2019-11-05 14:17:52,925 train 750 1.775679e-02 -0.833448
2019-11-05 14:18:03,121 train 800 1.777380e-02 -0.829775
2019-11-05 14:18:13,564 train 850 1.776706e-02 -0.821061
2019-11-05 14:18:16,594 training loss; R2: 1.776399e-02 -0.812510
2019-11-05 14:18:17,194 valid 000 1.719364e-02 -1.443568
2019-11-05 14:18:27,868 valid 050 1.613107e-02 -4.431646
2019-11-05 14:18:37,061 validation loss; R2: 1.608446e-02 -3.306280
2019-11-05 14:18:37,138 epoch 84 lr 1.000000e-04
2019-11-05 14:18:37,914 train 000 1.913908e-02 -3.517341
2019-11-05 14:18:48,488 train 050 1.770514e-02 -0.580827
2019-11-05 14:18:58,999 train 100 1.773035e-02 -0.595955
2019-11-05 14:19:09,349 train 150 1.778072e-02 -0.686961
2019-11-05 14:19:19,881 train 200 1.779116e-02 -0.704909
2019-11-05 14:19:30,215 train 250 1.786381e-02 -0.698745
2019-11-05 14:19:40,453 train 300 1.789417e-02 -0.690354
2019-11-05 14:19:50,885 train 350 1.787040e-02 -0.659000
2019-11-05 14:20:01,082 train 400 1.786495e-02 -0.680722
2019-11-05 14:20:11,319 train 450 1.784049e-02 -0.716754
2019-11-05 14:20:21,482 train 500 1.780603e-02 -0.746587
2019-11-05 14:20:31,659 train 550 1.778458e-02 -0.751110
2019-11-05 14:20:42,313 train 600 1.773880e-02 -0.753430
2019-11-05 14:20:52,786 train 650 1.773984e-02 -0.742370
2019-11-05 14:21:02,974 train 700 1.771741e-02 -0.759291
2019-11-05 14:21:13,175 train 750 1.770197e-02 -0.760642
2019-11-05 14:21:23,553 train 800 1.769034e-02 -0.765226
2019-11-05 14:21:33,782 train 850 1.772276e-02 -0.747053
2019-11-05 14:21:36,824 training loss; R2: 1.772182e-02 -0.742811
2019-11-05 14:21:37,411 valid 000 1.634220e-02 -3.606823
2019-11-05 14:21:47,389 valid 050 1.556452e-02 -1.497234
2019-11-05 14:21:56,098 validation loss; R2: 1.562506e-02 -1.434303
2019-11-05 14:21:56,168 epoch 85 lr 1.000000e-04
2019-11-05 14:21:56,938 train 000 1.788334e-02 -0.339696
2019-11-05 14:22:07,047 train 050 1.754111e-02 -0.610162
2019-11-05 14:22:17,248 train 100 1.761436e-02 -0.632786
2019-11-05 14:22:27,534 train 150 1.773926e-02 -0.789016
2019-11-05 14:22:37,601 train 200 1.775007e-02 -0.760273
2019-11-05 14:22:48,013 train 250 1.779641e-02 -0.763185
2019-11-05 14:22:58,336 train 300 1.783449e-02 -0.760513
2019-11-05 14:23:08,442 train 350 1.791423e-02 -0.732970
2019-11-05 14:23:18,474 train 400 1.788591e-02 -0.729667
2019-11-05 14:23:28,610 train 450 1.783092e-02 -0.732063
2019-11-05 14:23:38,718 train 500 1.781872e-02 -0.748469
2019-11-05 14:23:48,737 train 550 1.779314e-02 -0.745522
2019-11-05 14:23:58,849 train 600 1.775943e-02 -0.746994
2019-11-05 14:24:08,997 train 650 1.774315e-02 -0.750424
2019-11-05 14:24:19,048 train 700 1.772724e-02 -0.730974
2019-11-05 14:24:29,120 train 750 1.772356e-02 -0.741456
2019-11-05 14:24:39,629 train 800 1.771658e-02 -0.729895
2019-11-05 14:24:49,960 train 850 1.771964e-02 -0.743414
2019-11-05 14:24:52,984 training loss; R2: 1.772303e-02 -0.743703
2019-11-05 14:24:53,507 valid 000 1.413854e-02 -0.593668
2019-11-05 14:25:03,406 valid 050 1.477899e-02 -0.804713
2019-11-05 14:25:12,200 validation loss; R2: 1.494349e-02 -0.904664
2019-11-05 14:25:12,265 epoch 86 lr 1.000000e-04
2019-11-05 14:25:13,046 train 000 1.555823e-02 -0.855770
2019-11-05 14:25:23,304 train 050 1.758008e-02 -0.787048
2019-11-05 14:25:33,471 train 100 1.770727e-02 -0.779562
2019-11-05 14:25:43,763 train 150 1.759393e-02 -0.685658
2019-11-05 14:25:53,934 train 200 1.764887e-02 -1.028526
2019-11-05 14:26:04,236 train 250 1.766175e-02 -0.987788
2019-11-05 14:26:14,376 train 300 1.762460e-02 -0.926933
2019-11-05 14:26:24,559 train 350 1.761894e-02 -0.884464
2019-11-05 14:26:34,763 train 400 1.769995e-02 -0.863990
2019-11-05 14:26:44,875 train 450 1.771468e-02 -0.819541
2019-11-05 14:26:55,107 train 500 1.769592e-02 -0.822855
2019-11-05 14:27:05,251 train 550 1.772870e-02 -0.802377
2019-11-05 14:27:15,879 train 600 1.770378e-02 -0.804347
2019-11-05 14:27:26,300 train 650 1.769421e-02 -0.796700
2019-11-05 14:27:36,718 train 700 1.769916e-02 -0.776811
2019-11-05 14:27:46,846 train 750 1.770352e-02 -0.768231
2019-11-05 14:27:56,909 train 800 1.771506e-02 -0.756061
2019-11-05 14:28:07,013 train 850 1.771509e-02 -0.757592
2019-11-05 14:28:10,046 training loss; R2: 1.771841e-02 -0.759016
2019-11-05 14:28:10,565 valid 000 1.658257e-02 -11.077654
2019-11-05 14:28:20,576 valid 050 1.544412e-02 -1.194752
2019-11-05 14:28:29,394 validation loss; R2: 1.537616e-02 -1.213743
2019-11-05 14:28:29,458 epoch 87 lr 1.000000e-04
2019-11-05 14:28:30,138 train 000 1.797335e-02 -0.251695
2019-11-05 14:28:40,359 train 050 1.708063e-02 -0.815423
2019-11-05 14:28:50,570 train 100 1.738755e-02 -0.684969
2019-11-05 14:29:00,762 train 150 1.752899e-02 -0.704726
2019-11-05 14:29:10,961 train 200 1.759932e-02 -0.679058
2019-11-05 14:29:21,187 train 250 1.754595e-02 -0.661627
2019-11-05 14:29:31,390 train 300 1.754527e-02 -0.634478
2019-11-05 14:29:41,597 train 350 1.750866e-02 -0.618632
2019-11-05 14:29:51,820 train 400 1.754988e-02 -0.619539
2019-11-05 14:30:02,001 train 450 1.757040e-02 -1.978139
2019-11-05 14:30:12,196 train 500 1.757980e-02 -1.845466
2019-11-05 14:30:22,389 train 550 1.761356e-02 -1.757193
2019-11-05 14:30:32,539 train 600 1.770069e-02 -1.658638
2019-11-05 14:30:42,698 train 650 1.769792e-02 -1.602662
2019-11-05 14:30:52,839 train 700 1.770937e-02 -1.544731
2019-11-05 14:31:03,201 train 750 1.770916e-02 -1.501264
2019-11-05 14:31:13,494 train 800 1.766127e-02 -1.463413
2019-11-05 14:31:23,757 train 850 1.765558e-02 -1.406385
2019-11-05 14:31:26,892 training loss; R2: 1.766694e-02 -1.392383
2019-11-05 14:31:27,411 valid 000 1.384134e-02 -1.077312
2019-11-05 14:31:37,416 valid 050 1.564347e-02 -1.580963
2019-11-05 14:31:46,059 validation loss; R2: 1.574963e-02 -1.287975
2019-11-05 14:31:46,125 epoch 88 lr 1.000000e-04
2019-11-05 14:31:46,867 train 000 1.633151e-02 -0.664220
2019-11-05 14:31:57,204 train 050 1.708410e-02 -0.581227
2019-11-05 14:32:07,380 train 100 1.744187e-02 -1.831921
2019-11-05 14:32:17,530 train 150 1.722743e-02 -1.475674
2019-11-05 14:32:27,683 train 200 1.736264e-02 -1.268881
2019-11-05 14:32:38,154 train 250 1.734223e-02 -1.129306
2019-11-05 14:32:48,608 train 300 1.739313e-02 -1.086729
2019-11-05 14:32:58,871 train 350 1.751287e-02 -0.999511
2019-11-05 14:33:09,157 train 400 1.754182e-02 -0.929120
2019-11-05 14:33:19,408 train 450 1.754103e-02 -0.913818
2019-11-05 14:33:29,597 train 500 1.753143e-02 -0.891952
2019-11-05 14:33:39,854 train 550 1.746549e-02 -0.914134
2019-11-05 14:33:50,063 train 600 1.747756e-02 -0.876192
2019-11-05 14:34:00,201 train 650 1.749645e-02 -0.851481
2019-11-05 14:34:10,364 train 700 1.750567e-02 -0.829000
2019-11-05 14:34:20,498 train 750 1.753289e-02 -0.821603
2019-11-05 14:34:30,668 train 800 1.753515e-02 -0.807818
2019-11-05 14:34:40,809 train 850 1.755417e-02 -0.784279
2019-11-05 14:34:43,843 training loss; R2: 1.756320e-02 -0.786310
2019-11-05 14:34:44,362 valid 000 1.648285e-02 -0.018945
2019-11-05 14:34:54,200 valid 050 1.486483e-02 -0.827888
2019-11-05 14:35:02,865 validation loss; R2: 1.480925e-02 -0.752360
2019-11-05 14:35:02,929 epoch 89 lr 1.000000e-04
2019-11-05 14:35:03,631 train 000 1.543756e-02 -0.174133
2019-11-05 14:35:14,035 train 050 1.780676e-02 -0.814071
2019-11-05 14:35:24,423 train 100 1.761472e-02 -0.667855
2019-11-05 14:35:34,749 train 150 1.753175e-02 -0.627830
2019-11-05 14:35:45,093 train 200 1.757023e-02 -0.654543
2019-11-05 14:35:55,435 train 250 1.758401e-02 -0.674475
2019-11-05 14:36:05,778 train 300 1.752368e-02 -0.638284
2019-11-05 14:36:16,108 train 350 1.753034e-02 -0.675332
2019-11-05 14:36:26,462 train 400 1.751048e-02 -0.691049
2019-11-05 14:36:36,742 train 450 1.753272e-02 -0.693240
2019-11-05 14:36:47,048 train 500 1.757625e-02 -0.669367
2019-11-05 14:36:57,356 train 550 1.760465e-02 -0.676479
2019-11-05 14:37:07,607 train 600 1.760621e-02 -0.667918
2019-11-05 14:37:17,815 train 650 1.759491e-02 -0.690269
2019-11-05 14:37:28,030 train 700 1.757820e-02 -0.682260
2019-11-05 14:37:38,220 train 750 1.754854e-02 -0.680277
2019-11-05 14:37:48,427 train 800 1.754958e-02 -0.705904
2019-11-05 14:37:58,614 train 850 1.755201e-02 -0.700000
2019-11-05 14:38:01,667 training loss; R2: 1.756348e-02 -0.704966
2019-11-05 14:38:02,211 valid 000 1.619871e-02 -2.644669
2019-11-05 14:38:12,075 valid 050 1.589042e-02 -1.704392
2019-11-05 14:38:20,815 validation loss; R2: 1.594630e-02 -1.554345
2019-11-05 14:38:20,886 epoch 90 lr 1.000000e-04
2019-11-05 14:38:21,654 train 000 1.638445e-02 -0.220940
2019-11-05 14:38:31,881 train 050 1.744145e-02 -1.248974
2019-11-05 14:38:42,089 train 100 1.733975e-02 -0.940953
2019-11-05 14:38:52,277 train 150 1.730273e-02 -0.917464
2019-11-05 14:39:02,482 train 200 1.721696e-02 -0.843843
2019-11-05 14:39:12,661 train 250 1.740802e-02 -0.811456
2019-11-05 14:39:22,829 train 300 1.740615e-02 -0.772137
2019-11-05 14:39:33,022 train 350 1.744996e-02 -0.736801
2019-11-05 14:39:43,232 train 400 1.754038e-02 -0.727280
2019-11-05 14:39:53,381 train 450 1.753272e-02 -0.773244
2019-11-05 14:40:03,601 train 500 1.754574e-02 -0.766265
2019-11-05 14:40:13,796 train 550 1.756899e-02 -0.774895
2019-11-05 14:40:23,995 train 600 1.757044e-02 -0.775184
2019-11-05 14:40:34,148 train 650 1.757384e-02 -0.766730
2019-11-05 14:40:44,326 train 700 1.759181e-02 -0.757687
2019-11-05 14:40:54,464 train 750 1.759141e-02 -0.752643
2019-11-05 14:41:04,648 train 800 1.757470e-02 -0.740758
2019-11-05 14:41:14,801 train 850 1.754836e-02 -0.750989
2019-11-05 14:41:17,839 training loss; R2: 1.753785e-02 -0.747013
2019-11-05 14:41:18,363 valid 000 1.583781e-02 -1.478637
2019-11-05 14:41:28,194 valid 050 1.554826e-02 -1.334718
2019-11-05 14:41:36,853 validation loss; R2: 1.542205e-02 -1.350240
2019-11-05 14:41:36,917 epoch 91 lr 1.000000e-04
2019-11-05 14:41:37,674 train 000 1.650287e-02 -0.227449
2019-11-05 14:41:48,015 train 050 1.792055e-02 -0.753325
2019-11-05 14:41:58,216 train 100 1.762521e-02 -0.806725
2019-11-05 14:42:08,422 train 150 1.774961e-02 -0.825340
2019-11-05 14:42:18,626 train 200 1.773389e-02 -0.777043
2019-11-05 14:42:28,788 train 250 1.767933e-02 -0.781610
2019-11-05 14:42:38,971 train 300 1.759781e-02 -0.760771
2019-11-05 14:42:49,132 train 350 1.767166e-02 -0.748692
2019-11-05 14:42:59,297 train 400 1.762225e-02 -0.723000
2019-11-05 14:43:09,470 train 450 1.760184e-02 -0.693135
2019-11-05 14:43:19,669 train 500 1.761951e-02 -0.674813
2019-11-05 14:43:29,855 train 550 1.760723e-02 -0.690778
2019-11-05 14:43:40,049 train 600 1.760062e-02 -0.721858
2019-11-05 14:43:50,207 train 650 1.760393e-02 -0.714174
2019-11-05 14:44:00,372 train 700 1.759824e-02 -0.710552
2019-11-05 14:44:10,527 train 750 1.757363e-02 -0.712351
2019-11-05 14:44:20,687 train 800 1.756086e-02 -0.714951
2019-11-05 14:44:30,846 train 850 1.757055e-02 -0.711878
2019-11-05 14:44:33,890 training loss; R2: 1.755674e-02 -0.714353
2019-11-05 14:44:34,448 valid 000 1.479598e-02 -0.403199
2019-11-05 14:44:44,284 valid 050 1.574678e-02 -1.160893
2019-11-05 14:44:52,967 validation loss; R2: 1.556753e-02 -1.298557
2019-11-05 14:44:53,035 epoch 92 lr 1.000000e-04
2019-11-05 14:44:53,740 train 000 1.932469e-02 -0.797394
2019-11-05 14:45:03,979 train 050 1.736558e-02 -0.729774
2019-11-05 14:45:14,240 train 100 1.731074e-02 -0.639735
2019-11-05 14:45:24,441 train 150 1.752893e-02 -0.575104
2019-11-05 14:45:34,660 train 200 1.744707e-02 -0.521944
2019-11-05 14:45:44,828 train 250 1.741906e-02 -0.543634
2019-11-05 14:45:54,984 train 300 1.738688e-02 -0.566132
2019-11-05 14:46:05,129 train 350 1.738058e-02 -0.571268
2019-11-05 14:46:15,228 train 400 1.745385e-02 -0.588198
2019-11-05 14:46:25,387 train 450 1.750797e-02 -0.603312
2019-11-05 14:46:35,556 train 500 1.752601e-02 -0.593031
2019-11-05 14:46:45,700 train 550 1.747807e-02 -0.588159
2019-11-05 14:46:55,866 train 600 1.746877e-02 -0.621087
2019-11-05 14:47:06,001 train 650 1.749161e-02 -0.640901
2019-11-05 14:47:16,146 train 700 1.750511e-02 -0.639593
2019-11-05 14:47:26,270 train 750 1.748597e-02 -0.645580
2019-11-05 14:47:36,435 train 800 1.752185e-02 -0.696682
2019-11-05 14:47:46,580 train 850 1.753552e-02 -0.695209
2019-11-05 14:47:49,624 training loss; R2: 1.753733e-02 -0.728290
2019-11-05 14:47:50,215 valid 000 1.383536e-02 -0.889508
2019-11-05 14:48:00,012 valid 050 1.521258e-02 -1.067299
2019-11-05 14:48:08,990 validation loss; R2: 1.534348e-02 -1.005023
2019-11-05 14:48:09,065 epoch 93 lr 1.000000e-04
2019-11-05 14:48:09,824 train 000 1.857235e-02 -0.570789
2019-11-05 14:48:20,039 train 050 1.751324e-02 -0.738543
2019-11-05 14:48:30,266 train 100 1.762134e-02 -0.640932
2019-11-05 14:48:40,473 train 150 1.758735e-02 -0.612672
2019-11-05 14:48:50,695 train 200 1.756959e-02 -0.598765
2019-11-05 14:49:00,899 train 250 1.760052e-02 -0.654161
2019-11-05 14:49:11,110 train 300 1.758901e-02 -0.653150
2019-11-05 14:49:21,319 train 350 1.759973e-02 -0.650372
2019-11-05 14:49:31,537 train 400 1.760127e-02 -0.679071
2019-11-05 14:49:41,725 train 450 1.759609e-02 -0.704943
2019-11-05 14:49:51,977 train 500 1.755715e-02 -0.704556
2019-11-05 14:50:02,158 train 550 1.757561e-02 -0.707400
2019-11-05 14:50:12,350 train 600 1.756543e-02 -0.693693
2019-11-05 14:50:22,521 train 650 1.755348e-02 -0.684129
2019-11-05 14:50:32,712 train 700 1.754262e-02 -0.678911
2019-11-05 14:50:42,881 train 750 1.754507e-02 -0.691131
2019-11-05 14:50:53,086 train 800 1.751933e-02 -0.679095
2019-11-05 14:51:03,256 train 850 1.753935e-02 -0.679576
2019-11-05 14:51:06,304 training loss; R2: 1.752908e-02 -0.675815
2019-11-05 14:51:06,870 valid 000 1.539178e-02 0.011670
2019-11-05 14:51:16,718 valid 050 1.570515e-02 -1.222406
2019-11-05 14:51:25,440 validation loss; R2: 1.569069e-02 -1.247348
2019-11-05 14:51:25,506 epoch 94 lr 1.000000e-04
2019-11-05 14:51:26,211 train 000 1.940856e-02 -1.701773
2019-11-05 14:51:36,464 train 050 1.794150e-02 -0.847995
2019-11-05 14:51:46,707 train 100 1.766892e-02 -0.893825
2019-11-05 14:51:56,920 train 150 1.756141e-02 -0.852413
2019-11-05 14:52:07,139 train 200 1.758332e-02 -0.808976
2019-11-05 14:52:17,311 train 250 1.757524e-02 -0.795080
2019-11-05 14:52:27,485 train 300 1.756492e-02 -0.741969
2019-11-05 14:52:37,637 train 350 1.754725e-02 -0.772702
2019-11-05 14:52:47,822 train 400 1.752993e-02 -0.758712
2019-11-05 14:52:57,949 train 450 1.749197e-02 -0.744003
2019-11-05 14:53:08,018 train 500 1.748465e-02 -0.714367
2019-11-05 14:53:18,071 train 550 1.749052e-02 -0.734182
2019-11-05 14:53:28,142 train 600 1.749089e-02 -0.725984
2019-11-05 14:53:38,163 train 650 1.747862e-02 -0.695249
2019-11-05 14:53:48,221 train 700 1.748345e-02 -0.707722
2019-11-05 14:53:58,269 train 750 1.746733e-02 -0.691006
2019-11-05 14:54:08,350 train 800 1.745594e-02 -0.689884
2019-11-05 14:54:18,403 train 850 1.743958e-02 -0.680123
2019-11-05 14:54:21,422 training loss; R2: 1.745070e-02 -0.678875
2019-11-05 14:54:21,934 valid 000 1.423260e-02 -0.015496
2019-11-05 14:54:31,745 valid 050 1.562599e-02 -2.060167
2019-11-05 14:54:40,425 validation loss; R2: 1.593147e-02 -1.609393
2019-11-05 14:54:40,496 epoch 95 lr 1.000000e-04
2019-11-05 14:54:41,203 train 000 1.650214e-02 -1.150393
2019-11-05 14:54:51,376 train 050 1.752437e-02 -0.963240
2019-11-05 14:55:01,592 train 100 1.757437e-02 -1.005233
2019-11-05 14:55:11,775 train 150 1.760311e-02 -0.883729
2019-11-05 14:55:21,974 train 200 1.758290e-02 -0.861224
2019-11-05 14:55:32,132 train 250 1.759209e-02 -0.856128
2019-11-05 14:55:42,304 train 300 1.760015e-02 -0.897883
2019-11-05 14:55:52,477 train 350 1.756360e-02 -0.858246
2019-11-05 14:56:02,650 train 400 1.755371e-02 -0.832335
2019-11-05 14:56:12,836 train 450 1.754824e-02 -0.827359
2019-11-05 14:56:23,009 train 500 1.755926e-02 -0.792992
2019-11-05 14:56:33,164 train 550 1.760390e-02 -0.776681
2019-11-05 14:56:43,354 train 600 1.762107e-02 -0.765654
2019-11-05 14:56:53,506 train 650 1.759187e-02 -0.857482
2019-11-05 14:57:03,681 train 700 1.755997e-02 -0.834697
2019-11-05 14:57:13,826 train 750 1.756009e-02 -0.820893
2019-11-05 14:57:24,032 train 800 1.752726e-02 -0.806878
2019-11-05 14:57:34,208 train 850 1.750929e-02 -0.784447
2019-11-05 14:57:37,242 training loss; R2: 1.751299e-02 -0.789057
2019-11-05 14:57:37,832 valid 000 1.817418e-02 -0.526377
2019-11-05 14:57:47,642 valid 050 1.490702e-02 -2.890207
2019-11-05 14:57:56,315 validation loss; R2: 1.488270e-02 -2.168197
2019-11-05 14:57:56,381 epoch 96 lr 1.000000e-04
2019-11-05 14:57:57,053 train 000 2.215614e-02 -0.418525
2019-11-05 14:58:07,276 train 050 1.742365e-02 -0.517679
2019-11-05 14:58:17,489 train 100 1.744008e-02 -0.613298
2019-11-05 14:58:27,641 train 150 1.745688e-02 -0.701073
2019-11-05 14:58:37,812 train 200 1.745431e-02 -0.712643
2019-11-05 14:58:47,933 train 250 1.743366e-02 -0.715047
2019-11-05 14:58:58,090 train 300 1.747802e-02 -0.689427
2019-11-05 14:59:08,218 train 350 1.746077e-02 -0.715045
2019-11-05 14:59:18,387 train 400 1.745663e-02 -0.778359
2019-11-05 14:59:28,499 train 450 1.745105e-02 -0.805758
2019-11-05 14:59:38,692 train 500 1.746027e-02 -1.469653
2019-11-05 14:59:48,894 train 550 1.744784e-02 -1.433416
2019-11-05 14:59:59,119 train 600 1.742818e-02 -1.373751
2019-11-05 15:00:09,284 train 650 1.743054e-02 -1.328422
2019-11-05 15:00:19,485 train 700 1.741861e-02 -1.291637
2019-11-05 15:00:29,639 train 750 1.741823e-02 -1.252169
2019-11-05 15:00:39,824 train 800 1.742172e-02 -1.218450
2019-11-05 15:00:49,994 train 850 1.743491e-02 -1.213010
2019-11-05 15:00:53,038 training loss; R2: 1.743721e-02 -1.201822
2019-11-05 15:00:53,556 valid 000 1.355040e-02 -0.626150
2019-11-05 15:01:03,488 valid 050 1.580977e-02 -1.284393
2019-11-05 15:01:12,222 validation loss; R2: 1.570143e-02 -1.159077
2019-11-05 15:01:12,288 epoch 97 lr 1.000000e-04
2019-11-05 15:01:12,955 train 000 1.756071e-02 0.057916
2019-11-05 15:01:23,157 train 050 1.784204e-02 -1.243340
2019-11-05 15:01:33,435 train 100 1.753600e-02 -1.247592
2019-11-05 15:01:43,701 train 150 1.770014e-02 -1.024410
2019-11-05 15:01:53,823 train 200 1.758744e-02 -0.974731
2019-11-05 15:02:03,999 train 250 1.754534e-02 -0.901964
2019-11-05 15:02:14,267 train 300 1.757780e-02 -0.901741
2019-11-05 15:02:24,523 train 350 1.755982e-02 -0.882648
2019-11-05 15:02:34,759 train 400 1.752871e-02 -0.849014
2019-11-05 15:02:44,984 train 450 1.753051e-02 -0.867420
2019-11-05 15:02:55,221 train 500 1.751450e-02 -0.833706
2019-11-05 15:03:05,394 train 550 1.750418e-02 -0.818644
2019-11-05 15:03:15,606 train 600 1.749893e-02 -0.813721
2019-11-05 15:03:25,764 train 650 1.746298e-02 -0.804794
2019-11-05 15:03:35,950 train 700 1.748507e-02 -0.784163
2019-11-05 15:03:46,082 train 750 1.748600e-02 -0.809461
2019-11-05 15:03:56,238 train 800 1.746881e-02 -0.783645
2019-11-05 15:04:06,372 train 850 1.746633e-02 -0.759495
2019-11-05 15:04:09,405 training loss; R2: 1.745165e-02 -0.758055
2019-11-05 15:04:09,917 valid 000 1.862902e-02 -0.022514
2019-11-05 15:04:19,732 valid 050 1.517080e-02 -1.233816
2019-11-05 15:04:28,418 validation loss; R2: 1.537439e-02 -1.153107
2019-11-05 15:04:28,487 epoch 98 lr 1.000000e-04
2019-11-05 15:04:29,217 train 000 1.840720e-02 -1.027589
2019-11-05 15:04:39,389 train 050 1.732847e-02 -0.614198
2019-11-05 15:04:49,607 train 100 1.747918e-02 -0.699376
2019-11-05 15:04:59,781 train 150 1.741357e-02 -0.705695
2019-11-05 15:05:09,963 train 200 1.739068e-02 -0.731566
2019-11-05 15:05:20,108 train 250 1.737867e-02 -0.744233
2019-11-05 15:05:30,274 train 300 1.740267e-02 -0.714268
2019-11-05 15:05:40,417 train 350 1.741425e-02 -0.751000
2019-11-05 15:05:50,624 train 400 1.746495e-02 -0.735955
2019-11-05 15:06:00,780 train 450 1.746132e-02 -0.744221
2019-11-05 15:06:11,000 train 500 1.747078e-02 -0.740475
2019-11-05 15:06:21,165 train 550 1.745023e-02 -0.724895
2019-11-05 15:06:31,356 train 600 1.742298e-02 -0.728027
2019-11-05 15:06:41,517 train 650 1.742563e-02 -0.706580
2019-11-05 15:06:51,696 train 700 1.741852e-02 -0.689907
2019-11-05 15:07:01,845 train 750 1.740632e-02 -0.718861
2019-11-05 15:07:12,032 train 800 1.740015e-02 -0.709640
2019-11-05 15:07:22,199 train 850 1.740492e-02 -0.715362
2019-11-05 15:07:25,241 training loss; R2: 1.741588e-02 -0.708235
2019-11-05 15:07:25,808 valid 000 1.669637e-02 0.067701
2019-11-05 15:07:35,627 valid 050 1.549017e-02 -0.684156
2019-11-05 15:07:44,345 validation loss; R2: 1.544544e-02 -1.032285
2019-11-05 15:07:44,410 epoch 99 lr 1.000000e-04
2019-11-05 15:07:45,166 train 000 1.699788e-02 -0.673932
2019-11-05 15:07:55,349 train 050 1.759881e-02 -0.536424
2019-11-05 15:08:05,536 train 100 1.756111e-02 -0.669027
2019-11-05 15:08:15,726 train 150 1.735621e-02 -0.721287
2019-11-05 15:08:25,930 train 200 1.732505e-02 -0.675199
2019-11-05 15:08:36,104 train 250 1.744899e-02 -1.266311
2019-11-05 15:08:46,275 train 300 1.743292e-02 -1.189189
2019-11-05 15:08:56,431 train 350 1.745674e-02 -1.087601
2019-11-05 15:09:06,598 train 400 1.749451e-02 -1.024490
2019-11-05 15:09:16,720 train 450 1.749787e-02 -1.176301
2019-11-05 15:09:26,882 train 500 1.748743e-02 -1.129466
2019-11-05 15:09:37,025 train 550 1.751799e-02 -1.077854
2019-11-05 15:09:47,183 train 600 1.748938e-02 -1.079306
2019-11-05 15:09:57,322 train 650 1.749378e-02 -1.072603
2019-11-05 15:10:07,404 train 700 1.748724e-02 -1.036055
2019-11-05 15:10:17,444 train 750 1.748315e-02 -1.006737
2019-11-05 15:10:27,517 train 800 1.748070e-02 -0.985218
2019-11-05 15:10:37,659 train 850 1.749204e-02 -0.973390
2019-11-05 15:10:40,705 training loss; R2: 1.749511e-02 -0.967335
2019-11-05 15:10:41,225 valid 000 1.484639e-02 -0.109012
2019-11-05 15:10:51,056 valid 050 1.565895e-02 -1.701436
2019-11-05 15:10:59,769 validation loss; R2: 1.574108e-02 -1.396745
2019-11-05 15:10:59,836 epoch 100 lr 1.000000e-04
2019-11-05 15:11:00,528 train 000 1.832622e-02 -0.696607
2019-11-05 15:11:10,662 train 050 1.739075e-02 -0.851913
2019-11-05 15:11:20,826 train 100 1.751807e-02 -0.689083
2019-11-05 15:11:31,023 train 150 1.751608e-02 -0.781253
2019-11-05 15:11:41,209 train 200 1.761095e-02 -0.732020
2019-11-05 15:11:51,333 train 250 1.761965e-02 -0.701742
2019-11-05 15:12:01,673 train 300 1.757572e-02 -0.701576
2019-11-05 15:12:11,832 train 350 1.758502e-02 -0.717620
2019-11-05 15:12:22,015 train 400 1.755239e-02 -3.611715
2019-11-05 15:12:32,173 train 450 1.749377e-02 -3.283711
2019-11-05 15:12:42,369 train 500 1.749634e-02 -3.026368
2019-11-05 15:12:52,535 train 550 1.748861e-02 -2.803805
2019-11-05 15:13:02,737 train 600 1.746940e-02 -2.621513
2019-11-05 15:13:12,888 train 650 1.746762e-02 -2.480185
2019-11-05 15:13:23,100 train 700 1.746497e-02 -2.354948
2019-11-05 15:13:33,272 train 750 1.745255e-02 -2.236233
2019-11-05 15:13:43,449 train 800 1.747050e-02 -2.128250
2019-11-05 15:13:53,603 train 850 1.746754e-02 -2.043120
2019-11-05 15:13:56,638 training loss; R2: 1.747416e-02 -2.025444
2019-11-05 15:13:57,221 valid 000 1.273131e-02 -1.047478
2019-11-05 15:14:06,956 valid 050 1.541183e-02 -1.287720
2019-11-05 15:14:15,710 validation loss; R2: 1.554801e-02 -1.133952
2019-11-05 15:14:15,783 epoch 101 lr 1.000000e-04
2019-11-05 15:14:16,559 train 000 1.915817e-02 -0.016651
2019-11-05 15:14:26,634 train 050 1.756525e-02 -0.606575
2019-11-05 15:14:36,809 train 100 1.716500e-02 -0.705329
2019-11-05 15:14:46,985 train 150 1.735858e-02 -0.612311
2019-11-05 15:14:57,095 train 200 1.735590e-02 -0.606342
2019-11-05 15:15:07,231 train 250 1.732900e-02 -0.626538
2019-11-05 15:15:17,434 train 300 1.736760e-02 -0.642868
2019-11-05 15:15:27,490 train 350 1.738930e-02 -0.650825
2019-11-05 15:15:37,621 train 400 1.735936e-02 -0.641586
2019-11-05 15:15:47,772 train 450 1.734799e-02 -0.657807
2019-11-05 15:15:57,837 train 500 1.735177e-02 -0.658792
2019-11-05 15:16:08,006 train 550 1.738139e-02 -0.699908
2019-11-05 15:16:18,294 train 600 1.739138e-02 -0.726285
2019-11-05 15:16:28,404 train 650 1.738047e-02 -0.713217
2019-11-05 15:16:38,485 train 700 1.733611e-02 -0.726708
2019-11-05 15:16:48,658 train 750 1.733011e-02 -0.721017
2019-11-05 15:16:58,809 train 800 1.732873e-02 -0.869670
2019-11-05 15:17:08,869 train 850 1.731809e-02 -0.850766
2019-11-05 15:17:11,891 training loss; R2: 1.732938e-02 -0.841286
2019-11-05 15:17:12,469 valid 000 1.510553e-02 -0.014797
2019-11-05 15:17:22,552 valid 050 1.525557e-02 -1.307769
2019-11-05 15:17:31,451 validation loss; R2: 1.542230e-02 -1.082152
2019-11-05 15:17:31,515 epoch 102 lr 1.000000e-04
2019-11-05 15:17:32,263 train 000 1.680381e-02 -0.518884
2019-11-05 15:17:42,447 train 050 1.740505e-02 -0.923359
2019-11-05 15:17:52,644 train 100 1.736474e-02 -0.788640
2019-11-05 15:18:02,802 train 150 1.734566e-02 -0.694134
2019-11-05 15:18:12,975 train 200 1.729165e-02 -0.732481
2019-11-05 15:18:23,143 train 250 1.732629e-02 -0.719632
2019-11-05 15:18:33,294 train 300 1.731144e-02 -0.691832
2019-11-05 15:18:43,441 train 350 1.734230e-02 -0.679205
2019-11-05 15:18:53,612 train 400 1.734723e-02 -0.683964
2019-11-05 15:19:03,765 train 450 1.731963e-02 -0.686782
2019-11-05 15:19:13,933 train 500 1.734500e-02 -0.661845
2019-11-05 15:19:24,070 train 550 1.736545e-02 -0.697214
2019-11-05 15:19:34,273 train 600 1.740149e-02 -0.734564
2019-11-05 15:19:44,429 train 650 1.740602e-02 -0.737728
2019-11-05 15:19:54,679 train 700 1.739785e-02 -0.713461
2019-11-05 15:20:04,975 train 750 1.736049e-02 -0.710575
2019-11-05 15:20:15,114 train 800 1.734713e-02 -0.723033
2019-11-05 15:20:25,255 train 850 1.735617e-02 -0.725564
2019-11-05 15:20:28,301 training loss; R2: 1.735670e-02 -0.722765
2019-11-05 15:20:28,821 valid 000 2.316597e-02 -0.170315
2019-11-05 15:20:38,691 valid 050 2.628986e-02 -0.522022
2019-11-05 15:20:47,414 validation loss; R2: 2.593079e-02 -0.570200
2019-11-05 15:20:47,477 epoch 103 lr 1.000000e-04
2019-11-05 15:20:48,162 train 000 1.636118e-02 -0.307129
2019-11-05 15:20:58,427 train 050 1.741889e-02 -1.176250
2019-11-05 15:21:08,681 train 100 1.753870e-02 -0.968651
2019-11-05 15:21:18,912 train 150 1.743885e-02 -0.853822
2019-11-05 15:21:29,137 train 200 1.737488e-02 -0.772934
2019-11-05 15:21:39,348 train 250 1.743258e-02 -0.723710
2019-11-05 15:21:49,576 train 300 1.745509e-02 -0.777860
2019-11-05 15:21:59,766 train 350 1.746378e-02 -0.772875
2019-11-05 15:22:09,966 train 400 1.741752e-02 -0.794606
2019-11-05 15:22:20,137 train 450 1.741988e-02 -0.821043
2019-11-05 15:22:30,353 train 500 1.735656e-02 -0.806076
2019-11-05 15:22:40,538 train 550 1.738712e-02 -0.784108
2019-11-05 15:22:50,744 train 600 1.737725e-02 -0.764429
2019-11-05 15:23:00,921 train 650 1.734336e-02 -0.745272
2019-11-05 15:23:11,098 train 700 1.735870e-02 -0.747323
2019-11-05 15:23:21,235 train 750 1.736758e-02 -0.758566
2019-11-05 15:23:31,406 train 800 1.736929e-02 -0.744085
2019-11-05 15:23:41,550 train 850 1.735562e-02 -0.735179
2019-11-05 15:23:44,587 training loss; R2: 1.736274e-02 -0.732313
2019-11-05 15:23:45,157 valid 000 1.225506e-02 -6.962493
2019-11-05 15:23:54,892 valid 050 1.474689e-02 -1.414794
2019-11-05 15:24:03,557 validation loss; R2: 1.490621e-02 -1.187911
2019-11-05 15:24:03,632 epoch 104 lr 1.000000e-04
2019-11-05 15:24:04,402 train 000 1.826466e-02 -0.731319
2019-11-05 15:24:14,527 train 050 1.734693e-02 -0.586081
2019-11-05 15:24:24,725 train 100 1.741243e-02 -0.680089
2019-11-05 15:24:34,889 train 150 1.737067e-02 -0.565436
2019-11-05 15:24:45,048 train 200 1.733416e-02 -0.705259
2019-11-05 15:24:55,183 train 250 1.727008e-02 -0.667811
2019-11-05 15:25:05,333 train 300 1.734495e-02 -0.725954
2019-11-05 15:25:15,436 train 350 1.740295e-02 -0.710198
2019-11-05 15:25:25,561 train 400 1.739040e-02 -0.694092
2019-11-05 15:25:35,666 train 450 1.735524e-02 -0.857888
2019-11-05 15:25:45,810 train 500 1.736950e-02 -0.844606
2019-11-05 15:25:55,939 train 550 1.738845e-02 -0.822431
2019-11-05 15:26:06,142 train 600 1.741739e-02 -0.834286
2019-11-05 15:26:16,282 train 650 1.742114e-02 -0.831570
2019-11-05 15:26:26,420 train 700 1.739442e-02 -0.808834
2019-11-05 15:26:36,549 train 750 1.740175e-02 -0.795633
2019-11-05 15:26:46,703 train 800 1.741031e-02 -0.794048
2019-11-05 15:26:56,838 train 850 1.742564e-02 -0.791401
2019-11-05 15:26:59,863 training loss; R2: 1.743041e-02 -0.786629
2019-11-05 15:27:00,460 valid 000 1.663465e-02 -0.153081
2019-11-05 15:27:10,222 valid 050 1.506334e-02 -1.185131
2019-11-05 15:27:19,005 validation loss; R2: 1.521817e-02 -1.033414
2019-11-05 15:27:19,081 epoch 105 lr 1.000000e-04
2019-11-05 15:27:19,838 train 000 1.748957e-02 -1.184262
2019-11-05 15:27:29,986 train 050 1.718305e-02 -0.469110
2019-11-05 15:27:40,222 train 100 1.732965e-02 -0.744832
2019-11-05 15:27:50,454 train 150 1.733109e-02 -0.720550
2019-11-05 15:28:00,642 train 200 1.736207e-02 -0.780633
2019-11-05 15:28:10,788 train 250 1.728694e-02 -0.721405
2019-11-05 15:28:20,925 train 300 1.731089e-02 -0.730026
2019-11-05 15:28:31,038 train 350 1.737695e-02 -0.709488
2019-11-05 15:28:41,166 train 400 1.738614e-02 -0.700628
2019-11-05 15:28:51,295 train 450 1.737357e-02 -0.689675
2019-11-05 15:29:01,465 train 500 1.737153e-02 -0.680394
2019-11-05 15:29:11,608 train 550 1.735156e-02 -0.687699
2019-11-05 15:29:21,791 train 600 1.731699e-02 -0.700174
2019-11-05 15:29:31,958 train 650 1.731868e-02 -0.709911
2019-11-05 15:29:42,151 train 700 1.730720e-02 -0.733871
2019-11-05 15:29:52,298 train 750 1.732606e-02 -0.723699
2019-11-05 15:30:02,493 train 800 1.735291e-02 -0.739803
2019-11-05 15:30:12,655 train 850 1.735767e-02 -1.534261
2019-11-05 15:30:15,694 training loss; R2: 1.736487e-02 -1.521283
2019-11-05 15:30:16,225 valid 000 1.492343e-02 0.058571
2019-11-05 15:30:26,064 valid 050 1.504632e-02 -0.924370
2019-11-05 15:30:34,760 validation loss; R2: 1.482361e-02 -1.042343
2019-11-05 15:30:34,829 epoch 106 lr 1.000000e-04
2019-11-05 15:30:35,593 train 000 1.437654e-02 -0.414902
2019-11-05 15:30:45,766 train 050 1.718609e-02 -0.510502
2019-11-05 15:30:55,974 train 100 1.736367e-02 -0.528991
2019-11-05 15:31:06,148 train 150 1.734709e-02 -0.624960
2019-11-05 15:31:16,334 train 200 1.738509e-02 -0.635870
2019-11-05 15:31:26,514 train 250 1.740177e-02 -0.654420
2019-11-05 15:31:36,691 train 300 1.742034e-02 -0.622938
2019-11-05 15:31:46,855 train 350 1.743185e-02 -0.626711
2019-11-05 15:31:57,057 train 400 1.742525e-02 -0.644130
2019-11-05 15:32:07,223 train 450 1.735346e-02 -0.655275
2019-11-05 15:32:17,411 train 500 1.737049e-02 -0.745694
2019-11-05 15:32:27,566 train 550 1.733547e-02 -0.742062
2019-11-05 15:32:37,754 train 600 1.735018e-02 -0.804830
2019-11-05 15:32:47,931 train 650 1.736107e-02 -0.788924
2019-11-05 15:32:58,100 train 700 1.732576e-02 -0.780298
2019-11-05 15:33:08,249 train 750 1.732129e-02 -0.774678
2019-11-05 15:33:18,410 train 800 1.732653e-02 -0.796267
2019-11-05 15:33:28,550 train 850 1.733266e-02 -0.794857
2019-11-05 15:33:31,594 training loss; R2: 1.732898e-02 -0.859154
2019-11-05 15:33:32,115 valid 000 1.490671e-02 -2.010272
2019-11-05 15:33:41,977 valid 050 1.534650e-02 -1.023096
2019-11-05 15:33:50,628 validation loss; R2: 1.547433e-02 -1.272509
2019-11-05 15:33:50,694 epoch 107 lr 1.000000e-04
2019-11-05 15:33:51,514 train 000 1.766060e-02 -1.713308
2019-11-05 15:34:01,634 train 050 1.721030e-02 -0.598023
2019-11-05 15:34:11,841 train 100 1.729136e-02 -0.545874
2019-11-05 15:34:21,998 train 150 1.733351e-02 -0.589102
2019-11-05 15:34:32,189 train 200 1.730939e-02 -0.661785
2019-11-05 15:34:42,332 train 250 1.721783e-02 -0.657338
2019-11-05 15:34:52,468 train 300 1.718645e-02 -0.669931
2019-11-05 15:35:02,594 train 350 1.718398e-02 -0.670377
2019-11-05 15:35:12,736 train 400 1.719438e-02 -0.668953
2019-11-05 15:35:22,861 train 450 1.723175e-02 -0.675811
2019-11-05 15:35:33,035 train 500 1.724206e-02 -0.668976
2019-11-05 15:35:43,146 train 550 1.724429e-02 -0.684525
2019-11-05 15:35:53,294 train 600 1.722424e-02 -0.703984
2019-11-05 15:36:03,446 train 650 1.725608e-02 -0.690097
2019-11-05 15:36:13,587 train 700 1.723546e-02 -0.690494
2019-11-05 15:36:23,716 train 750 1.724550e-02 -0.675773
2019-11-05 15:36:33,868 train 800 1.725085e-02 -0.683982
2019-11-05 15:36:43,996 train 850 1.728048e-02 -2.681734
2019-11-05 15:36:47,037 training loss; R2: 1.727130e-02 -2.645526
2019-11-05 15:36:47,622 valid 000 1.598104e-02 0.056335
2019-11-05 15:36:57,400 valid 050 1.561638e-02 -0.847466
2019-11-05 15:37:06,112 validation loss; R2: 1.557930e-02 -1.074197
2019-11-05 15:37:06,183 epoch 108 lr 1.000000e-04
2019-11-05 15:37:06,880 train 000 1.528500e-02 0.135564
2019-11-05 15:37:17,154 train 050 1.699754e-02 -0.396337
2019-11-05 15:37:27,419 train 100 1.703144e-02 -0.491136
2019-11-05 15:37:37,625 train 150 1.699081e-02 -0.555429
2019-11-05 15:37:47,823 train 200 1.701159e-02 -0.595157
2019-11-05 15:37:57,981 train 250 1.703317e-02 -0.690109
2019-11-05 15:38:08,157 train 300 1.710914e-02 -0.755480
2019-11-05 15:38:18,310 train 350 1.712529e-02 -0.768089
2019-11-05 15:38:28,490 train 400 1.724043e-02 -0.749063
2019-11-05 15:38:38,666 train 450 1.723593e-02 -0.759019
2019-11-05 15:38:48,875 train 500 1.721801e-02 -0.756122
2019-11-05 15:38:59,020 train 550 1.722331e-02 -0.756110
2019-11-05 15:39:09,226 train 600 1.722620e-02 -0.758322
2019-11-05 15:39:19,406 train 650 1.727882e-02 -0.764400
2019-11-05 15:39:29,618 train 700 1.727816e-02 -0.765600
2019-11-05 15:39:39,781 train 750 1.729971e-02 -0.755222
2019-11-05 15:39:50,002 train 800 1.731170e-02 -0.753944
2019-11-05 15:40:00,179 train 850 1.727734e-02 -0.752019
2019-11-05 15:40:03,237 training loss; R2: 1.725087e-02 -0.746986
2019-11-05 15:40:03,780 valid 000 1.387911e-02 -0.097024
2019-11-05 15:40:13,588 valid 050 1.508852e-02 -2.025656
2019-11-05 15:40:22,335 validation loss; R2: 1.511279e-02 -1.604853
2019-11-05 15:40:22,402 epoch 109 lr 1.000000e-04
2019-11-05 15:40:23,088 train 000 1.669866e-02 -0.616954
2019-11-05 15:40:33,343 train 050 1.735522e-02 -0.846900
2019-11-05 15:40:43,596 train 100 1.740884e-02 -1.126576
2019-11-05 15:40:53,790 train 150 1.730398e-02 -0.946874
2019-11-05 15:41:04,030 train 200 1.720895e-02 -0.966403
2019-11-05 15:41:14,225 train 250 1.725769e-02 -0.852336
2019-11-05 15:41:24,444 train 300 1.730361e-02 -0.844386
2019-11-05 15:41:34,616 train 350 1.737769e-02 -0.842493
2019-11-05 15:41:44,804 train 400 1.738617e-02 -0.807134
2019-11-05 15:41:54,964 train 450 1.738847e-02 -0.842216
2019-11-05 15:42:05,151 train 500 1.739453e-02 -0.826700
2019-11-05 15:42:15,298 train 550 1.738461e-02 -0.800975
2019-11-05 15:42:25,456 train 600 1.738098e-02 -0.790087
2019-11-05 15:42:35,583 train 650 1.737716e-02 -0.764265
2019-11-05 15:42:45,739 train 700 1.741698e-02 -0.780208
2019-11-05 15:42:55,873 train 750 1.741147e-02 -0.776341
2019-11-05 15:43:06,047 train 800 1.742657e-02 -0.764803
2019-11-05 15:43:16,168 train 850 1.740393e-02 -0.760039
2019-11-05 15:43:19,209 training loss; R2: 1.741695e-02 -0.756571
2019-11-05 15:43:19,721 valid 000 1.410841e-02 -0.026105
2019-11-05 15:43:29,542 valid 050 1.472067e-02 -0.652502
2019-11-05 15:43:38,259 validation loss; R2: 1.480762e-02 -0.812418
2019-11-05 15:43:38,326 epoch 110 lr 1.000000e-04
2019-11-05 15:43:39,075 train 000 1.498341e-02 -0.178437
2019-11-05 15:43:49,342 train 050 1.733076e-02 -1.466380
2019-11-05 15:43:59,561 train 100 1.716663e-02 -1.055546
2019-11-05 15:44:09,638 train 150 1.724763e-02 -1.004406
2019-11-05 15:44:19,789 train 200 1.720869e-02 -0.891314
2019-11-05 15:44:29,974 train 250 1.722678e-02 -0.815384
2019-11-05 15:44:40,132 train 300 1.723122e-02 -0.822006
2019-11-05 15:44:50,188 train 350 1.727766e-02 -0.788024
2019-11-05 15:45:00,426 train 400 1.725695e-02 -0.755626
2019-11-05 15:45:10,591 train 450 1.726253e-02 -0.740260
2019-11-05 15:45:20,688 train 500 1.725229e-02 -0.723436
2019-11-05 15:45:30,769 train 550 1.725428e-02 -0.712554
2019-11-05 15:45:40,971 train 600 1.724390e-02 -0.713477
2019-11-05 15:45:51,110 train 650 1.728713e-02 -0.726652
2019-11-05 15:46:01,238 train 700 1.727914e-02 -0.732893
2019-11-05 15:46:11,414 train 750 1.730066e-02 -0.723140
2019-11-05 15:46:21,612 train 800 1.729872e-02 -0.709674
2019-11-05 15:46:31,687 train 850 1.728934e-02 -1.719322
2019-11-05 15:46:34,711 training loss; R2: 1.730338e-02 -1.696342
2019-11-05 15:46:35,297 valid 000 1.672937e-02 -0.249998
2019-11-05 15:46:45,084 valid 050 1.641403e-02 -1.004833
2019-11-05 15:46:53,763 validation loss; R2: 1.649422e-02 -0.826035
2019-11-05 15:46:53,835 epoch 111 lr 1.000000e-04
2019-11-05 15:46:54,566 train 000 1.757351e-02 -5.675982
2019-11-05 15:47:04,801 train 050 1.759144e-02 -1.107611
2019-11-05 15:47:15,009 train 100 1.732845e-02 -0.831105
2019-11-05 15:47:25,186 train 150 1.743130e-02 -0.709255
2019-11-05 15:47:35,364 train 200 1.727588e-02 -0.719350
2019-11-05 15:47:45,524 train 250 1.731707e-02 -0.730862
2019-11-05 15:47:55,699 train 300 1.725246e-02 -0.744429
2019-11-05 15:48:05,869 train 350 1.724447e-02 -0.739081
2019-11-05 15:48:16,063 train 400 1.731476e-02 -0.729655
2019-11-05 15:48:26,221 train 450 1.733873e-02 -0.733907
2019-11-05 15:48:36,413 train 500 1.735231e-02 -0.868975
2019-11-05 15:48:46,555 train 550 1.735815e-02 -0.842578
2019-11-05 15:48:56,737 train 600 1.732464e-02 -0.862507
2019-11-05 15:49:06,884 train 650 1.732017e-02 -0.847096
2019-11-05 15:49:17,047 train 700 1.729151e-02 -0.841805
2019-11-05 15:49:27,184 train 750 1.728827e-02 -0.839010
2019-11-05 15:49:37,356 train 800 1.728639e-02 -0.826612
2019-11-05 15:49:47,519 train 850 1.728155e-02 -0.808786
2019-11-05 15:49:50,575 training loss; R2: 1.727948e-02 -0.805445
2019-11-05 15:49:51,095 valid 000 1.328958e-02 -0.217091
2019-11-05 15:50:00,983 valid 050 1.546860e-02 -1.094684
2019-11-05 15:50:09,671 validation loss; R2: 1.547472e-02 -1.357677
2019-11-05 15:50:09,737 epoch 112 lr 1.000000e-04
2019-11-05 15:50:10,485 train 000 1.376215e-02 -0.456750
2019-11-05 15:50:20,511 train 050 1.728566e-02 -0.576031
2019-11-05 15:50:30,715 train 100 1.734252e-02 -0.634290
2019-11-05 15:50:40,850 train 150 1.720630e-02 -0.656717
2019-11-05 15:50:50,916 train 200 1.718255e-02 -0.696131
2019-11-05 15:51:01,028 train 250 1.716801e-02 -0.686405
2019-11-05 15:51:11,193 train 300 1.730322e-02 -0.705440
2019-11-05 15:51:21,253 train 350 1.725395e-02 -0.767620
2019-11-05 15:51:31,350 train 400 1.722034e-02 -0.732363
2019-11-05 15:51:41,510 train 450 1.724462e-02 -0.743711
2019-11-05 15:51:51,617 train 500 1.723506e-02 -0.718263
2019-11-05 15:52:01,703 train 550 1.722360e-02 -0.703967
2019-11-05 15:52:11,922 train 600 1.723277e-02 -0.692125
2019-11-05 15:52:22,040 train 650 1.722146e-02 -0.688870
2019-11-05 15:52:32,218 train 700 1.721563e-02 -0.698454
2019-11-05 15:52:42,427 train 750 1.720731e-02 -0.694952
2019-11-05 15:52:52,578 train 800 1.719951e-02 -0.680546
2019-11-05 15:53:02,697 train 850 1.719202e-02 -0.683901
2019-11-05 15:53:05,742 training loss; R2: 1.719625e-02 -0.694128
2019-11-05 15:53:06,258 valid 000 1.723060e-02 -0.647593
2019-11-05 15:53:16,149 valid 050 1.548136e-02 -0.813652
2019-11-05 15:53:24,918 validation loss; R2: 1.550866e-02 -0.816183
2019-11-05 15:53:24,982 epoch 113 lr 1.000000e-04
2019-11-05 15:53:25,732 train 000 1.636234e-02 -0.003258
2019-11-05 15:53:35,983 train 050 1.719804e-02 -0.718752
2019-11-05 15:53:46,199 train 100 1.714231e-02 -0.680433
2019-11-05 15:53:56,372 train 150 1.725061e-02 -0.745315
2019-11-05 15:54:06,564 train 200 1.725205e-02 -0.704961
2019-11-05 15:54:16,727 train 250 1.715070e-02 -0.702390
2019-11-05 15:54:26,885 train 300 1.717506e-02 -0.700503
2019-11-05 15:54:37,032 train 350 1.714353e-02 -0.669695
2019-11-05 15:54:47,220 train 400 1.717385e-02 -0.712705
2019-11-05 15:54:57,391 train 450 1.716349e-02 -0.728483
2019-11-05 15:55:07,590 train 500 1.716402e-02 -0.725182
2019-11-05 15:55:17,765 train 550 1.719292e-02 -0.723337
2019-11-05 15:55:27,950 train 600 1.719402e-02 -0.730543
2019-11-05 15:55:38,118 train 650 1.718151e-02 -0.747788
2019-11-05 15:55:48,306 train 700 1.719732e-02 -0.738218
2019-11-05 15:55:58,458 train 750 1.716937e-02 -0.729284
2019-11-05 15:56:08,642 train 800 1.716239e-02 -0.731112
2019-11-05 15:56:18,810 train 850 1.717926e-02 -0.728091
2019-11-05 15:56:21,852 training loss; R2: 1.716447e-02 -0.727902
2019-11-05 15:56:22,418 valid 000 1.346882e-02 -0.125167
2019-11-05 15:56:32,164 valid 050 1.451292e-02 -1.250018
2019-11-05 15:56:40,820 validation loss; R2: 1.490068e-02 -1.184351
2019-11-05 15:56:40,888 epoch 114 lr 1.000000e-04
2019-11-05 15:56:41,618 train 000 1.667739e-02 -0.751678
2019-11-05 15:56:51,824 train 050 1.705311e-02 -0.693231
2019-11-05 15:57:02,041 train 100 1.711536e-02 -0.854555
2019-11-05 15:57:12,214 train 150 1.712113e-02 -0.794439
2019-11-05 15:57:22,406 train 200 1.728416e-02 -0.762823
2019-11-05 15:57:32,574 train 250 1.732202e-02 -0.769258
2019-11-05 15:57:42,762 train 300 1.734450e-02 -0.761231
2019-11-05 15:57:52,947 train 350 1.733929e-02 -0.751387
2019-11-05 15:58:03,127 train 400 1.728407e-02 -0.839729
2019-11-05 15:58:13,306 train 450 1.724925e-02 -1.010163
2019-11-05 15:58:23,494 train 500 1.720207e-02 -0.995738
2019-11-05 15:58:33,667 train 550 1.718004e-02 -0.946942
2019-11-05 15:58:43,880 train 600 1.718315e-02 -0.971254
2019-11-05 15:58:54,078 train 650 1.717604e-02 -0.944597
2019-11-05 15:59:04,298 train 700 1.716398e-02 -0.921159
2019-11-05 15:59:14,496 train 750 1.715866e-02 -0.902120
2019-11-05 15:59:24,733 train 800 1.715613e-02 -0.884033
2019-11-05 15:59:34,918 train 850 1.714844e-02 -0.892130
2019-11-05 15:59:37,953 training loss; R2: 1.714502e-02 -0.884111
2019-11-05 15:59:38,471 valid 000 1.629753e-02 0.058716
2019-11-05 15:59:48,342 valid 050 1.508026e-02 -1.031456
2019-11-05 15:59:57,049 validation loss; R2: 1.499266e-02 -1.182964
2019-11-05 15:59:57,115 epoch 115 lr 1.000000e-04
2019-11-05 15:59:57,795 train 000 1.512275e-02 -1.632475
2019-11-05 16:00:07,954 train 050 1.698811e-02 -0.673145
2019-11-05 16:00:18,126 train 100 1.697279e-02 -0.638710
2019-11-05 16:00:28,241 train 150 1.701100e-02 -0.672026
2019-11-05 16:00:38,358 train 200 1.708506e-02 -0.654604
2019-11-05 16:00:48,539 train 250 1.705879e-02 -0.649619
2019-11-05 16:00:58,746 train 300 1.710724e-02 -0.628361
2019-11-05 16:01:08,927 train 350 1.710889e-02 -0.647084
2019-11-05 16:01:19,117 train 400 1.709759e-02 -0.652116
2019-11-05 16:01:29,299 train 450 1.716623e-02 -0.659124
2019-11-05 16:01:39,540 train 500 1.715905e-02 -0.650418
2019-11-05 16:01:49,758 train 550 1.717882e-02 -0.658600
2019-11-05 16:01:59,966 train 600 1.717716e-02 -0.645882
2019-11-05 16:02:10,177 train 650 1.713408e-02 -0.655336
2019-11-05 16:02:20,385 train 700 1.713636e-02 -0.662488
2019-11-05 16:02:30,573 train 750 1.714291e-02 -0.664232
2019-11-05 16:02:40,785 train 800 1.715948e-02 -0.687062
2019-11-05 16:02:50,953 train 850 1.714061e-02 -0.690675
2019-11-05 16:02:53,988 training loss; R2: 1.713797e-02 -0.693599
2019-11-05 16:02:54,499 valid 000 1.562457e-02 -2.588045
2019-11-05 16:03:04,293 valid 050 1.508275e-02 -1.505994
2019-11-05 16:03:12,976 validation loss; R2: 1.503830e-02 -1.418898
2019-11-05 16:03:13,050 epoch 116 lr 1.000000e-04
2019-11-05 16:03:13,756 train 000 1.601731e-02 -3.081675
2019-11-05 16:03:23,927 train 050 1.743658e-02 -8.736995
2019-11-05 16:03:34,114 train 100 1.715871e-02 -4.830611
2019-11-05 16:03:44,284 train 150 1.708045e-02 -3.526198
2019-11-05 16:03:54,454 train 200 1.702447e-02 -2.791958
2019-11-05 16:04:04,597 train 250 1.705689e-02 -2.319308
2019-11-05 16:04:14,783 train 300 1.705562e-02 -2.248267
2019-11-05 16:04:24,978 train 350 1.704109e-02 -2.015294
2019-11-05 16:04:35,181 train 400 1.708565e-02 -1.869174
2019-11-05 16:04:45,363 train 450 1.713141e-02 -1.742998
2019-11-05 16:04:55,517 train 500 1.709208e-02 -1.625754
2019-11-05 16:05:05,658 train 550 1.708550e-02 -1.528584
2019-11-05 16:05:15,787 train 600 1.710576e-02 -1.479905
2019-11-05 16:05:25,940 train 650 1.705820e-02 -1.433860
2019-11-05 16:05:36,099 train 700 1.706620e-02 -1.389193
2019-11-05 16:05:46,252 train 750 1.706871e-02 -1.354014
2019-11-05 16:05:56,424 train 800 1.706559e-02 -1.355499
2019-11-05 16:06:06,602 train 850 1.707138e-02 -1.308026
2019-11-05 16:06:09,659 training loss; R2: 1.707699e-02 -1.314323
2019-11-05 16:06:10,192 valid 000 1.547343e-02 -0.549620
2019-11-05 16:06:20,096 valid 050 1.617680e-02 -1.247193
2019-11-05 16:06:28,821 validation loss; R2: 1.602859e-02 -1.652731
2019-11-05 16:06:28,888 epoch 117 lr 1.000000e-04
2019-11-05 16:06:29,606 train 000 1.658397e-02 -0.093960
2019-11-05 16:06:39,902 train 050 1.686909e-02 -0.745513
2019-11-05 16:06:50,185 train 100 1.690131e-02 -0.890206
2019-11-05 16:07:00,408 train 150 1.706754e-02 -1.059296
2019-11-05 16:07:10,644 train 200 1.709787e-02 -1.007939
2019-11-05 16:07:20,857 train 250 1.714735e-02 -0.962793
2019-11-05 16:07:31,167 train 300 1.713452e-02 -0.889177
2019-11-05 16:07:41,378 train 350 1.719542e-02 -0.882527
2019-11-05 16:07:51,589 train 400 1.724110e-02 -0.834715
2019-11-05 16:08:01,779 train 450 1.721817e-02 -0.826802
2019-11-05 16:08:11,988 train 500 1.717221e-02 -0.816083
2019-11-05 16:08:22,215 train 550 1.716706e-02 -0.788722
2019-11-05 16:08:32,464 train 600 1.715040e-02 -0.786529
2019-11-05 16:08:42,694 train 650 1.715224e-02 -0.775639
2019-11-05 16:08:52,940 train 700 1.714009e-02 -0.774397
2019-11-05 16:09:03,126 train 750 1.712160e-02 -0.783275
2019-11-05 16:09:13,352 train 800 1.712146e-02 -0.763737
2019-11-05 16:09:23,553 train 850 1.712606e-02 -0.759505
2019-11-05 16:09:26,604 training loss; R2: 1.712735e-02 -0.770996
2019-11-05 16:09:27,187 valid 000 1.643526e-02 0.056291
2019-11-05 16:09:37,015 valid 050 1.523701e-02 -1.282718
2019-11-05 16:09:45,688 validation loss; R2: 1.520647e-02 -1.309652
2019-11-05 16:09:45,753 epoch 118 lr 1.000000e-04
2019-11-05 16:09:46,502 train 000 1.664212e-02 -0.127281
2019-11-05 16:09:56,724 train 050 1.674623e-02 -0.855569
2019-11-05 16:10:06,923 train 100 1.677970e-02 -0.634770
2019-11-05 16:10:17,091 train 150 1.680909e-02 -0.699048
2019-11-05 16:10:27,275 train 200 1.681761e-02 -0.692429
2019-11-05 16:10:37,445 train 250 1.686729e-02 -0.718364
2019-11-05 16:10:47,628 train 300 1.698075e-02 -0.711152
2019-11-05 16:10:57,773 train 350 1.703016e-02 -0.753193
2019-11-05 16:11:07,883 train 400 1.700810e-02 -0.752963
2019-11-05 16:11:17,969 train 450 1.701662e-02 -0.740002
2019-11-05 16:11:28,088 train 500 1.697708e-02 -0.746525
2019-11-05 16:11:38,172 train 550 1.697879e-02 -1.396504
2019-11-05 16:11:48,297 train 600 1.700828e-02 -1.378949
2019-11-05 16:11:58,399 train 650 1.704154e-02 -11.809243
2019-11-05 16:12:08,502 train 700 1.706640e-02 -11.023977
2019-11-05 16:12:18,628 train 750 1.709427e-02 -10.333513
2019-11-05 16:12:28,818 train 800 1.710255e-02 -9.738671
2019-11-05 16:12:39,028 train 850 1.709807e-02 -9.208811
2019-11-05 16:12:42,083 training loss; R2: 1.709611e-02 -9.059601
2019-11-05 16:12:42,605 valid 000 1.572356e-02 -0.406558
2019-11-05 16:12:52,437 valid 050 1.612202e-02 -1.756904
2019-11-05 16:13:01,106 validation loss; R2: 1.600659e-02 -1.423138
2019-11-05 16:13:01,172 epoch 119 lr 1.000000e-04
2019-11-05 16:13:01,925 train 000 1.577929e-02 -0.236006
2019-11-05 16:13:12,138 train 050 1.721569e-02 -0.369461
2019-11-05 16:13:22,371 train 100 1.713117e-02 -0.537341
2019-11-05 16:13:32,564 train 150 1.718228e-02 -0.596149
2019-11-05 16:13:42,768 train 200 1.713300e-02 -0.628421
2019-11-05 16:13:52,939 train 250 1.723458e-02 -0.662210
2019-11-05 16:14:03,121 train 300 1.717800e-02 -0.635711
2019-11-05 16:14:13,282 train 350 1.715462e-02 -0.656640
2019-11-05 16:14:23,450 train 400 1.714616e-02 -0.638036
2019-11-05 16:14:33,608 train 450 1.711490e-02 -0.623225
2019-11-05 16:14:43,769 train 500 1.712664e-02 -0.615146
2019-11-05 16:14:53,908 train 550 1.715582e-02 -0.622877
2019-11-05 16:15:04,074 train 600 1.714520e-02 -0.621124
2019-11-05 16:15:14,233 train 650 1.714187e-02 -0.611040
2019-11-05 16:15:24,418 train 700 1.716047e-02 -0.608342
2019-11-05 16:15:34,543 train 750 1.715380e-02 -0.621393
2019-11-05 16:15:44,714 train 800 1.715934e-02 -0.622221
2019-11-05 16:15:54,837 train 850 1.715247e-02 -0.619581
2019-11-05 16:15:57,876 training loss; R2: 1.715505e-02 -0.635960
2019-11-05 16:15:58,397 valid 000 1.474558e-02 -1.347088
2019-11-05 16:16:08,199 valid 050 1.550281e-02 -1.310465
2019-11-05 16:16:16,847 validation loss; R2: 1.522320e-02 -1.348471
2019-11-05 16:16:16,914 epoch 120 lr 1.000000e-04
2019-11-05 16:16:17,653 train 000 2.038471e-02 -3.429867
2019-11-05 16:16:27,804 train 050 1.706955e-02 -0.866582
2019-11-05 16:16:38,000 train 100 1.711624e-02 -0.800581
2019-11-05 16:16:48,147 train 150 1.714753e-02 -0.784709
2019-11-05 16:16:58,328 train 200 1.713551e-02 -0.763890
2019-11-05 16:17:08,468 train 250 1.711127e-02 -0.713850
2019-11-05 16:17:18,655 train 300 1.705744e-02 -0.736257
2019-11-05 16:17:28,798 train 350 1.703979e-02 -0.725489
2019-11-05 16:17:38,960 train 400 1.708242e-02 -0.719518
2019-11-05 16:17:49,107 train 450 1.712673e-02 -0.725749
2019-11-05 16:17:59,184 train 500 1.708759e-02 -0.724900
2019-11-05 16:18:09,226 train 550 1.706102e-02 -0.707714
2019-11-05 16:18:19,294 train 600 1.706670e-02 -0.699500
2019-11-05 16:18:29,309 train 650 1.705239e-02 -0.683111
2019-11-05 16:18:39,363 train 700 1.707283e-02 -0.666594
2019-11-05 16:18:49,384 train 750 1.705866e-02 -0.677941
2019-11-05 16:18:59,513 train 800 1.705656e-02 -0.686837
2019-11-05 16:19:09,617 train 850 1.707775e-02 -0.675327
2019-11-05 16:19:12,635 training loss; R2: 1.707807e-02 -0.673356
2019-11-05 16:19:13,203 valid 000 1.400176e-02 -1.238033
2019-11-05 16:19:23,108 valid 050 1.496721e-02 -0.996735
2019-11-05 16:19:31,871 validation loss; R2: 1.515822e-02 -1.325461
2019-11-05 16:19:31,936 epoch 121 lr 1.000000e-04
2019-11-05 16:19:32,646 train 000 1.606672e-02 -0.527891
2019-11-05 16:19:42,905 train 050 1.712066e-02 -0.648454
2019-11-05 16:19:53,149 train 100 1.717966e-02 -0.660157
2019-11-05 16:20:03,350 train 150 1.702911e-02 -0.737702
2019-11-05 16:20:13,552 train 200 1.701841e-02 -0.649335
2019-11-05 16:20:23,749 train 250 1.703243e-02 -0.662742
2019-11-05 16:20:33,957 train 300 1.696742e-02 -0.657696
2019-11-05 16:20:44,141 train 350 1.703369e-02 -0.666635
2019-11-05 16:20:54,365 train 400 1.708652e-02 -0.645181
2019-11-05 16:21:04,590 train 450 1.710045e-02 -0.643293
2019-11-05 16:21:14,825 train 500 1.712874e-02 -0.629418
2019-11-05 16:21:25,044 train 550 1.711740e-02 -0.623861
2019-11-05 16:21:35,275 train 600 1.710118e-02 -0.639450
2019-11-05 16:21:45,498 train 650 1.710951e-02 -0.633488
2019-11-05 16:21:55,747 train 700 1.711434e-02 -0.623163
2019-11-05 16:22:05,955 train 750 1.711947e-02 -0.623536
2019-11-05 16:22:16,189 train 800 1.711848e-02 -0.629753
2019-11-05 16:22:26,368 train 850 1.710817e-02 -0.653126
2019-11-05 16:22:29,417 training loss; R2: 1.710337e-02 -0.651905
2019-11-05 16:22:29,979 valid 000 1.539768e-02 -0.153207
2019-11-05 16:22:39,746 valid 050 1.534341e-02 -1.409800
2019-11-05 16:22:48,458 validation loss; R2: 1.524426e-02 -1.165052
2019-11-05 16:22:48,524 epoch 122 lr 1.000000e-04
2019-11-05 16:22:49,273 train 000 1.742543e-02 0.031786
2019-11-05 16:22:59,484 train 050 1.732369e-02 -0.725029
2019-11-05 16:23:09,732 train 100 1.720099e-02 -0.771574
2019-11-05 16:23:19,951 train 150 1.720023e-02 -0.768156
2019-11-05 16:23:30,168 train 200 1.714824e-02 -0.810568
2019-11-05 16:23:40,371 train 250 1.715840e-02 -0.862486
2019-11-05 16:23:50,603 train 300 1.712819e-02 -0.903407
2019-11-05 16:24:00,808 train 350 1.715765e-02 -0.842730
2019-11-05 16:24:10,989 train 400 1.716520e-02 -0.822753
2019-11-05 16:24:21,141 train 450 1.718520e-02 -0.797024
2019-11-05 16:24:31,336 train 500 1.717390e-02 -0.764288
2019-11-05 16:24:41,506 train 550 1.715240e-02 -0.758153
2019-11-05 16:24:51,690 train 600 1.711751e-02 -0.747068
2019-11-05 16:25:01,861 train 650 1.711007e-02 -0.758675
2019-11-05 16:25:12,057 train 700 1.710822e-02 -0.742876
2019-11-05 16:25:22,227 train 750 1.711740e-02 -0.733248
2019-11-05 16:25:32,414 train 800 1.711348e-02 -0.747440
2019-11-05 16:25:42,577 train 850 1.712536e-02 -0.752694
2019-11-05 16:25:45,623 training loss; R2: 1.711881e-02 -0.746845
2019-11-05 16:25:46,214 valid 000 1.807606e-02 -0.941388
2019-11-05 16:25:55,956 valid 050 1.640781e-02 -1.391471
2019-11-05 16:26:04,628 validation loss; R2: 1.645557e-02 -1.478200
2019-11-05 16:26:04,699 epoch 123 lr 1.000000e-04
2019-11-05 16:26:05,433 train 000 1.791516e-02 -0.238725
2019-11-05 16:26:15,673 train 050 1.710848e-02 -0.676830
2019-11-05 16:26:25,887 train 100 1.698894e-02 -0.745702
2019-11-05 16:26:36,052 train 150 1.696615e-02 -0.739554
2019-11-05 16:26:46,226 train 200 1.694414e-02 -1.704791
2019-11-05 16:26:56,375 train 250 1.705248e-02 -1.492275
2019-11-05 16:27:06,556 train 300 1.702546e-02 -1.353027
2019-11-05 16:27:16,703 train 350 1.700508e-02 -1.263279
2019-11-05 16:27:26,853 train 400 1.704577e-02 -1.202202
2019-11-05 16:27:36,986 train 450 1.704136e-02 -1.154622
2019-11-05 16:27:47,164 train 500 1.701036e-02 -1.116769
2019-11-05 16:27:57,315 train 550 1.702238e-02 -1.679078
2019-11-05 16:28:07,458 train 600 1.705289e-02 -1.596565
2019-11-05 16:28:17,579 train 650 1.703663e-02 -1.535158
2019-11-05 16:28:27,708 train 700 1.704048e-02 -1.468518
2019-11-05 16:28:37,854 train 750 1.704332e-02 -1.404315
2019-11-05 16:28:48,030 train 800 1.705960e-02 -1.347320
2019-11-05 16:28:58,154 train 850 1.708979e-02 -1.303025
2019-11-05 16:29:01,190 training loss; R2: 1.709993e-02 -1.291252
2019-11-05 16:29:01,708 valid 000 1.716881e-02 -0.388883
2019-11-05 16:29:11,569 valid 050 1.532997e-02 -1.295617
2019-11-05 16:29:20,298 validation loss; R2: 1.516566e-02 -1.311898
2019-11-05 16:29:20,364 epoch 124 lr 1.000000e-04
2019-11-05 16:29:21,043 train 000 1.539476e-02 -0.113473
2019-11-05 16:29:31,372 train 050 1.770553e-02 -0.740434
2019-11-05 16:29:41,670 train 100 1.733039e-02 -0.764480
2019-11-05 16:29:51,902 train 150 1.742924e-02 -0.850609
2019-11-05 16:30:02,142 train 200 1.732825e-02 -0.806825
2019-11-05 16:30:12,347 train 250 1.734640e-02 -0.736129
2019-11-05 16:30:22,565 train 300 1.732414e-02 -0.692473
2019-11-05 16:30:32,768 train 350 1.733275e-02 -0.747565
2019-11-05 16:30:42,984 train 400 1.726834e-02 -0.820424
2019-11-05 16:30:53,181 train 450 1.718803e-02 -0.813667
2019-11-05 16:31:03,371 train 500 1.717458e-02 -0.817136
2019-11-05 16:31:13,547 train 550 1.716300e-02 -0.811943
2019-11-05 16:31:23,788 train 600 1.713871e-02 -0.808585
2019-11-05 16:31:33,963 train 650 1.711513e-02 -0.810554
2019-11-05 16:31:44,215 train 700 1.711801e-02 -0.787945
2019-11-05 16:31:54,440 train 750 1.714054e-02 -0.780287
2019-11-05 16:32:04,675 train 800 1.715253e-02 -0.803103
2019-11-05 16:32:14,868 train 850 1.715798e-02 -0.820150
2019-11-05 16:32:17,926 training loss; R2: 1.714912e-02 -0.822723
2019-11-05 16:32:18,444 valid 000 1.592761e-02 -1.051451
2019-11-05 16:32:28,344 valid 050 1.576071e-02 -1.233498
2019-11-05 16:32:37,058 validation loss; R2: 1.561596e-02 -1.099642
2019-11-05 16:32:37,129 epoch 125 lr 1.000000e-04
2019-11-05 16:32:37,880 train 000 2.007461e-02 -0.761686
2019-11-05 16:32:48,155 train 050 1.696397e-02 -0.675006
2019-11-05 16:32:58,407 train 100 1.697874e-02 -0.614840
2019-11-05 16:33:08,625 train 150 1.687178e-02 -0.563968
2019-11-05 16:33:18,851 train 200 1.691919e-02 -0.637316
2019-11-05 16:33:29,071 train 250 1.698419e-02 -0.692372
2019-11-05 16:33:39,263 train 300 1.690182e-02 -0.655565
2019-11-05 16:33:49,468 train 350 1.702117e-02 -0.665859
2019-11-05 16:33:59,649 train 400 1.704373e-02 -0.668639
2019-11-05 16:34:09,822 train 450 1.706235e-02 -0.648139
2019-11-05 16:34:20,035 train 500 1.708354e-02 -0.631629
2019-11-05 16:34:30,241 train 550 1.706653e-02 -0.619981
2019-11-05 16:34:40,490 train 600 1.704205e-02 -0.635123
2019-11-05 16:34:50,709 train 650 1.700499e-02 -0.671472
2019-11-05 16:35:00,944 train 700 1.700466e-02 -0.673556
2019-11-05 16:35:11,145 train 750 1.701139e-02 -0.686727
2019-11-05 16:35:21,365 train 800 1.704310e-02 -0.678405
2019-11-05 16:35:31,543 train 850 1.703095e-02 -0.695481
2019-11-05 16:35:34,597 training loss; R2: 1.703901e-02 -0.696886
2019-11-05 16:35:35,117 valid 000 1.476070e-02 -0.139967
2019-11-05 16:35:45,027 valid 050 1.567472e-02 -1.604166
2019-11-05 16:35:53,698 validation loss; R2: 1.560609e-02 -1.591856
2019-11-05 16:35:53,764 epoch 126 lr 1.000000e-04
2019-11-05 16:35:54,489 train 000 1.623010e-02 -0.088349
2019-11-05 16:36:04,686 train 050 1.696825e-02 -0.628374
2019-11-05 16:36:14,901 train 100 1.699615e-02 -0.693583
2019-11-05 16:36:25,068 train 150 1.698872e-02 -0.716637
2019-11-05 16:36:35,157 train 200 1.701594e-02 -0.709104
2019-11-05 16:36:45,222 train 250 1.707738e-02 -0.747266
2019-11-05 16:36:55,320 train 300 1.704351e-02 -0.750032
2019-11-05 16:37:05,435 train 350 1.711160e-02 -0.749929
2019-11-05 16:37:15,616 train 400 1.710091e-02 -0.752949
2019-11-05 16:37:25,782 train 450 1.708544e-02 -0.728012
2019-11-05 16:37:35,963 train 500 1.709096e-02 -0.732451
2019-11-05 16:37:46,115 train 550 1.706577e-02 -0.744824
2019-11-05 16:37:56,305 train 600 1.707831e-02 -0.784867
2019-11-05 16:38:06,458 train 650 1.709900e-02 -0.772321
2019-11-05 16:38:16,642 train 700 1.707471e-02 -0.767729
2019-11-05 16:38:26,783 train 750 1.706236e-02 -0.766832
2019-11-05 16:38:36,968 train 800 1.706722e-02 -0.997967
2019-11-05 16:38:47,149 train 850 1.706798e-02 -0.992192
2019-11-05 16:38:50,188 training loss; R2: 1.707083e-02 -0.982208
2019-11-05 16:38:50,765 valid 000 1.588402e-02 -1.891801
2019-11-05 16:39:00,610 valid 050 1.620799e-02 -1.244885
2019-11-05 16:39:09,259 validation loss; R2: 1.634454e-02 -1.236604
2019-11-05 16:39:09,325 epoch 127 lr 1.000000e-04
2019-11-05 16:39:10,067 train 000 1.938527e-02 -1.673302
2019-11-05 16:39:20,434 train 050 1.664486e-02 -0.499397
2019-11-05 16:39:30,814 train 100 1.688427e-02 -0.804602
2019-11-05 16:39:40,990 train 150 1.696130e-02 -0.821621
2019-11-05 16:39:51,189 train 200 1.704605e-02 -0.815943
2019-11-05 16:40:01,361 train 250 1.710517e-02 -0.813155
2019-11-05 16:40:11,486 train 300 1.711573e-02 -0.789651
2019-11-05 16:40:21,669 train 350 1.715291e-02 -0.777108
2019-11-05 16:40:31,889 train 400 1.716086e-02 -0.755202
2019-11-05 16:40:42,064 train 450 1.717679e-02 -0.735905
2019-11-05 16:40:52,229 train 500 1.717470e-02 -0.746131
2019-11-05 16:41:02,429 train 550 1.716462e-02 -0.742674
2019-11-05 16:41:12,676 train 600 1.714200e-02 -0.741564
2019-11-05 16:41:22,783 train 650 1.714750e-02 -0.752780
2019-11-05 16:41:32,937 train 700 1.713755e-02 -0.761231
2019-11-05 16:41:43,157 train 750 1.713651e-02 -0.750342
2019-11-05 16:41:53,440 train 800 1.714211e-02 -0.736020
2019-11-05 16:42:03,637 train 850 1.713740e-02 -0.744589
2019-11-05 16:42:06,676 training loss; R2: 1.714981e-02 -0.742115
2019-11-05 16:42:07,194 valid 000 1.700500e-02 -0.201135
2019-11-05 16:42:16,999 valid 050 1.593184e-02 -1.926003
2019-11-05 16:42:25,643 validation loss; R2: 1.587241e-02 -1.845883
2019-11-05 16:42:25,709 epoch 128 lr 1.000000e-04
2019-11-05 16:42:26,383 train 000 1.690697e-02 -7.185307
2019-11-05 16:42:36,605 train 050 1.709544e-02 -0.954091
2019-11-05 16:42:46,806 train 100 1.716636e-02 -0.964373
2019-11-05 16:42:56,971 train 150 1.721504e-02 -0.836775
2019-11-05 16:43:07,151 train 200 1.712626e-02 -0.773269
2019-11-05 16:43:17,322 train 250 1.705211e-02 -0.746277
2019-11-05 16:43:27,504 train 300 1.701408e-02 -0.730927
2019-11-05 16:43:37,643 train 350 1.698750e-02 -0.711976
2019-11-05 16:43:47,786 train 400 1.696718e-02 -0.783116
2019-11-05 16:43:57,917 train 450 1.696140e-02 -0.774843
2019-11-05 16:44:08,096 train 500 1.693742e-02 -0.769686
2019-11-05 16:44:18,242 train 550 1.694598e-02 -0.767839
2019-11-05 16:44:28,408 train 600 1.694304e-02 -0.760640
2019-11-05 16:44:38,532 train 650 1.694270e-02 -0.769227
2019-11-05 16:44:48,658 train 700 1.697019e-02 -0.739741
2019-11-05 16:44:58,772 train 750 1.695618e-02 -0.731969
2019-11-05 16:45:08,906 train 800 1.696816e-02 -0.745665
2019-11-05 16:45:19,031 train 850 1.701060e-02 -0.739730
2019-11-05 16:45:22,074 training loss; R2: 1.698806e-02 -0.736804
2019-11-05 16:45:22,596 valid 000 1.520204e-02 -1.178131
2019-11-05 16:45:32,452 valid 050 1.513693e-02 -0.827773
2019-11-05 16:45:41,175 validation loss; R2: 1.481873e-02 -0.914025
2019-11-05 16:45:41,240 epoch 129 lr 1.000000e-04
2019-11-05 16:45:41,940 train 000 1.691222e-02 -0.962219
2019-11-05 16:45:52,152 train 050 1.674013e-02 -0.785858
2019-11-05 16:46:02,344 train 100 1.699809e-02 -0.741045
2019-11-05 16:46:12,492 train 150 1.706884e-02 -0.700338
2019-11-05 16:46:22,674 train 200 1.711321e-02 -0.640127
2019-11-05 16:46:32,816 train 250 1.708965e-02 -0.635584
2019-11-05 16:46:42,972 train 300 1.713300e-02 -0.617827
2019-11-05 16:46:53,134 train 350 1.717488e-02 -0.653750
2019-11-05 16:47:03,345 train 400 1.713451e-02 -0.635443
2019-11-05 16:47:13,514 train 450 1.710435e-02 -0.632942
2019-11-05 16:47:23,693 train 500 1.709928e-02 -0.637256
2019-11-05 16:47:33,837 train 550 1.708970e-02 -0.634645
2019-11-05 16:47:43,996 train 600 1.707178e-02 -0.649479
2019-11-05 16:47:54,132 train 650 1.707226e-02 -0.659662
2019-11-05 16:48:04,331 train 700 1.709141e-02 -0.654451
2019-11-05 16:48:14,518 train 750 1.707437e-02 -0.652475
2019-11-05 16:48:24,748 train 800 1.706794e-02 -0.644586
2019-11-05 16:48:34,940 train 850 1.703949e-02 -0.651358
2019-11-05 16:48:37,993 training loss; R2: 1.704541e-02 -0.653756
2019-11-05 16:48:38,517 valid 000 1.619096e-02 0.182343
2019-11-05 16:48:48,373 valid 050 1.526314e-02 -2.586546
2019-11-05 16:48:57,055 validation loss; R2: 1.499990e-02 -1.734323
2019-11-05 16:48:57,118 epoch 130 lr 1.000000e-04
2019-11-05 16:48:57,788 train 000 1.547094e-02 0.018625
2019-11-05 16:49:08,121 train 050 1.696843e-02 -0.575795
2019-11-05 16:49:18,343 train 100 1.692606e-02 -0.530151
2019-11-05 16:49:28,514 train 150 1.690772e-02 -0.553268
2019-11-05 16:49:38,678 train 200 1.691674e-02 -0.520447
2019-11-05 16:49:48,854 train 250 1.684370e-02 -0.561066
2019-11-05 16:49:59,065 train 300 1.690119e-02 -0.585455
2019-11-05 16:50:09,244 train 350 1.690176e-02 -0.580321
2019-11-05 16:50:19,371 train 400 1.685449e-02 -0.604623
2019-11-05 16:50:29,465 train 450 1.686278e-02 -0.623903
2019-11-05 16:50:39,591 train 500 1.690091e-02 -0.630232
2019-11-05 16:50:49,691 train 550 1.688432e-02 -0.630613
2019-11-05 16:50:59,842 train 600 1.690245e-02 -0.657388
2019-11-05 16:51:09,977 train 650 1.689482e-02 -0.660913
2019-11-05 16:51:20,147 train 700 1.690765e-02 -0.676076
2019-11-05 16:51:30,297 train 750 1.691990e-02 -0.661138
2019-11-05 16:51:40,457 train 800 1.693361e-02 -0.683167
2019-11-05 16:51:50,576 train 850 1.691715e-02 -0.713045
2019-11-05 16:51:53,603 training loss; R2: 1.690835e-02 -0.722940
2019-11-05 16:51:54,181 valid 000 1.479406e-02 -7.630698
2019-11-05 16:52:03,951 valid 050 1.486513e-02 -1.332309
2019-11-05 16:52:12,682 validation loss; R2: 1.465791e-02 -1.220018
2019-11-05 16:52:12,748 epoch 131 lr 1.000000e-04
2019-11-05 16:52:13,444 train 000 1.670823e-02 -0.666718
2019-11-05 16:52:23,693 train 050 1.688783e-02 -0.733158
2019-11-05 16:52:33,933 train 100 1.683516e-02 -0.639613
2019-11-05 16:52:44,034 train 150 1.699374e-02 -0.689189
2019-11-05 16:52:54,265 train 200 1.705460e-02 -0.636922
2019-11-05 16:53:04,442 train 250 1.706971e-02 -0.644319
2019-11-05 16:53:14,597 train 300 1.705583e-02 -0.667478
2019-11-05 16:53:24,792 train 350 1.705195e-02 -0.690421
2019-11-05 16:53:34,993 train 400 1.708584e-02 -0.707198
2019-11-05 16:53:45,175 train 450 1.709788e-02 -0.681757
2019-11-05 16:53:55,349 train 500 1.715354e-02 -0.677492
2019-11-05 16:54:05,492 train 550 1.716036e-02 -0.666121
2019-11-05 16:54:15,580 train 600 1.712070e-02 -0.660250
2019-11-05 16:54:25,712 train 650 1.711626e-02 -0.664263
2019-11-05 16:54:35,902 train 700 1.710376e-02 -0.752986
2019-11-05 16:54:46,069 train 750 1.707966e-02 -0.742461
2019-11-05 16:54:56,232 train 800 1.707121e-02 -0.748871
2019-11-05 16:55:06,373 train 850 1.704038e-02 -0.969181
2019-11-05 16:55:09,415 training loss; R2: 1.703697e-02 -0.961285
2019-11-05 16:55:10,029 valid 000 1.369642e-02 -1.400825
2019-11-05 16:55:19,811 valid 050 1.524231e-02 -1.946455
2019-11-05 16:55:28,499 validation loss; R2: 1.550358e-02 -1.819185
2019-11-05 16:55:28,563 epoch 132 lr 1.000000e-04
2019-11-05 16:55:29,282 train 000 1.495204e-02 0.045580
2019-11-05 16:55:39,517 train 050 1.723818e-02 -0.611419
2019-11-05 16:55:49,755 train 100 1.705028e-02 -0.830464
2019-11-05 16:55:59,934 train 150 1.707916e-02 -0.774117
2019-11-05 16:56:10,114 train 200 1.705763e-02 -0.756214
2019-11-05 16:56:20,270 train 250 1.704043e-02 -0.711371
2019-11-05 16:56:30,417 train 300 1.694254e-02 -0.697479
2019-11-05 16:56:40,499 train 350 1.699383e-02 -0.738292
2019-11-05 16:56:50,579 train 400 1.702437e-02 -0.724719
2019-11-05 16:57:00,644 train 450 1.706137e-02 -0.737715
2019-11-05 16:57:10,782 train 500 1.707514e-02 -0.730864
2019-11-05 16:57:20,918 train 550 1.706863e-02 -0.732667
2019-11-05 16:57:31,073 train 600 1.705481e-02 -0.742971
2019-11-05 16:57:41,220 train 650 1.705887e-02 -0.731339
2019-11-05 16:57:51,404 train 700 1.705773e-02 -0.725628
2019-11-05 16:58:01,543 train 750 1.705375e-02 -0.742401
2019-11-05 16:58:11,718 train 800 1.709823e-02 -0.734611
2019-11-05 16:58:21,853 train 850 1.707154e-02 -0.733021
2019-11-05 16:58:24,892 training loss; R2: 1.705829e-02 -0.731964
2019-11-05 16:58:25,413 valid 000 1.593778e-02 -0.493496
2019-11-05 16:58:35,233 valid 050 1.556981e-02 -1.663814
2019-11-05 16:58:43,902 validation loss; R2: 1.568952e-02 -1.693417
2019-11-05 16:58:43,967 epoch 133 lr 1.000000e-04
2019-11-05 16:58:44,699 train 000 1.644263e-02 -0.554785
2019-11-05 16:58:54,857 train 050 1.682546e-02 -0.462582
2019-11-05 16:59:05,054 train 100 1.677774e-02 -0.729962
2019-11-05 16:59:15,206 train 150 1.690149e-02 -0.670255
2019-11-05 16:59:25,374 train 200 1.700323e-02 -0.636741
2019-11-05 16:59:35,532 train 250 1.684717e-02 -0.613742
2019-11-05 16:59:45,718 train 300 1.685176e-02 -0.628098
2019-11-05 16:59:55,861 train 350 1.681291e-02 -0.632235
2019-11-05 17:00:06,042 train 400 1.680930e-02 -0.646987
2019-11-05 17:00:16,188 train 450 1.681855e-02 -0.654059
2019-11-05 17:00:26,355 train 500 1.682892e-02 -0.797227
2019-11-05 17:00:36,515 train 550 1.682995e-02 -0.799268
2019-11-05 17:00:46,675 train 600 1.684261e-02 -0.789987
2019-11-05 17:00:56,785 train 650 1.684115e-02 -0.781702
2019-11-05 17:01:06,938 train 700 1.684405e-02 -0.800780
2019-11-05 17:01:17,082 train 750 1.684932e-02 -0.826205
2019-11-05 17:01:27,257 train 800 1.687468e-02 -0.830007
2019-11-05 17:01:37,415 train 850 1.687688e-02 -0.823365
2019-11-05 17:01:40,457 training loss; R2: 1.688301e-02 -0.816366
2019-11-05 17:01:41,034 valid 000 1.686497e-02 -0.414402
2019-11-05 17:01:50,855 valid 050 1.630719e-02 -0.999125
2019-11-05 17:01:59,553 validation loss; R2: 1.614441e-02 -1.248378
2019-11-05 17:01:59,620 epoch 134 lr 1.000000e-04
2019-11-05 17:02:00,302 train 000 1.946530e-02 -1.880207
2019-11-05 17:02:10,514 train 050 1.701151e-02 -0.974927
2019-11-05 17:02:20,736 train 100 1.713587e-02 -1.099029
2019-11-05 17:02:30,895 train 150 1.706836e-02 -0.912500
2019-11-05 17:02:41,058 train 200 1.700476e-02 -0.862672
2019-11-05 17:02:51,105 train 250 1.700762e-02 -0.874776
2019-11-05 17:03:01,242 train 300 1.699149e-02 -0.826276
2019-11-05 17:03:11,375 train 350 1.697182e-02 -0.809010
2019-11-05 17:03:21,524 train 400 1.698596e-02 -0.771110
2019-11-05 17:03:31,654 train 450 1.702681e-02 -0.775076
2019-11-05 17:03:41,811 train 500 1.701071e-02 -0.745959
2019-11-05 17:03:51,938 train 550 1.699439e-02 -0.737724
2019-11-05 17:04:02,109 train 600 1.698643e-02 -0.731554
2019-11-05 17:04:12,248 train 650 1.697769e-02 -0.715585
2019-11-05 17:04:22,402 train 700 1.698372e-02 -0.715723
2019-11-05 17:04:32,551 train 750 1.701001e-02 -0.704227
2019-11-05 17:04:42,723 train 800 1.699348e-02 -0.704025
2019-11-05 17:04:52,893 train 850 1.700556e-02 -0.706521
2019-11-05 17:04:55,943 training loss; R2: 1.699927e-02 -0.703539
2019-11-05 17:04:56,459 valid 000 1.612114e-02 -1.283456
2019-11-05 17:05:06,327 valid 050 1.497603e-02 -1.283315
2019-11-05 17:05:15,000 validation loss; R2: 1.502077e-02 -1.210915
2019-11-05 17:05:15,065 epoch 135 lr 1.000000e-04
2019-11-05 17:05:15,817 train 000 1.550504e-02 -1.327531
2019-11-05 17:05:25,952 train 050 1.696838e-02 -0.748938
2019-11-05 17:05:36,085 train 100 1.692205e-02 -0.671374
2019-11-05 17:05:46,199 train 150 1.703510e-02 -0.673999
2019-11-05 17:05:56,412 train 200 1.702145e-02 -0.750708
2019-11-05 17:06:06,510 train 250 1.702150e-02 -0.731757
2019-11-05 17:06:16,602 train 300 1.697883e-02 -0.720989
2019-11-05 17:06:26,758 train 350 1.700642e-02 -0.780315
2019-11-05 17:06:36,969 train 400 1.696778e-02 -0.770180
2019-11-05 17:06:47,195 train 450 1.697744e-02 -0.758068
2019-11-05 17:06:57,412 train 500 1.695652e-02 -0.764377
2019-11-05 17:07:07,592 train 550 1.695530e-02 -0.746891
2019-11-05 17:07:17,797 train 600 1.694389e-02 -0.762846
2019-11-05 17:07:28,007 train 650 1.690020e-02 -0.766370
2019-11-05 17:07:38,244 train 700 1.686866e-02 -0.758538
2019-11-05 17:07:48,429 train 750 1.687680e-02 -0.759914
2019-11-05 17:07:58,650 train 800 1.689511e-02 -1.036990
2019-11-05 17:08:08,865 train 850 1.692501e-02 -1.003405
2019-11-05 17:08:11,917 training loss; R2: 1.692215e-02 -0.994556
2019-11-05 17:08:12,458 valid 000 1.638018e-02 -1.579446
2019-11-05 17:08:22,462 valid 050 1.646378e-02 -1.154022
2019-11-05 17:08:31,182 validation loss; R2: 1.674830e-02 -13.153828
2019-11-05 17:08:31,247 epoch 136 lr 1.000000e-04
2019-11-05 17:08:31,997 train 000 1.897618e-02 -0.534279
2019-11-05 17:08:42,264 train 050 1.720398e-02 -0.669200
2019-11-05 17:08:52,473 train 100 1.701118e-02 -0.697026
2019-11-05 17:09:02,647 train 150 1.691112e-02 -0.701957
2019-11-05 17:09:12,846 train 200 1.695299e-02 -0.690655
2019-11-05 17:09:23,017 train 250 1.687980e-02 -0.651973
2019-11-05 17:09:33,224 train 300 1.691299e-02 -0.672141
2019-11-05 17:09:43,402 train 350 1.688454e-02 -0.687475
2019-11-05 17:09:53,628 train 400 1.685638e-02 -0.816121
2019-11-05 17:10:03,799 train 450 1.684574e-02 -0.791821
2019-11-05 17:10:14,009 train 500 1.689079e-02 -0.778714
2019-11-05 17:10:24,181 train 550 1.686730e-02 -0.799710
2019-11-05 17:10:34,390 train 600 1.690314e-02 -0.801595
2019-11-05 17:10:44,570 train 650 1.689684e-02 -0.779847
2019-11-05 17:10:54,755 train 700 1.691224e-02 -0.773386
2019-11-05 17:11:04,925 train 750 1.691721e-02 -0.773971
2019-11-05 17:11:15,087 train 800 1.692049e-02 -0.821195
2019-11-05 17:11:25,252 train 850 1.693041e-02 -0.801476
2019-11-05 17:11:28,308 training loss; R2: 1.693178e-02 -0.796047
2019-11-05 17:11:28,882 valid 000 1.436218e-02 -2.288183
2019-11-05 17:11:38,700 valid 050 1.525209e-02 -1.216111
2019-11-05 17:11:47,352 validation loss; R2: 1.507050e-02 -1.256259
2019-11-05 17:11:47,419 epoch 137 lr 1.000000e-04
2019-11-05 17:11:48,172 train 000 1.316794e-02 -1.121103
2019-11-05 17:11:58,357 train 050 1.758208e-02 -0.716899
2019-11-05 17:12:08,610 train 100 1.724185e-02 -0.713300
2019-11-05 17:12:18,794 train 150 1.720557e-02 -0.750131
2019-11-05 17:12:29,014 train 200 1.713447e-02 -0.727535
2019-11-05 17:12:39,239 train 250 1.704218e-02 -0.737995
2019-11-05 17:12:49,382 train 300 1.703607e-02 -0.726084
2019-11-05 17:12:59,497 train 350 1.697524e-02 -0.725019
2019-11-05 17:13:09,757 train 400 1.691397e-02 -0.754233
2019-11-05 17:13:19,959 train 450 1.690324e-02 -0.759860
2019-11-05 17:13:30,104 train 500 1.686873e-02 -0.771449
2019-11-05 17:13:40,160 train 550 1.684472e-02 -0.754002
2019-11-05 17:13:50,236 train 600 1.682853e-02 -0.743694
2019-11-05 17:14:00,277 train 650 1.683951e-02 -0.732968
2019-11-05 17:14:10,341 train 700 1.682782e-02 -0.734810
2019-11-05 17:14:20,398 train 750 1.684069e-02 -0.718591
2019-11-05 17:14:30,470 train 800 1.683622e-02 -0.733313
2019-11-05 17:14:40,518 train 850 1.683243e-02 -0.717996
2019-11-05 17:14:43,542 training loss; R2: 1.682825e-02 -0.710334
2019-11-05 17:14:44,058 valid 000 1.465975e-02 -1.286576
2019-11-05 17:14:53,860 valid 050 1.468141e-02 -1.159794
2019-11-05 17:15:02,599 validation loss; R2: 1.455220e-02 -1.051901
2019-11-05 17:15:02,673 epoch 138 lr 1.000000e-04
2019-11-05 17:15:03,372 train 000 1.900479e-02 -0.602155
2019-11-05 17:15:13,566 train 050 1.663647e-02 -0.608669
2019-11-05 17:15:23,759 train 100 1.704182e-02 -0.526801
2019-11-05 17:15:33,902 train 150 1.702895e-02 -0.561903
2019-11-05 17:15:44,047 train 200 1.687975e-02 -0.562692
2019-11-05 17:15:54,165 train 250 1.696450e-02 -0.540437
2019-11-05 17:16:04,330 train 300 1.693136e-02 -0.555319
2019-11-05 17:16:14,479 train 350 1.694557e-02 -0.563059
2019-11-05 17:16:24,677 train 400 1.700525e-02 -0.576516
2019-11-05 17:16:34,834 train 450 1.701417e-02 -0.581576
2019-11-05 17:16:45,024 train 500 1.696881e-02 -0.588350
2019-11-05 17:16:55,228 train 550 1.696111e-02 -0.611458
2019-11-05 17:17:05,396 train 600 1.694156e-02 -0.738482
2019-11-05 17:17:15,553 train 650 1.692024e-02 -0.733584
2019-11-05 17:17:25,769 train 700 1.691153e-02 -0.729441
2019-11-05 17:17:35,854 train 750 1.693411e-02 -0.722769
2019-11-05 17:17:45,989 train 800 1.693032e-02 -0.723942
2019-11-05 17:17:56,163 train 850 1.690737e-02 -0.714655
2019-11-05 17:17:59,215 training loss; R2: 1.691242e-02 -0.722616
2019-11-05 17:17:59,809 valid 000 1.378402e-02 0.087998
2019-11-05 17:18:09,689 valid 050 1.538341e-02 -1.426935
2019-11-05 17:18:18,357 validation loss; R2: 1.541356e-02 -1.322385
2019-11-05 17:18:18,421 epoch 139 lr 1.000000e-04
2019-11-05 17:18:19,177 train 000 1.485027e-02 -0.230295
2019-11-05 17:18:29,343 train 050 1.667919e-02 -0.531376
2019-11-05 17:18:39,509 train 100 1.677168e-02 -0.915656
2019-11-05 17:18:49,625 train 150 1.692498e-02 -0.833826
2019-11-05 17:18:59,776 train 200 1.693607e-02 -0.788659
2019-11-05 17:19:09,920 train 250 1.689477e-02 -0.747140
2019-11-05 17:19:20,064 train 300 1.690903e-02 -0.753845
2019-11-05 17:19:30,261 train 350 1.699234e-02 -0.753832
2019-11-05 17:19:40,450 train 400 1.692339e-02 -0.756563
2019-11-05 17:19:50,550 train 450 1.690832e-02 -0.833087
2019-11-05 17:20:00,639 train 500 1.688962e-02 -0.822083
2019-11-05 17:20:10,702 train 550 1.691406e-02 -0.800595
2019-11-05 17:20:20,797 train 600 1.693105e-02 -0.788744
2019-11-05 17:20:30,866 train 650 1.693667e-02 -0.789357
2019-11-05 17:20:40,975 train 700 1.695498e-02 -0.785739
2019-11-05 17:20:51,045 train 750 1.696280e-02 -0.773509
2019-11-05 17:21:01,153 train 800 1.699302e-02 -0.764134
2019-11-05 17:21:11,221 train 850 1.699031e-02 -0.753289
2019-11-05 17:21:14,243 training loss; R2: 1.698786e-02 -0.763670
2019-11-05 17:21:14,763 valid 000 1.287332e-02 -8.261764
2019-11-05 17:21:24,545 valid 050 1.515560e-02 -1.652595
2019-11-05 17:21:33,213 validation loss; R2: 1.509954e-02 -1.721342
2019-11-05 17:21:33,277 epoch 140 lr 1.000000e-04
2019-11-05 17:21:34,023 train 000 1.628021e-02 -0.639667
2019-11-05 17:21:44,106 train 050 1.686196e-02 -0.657930
2019-11-05 17:21:54,240 train 100 1.673629e-02 -0.613488
2019-11-05 17:22:04,327 train 150 1.672008e-02 -0.615914
2019-11-05 17:22:14,425 train 200 1.684415e-02 -0.601156
2019-11-05 17:22:24,497 train 250 1.684949e-02 -0.630801
2019-11-05 17:22:34,633 train 300 1.688949e-02 -0.616470
2019-11-05 17:22:44,752 train 350 1.686999e-02 -0.614684
2019-11-05 17:22:54,903 train 400 1.684923e-02 -0.616668
2019-11-05 17:23:05,046 train 450 1.681131e-02 -0.608133
2019-11-05 17:23:15,204 train 500 1.681481e-02 -0.621147
2019-11-05 17:23:25,323 train 550 1.681337e-02 -0.616160
2019-11-05 17:23:35,503 train 600 1.679736e-02 -0.673875
2019-11-05 17:23:45,684 train 650 1.682080e-02 -0.652160
2019-11-05 17:23:55,899 train 700 1.681588e-02 -0.659896
2019-11-05 17:24:06,043 train 750 1.684526e-02 -0.662097
2019-11-05 17:24:16,171 train 800 1.684901e-02 -0.663755
2019-11-05 17:24:26,275 train 850 1.685543e-02 -0.665304
2019-11-05 17:24:29,316 training loss; R2: 1.685326e-02 -0.670749
2019-11-05 17:24:29,896 valid 000 1.416296e-02 -1.018210
2019-11-05 17:24:39,725 valid 050 1.668802e-02 -1.793376
2019-11-05 17:24:48,374 validation loss; R2: 1.647885e-02 -1.646688
2019-11-05 17:24:48,445 epoch 141 lr 1.000000e-04
2019-11-05 17:24:49,117 train 000 1.491772e-02 0.020344
2019-11-05 17:24:59,337 train 050 1.743735e-02 -0.579588
2019-11-05 17:25:09,529 train 100 1.737137e-02 -0.705693
2019-11-05 17:25:19,703 train 150 1.715265e-02 -0.693730
2019-11-05 17:25:29,867 train 200 1.702526e-02 -0.702253
2019-11-05 17:25:40,013 train 250 1.695351e-02 -0.681429
2019-11-05 17:25:50,177 train 300 1.692850e-02 -0.668973
2019-11-05 17:26:00,303 train 350 1.691799e-02 -0.720906
2019-11-05 17:26:10,459 train 400 1.688864e-02 -0.702719
2019-11-05 17:26:20,604 train 450 1.689706e-02 -0.680363
2019-11-05 17:26:30,785 train 500 1.687155e-02 -0.671095
2019-11-05 17:26:40,977 train 550 1.684136e-02 -0.683832
2019-11-05 17:26:51,185 train 600 1.683686e-02 -0.679315
2019-11-05 17:27:01,377 train 650 1.686519e-02 -0.670292
2019-11-05 17:27:11,572 train 700 1.687993e-02 -0.668952
2019-11-05 17:27:21,750 train 750 1.687673e-02 -0.660677
2019-11-05 17:27:31,967 train 800 1.688439e-02 -0.643891
2019-11-05 17:27:42,149 train 850 1.689602e-02 -0.663168
2019-11-05 17:27:45,199 training loss; R2: 1.689051e-02 -0.658926
2019-11-05 17:27:45,765 valid 000 1.692121e-02 -0.030792
2019-11-05 17:27:55,620 valid 050 1.541001e-02 -1.298143
2019-11-05 17:28:04,318 validation loss; R2: 1.551910e-02 -1.206515
2019-11-05 17:28:04,384 epoch 142 lr 1.000000e-04
2019-11-05 17:28:05,121 train 000 2.305930e-02 -5.807347
2019-11-05 17:28:15,394 train 050 1.685900e-02 -0.774895
2019-11-05 17:28:25,642 train 100 1.669021e-02 -0.827177
2019-11-05 17:28:35,881 train 150 1.663081e-02 -0.806424
2019-11-05 17:28:46,114 train 200 1.667830e-02 -0.778659
2019-11-05 17:28:56,349 train 250 1.681685e-02 -0.831194
2019-11-05 17:29:06,594 train 300 1.684687e-02 -0.825894
2019-11-05 17:29:16,841 train 350 1.680945e-02 -0.759659
2019-11-05 17:29:27,091 train 400 1.683077e-02 -0.795623
2019-11-05 17:29:37,320 train 450 1.686861e-02 -0.763060
2019-11-05 17:29:47,575 train 500 1.682644e-02 -0.779558
2019-11-05 17:29:57,761 train 550 1.681727e-02 -0.754088
2019-11-05 17:30:07,974 train 600 1.682041e-02 -0.746156
2019-11-05 17:30:18,200 train 650 1.682868e-02 -0.725789
2019-11-05 17:30:28,459 train 700 1.681780e-02 -0.706234
2019-11-05 17:30:38,664 train 750 1.683160e-02 -0.693177
2019-11-05 17:30:48,879 train 800 1.682579e-02 -0.691205
2019-11-05 17:30:59,187 train 850 1.681774e-02 -0.695399
2019-11-05 17:31:02,290 training loss; R2: 1.681949e-02 -0.698936
2019-11-05 17:31:02,864 valid 000 1.906471e-02 -0.621810
2019-11-05 17:31:12,730 valid 050 1.575923e-02 -1.413478
2019-11-05 17:31:21,625 validation loss; R2: 1.589075e-02 -1.183171
2019-11-05 17:31:21,692 epoch 143 lr 1.000000e-04
2019-11-05 17:31:22,445 train 000 1.577989e-02 -0.398792
2019-11-05 17:31:32,860 train 050 1.656096e-02 -1.124100
2019-11-05 17:31:43,193 train 100 1.670373e-02 -0.938670
2019-11-05 17:31:53,396 train 150 1.677181e-02 -0.939437
2019-11-05 17:32:03,622 train 200 1.680870e-02 -0.815024
2019-11-05 17:32:13,787 train 250 1.677208e-02 -0.763067
2019-11-05 17:32:23,978 train 300 1.678655e-02 -0.744553
2019-11-05 17:32:34,142 train 350 1.676102e-02 -0.723983
2019-11-05 17:32:44,334 train 400 1.678344e-02 -0.744156
2019-11-05 17:32:54,508 train 450 1.679673e-02 -0.729503
2019-11-05 17:33:04,695 train 500 1.680628e-02 -5.177687
2019-11-05 17:33:14,840 train 550 1.680753e-02 -4.763274
2019-11-05 17:33:25,023 train 600 1.678208e-02 -4.426113
2019-11-05 17:33:35,189 train 650 1.679055e-02 -4.152788
2019-11-05 17:33:45,360 train 700 1.681560e-02 -3.895310
2019-11-05 17:33:55,524 train 750 1.681579e-02 -3.682834
2019-11-05 17:34:05,717 train 800 1.681298e-02 -3.504851
2019-11-05 17:34:15,870 train 850 1.681370e-02 -3.357790
2019-11-05 17:34:18,911 training loss; R2: 1.681136e-02 -3.305581
2019-11-05 17:34:19,454 valid 000 1.278212e-02 -1.922842
2019-11-05 17:34:29,696 valid 050 1.467619e-02 -1.146535
2019-11-05 17:34:38,397 validation loss; R2: 1.481025e-02 -1.169606
2019-11-05 17:34:38,465 epoch 144 lr 1.000000e-04
2019-11-05 17:34:39,199 train 000 1.825156e-02 -0.313917
2019-11-05 17:34:49,387 train 050 1.694738e-02 -0.770409
2019-11-05 17:34:59,549 train 100 1.688514e-02 -0.751100
2019-11-05 17:35:09,833 train 150 1.680578e-02 -0.685739
2019-11-05 17:35:20,202 train 200 1.684059e-02 -0.654647
2019-11-05 17:35:30,512 train 250 1.692774e-02 -0.652530
2019-11-05 17:35:40,939 train 300 1.693455e-02 -0.656500
2019-11-05 17:35:51,318 train 350 1.691459e-02 -0.718538
2019-11-05 17:36:01,718 train 400 1.691751e-02 -0.746719
2019-11-05 17:36:12,086 train 450 1.685713e-02 -0.727735
2019-11-05 17:36:22,495 train 500 1.689301e-02 -0.722472
2019-11-05 17:36:32,850 train 550 1.691473e-02 -0.738640
2019-11-05 17:36:43,064 train 600 1.693026e-02 -0.749272
2019-11-05 17:36:53,261 train 650 1.692304e-02 -0.735098
2019-11-05 17:37:03,472 train 700 1.695657e-02 -0.738333
2019-11-05 17:37:13,633 train 750 1.695939e-02 -0.747568
2019-11-05 17:37:23,826 train 800 1.692649e-02 -0.743440
2019-11-05 17:37:34,321 train 850 1.692497e-02 -0.752093
2019-11-05 17:37:37,472 training loss; R2: 1.691994e-02 -0.757454
2019-11-05 17:37:38,011 valid 000 1.626834e-02 -3.938924
2019-11-05 17:37:48,144 valid 050 1.575325e-02 -3.101402
2019-11-05 17:37:56,814 validation loss; R2: 1.571217e-02 -2.324917
2019-11-05 17:37:56,880 epoch 145 lr 1.000000e-04
2019-11-05 17:37:57,551 train 000 1.817153e-02 -0.890169
2019-11-05 17:38:07,797 train 050 1.676094e-02 -1.010053
2019-11-05 17:38:17,991 train 100 1.682243e-02 -0.882033
2019-11-05 17:38:28,155 train 150 1.680181e-02 -0.958170
2019-11-05 17:38:38,355 train 200 1.684803e-02 -0.885151
2019-11-05 17:38:48,534 train 250 1.685735e-02 -0.867433
2019-11-05 17:38:58,735 train 300 1.683398e-02 -0.851727
2019-11-05 17:39:08,899 train 350 1.682581e-02 -0.791315
2019-11-05 17:39:19,092 train 400 1.681973e-02 -0.763320
2019-11-05 17:39:29,262 train 450 1.681125e-02 -4.711715
2019-11-05 17:39:39,425 train 500 1.682763e-02 -4.308820
2019-11-05 17:39:49,580 train 550 1.681103e-02 -4.018005
2019-11-05 17:39:59,785 train 600 1.683051e-02 -3.739505
2019-11-05 17:40:09,975 train 650 1.679321e-02 -3.532655
2019-11-05 17:40:20,198 train 700 1.677894e-02 -3.333531
2019-11-05 17:40:30,398 train 750 1.675526e-02 -3.146383
2019-11-05 17:40:40,593 train 800 1.675926e-02 -3.004281
2019-11-05 17:40:50,774 train 850 1.675412e-02 -2.849841
2019-11-05 17:40:53,824 training loss; R2: 1.675363e-02 -2.808579
2019-11-05 17:40:54,352 valid 000 1.467954e-02 0.037923
2019-11-05 17:41:04,397 valid 050 1.479061e-02 -0.995507
2019-11-05 17:41:13,076 validation loss; R2: 1.471355e-02 -1.373434
2019-11-05 17:41:13,145 epoch 146 lr 1.000000e-04
2019-11-05 17:41:13,879 train 000 1.965683e-02 -0.355283
2019-11-05 17:41:24,040 train 050 1.675263e-02 -137.354216
2019-11-05 17:41:34,231 train 100 1.683009e-02 -69.933867
2019-11-05 17:41:44,427 train 150 1.673950e-02 -46.986271
2019-11-05 17:41:54,552 train 200 1.659171e-02 -35.427485
2019-11-05 17:42:04,630 train 250 1.665990e-02 -28.483506
2019-11-05 17:42:14,804 train 300 1.671424e-02 -23.884414
2019-11-05 17:42:24,988 train 350 1.676694e-02 -20.608251
2019-11-05 17:42:35,081 train 400 1.682179e-02 -18.119778
2019-11-05 17:42:45,149 train 450 1.682072e-02 -16.159462
2019-11-05 17:42:55,309 train 500 1.684253e-02 -14.673078
2019-11-05 17:43:05,311 train 550 1.679321e-02 -13.410105
2019-11-05 17:43:15,470 train 600 1.682437e-02 -12.348765
2019-11-05 17:43:25,548 train 650 1.680395e-02 -11.464112
2019-11-05 17:43:35,636 train 700 1.679481e-02 -10.683994
2019-11-05 17:43:45,769 train 750 1.681796e-02 -10.021850
2019-11-05 17:43:55,924 train 800 1.681777e-02 -9.432450
2019-11-05 17:44:05,962 train 850 1.681033e-02 -8.941163
2019-11-05 17:44:08,973 training loss; R2: 1.681270e-02 -8.802588
2019-11-05 17:44:09,523 valid 000 1.562932e-02 -0.317903
2019-11-05 17:44:19,354 valid 050 1.514361e-02 -1.218404
2019-11-05 17:44:28,045 validation loss; R2: 1.497493e-02 -1.353677
2019-11-05 17:44:28,109 epoch 147 lr 1.000000e-04
2019-11-05 17:44:28,813 train 000 1.681755e-02 -0.689306
2019-11-05 17:44:38,986 train 050 1.670750e-02 -0.740040
2019-11-05 17:44:49,178 train 100 1.670029e-02 -0.754503
2019-11-05 17:44:59,371 train 150 1.665384e-02 -0.744827
2019-11-05 17:45:09,524 train 200 1.669613e-02 -0.810835
2019-11-05 17:45:19,648 train 250 1.670112e-02 -0.914937
2019-11-05 17:45:29,915 train 300 1.673074e-02 -0.863970
2019-11-05 17:45:40,075 train 350 1.670937e-02 -0.869090
2019-11-05 17:45:50,204 train 400 1.668203e-02 -0.834199
2019-11-05 17:46:00,398 train 450 1.671140e-02 -0.831832
2019-11-05 17:46:10,631 train 500 1.672385e-02 -0.819722
2019-11-05 17:46:20,701 train 550 1.675400e-02 -0.793190
2019-11-05 17:46:30,864 train 600 1.677127e-02 -0.769828
2019-11-05 17:46:41,051 train 650 1.677619e-02 -0.768458
2019-11-05 17:46:51,166 train 700 1.676665e-02 -0.773175
2019-11-05 17:47:01,254 train 750 1.677307e-02 -0.778765
2019-11-05 17:47:11,451 train 800 1.677108e-02 -0.783639
2019-11-05 17:47:21,575 train 850 1.680757e-02 -0.787499
2019-11-05 17:47:24,594 training loss; R2: 1.679791e-02 -0.808679
2019-11-05 17:47:25,113 valid 000 1.536394e-02 -0.252772
2019-11-05 17:47:34,911 valid 050 1.563296e-02 -1.824025
2019-11-05 17:47:43,556 validation loss; R2: 1.560094e-02 -1.869431
2019-11-05 17:47:43,621 epoch 148 lr 1.000000e-04
2019-11-05 17:47:44,371 train 000 1.617156e-02 -0.726589
2019-11-05 17:47:54,477 train 050 1.688593e-02 -0.830380
2019-11-05 17:48:04,594 train 100 1.704537e-02 -0.744406
2019-11-05 17:48:14,770 train 150 1.706368e-02 -0.717131
2019-11-05 17:48:24,948 train 200 1.707076e-02 -0.726893
2019-11-05 17:48:35,043 train 250 1.701606e-02 -0.685583
2019-11-05 17:48:45,134 train 300 1.693444e-02 -0.697720
2019-11-05 17:48:55,185 train 350 1.694491e-02 -0.706090
2019-11-05 17:49:05,334 train 400 1.691372e-02 -0.690372
2019-11-05 17:49:15,490 train 450 1.688947e-02 -0.695471
2019-11-05 17:49:25,568 train 500 1.683294e-02 -0.694584
2019-11-05 17:49:35,607 train 550 1.682326e-02 -0.712206
2019-11-05 17:49:45,770 train 600 1.682110e-02 -0.709186
2019-11-05 17:49:55,863 train 650 1.681592e-02 -0.695081
2019-11-05 17:50:05,915 train 700 1.683009e-02 -0.677585
2019-11-05 17:50:16,015 train 750 1.685755e-02 -0.661578
2019-11-05 17:50:26,188 train 800 1.682404e-02 -0.654234
2019-11-05 17:50:36,286 train 850 1.684147e-02 -0.673884
2019-11-05 17:50:39,299 training loss; R2: 1.683959e-02 -0.671024
2019-11-05 17:50:39,853 valid 000 1.370238e-02 -0.412762
2019-11-05 17:50:49,656 valid 050 1.498291e-02 -1.636811
2019-11-05 17:50:58,333 validation loss; R2: 1.501902e-02 -1.327782
2019-11-05 17:50:58,390 epoch 149 lr 1.000000e-04
2019-11-05 17:50:59,124 train 000 1.890752e-02 -1.236200
2019-11-05 17:51:09,495 train 050 1.711421e-02 -0.780236
2019-11-05 17:51:19,686 train 100 1.696877e-02 -0.818788
2019-11-05 17:51:29,873 train 150 1.693275e-02 -0.786117
2019-11-05 17:51:40,060 train 200 1.686964e-02 -0.778448
2019-11-05 17:51:50,210 train 250 1.691585e-02 -0.788763
2019-11-05 17:52:00,369 train 300 1.700046e-02 -0.774661
2019-11-05 17:52:10,508 train 350 1.698542e-02 -0.759816
2019-11-05 17:52:20,669 train 400 1.695796e-02 -0.748829
2019-11-05 17:52:30,812 train 450 1.699263e-02 -0.723149
2019-11-05 17:52:40,961 train 500 1.701101e-02 -0.715812
2019-11-05 17:52:51,133 train 550 1.703210e-02 -0.720764
2019-11-05 17:53:01,319 train 600 1.702214e-02 -0.716263
2019-11-05 17:53:11,486 train 650 1.700047e-02 -0.703588
2019-11-05 17:53:21,688 train 700 1.698699e-02 -0.700306
2019-11-05 17:53:31,815 train 750 1.696632e-02 -0.708243
2019-11-05 17:53:41,974 train 800 1.697513e-02 -0.704250
2019-11-05 17:53:52,101 train 850 1.695358e-02 -0.702494
2019-11-05 17:53:55,136 training loss; R2: 1.695182e-02 -0.716028
2019-11-05 17:53:55,659 valid 000 1.686084e-02 -2.335010
2019-11-05 17:54:05,542 valid 050 1.456726e-02 -1.102328
2019-11-05 17:54:14,222 validation loss; R2: 1.478419e-02 -1.345471
2019-11-05 17:54:14,288 epoch 150 lr 1.000000e-04
2019-11-05 17:54:15,017 train 000 2.199686e-02 -0.663338
2019-11-05 17:54:25,264 train 050 1.689585e-02 -0.637347
2019-11-05 17:54:35,506 train 100 1.675641e-02 -0.954993
2019-11-05 17:54:45,661 train 150 1.676760e-02 -0.858335
2019-11-05 17:54:55,820 train 200 1.672951e-02 -0.821911
2019-11-05 17:55:05,955 train 250 1.668981e-02 -0.800878
2019-11-05 17:55:16,105 train 300 1.670850e-02 -0.849656
2019-11-05 17:55:26,236 train 350 1.675073e-02 -0.819280
2019-11-05 17:55:36,400 train 400 1.674245e-02 -0.796934
2019-11-05 17:55:46,572 train 450 1.671456e-02 -0.783084
2019-11-05 17:55:56,819 train 500 1.670541e-02 -0.767397
2019-11-05 17:56:07,045 train 550 1.672129e-02 -0.752700
2019-11-05 17:56:17,279 train 600 1.675129e-02 -0.757405
2019-11-05 17:56:27,499 train 650 1.677055e-02 -0.739787
2019-11-05 17:56:37,749 train 700 1.675835e-02 -0.731075
2019-11-05 17:56:47,931 train 750 1.678262e-02 -0.729098
2019-11-05 17:56:58,137 train 800 1.679392e-02 -0.706308
2019-11-05 17:57:08,329 train 850 1.680445e-02 -0.699669
2019-11-05 17:57:11,384 training loss; R2: 1.680178e-02 -0.701515
2019-11-05 17:57:11,949 valid 000 1.911917e-02 0.079642
2019-11-05 17:57:21,828 valid 050 1.485113e-02 -3.046537
2019-11-05 17:57:30,529 validation loss; R2: 1.495258e-02 -2.455592
2019-11-05 17:57:30,595 epoch 151 lr 1.000000e-04
2019-11-05 17:57:31,274 train 000 1.579688e-02 0.044874
2019-11-05 17:57:41,512 train 050 1.663634e-02 -0.702869
2019-11-05 17:57:51,742 train 100 1.669060e-02 -0.728718
2019-11-05 17:58:01,943 train 150 1.666740e-02 -0.622752
2019-11-05 17:58:12,149 train 200 1.672785e-02 -0.643054
2019-11-05 17:58:22,316 train 250 1.670278e-02 -0.656901
2019-11-05 17:58:32,499 train 300 1.670417e-02 -0.669034
2019-11-05 17:58:42,639 train 350 1.674150e-02 -0.668944
2019-11-05 17:58:52,824 train 400 1.671097e-02 -0.654755
2019-11-05 17:59:02,967 train 450 1.668019e-02 -0.677056
2019-11-05 17:59:13,135 train 500 1.671819e-02 -0.676374
2019-11-05 17:59:23,298 train 550 1.670612e-02 -0.660388
2019-11-05 17:59:33,475 train 600 1.671613e-02 -0.644638
2019-11-05 17:59:43,644 train 650 1.668314e-02 -0.644197
2019-11-05 17:59:53,862 train 700 1.670017e-02 -0.640072
2019-11-05 18:00:04,018 train 750 1.669928e-02 -0.643317
2019-11-05 18:00:14,191 train 800 1.670828e-02 -0.658020
2019-11-05 18:00:24,358 train 850 1.672603e-02 -0.679730
2019-11-05 18:00:27,404 training loss; R2: 1.673283e-02 -0.676082
2019-11-05 18:00:27,913 valid 000 1.698259e-02 -0.134754
2019-11-05 18:00:37,710 valid 050 1.497996e-02 -2.555297
2019-11-05 18:00:46,382 validation loss; R2: 1.493358e-02 -2.069641
2019-11-05 18:00:46,447 epoch 152 lr 1.000000e-04
2019-11-05 18:00:47,123 train 000 1.842280e-02 -0.232847
2019-11-05 18:00:57,346 train 050 1.647810e-02 -1.005633
2019-11-05 18:01:07,538 train 100 1.652928e-02 -0.900525
2019-11-05 18:01:17,702 train 150 1.653030e-02 -0.950786
2019-11-05 18:01:27,850 train 200 1.650844e-02 -0.946429
2019-11-05 18:01:37,984 train 250 1.658027e-02 -0.870321
2019-11-05 18:01:48,135 train 300 1.656478e-02 -0.794366
2019-11-05 18:01:58,260 train 350 1.656061e-02 -0.804980
2019-11-05 18:02:08,413 train 400 1.656674e-02 -0.762622
2019-11-05 18:02:18,563 train 450 1.661041e-02 -0.759433
2019-11-05 18:02:28,744 train 500 1.660545e-02 -0.777314
2019-11-05 18:02:38,914 train 550 1.663965e-02 -0.773403
2019-11-05 18:02:49,081 train 600 1.667345e-02 -0.759031
2019-11-05 18:02:59,168 train 650 1.669907e-02 -0.759753
2019-11-05 18:03:09,347 train 700 1.673014e-02 -0.756401
2019-11-05 18:03:19,419 train 750 1.674691e-02 -0.770016
2019-11-05 18:03:29,574 train 800 1.674379e-02 -0.758270
2019-11-05 18:03:39,704 train 850 1.672524e-02 -0.751224
2019-11-05 18:03:42,737 training loss; R2: 1.672757e-02 -0.750477
2019-11-05 18:03:43,259 valid 000 1.427520e-02 -0.185935
2019-11-05 18:03:53,070 valid 050 1.499634e-02 -1.462795
2019-11-05 18:04:01,744 validation loss; R2: 1.524313e-02 -1.235543
2019-11-05 18:04:01,813 epoch 153 lr 1.000000e-04
2019-11-05 18:04:02,503 train 000 1.640446e-02 -0.265883
2019-11-05 18:04:12,737 train 050 1.682036e-02 -0.581373
2019-11-05 18:04:22,933 train 100 1.677216e-02 -0.690104
2019-11-05 18:04:33,081 train 150 1.665292e-02 -0.599009
2019-11-05 18:04:43,243 train 200 1.664997e-02 -0.658280
2019-11-05 18:04:53,385 train 250 1.661357e-02 -0.711783
2019-11-05 18:05:03,558 train 300 1.668570e-02 -0.734620
2019-11-05 18:05:13,698 train 350 1.674703e-02 -0.708155
2019-11-05 18:05:23,855 train 400 1.679575e-02 -0.714897
2019-11-05 18:05:34,000 train 450 1.681338e-02 -0.746201
2019-11-05 18:05:44,185 train 500 1.681600e-02 -0.716095
2019-11-05 18:05:54,348 train 550 1.678010e-02 -0.702566
2019-11-05 18:06:04,523 train 600 1.677489e-02 -0.699772
2019-11-05 18:06:14,698 train 650 1.676389e-02 -0.693540
2019-11-05 18:06:24,893 train 700 1.676010e-02 -0.708788
2019-11-05 18:06:35,014 train 750 1.677118e-02 -0.697432
2019-11-05 18:06:45,115 train 800 1.675613e-02 -0.713841
2019-11-05 18:06:55,260 train 850 1.671870e-02 -0.730659
2019-11-05 18:06:58,301 training loss; R2: 1.672996e-02 -0.726457
2019-11-05 18:06:58,827 valid 000 1.694598e-02 0.115183
2019-11-05 18:07:08,641 valid 050 1.558040e-02 -1.100154
2019-11-05 18:07:17,354 validation loss; R2: 1.569890e-02 -0.954433
2019-11-05 18:07:17,429 epoch 154 lr 1.000000e-04
2019-11-05 18:07:18,116 train 000 1.820311e-02 -0.601037
2019-11-05 18:07:28,513 train 050 1.646056e-02 -0.655730
2019-11-05 18:07:38,894 train 100 1.649800e-02 -0.876418
2019-11-05 18:07:49,190 train 150 1.665131e-02 -0.757991
2019-11-05 18:07:59,385 train 200 1.672219e-02 -0.792992
2019-11-05 18:08:09,531 train 250 1.672083e-02 -0.767478
2019-11-05 18:08:19,687 train 300 1.672406e-02 -0.743256
2019-11-05 18:08:29,831 train 350 1.674631e-02 -0.735344
2019-11-05 18:08:40,033 train 400 1.675555e-02 -0.735144
2019-11-05 18:08:50,071 train 450 1.671704e-02 -0.915927
2019-11-05 18:09:00,166 train 500 1.675523e-02 -0.864591
2019-11-05 18:09:10,281 train 550 1.678511e-02 -0.867591
2019-11-05 18:09:20,389 train 600 1.678464e-02 -0.862749
2019-11-05 18:09:30,435 train 650 1.679837e-02 -0.860882
2019-11-05 18:09:40,577 train 700 1.679310e-02 -0.856313
2019-11-05 18:09:50,700 train 750 1.677742e-02 -0.845829
2019-11-05 18:10:00,807 train 800 1.675244e-02 -0.846525
2019-11-05 18:10:10,857 train 850 1.677204e-02 -0.860088
2019-11-05 18:10:13,859 training loss; R2: 1.676759e-02 -0.856245
2019-11-05 18:10:14,445 valid 000 1.744634e-02 -0.316723
2019-11-05 18:10:24,249 valid 050 1.508629e-02 -0.802404
2019-11-05 18:10:32,921 validation loss; R2: 1.515716e-02 -1.250836
2019-11-05 18:10:32,987 epoch 155 lr 1.000000e-04
2019-11-05 18:10:33,710 train 000 1.477274e-02 -1.074712
2019-11-05 18:10:43,934 train 050 1.685513e-02 -1.628272
2019-11-05 18:10:54,137 train 100 1.703144e-02 -1.270386
2019-11-05 18:11:04,298 train 150 1.683251e-02 -1.117144
2019-11-05 18:11:14,472 train 200 1.690946e-02 -1.010461
2019-11-05 18:11:24,636 train 250 1.687173e-02 -0.981919
2019-11-05 18:11:34,804 train 300 1.687964e-02 -0.936447
2019-11-05 18:11:44,943 train 350 1.687883e-02 -0.913821
2019-11-05 18:11:55,088 train 400 1.687318e-02 -0.921566
2019-11-05 18:12:05,234 train 450 1.684888e-02 -0.936702
2019-11-05 18:12:15,394 train 500 1.685422e-02 -0.924056
2019-11-05 18:12:25,531 train 550 1.684504e-02 -0.914271
2019-11-05 18:12:35,681 train 600 1.680489e-02 -0.899837
2019-11-05 18:12:45,811 train 650 1.682639e-02 -0.861533
2019-11-05 18:12:55,963 train 700 1.681725e-02 -0.877401
2019-11-05 18:13:06,054 train 750 1.684330e-02 -0.849194
2019-11-05 18:13:16,155 train 800 1.681808e-02 -0.844167
2019-11-05 18:13:26,226 train 850 1.679313e-02 -0.824539
2019-11-05 18:13:29,262 training loss; R2: 1.677710e-02 -0.820249
2019-11-05 18:13:29,785 valid 000 1.500022e-02 -1.606319
2019-11-05 18:13:39,580 valid 050 1.546541e-02 -1.840467
2019-11-05 18:13:48,235 validation loss; R2: 1.548745e-02 -1.377520
2019-11-05 18:13:48,316 epoch 156 lr 1.000000e-04
2019-11-05 18:13:49,011 train 000 1.546875e-02 -1.749933
2019-11-05 18:13:59,102 train 050 1.690045e-02 -0.759605
2019-11-05 18:14:09,292 train 100 1.679749e-02 -0.727786
2019-11-05 18:14:19,440 train 150 1.680584e-02 -0.683972
2019-11-05 18:14:29,540 train 200 1.685660e-02 -0.675523
2019-11-05 18:14:39,637 train 250 1.689464e-02 -0.678259
2019-11-05 18:14:49,842 train 300 1.678519e-02 -0.753314
2019-11-05 18:14:59,945 train 350 1.677146e-02 -0.733768
2019-11-05 18:15:10,039 train 400 1.675026e-02 -0.698675
2019-11-05 18:15:20,207 train 450 1.675405e-02 -0.688032
2019-11-05 18:15:30,364 train 500 1.671454e-02 -0.727814
2019-11-05 18:15:40,418 train 550 1.673896e-02 -0.736899
2019-11-05 18:15:50,573 train 600 1.667545e-02 -0.719249
2019-11-05 18:16:00,717 train 650 1.669331e-02 -0.720898
2019-11-05 18:16:10,802 train 700 1.666937e-02 -0.718391
2019-11-05 18:16:20,850 train 750 1.667596e-02 -0.759781
2019-11-05 18:16:31,013 train 800 1.669024e-02 -0.752210
2019-11-05 18:16:41,123 train 850 1.668644e-02 -0.753500
2019-11-05 18:16:44,134 training loss; R2: 1.668010e-02 -0.763955
2019-11-05 18:16:44,693 valid 000 1.481102e-02 -1.468142
2019-11-05 18:16:54,560 valid 050 1.442306e-02 -0.970684
2019-11-05 18:17:03,230 validation loss; R2: 1.459475e-02 -1.183923
2019-11-05 18:17:03,299 epoch 157 lr 1.000000e-04
2019-11-05 18:17:04,068 train 000 1.826435e-02 -0.153891
2019-11-05 18:17:14,302 train 050 1.684257e-02 -0.944854
2019-11-05 18:17:24,517 train 100 1.683031e-02 -0.830025
2019-11-05 18:17:34,707 train 150 1.675776e-02 -0.749324
2019-11-05 18:17:44,894 train 200 1.673059e-02 -0.728292
2019-11-05 18:17:55,047 train 250 1.681413e-02 -0.731635
2019-11-05 18:18:05,224 train 300 1.681008e-02 -0.712251
2019-11-05 18:18:15,394 train 350 1.682003e-02 -0.694139
2019-11-05 18:18:25,562 train 400 1.676201e-02 -0.692407
2019-11-05 18:18:35,712 train 450 1.673588e-02 -0.691455
2019-11-05 18:18:45,912 train 500 1.676979e-02 -0.680959
2019-11-05 18:18:56,077 train 550 1.673687e-02 -0.684361
2019-11-05 18:19:06,252 train 600 1.673851e-02 -0.680749
2019-11-05 18:19:16,417 train 650 1.670241e-02 -0.678267
2019-11-05 18:19:26,594 train 700 1.670521e-02 -0.673770
2019-11-05 18:19:36,754 train 750 1.666442e-02 -0.683020
2019-11-05 18:19:46,929 train 800 1.665299e-02 -0.746717
2019-11-05 18:19:57,082 train 850 1.664682e-02 -0.751318
2019-11-05 18:20:00,135 training loss; R2: 1.666001e-02 -0.757112
2019-11-05 18:20:00,683 valid 000 1.588910e-02 -0.229082
2019-11-05 18:20:10,630 valid 050 1.511709e-02 -0.954784
2019-11-05 18:20:19,319 validation loss; R2: 1.495202e-02 -1.067868
2019-11-05 18:20:19,385 epoch 158 lr 1.000000e-04
2019-11-05 18:20:20,062 train 000 1.626137e-02 -0.061065
2019-11-05 18:20:30,220 train 050 1.677117e-02 -0.841175
2019-11-05 18:20:40,340 train 100 1.685480e-02 -0.637132
2019-11-05 18:20:50,419 train 150 1.692757e-02 -0.669241
2019-11-05 18:21:00,540 train 200 1.686920e-02 -0.677001
2019-11-05 18:21:10,728 train 250 1.690207e-02 -0.705368
2019-11-05 18:21:20,953 train 300 1.697330e-02 -0.694467
2019-11-05 18:21:31,037 train 350 1.693149e-02 -0.685071
2019-11-05 18:21:41,159 train 400 1.690462e-02 -0.701178
2019-11-05 18:21:51,331 train 450 1.689761e-02 -0.758629
2019-11-05 18:22:01,527 train 500 1.683098e-02 -0.757399
2019-11-05 18:22:11,693 train 550 1.680049e-02 -0.783258
2019-11-05 18:22:21,885 train 600 1.677094e-02 -0.758055
2019-11-05 18:22:32,040 train 650 1.677508e-02 -0.759914
2019-11-05 18:22:42,229 train 700 1.674665e-02 -0.772092
2019-11-05 18:22:52,400 train 750 1.677641e-02 -0.764412
2019-11-05 18:23:02,600 train 800 1.680260e-02 -0.766323
2019-11-05 18:23:12,778 train 850 1.676994e-02 -0.752943
2019-11-05 18:23:15,815 training loss; R2: 1.676950e-02 -0.747280
2019-11-05 18:23:16,345 valid 000 1.308312e-02 -0.781924
2019-11-05 18:23:26,134 valid 050 1.480658e-02 -1.059573
2019-11-05 18:23:34,802 validation loss; R2: 1.486604e-02 -0.971723
2019-11-05 18:23:34,867 epoch 159 lr 1.000000e-04
2019-11-05 18:23:35,545 train 000 1.678364e-02 -0.912732
2019-11-05 18:23:45,780 train 050 1.649411e-02 -0.485815
2019-11-05 18:23:55,969 train 100 1.632945e-02 -0.545110
2019-11-05 18:24:06,175 train 150 1.635212e-02 -0.563209
2019-11-05 18:24:16,376 train 200 1.641463e-02 -0.554538
2019-11-05 18:24:26,554 train 250 1.657605e-02 -0.554834
2019-11-05 18:24:36,761 train 300 1.651194e-02 -0.547176
2019-11-05 18:24:46,944 train 350 1.658639e-02 -0.557122
2019-11-05 18:24:57,141 train 400 1.658034e-02 -0.569529
2019-11-05 18:25:07,308 train 450 1.661253e-02 -0.595598
2019-11-05 18:25:17,509 train 500 1.661018e-02 -0.628619
2019-11-05 18:25:27,666 train 550 1.662467e-02 -0.626396
2019-11-05 18:25:37,862 train 600 1.660548e-02 -0.616861
2019-11-05 18:25:48,030 train 650 1.661502e-02 -0.614326
2019-11-05 18:25:58,225 train 700 1.662341e-02 -0.601108
2019-11-05 18:26:08,398 train 750 1.663484e-02 -0.605709
2019-11-05 18:26:18,571 train 800 1.663875e-02 -0.609463
2019-11-05 18:26:28,707 train 850 1.663336e-02 -0.627592
2019-11-05 18:26:31,747 training loss; R2: 1.661660e-02 -0.634807
2019-11-05 18:26:32,313 valid 000 1.561221e-02 -0.280718
2019-11-05 18:26:42,146 valid 050 1.475619e-02 -0.700398
2019-11-05 18:26:50,822 validation loss; R2: 1.474503e-02 -0.697159
2019-11-05 18:26:50,884 epoch 160 lr 1.000000e-04
2019-11-05 18:26:51,559 train 000 1.606895e-02 -0.253517
2019-11-05 18:27:01,811 train 050 1.637882e-02 -0.533975
2019-11-05 18:27:12,021 train 100 1.644180e-02 -0.596573
2019-11-05 18:27:22,233 train 150 1.651723e-02 -0.617900
2019-11-05 18:27:32,472 train 200 1.658151e-02 -0.688871
2019-11-05 18:27:42,660 train 250 1.653743e-02 -0.686219
2019-11-05 18:27:52,876 train 300 1.654828e-02 -0.679868
2019-11-05 18:28:03,052 train 350 1.656292e-02 -0.665160
2019-11-05 18:28:13,216 train 400 1.658763e-02 -0.657980
2019-11-05 18:28:23,370 train 450 1.661407e-02 -0.659194
2019-11-05 18:28:33,558 train 500 1.663143e-02 -0.649969
2019-11-05 18:28:43,716 train 550 1.668066e-02 -0.648348
2019-11-05 18:28:53,892 train 600 1.672133e-02 -0.669762
2019-11-05 18:29:04,023 train 650 1.674495e-02 -0.683641
2019-11-05 18:29:14,179 train 700 1.672221e-02 -0.686387
2019-11-05 18:29:24,314 train 750 1.670858e-02 -0.711137
2019-11-05 18:29:34,479 train 800 1.672050e-02 -0.711428
2019-11-05 18:29:44,610 train 850 1.671816e-02 -0.705577
2019-11-05 18:29:47,644 training loss; R2: 1.671860e-02 -0.706325
2019-11-05 18:29:48,216 valid 000 1.403387e-02 -1.683042
2019-11-05 18:29:58,264 valid 050 1.566591e-02 -1.480466
2019-11-05 18:30:07,177 validation loss; R2: 1.567743e-02 -1.659335
2019-11-05 18:30:07,244 epoch 161 lr 1.000000e-04
2019-11-05 18:30:07,978 train 000 1.790472e-02 -0.092585
2019-11-05 18:30:18,153 train 050 1.615070e-02 -0.859302
2019-11-05 18:30:28,239 train 100 1.646715e-02 -2.096794
2019-11-05 18:30:38,393 train 150 1.652161e-02 -1.665351
2019-11-05 18:30:48,534 train 200 1.642672e-02 -1.413560
2019-11-05 18:30:58,588 train 250 1.651723e-02 -1.249820
2019-11-05 18:31:08,746 train 300 1.654027e-02 -1.143132
2019-11-05 18:31:18,890 train 350 1.650126e-02 -1.097301
2019-11-05 18:31:28,970 train 400 1.654955e-02 -1.164437
2019-11-05 18:31:39,039 train 450 1.662124e-02 -1.071767
2019-11-05 18:31:49,198 train 500 1.667061e-02 -1.053462
2019-11-05 18:31:59,291 train 550 1.666943e-02 -1.015327
2019-11-05 18:32:09,346 train 600 1.665324e-02 -0.978722
2019-11-05 18:32:19,468 train 650 1.668488e-02 -0.952824
2019-11-05 18:32:29,618 train 700 1.668623e-02 -0.931078
2019-11-05 18:32:39,658 train 750 1.668692e-02 -0.936548
2019-11-05 18:32:49,762 train 800 1.666835e-02 -0.920384
2019-11-05 18:32:59,934 train 850 1.668591e-02 -0.897419
2019-11-05 18:33:02,944 training loss; R2: 1.669671e-02 -0.898783
2019-11-05 18:33:03,501 valid 000 1.512144e-02 -2.032299
2019-11-05 18:33:13,255 valid 050 1.494814e-02 -1.236903
2019-11-05 18:33:21,929 validation loss; R2: 1.522137e-02 -1.368591
2019-11-05 18:33:21,995 epoch 162 lr 1.000000e-04
2019-11-05 18:33:22,744 train 000 1.605151e-02 -0.224636
2019-11-05 18:33:32,903 train 050 1.658650e-02 -0.603163
2019-11-05 18:33:43,307 train 100 1.660594e-02 -0.696242
2019-11-05 18:33:53,633 train 150 1.655295e-02 -0.683632
2019-11-05 18:34:03,988 train 200 1.659261e-02 -0.746097
2019-11-05 18:34:14,262 train 250 1.654164e-02 -0.718638
2019-11-05 18:34:24,581 train 300 1.659174e-02 -0.711601
2019-11-05 18:34:34,872 train 350 1.658838e-02 -0.681931
2019-11-05 18:34:45,037 train 400 1.659674e-02 -0.786757
2019-11-05 18:34:55,172 train 450 1.659171e-02 -0.748836
2019-11-05 18:35:05,355 train 500 1.657408e-02 -1.001893
2019-11-05 18:35:15,499 train 550 1.658042e-02 -0.982308
2019-11-05 18:35:25,654 train 600 1.654393e-02 -0.995508
2019-11-05 18:35:35,802 train 650 1.655645e-02 -0.971163
2019-11-05 18:35:45,950 train 700 1.654047e-02 -0.954232
2019-11-05 18:35:56,070 train 750 1.656145e-02 -0.945471
2019-11-05 18:36:06,221 train 800 1.658689e-02 -0.927218
2019-11-05 18:36:16,348 train 850 1.659110e-02 -0.959660
2019-11-05 18:36:19,381 training loss; R2: 1.658514e-02 -0.953203
2019-11-05 18:36:19,933 valid 000 1.249805e-02 -0.009422
2019-11-05 18:36:29,783 valid 050 1.397559e-02 -0.780563
2019-11-05 18:36:38,520 validation loss; R2: 1.422532e-02 -0.998022
2019-11-05 18:36:38,587 epoch 163 lr 1.000000e-04
2019-11-05 18:36:39,329 train 000 1.557357e-02 -0.031193
2019-11-05 18:36:49,514 train 050 1.699074e-02 -0.614136
2019-11-05 18:36:59,694 train 100 1.698400e-02 -0.585145
2019-11-05 18:37:09,832 train 150 1.693981e-02 -0.603763
2019-11-05 18:37:19,987 train 200 1.692347e-02 -0.641360
2019-11-05 18:37:30,141 train 250 1.682452e-02 -0.648090
2019-11-05 18:37:40,298 train 300 1.675146e-02 -0.642915
2019-11-05 18:37:50,444 train 350 1.675362e-02 -0.685115
2019-11-05 18:38:00,638 train 400 1.672890e-02 -0.672085
2019-11-05 18:38:10,800 train 450 1.676040e-02 -0.658411
2019-11-05 18:38:20,978 train 500 1.672747e-02 -0.660048
2019-11-05 18:38:31,134 train 550 1.671801e-02 -0.680065
2019-11-05 18:38:41,304 train 600 1.671316e-02 -0.681231
2019-11-05 18:38:51,444 train 650 1.672328e-02 -0.671998
2019-11-05 18:39:01,606 train 700 1.671463e-02 -0.731354
2019-11-05 18:39:11,741 train 750 1.671263e-02 -0.739222
2019-11-05 18:39:21,927 train 800 1.669651e-02 -0.771612
2019-11-05 18:39:32,094 train 850 1.667745e-02 -0.766700
2019-11-05 18:39:35,125 training loss; R2: 1.667038e-02 -0.763011
2019-11-05 18:39:35,645 valid 000 1.525715e-02 -0.133719
2019-11-05 18:39:45,710 valid 050 1.499048e-02 -1.322342
2019-11-05 18:39:54,718 validation loss; R2: 1.513259e-02 -1.267383
2019-11-05 18:39:54,787 epoch 164 lr 1.000000e-04
2019-11-05 18:39:55,568 train 000 1.535203e-02 -0.239584
2019-11-05 18:40:05,823 train 050 1.629801e-02 -0.532639
2019-11-05 18:40:16,071 train 100 1.644571e-02 -0.670383
2019-11-05 18:40:26,254 train 150 1.650941e-02 -0.705151
2019-11-05 18:40:36,482 train 200 1.646096e-02 -0.881657
2019-11-05 18:40:46,703 train 250 1.651503e-02 -0.914420
2019-11-05 18:40:56,950 train 300 1.659868e-02 -0.888553
2019-11-05 18:41:07,141 train 350 1.657514e-02 -0.862651
2019-11-05 18:41:17,357 train 400 1.657309e-02 -0.822573
2019-11-05 18:41:27,537 train 450 1.662670e-02 -0.809425
2019-11-05 18:41:37,733 train 500 1.663613e-02 -0.878256
2019-11-05 18:41:47,914 train 550 1.667173e-02 -1.538334
2019-11-05 18:41:58,131 train 600 1.666820e-02 -1.465747
2019-11-05 18:42:08,314 train 650 1.666772e-02 -1.415664
2019-11-05 18:42:18,534 train 700 1.664003e-02 -1.351505
2019-11-05 18:42:28,713 train 750 1.663565e-02 -1.295848
2019-11-05 18:42:38,934 train 800 1.663850e-02 -1.263300
2019-11-05 18:42:49,094 train 850 1.664392e-02 -1.243133
2019-11-05 18:42:52,146 training loss; R2: 1.663415e-02 -1.234196
2019-11-05 18:42:52,716 valid 000 1.386933e-02 0.080991
2019-11-05 18:43:02,497 valid 050 1.507462e-02 -1.739066
2019-11-05 18:43:11,143 validation loss; R2: 1.510823e-02 -1.462200
2019-11-05 18:43:11,219 epoch 165 lr 1.000000e-04
2019-11-05 18:43:11,962 train 000 1.508866e-02 -0.188184
2019-11-05 18:43:22,128 train 050 1.690266e-02 -0.678903
2019-11-05 18:43:32,348 train 100 1.674323e-02 -0.871110
2019-11-05 18:43:42,517 train 150 1.669785e-02 -0.911938
2019-11-05 18:43:52,723 train 200 1.663893e-02 -0.782332
2019-11-05 18:44:02,909 train 250 1.658021e-02 -0.767119
2019-11-05 18:44:13,103 train 300 1.668110e-02 -0.798550
2019-11-05 18:44:23,301 train 350 1.668657e-02 -0.781934
2019-11-05 18:44:33,504 train 400 1.671988e-02 -0.742857
2019-11-05 18:44:43,667 train 450 1.665898e-02 -0.715513
2019-11-05 18:44:53,837 train 500 1.664823e-02 -1.224701
2019-11-05 18:45:03,991 train 550 1.662426e-02 -1.175329
2019-11-05 18:45:14,173 train 600 1.661191e-02 -1.134077
2019-11-05 18:45:24,346 train 650 1.660843e-02 -1.120956
2019-11-05 18:45:34,516 train 700 1.660016e-02 -1.084632
2019-11-05 18:45:44,852 train 750 1.658240e-02 -1.047559
2019-11-05 18:45:55,126 train 800 1.660120e-02 -1.037488
2019-11-05 18:46:05,280 train 850 1.660042e-02 -1.042217
2019-11-05 18:46:08,326 training loss; R2: 1.661103e-02 -1.033375
2019-11-05 18:46:08,901 valid 000 1.489850e-02 -2.950751
2019-11-05 18:46:18,719 valid 050 1.580056e-02 -1.497569
2019-11-05 18:46:27,407 validation loss; R2: 1.550326e-02 -1.508189
2019-11-05 18:46:27,472 epoch 166 lr 1.000000e-04
2019-11-05 18:46:28,156 train 000 1.862416e-02 -0.314084
2019-11-05 18:46:38,370 train 050 1.686204e-02 -0.784258
2019-11-05 18:46:48,558 train 100 1.684818e-02 -0.696571
2019-11-05 18:46:58,711 train 150 1.692871e-02 -0.699955
2019-11-05 18:47:08,877 train 200 1.684800e-02 -0.733665
2019-11-05 18:47:18,993 train 250 1.677788e-02 -0.743650
2019-11-05 18:47:29,167 train 300 1.671296e-02 -0.716992
2019-11-05 18:47:39,282 train 350 1.672034e-02 -0.690496
2019-11-05 18:47:49,414 train 400 1.674931e-02 -0.681949
2019-11-05 18:47:59,542 train 450 1.672385e-02 -0.681732
2019-11-05 18:48:09,669 train 500 1.673003e-02 -0.686864
2019-11-05 18:48:19,793 train 550 1.670857e-02 -0.687825
2019-11-05 18:48:29,994 train 600 1.673009e-02 -0.710019
2019-11-05 18:48:40,169 train 650 1.671671e-02 -0.716752
2019-11-05 18:48:50,346 train 700 1.669279e-02 -0.730227
2019-11-05 18:49:00,542 train 750 1.667444e-02 -0.719529
2019-11-05 18:49:10,728 train 800 1.666127e-02 -0.720071
2019-11-05 18:49:20,862 train 850 1.664386e-02 -0.704947
2019-11-05 18:49:23,897 training loss; R2: 1.664287e-02 -0.702206
2019-11-05 18:49:24,454 valid 000 1.468479e-02 -2.050831
2019-11-05 18:49:34,244 valid 050 1.442115e-02 -1.239481
2019-11-05 18:49:42,939 validation loss; R2: 1.457199e-02 -1.319713
2019-11-05 18:49:43,006 epoch 167 lr 1.000000e-04
2019-11-05 18:49:43,745 train 000 1.423328e-02 -1.141840
2019-11-05 18:49:53,955 train 050 1.676063e-02 -0.733330
2019-11-05 18:50:04,231 train 100 1.668515e-02 -0.666368
2019-11-05 18:50:14,489 train 150 1.655866e-02 -0.606127
2019-11-05 18:50:24,774 train 200 1.644213e-02 -0.652740
2019-11-05 18:50:35,017 train 250 1.645429e-02 -0.661373
2019-11-05 18:50:45,252 train 300 1.650024e-02 -0.677415
2019-11-05 18:50:55,473 train 350 1.652137e-02 -0.662751
2019-11-05 18:51:05,723 train 400 1.652670e-02 -0.671579
2019-11-05 18:51:15,951 train 450 1.655292e-02 -0.676353
2019-11-05 18:51:26,171 train 500 1.659116e-02 -0.680451
2019-11-05 18:51:36,390 train 550 1.660600e-02 -0.672708
2019-11-05 18:51:46,617 train 600 1.664443e-02 -0.685325
2019-11-05 18:51:56,797 train 650 1.663148e-02 -0.689916
2019-11-05 18:52:06,968 train 700 1.663266e-02 -0.697066
2019-11-05 18:52:17,174 train 750 1.661875e-02 -0.697879
2019-11-05 18:52:27,365 train 800 1.660191e-02 -0.696088
2019-11-05 18:52:37,425 train 850 1.660110e-02 -0.701810
2019-11-05 18:52:40,473 training loss; R2: 1.660195e-02 -0.704389
2019-11-05 18:52:40,993 valid 000 1.440990e-02 -0.459717
2019-11-05 18:52:50,815 valid 050 1.488158e-02 -1.194583
2019-11-05 18:52:59,495 validation loss; R2: 1.495099e-02 -1.272935
2019-11-05 18:52:59,568 epoch 168 lr 1.000000e-04
2019-11-05 18:53:00,303 train 000 1.717780e-02 -0.306303
2019-11-05 18:53:10,490 train 050 1.685490e-02 -0.617285
2019-11-05 18:53:20,715 train 100 1.681910e-02 -0.777458
2019-11-05 18:53:30,886 train 150 1.672102e-02 -0.791278
2019-11-05 18:53:41,078 train 200 1.659008e-02 -0.732739
2019-11-05 18:53:51,238 train 250 1.664034e-02 -0.756792
2019-11-05 18:54:01,418 train 300 1.664502e-02 -0.766502
2019-11-05 18:54:11,566 train 350 1.662103e-02 -0.763492
2019-11-05 18:54:21,741 train 400 1.661786e-02 -0.808639
2019-11-05 18:54:31,887 train 450 1.658847e-02 -0.768568
2019-11-05 18:54:42,060 train 500 1.657418e-02 -0.748368
2019-11-05 18:54:52,193 train 550 1.656400e-02 -0.743338
2019-11-05 18:55:02,351 train 600 1.652419e-02 -0.738442
2019-11-05 18:55:12,470 train 650 1.653285e-02 -0.740154
2019-11-05 18:55:22,638 train 700 1.654140e-02 -0.732144
2019-11-05 18:55:32,783 train 750 1.655826e-02 -0.730318
2019-11-05 18:55:42,931 train 800 1.657405e-02 -0.721003
2019-11-05 18:55:53,078 train 850 1.657415e-02 -0.709127
2019-11-05 18:55:56,115 training loss; R2: 1.658348e-02 -0.703592
2019-11-05 18:55:56,648 valid 000 1.568227e-02 -2.988315
2019-11-05 18:56:06,478 valid 050 1.533490e-02 -1.074424
2019-11-05 18:56:15,195 validation loss; R2: 1.512023e-02 -2.487986
2019-11-05 18:56:15,266 epoch 169 lr 1.000000e-04
2019-11-05 18:56:16,019 train 000 1.627196e-02 -0.187957
2019-11-05 18:56:26,155 train 050 1.660044e-02 -0.579637
2019-11-05 18:56:36,313 train 100 1.662394e-02 -0.683986
2019-11-05 18:56:46,491 train 150 1.659489e-02 -0.610105
2019-11-05 18:56:56,735 train 200 1.656009e-02 -0.630244
2019-11-05 18:57:06,830 train 250 1.651833e-02 -0.712042
2019-11-05 18:57:16,987 train 300 1.658746e-02 -0.760746
2019-11-05 18:57:27,174 train 350 1.664444e-02 -0.789753
2019-11-05 18:57:37,354 train 400 1.670847e-02 -0.780922
2019-11-05 18:57:47,449 train 450 1.663202e-02 -0.782187
2019-11-05 18:57:57,596 train 500 1.661263e-02 -0.788065
2019-11-05 18:58:07,845 train 550 1.661704e-02 -0.783480
2019-11-05 18:58:17,970 train 600 1.662805e-02 -0.775708
2019-11-05 18:58:28,115 train 650 1.664499e-02 -0.778816
2019-11-05 18:58:38,325 train 700 1.659779e-02 -0.797383
2019-11-05 18:58:48,458 train 750 1.660200e-02 -0.783216
2019-11-05 18:58:58,555 train 800 1.659215e-02 -0.775652
2019-11-05 18:59:08,718 train 850 1.662429e-02 -0.755457
2019-11-05 18:59:11,779 training loss; R2: 1.663174e-02 -0.750582
2019-11-05 18:59:12,309 valid 000 1.613745e-02 -0.564167
2019-11-05 18:59:22,145 valid 050 1.521268e-02 -1.108983
2019-11-05 18:59:30,797 validation loss; R2: 1.510428e-02 -1.425082
2019-11-05 18:59:30,867 epoch 170 lr 1.000000e-04
2019-11-05 18:59:31,576 train 000 1.687027e-02 -0.047205
2019-11-05 18:59:41,824 train 050 1.645080e-02 -0.674989
2019-11-05 18:59:52,012 train 100 1.646312e-02 -0.590376
2019-11-05 19:00:02,145 train 150 1.654266e-02 -0.628954
2019-11-05 19:00:12,237 train 200 1.647863e-02 -0.585175
2019-11-05 19:00:22,399 train 250 1.649009e-02 -0.618806
2019-11-05 19:00:32,575 train 300 1.660233e-02 -0.708043
2019-11-05 19:00:42,734 train 350 1.665383e-02 -1.042800
2019-11-05 19:00:52,914 train 400 1.665424e-02 -0.996514
2019-11-05 19:01:03,067 train 450 1.662045e-02 -0.993869
2019-11-05 19:01:13,225 train 500 1.658078e-02 -0.967766
2019-11-05 19:01:23,375 train 550 1.656947e-02 -0.952872
2019-11-05 19:01:33,544 train 600 1.655326e-02 -0.930413
2019-11-05 19:01:43,680 train 650 1.657335e-02 -0.923381
2019-11-05 19:01:53,840 train 700 1.657176e-02 -0.896658
2019-11-05 19:02:04,008 train 750 1.656748e-02 -0.892055
2019-11-05 19:02:14,241 train 800 1.659029e-02 -0.889507
2019-11-05 19:02:24,440 train 850 1.659625e-02 -0.872050
2019-11-05 19:02:27,493 training loss; R2: 1.658474e-02 -0.902929
2019-11-05 19:02:28,026 valid 000 1.333943e-02 -0.386418
2019-11-05 19:02:37,856 valid 050 1.435750e-02 -1.241771
2019-11-05 19:02:46,547 validation loss; R2: 1.432859e-02 -1.121789
2019-11-05 19:02:46,617 epoch 171 lr 1.000000e-04
2019-11-05 19:02:47,379 train 000 1.692227e-02 -0.120897
2019-11-05 19:02:57,570 train 050 1.614281e-02 -0.629349
2019-11-05 19:03:07,790 train 100 1.640418e-02 -0.736093
2019-11-05 19:03:17,995 train 150 1.641032e-02 -0.642013
2019-11-05 19:03:28,221 train 200 1.643224e-02 -0.677274
2019-11-05 19:03:38,407 train 250 1.643163e-02 -0.689637
2019-11-05 19:03:48,627 train 300 1.645027e-02 -0.772153
2019-11-05 19:03:58,771 train 350 1.639218e-02 -0.800225
2019-11-05 19:04:08,925 train 400 1.638065e-02 -0.834065
2019-11-05 19:04:19,095 train 450 1.637008e-02 -0.802067
2019-11-05 19:04:29,364 train 500 1.641822e-02 -0.776936
2019-11-05 19:04:39,564 train 550 1.643728e-02 -0.783422
2019-11-05 19:04:49,736 train 600 1.644947e-02 -0.779228
2019-11-05 19:04:59,907 train 650 1.647554e-02 -0.759642
2019-11-05 19:05:10,083 train 700 1.648823e-02 -0.743647
2019-11-05 19:05:20,256 train 750 1.650126e-02 -0.784844
2019-11-05 19:05:30,443 train 800 1.649930e-02 -0.772058
2019-11-05 19:05:40,614 train 850 1.653012e-02 -0.763907
2019-11-05 19:05:43,656 training loss; R2: 1.653475e-02 -0.757768
2019-11-05 19:05:44,172 valid 000 1.702304e-02 -0.682500
2019-11-05 19:05:54,032 valid 050 1.521104e-02 -2.435923
2019-11-05 19:06:02,743 validation loss; R2: 1.537200e-02 -3.172180
2019-11-05 19:06:02,820 epoch 172 lr 1.000000e-04
2019-11-05 19:06:03,535 train 000 1.734194e-02 -0.114756
2019-11-05 19:06:13,700 train 050 1.659382e-02 -1.058632
2019-11-05 19:06:23,867 train 100 1.672551e-02 -0.982200
2019-11-05 19:06:33,986 train 150 1.663374e-02 -0.960429
2019-11-05 19:06:44,133 train 200 1.666648e-02 -0.900470
2019-11-05 19:06:54,244 train 250 1.662994e-02 -0.876850
2019-11-05 19:07:04,392 train 300 1.661164e-02 -0.826471
2019-11-05 19:07:14,546 train 350 1.661519e-02 -0.805740
2019-11-05 19:07:24,740 train 400 1.662488e-02 -0.812207
2019-11-05 19:07:34,901 train 450 1.659357e-02 -9.595566
2019-11-05 19:07:45,097 train 500 1.658113e-02 -8.676045
2019-11-05 19:07:55,275 train 550 1.657914e-02 -7.967825
2019-11-05 19:08:05,453 train 600 1.656858e-02 -7.357636
2019-11-05 19:08:15,551 train 650 1.657925e-02 -6.828304
2019-11-05 19:08:25,686 train 700 1.657088e-02 -6.388220
2019-11-05 19:08:35,788 train 750 1.659193e-02 -6.008360
2019-11-05 19:08:45,900 train 800 1.659021e-02 -5.690983
2019-11-05 19:08:56,000 train 850 1.660599e-02 -5.390282
2019-11-05 19:08:59,021 training loss; R2: 1.660557e-02 -5.307240
2019-11-05 19:08:59,603 valid 000 1.659894e-02 0.032385
2019-11-05 19:09:09,404 valid 050 1.521338e-02 -1.759914
2019-11-05 19:09:18,062 validation loss; R2: 1.555292e-02 -1.903427
2019-11-05 19:09:18,131 epoch 173 lr 1.000000e-04
2019-11-05 19:09:18,850 train 000 1.816902e-02 -1.067642
2019-11-05 19:09:29,051 train 050 1.612198e-02 -0.772763
2019-11-05 19:09:39,289 train 100 1.605560e-02 -0.776586
2019-11-05 19:09:49,494 train 150 1.624450e-02 -0.678064
2019-11-05 19:09:59,716 train 200 1.636303e-02 -1.064337
2019-11-05 19:10:09,925 train 250 1.637220e-02 -0.992340
2019-11-05 19:10:20,120 train 300 1.646414e-02 -0.944327
2019-11-05 19:10:30,326 train 350 1.645866e-02 -0.910265
2019-11-05 19:10:40,524 train 400 1.650497e-02 -0.904490
2019-11-05 19:10:50,708 train 450 1.652014e-02 -0.863930
2019-11-05 19:11:00,909 train 500 1.649451e-02 -0.867517
2019-11-05 19:11:11,039 train 550 1.653122e-02 -0.878937
2019-11-05 19:11:21,203 train 600 1.654982e-02 -0.855932
2019-11-05 19:11:31,387 train 650 1.653533e-02 -0.839317
2019-11-05 19:11:41,595 train 700 1.654779e-02 -0.841869
2019-11-05 19:11:51,772 train 750 1.654668e-02 -0.823197
2019-11-05 19:12:01,978 train 800 1.656511e-02 -0.805765
2019-11-05 19:12:12,152 train 850 1.654623e-02 -0.792466
2019-11-05 19:12:15,207 training loss; R2: 1.655780e-02 -0.803026
2019-11-05 19:12:15,744 valid 000 1.323830e-02 -0.054155
2019-11-05 19:12:25,754 valid 050 1.447885e-02 -1.235126
2019-11-05 19:12:34,499 validation loss; R2: 1.478180e-02 -1.130481
2019-11-05 19:12:34,570 epoch 174 lr 1.000000e-04
2019-11-05 19:12:35,282 train 000 1.372201e-02 -0.017919
2019-11-05 19:12:45,496 train 050 1.671167e-02 -0.713163
2019-11-05 19:12:55,740 train 100 1.665955e-02 -0.817827
2019-11-05 19:13:05,910 train 150 1.656661e-02 -0.833661
2019-11-05 19:13:16,102 train 200 1.659207e-02 -0.803201
2019-11-05 19:13:26,213 train 250 1.659134e-02 -0.737322
2019-11-05 19:13:36,394 train 300 1.661855e-02 -0.741936
2019-11-05 19:13:46,532 train 350 1.660611e-02 -0.748477
2019-11-05 19:13:56,690 train 400 1.657027e-02 -0.733900
2019-11-05 19:14:06,834 train 450 1.663260e-02 -0.723507
2019-11-05 19:14:16,995 train 500 1.664796e-02 -0.707872
2019-11-05 19:14:27,132 train 550 1.663969e-02 -0.710026
2019-11-05 19:14:37,315 train 600 1.660519e-02 -0.683394
2019-11-05 19:14:47,471 train 650 1.661603e-02 -0.707712
2019-11-05 19:14:57,631 train 700 1.659036e-02 -0.822480
2019-11-05 19:15:07,695 train 750 1.658087e-02 -0.833907
2019-11-05 19:15:17,777 train 800 1.658802e-02 -0.865524
2019-11-05 19:15:27,830 train 850 1.659905e-02 -1.093718
2019-11-05 19:15:30,860 training loss; R2: 1.659225e-02 -1.084578
2019-11-05 19:15:31,454 valid 000 1.306308e-02 -3.322157
2019-11-05 19:15:41,664 valid 050 1.404300e-02 -1.124292
2019-11-05 19:15:50,376 validation loss; R2: 1.394556e-02 -1.349779
2019-11-05 19:15:50,442 epoch 175 lr 1.000000e-04
2019-11-05 19:15:51,197 train 000 2.072462e-02 -0.458688
2019-11-05 19:16:01,437 train 050 1.632371e-02 -0.436965
2019-11-05 19:16:11,647 train 100 1.629608e-02 -0.660655
2019-11-05 19:16:21,822 train 150 1.620181e-02 -0.706233
2019-11-05 19:16:31,998 train 200 1.631066e-02 -0.647401
2019-11-05 19:16:42,171 train 250 1.634711e-02 -0.707862
2019-11-05 19:16:52,400 train 300 1.633438e-02 -0.803006
2019-11-05 19:17:02,570 train 350 1.644313e-02 -0.806484
2019-11-05 19:17:12,767 train 400 1.650727e-02 -0.991921
2019-11-05 19:17:22,971 train 450 1.649247e-02 -0.982571
2019-11-05 19:17:33,204 train 500 1.648668e-02 -0.949832
2019-11-05 19:17:43,387 train 550 1.645250e-02 -0.958257
2019-11-05 19:17:53,598 train 600 1.645996e-02 -0.961235
2019-11-05 19:18:03,787 train 650 1.647140e-02 -0.963199
2019-11-05 19:18:13,978 train 700 1.649082e-02 -0.932597
2019-11-05 19:18:24,121 train 750 1.651744e-02 -0.906605
2019-11-05 19:18:34,317 train 800 1.653930e-02 -0.897015
2019-11-05 19:18:44,510 train 850 1.653815e-02 -0.880118
2019-11-05 19:18:47,569 training loss; R2: 1.654981e-02 -0.884629
2019-11-05 19:18:48,146 valid 000 1.367214e-02 0.032913
2019-11-05 19:18:58,149 valid 050 1.416334e-02 -1.190148
2019-11-05 19:19:06,816 validation loss; R2: 1.409375e-02 -0.999052
2019-11-05 19:19:06,883 epoch 176 lr 1.000000e-04
2019-11-05 19:19:07,632 train 000 1.658916e-02 -0.174526
2019-11-05 19:19:17,800 train 050 1.647540e-02 -0.697569
2019-11-05 19:19:28,016 train 100 1.639116e-02 -0.929657
2019-11-05 19:19:38,199 train 150 1.642081e-02 -46.184079
2019-11-05 19:19:48,376 train 200 1.643168e-02 -34.887250
2019-11-05 19:19:58,451 train 250 1.648975e-02 -28.066997
2019-11-05 19:20:08,562 train 300 1.647409e-02 -23.506914
2019-11-05 19:20:18,622 train 350 1.648378e-02 -20.289986
2019-11-05 19:20:28,705 train 400 1.646462e-02 -17.849639
2019-11-05 19:20:38,779 train 450 1.648876e-02 -15.936376
2019-11-05 19:20:48,925 train 500 1.647915e-02 -14.419585
2019-11-05 19:20:59,051 train 550 1.651310e-02 -13.404236
2019-11-05 19:21:09,238 train 600 1.650280e-02 -12.331591
2019-11-05 19:21:19,368 train 650 1.651286e-02 -11.475504
2019-11-05 19:21:29,523 train 700 1.649496e-02 -10.708062
2019-11-05 19:21:39,646 train 750 1.648692e-02 -10.037464
2019-11-05 19:21:49,819 train 800 1.648228e-02 -9.452682
2019-11-05 19:21:59,974 train 850 1.651602e-02 -8.933086
2019-11-05 19:22:03,016 training loss; R2: 1.650861e-02 -8.786585
2019-11-05 19:22:03,595 valid 000 1.258216e-02 -0.010096
2019-11-05 19:22:13,377 valid 050 1.469635e-02 -1.397349
2019-11-05 19:22:22,062 validation loss; R2: 1.461662e-02 -1.412204
2019-11-05 19:22:22,127 epoch 177 lr 1.000000e-04
2019-11-05 19:22:22,864 train 000 1.582153e-02 -0.267968
2019-11-05 19:22:32,985 train 050 1.674556e-02 -0.821196
2019-11-05 19:22:43,145 train 100 1.686784e-02 -0.922321
2019-11-05 19:22:53,322 train 150 1.677320e-02 -0.797515
2019-11-05 19:23:03,458 train 200 1.671963e-02 -0.754431
2019-11-05 19:23:13,546 train 250 1.666289e-02 -0.843774
2019-11-05 19:23:23,714 train 300 1.655379e-02 -0.809622
2019-11-05 19:23:33,865 train 350 1.653156e-02 -0.780214
2019-11-05 19:23:43,962 train 400 1.650130e-02 -0.815161
2019-11-05 19:23:54,034 train 450 1.651864e-02 -0.800637
2019-11-05 19:24:04,175 train 500 1.655218e-02 -0.779117
2019-11-05 19:24:14,327 train 550 1.652686e-02 -0.765488
2019-11-05 19:24:24,443 train 600 1.650647e-02 -0.782322
2019-11-05 19:24:34,533 train 650 1.647643e-02 -0.789812
2019-11-05 19:24:44,652 train 700 1.650244e-02 -0.780957
2019-11-05 19:24:54,783 train 750 1.650463e-02 -0.761966
2019-11-05 19:25:04,958 train 800 1.651112e-02 -0.751805
2019-11-05 19:25:15,034 train 850 1.648129e-02 -0.764827
2019-11-05 19:25:18,057 training loss; R2: 1.649267e-02 -0.761658
2019-11-05 19:25:18,647 valid 000 1.534421e-02 -1.098327
2019-11-05 19:25:28,449 valid 050 1.433097e-02 -0.808644
2019-11-05 19:25:37,119 validation loss; R2: 1.444944e-02 -1.015467
2019-11-05 19:25:37,184 epoch 178 lr 1.000000e-04
2019-11-05 19:25:37,910 train 000 1.691752e-02 -0.602412
2019-11-05 19:25:48,089 train 050 1.630579e-02 -0.779673
2019-11-05 19:25:58,274 train 100 1.636650e-02 -0.734743
2019-11-05 19:26:08,431 train 150 1.634103e-02 -0.828757
2019-11-05 19:26:18,617 train 200 1.640078e-02 -0.752177
2019-11-05 19:26:28,747 train 250 1.641616e-02 -0.714535
2019-11-05 19:26:38,929 train 300 1.636798e-02 -0.672749
2019-11-05 19:26:49,062 train 350 1.641758e-02 -0.652592
2019-11-05 19:26:59,191 train 400 1.642434e-02 -0.662322
2019-11-05 19:27:09,322 train 450 1.647973e-02 -0.658560
2019-11-05 19:27:19,459 train 500 1.644608e-02 -0.657131
2019-11-05 19:27:29,568 train 550 1.645292e-02 -0.651507
2019-11-05 19:27:39,702 train 600 1.647036e-02 -0.646050
2019-11-05 19:27:49,810 train 650 1.648363e-02 -0.661166
2019-11-05 19:27:59,900 train 700 1.650018e-02 -0.660773
2019-11-05 19:28:09,946 train 750 1.649930e-02 -0.680754
2019-11-05 19:28:20,059 train 800 1.648987e-02 -0.679587
2019-11-05 19:28:30,210 train 850 1.650743e-02 -0.665350
2019-11-05 19:28:33,244 training loss; R2: 1.649971e-02 -0.664008
2019-11-05 19:28:33,809 valid 000 1.396921e-02 -0.161452
2019-11-05 19:28:43,572 valid 050 1.514296e-02 -0.783173
2019-11-05 19:28:52,269 validation loss; R2: 1.519724e-02 -1.172839
2019-11-05 19:28:52,336 epoch 179 lr 1.000000e-04
2019-11-05 19:28:53,073 train 000 1.578358e-02 -0.771673
2019-11-05 19:29:03,242 train 050 1.641738e-02 -0.637554
2019-11-05 19:29:13,448 train 100 1.649086e-02 -0.699131
2019-11-05 19:29:23,640 train 150 1.651681e-02 -0.771109
2019-11-05 19:29:33,861 train 200 1.652855e-02 -0.766030
2019-11-05 19:29:44,055 train 250 1.660251e-02 -0.738456
2019-11-05 19:29:54,281 train 300 1.660924e-02 -0.748799
2019-11-05 19:30:04,444 train 350 1.658503e-02 -0.730216
2019-11-05 19:30:14,629 train 400 1.655094e-02 -0.748742
2019-11-05 19:30:24,797 train 450 1.656599e-02 -0.732665
2019-11-05 19:30:34,986 train 500 1.654092e-02 -0.737060
2019-11-05 19:30:45,132 train 550 1.656642e-02 -0.761605
2019-11-05 19:30:55,299 train 600 1.656966e-02 -0.746159
2019-11-05 19:31:05,475 train 650 1.657210e-02 -0.729892
2019-11-05 19:31:15,661 train 700 1.658544e-02 -0.717312
2019-11-05 19:31:25,822 train 750 1.660439e-02 -0.714420
2019-11-05 19:31:36,011 train 800 1.658495e-02 -0.713032
2019-11-05 19:31:46,154 train 850 1.659878e-02 -0.703616
2019-11-05 19:31:49,201 training loss; R2: 1.660306e-02 -0.697787
2019-11-05 19:31:49,706 valid 000 1.650516e-02 -0.723845
2019-11-05 19:31:59,540 valid 050 1.460155e-02 -1.228893
2019-11-05 19:32:08,204 validation loss; R2: 1.440090e-02 -1.195002
2019-11-05 19:32:08,269 epoch 180 lr 1.000000e-04
2019-11-05 19:32:09,019 train 000 1.918654e-02 -0.383677
2019-11-05 19:32:19,167 train 050 1.614018e-02 -0.596595
2019-11-05 19:32:29,384 train 100 1.635195e-02 -0.733179
2019-11-05 19:32:39,554 train 150 1.652370e-02 -0.838512
2019-11-05 19:32:49,746 train 200 1.647896e-02 -0.771735
2019-11-05 19:32:59,906 train 250 1.650851e-02 -0.750125
2019-11-05 19:33:10,097 train 300 1.647557e-02 -0.769059
2019-11-05 19:33:20,253 train 350 1.655242e-02 -0.721043
2019-11-05 19:33:30,435 train 400 1.653378e-02 -0.727725
2019-11-05 19:33:40,584 train 450 1.652826e-02 -0.717270
2019-11-05 19:33:50,767 train 500 1.652553e-02 -0.723063
2019-11-05 19:34:00,922 train 550 1.650923e-02 -0.700235
2019-11-05 19:34:11,114 train 600 1.653908e-02 -0.695026
2019-11-05 19:34:21,270 train 650 1.651969e-02 -0.697210
2019-11-05 19:34:31,379 train 700 1.653972e-02 -0.701702
2019-11-05 19:34:41,476 train 750 1.652906e-02 -0.725932
2019-11-05 19:34:51,589 train 800 1.651187e-02 -0.733600
2019-11-05 19:35:01,726 train 850 1.649538e-02 -0.749237
2019-11-05 19:35:04,762 training loss; R2: 1.649068e-02 -0.745733
2019-11-05 19:35:05,353 valid 000 1.325812e-02 -0.896903
2019-11-05 19:35:15,042 valid 050 1.532616e-02 -1.624273
2019-11-05 19:35:23,782 validation loss; R2: 1.564161e-02 -1.936561
2019-11-05 19:35:23,848 epoch 181 lr 1.000000e-04
2019-11-05 19:35:24,574 train 000 1.896428e-02 -0.333641
2019-11-05 19:35:34,916 train 050 1.599738e-02 -0.847510
2019-11-05 19:35:45,282 train 100 1.610045e-02 -0.809734
2019-11-05 19:35:55,593 train 150 1.630530e-02 -0.841304
2019-11-05 19:36:05,938 train 200 1.634858e-02 -0.796864
2019-11-05 19:36:16,228 train 250 1.638083e-02 -0.754140
2019-11-05 19:36:26,397 train 300 1.640794e-02 -0.796782
2019-11-05 19:36:36,529 train 350 1.640100e-02 -0.791259
2019-11-05 19:36:46,693 train 400 1.637015e-02 -0.848650
2019-11-05 19:36:56,799 train 450 1.638042e-02 -0.844322
2019-11-05 19:37:06,964 train 500 1.641657e-02 -0.828716
2019-11-05 19:37:17,172 train 550 1.642026e-02 -0.801611
2019-11-05 19:37:27,329 train 600 1.642583e-02 -0.784317
2019-11-05 19:37:37,466 train 650 1.639231e-02 -0.782912
2019-11-05 19:37:47,606 train 700 1.640457e-02 -0.765762
2019-11-05 19:37:57,733 train 750 1.641729e-02 -0.755228
2019-11-05 19:38:07,887 train 800 1.641596e-02 -0.741934
2019-11-05 19:38:18,012 train 850 1.643741e-02 -0.757829
2019-11-05 19:38:21,051 training loss; R2: 1.644072e-02 -0.756977
2019-11-05 19:38:21,616 valid 000 1.357429e-02 -0.089889
2019-11-05 19:38:31,384 valid 050 1.421738e-02 -3.924420
2019-11-05 19:38:40,026 validation loss; R2: 1.427545e-02 -3.156553
2019-11-05 19:38:40,090 epoch 182 lr 1.000000e-04
2019-11-05 19:38:40,772 train 000 1.538942e-02 -0.269368
2019-11-05 19:38:50,959 train 050 1.655429e-02 -0.483414
2019-11-05 19:39:01,155 train 100 1.643420e-02 -0.591413
2019-11-05 19:39:11,291 train 150 1.636137e-02 -0.628883
2019-11-05 19:39:21,458 train 200 1.634882e-02 -0.589148
2019-11-05 19:39:31,594 train 250 1.631648e-02 -0.599167
2019-11-05 19:39:41,771 train 300 1.638230e-02 -0.644050
2019-11-05 19:39:51,920 train 350 1.637153e-02 -0.668525
2019-11-05 19:40:02,095 train 400 1.633348e-02 -0.666552
2019-11-05 19:40:12,246 train 450 1.640140e-02 -0.694014
2019-11-05 19:40:22,407 train 500 1.642346e-02 -0.698826
2019-11-05 19:40:32,569 train 550 1.639114e-02 -0.869403
2019-11-05 19:40:42,757 train 600 1.641179e-02 -0.876058
2019-11-05 19:40:52,903 train 650 1.638696e-02 -0.863686
2019-11-05 19:41:03,085 train 700 1.637631e-02 -0.851973
2019-11-05 19:41:13,215 train 750 1.638857e-02 -0.839348
2019-11-05 19:41:23,358 train 800 1.638464e-02 -0.838385
2019-11-05 19:41:33,498 train 850 1.640459e-02 -0.848631
2019-11-05 19:41:36,546 training loss; R2: 1.641652e-02 -0.846481
2019-11-05 19:41:37,132 valid 000 1.448191e-02 -6.296225
2019-11-05 19:41:46,986 valid 050 1.417956e-02 -1.622171
2019-11-05 19:41:55,725 validation loss; R2: 1.406088e-02 -1.652630
2019-11-05 19:41:55,791 epoch 183 lr 1.000000e-04
2019-11-05 19:41:56,513 train 000 1.764236e-02 0.103652
2019-11-05 19:42:06,607 train 050 1.639068e-02 -0.611135
2019-11-05 19:42:16,767 train 100 1.637427e-02 -0.713011
2019-11-05 19:42:26,933 train 150 1.643876e-02 -0.645007
2019-11-05 19:42:37,004 train 200 1.640034e-02 -0.634888
2019-11-05 19:42:47,089 train 250 1.627721e-02 -0.627978
2019-11-05 19:42:57,253 train 300 1.635228e-02 -0.615752
2019-11-05 19:43:07,325 train 350 1.634210e-02 -0.648692
2019-11-05 19:43:17,421 train 400 1.642400e-02 -0.646904
2019-11-05 19:43:27,520 train 450 1.643779e-02 -0.667701
2019-11-05 19:43:37,702 train 500 1.650825e-02 -0.684060
2019-11-05 19:43:47,801 train 550 1.644854e-02 -0.685071
2019-11-05 19:43:57,859 train 600 1.643790e-02 -1.005744
2019-11-05 19:44:07,969 train 650 1.641374e-02 -0.975524
2019-11-05 19:44:18,175 train 700 1.640498e-02 -0.939327
2019-11-05 19:44:28,235 train 750 1.638656e-02 -0.935238
2019-11-05 19:44:38,319 train 800 1.638888e-02 -0.921330
2019-11-05 19:44:48,484 train 850 1.639113e-02 -0.909609
2019-11-05 19:44:51,509 training loss; R2: 1.639406e-02 -0.909498
2019-11-05 19:44:52,072 valid 000 1.648402e-02 -1.592671
2019-11-05 19:45:02,227 valid 050 1.506973e-02 -0.953051
2019-11-05 19:45:11,298 validation loss; R2: 1.493296e-02 -0.902998
2019-11-05 19:45:11,369 epoch 184 lr 1.000000e-04
2019-11-05 19:45:12,129 train 000 1.648146e-02 -1.255166
2019-11-05 19:45:22,368 train 050 1.645086e-02 -0.687097
2019-11-05 19:45:32,562 train 100 1.631738e-02 -0.953376
2019-11-05 19:45:42,754 train 150 1.625527e-02 -0.856590
2019-11-05 19:45:52,974 train 200 1.632599e-02 -0.742073
2019-11-05 19:46:03,159 train 250 1.630449e-02 -0.981426
2019-11-05 19:46:13,374 train 300 1.632830e-02 -1.001230
2019-11-05 19:46:23,572 train 350 1.636992e-02 -0.939792
2019-11-05 19:46:33,754 train 400 1.633876e-02 -0.876429
2019-11-05 19:46:43,922 train 450 1.637145e-02 -0.835874
2019-11-05 19:46:54,110 train 500 1.640652e-02 -0.844388
2019-11-05 19:47:04,275 train 550 1.640569e-02 -0.831278
2019-11-05 19:47:14,489 train 600 1.637693e-02 -0.820267
2019-11-05 19:47:24,595 train 650 1.640623e-02 -0.788109
2019-11-05 19:47:34,722 train 700 1.642264e-02 -0.795927
2019-11-05 19:47:44,824 train 750 1.641149e-02 -0.788188
2019-11-05 19:47:54,959 train 800 1.641050e-02 -0.792001
2019-11-05 19:48:05,117 train 850 1.643586e-02 -0.778321
2019-11-05 19:48:08,157 training loss; R2: 1.643682e-02 -0.774238
2019-11-05 19:48:08,695 valid 000 1.508823e-02 -2.121491
2019-11-05 19:48:18,773 valid 050 1.519996e-02 -1.596649
2019-11-05 19:48:27,486 validation loss; R2: 1.522365e-02 -1.325310
2019-11-05 19:48:27,567 epoch 185 lr 1.000000e-04
2019-11-05 19:48:28,263 train 000 1.957658e-02 -0.125172
2019-11-05 19:48:38,513 train 050 1.636984e-02 -0.782315
2019-11-05 19:48:48,729 train 100 1.663339e-02 -0.711499
2019-11-05 19:48:58,874 train 150 1.650040e-02 -0.666094
2019-11-05 19:49:09,060 train 200 1.653198e-02 -0.656082
2019-11-05 19:49:19,206 train 250 1.649472e-02 -0.889184
2019-11-05 19:49:29,367 train 300 1.647804e-02 -0.858324
2019-11-05 19:49:39,513 train 350 1.643525e-02 -0.836837
2019-11-05 19:49:49,668 train 400 1.639067e-02 -0.816522
2019-11-05 19:49:59,794 train 450 1.638210e-02 -0.816971
2019-11-05 19:50:10,008 train 500 1.639891e-02 -0.832087
2019-11-05 19:50:20,172 train 550 1.637953e-02 -0.830755
2019-11-05 19:50:30,386 train 600 1.635593e-02 -0.815813
2019-11-05 19:50:40,566 train 650 1.639785e-02 -0.796415
2019-11-05 19:50:50,753 train 700 1.639336e-02 -0.793079
2019-11-05 19:51:00,902 train 750 1.640983e-02 -0.785239
2019-11-05 19:51:11,101 train 800 1.639024e-02 -0.772345
2019-11-05 19:51:21,274 train 850 1.641305e-02 -0.758895
2019-11-05 19:51:24,322 training loss; R2: 1.641347e-02 -0.751097
2019-11-05 19:51:24,895 valid 000 1.858676e-02 0.030817
2019-11-05 19:51:34,825 valid 050 1.578038e-02 -1.748992
2019-11-05 19:51:43,499 validation loss; R2: 1.548872e-02 -1.708874
2019-11-05 19:51:43,564 epoch 186 lr 1.000000e-04
2019-11-05 19:51:44,305 train 000 1.445208e-02 -0.319245
2019-11-05 19:51:54,505 train 050 1.660877e-02 -0.625592
2019-11-05 19:52:04,721 train 100 1.639624e-02 -0.671785
2019-11-05 19:52:14,892 train 150 1.654974e-02 -0.767368
2019-11-05 19:52:25,080 train 200 1.653892e-02 -0.740434
2019-11-05 19:52:35,230 train 250 1.652539e-02 -0.721106
2019-11-05 19:52:45,391 train 300 1.649542e-02 -0.701565
2019-11-05 19:52:55,539 train 350 1.650237e-02 -0.737710
2019-11-05 19:53:05,722 train 400 1.651787e-02 -0.756765
2019-11-05 19:53:15,866 train 450 1.649889e-02 -0.722677
2019-11-05 19:53:25,961 train 500 1.647189e-02 -0.745905
2019-11-05 19:53:35,997 train 550 1.648434e-02 -0.752076
2019-11-05 19:53:46,070 train 600 1.647265e-02 -0.726321
2019-11-05 19:53:56,139 train 650 1.647204e-02 -0.712110
2019-11-05 19:54:06,238 train 700 1.650208e-02 -0.722664
2019-11-05 19:54:16,373 train 750 1.646658e-02 -0.734277
2019-11-05 19:54:26,529 train 800 1.646551e-02 -0.725518
2019-11-05 19:54:36,651 train 850 1.646803e-02 -0.729099
2019-11-05 19:54:39,689 training loss; R2: 1.646443e-02 -0.725968
2019-11-05 19:54:40,252 valid 000 1.542306e-02 -0.700194
2019-11-05 19:54:50,098 valid 050 1.413737e-02 -1.593174
2019-11-05 19:54:58,809 validation loss; R2: 1.413705e-02 -2.280656
2019-11-05 19:54:58,877 epoch 187 lr 1.000000e-04
2019-11-05 19:54:59,574 train 000 1.807197e-02 -1.263647
2019-11-05 19:55:09,798 train 050 1.613932e-02 -0.849469
2019-11-05 19:55:20,021 train 100 1.633338e-02 -0.826666
2019-11-05 19:55:30,194 train 150 1.638168e-02 -0.750321
2019-11-05 19:55:40,389 train 200 1.651666e-02 -0.761767
2019-11-05 19:55:50,560 train 250 1.650073e-02 -0.778633
2019-11-05 19:56:00,768 train 300 1.645824e-02 -0.761377
2019-11-05 19:56:10,945 train 350 1.645095e-02 -0.750593
2019-11-05 19:56:21,177 train 400 1.644320e-02 -0.723045
2019-11-05 19:56:31,371 train 450 1.644692e-02 -0.715587
2019-11-05 19:56:41,610 train 500 1.644652e-02 -0.738870
2019-11-05 19:56:51,781 train 550 1.644721e-02 -0.764709
2019-11-05 19:57:01,956 train 600 1.642846e-02 -0.748868
2019-11-05 19:57:12,109 train 650 1.641407e-02 -2.160352
2019-11-05 19:57:22,293 train 700 1.640813e-02 -2.068182
2019-11-05 19:57:32,473 train 750 1.642498e-02 -2.000871
2019-11-05 19:57:42,673 train 800 1.641081e-02 -2.151123
2019-11-05 19:57:52,852 train 850 1.642500e-02 -2.090894
2019-11-05 19:57:55,906 training loss; R2: 1.643136e-02 -2.067610
2019-11-05 19:57:56,422 valid 000 1.608378e-02 -1.412461
2019-11-05 19:58:06,227 valid 050 1.553205e-02 -1.429510
2019-11-05 19:58:14,987 validation loss; R2: 1.539402e-02 -1.935742
2019-11-05 19:58:15,054 epoch 188 lr 1.000000e-04
2019-11-05 19:58:15,774 train 000 1.668437e-02 0.022827
2019-11-05 19:58:25,913 train 050 1.638964e-02 -0.653245
2019-11-05 19:58:36,082 train 100 1.628499e-02 -0.914767
2019-11-05 19:58:46,278 train 150 1.625384e-02 -0.889875
2019-11-05 19:58:56,368 train 200 1.631109e-02 -0.824411
2019-11-05 19:59:06,436 train 250 1.632558e-02 -0.814782
2019-11-05 19:59:16,627 train 300 1.640134e-02 -1.567118
2019-11-05 19:59:26,760 train 350 1.636528e-02 -1.446852
2019-11-05 19:59:36,838 train 400 1.633981e-02 -1.333565
2019-11-05 19:59:46,969 train 450 1.637313e-02 -1.253745
2019-11-05 19:59:57,160 train 500 1.639496e-02 -1.184866
2019-11-05 20:00:07,213 train 550 1.640052e-02 -1.283507
2019-11-05 20:00:17,334 train 600 1.641736e-02 -1.231115
2019-11-05 20:00:27,584 train 650 1.644550e-02 -1.225474
2019-11-05 20:00:37,782 train 700 1.646031e-02 -1.172226
2019-11-05 20:00:47,908 train 750 1.645260e-02 -1.136458
2019-11-05 20:00:58,153 train 800 1.643268e-02 -1.126878
2019-11-05 20:01:08,305 train 850 1.643206e-02 -1.096488
2019-11-05 20:01:11,339 training loss; R2: 1.643733e-02 -1.225406
2019-11-05 20:01:11,858 valid 000 1.460998e-02 -0.122829
2019-11-05 20:01:21,684 valid 050 1.548351e-02 -1.642517
2019-11-05 20:01:30,359 validation loss; R2: 1.551663e-02 -1.377335
2019-11-05 20:01:30,426 epoch 189 lr 1.000000e-04
2019-11-05 20:01:31,132 train 000 1.886810e-02 -0.216297
2019-11-05 20:01:41,353 train 050 1.611144e-02 -0.538353
2019-11-05 20:01:51,580 train 100 1.625899e-02 -1.169382
2019-11-05 20:02:01,728 train 150 1.627839e-02 -1.054762
2019-11-05 20:02:11,913 train 200 1.631797e-02 -0.966006
2019-11-05 20:02:22,048 train 250 1.624781e-02 -0.840884
2019-11-05 20:02:32,228 train 300 1.625538e-02 -0.799505
2019-11-05 20:02:42,379 train 350 1.622900e-02 -0.781479
2019-11-05 20:02:52,559 train 400 1.628534e-02 -0.772849
2019-11-05 20:03:02,713 train 450 1.632185e-02 -0.763999
2019-11-05 20:03:12,905 train 500 1.636680e-02 -0.758312
2019-11-05 20:03:23,066 train 550 1.638184e-02 -0.743323
2019-11-05 20:03:33,228 train 600 1.638597e-02 -0.732639
2019-11-05 20:03:43,373 train 650 1.640534e-02 -0.739875
2019-11-05 20:03:53,531 train 700 1.646294e-02 -0.723802
2019-11-05 20:04:03,672 train 750 1.645486e-02 -0.732365
2019-11-05 20:04:13,817 train 800 1.644158e-02 -0.745630
2019-11-05 20:04:24,073 train 850 1.644878e-02 -0.728871
2019-11-05 20:04:27,089 training loss; R2: 1.644994e-02 -0.743755
2019-11-05 20:04:27,668 valid 000 1.419203e-02 -0.608089
2019-11-05 20:04:37,492 valid 050 1.521667e-02 -1.680639
2019-11-05 20:04:46,176 validation loss; R2: 1.518827e-02 -1.725432
2019-11-05 20:04:46,254 epoch 190 lr 1.000000e-04
2019-11-05 20:04:46,977 train 000 1.730002e-02 -0.060284
2019-11-05 20:04:57,223 train 050 1.659854e-02 -0.448590
2019-11-05 20:05:07,427 train 100 1.622858e-02 -0.633163
2019-11-05 20:05:17,573 train 150 1.625789e-02 -0.704169
2019-11-05 20:05:27,735 train 200 1.623652e-02 -0.761664
2019-11-05 20:05:37,915 train 250 1.617356e-02 -0.747502
2019-11-05 20:05:48,077 train 300 1.620072e-02 -0.715132
2019-11-05 20:05:58,247 train 350 1.625176e-02 -0.711790
2019-11-05 20:06:08,414 train 400 1.628419e-02 -0.688354
2019-11-05 20:06:18,538 train 450 1.630602e-02 -0.680292
2019-11-05 20:06:28,678 train 500 1.629933e-02 -0.677207
2019-11-05 20:06:38,832 train 550 1.628657e-02 -0.710237
2019-11-05 20:06:48,969 train 600 1.626161e-02 -0.703157
2019-11-05 20:06:59,087 train 650 1.625886e-02 -0.747483
2019-11-05 20:07:09,221 train 700 1.628622e-02 -0.755227
2019-11-05 20:07:19,335 train 750 1.630484e-02 -0.747133
2019-11-05 20:07:29,474 train 800 1.629412e-02 -0.741790
2019-11-05 20:07:39,614 train 850 1.630973e-02 -0.779979
2019-11-05 20:07:42,648 training loss; R2: 1.632047e-02 -0.773717
2019-11-05 20:07:43,218 valid 000 1.439865e-02 -2.099009
2019-11-05 20:07:53,027 valid 050 1.447780e-02 -0.814814
2019-11-05 20:08:01,672 validation loss; R2: 1.452706e-02 -1.136336
2019-11-05 20:08:01,737 epoch 191 lr 1.000000e-04
2019-11-05 20:08:02,433 train 000 1.839679e-02 -0.401100
2019-11-05 20:08:12,644 train 050 1.659909e-02 -0.733698
2019-11-05 20:08:22,863 train 100 1.654334e-02 -0.686808
2019-11-05 20:08:33,028 train 150 1.665520e-02 -0.609657
2019-11-05 20:08:43,214 train 200 1.659454e-02 -0.622545
2019-11-05 20:08:53,353 train 250 1.655731e-02 -0.644706
2019-11-05 20:09:03,508 train 300 1.649314e-02 -0.632484
2019-11-05 20:09:13,674 train 350 1.645716e-02 -0.681041
2019-11-05 20:09:23,828 train 400 1.639758e-02 -0.678666
2019-11-05 20:09:33,969 train 450 1.637071e-02 -0.692834
2019-11-05 20:09:44,161 train 500 1.633775e-02 -0.711196
2019-11-05 20:09:54,346 train 550 1.637770e-02 -0.701336
2019-11-05 20:10:04,542 train 600 1.638040e-02 -0.693530
2019-11-05 20:10:14,712 train 650 1.634882e-02 -0.708665
2019-11-05 20:10:24,912 train 700 1.637017e-02 -0.702247
2019-11-05 20:10:35,080 train 750 1.636128e-02 -0.716903
2019-11-05 20:10:45,225 train 800 1.636135e-02 -0.714128
2019-11-05 20:10:55,325 train 850 1.634963e-02 -0.726243
2019-11-05 20:10:58,349 training loss; R2: 1.635110e-02 -0.716553
2019-11-05 20:10:58,917 valid 000 1.550791e-02 -0.145297
2019-11-05 20:11:08,813 valid 050 1.421849e-02 -1.086340
2019-11-05 20:11:17,497 validation loss; R2: 1.444217e-02 -1.107973
2019-11-05 20:11:17,566 epoch 192 lr 1.000000e-04
2019-11-05 20:11:18,298 train 000 1.781673e-02 -0.399794
2019-11-05 20:11:28,566 train 050 1.632501e-02 -0.976604
2019-11-05 20:11:38,798 train 100 1.626933e-02 -0.813376
2019-11-05 20:11:48,977 train 150 1.628324e-02 -0.713404
2019-11-05 20:11:59,177 train 200 1.624032e-02 -0.677708
2019-11-05 20:12:09,362 train 250 1.628786e-02 -0.698888
2019-11-05 20:12:19,547 train 300 1.623159e-02 -0.729569
2019-11-05 20:12:29,702 train 350 1.628258e-02 -0.728305
2019-11-05 20:12:39,883 train 400 1.628054e-02 -0.740176
2019-11-05 20:12:50,093 train 450 1.627979e-02 -0.746038
2019-11-05 20:13:00,291 train 500 1.628973e-02 -0.767565
2019-11-05 20:13:10,490 train 550 1.629471e-02 -0.750288
2019-11-05 20:13:20,694 train 600 1.630756e-02 -0.735472
2019-11-05 20:13:30,876 train 650 1.630580e-02 -0.729701
2019-11-05 20:13:41,093 train 700 1.630637e-02 -0.718801
2019-11-05 20:13:51,285 train 750 1.629957e-02 -0.712540
2019-11-05 20:14:01,504 train 800 1.632950e-02 -0.704708
2019-11-05 20:14:11,696 train 850 1.632067e-02 -0.699514
2019-11-05 20:14:14,743 training loss; R2: 1.633035e-02 -0.701158
2019-11-05 20:14:15,312 valid 000 1.522726e-02 -0.433332
2019-11-05 20:14:25,183 valid 050 1.463112e-02 -1.584520
2019-11-05 20:14:33,889 validation loss; R2: 1.465481e-02 -1.268025
2019-11-05 20:14:33,957 epoch 193 lr 1.000000e-04
2019-11-05 20:14:34,658 train 000 1.376837e-02 -0.146695
2019-11-05 20:14:44,889 train 050 1.628391e-02 -0.735948
2019-11-05 20:14:55,139 train 100 1.636302e-02 -1.149551
2019-11-05 20:15:05,331 train 150 1.642852e-02 -0.978005
2019-11-05 20:15:15,482 train 200 1.634507e-02 -0.886467
2019-11-05 20:15:25,644 train 250 1.628674e-02 -0.847296
2019-11-05 20:15:35,825 train 300 1.629385e-02 -0.866642
2019-11-05 20:15:45,977 train 350 1.634452e-02 -0.816780
2019-11-05 20:15:56,197 train 400 1.635830e-02 -0.832856
2019-11-05 20:16:06,345 train 450 1.641495e-02 -0.907264
2019-11-05 20:16:16,518 train 500 1.641006e-02 -0.868791
2019-11-05 20:16:26,677 train 550 1.643048e-02 -0.873416
2019-11-05 20:16:36,855 train 600 1.643068e-02 -0.869356
2019-11-05 20:16:47,017 train 650 1.643101e-02 -0.854998
2019-11-05 20:16:57,191 train 700 1.641273e-02 -0.853845
2019-11-05 20:17:07,336 train 750 1.642150e-02 -0.841804
2019-11-05 20:17:17,500 train 800 1.641224e-02 -0.823231
2019-11-05 20:17:27,655 train 850 1.641206e-02 -0.828929
2019-11-05 20:17:30,702 training loss; R2: 1.640676e-02 -0.828350
2019-11-05 20:17:31,244 valid 000 1.770017e-02 -0.256168
2019-11-05 20:17:41,077 valid 050 1.536530e-02 -3.641811
2019-11-05 20:17:49,728 validation loss; R2: 1.530595e-02 -3.049212
2019-11-05 20:17:49,794 epoch 194 lr 1.000000e-04
2019-11-05 20:17:50,470 train 000 1.525616e-02 -0.543814
2019-11-05 20:18:00,746 train 050 1.678282e-02 -0.879121
2019-11-05 20:18:10,963 train 100 1.654627e-02 -0.740275
2019-11-05 20:18:21,132 train 150 1.649599e-02 -0.631219
2019-11-05 20:18:31,322 train 200 1.645392e-02 -0.638181
2019-11-05 20:18:41,501 train 250 1.641976e-02 -0.721044
2019-11-05 20:18:51,702 train 300 1.636523e-02 -0.771494
2019-11-05 20:19:01,873 train 350 1.638065e-02 -0.746539
2019-11-05 20:19:12,091 train 400 1.641988e-02 -0.754997
2019-11-05 20:19:22,284 train 450 1.641386e-02 -0.747245
2019-11-05 20:19:32,503 train 500 1.638023e-02 -0.745995
2019-11-05 20:19:42,692 train 550 1.639937e-02 -0.723844
2019-11-05 20:19:52,871 train 600 1.642137e-02 -0.716194
2019-11-05 20:20:03,044 train 650 1.641611e-02 -0.714277
2019-11-05 20:20:13,232 train 700 1.637408e-02 -0.728693
2019-11-05 20:20:23,390 train 750 1.637512e-02 -0.718786
2019-11-05 20:20:33,586 train 800 1.638213e-02 -0.725419
2019-11-05 20:20:43,751 train 850 1.636626e-02 -0.717572
2019-11-05 20:20:46,791 training loss; R2: 1.637004e-02 -0.711399
2019-11-05 20:20:47,363 valid 000 1.291358e-02 -0.891651
2019-11-05 20:20:57,162 valid 050 1.379608e-02 -1.342708
2019-11-05 20:21:05,826 validation loss; R2: 1.362819e-02 -1.450013
2019-11-05 20:21:05,892 epoch 195 lr 1.000000e-04
2019-11-05 20:21:06,649 train 000 1.530885e-02 0.112274
2019-11-05 20:21:16,789 train 050 1.636831e-02 -31.177679
2019-11-05 20:21:26,991 train 100 1.642976e-02 -15.988454
2019-11-05 20:21:37,182 train 150 1.646167e-02 -10.950302
2019-11-05 20:21:47,402 train 200 1.641226e-02 -8.456394
2019-11-05 20:21:57,593 train 250 1.642296e-02 -6.878378
2019-11-05 20:22:07,803 train 300 1.636216e-02 -5.919739
2019-11-05 20:22:17,971 train 350 1.637938e-02 -5.204385
2019-11-05 20:22:28,172 train 400 1.633333e-02 -4.622309
2019-11-05 20:22:38,348 train 450 1.637198e-02 -4.207992
2019-11-05 20:22:48,543 train 500 1.631898e-02 -3.849604
2019-11-05 20:22:58,702 train 550 1.630152e-02 -3.553669
2019-11-05 20:23:08,869 train 600 1.627860e-02 -3.329211
2019-11-05 20:23:19,010 train 650 1.631257e-02 -3.115647
2019-11-05 20:23:29,168 train 700 1.633784e-02 -2.935840
2019-11-05 20:23:39,330 train 750 1.635334e-02 -2.790242
2019-11-05 20:23:49,501 train 800 1.632543e-02 -2.669686
2019-11-05 20:23:59,637 train 850 1.632671e-02 -2.546483
2019-11-05 20:24:02,678 training loss; R2: 1.634979e-02 -2.511702
2019-11-05 20:24:03,249 valid 000 1.487622e-02 -0.651380
2019-11-05 20:24:13,092 valid 050 1.406547e-02 -1.423097
2019-11-05 20:24:21,763 validation loss; R2: 1.417035e-02 -1.288984
2019-11-05 20:24:21,829 epoch 196 lr 1.000000e-04
2019-11-05 20:24:22,568 train 000 1.957222e-02 0.041683
2019-11-05 20:24:32,671 train 050 1.660288e-02 -0.858643
2019-11-05 20:24:42,887 train 100 1.653731e-02 -0.767910
2019-11-05 20:24:53,079 train 150 1.640299e-02 -0.735945
2019-11-05 20:25:03,173 train 200 1.647874e-02 -0.782225
2019-11-05 20:25:13,270 train 250 1.656618e-02 -0.802303
2019-11-05 20:25:23,511 train 300 1.653331e-02 -0.818322
2019-11-05 20:25:33,756 train 350 1.652440e-02 -0.837011
2019-11-05 20:25:43,984 train 400 1.650859e-02 -0.825818
2019-11-05 20:25:54,164 train 450 1.650339e-02 -0.797135
2019-11-05 20:26:04,340 train 500 1.646057e-02 -0.753322
2019-11-05 20:26:14,510 train 550 1.648215e-02 -0.738365
2019-11-05 20:26:24,694 train 600 1.644926e-02 -0.709671
2019-11-05 20:26:34,859 train 650 1.645166e-02 -0.719130
2019-11-05 20:26:45,050 train 700 1.644134e-02 -0.711082
2019-11-05 20:26:55,221 train 750 1.641638e-02 -0.701121
2019-11-05 20:27:05,393 train 800 1.640968e-02 -0.707558
2019-11-05 20:27:15,550 train 850 1.639668e-02 -0.704713
2019-11-05 20:27:18,595 training loss; R2: 1.640258e-02 -0.710222
2019-11-05 20:27:19,151 valid 000 1.652723e-02 -1.965415
2019-11-05 20:27:28,934 valid 050 1.449980e-02 -0.953468
2019-11-05 20:27:37,593 validation loss; R2: 1.451852e-02 -1.010993
2019-11-05 20:27:37,659 epoch 197 lr 1.000000e-04
2019-11-05 20:27:38,402 train 000 1.517894e-02 -0.975098
2019-11-05 20:27:48,526 train 050 1.661511e-02 -0.795759
2019-11-05 20:27:58,653 train 100 1.645043e-02 -0.828546
2019-11-05 20:28:08,817 train 150 1.636288e-02 -0.843791
2019-11-05 20:28:18,937 train 200 1.624983e-02 -0.766686
2019-11-05 20:28:28,965 train 250 1.630853e-02 -0.721081
2019-11-05 20:28:39,087 train 300 1.637538e-02 -0.746528
2019-11-05 20:28:49,224 train 350 1.636304e-02 -0.874814
2019-11-05 20:28:59,330 train 400 1.633968e-02 -0.836232
2019-11-05 20:29:09,401 train 450 1.634142e-02 -0.821477
2019-11-05 20:29:19,595 train 500 1.633285e-02 -0.798429
2019-11-05 20:29:29,726 train 550 1.630293e-02 -0.789091
2019-11-05 20:29:39,806 train 600 1.629513e-02 -0.794086
2019-11-05 20:29:49,909 train 650 1.630590e-02 -0.816672
2019-11-05 20:30:00,089 train 700 1.630243e-02 -0.813468
2019-11-05 20:30:10,173 train 750 1.628436e-02 -0.807239
2019-11-05 20:30:20,246 train 800 1.626872e-02 -0.795463
2019-11-05 20:30:30,342 train 850 1.625707e-02 -0.779818
2019-11-05 20:30:33,391 training loss; R2: 1.628452e-02 -0.770530
2019-11-05 20:30:33,930 valid 000 1.166007e-02 -0.311944
2019-11-05 20:30:43,803 valid 050 1.503249e-02 -1.187013
2019-11-05 20:30:52,480 validation loss; R2: 1.490356e-02 -1.223899
2019-11-05 20:30:52,545 epoch 198 lr 1.000000e-04
2019-11-05 20:30:53,245 train 000 1.844670e-02 -0.575576
2019-11-05 20:31:03,449 train 050 1.619052e-02 -0.931017
2019-11-05 20:31:13,654 train 100 1.646714e-02 -0.811470
2019-11-05 20:31:23,799 train 150 1.632486e-02 -0.719810
2019-11-05 20:31:33,987 train 200 1.631544e-02 -0.709254
2019-11-05 20:31:44,164 train 250 1.624836e-02 -0.728535
2019-11-05 20:31:54,343 train 300 1.625174e-02 -0.687031
2019-11-05 20:32:04,483 train 350 1.628969e-02 -0.667514
2019-11-05 20:32:14,650 train 400 1.622726e-02 -0.679444
2019-11-05 20:32:24,798 train 450 1.623340e-02 -0.716379
2019-11-05 20:32:34,963 train 500 1.625537e-02 -0.723965
2019-11-05 20:32:45,022 train 550 1.626693e-02 -0.705530
2019-11-05 20:32:55,208 train 600 1.628239e-02 -0.713539
2019-11-05 20:33:05,293 train 650 1.628806e-02 -0.720430
2019-11-05 20:33:15,445 train 700 1.632376e-02 -0.728912
2019-11-05 20:33:25,629 train 750 1.631629e-02 -0.721752
2019-11-05 20:33:35,818 train 800 1.632292e-02 -0.729258
2019-11-05 20:33:45,996 train 850 1.632106e-02 -0.726671
2019-11-05 20:33:49,030 training loss; R2: 1.631459e-02 -0.724360
2019-11-05 20:33:49,547 valid 000 1.309173e-02 -0.677696
2019-11-05 20:33:59,438 valid 050 1.463837e-02 -1.725018
2019-11-05 20:34:08,162 validation loss; R2: 1.464101e-02 -1.796561
2019-11-05 20:34:08,229 epoch 199 lr 1.000000e-04
2019-11-05 20:34:08,924 train 000 1.630524e-02 0.078454
2019-11-05 20:34:19,015 train 050 1.600749e-02 -0.543194
2019-11-05 20:34:29,183 train 100 1.606590e-02 -0.781223
2019-11-05 20:34:39,339 train 150 1.617557e-02 -0.691294
2019-11-05 20:34:49,524 train 200 1.616421e-02 -0.699387
2019-11-05 20:34:59,691 train 250 1.622990e-02 -0.672835
2019-11-05 20:35:09,872 train 300 1.625481e-02 -0.660833
2019-11-05 20:35:20,037 train 350 1.626097e-02 -0.670049
2019-11-05 20:35:30,238 train 400 1.624013e-02 -0.686268
2019-11-05 20:35:40,430 train 450 1.626816e-02 -0.678238
2019-11-05 20:35:50,633 train 500 1.623197e-02 -0.667430
2019-11-05 20:36:00,790 train 550 1.625009e-02 -0.693141
2019-11-05 20:36:10,985 train 600 1.624042e-02 -0.714103
2019-11-05 20:36:21,171 train 650 1.626275e-02 -0.720605
2019-11-05 20:36:31,371 train 700 1.630525e-02 -0.706080
2019-11-05 20:36:41,543 train 750 1.632528e-02 -0.711898
2019-11-05 20:36:51,733 train 800 1.633005e-02 -0.708809
2019-11-05 20:37:01,879 train 850 1.634244e-02 -0.715476
2019-11-05 20:37:04,907 training loss; R2: 1.635746e-02 -0.722053
2019-11-05 20:37:05,441 valid 000 1.488200e-02 -1.402775
2019-11-05 20:37:15,291 valid 050 1.637798e-02 -1.566513
2019-11-05 20:37:23,986 validation loss; R2: 1.640792e-02 -1.615185
2019-11-05 20:37:24,051 epoch 200 lr 1.000000e-04
2019-11-05 20:37:24,732 train 000 1.499919e-02 -3.302771
2019-11-05 20:37:34,849 train 050 1.612104e-02 -1.174282
2019-11-05 20:37:45,019 train 100 1.644025e-02 -0.936299
2019-11-05 20:37:55,220 train 150 1.639416e-02 -0.869224
2019-11-05 20:38:05,411 train 200 1.634127e-02 -0.908365
2019-11-05 20:38:15,572 train 250 1.627549e-02 -0.850588
2019-11-05 20:38:25,749 train 300 1.632416e-02 -0.833517
2019-11-05 20:38:35,893 train 350 1.629828e-02 -0.828732
2019-11-05 20:38:46,047 train 400 1.634015e-02 -0.820668
2019-11-05 20:38:56,184 train 450 1.631841e-02 -0.815739
2019-11-05 20:39:06,351 train 500 1.632765e-02 -0.799353
2019-11-05 20:39:16,465 train 550 1.634375e-02 -0.792140
2019-11-05 20:39:26,535 train 600 1.637390e-02 -0.795389
2019-11-05 20:39:36,586 train 650 1.637669e-02 -0.793618
2019-11-05 20:39:46,663 train 700 1.637421e-02 -0.796899
2019-11-05 20:39:56,735 train 750 1.637845e-02 -0.787383
2019-11-05 20:40:06,901 train 800 1.635833e-02 -0.780723
2019-11-05 20:40:17,040 train 850 1.633124e-02 -0.764211
2019-11-05 20:40:20,078 training loss; R2: 1.633337e-02 -0.770709
2019-11-05 20:40:20,648 valid 000 1.585278e-02 -0.139342
2019-11-05 20:40:30,494 valid 050 1.381510e-02 -1.516531
2019-11-05 20:40:39,135 validation loss; R2: 1.399847e-02 -1.344747
2019-11-05 20:40:39,198 epoch 201 lr 1.000000e-04
2019-11-05 20:40:39,942 train 000 1.838222e-02 -0.604191
2019-11-05 20:40:50,128 train 050 1.609084e-02 -0.544314
2019-11-05 20:41:00,397 train 100 1.622496e-02 -0.627940
2019-11-05 20:41:10,577 train 150 1.628718e-02 -0.731419
2019-11-05 20:41:20,797 train 200 1.626175e-02 -0.732193
2019-11-05 20:41:30,959 train 250 1.622780e-02 -0.698339
2019-11-05 20:41:41,169 train 300 1.625491e-02 -0.719598
2019-11-05 20:41:51,317 train 350 1.623792e-02 -0.726359
2019-11-05 20:42:01,478 train 400 1.624541e-02 -0.815347
2019-11-05 20:42:11,614 train 450 1.626748e-02 -0.833239
2019-11-05 20:42:21,766 train 500 1.627432e-02 -0.817554
2019-11-05 20:42:31,906 train 550 1.628379e-02 -0.821811
2019-11-05 20:42:42,031 train 600 1.624830e-02 -0.820423
2019-11-05 20:42:52,107 train 650 1.623845e-02 -0.836454
2019-11-05 20:43:02,244 train 700 1.623853e-02 -0.856996
2019-11-05 20:43:12,315 train 750 1.627090e-02 -0.834607
2019-11-05 20:43:22,412 train 800 1.626518e-02 -0.820032
2019-11-05 20:43:32,557 train 850 1.624723e-02 -0.804563
2019-11-05 20:43:35,610 training loss; R2: 1.624946e-02 -0.805546
2019-11-05 20:43:36,180 valid 000 1.468850e-02 -2.072263
2019-11-05 20:43:45,901 valid 050 1.543268e-02 -1.647676
2019-11-05 20:43:54,588 validation loss; R2: 1.551278e-02 -1.454989
2019-11-05 20:43:54,659 epoch 202 lr 1.000000e-04
2019-11-05 20:43:55,423 train 000 1.534581e-02 -0.699812
2019-11-05 20:44:05,573 train 050 1.598319e-02 -0.618849
2019-11-05 20:44:15,776 train 100 1.606765e-02 -0.631296
2019-11-05 20:44:25,930 train 150 1.618901e-02 -0.665947
2019-11-05 20:44:36,107 train 200 1.619631e-02 -0.603507
2019-11-05 20:44:46,236 train 250 1.618217e-02 -0.606580
2019-11-05 20:44:56,385 train 300 1.616567e-02 -0.606467
2019-11-05 20:45:06,508 train 350 1.617219e-02 -0.607372
2019-11-05 20:45:16,667 train 400 1.618846e-02 -0.637211
2019-11-05 20:45:26,812 train 450 1.616092e-02 -0.650176
2019-11-05 20:45:36,974 train 500 1.615801e-02 -0.663220
2019-11-05 20:45:47,142 train 550 1.616394e-02 -0.659352
2019-11-05 20:45:57,308 train 600 1.622600e-02 -0.672779
2019-11-05 20:46:07,458 train 650 1.622112e-02 -0.684517
2019-11-05 20:46:17,627 train 700 1.622795e-02 -1.514316
2019-11-05 20:46:27,776 train 750 1.627593e-02 -1.459315
2019-11-05 20:46:37,941 train 800 1.630359e-02 -1.415583
2019-11-05 20:46:48,086 train 850 1.630534e-02 -1.372382
2019-11-05 20:46:51,118 training loss; R2: 1.630357e-02 -1.354255
2019-11-05 20:46:51,636 valid 000 1.459710e-02 -0.060075
2019-11-05 20:47:01,411 valid 050 1.474107e-02 -1.216038
2019-11-05 20:47:10,091 validation loss; R2: 1.475710e-02 -1.217173
2019-11-05 20:47:10,157 epoch 203 lr 1.000000e-04
2019-11-05 20:47:10,887 train 000 1.620301e-02 0.123783
2019-11-05 20:47:21,019 train 050 1.612833e-02 -0.645039
2019-11-05 20:47:31,127 train 100 1.647765e-02 -0.632587
2019-11-05 20:47:41,281 train 150 1.647673e-02 -0.602118
2019-11-05 20:47:51,433 train 200 1.633380e-02 -37.885680
2019-11-05 20:48:01,448 train 250 1.625791e-02 -30.479433
2019-11-05 20:48:11,571 train 300 1.626349e-02 -25.562699
2019-11-05 20:48:21,706 train 350 1.628996e-02 -22.018230
2019-11-05 20:48:31,808 train 400 1.631423e-02 -19.349162
2019-11-05 20:48:41,896 train 450 1.631351e-02 -17.296703
2019-11-05 20:48:52,002 train 500 1.629854e-02 -15.626976
2019-11-05 20:49:02,169 train 550 1.628208e-02 -14.323925
2019-11-05 20:49:12,315 train 600 1.626354e-02 -13.191750
2019-11-05 20:49:22,373 train 650 1.627422e-02 -12.224990
2019-11-05 20:49:32,473 train 700 1.624407e-02 -11.410672
2019-11-05 20:49:42,620 train 750 1.624870e-02 -10.700007
2019-11-05 20:49:52,802 train 800 1.625726e-02 -10.084370
2019-11-05 20:50:02,887 train 850 1.627530e-02 -9.536888
2019-11-05 20:50:05,895 training loss; R2: 1.626187e-02 -9.378875
2019-11-05 20:50:06,444 valid 000 1.464573e-02 0.015178
2019-11-05 20:50:16,237 valid 050 1.368205e-02 -5.650400
2019-11-05 20:50:25,043 validation loss; R2: 1.366562e-02 -3.690629
2019-11-05 20:50:25,110 epoch 204 lr 1.000000e-04
2019-11-05 20:50:25,881 train 000 1.807407e-02 -2.212688
2019-11-05 20:50:36,175 train 050 1.633339e-02 -0.692030
2019-11-05 20:50:46,514 train 100 1.611994e-02 -0.719592
2019-11-05 20:50:56,842 train 150 1.617909e-02 -0.684794
2019-11-05 20:51:07,047 train 200 1.619581e-02 -0.640030
2019-11-05 20:51:17,259 train 250 1.631088e-02 -0.628937
2019-11-05 20:51:27,456 train 300 1.636937e-02 -0.754266
2019-11-05 20:51:37,695 train 350 1.638073e-02 -0.791269
2019-11-05 20:51:47,901 train 400 1.632498e-02 -0.776812
2019-11-05 20:51:58,145 train 450 1.632598e-02 -0.768700
2019-11-05 20:52:08,361 train 500 1.628957e-02 -0.767839
2019-11-05 20:52:18,514 train 550 1.626561e-02 -0.772782
2019-11-05 20:52:28,665 train 600 1.625740e-02 -0.772893
2019-11-05 20:52:38,813 train 650 1.621309e-02 -0.764313
2019-11-05 20:52:48,943 train 700 1.619840e-02 -0.755161
2019-11-05 20:52:59,143 train 750 1.621154e-02 -0.746739
2019-11-05 20:53:09,356 train 800 1.622796e-02 -0.737344
2019-11-05 20:53:19,580 train 850 1.624806e-02 -0.743053
2019-11-05 20:53:22,623 training loss; R2: 1.625089e-02 -0.738556
2019-11-05 20:53:23,198 valid 000 1.499255e-02 -1.681040
2019-11-05 20:53:32,986 valid 050 1.487615e-02 -1.553460
2019-11-05 20:53:41,664 validation loss; R2: 1.481238e-02 -1.310076
2019-11-05 20:53:41,737 epoch 205 lr 1.000000e-04
2019-11-05 20:53:42,455 train 000 1.550787e-02 -0.004437
2019-11-05 20:53:52,803 train 050 1.625568e-02 -0.658871
2019-11-05 20:54:03,144 train 100 1.619891e-02 -0.754784
2019-11-05 20:54:13,458 train 150 1.622341e-02 -0.689674
2019-11-05 20:54:23,797 train 200 1.619259e-02 -0.666154
2019-11-05 20:54:34,208 train 250 1.615008e-02 -0.725824
2019-11-05 20:54:44,595 train 300 1.622208e-02 -0.732118
2019-11-05 20:54:54,921 train 350 1.622884e-02 -0.742080
2019-11-05 20:55:05,096 train 400 1.624076e-02 -0.719366
2019-11-05 20:55:15,297 train 450 1.622650e-02 -0.699299
2019-11-05 20:55:25,508 train 500 1.622161e-02 -0.682228
2019-11-05 20:55:35,690 train 550 1.625506e-02 -0.706366
2019-11-05 20:55:45,873 train 600 1.629219e-02 -0.706555
2019-11-05 20:55:56,046 train 650 1.628307e-02 -0.716665
2019-11-05 20:56:06,204 train 700 1.629251e-02 -0.734312
2019-11-05 20:56:16,362 train 750 1.628418e-02 -0.743580
2019-11-05 20:56:26,506 train 800 1.629849e-02 -0.755724
2019-11-05 20:56:36,675 train 850 1.629175e-02 -0.765848
2019-11-05 20:56:39,715 training loss; R2: 1.629903e-02 -0.765002
2019-11-05 20:56:40,242 valid 000 1.420746e-02 -0.565825
2019-11-05 20:56:50,091 valid 050 1.517266e-02 -1.216911
2019-11-05 20:56:58,761 validation loss; R2: 1.496118e-02 -1.289901
2019-11-05 20:56:58,829 epoch 206 lr 1.000000e-04
2019-11-05 20:56:59,499 train 000 1.471907e-02 -0.154818
2019-11-05 20:57:09,683 train 050 1.606033e-02 -0.686378
2019-11-05 20:57:19,896 train 100 1.593431e-02 -0.546498
2019-11-05 20:57:30,071 train 150 1.599208e-02 -0.649626
2019-11-05 20:57:40,206 train 200 1.606573e-02 -0.598232
2019-11-05 20:57:50,262 train 250 1.618311e-02 -0.621862
2019-11-05 20:58:00,414 train 300 1.628002e-02 -0.650151
2019-11-05 20:58:10,565 train 350 1.628053e-02 -0.651137
2019-11-05 20:58:20,602 train 400 1.627742e-02 -0.647442
2019-11-05 20:58:30,689 train 450 1.625727e-02 -0.638068
2019-11-05 20:58:40,835 train 500 1.622686e-02 -0.630674
2019-11-05 20:58:50,976 train 550 1.623301e-02 -0.637102
2019-11-05 20:59:01,023 train 600 1.622936e-02 -0.658076
2019-11-05 20:59:11,115 train 650 1.621394e-02 -0.659313
2019-11-05 20:59:21,282 train 700 1.621598e-02 -0.648436
2019-11-05 20:59:31,367 train 750 1.620864e-02 -0.662834
2019-11-05 20:59:41,414 train 800 1.621721e-02 -0.691269
2019-11-05 20:59:51,539 train 850 1.623921e-02 -0.694055
2019-11-05 20:59:54,579 training loss; R2: 1.625224e-02 -0.701251
2019-11-05 20:59:55,149 valid 000 1.527737e-02 -0.142999
2019-11-05 21:00:04,953 valid 050 1.419813e-02 -1.282371
2019-11-05 21:00:13,571 validation loss; R2: 1.434411e-02 -1.165067
2019-11-05 21:00:13,637 epoch 207 lr 1.000000e-04
2019-11-05 21:00:14,372 train 000 1.690684e-02 -1.402928
2019-11-05 21:00:24,522 train 050 1.590444e-02 -0.775808
2019-11-05 21:00:34,586 train 100 1.614137e-02 -0.614982
2019-11-05 21:00:44,734 train 150 1.623453e-02 -0.626873
2019-11-05 21:00:54,890 train 200 1.627179e-02 -0.645153
2019-11-05 21:01:04,988 train 250 1.624200e-02 -0.652659
2019-11-05 21:01:15,042 train 300 1.621661e-02 -0.628002
2019-11-05 21:01:25,159 train 350 1.625953e-02 -0.716164
2019-11-05 21:01:35,357 train 400 1.624376e-02 -0.745411
2019-11-05 21:01:45,450 train 450 1.622776e-02 -0.740071
2019-11-05 21:01:55,488 train 500 1.623176e-02 -0.820159
2019-11-05 21:02:05,588 train 550 1.620615e-02 -0.818783
2019-11-05 21:02:15,722 train 600 1.622188e-02 -0.791965
2019-11-05 21:02:25,792 train 650 1.622361e-02 -0.788483
2019-11-05 21:02:35,852 train 700 1.622147e-02 -0.782684
2019-11-05 21:02:45,954 train 750 1.624208e-02 -0.773942
2019-11-05 21:02:56,131 train 800 1.625186e-02 -0.761013
2019-11-05 21:03:06,306 train 850 1.625142e-02 -0.778230
2019-11-05 21:03:09,344 training loss; R2: 1.625089e-02 -0.778638
2019-11-05 21:03:09,896 valid 000 1.610437e-02 -0.789257
2019-11-05 21:03:19,749 valid 050 1.470608e-02 -1.515519
2019-11-05 21:03:28,436 validation loss; R2: 1.484777e-02 -1.354771
2019-11-05 21:03:28,499 epoch 208 lr 1.000000e-04
2019-11-05 21:03:29,205 train 000 1.590641e-02 -0.099780
2019-11-05 21:03:39,329 train 050 1.613267e-02 -0.797949
2019-11-05 21:03:49,423 train 100 1.628953e-02 -0.883104
2019-11-05 21:03:59,616 train 150 1.627534e-02 -0.849011
2019-11-05 21:04:09,787 train 200 1.630092e-02 -0.811236
2019-11-05 21:04:19,873 train 250 1.642377e-02 -0.758531
2019-11-05 21:04:29,978 train 300 1.644253e-02 -0.740590
2019-11-05 21:04:40,158 train 350 1.643201e-02 -0.721290
2019-11-05 21:04:50,242 train 400 1.638836e-02 -0.718142
2019-11-05 21:05:00,274 train 450 1.633198e-02 -0.718769
2019-11-05 21:05:10,325 train 500 1.626286e-02 -0.701719
2019-11-05 21:05:20,437 train 550 1.623791e-02 -0.687718
2019-11-05 21:05:30,522 train 600 1.619972e-02 -0.675354
2019-11-05 21:05:40,551 train 650 1.618587e-02 -0.684548
2019-11-05 21:05:50,652 train 700 1.619679e-02 -0.692367
2019-11-05 21:06:00,772 train 750 1.619592e-02 -0.710671
2019-11-05 21:06:10,797 train 800 1.619397e-02 -0.712264
2019-11-05 21:06:20,814 train 850 1.618663e-02 -0.705501
2019-11-05 21:06:23,837 training loss; R2: 1.619226e-02 -0.701959
2019-11-05 21:06:24,409 valid 000 1.274038e-02 -2.003679
2019-11-05 21:06:34,130 valid 050 1.365070e-02 -1.270247
2019-11-05 21:06:42,747 validation loss; R2: 1.371776e-02 -1.265251
2019-11-05 21:06:42,817 epoch 209 lr 1.000000e-04
2019-11-05 21:06:43,540 train 000 1.739096e-02 -0.122938
2019-11-05 21:06:53,709 train 050 1.652192e-02 -0.901113
2019-11-05 21:07:03,977 train 100 1.639822e-02 -0.645255
2019-11-05 21:07:14,127 train 150 1.643237e-02 -0.624151
2019-11-05 21:07:24,287 train 200 1.638948e-02 -0.619812
2019-11-05 21:07:34,456 train 250 1.637231e-02 -0.621702
2019-11-05 21:07:44,650 train 300 1.640873e-02 -0.630673
2019-11-05 21:07:54,812 train 350 1.636336e-02 -0.671751
2019-11-05 21:08:04,960 train 400 1.635195e-02 -0.655117
2019-11-05 21:08:15,101 train 450 1.638116e-02 -0.643725
2019-11-05 21:08:25,256 train 500 1.636011e-02 -0.638984
2019-11-05 21:08:35,421 train 550 1.629407e-02 -0.654302
2019-11-05 21:08:45,592 train 600 1.627619e-02 -0.649312
2019-11-05 21:08:55,773 train 650 1.626087e-02 -0.642009
2019-11-05 21:09:05,965 train 700 1.623325e-02 -0.641949
2019-11-05 21:09:16,148 train 750 1.621886e-02 -0.636545
2019-11-05 21:09:26,353 train 800 1.621375e-02 -19.622447
2019-11-05 21:09:36,519 train 850 1.620275e-02 -18.530387
2019-11-05 21:09:39,572 training loss; R2: 1.619328e-02 -18.220155
2019-11-05 21:09:40,158 valid 000 1.489174e-02 -0.818018
2019-11-05 21:09:50,022 valid 050 1.516479e-02 -1.927462
2019-11-05 21:09:58,710 validation loss; R2: 1.506563e-02 -2.137528
2019-11-05 21:09:58,775 epoch 210 lr 1.000000e-04
2019-11-05 21:09:59,507 train 000 1.353476e-02 0.072349
2019-11-05 21:10:09,702 train 050 1.611351e-02 -0.789323
2019-11-05 21:10:19,853 train 100 1.620746e-02 -0.670420
2019-11-05 21:10:30,052 train 150 1.634782e-02 -0.664045
2019-11-05 21:10:40,274 train 200 1.626073e-02 -0.661628
2019-11-05 21:10:50,474 train 250 1.626708e-02 -0.690855
2019-11-05 21:11:00,601 train 300 1.617354e-02 -0.694416
2019-11-05 21:11:10,797 train 350 1.616371e-02 -0.706802
2019-11-05 21:11:21,028 train 400 1.617454e-02 -0.732430
2019-11-05 21:11:31,168 train 450 1.614571e-02 -0.764511
2019-11-05 21:11:41,316 train 500 1.614926e-02 -0.760166
2019-11-05 21:11:51,514 train 550 1.608688e-02 -0.753420
2019-11-05 21:12:01,718 train 600 1.610212e-02 -0.754754
2019-11-05 21:12:11,799 train 650 1.611009e-02 -0.755766
2019-11-05 21:12:21,930 train 700 1.613527e-02 -0.752000
2019-11-05 21:12:32,145 train 750 1.617166e-02 -0.755508
2019-11-05 21:12:42,279 train 800 1.615073e-02 -0.765448
2019-11-05 21:12:52,374 train 850 1.614212e-02 -0.754072
2019-11-05 21:12:55,382 training loss; R2: 1.616002e-02 -0.748749
2019-11-05 21:12:55,939 valid 000 1.658903e-02 -0.719888
2019-11-05 21:13:05,688 valid 050 1.413158e-02 -1.152741
2019-11-05 21:13:14,287 validation loss; R2: 1.429093e-02 -1.190275
2019-11-05 21:13:14,351 epoch 211 lr 1.000000e-04
2019-11-05 21:13:15,085 train 000 1.660797e-02 -0.462343
2019-11-05 21:13:25,162 train 050 1.620715e-02 -0.929589
2019-11-05 21:13:35,261 train 100 1.618698e-02 -0.838980
2019-11-05 21:13:45,425 train 150 1.612411e-02 -0.872751
2019-11-05 21:13:55,589 train 200 1.624570e-02 -0.817532
2019-11-05 21:14:05,668 train 250 1.622795e-02 -0.842141
2019-11-05 21:14:15,768 train 300 1.618900e-02 -0.817255
2019-11-05 21:14:25,927 train 350 1.614025e-02 -0.803386
2019-11-05 21:14:36,057 train 400 1.615492e-02 -0.795850
2019-11-05 21:14:46,112 train 450 1.615966e-02 -0.776133
2019-11-05 21:14:56,144 train 500 1.618836e-02 -0.741850
2019-11-05 21:15:06,259 train 550 1.616792e-02 -0.708026
2019-11-05 21:15:16,400 train 600 1.616874e-02 -0.703578
2019-11-05 21:15:26,502 train 650 1.617191e-02 -0.699388
2019-11-05 21:15:36,572 train 700 1.614199e-02 -0.689839
2019-11-05 21:15:46,659 train 750 1.616696e-02 -0.751371
2019-11-05 21:15:56,805 train 800 1.615154e-02 -0.759196
2019-11-05 21:16:06,954 train 850 1.616987e-02 -0.749074
2019-11-05 21:16:09,955 training loss; R2: 1.618315e-02 -0.755748
2019-11-05 21:16:10,465 valid 000 1.349299e-02 -0.718328
2019-11-05 21:16:20,252 valid 050 1.434468e-02 -1.902608
2019-11-05 21:16:28,880 validation loss; R2: 1.414836e-02 -1.641576
2019-11-05 21:16:28,943 epoch 212 lr 1.000000e-04
2019-11-05 21:16:29,692 train 000 1.597436e-02 -1.607546
2019-11-05 21:16:39,818 train 050 1.632182e-02 -0.552088
2019-11-05 21:16:49,928 train 100 1.629230e-02 -0.487126
2019-11-05 21:17:00,136 train 150 1.627293e-02 -0.649990
2019-11-05 21:17:10,307 train 200 1.619399e-02 -0.813054
2019-11-05 21:17:20,489 train 250 1.617718e-02 -0.750423
2019-11-05 21:17:30,720 train 300 1.612679e-02 -0.704241
2019-11-05 21:17:40,880 train 350 1.619329e-02 -0.688885
2019-11-05 21:17:51,022 train 400 1.616993e-02 -0.683757
2019-11-05 21:18:01,156 train 450 1.616583e-02 -0.688700
2019-11-05 21:18:11,310 train 500 1.618468e-02 -0.678756
2019-11-05 21:18:21,482 train 550 1.616850e-02 -0.689172
2019-11-05 21:18:31,644 train 600 1.617357e-02 -0.720764
2019-11-05 21:18:41,812 train 650 1.618205e-02 -0.695302
2019-11-05 21:18:51,961 train 700 1.618390e-02 -0.731248
2019-11-05 21:19:02,119 train 750 1.618321e-02 -0.725824
2019-11-05 21:19:12,294 train 800 1.617549e-02 -0.735787
2019-11-05 21:19:22,459 train 850 1.615996e-02 -0.817093
2019-11-05 21:19:25,538 training loss; R2: 1.614605e-02 -0.820679
2019-11-05 21:19:26,042 valid 000 1.223503e-02 -0.732579
2019-11-05 21:19:35,884 valid 050 1.419911e-02 -1.058951
2019-11-05 21:19:44,540 validation loss; R2: 1.417657e-02 -3.394464
2019-11-05 21:19:44,610 epoch 213 lr 1.000000e-04
2019-11-05 21:19:45,352 train 000 1.709288e-02 -1.839695
2019-11-05 21:19:55,545 train 050 1.646702e-02 -0.611420
2019-11-05 21:20:05,753 train 100 1.641520e-02 -0.641804
2019-11-05 21:20:15,915 train 150 1.650407e-02 -0.643271
2019-11-05 21:20:26,051 train 200 1.643635e-02 -0.658578
2019-11-05 21:20:36,159 train 250 1.636900e-02 -0.816057
2019-11-05 21:20:46,288 train 300 1.633500e-02 -0.832213
2019-11-05 21:20:56,413 train 350 1.630375e-02 -0.824750
2019-11-05 21:21:06,567 train 400 1.629346e-02 -0.808753
2019-11-05 21:21:16,723 train 450 1.621875e-02 -0.828591
2019-11-05 21:21:26,855 train 500 1.622682e-02 -0.825251
2019-11-05 21:21:36,991 train 550 1.619443e-02 -0.851023
2019-11-05 21:21:47,137 train 600 1.618157e-02 -0.880931
2019-11-05 21:21:57,296 train 650 1.615914e-02 -0.871349
2019-11-05 21:22:07,434 train 700 1.617115e-02 -0.860961
2019-11-05 21:22:17,578 train 750 1.616338e-02 -0.897011
2019-11-05 21:22:27,711 train 800 1.613859e-02 -0.872827
2019-11-05 21:22:37,847 train 850 1.614549e-02 -0.865820
2019-11-05 21:22:40,872 training loss; R2: 1.614391e-02 -0.866018
2019-11-05 21:22:41,384 valid 000 1.371616e-02 -0.102352
2019-11-05 21:22:51,178 valid 050 1.505030e-02 -0.799483
2019-11-05 21:22:59,874 validation loss; R2: 1.526348e-02 -0.761019
2019-11-05 21:22:59,940 epoch 214 lr 1.000000e-04
2019-11-05 21:23:00,686 train 000 1.572154e-02 -0.298159
2019-11-05 21:23:10,819 train 050 1.639488e-02 -0.853346
2019-11-05 21:23:20,977 train 100 1.630664e-02 -0.736226
2019-11-05 21:23:31,119 train 150 1.633929e-02 -0.682385
2019-11-05 21:23:41,273 train 200 1.634485e-02 -0.764699
2019-11-05 21:23:51,417 train 250 1.620661e-02 -0.796332
2019-11-05 21:24:01,536 train 300 1.624351e-02 -0.787591
2019-11-05 21:24:11,705 train 350 1.624634e-02 -0.783335
2019-11-05 21:24:21,874 train 400 1.621378e-02 -0.794552
2019-11-05 21:24:32,054 train 450 1.624592e-02 -0.760531
2019-11-05 21:24:42,206 train 500 1.617464e-02 -0.741398
2019-11-05 21:24:52,366 train 550 1.615059e-02 -0.768132
2019-11-05 21:25:02,556 train 600 1.619350e-02 -0.765063
2019-11-05 21:25:12,744 train 650 1.619993e-02 -0.780958
2019-11-05 21:25:22,913 train 700 1.620502e-02 -0.779838
2019-11-05 21:25:33,072 train 750 1.619714e-02 -0.791093
2019-11-05 21:25:43,247 train 800 1.620137e-02 -0.791757
2019-11-05 21:25:53,421 train 850 1.619203e-02 -0.774704
2019-11-05 21:25:56,460 training loss; R2: 1.618596e-02 -0.772803
2019-11-05 21:25:57,024 valid 000 1.443451e-02 -32.760238
2019-11-05 21:26:06,965 valid 050 1.513766e-02 -1.501555
2019-11-05 21:26:15,701 validation loss; R2: 1.490909e-02 -1.577742
2019-11-05 21:26:15,766 epoch 215 lr 1.000000e-04
2019-11-05 21:26:16,508 train 000 1.798814e-02 -0.253907
2019-11-05 21:26:26,768 train 050 1.659373e-02 -0.736459
2019-11-05 21:26:36,980 train 100 1.618636e-02 -0.692856
2019-11-05 21:26:47,138 train 150 1.627882e-02 -0.629581
2019-11-05 21:26:57,281 train 200 1.642060e-02 -0.706372
2019-11-05 21:27:07,416 train 250 1.634257e-02 -0.691394
2019-11-05 21:27:17,553 train 300 1.626644e-02 -0.682448
2019-11-05 21:27:27,681 train 350 1.623688e-02 -0.711746
2019-11-05 21:27:37,824 train 400 1.621060e-02 -0.707809
2019-11-05 21:27:47,950 train 450 1.621822e-02 -0.678579
2019-11-05 21:27:58,070 train 500 1.619318e-02 -0.668367
2019-11-05 21:28:08,189 train 550 1.618450e-02 -0.659769
2019-11-05 21:28:18,304 train 600 1.613371e-02 -0.691661
2019-11-05 21:28:28,498 train 650 1.610116e-02 -0.703211
2019-11-05 21:28:38,706 train 700 1.607893e-02 -0.702629
2019-11-05 21:28:48,887 train 750 1.606571e-02 -0.701871
2019-11-05 21:28:59,089 train 800 1.605065e-02 -0.704368
2019-11-05 21:29:09,286 train 850 1.606418e-02 -0.690702
2019-11-05 21:29:12,326 training loss; R2: 1.606887e-02 -0.691352
2019-11-05 21:29:12,882 valid 000 1.459793e-02 -0.752658
2019-11-05 21:29:22,781 valid 050 1.409686e-02 -0.834101
2019-11-05 21:29:31,461 validation loss; R2: 1.428372e-02 -1.048541
2019-11-05 21:29:31,526 epoch 216 lr 1.000000e-04
2019-11-05 21:29:32,246 train 000 1.779347e-02 -1.014822
2019-11-05 21:29:42,473 train 050 1.643181e-02 -0.861652
2019-11-05 21:29:52,672 train 100 1.639386e-02 -0.777954
2019-11-05 21:30:02,851 train 150 1.629773e-02 -0.721704
2019-11-05 21:30:13,037 train 200 1.622396e-02 -0.803481
2019-11-05 21:30:23,222 train 250 1.613563e-02 -0.872775
2019-11-05 21:30:33,382 train 300 1.613332e-02 -0.841040
2019-11-05 21:30:43,543 train 350 1.616319e-02 -1.396504
2019-11-05 21:30:53,702 train 400 1.615322e-02 -1.301984
2019-11-05 21:31:03,897 train 450 1.616079e-02 -1.280718
2019-11-05 21:31:14,091 train 500 1.617913e-02 -1.219546
2019-11-05 21:31:24,262 train 550 1.614569e-02 -1.191472
2019-11-05 21:31:34,398 train 600 1.614812e-02 -1.154608
2019-11-05 21:31:44,533 train 650 1.613203e-02 -1.125592
2019-11-05 21:31:54,655 train 700 1.609742e-02 -1.088856
2019-11-05 21:32:04,810 train 750 1.611219e-02 -1.070582
2019-11-05 21:32:14,977 train 800 1.611188e-02 -1.045114
2019-11-05 21:32:25,067 train 850 1.611769e-02 -1.012222
2019-11-05 21:32:28,087 training loss; R2: 1.611071e-02 -1.003511
2019-11-05 21:32:28,642 valid 000 1.755375e-02 -0.075947
2019-11-05 21:32:38,402 valid 050 1.618101e-02 -0.824428
2019-11-05 21:32:46,992 validation loss; R2: 1.598115e-02 -0.776435
2019-11-05 21:32:47,066 epoch 217 lr 1.000000e-04
2019-11-05 21:32:47,727 train 000 1.533314e-02 -0.232255
2019-11-05 21:32:57,922 train 050 1.610043e-02 -1.024068
2019-11-05 21:33:08,086 train 100 1.612329e-02 -1.011526
2019-11-05 21:33:18,175 train 150 1.612517e-02 -1.065034
2019-11-05 21:33:28,268 train 200 1.614004e-02 -1.029607
2019-11-05 21:33:38,379 train 250 1.621978e-02 -0.976391
2019-11-05 21:33:48,431 train 300 1.620646e-02 -0.946825
2019-11-05 21:33:58,439 train 350 1.619396e-02 -0.919829
2019-11-05 21:34:08,557 train 400 1.618503e-02 -0.897148
2019-11-05 21:34:18,654 train 450 1.616094e-02 -0.867507
2019-11-05 21:34:28,698 train 500 1.616184e-02 -0.866868
2019-11-05 21:34:38,790 train 550 1.612676e-02 -0.837553
2019-11-05 21:34:48,951 train 600 1.610249e-02 -0.830335
2019-11-05 21:34:59,027 train 650 1.613559e-02 -0.823877
2019-11-05 21:35:09,052 train 700 1.612064e-02 -0.802533
2019-11-05 21:35:19,159 train 750 1.611888e-02 -0.787895
2019-11-05 21:35:29,314 train 800 1.616329e-02 -0.780735
2019-11-05 21:35:39,337 train 850 1.614823e-02 -0.787248
2019-11-05 21:35:42,334 training loss; R2: 1.614682e-02 -0.777873
2019-11-05 21:35:42,896 valid 000 1.747636e-02 -1.186360
2019-11-05 21:35:52,681 valid 050 1.713101e-02 -1.190155
2019-11-05 21:36:01,410 validation loss; R2: 1.742105e-02 -1.128449
2019-11-05 21:36:01,481 epoch 218 lr 1.000000e-04
2019-11-05 21:36:02,154 train 000 1.574465e-02 -0.027126
2019-11-05 21:36:12,337 train 050 1.618644e-02 -1.070702
2019-11-05 21:36:22,429 train 100 1.602210e-02 -0.901198
2019-11-05 21:36:32,571 train 150 1.609961e-02 -0.919818
2019-11-05 21:36:42,712 train 200 1.609492e-02 -0.845821
2019-11-05 21:36:52,765 train 250 1.609541e-02 -0.865080
2019-11-05 21:37:02,838 train 300 1.611020e-02 -0.917136
2019-11-05 21:37:12,976 train 350 1.607082e-02 -0.883789
2019-11-05 21:37:23,127 train 400 1.607375e-02 -0.847220
2019-11-05 21:37:33,195 train 450 1.608618e-02 -0.818043
2019-11-05 21:37:43,262 train 500 1.609599e-02 -0.815875
2019-11-05 21:37:53,380 train 550 1.611846e-02 -0.810479
2019-11-05 21:38:03,532 train 600 1.611079e-02 -0.791136
2019-11-05 21:38:13,623 train 650 1.608597e-02 -0.782551
2019-11-05 21:38:23,681 train 700 1.610199e-02 -0.758447
2019-11-05 21:38:33,855 train 750 1.608355e-02 -0.743720
2019-11-05 21:38:44,021 train 800 1.608148e-02 -0.759716
2019-11-05 21:38:54,089 train 850 1.606946e-02 -0.741395
2019-11-05 21:38:57,090 training loss; R2: 1.605473e-02 -0.739714
2019-11-05 21:38:57,604 valid 000 1.440322e-02 -1.141734
2019-11-05 21:39:07,412 valid 050 1.577211e-02 -1.674463
2019-11-05 21:39:16,024 validation loss; R2: 1.591185e-02 -1.792152
2019-11-05 21:39:16,086 epoch 219 lr 1.000000e-04
2019-11-05 21:39:16,751 train 000 1.515026e-02 -0.057326
2019-11-05 21:39:26,947 train 050 1.635274e-02 -0.790210
2019-11-05 21:39:37,083 train 100 1.615146e-02 -0.696339
2019-11-05 21:39:47,218 train 150 1.619395e-02 -0.618084
2019-11-05 21:39:57,343 train 200 1.611030e-02 -0.729326
2019-11-05 21:40:07,485 train 250 1.607541e-02 -0.734111
2019-11-05 21:40:17,604 train 300 1.605373e-02 -0.750131
2019-11-05 21:40:27,760 train 350 1.610595e-02 -0.744561
2019-11-05 21:40:37,913 train 400 1.614116e-02 -0.740654
2019-11-05 21:40:48,098 train 450 1.611305e-02 -0.786384
2019-11-05 21:40:58,298 train 500 1.614523e-02 -0.756653
2019-11-05 21:41:08,470 train 550 1.613760e-02 -0.755372
2019-11-05 21:41:18,613 train 600 1.611984e-02 -0.741039
2019-11-05 21:41:28,753 train 650 1.611068e-02 -0.738953
2019-11-05 21:41:38,902 train 700 1.610118e-02 -0.743039
2019-11-05 21:41:49,065 train 750 1.610150e-02 -0.753550
2019-11-05 21:41:59,186 train 800 1.609855e-02 -0.765036
2019-11-05 21:42:09,305 train 850 1.608907e-02 -0.993182
2019-11-05 21:42:12,331 training loss; R2: 1.609847e-02 -0.991412
2019-11-05 21:42:12,884 valid 000 1.688764e-02 -3.728952
2019-11-05 21:42:22,606 valid 050 1.491230e-02 -1.187155
2019-11-05 21:42:31,218 validation loss; R2: 1.476062e-02 -1.699599
2019-11-05 21:42:31,280 epoch 220 lr 1.000000e-04
2019-11-05 21:42:32,030 train 000 2.055785e-02 -0.375657
2019-11-05 21:42:42,067 train 050 1.618578e-02 -0.739044
2019-11-05 21:42:52,222 train 100 1.608391e-02 -1.074172
2019-11-05 21:43:02,365 train 150 1.606013e-02 -0.927854
2019-11-05 21:43:12,426 train 200 1.605025e-02 -0.899756
2019-11-05 21:43:22,473 train 250 1.606905e-02 -0.799940
2019-11-05 21:43:32,614 train 300 1.607442e-02 -0.779152
2019-11-05 21:43:42,724 train 350 1.614422e-02 -0.806706
2019-11-05 21:43:52,799 train 400 1.617611e-02 -0.786255
2019-11-05 21:44:02,883 train 450 1.616457e-02 -0.792357
2019-11-05 21:44:12,992 train 500 1.615038e-02 -0.777543
2019-11-05 21:44:23,138 train 550 1.615301e-02 -0.778457
2019-11-05 21:44:33,177 train 600 1.615101e-02 -0.763971
2019-11-05 21:44:43,298 train 650 1.614332e-02 -0.768534
2019-11-05 21:44:53,458 train 700 1.613757e-02 -0.751029
2019-11-05 21:45:03,534 train 750 1.612165e-02 -9.881350
2019-11-05 21:45:13,582 train 800 1.611453e-02 -9.318059
2019-11-05 21:45:23,688 train 850 1.609807e-02 -8.806970
2019-11-05 21:45:26,711 training loss; R2: 1.610270e-02 -8.668245
2019-11-05 21:45:27,289 valid 000 1.702816e-02 -0.381591
2019-11-05 21:45:37,089 valid 050 1.523510e-02 -1.480930
2019-11-05 21:45:45,789 validation loss; R2: 1.527858e-02 -1.451580
2019-11-05 21:45:45,854 epoch 221 lr 1.000000e-04
2019-11-05 21:45:46,523 train 000 1.575144e-02 -2.606951
2019-11-05 21:45:56,750 train 050 1.574857e-02 -0.920913
2019-11-05 21:46:06,926 train 100 1.577496e-02 -0.881928
2019-11-05 21:46:17,096 train 150 1.600350e-02 -0.892293
2019-11-05 21:46:27,258 train 200 1.599713e-02 -0.938816
2019-11-05 21:46:37,399 train 250 1.604133e-02 -0.888251
2019-11-05 21:46:47,550 train 300 1.610092e-02 -0.856668
2019-11-05 21:46:57,725 train 350 1.610954e-02 -0.816892
2019-11-05 21:47:07,913 train 400 1.610590e-02 -0.791200
2019-11-05 21:47:18,117 train 450 1.619747e-02 -0.790356
2019-11-05 21:47:28,289 train 500 1.619311e-02 -0.770469
2019-11-05 21:47:38,473 train 550 1.621335e-02 -0.779042
2019-11-05 21:47:48,645 train 600 1.621772e-02 -0.764594
2019-11-05 21:47:58,803 train 650 1.621921e-02 -0.758288
2019-11-05 21:48:08,967 train 700 1.623612e-02 -0.747366
2019-11-05 21:48:19,160 train 750 1.620430e-02 -0.733349
2019-11-05 21:48:29,339 train 800 1.624417e-02 -0.730521
2019-11-05 21:48:39,522 train 850 1.624005e-02 -0.732836
2019-11-05 21:48:42,553 training loss; R2: 1.624384e-02 -0.731482
2019-11-05 21:48:43,060 valid 000 1.530953e-02 -0.133560
2019-11-05 21:48:52,832 valid 050 1.382043e-02 -1.100807
2019-11-05 21:49:01,463 validation loss; R2: 1.370178e-02 -1.125265
2019-11-05 21:49:01,528 epoch 222 lr 1.000000e-04
2019-11-05 21:49:02,272 train 000 1.592329e-02 -0.313712
2019-11-05 21:49:12,424 train 050 1.606487e-02 -0.551952
2019-11-05 21:49:22,584 train 100 1.614898e-02 -0.561627
2019-11-05 21:49:32,751 train 150 1.615116e-02 -0.655711
2019-11-05 21:49:42,920 train 200 1.607960e-02 -0.663644
2019-11-05 21:49:52,991 train 250 1.612400e-02 -0.621892
2019-11-05 21:50:03,028 train 300 1.604090e-02 -0.640165
2019-11-05 21:50:13,063 train 350 1.598187e-02 -0.658861
2019-11-05 21:50:23,161 train 400 1.600139e-02 -0.662399
2019-11-05 21:50:33,315 train 450 1.603276e-02 -0.680502
2019-11-05 21:50:43,463 train 500 1.609731e-02 -0.696669
2019-11-05 21:50:53,619 train 550 1.612949e-02 -0.705900
2019-11-05 21:51:03,765 train 600 1.613383e-02 -0.693503
2019-11-05 21:51:13,896 train 650 1.611899e-02 -0.681365
2019-11-05 21:51:24,022 train 700 1.610476e-02 -0.757555
2019-11-05 21:51:34,149 train 750 1.610664e-02 -0.739005
2019-11-05 21:51:44,315 train 800 1.610717e-02 -0.776620
2019-11-05 21:51:54,451 train 850 1.608610e-02 -0.763200
2019-11-05 21:51:57,471 training loss; R2: 1.609207e-02 -0.809324
2019-11-05 21:51:57,978 valid 000 1.420035e-02 -0.507362
2019-11-05 21:52:07,670 valid 050 1.432574e-02 -1.150667
2019-11-05 21:52:16,538 validation loss; R2: 1.451735e-02 -1.621229
2019-11-05 21:52:16,615 epoch 223 lr 1.000000e-04
2019-11-05 21:52:17,369 train 000 1.952431e-02 -1.417998
2019-11-05 21:52:27,509 train 050 1.604659e-02 -0.603081
2019-11-05 21:52:37,696 train 100 1.590317e-02 -0.797944
2019-11-05 21:52:47,866 train 150 1.590070e-02 -0.800437
2019-11-05 21:52:58,039 train 200 1.593653e-02 -0.766333
2019-11-05 21:53:08,183 train 250 1.606683e-02 -0.763122
2019-11-05 21:53:18,343 train 300 1.609463e-02 -0.717990
2019-11-05 21:53:28,504 train 350 1.612505e-02 -0.698931
2019-11-05 21:53:38,685 train 400 1.611375e-02 -0.698902
2019-11-05 21:53:48,896 train 450 1.610605e-02 -0.710124
2019-11-05 21:53:59,092 train 500 1.609680e-02 -0.707221
2019-11-05 21:54:09,275 train 550 1.611893e-02 -0.698597
2019-11-05 21:54:19,451 train 600 1.609386e-02 -0.692519
2019-11-05 21:54:29,633 train 650 1.608304e-02 -0.811932
2019-11-05 21:54:39,824 train 700 1.608312e-02 -0.788310
2019-11-05 21:54:49,958 train 750 1.607744e-02 -0.798608
2019-11-05 21:55:00,042 train 800 1.608480e-02 -0.810008
2019-11-05 21:55:10,202 train 850 1.608072e-02 -0.852651
2019-11-05 21:55:13,241 training loss; R2: 1.608781e-02 -0.842158
2019-11-05 21:55:13,776 valid 000 1.592384e-02 -1.458464
2019-11-05 21:55:23,650 valid 050 1.505027e-02 -1.410943
2019-11-05 21:55:32,372 validation loss; R2: 1.481757e-02 -1.255757
2019-11-05 21:55:32,439 epoch 224 lr 1.000000e-04
2019-11-05 21:55:33,172 train 000 1.502519e-02 -0.541796
2019-11-05 21:55:43,378 train 050 1.621351e-02 -0.415821
2019-11-05 21:55:53,583 train 100 1.597918e-02 -0.556891
2019-11-05 21:56:03,756 train 150 1.595113e-02 -0.502832
2019-11-05 21:56:13,951 train 200 1.605986e-02 -0.575290
2019-11-05 21:56:24,111 train 250 1.610718e-02 -0.602857
2019-11-05 21:56:34,267 train 300 1.604659e-02 -0.611914
2019-11-05 21:56:44,435 train 350 1.604438e-02 -0.652974
2019-11-05 21:56:54,603 train 400 1.606403e-02 -0.640389
2019-11-05 21:57:04,761 train 450 1.603502e-02 -0.635182
2019-11-05 21:57:14,893 train 500 1.601510e-02 -0.662664
2019-11-05 21:57:25,054 train 550 1.597829e-02 -0.668352
2019-11-05 21:57:35,217 train 600 1.601813e-02 -0.669969
2019-11-05 21:57:45,408 train 650 1.605156e-02 -0.662593
2019-11-05 21:57:55,572 train 700 1.605484e-02 -0.677396
2019-11-05 21:58:05,772 train 750 1.604011e-02 -0.678931
2019-11-05 21:58:15,958 train 800 1.604990e-02 -0.675665
2019-11-05 21:58:26,130 train 850 1.603069e-02 -0.683367
2019-11-05 21:58:29,161 training loss; R2: 1.603248e-02 -0.682701
2019-11-05 21:58:29,751 valid 000 1.452535e-02 -0.210973
2019-11-05 21:58:39,635 valid 050 1.434329e-02 -0.517421
2019-11-05 21:58:48,275 validation loss; R2: 1.443203e-02 -0.735817
2019-11-05 21:58:48,344 epoch 225 lr 1.000000e-04
2019-11-05 21:58:49,031 train 000 1.556227e-02 -0.094761
2019-11-05 21:58:59,210 train 050 1.618418e-02 -29.637931
2019-11-05 21:59:09,364 train 100 1.627524e-02 -15.267158
2019-11-05 21:59:19,473 train 150 1.628832e-02 -10.455055
2019-11-05 21:59:29,570 train 200 1.635465e-02 -7.991457
2019-11-05 21:59:39,667 train 250 1.631429e-02 -6.536387
2019-11-05 21:59:49,847 train 300 1.624997e-02 -5.542713
2019-11-05 22:00:00,028 train 350 1.623673e-02 -4.859606
2019-11-05 22:00:10,181 train 400 1.620880e-02 -4.317059
2019-11-05 22:00:20,342 train 450 1.617706e-02 -3.902063
2019-11-05 22:00:30,517 train 500 1.618109e-02 -3.576568
2019-11-05 22:00:40,690 train 550 1.610931e-02 -3.302925
2019-11-05 22:00:50,857 train 600 1.610636e-02 -3.077323
2019-11-05 22:01:01,021 train 650 1.609042e-02 -2.911220
2019-11-05 22:01:11,185 train 700 1.609818e-02 -2.754080
2019-11-05 22:01:21,357 train 750 1.606813e-02 -2.661143
2019-11-05 22:01:31,479 train 800 1.605959e-02 -2.531751
2019-11-05 22:01:41,592 train 850 1.606164e-02 -2.415154
2019-11-05 22:01:44,623 training loss; R2: 1.606816e-02 -2.386543
2019-11-05 22:01:45,145 valid 000 1.395156e-02 -1.075640
2019-11-05 22:01:54,979 valid 050 1.534539e-02 -1.260860
2019-11-05 22:02:03,667 validation loss; R2: 1.553596e-02 -1.408549
2019-11-05 22:02:03,725 epoch 226 lr 1.000000e-04
2019-11-05 22:02:04,490 train 000 1.841915e-02 -0.623286
2019-11-05 22:02:14,752 train 050 1.628807e-02 -0.893360
2019-11-05 22:02:24,970 train 100 1.616099e-02 -0.766580
2019-11-05 22:02:35,166 train 150 1.601113e-02 -0.801677
2019-11-05 22:02:45,375 train 200 1.610744e-02 -0.742896
2019-11-05 22:02:55,529 train 250 1.607744e-02 -0.735751
2019-11-05 22:03:05,753 train 300 1.604596e-02 -0.704310
2019-11-05 22:03:15,970 train 350 1.600595e-02 -0.708704
2019-11-05 22:03:26,174 train 400 1.602707e-02 -0.738118
2019-11-05 22:03:36,385 train 450 1.602915e-02 -0.724687
2019-11-05 22:03:46,596 train 500 1.601434e-02 -0.727405
2019-11-05 22:03:56,750 train 550 1.603289e-02 -0.704421
2019-11-05 22:04:06,919 train 600 1.603606e-02 -0.703843
2019-11-05 22:04:17,088 train 650 1.604176e-02 -0.696453
2019-11-05 22:04:27,289 train 700 1.602552e-02 -0.694190
2019-11-05 22:04:37,498 train 750 1.603886e-02 -0.724579
2019-11-05 22:04:47,697 train 800 1.603833e-02 -0.718810
2019-11-05 22:04:57,888 train 850 1.603794e-02 -0.726573
2019-11-05 22:05:00,921 training loss; R2: 1.603848e-02 -0.723688
2019-11-05 22:05:01,431 valid 000 1.464409e-02 -0.344776
2019-11-05 22:05:11,307 valid 050 1.459131e-02 -1.428757
2019-11-05 22:05:19,947 validation loss; R2: 1.466355e-02 -1.889107
2019-11-05 22:05:20,024 epoch 227 lr 1.000000e-04
2019-11-05 22:05:20,762 train 000 1.398270e-02 0.165319
2019-11-05 22:05:31,228 train 050 1.590941e-02 -0.672146
2019-11-05 22:05:41,658 train 100 1.612690e-02 -0.830564
2019-11-05 22:05:52,103 train 150 1.607101e-02 -0.824706
2019-11-05 22:06:02,422 train 200 1.610182e-02 -0.755141
2019-11-05 22:06:12,699 train 250 1.601592e-02 -0.720872
2019-11-05 22:06:22,991 train 300 1.607554e-02 -0.697566
2019-11-05 22:06:33,338 train 350 1.607211e-02 -0.694615
2019-11-05 22:06:43,634 train 400 1.604657e-02 -0.742442
2019-11-05 22:06:53,934 train 450 1.603554e-02 -0.745934
2019-11-05 22:07:04,246 train 500 1.606636e-02 -0.732123
2019-11-05 22:07:14,439 train 550 1.607441e-02 -0.818927
2019-11-05 22:07:24,715 train 600 1.606261e-02 -0.847620
2019-11-05 22:07:34,954 train 650 1.607451e-02 -0.833606
2019-11-05 22:07:45,234 train 700 1.604693e-02 -0.813323
2019-11-05 22:07:55,483 train 750 1.604241e-02 -0.795596
2019-11-05 22:08:05,839 train 800 1.601918e-02 -0.785512
2019-11-05 22:08:15,891 train 850 1.599350e-02 -0.774060
2019-11-05 22:08:18,862 training loss; R2: 1.600011e-02 -0.779134
2019-11-05 22:08:19,429 valid 000 1.279411e-02 -0.989015
2019-11-05 22:08:29,247 valid 050 1.372344e-02 -1.184155
2019-11-05 22:08:37,916 validation loss; R2: 1.395633e-02 -1.100375
2019-11-05 22:08:37,979 epoch 228 lr 1.000000e-04
2019-11-05 22:08:38,718 train 000 1.509087e-02 -1.276187
2019-11-05 22:08:48,543 train 050 1.610787e-02 -4.379501
2019-11-05 22:08:58,287 train 100 1.628439e-02 -2.450166
2019-11-05 22:09:07,994 train 150 1.631372e-02 -1.843449
2019-11-05 22:09:17,705 train 200 1.628398e-02 -1.659738
2019-11-05 22:09:27,462 train 250 1.623897e-02 -1.456532
2019-11-05 22:09:37,507 train 300 1.616140e-02 -1.321700
2019-11-05 22:09:47,762 train 350 1.615427e-02 -1.227141
2019-11-05 22:09:57,970 train 400 1.616488e-02 -1.177279
2019-11-05 22:10:08,290 train 450 1.611209e-02 -1.120467
2019-11-05 22:10:18,570 train 500 1.605223e-02 -1.060134
2019-11-05 22:10:28,783 train 550 1.603425e-02 -1.025808
2019-11-05 22:10:39,102 train 600 1.607805e-02 -1.008685
2019-11-05 22:10:49,297 train 650 1.601931e-02 -0.983812
2019-11-05 22:10:59,606 train 700 1.602914e-02 -0.973225
2019-11-05 22:11:09,831 train 750 1.603533e-02 -0.945236
2019-11-05 22:11:20,044 train 800 1.602611e-02 -0.942311
2019-11-05 22:11:30,400 train 850 1.605404e-02 -0.933814
2019-11-05 22:11:33,380 training loss; R2: 1.604641e-02 -0.924547
2019-11-05 22:11:33,956 valid 000 1.396009e-02 -2.621098
2019-11-05 22:11:43,886 valid 050 1.408856e-02 -1.309495
2019-11-05 22:11:52,612 validation loss; R2: 1.435400e-02 -1.034513
2019-11-05 22:11:52,675 epoch 229 lr 1.000000e-04
2019-11-05 22:11:53,418 train 000 1.979535e-02 -0.288625
2019-11-05 22:12:03,756 train 050 1.616366e-02 -1.119597
2019-11-05 22:12:14,076 train 100 1.627088e-02 -0.943778
2019-11-05 22:12:24,254 train 150 1.621185e-02 -0.879189
2019-11-05 22:12:34,447 train 200 1.627737e-02 -0.923047
2019-11-05 22:12:44,672 train 250 1.620197e-02 -0.864043
2019-11-05 22:12:54,953 train 300 1.618821e-02 -0.888765
2019-11-05 22:13:05,153 train 350 1.612431e-02 -0.857759
2019-11-05 22:13:15,323 train 400 1.609846e-02 -0.816943
2019-11-05 22:13:25,530 train 450 1.608383e-02 -0.780630
2019-11-05 22:13:35,783 train 500 1.604667e-02 -0.789712
2019-11-05 22:13:46,011 train 550 1.604736e-02 -0.778107
2019-11-05 22:13:56,201 train 600 1.603323e-02 -0.776331
2019-11-05 22:14:06,382 train 650 1.602881e-02 -0.782075
2019-11-05 22:14:16,637 train 700 1.603383e-02 -0.778553
2019-11-05 22:14:26,888 train 750 1.609206e-02 -0.773297
2019-11-05 22:14:37,046 train 800 1.608810e-02 -0.774049
2019-11-05 22:14:47,222 train 850 1.607312e-02 -0.769050
2019-11-05 22:14:50,265 training loss; R2: 1.607097e-02 -0.769451
2019-11-05 22:14:50,834 valid 000 1.423274e-02 -1.875639
2019-11-05 22:15:00,780 valid 050 1.376770e-02 -1.107870
2019-11-05 22:15:09,492 validation loss; R2: 1.373052e-02 -1.283503
2019-11-05 22:15:09,566 epoch 230 lr 1.000000e-04
2019-11-05 22:15:10,288 train 000 1.683521e-02 -2.787658
2019-11-05 22:15:20,616 train 050 1.568514e-02 -0.649839
2019-11-05 22:15:30,905 train 100 1.590423e-02 -1.200160
2019-11-05 22:15:41,128 train 150 1.602051e-02 -0.986046
2019-11-05 22:15:51,402 train 200 1.610963e-02 -0.909492
2019-11-05 22:16:01,661 train 250 1.608837e-02 -0.873732
2019-11-05 22:16:11,856 train 300 1.608662e-02 -0.826841
2019-11-05 22:16:22,088 train 350 1.610146e-02 -0.793825
2019-11-05 22:16:32,366 train 400 1.604543e-02 -0.769815
2019-11-05 22:16:42,538 train 450 1.604537e-02 -0.756842
2019-11-05 22:16:52,709 train 500 1.607228e-02 -0.720287
2019-11-05 22:17:02,947 train 550 1.606005e-02 -0.714718
2019-11-05 22:17:13,111 train 600 1.607394e-02 -0.703961
2019-11-05 22:17:23,286 train 650 1.603844e-02 -0.725199
2019-11-05 22:17:33,556 train 700 1.601880e-02 -0.722560
2019-11-05 22:17:43,741 train 750 1.603824e-02 -0.737600
2019-11-05 22:17:53,889 train 800 1.605149e-02 -0.713489
2019-11-05 22:18:04,049 train 850 1.605654e-02 -0.706007
2019-11-05 22:18:07,108 training loss; R2: 1.604882e-02 -0.701485
2019-11-05 22:18:07,622 valid 000 1.626955e-02 -0.219210
2019-11-05 22:18:17,536 valid 050 1.511543e-02 -1.225870
2019-11-05 22:18:26,246 validation loss; R2: 1.508742e-02 -1.456945
2019-11-05 22:18:26,310 epoch 231 lr 1.000000e-04
2019-11-05 22:18:27,014 train 000 1.654864e-02 -0.254178
2019-11-05 22:18:37,279 train 050 1.623365e-02 -0.521545
2019-11-05 22:18:47,516 train 100 1.612719e-02 -0.604615
2019-11-05 22:18:57,740 train 150 1.611097e-02 -0.678011
2019-11-05 22:19:07,935 train 200 1.610732e-02 -0.669856
2019-11-05 22:19:18,174 train 250 1.615041e-02 -0.715250
2019-11-05 22:19:28,380 train 300 1.614239e-02 -0.744813
2019-11-05 22:19:38,593 train 350 1.607026e-02 -0.778780
2019-11-05 22:19:48,793 train 400 1.607519e-02 -0.759912
2019-11-05 22:19:59,016 train 450 1.607471e-02 -0.776727
2019-11-05 22:20:09,213 train 500 1.605096e-02 -0.773890
2019-11-05 22:20:19,477 train 550 1.599249e-02 -0.780512
2019-11-05 22:20:29,697 train 600 1.595849e-02 -0.765066
2019-11-05 22:20:39,951 train 650 1.599797e-02 -0.770343
2019-11-05 22:20:50,185 train 700 1.598584e-02 -0.761153
2019-11-05 22:21:00,411 train 750 1.597731e-02 -0.755288
2019-11-05 22:21:10,651 train 800 1.598614e-02 -0.739339
2019-11-05 22:21:20,923 train 850 1.599703e-02 -0.738370
2019-11-05 22:21:23,986 training loss; R2: 1.599376e-02 -0.738569
2019-11-05 22:21:24,507 valid 000 1.326870e-02 -0.973973
2019-11-05 22:21:34,394 valid 050 1.429309e-02 -1.122205
2019-11-05 22:21:43,139 validation loss; R2: 1.419557e-02 -1.079494
2019-11-05 22:21:43,211 epoch 232 lr 1.000000e-04
2019-11-05 22:21:43,942 train 000 1.498431e-02 -1.007141
2019-11-05 22:21:54,168 train 050 1.629996e-02 -1.130135
2019-11-05 22:22:04,419 train 100 1.608721e-02 -0.886317
2019-11-05 22:22:14,651 train 150 1.608090e-02 -0.809304
2019-11-05 22:22:24,878 train 200 1.608666e-02 -0.815439
2019-11-05 22:22:35,168 train 250 1.609648e-02 -0.812561
2019-11-05 22:22:45,429 train 300 1.603279e-02 -0.759874
2019-11-05 22:22:55,624 train 350 1.598791e-02 -0.782489
2019-11-05 22:23:05,813 train 400 1.599637e-02 -0.783617
2019-11-05 22:23:16,017 train 450 1.598247e-02 -0.755171
2019-11-05 22:23:26,217 train 500 1.600703e-02 -0.731763
2019-11-05 22:23:36,397 train 550 1.600584e-02 -0.726194
2019-11-05 22:23:46,583 train 600 1.602057e-02 -0.721059
2019-11-05 22:23:56,809 train 650 1.598325e-02 -0.716257
2019-11-05 22:24:07,038 train 700 1.597529e-02 -0.707785
2019-11-05 22:24:17,272 train 750 1.598334e-02 -0.717346
2019-11-05 22:24:27,477 train 800 1.598537e-02 -0.720369
2019-11-05 22:24:37,676 train 850 1.598709e-02 -0.715686
2019-11-05 22:24:40,722 training loss; R2: 1.598674e-02 -0.713917
2019-11-05 22:24:41,292 valid 000 1.643321e-02 -0.811507
2019-11-05 22:24:51,037 valid 050 1.586323e-02 -1.533373
2019-11-05 22:24:59,907 validation loss; R2: 1.554159e-02 -3.046607
2019-11-05 22:24:59,982 epoch 233 lr 1.000000e-04
2019-11-05 22:25:00,750 train 000 1.593498e-02 -0.650340
2019-11-05 22:25:10,939 train 050 1.608444e-02 -9.951064
2019-11-05 22:25:21,129 train 100 1.595397e-02 -5.315435
2019-11-05 22:25:31,332 train 150 1.600028e-02 -3.788539
2019-11-05 22:25:41,540 train 200 1.606102e-02 -3.003978
2019-11-05 22:25:51,694 train 250 1.602679e-02 -2.676328
2019-11-05 22:26:01,889 train 300 1.602672e-02 -2.312462
2019-11-05 22:26:12,055 train 350 1.603235e-02 -2.082554
2019-11-05 22:26:22,245 train 400 1.604628e-02 -1.925331
2019-11-05 22:26:32,387 train 450 1.606313e-02 -1.822845
2019-11-05 22:26:42,553 train 500 1.605275e-02 -1.698820
2019-11-05 22:26:52,692 train 550 1.602536e-02 -1.607730
2019-11-05 22:27:02,822 train 600 1.603288e-02 -1.551290
2019-11-05 22:27:12,957 train 650 1.602658e-02 -1.499360
2019-11-05 22:27:23,116 train 700 1.603253e-02 -1.449440
2019-11-05 22:27:33,258 train 750 1.606273e-02 -1.398906
2019-11-05 22:27:43,425 train 800 1.607721e-02 -1.346788
2019-11-05 22:27:53,559 train 850 1.606483e-02 -1.306253
2019-11-05 22:27:56,599 training loss; R2: 1.607798e-02 -1.292039
2019-11-05 22:27:57,114 valid 000 1.457437e-02 -1.051409
2019-11-05 22:28:06,902 valid 050 1.400257e-02 -1.158170
2019-11-05 22:28:15,573 validation loss; R2: 1.407737e-02 -1.110846
2019-11-05 22:28:15,635 epoch 234 lr 1.000000e-04
2019-11-05 22:28:16,379 train 000 1.644007e-02 -1.640638
2019-11-05 22:28:26,537 train 050 1.603780e-02 -1.052948
2019-11-05 22:28:36,748 train 100 1.587786e-02 -1.421339
2019-11-05 22:28:46,940 train 150 1.588041e-02 -1.174897
2019-11-05 22:28:57,131 train 200 1.594028e-02 -1.033113
2019-11-05 22:29:07,325 train 250 1.595694e-02 -1.050022
2019-11-05 22:29:17,499 train 300 1.595342e-02 -0.983511
2019-11-05 22:29:27,651 train 350 1.595295e-02 -0.967757
2019-11-05 22:29:37,799 train 400 1.594405e-02 -0.911346
2019-11-05 22:29:47,961 train 450 1.588404e-02 -0.893704
2019-11-05 22:29:58,114 train 500 1.588885e-02 -0.871689
2019-11-05 22:30:08,292 train 550 1.594008e-02 -0.846489
2019-11-05 22:30:18,463 train 600 1.594968e-02 -0.925965
2019-11-05 22:30:28,633 train 650 1.595186e-02 -0.921136
2019-11-05 22:30:38,793 train 700 1.595698e-02 -0.904714
2019-11-05 22:30:48,947 train 750 1.591390e-02 -0.875675
2019-11-05 22:30:59,122 train 800 1.592772e-02 -0.845149
2019-11-05 22:31:09,270 train 850 1.594536e-02 -0.839719
2019-11-05 22:31:12,306 training loss; R2: 1.593991e-02 -0.836231
2019-11-05 22:31:12,864 valid 000 1.584810e-02 -0.823691
2019-11-05 22:31:22,634 valid 050 1.519151e-02 -1.484836
2019-11-05 22:31:31,410 validation loss; R2: 1.509663e-02 -1.476330
2019-11-05 22:31:31,479 epoch 235 lr 1.000000e-04
2019-11-05 22:31:32,172 train 000 1.456821e-02 -0.202112
2019-11-05 22:31:42,428 train 050 1.622305e-02 -0.891034
2019-11-05 22:31:52,633 train 100 1.604205e-02 -0.666580
2019-11-05 22:32:02,809 train 150 1.594597e-02 -0.720306
2019-11-05 22:32:12,936 train 200 1.588174e-02 -0.751442
2019-11-05 22:32:23,082 train 250 1.585435e-02 -0.754460
2019-11-05 22:32:33,223 train 300 1.584862e-02 -0.725672
2019-11-05 22:32:43,333 train 350 1.582279e-02 -0.791045
2019-11-05 22:32:53,446 train 400 1.588935e-02 -0.768169
2019-11-05 22:33:03,553 train 450 1.588248e-02 -0.757980
2019-11-05 22:33:13,682 train 500 1.589290e-02 -0.743929
2019-11-05 22:33:23,846 train 550 1.592554e-02 -0.735172
2019-11-05 22:33:34,018 train 600 1.590587e-02 -0.726111
2019-11-05 22:33:44,185 train 650 1.592025e-02 -0.756437
2019-11-05 22:33:54,363 train 700 1.593407e-02 -0.742853
2019-11-05 22:34:04,582 train 750 1.593863e-02 -0.737719
2019-11-05 22:34:14,760 train 800 1.592618e-02 -0.734978
2019-11-05 22:34:24,959 train 850 1.591507e-02 -0.755322
2019-11-05 22:34:28,007 training loss; R2: 1.590943e-02 -0.853539
2019-11-05 22:34:28,543 valid 000 1.431284e-02 -0.722522
2019-11-05 22:34:38,983 valid 050 1.358214e-02 -1.606618
2019-11-05 22:34:48,123 validation loss; R2: 1.352821e-02 -4.186343
2019-11-05 22:34:48,191 epoch 236 lr 1.000000e-04
2019-11-05 22:34:48,886 train 000 1.591110e-02 -2.033322
2019-11-05 22:34:59,180 train 050 1.582520e-02 -0.633539
2019-11-05 22:35:09,405 train 100 1.601549e-02 -0.769849
2019-11-05 22:35:19,579 train 150 1.610784e-02 -21.073516
2019-11-05 22:35:29,718 train 200 1.609385e-02 -15.977091
2019-11-05 22:35:39,863 train 250 1.608793e-02 -12.934994
2019-11-05 22:35:50,029 train 300 1.601726e-02 -10.923821
2019-11-05 22:36:00,191 train 350 1.596301e-02 -9.452890
2019-11-05 22:36:10,361 train 400 1.598930e-02 -8.378155
2019-11-05 22:36:20,525 train 450 1.596954e-02 -7.559545
2019-11-05 22:36:30,694 train 500 1.593774e-02 -6.886900
2019-11-05 22:36:40,830 train 550 1.594518e-02 -6.319310
2019-11-05 22:36:51,005 train 600 1.596535e-02 -5.848901
2019-11-05 22:37:01,150 train 650 1.594565e-02 -5.440497
2019-11-05 22:37:11,322 train 700 1.596164e-02 -5.103465
2019-11-05 22:37:21,471 train 750 1.595256e-02 -4.805695
2019-11-05 22:37:31,629 train 800 1.597204e-02 -4.541513
2019-11-05 22:37:41,678 train 850 1.594506e-02 -4.317737
2019-11-05 22:37:44,699 training loss; R2: 1.593650e-02 -4.256999
2019-11-05 22:37:45,234 valid 000 1.429031e-02 -0.631859
2019-11-05 22:37:55,085 valid 050 1.353421e-02 -0.832627
2019-11-05 22:38:03,732 validation loss; R2: 1.346361e-02 -0.961517
2019-11-05 22:38:03,800 epoch 237 lr 1.000000e-04
2019-11-05 22:38:04,525 train 000 1.429588e-02 -0.385117
2019-11-05 22:38:14,727 train 050 1.569264e-02 -1.028827
2019-11-05 22:38:24,923 train 100 1.590215e-02 -0.851973
2019-11-05 22:38:35,107 train 150 1.602293e-02 -0.914116
2019-11-05 22:38:45,348 train 200 1.602090e-02 -0.936550
2019-11-05 22:38:55,544 train 250 1.602011e-02 -0.940342
2019-11-05 22:39:05,699 train 300 1.606805e-02 -0.912872
2019-11-05 22:39:15,878 train 350 1.604255e-02 -0.888339
2019-11-05 22:39:26,038 train 400 1.605229e-02 -0.857762
2019-11-05 22:39:36,198 train 450 1.601069e-02 -0.824008
2019-11-05 22:39:46,366 train 500 1.598948e-02 -0.819944
2019-11-05 22:39:56,576 train 550 1.598232e-02 -0.831593
2019-11-05 22:40:06,735 train 600 1.597858e-02 -0.815406
2019-11-05 22:40:16,931 train 650 1.598245e-02 -0.817326
2019-11-05 22:40:27,080 train 700 1.595876e-02 -0.827404
2019-11-05 22:40:37,172 train 750 1.593482e-02 -0.822622
2019-11-05 22:40:47,305 train 800 1.592678e-02 -0.818155
2019-11-05 22:40:57,489 train 850 1.590418e-02 -0.822978
2019-11-05 22:41:00,538 training loss; R2: 1.590523e-02 -0.825035
2019-11-05 22:41:01,099 valid 000 1.108269e-02 -1.216090
2019-11-05 22:41:10,902 valid 050 1.369968e-02 -2.008262
2019-11-05 22:41:19,553 validation loss; R2: 1.377955e-02 -1.394750
2019-11-05 22:41:19,620 epoch 238 lr 1.000000e-04
2019-11-05 22:41:20,339 train 000 1.633803e-02 -0.934499
2019-11-05 22:41:30,463 train 050 1.576893e-02 -0.657291
2019-11-05 22:41:40,580 train 100 1.574857e-02 -0.595533
2019-11-05 22:41:50,755 train 150 1.576802e-02 -0.531831
2019-11-05 22:42:00,871 train 200 1.582036e-02 -0.559256
2019-11-05 22:42:10,959 train 250 1.583090e-02 -0.596955
2019-11-05 22:42:21,145 train 300 1.578934e-02 -0.612348
2019-11-05 22:42:31,211 train 350 1.585504e-02 -0.651252
2019-11-05 22:42:41,328 train 400 1.586739e-02 -0.734520
2019-11-05 22:42:51,473 train 450 1.589393e-02 -0.723494
2019-11-05 22:43:01,508 train 500 1.590191e-02 -0.739655
2019-11-05 22:43:11,645 train 550 1.592246e-02 -0.728630
2019-11-05 22:43:21,791 train 600 1.590726e-02 -0.745852
2019-11-05 22:43:31,840 train 650 1.590155e-02 -0.947227
2019-11-05 22:43:41,956 train 700 1.591613e-02 -0.910068
2019-11-05 22:43:52,132 train 750 1.593993e-02 -0.903018
2019-11-05 22:44:02,152 train 800 1.594439e-02 -0.972319
2019-11-05 22:44:12,237 train 850 1.593687e-02 -0.952626
2019-11-05 22:44:15,267 training loss; R2: 1.594509e-02 -0.949476
2019-11-05 22:44:15,774 valid 000 1.758978e-02 -0.884140
2019-11-05 22:44:25,649 valid 050 1.430002e-02 -1.146581
2019-11-05 22:44:34,313 validation loss; R2: 1.433971e-02 -1.246430
2019-11-05 22:44:34,376 epoch 239 lr 1.000000e-04
2019-11-05 22:44:35,101 train 000 1.541968e-02 -0.442067
2019-11-05 22:44:45,276 train 050 1.581450e-02 -0.589543
2019-11-05 22:44:55,464 train 100 1.598883e-02 -3.099686
2019-11-05 22:45:05,640 train 150 1.608144e-02 -2.230914
2019-11-05 22:45:15,817 train 200 1.598979e-02 -1.959782
2019-11-05 22:45:25,994 train 250 1.599222e-02 -1.835071
2019-11-05 22:45:36,157 train 300 1.597213e-02 -1.621666
2019-11-05 22:45:46,317 train 350 1.598577e-02 -1.541588
2019-11-05 22:45:56,442 train 400 1.595386e-02 -1.419234
2019-11-05 22:46:06,580 train 450 1.596715e-02 -1.422855
2019-11-05 22:46:16,730 train 500 1.596811e-02 -1.334055
2019-11-05 22:46:26,870 train 550 1.597998e-02 -1.284545
2019-11-05 22:46:37,003 train 600 1.598624e-02 -1.348960
2019-11-05 22:46:47,162 train 650 1.600071e-02 -1.286765
2019-11-05 22:46:57,308 train 700 1.598067e-02 -1.266869
2019-11-05 22:47:07,460 train 750 1.597200e-02 -1.218596
2019-11-05 22:47:17,599 train 800 1.595622e-02 -1.186341
2019-11-05 22:47:27,752 train 850 1.594820e-02 -1.168185
2019-11-05 22:47:30,786 training loss; R2: 1.595859e-02 -1.164593
2019-11-05 22:47:31,347 valid 000 1.237130e-02 -0.366195
2019-11-05 22:47:41,169 valid 050 1.425823e-02 -24.207729
2019-11-05 22:47:49,780 validation loss; R2: 1.446331e-02 -13.747321
2019-11-05 22:47:49,839 epoch 240 lr 1.000000e-04
2019-11-05 22:47:50,562 train 000 1.772644e-02 -1.181677
2019-11-05 22:48:00,686 train 050 1.617346e-02 -0.935513
2019-11-05 22:48:10,858 train 100 1.604995e-02 -0.910831
2019-11-05 22:48:21,031 train 150 1.604807e-02 -0.818530
2019-11-05 22:48:31,174 train 200 1.610917e-02 -0.777854
2019-11-05 22:48:41,332 train 250 1.603570e-02 -0.742441
2019-11-05 22:48:51,474 train 300 1.599811e-02 -0.767914
2019-11-05 22:49:01,650 train 350 1.596113e-02 -0.754454
2019-11-05 22:49:11,819 train 400 1.596850e-02 -0.764018
2019-11-05 22:49:22,017 train 450 1.600524e-02 -0.769165
2019-11-05 22:49:32,157 train 500 1.600863e-02 -0.780698
2019-11-05 22:49:42,343 train 550 1.597558e-02 -3.541167
2019-11-05 22:49:52,518 train 600 1.599548e-02 -3.325340
2019-11-05 22:50:02,717 train 650 1.599672e-02 -3.193616
2019-11-05 22:50:12,906 train 700 1.598868e-02 -3.024767
2019-11-05 22:50:23,104 train 750 1.596433e-02 -2.862220
2019-11-05 22:50:33,302 train 800 1.593507e-02 -2.737750
2019-11-05 22:50:43,528 train 850 1.593886e-02 -2.649998
2019-11-05 22:50:46,566 training loss; R2: 1.594388e-02 -2.609554
2019-11-05 22:50:47,084 valid 000 1.583194e-02 -0.186212
2019-11-05 22:50:56,945 valid 050 1.410118e-02 -1.903846
2019-11-05 22:51:05,607 validation loss; R2: 1.400796e-02 -2.183896
2019-11-05 22:51:05,672 epoch 241 lr 1.000000e-04
2019-11-05 22:51:06,387 train 000 1.514781e-02 -1.715402
2019-11-05 22:51:16,620 train 050 1.586073e-02 -0.770731
2019-11-05 22:51:26,873 train 100 1.574865e-02 -0.617318
2019-11-05 22:51:37,083 train 150 1.566164e-02 -0.733131
2019-11-05 22:51:47,306 train 200 1.582071e-02 -0.651399
2019-11-05 22:51:57,500 train 250 1.592698e-02 -0.651734
2019-11-05 22:52:07,700 train 300 1.595742e-02 -0.641628
2019-11-05 22:52:17,889 train 350 1.597649e-02 -0.629893
2019-11-05 22:52:28,061 train 400 1.599235e-02 -0.625335
2019-11-05 22:52:38,237 train 450 1.596267e-02 -0.622675
2019-11-05 22:52:48,411 train 500 1.594922e-02 -0.614618
2019-11-05 22:52:58,591 train 550 1.593860e-02 -0.618412
2019-11-05 22:53:08,739 train 600 1.591839e-02 -0.635429
2019-11-05 22:53:18,926 train 650 1.590565e-02 -0.885659
2019-11-05 22:53:29,121 train 700 1.589329e-02 -0.864617
2019-11-05 22:53:39,335 train 750 1.587653e-02 -0.856883
2019-11-05 22:53:49,519 train 800 1.587967e-02 -0.860543
2019-11-05 22:53:59,728 train 850 1.588527e-02 -0.850352
2019-11-05 22:54:02,758 training loss; R2: 1.588202e-02 -0.951019
2019-11-05 22:54:03,297 valid 000 1.563248e-02 -1.254214
2019-11-05 22:54:13,123 valid 050 1.423571e-02 -1.301033
2019-11-05 22:54:21,763 validation loss; R2: 1.424046e-02 -1.340631
2019-11-05 22:54:21,827 epoch 242 lr 1.000000e-04
2019-11-05 22:54:22,556 train 000 1.596491e-02 -1.008570
2019-11-05 22:54:32,912 train 050 1.601882e-02 -0.609390
2019-11-05 22:54:43,240 train 100 1.591345e-02 -1.537272
2019-11-05 22:54:53,538 train 150 1.576760e-02 -1.234296
2019-11-05 22:55:03,822 train 200 1.587294e-02 -1.116782
2019-11-05 22:55:14,094 train 250 1.578789e-02 -0.997094
2019-11-05 22:55:24,395 train 300 1.580161e-02 -0.954210
2019-11-05 22:55:34,761 train 350 1.580696e-02 -0.928274
2019-11-05 22:55:45,092 train 400 1.584551e-02 -0.888896
2019-11-05 22:55:55,448 train 450 1.585233e-02 -0.896439
2019-11-05 22:56:05,568 train 500 1.589490e-02 -0.881153
2019-11-05 22:56:15,733 train 550 1.591784e-02 -0.854101
2019-11-05 22:56:25,912 train 600 1.592207e-02 -0.875511
2019-11-05 22:56:36,102 train 650 1.592779e-02 -0.862758
2019-11-05 22:56:46,288 train 700 1.591222e-02 -0.906175
2019-11-05 22:56:56,451 train 750 1.590933e-02 -0.885553
2019-11-05 22:57:06,633 train 800 1.589341e-02 -0.865790
2019-11-05 22:57:16,836 train 850 1.588551e-02 -0.865297
2019-11-05 22:57:19,883 training loss; R2: 1.589267e-02 -0.858209
2019-11-05 22:57:20,449 valid 000 1.311536e-02 -0.123810
2019-11-05 22:57:30,295 valid 050 1.340386e-02 -1.102609
2019-11-05 22:57:38,947 validation loss; R2: 1.346109e-02 -1.237288
2019-11-05 22:57:39,010 epoch 243 lr 1.000000e-04
2019-11-05 22:57:39,751 train 000 1.559305e-02 -0.413006
2019-11-05 22:57:49,897 train 050 1.628078e-02 -0.606966
2019-11-05 22:58:00,035 train 100 1.600574e-02 -0.502196
2019-11-05 22:58:10,238 train 150 1.587258e-02 -0.548517
2019-11-05 22:58:20,430 train 200 1.597670e-02 -0.654851
2019-11-05 22:58:30,616 train 250 1.597495e-02 -0.725004
2019-11-05 22:58:40,805 train 300 1.594991e-02 -0.781694
2019-11-05 22:58:50,995 train 350 1.590862e-02 -0.799826
2019-11-05 22:59:01,159 train 400 1.591103e-02 -0.748656
2019-11-05 22:59:11,328 train 450 1.594993e-02 -0.716996
2019-11-05 22:59:21,485 train 500 1.591335e-02 -0.705459
2019-11-05 22:59:31,632 train 550 1.590716e-02 -0.709376
2019-11-05 22:59:41,811 train 600 1.589492e-02 -0.711436
2019-11-05 22:59:51,985 train 650 1.589331e-02 -0.719049
2019-11-05 23:00:02,185 train 700 1.591663e-02 -0.733908
2019-11-05 23:00:12,363 train 750 1.591503e-02 -0.737968
2019-11-05 23:00:22,516 train 800 1.593613e-02 -0.745732
2019-11-05 23:00:32,685 train 850 1.590210e-02 -0.742799
2019-11-05 23:00:35,715 training loss; R2: 1.588684e-02 -0.748051
2019-11-05 23:00:36,251 valid 000 1.802817e-02 -0.763719
2019-11-05 23:00:46,044 valid 050 1.721582e-02 -1.061178
2019-11-05 23:00:54,687 validation loss; R2: 1.744006e-02 -1.067605
2019-11-05 23:00:54,751 epoch 244 lr 1.000000e-04
2019-11-05 23:00:55,474 train 000 1.543767e-02 -1.145984
2019-11-05 23:01:05,667 train 050 1.599015e-02 -2.411082
2019-11-05 23:01:15,852 train 100 1.607266e-02 -1.592828
2019-11-05 23:01:26,012 train 150 1.598177e-02 -1.506256
2019-11-05 23:01:36,184 train 200 1.597765e-02 -1.257584
2019-11-05 23:01:46,339 train 250 1.592904e-02 -1.256040
2019-11-05 23:01:56,523 train 300 1.591183e-02 -1.488886
2019-11-05 23:02:06,676 train 350 1.598306e-02 -1.388762
2019-11-05 23:02:16,847 train 400 1.590329e-02 -1.281460
2019-11-05 23:02:26,981 train 450 1.586867e-02 -1.193981
2019-11-05 23:02:37,147 train 500 1.586530e-02 -1.152203
2019-11-05 23:02:47,301 train 550 1.585166e-02 -1.090930
2019-11-05 23:02:57,480 train 600 1.585070e-02 -1.028772
2019-11-05 23:03:07,806 train 650 1.584323e-02 -1.025561
2019-11-05 23:03:18,089 train 700 1.582032e-02 -1.023958
2019-11-05 23:03:28,214 train 750 1.583818e-02 -1.026655
2019-11-05 23:03:38,360 train 800 1.585320e-02 -1.009376
2019-11-05 23:03:48,496 train 850 1.586239e-02 -1.030448
2019-11-05 23:03:51,532 training loss; R2: 1.586691e-02 -1.025473
2019-11-05 23:03:52,124 valid 000 1.577465e-02 0.197972
2019-11-05 23:04:01,943 valid 050 1.402454e-02 -0.903890
2019-11-05 23:04:10,594 validation loss; R2: 1.400514e-02 -0.868988
2019-11-05 23:04:10,668 epoch 245 lr 1.000000e-04
2019-11-05 23:04:11,412 train 000 1.468780e-02 -7.321643
2019-11-05 23:04:21,620 train 050 1.597598e-02 -0.706699
2019-11-05 23:04:31,790 train 100 1.601501e-02 -0.564818
2019-11-05 23:04:41,977 train 150 1.592334e-02 -0.606721
2019-11-05 23:04:52,105 train 200 1.598415e-02 -0.656715
2019-11-05 23:05:02,248 train 250 1.587079e-02 -0.658652
2019-11-05 23:05:12,385 train 300 1.588610e-02 -0.679601
2019-11-05 23:05:22,539 train 350 1.590812e-02 -0.662435
2019-11-05 23:05:32,686 train 400 1.592874e-02 -0.697645
2019-11-05 23:05:42,846 train 450 1.595403e-02 -0.717449
2019-11-05 23:05:52,990 train 500 1.598295e-02 -0.715905
2019-11-05 23:06:03,159 train 550 1.598924e-02 -0.739926
2019-11-05 23:06:13,317 train 600 1.596606e-02 -0.729559
2019-11-05 23:06:23,443 train 650 1.596496e-02 -0.746252
2019-11-05 23:06:33,578 train 700 1.595893e-02 -0.807928
2019-11-05 23:06:43,696 train 750 1.592876e-02 -0.809229
2019-11-05 23:06:53,837 train 800 1.596142e-02 -0.812852
2019-11-05 23:07:03,974 train 850 1.597910e-02 -0.802669
2019-11-05 23:07:07,001 training loss; R2: 1.597796e-02 -0.805238
2019-11-05 23:07:07,556 valid 000 1.661853e-02 -0.742768
2019-11-05 23:07:17,384 valid 050 1.472054e-02 -0.946456
2019-11-05 23:07:26,064 validation loss; R2: 1.482222e-02 -1.067925
2019-11-05 23:07:26,128 epoch 246 lr 1.000000e-04
2019-11-05 23:07:26,854 train 000 1.467048e-02 -0.516363
2019-11-05 23:07:37,207 train 050 1.582729e-02 -0.632721
2019-11-05 23:07:47,540 train 100 1.601091e-02 -0.738572
2019-11-05 23:07:57,841 train 150 1.597945e-02 -0.721234
2019-11-05 23:08:08,158 train 200 1.605633e-02 -0.752097
2019-11-05 23:08:18,528 train 250 1.602619e-02 -0.721759
2019-11-05 23:08:28,852 train 300 1.598920e-02 -0.735518
2019-11-05 23:08:39,189 train 350 1.592299e-02 -0.740653
2019-11-05 23:08:49,505 train 400 1.591483e-02 -0.763290
2019-11-05 23:08:59,852 train 450 1.592098e-02 -0.737338
2019-11-05 23:09:10,201 train 500 1.591795e-02 -0.724698
2019-11-05 23:09:20,376 train 550 1.592575e-02 -0.733565
2019-11-05 23:09:30,533 train 600 1.593065e-02 -0.741770
2019-11-05 23:09:40,701 train 650 1.589654e-02 -0.727745
2019-11-05 23:09:50,860 train 700 1.587196e-02 -0.710271
2019-11-05 23:10:01,003 train 750 1.589710e-02 -0.717604
2019-11-05 23:10:11,161 train 800 1.588123e-02 -0.729606
2019-11-05 23:10:21,340 train 850 1.586235e-02 -0.727136
2019-11-05 23:10:24,384 training loss; R2: 1.586338e-02 -0.725901
2019-11-05 23:10:24,956 valid 000 2.118325e-02 -0.932218
2019-11-05 23:10:34,726 valid 050 2.741632e-02 -1.096969
2019-11-05 23:10:43,379 validation loss; R2: 2.723790e-02 -1.093120
2019-11-05 23:10:43,450 epoch 247 lr 1.000000e-04
2019-11-05 23:10:44,181 train 000 1.579228e-02 -1.644612
2019-11-05 23:10:54,406 train 050 1.618286e-02 -0.663139
2019-11-05 23:11:04,589 train 100 1.618357e-02 -2.782394
2019-11-05 23:11:14,776 train 150 1.601488e-02 -2.141598
2019-11-05 23:11:24,924 train 200 1.604095e-02 -1.845552
2019-11-05 23:11:35,077 train 250 1.595694e-02 -1.646720
2019-11-05 23:11:45,225 train 300 1.591668e-02 -1.510086
2019-11-05 23:11:55,383 train 350 1.592154e-02 -1.413482
2019-11-05 23:12:05,531 train 400 1.589090e-02 -1.348603
2019-11-05 23:12:15,703 train 450 1.588813e-02 -1.278563
2019-11-05 23:12:25,894 train 500 1.591538e-02 -1.227621
2019-11-05 23:12:36,056 train 550 1.591819e-02 -1.177516
2019-11-05 23:12:46,234 train 600 1.586715e-02 -1.113428
2019-11-05 23:12:56,388 train 650 1.583936e-02 -1.093253
2019-11-05 23:13:06,530 train 700 1.582873e-02 -1.073298
2019-11-05 23:13:16,658 train 750 1.583141e-02 -1.037289
2019-11-05 23:13:26,814 train 800 1.583883e-02 -1.037563
2019-11-05 23:13:36,956 train 850 1.583693e-02 -1.009295
2019-11-05 23:13:39,985 training loss; R2: 1.583065e-02 -0.998450
2019-11-05 23:13:40,508 valid 000 1.167052e-02 -1.120930
2019-11-05 23:13:50,354 valid 050 1.419808e-02 -1.141424
2019-11-05 23:13:58,988 validation loss; R2: 1.423752e-02 -1.127402
2019-11-05 23:13:59,067 epoch 248 lr 1.000000e-04
2019-11-05 23:13:59,768 train 000 1.329990e-02 -0.769992
2019-11-05 23:14:09,982 train 050 1.576921e-02 -0.760810
2019-11-05 23:14:20,176 train 100 1.572467e-02 -0.667500
2019-11-05 23:14:30,345 train 150 1.581751e-02 -0.687760
2019-11-05 23:14:40,508 train 200 1.588593e-02 -0.737551
2019-11-05 23:14:50,663 train 250 1.584348e-02 -1.600431
2019-11-05 23:15:00,803 train 300 1.576735e-02 -1.475047
2019-11-05 23:15:10,976 train 350 1.580946e-02 -1.349569
2019-11-05 23:15:21,173 train 400 1.581406e-02 -1.249681
2019-11-05 23:15:31,379 train 450 1.577534e-02 -1.185293
2019-11-05 23:15:41,540 train 500 1.580190e-02 -1.125204
2019-11-05 23:15:51,704 train 550 1.582046e-02 -1.097515
2019-11-05 23:16:01,844 train 600 1.581261e-02 -1.052789
2019-11-05 23:16:12,017 train 650 1.579739e-02 -1.017984
2019-11-05 23:16:22,154 train 700 1.582371e-02 -0.989012
2019-11-05 23:16:32,286 train 750 1.584698e-02 -0.973187
2019-11-05 23:16:42,410 train 800 1.584413e-02 -0.955355
2019-11-05 23:16:52,572 train 850 1.587003e-02 -0.968208
2019-11-05 23:16:55,597 training loss; R2: 1.587333e-02 -0.958871
2019-11-05 23:16:56,111 valid 000 1.240401e-02 -0.902012
2019-11-05 23:17:05,948 valid 050 1.356731e-02 -1.032463
2019-11-05 23:17:14,719 validation loss; R2: 1.357693e-02 -0.924033
2019-11-05 23:17:14,790 epoch 249 lr 1.000000e-04
2019-11-05 23:17:15,552 train 000 1.523322e-02 -0.976645
2019-11-05 23:17:25,780 train 050 1.561944e-02 -0.873519
2019-11-05 23:17:35,958 train 100 1.587969e-02 -0.785220
2019-11-05 23:17:46,129 train 150 1.584199e-02 -0.736885
2019-11-05 23:17:56,292 train 200 1.578247e-02 -0.664589
2019-11-05 23:18:06,457 train 250 1.580757e-02 -0.629232
2019-11-05 23:18:16,631 train 300 1.583587e-02 -0.638434
2019-11-05 23:18:26,799 train 350 1.584307e-02 -0.662801
2019-11-05 23:18:36,976 train 400 1.581834e-02 -0.670811
2019-11-05 23:18:47,119 train 450 1.583409e-02 -0.699227
2019-11-05 23:18:57,269 train 500 1.589613e-02 -0.685103
2019-11-05 23:19:07,422 train 550 1.590645e-02 -0.687702
2019-11-05 23:19:17,571 train 600 1.587946e-02 -0.672231
2019-11-05 23:19:27,711 train 650 1.586323e-02 -0.676653
2019-11-05 23:19:37,857 train 700 1.584572e-02 -0.659793
2019-11-05 23:19:48,004 train 750 1.588010e-02 -0.674461
2019-11-05 23:19:58,172 train 800 1.587412e-02 -0.672159
2019-11-05 23:20:08,334 train 850 1.587435e-02 -0.676636
2019-11-05 23:20:11,372 training loss; R2: 1.586113e-02 -0.673605
2019-11-05 23:20:11,907 valid 000 1.417666e-02 -0.000953
2019-11-05 23:20:21,772 valid 050 1.436028e-02 -1.355593
2019-11-05 23:20:30,472 validation loss; R2: 1.428246e-02 -1.435742
2019-11-05 23:20:30,557 epoch 250 lr 1.000000e-04
2019-11-05 23:20:31,316 train 000 1.685068e-02 -0.193274
2019-11-05 23:20:41,570 train 050 1.581287e-02 -6.522229
2019-11-05 23:20:51,762 train 100 1.589980e-02 -3.723620
2019-11-05 23:21:01,968 train 150 1.576994e-02 -2.699008
2019-11-05 23:21:12,041 train 200 1.576779e-02 -2.147558
2019-11-05 23:21:22,118 train 250 1.566579e-02 -1.886735
2019-11-05 23:21:32,194 train 300 1.569880e-02 -1.734551
2019-11-05 23:21:42,301 train 350 1.574060e-02 -1.572445
2019-11-05 23:21:52,390 train 400 1.575743e-02 -1.449753
2019-11-05 23:22:02,495 train 450 1.577599e-02 -1.348275
2019-11-05 23:22:12,567 train 500 1.579591e-02 -1.284775
2019-11-05 23:22:22,729 train 550 1.579187e-02 -1.234748
2019-11-05 23:22:32,900 train 600 1.580641e-02 -1.193837
2019-11-05 23:22:43,089 train 650 1.582976e-02 -1.140112
2019-11-05 23:22:53,237 train 700 1.583767e-02 -1.115691
2019-11-05 23:23:03,413 train 750 1.586054e-02 -1.186810
2019-11-05 23:23:13,571 train 800 1.586535e-02 -1.151331
2019-11-05 23:23:23,763 train 850 1.587343e-02 -20.371033
2019-11-05 23:23:26,804 training loss; R2: 1.587956e-02 -20.027371
2019-11-05 23:23:27,316 valid 000 2.119616e-02 -0.530924
2019-11-05 23:23:37,095 valid 050 2.094298e-02 -1.643726
2019-11-05 23:23:45,766 validation loss; R2: 2.037946e-02 -1.972688
2019-11-05 23:23:45,837 epoch 251 lr 1.000000e-04
2019-11-05 23:23:46,503 train 000 1.501414e-02 0.107691
2019-11-05 23:23:56,726 train 050 1.562637e-02 -0.791161
2019-11-05 23:24:06,917 train 100 1.568261e-02 -0.825707
2019-11-05 23:24:17,061 train 150 1.581184e-02 -0.858298
2019-11-05 23:24:27,186 train 200 1.573764e-02 -0.823976
2019-11-05 23:24:37,315 train 250 1.575229e-02 -0.783878
2019-11-05 23:24:47,525 train 300 1.569965e-02 -0.755537
2019-11-05 23:24:57,696 train 350 1.580950e-02 -0.713792
2019-11-05 23:25:07,851 train 400 1.579523e-02 -0.841880
2019-11-05 23:25:18,011 train 450 1.575849e-02 -0.859485
2019-11-05 23:25:28,173 train 500 1.579714e-02 -0.841093
2019-11-05 23:25:38,308 train 550 1.581636e-02 -0.831012
2019-11-05 23:25:48,436 train 600 1.579644e-02 -0.828009
2019-11-05 23:25:58,581 train 650 1.578880e-02 -0.825551
2019-11-05 23:26:08,704 train 700 1.578421e-02 -0.883990
2019-11-05 23:26:18,854 train 750 1.579716e-02 -0.867626
2019-11-05 23:26:29,017 train 800 1.581161e-02 -0.850193
2019-11-05 23:26:39,172 train 850 1.584138e-02 -0.837151
2019-11-05 23:26:42,187 training loss; R2: 1.583755e-02 -0.829320
2019-11-05 23:26:42,689 valid 000 1.361807e-02 -1.685960
2019-11-05 23:26:52,487 valid 050 1.447607e-02 -1.931048
2019-11-05 23:27:01,133 validation loss; R2: 1.443811e-02 -1.547209
2019-11-05 23:27:01,200 epoch 252 lr 1.000000e-04
2019-11-05 23:27:01,948 train 000 1.529619e-02 -0.448158
2019-11-05 23:27:12,156 train 050 1.553866e-02 -12.739873
2019-11-05 23:27:22,361 train 100 1.573646e-02 -6.763640
2019-11-05 23:27:32,525 train 150 1.578297e-02 -4.906411
2019-11-05 23:27:42,688 train 200 1.575214e-02 -3.922362
2019-11-05 23:27:52,853 train 250 1.575858e-02 -3.370636
2019-11-05 23:28:02,999 train 300 1.573866e-02 -2.944676
2019-11-05 23:28:13,136 train 350 1.580676e-02 -2.680543
2019-11-05 23:28:23,297 train 400 1.589412e-02 -2.461356
2019-11-05 23:28:33,456 train 450 1.590780e-02 -2.279628
2019-11-05 23:28:43,597 train 500 1.591324e-02 -2.107671
2019-11-05 23:28:53,732 train 550 1.587659e-02 -1.965781
2019-11-05 23:29:03,854 train 600 1.588121e-02 -1.849708
2019-11-05 23:29:13,973 train 650 1.589917e-02 -1.767799
2019-11-05 23:29:24,093 train 700 1.587368e-02 -1.673892
2019-11-05 23:29:34,216 train 750 1.585859e-02 -1.594875
2019-11-05 23:29:44,361 train 800 1.587163e-02 -1.559613
2019-11-05 23:29:54,488 train 850 1.586806e-02 -1.508257
2019-11-05 23:29:57,508 training loss; R2: 1.587000e-02 -1.504158
2019-11-05 23:29:58,057 valid 000 1.294014e-02 -0.168411
2019-11-05 23:30:07,911 valid 050 1.423597e-02 -1.287873
2019-11-05 23:30:16,564 validation loss; R2: 1.431559e-02 -1.267365
2019-11-05 23:30:16,641 epoch 253 lr 1.000000e-04
2019-11-05 23:30:17,387 train 000 1.834257e-02 -1.292173
2019-11-05 23:30:27,559 train 050 1.610500e-02 -0.630155
2019-11-05 23:30:37,750 train 100 1.577958e-02 -0.818930
2019-11-05 23:30:47,928 train 150 1.584904e-02 -0.784249
2019-11-05 23:30:58,131 train 200 1.582425e-02 -0.734578
2019-11-05 23:31:08,336 train 250 1.578980e-02 -0.707962
2019-11-05 23:31:18,493 train 300 1.583097e-02 -1.025292
2019-11-05 23:31:28,664 train 350 1.586198e-02 -0.971639
2019-11-05 23:31:38,794 train 400 1.583338e-02 -0.917855
2019-11-05 23:31:48,948 train 450 1.583309e-02 -0.885189
2019-11-05 23:31:59,106 train 500 1.583063e-02 -0.913615
2019-11-05 23:32:09,279 train 550 1.583188e-02 -0.911322
2019-11-05 23:32:19,414 train 600 1.582792e-02 -0.876891
2019-11-05 23:32:29,581 train 650 1.584608e-02 -0.853509
2019-11-05 23:32:39,733 train 700 1.584903e-02 -0.926371
2019-11-05 23:32:49,790 train 750 1.586030e-02 -0.904585
2019-11-05 23:32:59,829 train 800 1.585138e-02 -0.905451
2019-11-05 23:33:09,880 train 850 1.586048e-02 -0.906911
2019-11-05 23:33:12,890 training loss; R2: 1.586535e-02 -0.898192
2019-11-05 23:33:13,408 valid 000 1.356069e-02 -0.338964
2019-11-05 23:33:23,170 valid 050 1.384145e-02 -1.283386
2019-11-05 23:33:31,846 validation loss; R2: 1.361092e-02 -1.160587
2019-11-05 23:33:31,914 epoch 254 lr 1.000000e-04
2019-11-05 23:33:32,595 train 000 1.414518e-02 -0.270975
2019-11-05 23:33:42,846 train 050 1.573753e-02 -0.831412
2019-11-05 23:33:53,032 train 100 1.569905e-02 -0.935190
2019-11-05 23:34:03,219 train 150 1.578303e-02 -0.832446
2019-11-05 23:34:13,405 train 200 1.575855e-02 -0.839437
2019-11-05 23:34:23,566 train 250 1.579093e-02 -0.795718
2019-11-05 23:34:33,735 train 300 1.580521e-02 -0.750937
2019-11-05 23:34:43,883 train 350 1.577536e-02 -0.701749
2019-11-05 23:34:53,976 train 400 1.581932e-02 -0.699685
2019-11-05 23:35:04,072 train 450 1.582064e-02 -0.687855
2019-11-05 23:35:14,195 train 500 1.583786e-02 -0.692942
2019-11-05 23:35:24,382 train 550 1.585255e-02 -0.688060
2019-11-05 23:35:34,546 train 600 1.587449e-02 -0.712142
2019-11-05 23:35:44,711 train 650 1.584003e-02 -0.719907
2019-11-05 23:35:54,849 train 700 1.588498e-02 -0.704252
2019-11-05 23:36:05,012 train 750 1.587854e-02 -0.693186
2019-11-05 23:36:15,155 train 800 1.588241e-02 -1.180493
2019-11-05 23:36:25,321 train 850 1.586915e-02 -1.163165
2019-11-05 23:36:28,353 training loss; R2: 1.585958e-02 -1.158333
2019-11-05 23:36:28,868 valid 000 1.617418e-02 -0.363526
2019-11-05 23:36:38,756 valid 050 1.434414e-02 -1.767041
2019-11-05 23:36:47,451 validation loss; R2: 1.439364e-02 -1.406883
2019-11-05 23:36:47,514 epoch 255 lr 1.000000e-04
2019-11-05 23:36:48,275 train 000 1.700185e-02 -0.338930
2019-11-05 23:36:58,615 train 050 1.546952e-02 -1.117132
2019-11-05 23:37:08,895 train 100 1.560622e-02 -0.864875
2019-11-05 23:37:19,220 train 150 1.571613e-02 -0.811391
2019-11-05 23:37:29,574 train 200 1.578469e-02 -0.836260
2019-11-05 23:37:39,881 train 250 1.578483e-02 -0.815943
2019-11-05 23:37:50,249 train 300 1.573328e-02 -0.836541
2019-11-05 23:38:00,327 train 350 1.585263e-02 -0.826846
2019-11-05 23:38:10,421 train 400 1.588473e-02 -0.779545
2019-11-05 23:38:20,510 train 450 1.585217e-02 -0.745864
2019-11-05 23:38:30,617 train 500 1.582794e-02 -0.731615
2019-11-05 23:38:40,747 train 550 1.582861e-02 -0.720805
2019-11-05 23:38:50,798 train 600 1.581862e-02 -0.737574
2019-11-05 23:39:00,857 train 650 1.579013e-02 -0.731211
2019-11-05 23:39:11,034 train 700 1.582960e-02 -0.742869
2019-11-05 23:39:21,116 train 750 1.580671e-02 -0.750847
2019-11-05 23:39:31,162 train 800 1.580597e-02 -0.759245
2019-11-05 23:39:41,341 train 850 1.582441e-02 -0.755259
2019-11-05 23:39:44,364 training loss; R2: 1.582758e-02 -0.752649
2019-11-05 23:39:44,975 valid 000 2.535119e-02 -1.262271
2019-11-05 23:39:54,844 valid 050 2.159699e-02 -2.300475
2019-11-05 23:40:03,466 validation loss; R2: 2.148475e-02 -4.902790
2019-11-05 23:40:03,532 epoch 256 lr 1.000000e-04
2019-11-05 23:40:04,272 train 000 1.478984e-02 0.032409
2019-11-05 23:40:14,410 train 050 1.658872e-02 -0.863018
2019-11-05 23:40:24,512 train 100 1.619624e-02 -0.819330
2019-11-05 23:40:34,615 train 150 1.613842e-02 -0.821919
2019-11-05 23:40:44,756 train 200 1.608467e-02 -16.433925
2019-11-05 23:40:54,887 train 250 1.600867e-02 -13.289014
2019-11-05 23:41:04,955 train 300 1.599532e-02 -11.179056
2019-11-05 23:41:15,034 train 350 1.594026e-02 -9.748209
2019-11-05 23:41:25,185 train 400 1.599110e-02 -8.622911
2019-11-05 23:41:35,328 train 450 1.594627e-02 -7.771148
2019-11-05 23:41:45,404 train 500 1.592837e-02 -7.071249
2019-11-05 23:41:55,537 train 550 1.589870e-02 -6.480201
2019-11-05 23:42:05,693 train 600 1.585487e-02 -5.983156
2019-11-05 23:42:15,852 train 650 1.585834e-02 -5.571311
2019-11-05 23:42:26,012 train 700 1.584692e-02 -5.210428
2019-11-05 23:42:36,171 train 750 1.585666e-02 -4.921955
2019-11-05 23:42:46,305 train 800 1.587214e-02 -4.651430
2019-11-05 23:42:56,438 train 850 1.585814e-02 -4.418440
2019-11-05 23:42:59,470 training loss; R2: 1.586497e-02 -4.352821
2019-11-05 23:43:00,016 valid 000 1.543291e-02 0.144101
2019-11-05 23:43:09,797 valid 050 1.403944e-02 -0.575674
2019-11-05 23:43:18,456 validation loss; R2: 1.397434e-02 -0.668713
2019-11-05 23:43:18,523 epoch 257 lr 1.000000e-04
2019-11-05 23:43:19,235 train 000 1.577190e-02 0.074485
2019-11-05 23:43:29,423 train 050 1.586874e-02 -0.798649
2019-11-05 23:43:39,600 train 100 1.559699e-02 -0.673475
2019-11-05 23:43:49,785 train 150 1.562770e-02 -0.660607
2019-11-05 23:43:59,936 train 200 1.558623e-02 -0.647987
2019-11-05 23:44:10,073 train 250 1.564252e-02 -0.687341
2019-11-05 23:44:20,211 train 300 1.565253e-02 -0.701592
2019-11-05 23:44:30,366 train 350 1.576573e-02 -0.724061
2019-11-05 23:44:40,518 train 400 1.575415e-02 -0.770331
2019-11-05 23:44:50,705 train 450 1.574986e-02 -0.757452
2019-11-05 23:45:00,847 train 500 1.577788e-02 -0.759866
2019-11-05 23:45:11,000 train 550 1.576508e-02 -0.752491
2019-11-05 23:45:21,133 train 600 1.579974e-02 -0.749370
2019-11-05 23:45:31,278 train 650 1.580481e-02 -0.739362
2019-11-05 23:45:41,406 train 700 1.579609e-02 -0.725877
2019-11-05 23:45:51,559 train 750 1.583000e-02 -0.710003
2019-11-05 23:46:01,724 train 800 1.583165e-02 -0.704691
2019-11-05 23:46:11,930 train 850 1.583842e-02 -0.706215
2019-11-05 23:46:14,969 training loss; R2: 1.582425e-02 -0.721996
2019-11-05 23:46:15,539 valid 000 1.087265e-02 -1.450688
2019-11-05 23:46:25,388 valid 050 1.288165e-02 -1.162866
2019-11-05 23:46:34,067 validation loss; R2: 1.296318e-02 -1.134198
2019-11-05 23:46:34,145 epoch 258 lr 1.000000e-04
2019-11-05 23:46:34,822 train 000 1.344589e-02 -0.582175
2019-11-05 23:46:45,237 train 050 1.540804e-02 -0.462546
2019-11-05 23:46:55,606 train 100 1.562635e-02 -0.706485
2019-11-05 23:47:05,982 train 150 1.576171e-02 -0.714751
2019-11-05 23:47:16,316 train 200 1.581613e-02 -0.732786
2019-11-05 23:47:26,642 train 250 1.587452e-02 -0.826891
2019-11-05 23:47:36,984 train 300 1.582296e-02 -0.791723
2019-11-05 23:47:47,385 train 350 1.582504e-02 -0.752808
2019-11-05 23:47:57,767 train 400 1.585388e-02 -0.746332
2019-11-05 23:48:08,205 train 450 1.590081e-02 -0.708441
2019-11-05 23:48:18,562 train 500 1.585781e-02 -0.684674
2019-11-05 23:48:28,930 train 550 1.588368e-02 -0.685701
2019-11-05 23:48:39,242 train 600 1.589706e-02 -0.695501
2019-11-05 23:48:49,565 train 650 1.583655e-02 -0.728321
2019-11-05 23:48:59,860 train 700 1.583877e-02 -0.741613
2019-11-05 23:49:10,194 train 750 1.584582e-02 -0.765630
2019-11-05 23:49:20,588 train 800 1.584907e-02 -0.754393
2019-11-05 23:49:30,948 train 850 1.585372e-02 -0.739241
2019-11-05 23:49:34,046 training loss; R2: 1.585621e-02 -0.749815
2019-11-05 23:49:34,574 valid 000 1.457438e-02 -0.398443
2019-11-05 23:49:44,463 valid 050 1.398399e-02 -1.225899
2019-11-05 23:49:53,241 validation loss; R2: 1.393297e-02 -2.326610
2019-11-05 23:49:53,305 epoch 259 lr 1.000000e-04
2019-11-05 23:49:53,967 train 000 1.772452e-02 -0.094091
2019-11-05 23:50:04,290 train 050 1.589980e-02 -0.622852
2019-11-05 23:50:14,550 train 100 1.591087e-02 -0.556948
2019-11-05 23:50:24,741 train 150 1.599264e-02 -0.833265
2019-11-05 23:50:34,959 train 200 1.588866e-02 -0.752995
2019-11-05 23:50:45,197 train 250 1.583285e-02 -0.790871
2019-11-05 23:50:55,421 train 300 1.586793e-02 -0.813473
2019-11-05 23:51:05,653 train 350 1.581579e-02 -0.941493
2019-11-05 23:51:15,869 train 400 1.582300e-02 -0.909417
2019-11-05 23:51:26,096 train 450 1.583227e-02 -0.905518
2019-11-05 23:51:36,306 train 500 1.581804e-02 -0.899544
2019-11-05 23:51:46,534 train 550 1.583699e-02 -0.885440
2019-11-05 23:51:56,733 train 600 1.585627e-02 -0.903868
2019-11-05 23:52:06,949 train 650 1.589591e-02 -0.895030
2019-11-05 23:52:17,110 train 700 1.588814e-02 -0.872240
2019-11-05 23:52:27,331 train 750 1.589819e-02 -0.846948
2019-11-05 23:52:37,423 train 800 1.589134e-02 -0.840012
2019-11-05 23:52:47,561 train 850 1.588481e-02 -0.867706
2019-11-05 23:52:50,574 training loss; R2: 1.587588e-02 -0.862212
2019-11-05 23:52:51,137 valid 000 1.318063e-02 -0.538933
2019-11-05 23:53:00,893 valid 050 1.398309e-02 -1.982122
2019-11-05 23:53:09,552 validation loss; R2: 1.415464e-02 -1.678057
2019-11-05 23:53:09,614 epoch 260 lr 1.000000e-04
2019-11-05 23:53:10,345 train 000 1.413668e-02 -0.337941
2019-11-05 23:53:20,483 train 050 1.582618e-02 -0.713604
2019-11-05 23:53:30,599 train 100 1.585899e-02 -0.711746
2019-11-05 23:53:40,698 train 150 1.591379e-02 -0.668240
2019-11-05 23:53:50,818 train 200 1.585100e-02 -0.662325
2019-11-05 23:54:00,920 train 250 1.584495e-02 -0.667122
2019-11-05 23:54:11,033 train 300 1.579807e-02 -0.674272
2019-11-05 23:54:21,125 train 350 1.582857e-02 -0.655997
2019-11-05 23:54:31,251 train 400 1.586576e-02 -0.655730
2019-11-05 23:54:41,339 train 450 1.584990e-02 -0.661451
2019-11-05 23:54:51,458 train 500 1.581904e-02 -0.647584
2019-11-05 23:55:01,536 train 550 1.582060e-02 -0.661668
2019-11-05 23:55:11,655 train 600 1.581472e-02 -0.664999
2019-11-05 23:55:21,729 train 650 1.581807e-02 -0.661633
2019-11-05 23:55:31,841 train 700 1.581541e-02 -0.681560
2019-11-05 23:55:41,952 train 750 1.581461e-02 -0.689188
2019-11-05 23:55:52,159 train 800 1.580161e-02 -0.705026
2019-11-05 23:56:02,344 train 850 1.579946e-02 -0.704937
2019-11-05 23:56:05,397 training loss; R2: 1.579290e-02 -0.746921
2019-11-05 23:56:05,975 valid 000 1.456084e-02 -0.762105
2019-11-05 23:56:15,755 valid 050 1.368460e-02 -1.203226
2019-11-05 23:56:24,407 validation loss; R2: 1.364229e-02 -1.339209
2019-11-05 23:56:24,478 epoch 261 lr 1.000000e-04
2019-11-05 23:56:25,218 train 000 1.730662e-02 -0.091242
2019-11-05 23:56:35,332 train 050 1.585269e-02 -0.965170
2019-11-05 23:56:45,446 train 100 1.597169e-02 -1.008620
2019-11-05 23:56:55,605 train 150 1.595538e-02 -0.887046
2019-11-05 23:57:05,708 train 200 1.605957e-02 -0.838894
2019-11-05 23:57:15,741 train 250 1.608194e-02 -1.026348
2019-11-05 23:57:25,840 train 300 1.604659e-02 -0.979470
2019-11-05 23:57:35,982 train 350 1.599775e-02 -0.933835
2019-11-05 23:57:46,054 train 400 1.597316e-02 -0.997922
2019-11-05 23:57:56,138 train 450 1.598106e-02 -0.959905
2019-11-05 23:58:06,287 train 500 1.597145e-02 -0.915342
2019-11-05 23:58:16,421 train 550 1.591150e-02 -0.909483
2019-11-05 23:58:26,529 train 600 1.594294e-02 -1.167555
2019-11-05 23:58:36,695 train 650 1.591365e-02 -1.135889
2019-11-05 23:58:46,841 train 700 1.588364e-02 -1.103475
2019-11-05 23:58:56,976 train 750 1.590598e-02 -1.090604
2019-11-05 23:59:07,108 train 800 1.593818e-02 -1.058977
2019-11-05 23:59:17,247 train 850 1.591276e-02 -1.057244
2019-11-05 23:59:20,271 training loss; R2: 1.591600e-02 -1.051209
2019-11-05 23:59:20,830 valid 000 1.440577e-02 -0.099968
2019-11-05 23:59:30,677 valid 050 1.369673e-02 -1.201387
2019-11-05 23:59:39,334 validation loss; R2: 1.373073e-02 -1.110798
2019-11-05 23:59:39,398 epoch 262 lr 1.000000e-04
2019-11-05 23:59:40,129 train 000 1.571328e-02 -1.570228
2019-11-05 23:59:50,349 train 050 1.621564e-02 -0.609130
2019-11-06 00:00:00,561 train 100 1.600282e-02 -0.677121
2019-11-06 00:00:10,773 train 150 1.606051e-02 -0.682238
2019-11-06 00:00:20,985 train 200 1.592887e-02 -0.750443
2019-11-06 00:00:31,177 train 250 1.593395e-02 -0.737590
2019-11-06 00:00:41,339 train 300 1.590099e-02 -1.353716
2019-11-06 00:00:51,423 train 350 1.589208e-02 -1.291493
2019-11-06 00:01:01,551 train 400 1.593093e-02 -1.204963
2019-11-06 00:01:11,686 train 450 1.593229e-02 -1.135018
2019-11-06 00:01:21,851 train 500 1.590506e-02 -1.081756
2019-11-06 00:01:32,034 train 550 1.593199e-02 -1.034376
2019-11-06 00:01:42,251 train 600 1.591213e-02 -0.995187
2019-11-06 00:01:52,429 train 650 1.592192e-02 -0.961553
2019-11-06 00:02:02,611 train 700 1.592455e-02 -0.953169
2019-11-06 00:02:12,692 train 750 1.592283e-02 -1.098003
2019-11-06 00:02:22,779 train 800 1.590374e-02 -1.061898
2019-11-06 00:02:32,932 train 850 1.589620e-02 -1.036447
2019-11-06 00:02:35,962 training loss; R2: 1.589226e-02 -1.024304
2019-11-06 00:02:36,480 valid 000 1.249625e-02 -2.766662
2019-11-06 00:02:46,290 valid 050 1.313170e-02 -1.065138
2019-11-06 00:02:54,993 validation loss; R2: 1.335413e-02 -1.038620
2019-11-06 00:02:55,059 epoch 263 lr 1.000000e-04
2019-11-06 00:02:55,719 train 000 1.583100e-02 -0.593399
2019-11-06 00:03:05,861 train 050 1.554869e-02 -0.487832
2019-11-06 00:03:15,955 train 100 1.577311e-02 -0.658972
2019-11-06 00:03:26,105 train 150 1.579659e-02 -0.651652
2019-11-06 00:03:36,271 train 200 1.586215e-02 -0.635398
2019-11-06 00:03:46,387 train 250 1.589336e-02 -0.642748
2019-11-06 00:03:56,510 train 300 1.588334e-02 -0.640017
2019-11-06 00:04:06,638 train 350 1.594550e-02 -1.069929
2019-11-06 00:04:16,786 train 400 1.592700e-02 -1.000271
2019-11-06 00:04:26,898 train 450 1.591195e-02 -0.951131
2019-11-06 00:04:37,064 train 500 1.589814e-02 -0.937983
2019-11-06 00:04:47,215 train 550 1.588860e-02 -0.896202
2019-11-06 00:04:57,368 train 600 1.585327e-02 -0.879637
2019-11-06 00:05:07,505 train 650 1.581945e-02 -0.874780
2019-11-06 00:05:17,665 train 700 1.584658e-02 -0.853890
2019-11-06 00:05:27,787 train 750 1.585919e-02 -0.861282
2019-11-06 00:05:37,910 train 800 1.587358e-02 -0.858998
2019-11-06 00:05:48,029 train 850 1.584680e-02 -0.845905
2019-11-06 00:05:51,048 training loss; R2: 1.582644e-02 -0.839680
2019-11-06 00:05:51,619 valid 000 1.414120e-02 0.022545
2019-11-06 00:06:01,482 valid 050 1.340922e-02 -0.991142
2019-11-06 00:06:10,392 validation loss; R2: 1.329968e-02 -1.062516
2019-11-06 00:06:10,468 epoch 264 lr 1.000000e-04
2019-11-06 00:06:11,194 train 000 1.614523e-02 -0.476184
2019-11-06 00:06:21,441 train 050 1.568490e-02 -0.775486
2019-11-06 00:06:31,633 train 100 1.571056e-02 -0.803668
2019-11-06 00:06:41,806 train 150 1.580751e-02 -0.804405
2019-11-06 00:06:51,956 train 200 1.580142e-02 -0.743470
2019-11-06 00:07:02,114 train 250 1.576650e-02 -0.759289
2019-11-06 00:07:12,274 train 300 1.577956e-02 -0.757771
2019-11-06 00:07:22,433 train 350 1.582346e-02 -0.745064
2019-11-06 00:07:32,599 train 400 1.586320e-02 -0.757541
2019-11-06 00:07:42,747 train 450 1.583342e-02 -0.793386
2019-11-06 00:07:52,910 train 500 1.580320e-02 -0.770545
2019-11-06 00:08:03,075 train 550 1.583127e-02 -0.735384
2019-11-06 00:08:13,251 train 600 1.582956e-02 -0.718707
2019-11-06 00:08:23,401 train 650 1.582497e-02 -0.743680
2019-11-06 00:08:33,601 train 700 1.582735e-02 -0.763929
2019-11-06 00:08:43,786 train 750 1.584023e-02 -0.752892
2019-11-06 00:08:54,020 train 800 1.585188e-02 -0.745561
2019-11-06 00:09:04,266 train 850 1.582666e-02 -0.745774
2019-11-06 00:09:07,308 training loss; R2: 1.583752e-02 -0.751586
2019-11-06 00:09:07,903 valid 000 1.739185e-02 -0.268127
2019-11-06 00:09:17,616 valid 050 1.562780e-02 -1.521202
2019-11-06 00:09:26,353 validation loss; R2: 1.573263e-02 -1.407746
2019-11-06 00:09:26,424 epoch 265 lr 1.000000e-04
2019-11-06 00:09:27,120 train 000 1.244898e-02 -0.290757
2019-11-06 00:09:37,346 train 050 1.533269e-02 -0.688277
2019-11-06 00:09:47,530 train 100 1.557428e-02 -0.653248
2019-11-06 00:09:57,711 train 150 1.572296e-02 -0.687328
2019-11-06 00:10:07,880 train 200 1.565121e-02 -0.745609
2019-11-06 00:10:18,049 train 250 1.577030e-02 -0.712971
2019-11-06 00:10:28,204 train 300 1.574854e-02 -0.683808
2019-11-06 00:10:38,373 train 350 1.577137e-02 -0.662874
2019-11-06 00:10:48,534 train 400 1.576635e-02 -0.696348
2019-11-06 00:10:58,696 train 450 1.578484e-02 -0.719044
2019-11-06 00:11:08,843 train 500 1.582597e-02 -0.714849
2019-11-06 00:11:19,009 train 550 1.582870e-02 -0.717920
2019-11-06 00:11:29,176 train 600 1.582131e-02 -0.729060
2019-11-06 00:11:39,343 train 650 1.581322e-02 -0.705289
2019-11-06 00:11:49,536 train 700 1.581146e-02 -0.761349
2019-11-06 00:11:59,725 train 750 1.580796e-02 -0.767374
2019-11-06 00:12:09,915 train 800 1.581112e-02 -0.772842
2019-11-06 00:12:20,117 train 850 1.580397e-02 -0.758457
2019-11-06 00:12:23,158 training loss; R2: 1.580656e-02 -0.770947
2019-11-06 00:12:23,671 valid 000 1.497551e-02 -4.010513
2019-11-06 00:12:33,510 valid 050 1.317917e-02 -1.054636
2019-11-06 00:12:42,224 validation loss; R2: 1.319008e-02 -0.971511
2019-11-06 00:12:42,288 epoch 266 lr 1.000000e-04
2019-11-06 00:12:42,952 train 000 1.479944e-02 -0.245436
2019-11-06 00:12:53,182 train 050 1.572399e-02 -0.934672
2019-11-06 00:13:03,402 train 100 1.568073e-02 -0.828798
2019-11-06 00:13:13,590 train 150 1.570207e-02 -0.792710
2019-11-06 00:13:23,796 train 200 1.570988e-02 -0.783695
2019-11-06 00:13:33,975 train 250 1.572509e-02 -0.775151
2019-11-06 00:13:44,123 train 300 1.581068e-02 -0.760276
2019-11-06 00:13:54,306 train 350 1.591119e-02 -0.724937
2019-11-06 00:14:04,447 train 400 1.586980e-02 -0.752500
2019-11-06 00:14:14,590 train 450 1.586064e-02 -0.761396
2019-11-06 00:14:24,730 train 500 1.584260e-02 -0.752995
2019-11-06 00:14:34,892 train 550 1.581466e-02 -0.744969
2019-11-06 00:14:45,059 train 600 1.583919e-02 -0.731664
2019-11-06 00:14:55,242 train 650 1.586698e-02 -0.715740
2019-11-06 00:15:05,460 train 700 1.586239e-02 -0.717219
2019-11-06 00:15:15,688 train 750 1.585829e-02 -0.718960
2019-11-06 00:15:25,870 train 800 1.584766e-02 -0.714158
2019-11-06 00:15:36,053 train 850 1.583689e-02 -0.701280
2019-11-06 00:15:39,094 training loss; R2: 1.583584e-02 -0.697901
2019-11-06 00:15:39,668 valid 000 1.658043e-02 -0.222162
2019-11-06 00:15:49,353 valid 050 1.655148e-02 -0.936568
2019-11-06 00:15:58,153 validation loss; R2: 1.635832e-02 -0.869945
2019-11-06 00:15:58,218 epoch 267 lr 1.000000e-04
2019-11-06 00:15:58,972 train 000 1.600365e-02 -0.176459
2019-11-06 00:16:09,216 train 050 1.551719e-02 -1.844434
2019-11-06 00:16:19,428 train 100 1.572241e-02 -2.418515
2019-11-06 00:16:29,611 train 150 1.573260e-02 -1.909579
2019-11-06 00:16:39,823 train 200 1.578293e-02 -1.547426
2019-11-06 00:16:50,016 train 250 1.585963e-02 -1.373313
2019-11-06 00:17:00,228 train 300 1.586419e-02 -1.277436
2019-11-06 00:17:10,396 train 350 1.578553e-02 -1.212159
2019-11-06 00:17:20,706 train 400 1.578884e-02 -1.198714
2019-11-06 00:17:30,864 train 450 1.578586e-02 -1.172397
2019-11-06 00:17:41,054 train 500 1.582032e-02 -1.102602
2019-11-06 00:17:51,209 train 550 1.581159e-02 -1.081983
2019-11-06 00:18:01,378 train 600 1.580901e-02 -1.063402
2019-11-06 00:18:11,534 train 650 1.579650e-02 -1.032855
2019-11-06 00:18:21,725 train 700 1.579102e-02 -1.064788
2019-11-06 00:18:31,856 train 750 1.576389e-02 -1.038368
2019-11-06 00:18:42,035 train 800 1.577447e-02 -1.012367
2019-11-06 00:18:52,209 train 850 1.576782e-02 -0.987534
2019-11-06 00:18:55,249 training loss; R2: 1.576914e-02 -0.979573
2019-11-06 00:18:55,767 valid 000 1.376938e-02 -2.910857
2019-11-06 00:19:05,591 valid 050 1.341373e-02 -1.081647
2019-11-06 00:19:14,225 validation loss; R2: 1.312666e-02 -1.136439
2019-11-06 00:19:14,291 epoch 268 lr 1.000000e-04
2019-11-06 00:19:15,038 train 000 1.547325e-02 -0.208142
2019-11-06 00:19:25,195 train 050 1.593073e-02 -0.563927
2019-11-06 00:19:35,362 train 100 1.596665e-02 -0.534833
2019-11-06 00:19:45,563 train 150 1.570693e-02 -0.575189
2019-11-06 00:19:55,722 train 200 1.572931e-02 -0.593957
2019-11-06 00:20:05,876 train 250 1.581092e-02 -0.616589
2019-11-06 00:20:16,049 train 300 1.571848e-02 -0.643470
2019-11-06 00:20:26,209 train 350 1.577591e-02 -0.632800
2019-11-06 00:20:36,394 train 400 1.573161e-02 -0.638253
2019-11-06 00:20:46,584 train 450 1.575782e-02 -0.638867
2019-11-06 00:20:56,740 train 500 1.575680e-02 -0.648546
2019-11-06 00:21:06,941 train 550 1.576218e-02 -0.628858
2019-11-06 00:21:17,099 train 600 1.576327e-02 -0.622852
2019-11-06 00:21:27,282 train 650 1.574976e-02 -0.623000
2019-11-06 00:21:37,500 train 700 1.573582e-02 -0.626068
2019-11-06 00:21:47,677 train 750 1.574000e-02 -0.653990
2019-11-06 00:21:57,836 train 800 1.575557e-02 -0.655274
2019-11-06 00:22:07,970 train 850 1.576097e-02 -0.685273
2019-11-06 00:22:11,008 training loss; R2: 1.575557e-02 -0.683593
2019-11-06 00:22:11,517 valid 000 1.222898e-02 -0.527818
2019-11-06 00:22:21,349 valid 050 1.363621e-02 -0.951213
2019-11-06 00:22:29,980 validation loss; R2: 1.379333e-02 -0.942552
2019-11-06 00:22:30,048 epoch 269 lr 1.000000e-04
2019-11-06 00:22:30,778 train 000 1.436849e-02 -0.288502
2019-11-06 00:22:41,002 train 050 1.570639e-02 -0.598324
2019-11-06 00:22:51,220 train 100 1.586663e-02 -0.732912
2019-11-06 00:23:01,400 train 150 1.602864e-02 -0.652599
2019-11-06 00:23:11,593 train 200 1.598412e-02 -0.643562
2019-11-06 00:23:21,760 train 250 1.598624e-02 -0.641211
2019-11-06 00:23:31,924 train 300 1.593876e-02 -0.640986
2019-11-06 00:23:41,996 train 350 1.587971e-02 -0.647194
2019-11-06 00:23:52,077 train 400 1.589542e-02 -0.660779
2019-11-06 00:24:02,179 train 450 1.597195e-02 -4.513799
2019-11-06 00:24:12,352 train 500 1.593593e-02 -4.148361
2019-11-06 00:24:22,525 train 550 1.591078e-02 -3.827126
2019-11-06 00:24:32,736 train 600 1.591961e-02 -3.557342
2019-11-06 00:24:42,925 train 650 1.590683e-02 -3.340731
2019-11-06 00:24:53,113 train 700 1.585503e-02 -3.130556
2019-11-06 00:25:03,294 train 750 1.581969e-02 -2.966125
2019-11-06 00:25:13,488 train 800 1.582027e-02 -3.119433
2019-11-06 00:25:23,683 train 850 1.581434e-02 -2.975370
2019-11-06 00:25:26,717 training loss; R2: 1.580656e-02 -2.939513
2019-11-06 00:25:27,312 valid 000 1.287894e-02 0.124881
2019-11-06 00:25:37,254 valid 050 1.344759e-02 -1.484739
2019-11-06 00:25:46,062 validation loss; R2: 1.346036e-02 -1.779215
2019-11-06 00:25:46,131 epoch 270 lr 1.000000e-04
2019-11-06 00:25:46,893 train 000 1.455411e-02 -2.190680
2019-11-06 00:25:57,099 train 050 1.567066e-02 -0.580040
2019-11-06 00:26:07,417 train 100 1.589151e-02 -0.700822
2019-11-06 00:26:17,767 train 150 1.567293e-02 -0.657287
2019-11-06 00:26:28,106 train 200 1.569479e-02 -0.651034
2019-11-06 00:26:38,439 train 250 1.570521e-02 -0.678040
2019-11-06 00:26:48,778 train 300 1.571604e-02 -0.723736
2019-11-06 00:26:59,103 train 350 1.575593e-02 -0.713416
2019-11-06 00:27:09,410 train 400 1.575659e-02 -0.686646
2019-11-06 00:27:19,754 train 450 1.575454e-02 -0.750275
2019-11-06 00:27:29,925 train 500 1.574525e-02 -0.733917
2019-11-06 00:27:40,086 train 550 1.579734e-02 -0.810000
2019-11-06 00:27:50,248 train 600 1.577207e-02 -0.796986
2019-11-06 00:28:00,392 train 650 1.576629e-02 -0.793773
2019-11-06 00:28:10,551 train 700 1.575679e-02 -0.785506
2019-11-06 00:28:20,711 train 750 1.576480e-02 -0.791407
2019-11-06 00:28:30,909 train 800 1.575105e-02 -0.785917
2019-11-06 00:28:41,121 train 850 1.576562e-02 -0.782593
2019-11-06 00:28:44,158 training loss; R2: 1.576498e-02 -0.777777
2019-11-06 00:28:44,719 valid 000 1.303091e-02 -1.510002
2019-11-06 00:28:54,510 valid 050 1.359688e-02 -1.569131
2019-11-06 00:29:03,184 validation loss; R2: 1.351942e-02 -1.505085
2019-11-06 00:29:03,249 epoch 271 lr 1.000000e-04
2019-11-06 00:29:03,980 train 000 1.694290e-02 -0.375599
2019-11-06 00:29:14,176 train 050 1.612637e-02 -0.879410
2019-11-06 00:29:24,379 train 100 1.593474e-02 -0.836761
2019-11-06 00:29:34,581 train 150 1.604709e-02 -0.820488
2019-11-06 00:29:44,784 train 200 1.599323e-02 -0.794038
2019-11-06 00:29:54,988 train 250 1.589837e-02 -0.834416
2019-11-06 00:30:05,181 train 300 1.587300e-02 -0.763796
2019-11-06 00:30:15,319 train 350 1.581282e-02 -0.753739
2019-11-06 00:30:25,457 train 400 1.582999e-02 -0.737532
2019-11-06 00:30:35,603 train 450 1.582122e-02 -0.737700
2019-11-06 00:30:45,737 train 500 1.581455e-02 -0.742161
2019-11-06 00:30:55,905 train 550 1.575364e-02 -0.726584
2019-11-06 00:31:06,089 train 600 1.575617e-02 -0.722183
2019-11-06 00:31:16,238 train 650 1.569309e-02 -0.721862
2019-11-06 00:31:26,397 train 700 1.571027e-02 -0.730725
2019-11-06 00:31:36,572 train 750 1.571726e-02 -0.733696
2019-11-06 00:31:46,765 train 800 1.571976e-02 -0.713694
2019-11-06 00:31:56,955 train 850 1.573050e-02 -0.738187
2019-11-06 00:31:59,988 training loss; R2: 1.573209e-02 -0.738037
2019-11-06 00:32:00,590 valid 000 1.507904e-02 -9.042058
2019-11-06 00:32:10,402 valid 050 1.486064e-02 -1.858483
2019-11-06 00:32:19,078 validation loss; R2: 1.485301e-02 -1.628364
2019-11-06 00:32:19,154 epoch 272 lr 1.000000e-04
2019-11-06 00:32:19,831 train 000 1.751517e-02 -0.468461
2019-11-06 00:32:30,117 train 050 1.586611e-02 -0.540343
2019-11-06 00:32:40,300 train 100 1.586529e-02 -0.585298
2019-11-06 00:32:50,440 train 150 1.574181e-02 -0.716306
2019-11-06 00:33:00,561 train 200 1.568527e-02 -0.655651
2019-11-06 00:33:10,687 train 250 1.574959e-02 -0.664120
2019-11-06 00:33:20,792 train 300 1.569741e-02 -0.664920
2019-11-06 00:33:30,999 train 350 1.567089e-02 -0.665536
2019-11-06 00:33:41,186 train 400 1.570480e-02 -0.664967
2019-11-06 00:33:51,344 train 450 1.570067e-02 -0.690693
2019-11-06 00:34:01,549 train 500 1.571697e-02 -0.706873
2019-11-06 00:34:11,731 train 550 1.570177e-02 -0.702804
2019-11-06 00:34:21,940 train 600 1.570440e-02 -0.696848
2019-11-06 00:34:32,078 train 650 1.573451e-02 -0.711378
2019-11-06 00:34:42,197 train 700 1.573075e-02 -0.714693
2019-11-06 00:34:52,345 train 750 1.573230e-02 -0.722098
2019-11-06 00:35:02,582 train 800 1.572774e-02 -0.785111
2019-11-06 00:35:12,728 train 850 1.572953e-02 -0.780427
2019-11-06 00:35:15,755 training loss; R2: 1.573080e-02 -0.781048
2019-11-06 00:35:16,322 valid 000 1.527632e-02 0.117216
2019-11-06 00:35:26,136 valid 050 1.479356e-02 -1.136351
2019-11-06 00:35:34,794 validation loss; R2: 1.489422e-02 -1.039369
2019-11-06 00:35:34,859 epoch 273 lr 1.000000e-04
2019-11-06 00:35:35,552 train 000 1.644509e-02 -0.245708
2019-11-06 00:35:45,800 train 050 1.571581e-02 -0.596796
2019-11-06 00:35:56,021 train 100 1.580692e-02 -56.731231
2019-11-06 00:36:06,209 train 150 1.592172e-02 -38.181671
2019-11-06 00:36:16,379 train 200 1.585489e-02 -28.905795
2019-11-06 00:36:26,525 train 250 1.584071e-02 -23.253696
2019-11-06 00:36:36,668 train 300 1.588224e-02 -19.491290
2019-11-06 00:36:46,838 train 350 1.589150e-02 -16.810867
2019-11-06 00:36:56,981 train 400 1.589001e-02 -14.781405
2019-11-06 00:37:07,138 train 450 1.587186e-02 -13.299959
2019-11-06 00:37:17,293 train 500 1.595593e-02 -12.027809
2019-11-06 00:37:27,489 train 550 1.595402e-02 -10.986320
2019-11-06 00:37:37,651 train 600 1.593787e-02 -10.160033
2019-11-06 00:37:47,802 train 650 1.591759e-02 -9.441704
2019-11-06 00:37:57,918 train 700 1.589591e-02 -8.816983
2019-11-06 00:38:08,056 train 750 1.588145e-02 -8.273934
2019-11-06 00:38:18,241 train 800 1.589800e-02 -7.799183
2019-11-06 00:38:28,412 train 850 1.587447e-02 -7.381486
2019-11-06 00:38:31,427 training loss; R2: 1.586875e-02 -7.258671
2019-11-06 00:38:31,998 valid 000 1.405629e-02 -0.234603
2019-11-06 00:38:41,851 valid 050 1.332317e-02 -1.310259
2019-11-06 00:38:50,523 validation loss; R2: 1.321365e-02 -0.976745
2019-11-06 00:38:50,595 epoch 274 lr 1.000000e-04
2019-11-06 00:38:51,327 train 000 1.357145e-02 -1.801441
2019-11-06 00:39:01,580 train 050 1.576130e-02 -0.807189
2019-11-06 00:39:11,828 train 100 1.594369e-02 -0.717022
2019-11-06 00:39:22,043 train 150 1.585035e-02 -0.651965
2019-11-06 00:39:32,227 train 200 1.579669e-02 -0.685564
2019-11-06 00:39:42,397 train 250 1.574405e-02 -0.684973
2019-11-06 00:39:52,559 train 300 1.578011e-02 -0.945729
2019-11-06 00:40:02,751 train 350 1.573756e-02 -0.893203
2019-11-06 00:40:12,946 train 400 1.575270e-02 -0.900693
2019-11-06 00:40:23,133 train 450 1.573477e-02 -0.875554
2019-11-06 00:40:33,317 train 500 1.571913e-02 -0.837803
2019-11-06 00:40:43,500 train 550 1.569972e-02 -0.828885
2019-11-06 00:40:53,686 train 600 1.570632e-02 -0.828093
2019-11-06 00:41:03,845 train 650 1.568774e-02 -0.823717
2019-11-06 00:41:13,995 train 700 1.569395e-02 -0.863898
2019-11-06 00:41:24,144 train 750 1.570370e-02 -0.848272
2019-11-06 00:41:34,344 train 800 1.570028e-02 -0.834528
2019-11-06 00:41:44,550 train 850 1.570058e-02 -0.831235
2019-11-06 00:41:47,605 training loss; R2: 1.571093e-02 -0.840459
2019-11-06 00:41:48,200 valid 000 1.625916e-02 -0.609739
2019-11-06 00:41:57,989 valid 050 1.458575e-02 -1.224879
2019-11-06 00:42:06,652 validation loss; R2: 1.467300e-02 -1.276937
2019-11-06 00:42:06,714 epoch 275 lr 1.000000e-04
2019-11-06 00:42:07,465 train 000 1.316806e-02 -1.428951
2019-11-06 00:42:17,678 train 050 1.583012e-02 -0.708700
2019-11-06 00:42:27,898 train 100 1.552535e-02 -0.724896
2019-11-06 00:42:38,152 train 150 1.553517e-02 -0.718502
2019-11-06 00:42:48,328 train 200 1.562891e-02 -0.693754
2019-11-06 00:42:58,541 train 250 1.563754e-02 -0.680918
2019-11-06 00:43:08,703 train 300 1.560871e-02 -0.731146
2019-11-06 00:43:18,878 train 350 1.567323e-02 -0.751679
2019-11-06 00:43:29,010 train 400 1.564458e-02 -0.780034
2019-11-06 00:43:39,202 train 450 1.565355e-02 -0.782859
2019-11-06 00:43:49,379 train 500 1.566652e-02 -0.775782
2019-11-06 00:43:59,540 train 550 1.574347e-02 -0.738418
2019-11-06 00:44:09,697 train 600 1.575292e-02 -0.739920
2019-11-06 00:44:19,872 train 650 1.575756e-02 -0.724270
2019-11-06 00:44:30,039 train 700 1.579387e-02 -0.742590
2019-11-06 00:44:40,163 train 750 1.578568e-02 -0.746021
2019-11-06 00:44:50,280 train 800 1.578134e-02 -0.750532
2019-11-06 00:45:00,387 train 850 1.576609e-02 -0.744718
2019-11-06 00:45:03,404 training loss; R2: 1.576816e-02 -0.736628
2019-11-06 00:45:03,984 valid 000 1.406751e-02 0.058521
2019-11-06 00:45:13,774 valid 050 1.339617e-02 -1.517420
2019-11-06 00:45:22,473 validation loss; R2: 1.325444e-02 -1.464994
2019-11-06 00:45:22,559 epoch 276 lr 1.000000e-04
2019-11-06 00:45:23,300 train 000 1.493197e-02 -0.017961
2019-11-06 00:45:33,467 train 050 1.595759e-02 -0.931266
2019-11-06 00:45:43,576 train 100 1.592476e-02 -0.753233
2019-11-06 00:45:53,655 train 150 1.594742e-02 -0.837200
2019-11-06 00:46:03,777 train 200 1.592304e-02 -1.084686
2019-11-06 00:46:13,908 train 250 1.586136e-02 -1.303825
2019-11-06 00:46:24,087 train 300 1.584441e-02 -1.188215
2019-11-06 00:46:34,273 train 350 1.577390e-02 -1.154641
2019-11-06 00:46:44,431 train 400 1.578278e-02 -1.112036
2019-11-06 00:46:54,601 train 450 1.577443e-02 -1.050292
2019-11-06 00:47:04,769 train 500 1.578069e-02 -1.001290
2019-11-06 00:47:14,944 train 550 1.578696e-02 -1.012303
2019-11-06 00:47:25,082 train 600 1.580035e-02 -0.966280
2019-11-06 00:47:35,246 train 650 1.580991e-02 -0.940776
2019-11-06 00:47:45,388 train 700 1.579230e-02 -0.925168
2019-11-06 00:47:55,565 train 750 1.580466e-02 -0.927666
2019-11-06 00:48:05,701 train 800 1.578598e-02 -0.904414
2019-11-06 00:48:15,882 train 850 1.579220e-02 -0.895390
2019-11-06 00:48:18,908 training loss; R2: 1.578022e-02 -0.893509
2019-11-06 00:48:19,422 valid 000 1.289545e-02 -1.117239
2019-11-06 00:48:29,203 valid 050 1.318948e-02 -0.867435
2019-11-06 00:48:37,854 validation loss; R2: 1.328325e-02 -0.844003
2019-11-06 00:48:37,919 epoch 277 lr 1.000000e-04
2019-11-06 00:48:38,622 train 000 1.360001e-02 0.012247
2019-11-06 00:48:48,789 train 050 1.559836e-02 -0.548472
2019-11-06 00:48:58,978 train 100 1.577880e-02 -0.617444
2019-11-06 00:49:09,146 train 150 1.571815e-02 -0.604247
2019-11-06 00:49:19,326 train 200 1.575919e-02 -0.557859
2019-11-06 00:49:29,466 train 250 1.579524e-02 -0.591270
2019-11-06 00:49:39,638 train 300 1.580765e-02 -0.650650
2019-11-06 00:49:49,784 train 350 1.584373e-02 -0.733493
2019-11-06 00:49:59,943 train 400 1.582609e-02 -0.728680
2019-11-06 00:50:10,081 train 450 1.582206e-02 -0.712411
2019-11-06 00:50:20,240 train 500 1.580841e-02 -0.706021
2019-11-06 00:50:30,407 train 550 1.580262e-02 -0.758381
2019-11-06 00:50:40,560 train 600 1.579054e-02 -0.772216
2019-11-06 00:50:50,614 train 650 1.580997e-02 -0.755914
2019-11-06 00:51:00,699 train 700 1.580853e-02 -0.766362
2019-11-06 00:51:10,800 train 750 1.582862e-02 -0.755283
2019-11-06 00:51:20,978 train 800 1.582886e-02 -0.751160
2019-11-06 00:51:31,138 train 850 1.583496e-02 -0.753327
2019-11-06 00:51:34,170 training loss; R2: 1.584677e-02 -0.760742
2019-11-06 00:51:34,684 valid 000 1.486987e-02 -0.418654
2019-11-06 00:51:44,504 valid 050 1.321942e-02 -0.775228
2019-11-06 00:51:53,199 validation loss; R2: 1.338738e-02 -0.921449
2019-11-06 00:51:53,272 epoch 278 lr 1.000000e-04
2019-11-06 00:51:53,961 train 000 1.468027e-02 -1.792103
2019-11-06 00:52:04,214 train 050 1.582543e-02 -0.834066
2019-11-06 00:52:14,438 train 100 1.572294e-02 -0.869295
2019-11-06 00:52:24,665 train 150 1.588932e-02 -0.811199
2019-11-06 00:52:34,879 train 200 1.584780e-02 -1.454691
2019-11-06 00:52:45,110 train 250 1.583888e-02 -1.283549
2019-11-06 00:52:55,325 train 300 1.583552e-02 -1.386098
2019-11-06 00:53:05,529 train 350 1.580653e-02 -1.280196
2019-11-06 00:53:15,716 train 400 1.574774e-02 -1.199306
2019-11-06 00:53:25,921 train 450 1.580709e-02 -1.116177
2019-11-06 00:53:36,085 train 500 1.579998e-02 -1.077063
2019-11-06 00:53:46,282 train 550 1.578130e-02 -1.032707
2019-11-06 00:53:56,467 train 600 1.580453e-02 -1.136501
2019-11-06 00:54:06,641 train 650 1.577007e-02 -1.131054
2019-11-06 00:54:16,803 train 700 1.576707e-02 -1.085515
2019-11-06 00:54:26,983 train 750 1.576507e-02 -1.068091
2019-11-06 00:54:37,155 train 800 1.579198e-02 -1.036253
2019-11-06 00:54:47,352 train 850 1.578084e-02 -1.009824
2019-11-06 00:54:50,394 training loss; R2: 1.578149e-02 -1.008582
2019-11-06 00:54:50,909 valid 000 1.127137e-02 0.246897
2019-11-06 00:55:00,725 valid 050 1.302312e-02 -0.773683
2019-11-06 00:55:09,379 validation loss; R2: 1.310862e-02 -1.052242
2019-11-06 00:55:09,452 epoch 279 lr 1.000000e-04
2019-11-06 00:55:10,180 train 000 1.496910e-02 -0.831760
2019-11-06 00:55:20,415 train 050 1.630453e-02 -0.630954
2019-11-06 00:55:30,613 train 100 1.608151e-02 -0.609112
2019-11-06 00:55:40,758 train 150 1.587007e-02 -0.556354
2019-11-06 00:55:50,955 train 200 1.586827e-02 -0.530447
2019-11-06 00:56:01,132 train 250 1.585570e-02 -0.594701
2019-11-06 00:56:11,327 train 300 1.585269e-02 -0.646126
2019-11-06 00:56:21,474 train 350 1.581517e-02 -0.634023
2019-11-06 00:56:31,636 train 400 1.585146e-02 -0.669186
2019-11-06 00:56:41,796 train 450 1.586182e-02 -0.663635
2019-11-06 00:56:51,977 train 500 1.583489e-02 -0.654891
2019-11-06 00:57:02,132 train 550 1.580009e-02 -0.669800
2019-11-06 00:57:12,319 train 600 1.580440e-02 -0.697670
2019-11-06 00:57:22,465 train 650 1.580772e-02 -0.712732
2019-11-06 00:57:32,627 train 700 1.578740e-02 -0.709998
2019-11-06 00:57:42,749 train 750 1.576442e-02 -0.692199
2019-11-06 00:57:52,928 train 800 1.573825e-02 -0.687113
2019-11-06 00:58:03,086 train 850 1.574608e-02 -0.728767
2019-11-06 00:58:06,127 training loss; R2: 1.573630e-02 -0.722299
2019-11-06 00:58:06,637 valid 000 1.340257e-02 -0.030464
2019-11-06 00:58:16,413 valid 050 1.424723e-02 -1.262596
2019-11-06 00:58:25,053 validation loss; R2: 1.423213e-02 -1.077686
2019-11-06 00:58:25,118 epoch 280 lr 1.000000e-04
2019-11-06 00:58:25,861 train 000 1.748686e-02 -0.869102
2019-11-06 00:58:36,128 train 050 1.598384e-02 -0.580583
2019-11-06 00:58:46,385 train 100 1.592104e-02 -0.721950
2019-11-06 00:58:56,621 train 150 1.587418e-02 -0.697101
2019-11-06 00:59:06,843 train 200 1.586525e-02 -0.654864
2019-11-06 00:59:17,025 train 250 1.583113e-02 -1.020807
2019-11-06 00:59:27,192 train 300 1.586468e-02 -0.964495
2019-11-06 00:59:37,379 train 350 1.580873e-02 -0.924396
2019-11-06 00:59:47,560 train 400 1.575220e-02 -0.878188
2019-11-06 00:59:57,759 train 450 1.573166e-02 -0.959159
2019-11-06 01:00:07,967 train 500 1.574549e-02 -0.951880
2019-11-06 01:00:18,140 train 550 1.575582e-02 -0.911894
2019-11-06 01:00:28,241 train 600 1.573281e-02 -0.891178
2019-11-06 01:00:38,323 train 650 1.571882e-02 -0.880643
2019-11-06 01:00:48,469 train 700 1.573691e-02 -0.869545
2019-11-06 01:00:58,640 train 750 1.569952e-02 -0.866483
2019-11-06 01:01:08,816 train 800 1.569251e-02 -0.854550
2019-11-06 01:01:18,976 train 850 1.569005e-02 -0.845034
2019-11-06 01:01:22,027 training loss; R2: 1.568216e-02 -0.839791
2019-11-06 01:01:22,589 valid 000 1.446269e-02 0.099829
2019-11-06 01:01:32,371 valid 050 1.362985e-02 -1.239288
2019-11-06 01:01:41,065 validation loss; R2: 1.367877e-02 -1.179376
2019-11-06 01:01:41,132 epoch 281 lr 1.000000e-04
2019-11-06 01:01:41,861 train 000 1.476835e-02 -0.418463
2019-11-06 01:01:52,152 train 050 1.598783e-02 -1.079890
2019-11-06 01:02:02,354 train 100 1.574552e-02 -0.968627
2019-11-06 01:02:12,569 train 150 1.586070e-02 -0.950053
2019-11-06 01:02:22,747 train 200 1.585761e-02 -0.822030
2019-11-06 01:02:32,943 train 250 1.588892e-02 -0.788039
2019-11-06 01:02:43,090 train 300 1.581631e-02 -0.754225
2019-11-06 01:02:53,264 train 350 1.589398e-02 -0.756345
2019-11-06 01:03:03,436 train 400 1.589984e-02 -0.778220
2019-11-06 01:03:13,554 train 450 1.587172e-02 -0.767274
2019-11-06 01:03:23,659 train 500 1.586360e-02 -0.777319
2019-11-06 01:03:33,785 train 550 1.587827e-02 -0.769509
2019-11-06 01:03:43,890 train 600 1.585078e-02 -0.762721
2019-11-06 01:03:54,053 train 650 1.584372e-02 -0.747735
2019-11-06 01:04:04,231 train 700 1.583929e-02 -0.762790
2019-11-06 01:04:14,442 train 750 1.581304e-02 -0.773498
2019-11-06 01:04:24,643 train 800 1.579856e-02 -0.766113
2019-11-06 01:04:34,838 train 850 1.578703e-02 -0.772751
2019-11-06 01:04:37,885 training loss; R2: 1.579037e-02 -0.767449
2019-11-06 01:04:38,442 valid 000 1.348796e-02 -0.011709
2019-11-06 01:04:48,186 valid 050 1.657097e-02 -1.405495
2019-11-06 01:04:56,809 validation loss; R2: 1.643417e-02 -1.320661
2019-11-06 01:04:56,873 epoch 282 lr 1.000000e-04
2019-11-06 01:04:57,589 train 000 1.276645e-02 -3.693810
2019-11-06 01:05:07,755 train 050 1.565771e-02 -0.984056
2019-11-06 01:05:17,931 train 100 1.587398e-02 -0.873169
2019-11-06 01:05:28,215 train 150 1.581864e-02 -0.832556
2019-11-06 01:05:38,406 train 200 1.577458e-02 -0.838763
2019-11-06 01:05:48,610 train 250 1.580859e-02 -0.772417
2019-11-06 01:05:58,795 train 300 1.585627e-02 -0.813677
2019-11-06 01:06:08,985 train 350 1.583341e-02 -0.798252
2019-11-06 01:06:19,164 train 400 1.587572e-02 -0.814228
2019-11-06 01:06:29,341 train 450 1.581584e-02 -0.816720
2019-11-06 01:06:39,502 train 500 1.579719e-02 -0.806930
2019-11-06 01:06:49,626 train 550 1.577278e-02 -0.847678
2019-11-06 01:06:59,705 train 600 1.577678e-02 -0.818238
2019-11-06 01:07:09,833 train 650 1.575377e-02 -0.805356
2019-11-06 01:07:19,974 train 700 1.577045e-02 -0.789256
2019-11-06 01:07:30,153 train 750 1.574706e-02 -0.774019
2019-11-06 01:07:40,287 train 800 1.575053e-02 -0.771067
2019-11-06 01:07:50,460 train 850 1.575150e-02 -0.977289
2019-11-06 01:07:53,486 training loss; R2: 1.575193e-02 -0.970364
2019-11-06 01:07:54,072 valid 000 1.406676e-02 -7.496600
2019-11-06 01:08:03,894 valid 050 1.297958e-02 -1.096311
2019-11-06 01:08:12,539 validation loss; R2: 1.300616e-02 -1.405880
2019-11-06 01:08:12,606 epoch 283 lr 1.000000e-04
2019-11-06 01:08:13,345 train 000 1.536368e-02 -0.070512
2019-11-06 01:08:23,529 train 050 1.544688e-02 -0.717251
2019-11-06 01:08:33,678 train 100 1.559343e-02 -0.748485
2019-11-06 01:08:43,817 train 150 1.610446e-02 -0.727043
2019-11-06 01:08:53,929 train 200 1.617795e-02 -0.739728
2019-11-06 01:09:04,023 train 250 1.612667e-02 -0.806166
2019-11-06 01:09:14,127 train 300 1.606766e-02 -0.767921
2019-11-06 01:09:24,204 train 350 1.603228e-02 -0.773968
2019-11-06 01:09:34,313 train 400 1.597189e-02 -0.771912
2019-11-06 01:09:44,438 train 450 1.594346e-02 -0.739982
2019-11-06 01:09:54,566 train 500 1.590438e-02 -0.719915
2019-11-06 01:10:04,762 train 550 1.590528e-02 -0.697403
2019-11-06 01:10:14,905 train 600 1.590909e-02 -0.701221
2019-11-06 01:10:25,006 train 650 1.591129e-02 -0.702123
2019-11-06 01:10:35,148 train 700 1.588832e-02 -0.702179
2019-11-06 01:10:45,321 train 750 1.589235e-02 -0.701922
2019-11-06 01:10:55,474 train 800 1.590965e-02 -0.758021
2019-11-06 01:11:05,618 train 850 1.591613e-02 -0.756406
2019-11-06 01:11:08,659 training loss; R2: 1.590624e-02 -0.760475
2019-11-06 01:11:09,193 valid 000 1.142965e-02 -1.581823
2019-11-06 01:11:19,128 valid 050 1.381849e-02 -0.663103
2019-11-06 01:11:27,850 validation loss; R2: 1.371739e-02 -1.060061
2019-11-06 01:11:27,915 epoch 284 lr 1.000000e-04
2019-11-06 01:11:28,611 train 000 1.683166e-02 -0.212395
2019-11-06 01:11:38,862 train 050 1.609764e-02 -0.834817
2019-11-06 01:11:49,033 train 100 1.612827e-02 -0.766982
2019-11-06 01:11:59,213 train 150 1.589569e-02 -0.711448
2019-11-06 01:12:09,349 train 200 1.574948e-02 -0.706305
2019-11-06 01:12:19,497 train 250 1.571237e-02 -0.701523
2019-11-06 01:12:29,625 train 300 1.568625e-02 -0.710065
2019-11-06 01:12:39,783 train 350 1.571340e-02 -0.707253
2019-11-06 01:12:49,929 train 400 1.574023e-02 -0.743641
2019-11-06 01:13:00,097 train 450 1.576610e-02 -0.747184
2019-11-06 01:13:10,172 train 500 1.577983e-02 -0.751624
2019-11-06 01:13:20,254 train 550 1.578463e-02 -0.794944
2019-11-06 01:13:30,323 train 600 1.579130e-02 -0.793509
2019-11-06 01:13:40,395 train 650 1.579422e-02 -0.786232
2019-11-06 01:13:50,448 train 700 1.580585e-02 -0.785934
2019-11-06 01:14:00,541 train 750 1.581213e-02 -0.797551
2019-11-06 01:14:10,593 train 800 1.578797e-02 -0.791121
2019-11-06 01:14:20,716 train 850 1.577757e-02 -0.800415
2019-11-06 01:14:23,733 training loss; R2: 1.578452e-02 -0.811104
2019-11-06 01:14:24,288 valid 000 1.424463e-02 -2.100110
2019-11-06 01:14:34,117 valid 050 1.447034e-02 -1.429003
2019-11-06 01:14:42,826 validation loss; R2: 1.439804e-02 -1.295929
2019-11-06 01:14:42,891 epoch 285 lr 1.000000e-04
2019-11-06 01:14:43,636 train 000 1.781789e-02 -0.064371
2019-11-06 01:14:53,995 train 050 1.579820e-02 -1.095449
2019-11-06 01:15:04,374 train 100 1.571002e-02 -0.837951
2019-11-06 01:15:14,714 train 150 1.575419e-02 -0.817759
2019-11-06 01:15:25,058 train 200 1.575996e-02 -0.856248
2019-11-06 01:15:35,375 train 250 1.575048e-02 -1.188509
2019-11-06 01:15:45,539 train 300 1.574773e-02 -1.149426
2019-11-06 01:15:55,740 train 350 1.573729e-02 -1.110388
2019-11-06 01:16:05,949 train 400 1.570404e-02 -1.023664
2019-11-06 01:16:16,147 train 450 1.573803e-02 -0.973074
2019-11-06 01:16:26,355 train 500 1.572858e-02 -0.945611
2019-11-06 01:16:36,552 train 550 1.568191e-02 -0.916746
2019-11-06 01:16:46,734 train 600 1.569256e-02 -0.886580
2019-11-06 01:16:56,914 train 650 1.568610e-02 -0.862990
2019-11-06 01:17:07,111 train 700 1.567163e-02 -0.844053
2019-11-06 01:17:17,290 train 750 1.568012e-02 -0.829157
2019-11-06 01:17:27,480 train 800 1.569704e-02 -0.823282
2019-11-06 01:17:37,718 train 850 1.571368e-02 -0.817849
2019-11-06 01:17:40,763 training loss; R2: 1.572261e-02 -0.811459
2019-11-06 01:17:41,276 valid 000 1.453672e-02 0.135853
2019-11-06 01:17:51,195 valid 050 1.397516e-02 -0.886886
2019-11-06 01:17:59,874 validation loss; R2: 1.396346e-02 -1.030674
2019-11-06 01:17:59,942 epoch 286 lr 1.000000e-04
2019-11-06 01:18:00,649 train 000 1.625331e-02 -0.713673
2019-11-06 01:18:10,793 train 050 1.552117e-02 -0.568295
2019-11-06 01:18:20,917 train 100 1.548344e-02 -0.671060
2019-11-06 01:18:31,049 train 150 1.551654e-02 -2.624442
2019-11-06 01:18:41,170 train 200 1.556104e-02 -2.165491
2019-11-06 01:18:51,313 train 250 1.559629e-02 -1.874186
2019-11-06 01:19:01,507 train 300 1.561507e-02 -1.696112
2019-11-06 01:19:11,718 train 350 1.561458e-02 -1.554376
2019-11-06 01:19:21,928 train 400 1.559915e-02 -1.498853
2019-11-06 01:19:32,137 train 450 1.563650e-02 -1.386419
2019-11-06 01:19:42,330 train 500 1.562566e-02 -1.308087
2019-11-06 01:19:52,553 train 550 1.562904e-02 -1.277892
2019-11-06 01:20:02,744 train 600 1.566823e-02 -1.242661
2019-11-06 01:20:12,938 train 650 1.567075e-02 -1.201893
2019-11-06 01:20:23,096 train 700 1.569687e-02 -1.175302
2019-11-06 01:20:33,308 train 750 1.573676e-02 -1.140235
2019-11-06 01:20:43,492 train 800 1.577696e-02 -1.123506
2019-11-06 01:20:53,713 train 850 1.581629e-02 -1.095710
2019-11-06 01:20:56,767 training loss; R2: 1.580810e-02 -1.084819
2019-11-06 01:20:57,326 valid 000 1.292523e-02 -0.448034
2019-11-06 01:21:07,185 valid 050 1.298985e-02 -1.641979
2019-11-06 01:21:15,924 validation loss; R2: 1.297401e-02 -1.652941
2019-11-06 01:21:15,992 epoch 287 lr 1.000000e-04
2019-11-06 01:21:16,714 train 000 1.539726e-02 0.022618
2019-11-06 01:21:26,911 train 050 1.586431e-02 -0.912734
2019-11-06 01:21:37,101 train 100 1.580882e-02 -0.864116
2019-11-06 01:21:47,259 train 150 1.589604e-02 -0.709290
2019-11-06 01:21:57,408 train 200 1.593013e-02 -0.665785
2019-11-06 01:22:07,567 train 250 1.586325e-02 -0.700493
2019-11-06 01:22:17,749 train 300 1.589438e-02 -0.706804
2019-11-06 01:22:27,908 train 350 1.585311e-02 -0.696870
2019-11-06 01:22:38,089 train 400 1.582942e-02 -0.687286
2019-11-06 01:22:48,250 train 450 1.586510e-02 -0.682872
2019-11-06 01:22:58,408 train 500 1.588773e-02 -0.674452
2019-11-06 01:23:08,562 train 550 1.587268e-02 -0.693687
2019-11-06 01:23:18,722 train 600 1.585593e-02 -0.686293
2019-11-06 01:23:28,867 train 650 1.587627e-02 -0.679790
2019-11-06 01:23:39,026 train 700 1.585444e-02 -0.681709
2019-11-06 01:23:49,200 train 750 1.583719e-02 -0.674432
2019-11-06 01:23:59,370 train 800 1.581403e-02 -0.671304
2019-11-06 01:24:09,486 train 850 1.581744e-02 -0.681019
2019-11-06 01:24:12,482 training loss; R2: 1.581684e-02 -0.677001
2019-11-06 01:24:13,038 valid 000 1.068010e-02 -0.888299
2019-11-06 01:24:22,842 valid 050 1.350039e-02 -1.228016
2019-11-06 01:24:31,483 validation loss; R2: 1.351254e-02 -1.192480
2019-11-06 01:24:31,551 epoch 288 lr 1.000000e-04
2019-11-06 01:24:32,294 train 000 1.397684e-02 -0.241420
2019-11-06 01:24:42,469 train 050 1.537615e-02 -0.941104
2019-11-06 01:24:52,659 train 100 1.577226e-02 -0.969667
2019-11-06 01:25:02,861 train 150 1.579658e-02 -0.764240
2019-11-06 01:25:13,051 train 200 1.569318e-02 -0.729404
2019-11-06 01:25:23,249 train 250 1.560814e-02 -0.678119
2019-11-06 01:25:33,396 train 300 1.560206e-02 -0.694519
2019-11-06 01:25:43,623 train 350 1.557131e-02 -0.692879
2019-11-06 01:25:53,802 train 400 1.561877e-02 -0.656946
2019-11-06 01:26:03,957 train 450 1.564324e-02 -0.675064
2019-11-06 01:26:14,086 train 500 1.568686e-02 -0.647568
2019-11-06 01:26:24,273 train 550 1.573462e-02 -0.644638
2019-11-06 01:26:34,410 train 600 1.575261e-02 -0.647504
2019-11-06 01:26:44,555 train 650 1.571730e-02 -0.666036
2019-11-06 01:26:54,691 train 700 1.570877e-02 -0.671257
2019-11-06 01:27:04,842 train 750 1.570930e-02 -0.680562
2019-11-06 01:27:15,012 train 800 1.570339e-02 -0.839170
2019-11-06 01:27:25,172 train 850 1.570764e-02 -0.826005
2019-11-06 01:27:28,224 training loss; R2: 1.571067e-02 -0.816480
2019-11-06 01:27:28,743 valid 000 1.402834e-02 -1.842721
2019-11-06 01:27:38,648 valid 050 1.411206e-02 -1.119495
2019-11-06 01:27:47,411 validation loss; R2: 1.420325e-02 -1.089163
2019-11-06 01:27:47,479 epoch 289 lr 1.000000e-04
2019-11-06 01:27:48,247 train 000 1.848036e-02 -0.069754
2019-11-06 01:27:58,492 train 050 1.585809e-02 -0.949158
2019-11-06 01:28:08,674 train 100 1.575727e-02 -0.797857
2019-11-06 01:28:18,812 train 150 1.562784e-02 -0.737263
2019-11-06 01:28:28,980 train 200 1.572072e-02 -0.793114
2019-11-06 01:28:39,092 train 250 1.567318e-02 -0.842098
2019-11-06 01:28:49,235 train 300 1.572785e-02 -0.811356
2019-11-06 01:28:59,366 train 350 1.571799e-02 -0.811639
2019-11-06 01:29:09,508 train 400 1.570574e-02 -0.787735
2019-11-06 01:29:19,635 train 450 1.573622e-02 -0.774071
2019-11-06 01:29:29,769 train 500 1.572677e-02 -0.760385
2019-11-06 01:29:39,901 train 550 1.571801e-02 -0.733155
2019-11-06 01:29:50,056 train 600 1.568425e-02 -0.762702
2019-11-06 01:30:00,211 train 650 1.569954e-02 -0.741518
2019-11-06 01:30:10,433 train 700 1.570122e-02 -0.722406
2019-11-06 01:30:20,692 train 750 1.572594e-02 -0.728478
2019-11-06 01:30:30,900 train 800 1.575186e-02 -0.708241
2019-11-06 01:30:41,122 train 850 1.575788e-02 -0.701205
2019-11-06 01:30:44,158 training loss; R2: 1.574270e-02 -0.700500
2019-11-06 01:30:44,672 valid 000 2.326045e-02 -0.717658
2019-11-06 01:30:54,502 valid 050 1.942075e-02 -2.523420
2019-11-06 01:31:03,231 validation loss; R2: 1.939695e-02 -2.009583
2019-11-06 01:31:03,292 epoch 290 lr 1.000000e-04
2019-11-06 01:31:04,028 train 000 1.269353e-02 -0.398287
2019-11-06 01:31:14,218 train 050 1.616245e-02 -0.634246
2019-11-06 01:31:24,425 train 100 1.590733e-02 -0.613991
2019-11-06 01:31:34,616 train 150 1.595097e-02 -0.629624
2019-11-06 01:31:44,808 train 200 1.591944e-02 -0.649112
2019-11-06 01:31:55,002 train 250 1.586508e-02 -0.712166
2019-11-06 01:32:05,132 train 300 1.594082e-02 -0.685695
2019-11-06 01:32:15,224 train 350 1.587122e-02 -0.670270
2019-11-06 01:32:25,323 train 400 1.585481e-02 -0.706587
2019-11-06 01:32:35,439 train 450 1.578890e-02 -0.692133
2019-11-06 01:32:45,579 train 500 1.578903e-02 -0.687201
2019-11-06 01:32:55,739 train 550 1.579540e-02 -0.683410
2019-11-06 01:33:05,901 train 600 1.582773e-02 -0.669189
2019-11-06 01:33:16,061 train 650 1.581880e-02 -0.678446
2019-11-06 01:33:26,222 train 700 1.578431e-02 -0.672727
2019-11-06 01:33:36,357 train 750 1.580105e-02 -0.697120
2019-11-06 01:33:46,483 train 800 1.578858e-02 -0.705986
2019-11-06 01:33:56,598 train 850 1.577512e-02 -0.711518
2019-11-06 01:33:59,620 training loss; R2: 1.576922e-02 -0.709590
2019-11-06 01:34:00,194 valid 000 1.511810e-02 -0.331012
2019-11-06 01:34:09,969 valid 050 1.391531e-02 -1.323579
2019-11-06 01:34:18,671 validation loss; R2: 1.384875e-02 -1.362956
2019-11-06 01:34:18,739 epoch 291 lr 1.000000e-04
2019-11-06 01:34:19,466 train 000 1.312746e-02 -1.177868
2019-11-06 01:34:29,696 train 050 1.521792e-02 -0.866077
2019-11-06 01:34:39,880 train 100 1.553725e-02 -0.721248
2019-11-06 01:34:50,053 train 150 1.573617e-02 -0.668870
2019-11-06 01:35:00,211 train 200 1.571474e-02 -1.254844
2019-11-06 01:35:10,350 train 250 1.570621e-02 -1.114625
2019-11-06 01:35:20,533 train 300 1.569300e-02 -1.090590
2019-11-06 01:35:30,664 train 350 1.569927e-02 -1.046788
2019-11-06 01:35:40,804 train 400 1.573727e-02 -1.018009
2019-11-06 01:35:50,933 train 450 1.577564e-02 -1.748639
2019-11-06 01:36:01,117 train 500 1.575729e-02 -1.679289
2019-11-06 01:36:11,298 train 550 1.576687e-02 -1.582855
2019-11-06 01:36:21,504 train 600 1.577899e-02 -1.534319
2019-11-06 01:36:31,701 train 650 1.578476e-02 -1.470563
2019-11-06 01:36:41,850 train 700 1.574809e-02 -1.403062
2019-11-06 01:36:51,989 train 750 1.574004e-02 -1.350719
2019-11-06 01:37:02,108 train 800 1.572651e-02 -1.323753
2019-11-06 01:37:12,258 train 850 1.577596e-02 -1.288596
2019-11-06 01:37:15,274 training loss; R2: 1.579189e-02 -1.282073
2019-11-06 01:37:15,779 valid 000 1.281514e-02 -0.425835
2019-11-06 01:37:25,546 valid 050 1.360467e-02 -0.964782
2019-11-06 01:37:34,199 validation loss; R2: 1.353533e-02 -0.850883
2019-11-06 01:37:34,274 epoch 292 lr 1.000000e-04
2019-11-06 01:37:34,984 train 000 1.688605e-02 0.110803
2019-11-06 01:37:45,133 train 050 1.572662e-02 -0.680813
2019-11-06 01:37:55,320 train 100 1.552644e-02 -0.554660
2019-11-06 01:38:05,478 train 150 1.560650e-02 -0.603166
2019-11-06 01:38:15,638 train 200 1.568829e-02 -0.661442
2019-11-06 01:38:25,722 train 250 1.559584e-02 -0.997776
2019-11-06 01:38:35,778 train 300 1.561204e-02 -0.943261
2019-11-06 01:38:45,873 train 350 1.564317e-02 -0.936123
2019-11-06 01:38:55,973 train 400 1.569201e-02 -0.894685
2019-11-06 01:39:06,075 train 450 1.569907e-02 -0.875232
2019-11-06 01:39:16,267 train 500 1.576603e-02 -0.853852
2019-11-06 01:39:26,410 train 550 1.577239e-02 -0.835954
2019-11-06 01:39:36,549 train 600 1.577072e-02 -0.813200
2019-11-06 01:39:46,705 train 650 1.578226e-02 -0.804764
2019-11-06 01:39:56,855 train 700 1.575313e-02 -0.789985
2019-11-06 01:40:07,013 train 750 1.574678e-02 -0.790411
2019-11-06 01:40:17,156 train 800 1.570868e-02 -0.776254
2019-11-06 01:40:27,305 train 850 1.571181e-02 -0.761172
2019-11-06 01:40:30,324 training loss; R2: 1.571931e-02 -0.758322
2019-11-06 01:40:30,934 valid 000 1.266995e-02 -0.121991
2019-11-06 01:40:40,601 valid 050 1.315706e-02 -0.882836
2019-11-06 01:40:49,364 validation loss; R2: 1.328663e-02 -0.936280
2019-11-06 01:40:49,449 epoch 293 lr 1.000000e-04
2019-11-06 01:40:50,217 train 000 1.606841e-02 -0.827841
2019-11-06 01:41:00,388 train 050 1.597005e-02 -2.431214
2019-11-06 01:41:10,578 train 100 1.601939e-02 -1.663482
2019-11-06 01:41:20,755 train 150 1.599942e-02 -1.350962
2019-11-06 01:41:30,931 train 200 1.594849e-02 -1.217560
2019-11-06 01:41:41,093 train 250 1.594018e-02 -1.095965
2019-11-06 01:41:51,279 train 300 1.586203e-02 -1.048561
2019-11-06 01:42:01,377 train 350 1.585229e-02 -1.034518
2019-11-06 01:42:11,503 train 400 1.583836e-02 -0.978560
2019-11-06 01:42:21,628 train 450 1.584323e-02 -0.933631
2019-11-06 01:42:31,761 train 500 1.582139e-02 -0.916088
2019-11-06 01:42:41,956 train 550 1.582598e-02 -0.878433
2019-11-06 01:42:52,078 train 600 1.579298e-02 -0.861432
2019-11-06 01:43:02,225 train 650 1.578890e-02 -0.838311
2019-11-06 01:43:12,360 train 700 1.577135e-02 -0.836397
2019-11-06 01:43:22,519 train 750 1.577082e-02 -0.820022
2019-11-06 01:43:32,678 train 800 1.576816e-02 -0.797187
2019-11-06 01:43:42,859 train 850 1.575994e-02 -0.785722
2019-11-06 01:43:45,891 training loss; R2: 1.576478e-02 -0.779291
2019-11-06 01:43:46,408 valid 000 1.639573e-02 0.197034
2019-11-06 01:43:56,222 valid 050 1.417489e-02 -1.199296
2019-11-06 01:44:04,851 validation loss; R2: 1.410949e-02 -1.025502
2019-11-06 01:44:04,916 epoch 294 lr 1.000000e-04
2019-11-06 01:44:05,613 train 000 1.455890e-02 -1.009257
2019-11-06 01:44:15,775 train 050 1.569722e-02 -1.002916
2019-11-06 01:44:25,954 train 100 1.557990e-02 -0.753991
2019-11-06 01:44:36,110 train 150 1.574970e-02 -0.782527
2019-11-06 01:44:46,276 train 200 1.568931e-02 -0.884796
2019-11-06 01:44:56,408 train 250 1.559547e-02 -0.846749
2019-11-06 01:45:06,573 train 300 1.563472e-02 -0.822892
2019-11-06 01:45:16,718 train 350 1.564459e-02 -0.798357
2019-11-06 01:45:26,871 train 400 1.565785e-02 -0.785937
2019-11-06 01:45:37,014 train 450 1.563892e-02 -0.763093
2019-11-06 01:45:47,169 train 500 1.566991e-02 -0.778748
2019-11-06 01:45:57,311 train 550 1.579269e-02 -0.761803
2019-11-06 01:46:07,472 train 600 1.582712e-02 -0.733067
2019-11-06 01:46:17,643 train 650 1.583537e-02 -0.739528
2019-11-06 01:46:27,813 train 700 1.587266e-02 -0.721720
2019-11-06 01:46:37,971 train 750 1.585029e-02 -0.707944
2019-11-06 01:46:48,133 train 800 1.584209e-02 -0.693449
2019-11-06 01:46:58,295 train 850 1.583732e-02 -0.694588
2019-11-06 01:47:01,331 training loss; R2: 1.584056e-02 -0.698446
2019-11-06 01:47:01,859 valid 000 1.143032e-02 0.207929
2019-11-06 01:47:12,116 valid 050 1.349104e-02 -1.013161
2019-11-06 01:47:21,313 validation loss; R2: 1.352931e-02 -0.981915
2019-11-06 01:47:21,385 epoch 295 lr 1.000000e-04
2019-11-06 01:47:22,138 train 000 1.446054e-02 -0.130053
2019-11-06 01:47:32,418 train 050 1.555893e-02 -0.893727
2019-11-06 01:47:42,828 train 100 1.551313e-02 -0.886388
2019-11-06 01:47:53,025 train 150 1.567560e-02 -0.815807
2019-11-06 01:48:03,222 train 200 1.569194e-02 -0.788158
2019-11-06 01:48:13,346 train 250 1.574309e-02 -0.839325
2019-11-06 01:48:23,454 train 300 1.573603e-02 -0.829490
2019-11-06 01:48:33,564 train 350 1.579871e-02 -0.793560
2019-11-06 01:48:43,684 train 400 1.577003e-02 -0.786808
2019-11-06 01:48:53,749 train 450 1.574635e-02 -0.804580
2019-11-06 01:49:03,855 train 500 1.576038e-02 -0.810097
2019-11-06 01:49:13,903 train 550 1.576144e-02 -0.796190
2019-11-06 01:49:23,928 train 600 1.578384e-02 -0.773528
2019-11-06 01:49:33,973 train 650 1.578820e-02 -0.759957
2019-11-06 01:49:44,068 train 700 1.576644e-02 -0.760783
2019-11-06 01:49:54,183 train 750 1.578652e-02 -0.778007
2019-11-06 01:50:04,291 train 800 1.575917e-02 -0.933672
2019-11-06 01:50:14,441 train 850 1.578209e-02 -0.921271
2019-11-06 01:50:17,484 training loss; R2: 1.578244e-02 -0.910658
2019-11-06 01:50:18,026 valid 000 1.525800e-02 -0.449232
2019-11-06 01:50:28,361 valid 050 1.525826e-02 -0.882977
2019-11-06 01:50:37,495 validation loss; R2: 1.505929e-02 -1.031954
2019-11-06 01:50:37,566 epoch 296 lr 1.000000e-04
2019-11-06 01:50:38,276 train 000 1.486031e-02 -0.703280
2019-11-06 01:50:48,817 train 050 1.610314e-02 -1.096383
2019-11-06 01:50:59,024 train 100 1.591813e-02 -0.794986
2019-11-06 01:51:09,186 train 150 1.584774e-02 -0.902645
2019-11-06 01:51:19,390 train 200 1.572727e-02 -2.948002
2019-11-06 01:51:29,560 train 250 1.572799e-02 -2.495813
2019-11-06 01:51:39,756 train 300 1.575077e-02 -2.220863
2019-11-06 01:51:49,909 train 350 1.575439e-02 -2.022516
2019-11-06 01:52:00,064 train 400 1.575602e-02 -1.861393
2019-11-06 01:52:10,209 train 450 1.576750e-02 -1.733466
2019-11-06 01:52:20,362 train 500 1.576660e-02 -1.616905
2019-11-06 01:52:30,514 train 550 1.577320e-02 -1.517420
2019-11-06 01:52:40,681 train 600 1.572577e-02 -1.451936
2019-11-06 01:52:50,847 train 650 1.570879e-02 -1.408904
2019-11-06 01:53:01,039 train 700 1.573457e-02 -1.350317
2019-11-06 01:53:11,210 train 750 1.572216e-02 -1.305289
2019-11-06 01:53:21,390 train 800 1.574855e-02 -1.272038
2019-11-06 01:53:31,594 train 850 1.576613e-02 -1.229366
2019-11-06 01:53:34,656 training loss; R2: 1.577404e-02 -1.231364
2019-11-06 01:53:35,196 valid 000 1.134563e-02 -1.695063
2019-11-06 01:53:45,272 valid 050 1.294631e-02 -1.030735
2019-11-06 01:53:53,971 validation loss; R2: 1.305221e-02 -0.991073
2019-11-06 01:53:54,037 epoch 297 lr 1.000000e-04
2019-11-06 01:53:54,705 train 000 1.681275e-02 -0.099861
2019-11-06 01:54:05,001 train 050 1.618134e-02 -0.478506
2019-11-06 01:54:15,172 train 100 1.598676e-02 -0.717400
2019-11-06 01:54:25,340 train 150 1.600245e-02 -0.716264
2019-11-06 01:54:35,482 train 200 1.589136e-02 -0.672378
2019-11-06 01:54:45,655 train 250 1.589708e-02 -0.701136
2019-11-06 01:54:55,855 train 300 1.592019e-02 -0.667628
2019-11-06 01:55:06,146 train 350 1.592892e-02 -0.691884
2019-11-06 01:55:16,453 train 400 1.591689e-02 -0.704015
2019-11-06 01:55:26,754 train 450 1.586480e-02 -0.676156
2019-11-06 01:55:36,904 train 500 1.587121e-02 -0.667932
2019-11-06 01:55:47,035 train 550 1.585972e-02 -0.700292
2019-11-06 01:55:57,171 train 600 1.585447e-02 -0.700633
2019-11-06 01:56:07,315 train 650 1.581115e-02 -0.676335
2019-11-06 01:56:17,380 train 700 1.581234e-02 -0.699589
2019-11-06 01:56:27,449 train 750 1.580512e-02 -0.700522
2019-11-06 01:56:37,520 train 800 1.580230e-02 -0.695738
2019-11-06 01:56:47,580 train 850 1.580728e-02 -0.697709
2019-11-06 01:56:50,588 training loss; R2: 1.581888e-02 -0.698418
2019-11-06 01:56:51,108 valid 000 1.513049e-02 -1.154408
2019-11-06 01:57:00,897 valid 050 1.400796e-02 -1.342596
2019-11-06 01:57:09,587 validation loss; R2: 1.388174e-02 -1.302228
2019-11-06 01:57:09,672 epoch 298 lr 1.000000e-04
2019-11-06 01:57:10,423 train 000 1.658210e-02 -0.056408
2019-11-06 01:57:20,615 train 050 1.553694e-02 -0.805696
2019-11-06 01:57:30,798 train 100 1.535132e-02 -0.714123
2019-11-06 01:57:40,968 train 150 1.552225e-02 -0.724712
2019-11-06 01:57:51,132 train 200 1.563172e-02 -0.697027
2019-11-06 01:58:01,295 train 250 1.568182e-02 -0.683556
2019-11-06 01:58:11,448 train 300 1.565838e-02 -0.699768
2019-11-06 01:58:21,578 train 350 1.567693e-02 -0.680529
2019-11-06 01:58:31,738 train 400 1.568619e-02 -0.681279
2019-11-06 01:58:41,875 train 450 1.567576e-02 -0.765811
2019-11-06 01:58:51,997 train 500 1.569474e-02 -0.753509
2019-11-06 01:59:02,101 train 550 1.568785e-02 -0.758026
2019-11-06 01:59:12,232 train 600 1.567052e-02 -0.754709
2019-11-06 01:59:22,364 train 650 1.564700e-02 -14.936611
2019-11-06 01:59:32,512 train 700 1.566786e-02 -13.908893
2019-11-06 01:59:42,669 train 750 1.565803e-02 -13.059952
2019-11-06 01:59:52,823 train 800 1.567150e-02 -12.289874
2019-11-06 02:00:02,981 train 850 1.570864e-02 -11.607366
2019-11-06 02:00:06,014 training loss; R2: 1.570893e-02 -11.412582
2019-11-06 02:00:06,529 valid 000 1.355726e-02 -11.256284
2019-11-06 02:00:16,342 valid 050 1.424319e-02 -1.817037
2019-11-06 02:00:24,974 validation loss; R2: 1.406908e-02 -1.511317
2019-11-06 02:00:25,045 epoch 299 lr 1.000000e-04
2019-11-06 02:00:25,781 train 000 1.434993e-02 -0.082617
2019-11-06 02:00:35,957 train 050 1.578477e-02 -0.795736
2019-11-06 02:00:46,153 train 100 1.569426e-02 -0.770700
2019-11-06 02:00:56,317 train 150 1.571440e-02 -0.882143
2019-11-06 02:01:06,482 train 200 1.571669e-02 -0.893632
2019-11-06 02:01:16,681 train 250 1.575846e-02 -0.837897
2019-11-06 02:01:26,871 train 300 1.577928e-02 -0.809360
2019-11-06 02:01:37,038 train 350 1.576295e-02 -0.807596
2019-11-06 02:01:47,206 train 400 1.569407e-02 -0.798367
2019-11-06 02:01:57,360 train 450 1.568180e-02 -0.773442
2019-11-06 02:02:07,529 train 500 1.575616e-02 -0.761507
2019-11-06 02:02:17,681 train 550 1.575718e-02 -0.744336
2019-11-06 02:02:27,832 train 600 1.575000e-02 -0.723994
2019-11-06 02:02:38,000 train 650 1.573988e-02 -0.704103
2019-11-06 02:02:48,181 train 700 1.571935e-02 -0.690534
2019-11-06 02:02:58,328 train 750 1.570952e-02 -0.692143
2019-11-06 02:03:08,516 train 800 1.573562e-02 -0.689016
2019-11-06 02:03:18,677 train 850 1.570829e-02 -0.685921
2019-11-06 02:03:21,710 training loss; R2: 1.571426e-02 -0.684050
2019-11-06 02:03:22,244 valid 000 1.210862e-02 -0.025259
2019-11-06 02:03:32,049 valid 050 1.308511e-02 -1.221205
2019-11-06 02:03:40,727 validation loss; R2: 1.318158e-02 -1.176390
2019-11-06 02:03:40,792 epoch 300 lr 1.000000e-04
2019-11-06 02:03:41,490 train 000 1.535273e-02 0.042962
2019-11-06 02:03:51,712 train 050 1.551536e-02 -0.532841
2019-11-06 02:04:01,918 train 100 1.576878e-02 -0.619830
2019-11-06 02:04:12,140 train 150 1.575231e-02 -0.639104
2019-11-06 02:04:22,351 train 200 1.579767e-02 -0.586106
2019-11-06 02:04:32,625 train 250 1.584228e-02 -0.686752
2019-11-06 02:04:42,805 train 300 1.582878e-02 -0.702361
2019-11-06 02:04:52,978 train 350 1.577952e-02 -0.706806
2019-11-06 02:05:03,174 train 400 1.572988e-02 -0.704022
2019-11-06 02:05:13,353 train 450 1.572416e-02 -0.953931
2019-11-06 02:05:23,564 train 500 1.570570e-02 -0.947298
2019-11-06 02:05:33,776 train 550 1.570723e-02 -0.911246
2019-11-06 02:05:43,989 train 600 1.572448e-02 -0.874605
2019-11-06 02:05:54,160 train 650 1.573561e-02 -0.863679
2019-11-06 02:06:04,332 train 700 1.573542e-02 -0.869756
2019-11-06 02:06:14,501 train 750 1.569526e-02 -0.866011
2019-11-06 02:06:24,645 train 800 1.569722e-02 -0.865929
2019-11-06 02:06:34,803 train 850 1.572103e-02 -0.908245
2019-11-06 02:06:37,830 training loss; R2: 1.572798e-02 -0.899358
2019-11-06 02:06:38,388 valid 000 1.660227e-02 -0.495252
2019-11-06 02:06:48,122 valid 050 1.335370e-02 -0.875836
2019-11-06 02:06:56,758 validation loss; R2: 1.342358e-02 -0.951304
2019-11-06 02:06:56,821 epoch 301 lr 1.000000e-04
2019-11-06 02:06:57,540 train 000 1.730579e-02 -0.163452
2019-11-06 02:07:07,738 train 050 1.568315e-02 -0.753551
2019-11-06 02:07:17,924 train 100 1.562724e-02 -0.639657
2019-11-06 02:07:28,117 train 150 1.565747e-02 -0.598447
2019-11-06 02:07:38,306 train 200 1.555566e-02 -0.693076
2019-11-06 02:07:48,449 train 250 1.560453e-02 -0.652400
2019-11-06 02:07:58,567 train 300 1.566232e-02 -0.644356
2019-11-06 02:08:08,692 train 350 1.570889e-02 -0.672209
2019-11-06 02:08:18,811 train 400 1.572665e-02 -0.687892
2019-11-06 02:08:28,926 train 450 1.573380e-02 -0.726205
2019-11-06 02:08:39,051 train 500 1.569924e-02 -0.724452
2019-11-06 02:08:49,175 train 550 1.573290e-02 -0.737163
2019-11-06 02:08:59,326 train 600 1.571122e-02 -0.725323
2019-11-06 02:09:09,501 train 650 1.570303e-02 -0.714737
2019-11-06 02:09:19,683 train 700 1.567444e-02 -0.697024
2019-11-06 02:09:29,847 train 750 1.567037e-02 -0.703114
2019-11-06 02:09:40,012 train 800 1.565948e-02 -0.692607
2019-11-06 02:09:50,164 train 850 1.567478e-02 -0.692712
2019-11-06 02:09:53,200 training loss; R2: 1.568414e-02 -0.692350
2019-11-06 02:09:53,792 valid 000 1.202133e-02 0.019013
2019-11-06 02:10:03,759 valid 050 1.371163e-02 -1.100762
2019-11-06 02:10:12,692 validation loss; R2: 1.380194e-02 -1.181387
2019-11-06 02:10:12,755 epoch 302 lr 1.000000e-04
2019-11-06 02:10:13,502 train 000 1.551388e-02 -0.905463
2019-11-06 02:10:23,797 train 050 1.507117e-02 -0.824572
2019-11-06 02:10:34,026 train 100 1.553420e-02 -0.723208
2019-11-06 02:10:44,262 train 150 1.561766e-02 -0.656193
2019-11-06 02:10:54,463 train 200 1.566806e-02 -0.987375
2019-11-06 02:11:04,680 train 250 1.564701e-02 -0.946751
2019-11-06 02:11:14,850 train 300 1.568279e-02 -0.928795
2019-11-06 02:11:25,043 train 350 1.571611e-02 -0.868523
2019-11-06 02:11:35,193 train 400 1.575060e-02 -0.823508
2019-11-06 02:11:45,371 train 450 1.576146e-02 -0.808153
2019-11-06 02:11:55,583 train 500 1.574103e-02 -0.816043
2019-11-06 02:12:05,822 train 550 1.572034e-02 -0.815187
2019-11-06 02:12:15,975 train 600 1.573269e-02 -0.810558
2019-11-06 02:12:26,172 train 650 1.579297e-02 -0.795698
2019-11-06 02:12:36,342 train 700 1.577318e-02 -0.793931
2019-11-06 02:12:46,526 train 750 1.574384e-02 -0.790108
2019-11-06 02:12:56,668 train 800 1.573800e-02 -0.796939
2019-11-06 02:13:06,888 train 850 1.574653e-02 -0.860467
2019-11-06 02:13:09,918 training loss; R2: 1.574287e-02 -0.849969
2019-11-06 02:13:10,503 valid 000 1.375526e-02 -2.277057
2019-11-06 02:13:20,318 valid 050 1.344467e-02 -1.297929
2019-11-06 02:13:29,000 validation loss; R2: 1.351570e-02 -1.040622
2019-11-06 02:13:29,066 epoch 303 lr 1.000000e-04
2019-11-06 02:13:29,742 train 000 1.396629e-02 -0.538163
2019-11-06 02:13:39,928 train 050 1.590633e-02 -0.741035
2019-11-06 02:13:50,084 train 100 1.598564e-02 -0.641620
2019-11-06 02:14:00,349 train 150 1.577213e-02 -0.628861
2019-11-06 02:14:10,451 train 200 1.565087e-02 -0.777395
2019-11-06 02:14:20,567 train 250 1.568315e-02 -0.741496
2019-11-06 02:14:30,764 train 300 1.570372e-02 -0.876444
2019-11-06 02:14:40,906 train 350 1.569621e-02 -0.888496
2019-11-06 02:14:50,995 train 400 1.567528e-02 -0.873453
2019-11-06 02:15:01,183 train 450 1.568727e-02 -0.845540
2019-11-06 02:15:11,275 train 500 1.567726e-02 -0.836046
2019-11-06 02:15:21,376 train 550 1.566936e-02 -0.834699
2019-11-06 02:15:31,555 train 600 1.566070e-02 -0.800216
2019-11-06 02:15:41,684 train 650 1.570749e-02 -0.784872
2019-11-06 02:15:51,755 train 700 1.570413e-02 -0.769491
2019-11-06 02:16:01,943 train 750 1.569836e-02 -0.762324
2019-11-06 02:16:12,058 train 800 1.571731e-02 -0.763950
2019-11-06 02:16:22,146 train 850 1.573916e-02 -0.761305
2019-11-06 02:16:25,171 training loss; R2: 1.574308e-02 -0.761370
2019-11-06 02:16:25,684 valid 000 1.158437e-02 0.137400
2019-11-06 02:16:35,492 valid 050 1.348168e-02 -1.996584
2019-11-06 02:16:44,153 validation loss; R2: 1.360318e-02 -1.678127
2019-11-06 02:16:44,227 epoch 304 lr 1.000000e-04
2019-11-06 02:16:44,973 train 000 1.227141e-02 -4.834102
2019-11-06 02:16:55,131 train 050 1.553168e-02 -1.026740
2019-11-06 02:17:05,293 train 100 1.576208e-02 -0.847699
2019-11-06 02:17:15,468 train 150 1.566975e-02 -0.783224
2019-11-06 02:17:25,689 train 200 1.570758e-02 -0.710733
2019-11-06 02:17:35,834 train 250 1.572016e-02 -0.689223
2019-11-06 02:17:45,968 train 300 1.572964e-02 -0.700867
2019-11-06 02:17:56,155 train 350 1.575021e-02 -0.675960
2019-11-06 02:18:06,370 train 400 1.572242e-02 -0.675605
2019-11-06 02:18:16,562 train 450 1.571176e-02 -0.680266
2019-11-06 02:18:26,754 train 500 1.571216e-02 -0.681568
2019-11-06 02:18:36,961 train 550 1.569219e-02 -0.672514
2019-11-06 02:18:47,170 train 600 1.568461e-02 -0.672010
2019-11-06 02:18:57,395 train 650 1.570256e-02 -0.685249
2019-11-06 02:19:07,584 train 700 1.570467e-02 -0.687503
2019-11-06 02:19:17,779 train 750 1.572753e-02 -0.679417
2019-11-06 02:19:27,966 train 800 1.573140e-02 -0.685068
2019-11-06 02:19:38,135 train 850 1.577649e-02 -0.680842
2019-11-06 02:19:41,170 training loss; R2: 1.578549e-02 -0.674073
2019-11-06 02:19:41,684 valid 000 1.554016e-02 -0.101206
2019-11-06 02:19:51,525 valid 050 1.330373e-02 -0.439617
2019-11-06 02:20:00,220 validation loss; R2: 1.345374e-02 -0.608318
2019-11-06 02:20:00,285 epoch 305 lr 1.000000e-04
2019-11-06 02:20:01,018 train 000 1.597750e-02 0.044571
2019-11-06 02:20:11,284 train 050 1.618091e-02 -0.612020
2019-11-06 02:20:21,476 train 100 1.597088e-02 -0.609363
2019-11-06 02:20:31,649 train 150 1.605082e-02 -0.574766
2019-11-06 02:20:41,784 train 200 1.599263e-02 -0.590458
2019-11-06 02:20:51,946 train 250 1.593000e-02 -0.616500
2019-11-06 02:21:02,065 train 300 1.590423e-02 -0.622096
2019-11-06 02:21:12,206 train 350 1.587987e-02 -0.590043
2019-11-06 02:21:22,349 train 400 1.585007e-02 -0.589498
2019-11-06 02:21:32,517 train 450 1.579911e-02 -0.622136
2019-11-06 02:21:42,642 train 500 1.582500e-02 -0.646237
2019-11-06 02:21:52,811 train 550 1.583148e-02 -0.629146
2019-11-06 02:22:02,937 train 600 1.580297e-02 -0.623264
2019-11-06 02:22:13,114 train 650 1.579574e-02 -0.622797
2019-11-06 02:22:23,279 train 700 1.583221e-02 -0.626575
2019-11-06 02:22:33,438 train 750 1.580936e-02 -0.642750
2019-11-06 02:22:43,581 train 800 1.581936e-02 -0.640239
2019-11-06 02:22:53,758 train 850 1.583089e-02 -0.650044
2019-11-06 02:22:56,803 training loss; R2: 1.583353e-02 -0.641519
2019-11-06 02:22:57,378 valid 000 2.153624e-02 -1.155785
2019-11-06 02:23:07,192 valid 050 1.912360e-02 -3.082569
2019-11-06 02:23:15,879 validation loss; R2: 1.910479e-02 -2.753962
2019-11-06 02:23:15,950 epoch 306 lr 1.000000e-04
2019-11-06 02:23:16,661 train 000 1.553619e-02 -1.182260
2019-11-06 02:23:26,894 train 050 1.612872e-02 -0.741652
2019-11-06 02:23:37,090 train 100 1.594810e-02 -0.603081
2019-11-06 02:23:47,267 train 150 1.597302e-02 -0.683645
2019-11-06 02:23:57,447 train 200 1.592109e-02 -0.720604
2019-11-06 02:24:07,632 train 250 1.585910e-02 -0.740231
2019-11-06 02:24:17,815 train 300 1.586810e-02 -0.700639
2019-11-06 02:24:27,977 train 350 1.583034e-02 -0.701471
2019-11-06 02:24:38,194 train 400 1.579682e-02 -0.741197
2019-11-06 02:24:48,396 train 450 1.580618e-02 -0.740167
2019-11-06 02:24:58,630 train 500 1.577631e-02 -0.744782
2019-11-06 02:25:08,828 train 550 1.573329e-02 -0.724643
2019-11-06 02:25:19,020 train 600 1.572649e-02 -0.757149
2019-11-06 02:25:29,203 train 650 1.574260e-02 -0.750875
2019-11-06 02:25:39,401 train 700 1.575883e-02 -0.738212
2019-11-06 02:25:49,574 train 750 1.573460e-02 -0.722175
2019-11-06 02:25:59,749 train 800 1.573933e-02 -0.714178
2019-11-06 02:26:09,986 train 850 1.574304e-02 -0.716916
2019-11-06 02:26:13,036 training loss; R2: 1.573981e-02 -0.712447
2019-11-06 02:26:13,590 valid 000 1.291023e-02 -5.454936
2019-11-06 02:26:23,385 valid 050 1.318788e-02 -0.802807
2019-11-06 02:26:32,356 validation loss; R2: 1.313115e-02 -8.421445
2019-11-06 02:26:32,425 epoch 307 lr 1.000000e-04
2019-11-06 02:26:33,106 train 000 1.576294e-02 -0.040915
2019-11-06 02:26:43,364 train 050 1.607326e-02 -0.723914
2019-11-06 02:26:53,550 train 100 1.601629e-02 -0.642715
2019-11-06 02:27:03,748 train 150 1.586700e-02 -0.598594
2019-11-06 02:27:13,944 train 200 1.592961e-02 -0.619790
2019-11-06 02:27:24,141 train 250 1.590358e-02 -0.648656
2019-11-06 02:27:34,327 train 300 1.578467e-02 -0.636057
2019-11-06 02:27:44,535 train 350 1.584857e-02 -0.611734
2019-11-06 02:27:54,715 train 400 1.581790e-02 -0.651462
2019-11-06 02:28:04,910 train 450 1.581002e-02 -0.681661
2019-11-06 02:28:15,109 train 500 1.577200e-02 -2.210839
2019-11-06 02:28:25,330 train 550 1.574670e-02 -2.049588
2019-11-06 02:28:35,527 train 600 1.573979e-02 -1.929365
2019-11-06 02:28:45,720 train 650 1.568234e-02 -1.832918
2019-11-06 02:28:55,907 train 700 1.569530e-02 -1.738536
2019-11-06 02:29:06,112 train 750 1.569676e-02 -1.670012
2019-11-06 02:29:16,312 train 800 1.571651e-02 -1.621607
2019-11-06 02:29:26,537 train 850 1.571860e-02 -1.580501
2019-11-06 02:29:29,584 training loss; R2: 1.572059e-02 -1.560515
2019-11-06 02:29:30,104 valid 000 1.505970e-02 -0.379687
2019-11-06 02:29:39,959 valid 050 1.352140e-02 -0.726199
2019-11-06 02:29:48,684 validation loss; R2: 1.347803e-02 -0.885189
2019-11-06 02:29:48,749 epoch 308 lr 1.000000e-04
2019-11-06 02:29:49,409 train 000 1.460615e-02 -1.965189
2019-11-06 02:29:59,597 train 050 1.599588e-02 -0.892776
2019-11-06 02:30:09,834 train 100 1.585936e-02 -0.800969
2019-11-06 02:30:20,025 train 150 1.582385e-02 -0.820101
2019-11-06 02:30:30,240 train 200 1.570451e-02 -0.747764
2019-11-06 02:30:40,450 train 250 1.574443e-02 -0.734306
2019-11-06 02:30:50,634 train 300 1.572348e-02 -0.696644
2019-11-06 02:31:00,826 train 350 1.568380e-02 -1.739090
2019-11-06 02:31:10,990 train 400 1.576210e-02 -1.603083
2019-11-06 02:31:21,151 train 450 1.582889e-02 -1.494356
2019-11-06 02:31:31,311 train 500 1.581525e-02 -1.478103
2019-11-06 02:31:41,465 train 550 1.576911e-02 -1.412831
2019-11-06 02:31:51,639 train 600 1.576030e-02 -1.358207
2019-11-06 02:32:01,827 train 650 1.577982e-02 -1.292071
2019-11-06 02:32:12,009 train 700 1.575051e-02 -1.265541
2019-11-06 02:32:22,208 train 750 1.574118e-02 -1.227729
2019-11-06 02:32:32,428 train 800 1.575861e-02 -1.183809
2019-11-06 02:32:42,629 train 850 1.574934e-02 -1.144568
2019-11-06 02:32:45,669 training loss; R2: 1.575631e-02 -1.131320
2019-11-06 02:32:46,191 valid 000 1.164392e-02 0.084701
2019-11-06 02:32:56,051 valid 050 1.284413e-02 -1.497632
2019-11-06 02:33:04,729 validation loss; R2: 1.262482e-02 -1.307116
2019-11-06 02:33:04,794 epoch 309 lr 1.000000e-04
2019-11-06 02:33:05,493 train 000 1.632325e-02 0.067871
2019-11-06 02:33:15,643 train 050 1.612419e-02 -0.583259
2019-11-06 02:33:25,752 train 100 1.581244e-02 -0.595020
2019-11-06 02:33:35,849 train 150 1.575287e-02 -0.620226
2019-11-06 02:33:45,880 train 200 1.578242e-02 -0.641420
2019-11-06 02:33:55,924 train 250 1.569149e-02 -0.846486
2019-11-06 02:34:05,977 train 300 1.566803e-02 -0.857224
2019-11-06 02:34:16,039 train 350 1.572327e-02 -0.823699
2019-11-06 02:34:26,070 train 400 1.573627e-02 -0.797804
2019-11-06 02:34:36,120 train 450 1.575755e-02 -0.770682
2019-11-06 02:34:46,157 train 500 1.575853e-02 -0.853382
2019-11-06 02:34:56,203 train 550 1.576404e-02 -0.946732
2019-11-06 02:35:06,253 train 600 1.578728e-02 -0.905264
2019-11-06 02:35:16,325 train 650 1.580572e-02 -0.898376
2019-11-06 02:35:26,392 train 700 1.579805e-02 -0.887784
2019-11-06 02:35:36,476 train 750 1.577284e-02 -0.873450
2019-11-06 02:35:46,589 train 800 1.576679e-02 -0.854199
2019-11-06 02:35:56,756 train 850 1.577812e-02 -0.859108
2019-11-06 02:35:59,786 training loss; R2: 1.576608e-02 -0.853029
2019-11-06 02:36:00,311 valid 000 1.404779e-02 -0.615849
2019-11-06 02:36:10,126 valid 050 1.384861e-02 -0.767405
2019-11-06 02:36:18,793 validation loss; R2: 1.370978e-02 -0.769650
2019-11-06 02:36:18,857 epoch 310 lr 1.000000e-04
2019-11-06 02:36:19,586 train 000 1.488447e-02 -3.581160
2019-11-06 02:36:29,728 train 050 1.574967e-02 -0.644921
2019-11-06 02:36:39,862 train 100 1.587502e-02 -5.204100
2019-11-06 02:36:50,045 train 150 1.596532e-02 -3.709481
2019-11-06 02:37:00,123 train 200 1.592148e-02 -2.941781
2019-11-06 02:37:10,218 train 250 1.594326e-02 -2.468453
2019-11-06 02:37:20,389 train 300 1.587173e-02 -2.151277
2019-11-06 02:37:30,429 train 350 1.588570e-02 -1.905672
2019-11-06 02:37:40,536 train 400 1.588276e-02 -1.778589
2019-11-06 02:37:50,695 train 450 1.586248e-02 -1.678803
2019-11-06 02:38:00,914 train 500 1.586779e-02 -1.559295
2019-11-06 02:38:11,107 train 550 1.582494e-02 -1.496358
2019-11-06 02:38:21,289 train 600 1.585341e-02 -1.450263
2019-11-06 02:38:31,501 train 650 1.585807e-02 -1.386398
2019-11-06 02:38:41,646 train 700 1.584986e-02 -1.356794
2019-11-06 02:38:51,725 train 750 1.583456e-02 -1.311699
2019-11-06 02:39:01,817 train 800 1.583474e-02 -1.399100
2019-11-06 02:39:11,958 train 850 1.582288e-02 -1.348779
2019-11-06 02:39:14,986 training loss; R2: 1.581315e-02 -1.335773
2019-11-06 02:39:15,506 valid 000 1.367107e-02 -0.161804
2019-11-06 02:39:25,297 valid 050 1.255467e-02 -0.998536
2019-11-06 02:39:33,972 validation loss; R2: 1.259978e-02 -0.923439
2019-11-06 02:39:34,037 epoch 311 lr 1.000000e-04
2019-11-06 02:39:34,702 train 000 1.283001e-02 0.072480
2019-11-06 02:39:44,922 train 050 1.533832e-02 -1.332246
2019-11-06 02:39:55,117 train 100 1.544452e-02 -0.976297
2019-11-06 02:40:05,290 train 150 1.557939e-02 -0.899651
2019-11-06 02:40:15,468 train 200 1.549914e-02 -0.868643
2019-11-06 02:40:25,636 train 250 1.553131e-02 -0.824877
2019-11-06 02:40:35,817 train 300 1.556802e-02 -0.853252
2019-11-06 02:40:45,962 train 350 1.553777e-02 -0.858656
2019-11-06 02:40:56,102 train 400 1.556431e-02 -0.857313
2019-11-06 02:41:06,229 train 450 1.562134e-02 -0.823877
2019-11-06 02:41:16,368 train 500 1.563311e-02 -0.814163
2019-11-06 02:41:26,489 train 550 1.564597e-02 -0.874905
2019-11-06 02:41:36,637 train 600 1.562012e-02 -0.836282
2019-11-06 02:41:46,798 train 650 1.561681e-02 -0.823639
2019-11-06 02:41:56,945 train 700 1.563943e-02 -0.808810
2019-11-06 02:42:07,081 train 750 1.565445e-02 -0.799536
2019-11-06 02:42:17,239 train 800 1.565737e-02 -0.807698
2019-11-06 02:42:27,375 train 850 1.565571e-02 -0.803356
2019-11-06 02:42:30,414 training loss; R2: 1.565112e-02 -0.800571
2019-11-06 02:42:31,016 valid 000 1.171180e-02 -1.235941
2019-11-06 02:42:40,746 valid 050 1.278943e-02 -3.385843
2019-11-06 02:42:49,394 validation loss; R2: 1.292678e-02 -2.493028
2019-11-06 02:42:49,458 epoch 312 lr 1.000000e-04
2019-11-06 02:42:50,150 train 000 1.509279e-02 -0.079748
2019-11-06 02:43:00,352 train 050 1.578605e-02 -0.642600
2019-11-06 02:43:10,522 train 100 1.582344e-02 -0.678409
2019-11-06 02:43:20,703 train 150 1.569910e-02 -0.634722
2019-11-06 02:43:30,853 train 200 1.565427e-02 -0.648589
2019-11-06 02:43:41,016 train 250 1.562307e-02 -0.653206
2019-11-06 02:43:51,165 train 300 1.567533e-02 -0.660843
2019-11-06 02:44:01,323 train 350 1.568590e-02 -0.656673
2019-11-06 02:44:11,468 train 400 1.570211e-02 -0.672950
2019-11-06 02:44:21,650 train 450 1.576488e-02 -0.699442
2019-11-06 02:44:31,765 train 500 1.579424e-02 -0.736727
2019-11-06 02:44:41,911 train 550 1.579896e-02 -0.710522
2019-11-06 02:44:52,075 train 600 1.579861e-02 -0.684508
2019-11-06 02:45:02,261 train 650 1.579999e-02 -0.667580
2019-11-06 02:45:12,474 train 700 1.577791e-02 -0.706510
2019-11-06 02:45:22,647 train 750 1.576487e-02 -0.709568
2019-11-06 02:45:32,793 train 800 1.576342e-02 -0.707287
2019-11-06 02:45:42,870 train 850 1.576133e-02 -0.697806
2019-11-06 02:45:45,882 training loss; R2: 1.575596e-02 -0.701385
2019-11-06 02:45:46,438 valid 000 1.390757e-02 -0.366405
2019-11-06 02:45:56,184 valid 050 1.407065e-02 -0.969431
2019-11-06 02:46:04,848 validation loss; R2: 1.407492e-02 -1.375340
2019-11-06 02:46:04,920 epoch 313 lr 1.000000e-04
2019-11-06 02:46:05,586 train 000 1.506746e-02 -1.482768
2019-11-06 02:46:15,784 train 050 1.554027e-02 -0.720280
2019-11-06 02:46:25,930 train 100 1.556808e-02 -0.819722
2019-11-06 02:46:36,053 train 150 1.562432e-02 -0.785984
2019-11-06 02:46:46,176 train 200 1.570987e-02 -0.840244
2019-11-06 02:46:56,257 train 250 1.563976e-02 -0.782147
2019-11-06 02:47:06,385 train 300 1.561068e-02 -0.734932
2019-11-06 02:47:16,502 train 350 1.553888e-02 -0.746491
2019-11-06 02:47:26,635 train 400 1.550855e-02 -0.769502
2019-11-06 02:47:36,801 train 450 1.553606e-02 -0.765781
2019-11-06 02:47:46,977 train 500 1.554943e-02 -0.742796
2019-11-06 02:47:57,149 train 550 1.555417e-02 -0.754853
2019-11-06 02:48:07,335 train 600 1.559516e-02 -0.750188
2019-11-06 02:48:17,492 train 650 1.558509e-02 -0.745317
2019-11-06 02:48:27,661 train 700 1.562170e-02 -0.733657
2019-11-06 02:48:37,795 train 750 1.563928e-02 -0.722253
2019-11-06 02:48:47,949 train 800 1.566132e-02 -0.701922
2019-11-06 02:48:58,106 train 850 1.566964e-02 -0.945726
2019-11-06 02:49:01,137 training loss; R2: 1.567168e-02 -0.938667
2019-11-06 02:49:01,642 valid 000 1.492666e-02 -0.773418
2019-11-06 02:49:11,450 valid 050 1.318972e-02 -1.046152
2019-11-06 02:49:20,084 validation loss; R2: 1.315352e-02 -1.360167
2019-11-06 02:49:20,151 epoch 314 lr 1.000000e-04
2019-11-06 02:49:20,887 train 000 1.709486e-02 -0.063365
2019-11-06 02:49:31,045 train 050 1.603071e-02 -0.603705
2019-11-06 02:49:41,223 train 100 1.597731e-02 -0.683656
2019-11-06 02:49:51,392 train 150 1.589314e-02 -0.704604
2019-11-06 02:50:01,528 train 200 1.591505e-02 -0.673633
2019-11-06 02:50:11,722 train 250 1.581193e-02 -0.659346
2019-11-06 02:50:21,885 train 300 1.584400e-02 -8.331999
2019-11-06 02:50:32,030 train 350 1.586179e-02 -7.284877
2019-11-06 02:50:42,185 train 400 1.582011e-02 -6.545732
2019-11-06 02:50:52,362 train 450 1.580795e-02 -5.868457
2019-11-06 02:51:02,561 train 500 1.580561e-02 -5.360848
2019-11-06 02:51:12,779 train 550 1.580257e-02 -4.927745
2019-11-06 02:51:22,944 train 600 1.581092e-02 -4.606857
2019-11-06 02:51:33,048 train 650 1.581864e-02 -4.293549
2019-11-06 02:51:43,229 train 700 1.580279e-02 -4.039674
2019-11-06 02:51:53,359 train 750 1.582555e-02 -3.982056
2019-11-06 02:52:03,492 train 800 1.580634e-02 -3.798789
2019-11-06 02:52:13,616 train 850 1.583140e-02 -3.600399
2019-11-06 02:52:16,638 training loss; R2: 1.583889e-02 -3.554157
2019-11-06 02:52:17,157 valid 000 1.510634e-02 -0.397191
2019-11-06 02:52:26,916 valid 050 1.392120e-02 -1.104809
2019-11-06 02:52:35,548 validation loss; R2: 1.406511e-02 -0.836110
2019-11-06 02:52:35,620 epoch 315 lr 1.000000e-04
2019-11-06 02:52:36,360 train 000 1.601016e-02 -0.230591
2019-11-06 02:52:46,599 train 050 1.568678e-02 -0.799838
2019-11-06 02:52:56,771 train 100 1.564863e-02 -0.742125
2019-11-06 02:53:06,959 train 150 1.566036e-02 -0.684538
2019-11-06 02:53:17,089 train 200 1.582076e-02 -0.710919
2019-11-06 02:53:27,246 train 250 1.580232e-02 -0.725317
2019-11-06 02:53:37,380 train 300 1.583452e-02 -0.695615
2019-11-06 02:53:47,530 train 350 1.581752e-02 -0.689290
2019-11-06 02:53:57,682 train 400 1.579971e-02 -0.708498
2019-11-06 02:54:07,827 train 450 1.579192e-02 -0.713643
2019-11-06 02:54:17,965 train 500 1.580168e-02 -0.697302
2019-11-06 02:54:28,109 train 550 1.580497e-02 -0.731246
2019-11-06 02:54:38,245 train 600 1.580156e-02 -0.746553
2019-11-06 02:54:48,396 train 650 1.579200e-02 -0.745713
2019-11-06 02:54:58,528 train 700 1.578571e-02 -0.728754
2019-11-06 02:55:08,681 train 750 1.579965e-02 -0.735893
2019-11-06 02:55:18,770 train 800 1.579501e-02 -0.731064
2019-11-06 02:55:28,905 train 850 1.574962e-02 -0.732090
2019-11-06 02:55:31,922 training loss; R2: 1.573662e-02 -0.725910
2019-11-06 02:55:32,434 valid 000 1.846590e-02 -0.165877
2019-11-06 02:55:42,203 valid 050 1.831840e-02 -2.023662
2019-11-06 02:55:50,840 validation loss; R2: 1.831398e-02 -2.356077
2019-11-06 02:55:50,904 epoch 316 lr 1.000000e-04
2019-11-06 02:55:51,617 train 000 1.274416e-02 -1.264174
2019-11-06 02:56:01,753 train 050 1.551003e-02 -0.918175
2019-11-06 02:56:11,845 train 100 1.566231e-02 -0.788958
2019-11-06 02:56:21,909 train 150 1.558493e-02 -0.820300
2019-11-06 02:56:32,095 train 200 1.567815e-02 -0.754576
2019-11-06 02:56:42,266 train 250 1.567926e-02 -0.694736
2019-11-06 02:56:52,437 train 300 1.573460e-02 -0.648716
2019-11-06 02:57:02,607 train 350 1.570160e-02 -0.715589
2019-11-06 02:57:12,804 train 400 1.567271e-02 -0.717516
2019-11-06 02:57:22,995 train 450 1.566323e-02 -0.774737
2019-11-06 02:57:33,208 train 500 1.569376e-02 -0.791499
2019-11-06 02:57:43,419 train 550 1.567809e-02 -0.782728
2019-11-06 02:57:53,583 train 600 1.566155e-02 -0.777502
2019-11-06 02:58:03,748 train 650 1.567826e-02 -0.756511
2019-11-06 02:58:13,894 train 700 1.568374e-02 -0.746980
2019-11-06 02:58:24,031 train 750 1.570748e-02 -1.001005
2019-11-06 02:58:34,154 train 800 1.570573e-02 -0.970873
2019-11-06 02:58:44,270 train 850 1.569195e-02 -0.962431
2019-11-06 02:58:47,282 training loss; R2: 1.570180e-02 -0.967716
2019-11-06 02:58:47,832 valid 000 1.154403e-02 -0.084740
2019-11-06 02:58:57,577 valid 050 1.385135e-02 -0.860026
2019-11-06 02:59:06,272 validation loss; R2: 1.412305e-02 -0.894759
2019-11-06 02:59:06,337 epoch 317 lr 1.000000e-04
2019-11-06 02:59:07,000 train 000 1.623586e-02 -0.528238
2019-11-06 02:59:17,218 train 050 1.558027e-02 -0.828674
2019-11-06 02:59:27,399 train 100 1.560018e-02 -0.843002
2019-11-06 02:59:37,546 train 150 1.562052e-02 -0.907994
2019-11-06 02:59:47,725 train 200 1.567242e-02 -0.897942
2019-11-06 02:59:57,867 train 250 1.566539e-02 -0.901304
2019-11-06 03:00:08,058 train 300 1.568496e-02 -0.865221
2019-11-06 03:00:18,227 train 350 1.571285e-02 -0.854064
2019-11-06 03:00:28,400 train 400 1.575445e-02 -0.844339
2019-11-06 03:00:38,536 train 450 1.576753e-02 -0.823997
2019-11-06 03:00:48,706 train 500 1.573994e-02 -0.802573
2019-11-06 03:00:58,846 train 550 1.572121e-02 -0.796696
2019-11-06 03:01:08,980 train 600 1.572418e-02 -0.793785
2019-11-06 03:01:19,118 train 650 1.567808e-02 -0.776940
2019-11-06 03:01:29,261 train 700 1.565700e-02 -0.761123
2019-11-06 03:01:39,411 train 750 1.569716e-02 -0.763378
2019-11-06 03:01:49,553 train 800 1.571824e-02 -0.766721
2019-11-06 03:01:59,691 train 850 1.572682e-02 -0.748000
2019-11-06 03:02:02,718 training loss; R2: 1.572709e-02 -0.753170
2019-11-06 03:02:03,259 valid 000 1.310355e-02 -0.472281
2019-11-06 03:02:12,996 valid 050 1.304061e-02 -2.536989
2019-11-06 03:02:21,783 validation loss; R2: 1.309199e-02 -1.870979
2019-11-06 03:02:21,861 epoch 318 lr 1.000000e-04
2019-11-06 03:02:22,541 train 000 1.541640e-02 -0.909861
2019-11-06 03:02:32,646 train 050 1.577781e-02 -0.751774
2019-11-06 03:02:42,721 train 100 1.565460e-02 -0.854134
2019-11-06 03:02:52,877 train 150 1.559593e-02 -0.804910
2019-11-06 03:03:02,993 train 200 1.563523e-02 -0.759188
2019-11-06 03:03:13,061 train 250 1.564136e-02 -0.713888
2019-11-06 03:03:23,184 train 300 1.563631e-02 -0.675882
2019-11-06 03:03:33,349 train 350 1.566709e-02 -0.691422
2019-11-06 03:03:43,447 train 400 1.564704e-02 -0.687310
2019-11-06 03:03:53,536 train 450 1.563129e-02 -0.708626
2019-11-06 03:04:03,693 train 500 1.560666e-02 -0.719410
2019-11-06 03:04:13,813 train 550 1.560640e-02 -0.749394
2019-11-06 03:04:23,861 train 600 1.560340e-02 -0.729720
2019-11-06 03:04:34,002 train 650 1.563324e-02 -0.768185
2019-11-06 03:04:44,045 train 700 1.563493e-02 -0.781038
2019-11-06 03:04:54,140 train 750 1.564887e-02 -0.789832
2019-11-06 03:05:04,283 train 800 1.563541e-02 -0.770830
2019-11-06 03:05:14,376 train 850 1.563816e-02 -0.775576
2019-11-06 03:05:17,366 training loss; R2: 1.564530e-02 -0.767620
2019-11-06 03:05:17,923 valid 000 1.182336e-02 -11.096059
2019-11-06 03:05:27,697 valid 050 1.513651e-02 -2.419912
2019-11-06 03:05:36,341 validation loss; R2: 1.494457e-02 -2.262629
2019-11-06 03:05:36,408 epoch 319 lr 1.000000e-04
2019-11-06 03:05:37,140 train 000 1.416807e-02 -0.406086
2019-11-06 03:05:47,291 train 050 1.541623e-02 -0.534863
2019-11-06 03:05:57,484 train 100 1.565271e-02 -0.663334
2019-11-06 03:06:07,680 train 150 1.554160e-02 -0.758040
2019-11-06 03:06:17,875 train 200 1.560606e-02 -0.788360
2019-11-06 03:06:28,045 train 250 1.563876e-02 -0.804126
2019-11-06 03:06:38,241 train 300 1.565784e-02 -0.800729
2019-11-06 03:06:48,451 train 350 1.568661e-02 -0.781256
2019-11-06 03:06:58,653 train 400 1.569706e-02 -0.774663
2019-11-06 03:07:08,791 train 450 1.571001e-02 -0.773345
2019-11-06 03:07:18,976 train 500 1.570096e-02 -0.769243
2019-11-06 03:07:29,116 train 550 1.567747e-02 -0.763829
2019-11-06 03:07:39,275 train 600 1.564807e-02 -0.770860
2019-11-06 03:07:49,432 train 650 1.565449e-02 -0.932599
2019-11-06 03:07:59,608 train 700 1.564276e-02 -0.905751
2019-11-06 03:08:09,774 train 750 1.563109e-02 -0.909118
2019-11-06 03:08:19,935 train 800 1.561836e-02 -0.901340
2019-11-06 03:08:30,069 train 850 1.563899e-02 -0.899828
2019-11-06 03:08:33,103 training loss; R2: 1.563278e-02 -0.891233
2019-11-06 03:08:33,672 valid 000 1.572206e-02 -1.424377
2019-11-06 03:08:43,494 valid 050 1.281932e-02 -0.716196
2019-11-06 03:08:52,150 validation loss; R2: 1.301854e-02 -2.128670
2019-11-06 03:08:52,213 epoch 320 lr 1.000000e-04
2019-11-06 03:08:52,932 train 000 1.686615e-02 -0.754572
2019-11-06 03:09:03,172 train 050 1.556391e-02 -0.516579
2019-11-06 03:09:13,390 train 100 1.566877e-02 -0.602301
2019-11-06 03:09:23,641 train 150 1.567888e-02 -0.591432
2019-11-06 03:09:33,838 train 200 1.575496e-02 -0.630479
2019-11-06 03:09:44,046 train 250 1.583257e-02 -108.709431
2019-11-06 03:09:54,266 train 300 1.576728e-02 -90.809069
2019-11-06 03:10:04,486 train 350 1.577862e-02 -77.971605
2019-11-06 03:10:14,673 train 400 1.574176e-02 -68.354295
2019-11-06 03:10:24,851 train 450 1.570993e-02 -60.869889
2019-11-06 03:10:35,014 train 500 1.573586e-02 -54.859746
2019-11-06 03:10:45,172 train 550 1.576524e-02 -49.935038
2019-11-06 03:10:55,299 train 600 1.576328e-02 -45.839113
2019-11-06 03:11:05,436 train 650 1.576724e-02 -42.378931
2019-11-06 03:11:15,546 train 700 1.574418e-02 -39.421582
2019-11-06 03:11:25,654 train 750 1.572994e-02 -36.844367
2019-11-06 03:11:35,768 train 800 1.571424e-02 -34.585299
2019-11-06 03:11:45,877 train 850 1.572604e-02 -32.609026
2019-11-06 03:11:48,901 training loss; R2: 1.573164e-02 -32.158416
2019-11-06 03:11:49,451 valid 000 1.441053e-02 -5.948765
2019-11-06 03:11:59,218 valid 050 1.315930e-02 -1.774725
2019-11-06 03:12:07,856 validation loss; R2: 1.309912e-02 -1.359739
2019-11-06 03:12:07,921 epoch 321 lr 1.000000e-04
2019-11-06 03:12:08,660 train 000 1.570224e-02 -0.346032
2019-11-06 03:12:18,861 train 050 1.568087e-02 -0.546359
2019-11-06 03:12:29,049 train 100 1.561945e-02 -0.674419
2019-11-06 03:12:39,226 train 150 1.558361e-02 -0.659794
2019-11-06 03:12:49,401 train 200 1.553270e-02 -0.635931
2019-11-06 03:12:59,551 train 250 1.559412e-02 -0.676496
2019-11-06 03:13:09,723 train 300 1.556488e-02 -0.682056
2019-11-06 03:13:19,868 train 350 1.562893e-02 -0.732082
2019-11-06 03:13:30,025 train 400 1.569403e-02 -0.795823
2019-11-06 03:13:40,150 train 450 1.567535e-02 -0.797794
2019-11-06 03:13:50,311 train 500 1.564181e-02 -0.812277
2019-11-06 03:14:00,363 train 550 1.564744e-02 -0.776454
2019-11-06 03:14:10,425 train 600 1.567027e-02 -0.762545
2019-11-06 03:14:20,573 train 650 1.568764e-02 -0.755338
2019-11-06 03:14:30,681 train 700 1.570093e-02 -0.747247
2019-11-06 03:14:40,717 train 750 1.568021e-02 -0.740977
2019-11-06 03:14:50,857 train 800 1.569204e-02 -0.741935
2019-11-06 03:15:01,010 train 850 1.571406e-02 -0.731844
2019-11-06 03:15:04,021 training loss; R2: 1.571337e-02 -0.735476
2019-11-06 03:15:04,577 valid 000 1.936907e-02 -3.024811
2019-11-06 03:15:14,315 valid 050 1.371801e-02 -0.916287
2019-11-06 03:15:22,878 validation loss; R2: 1.378565e-02 -0.941572
2019-11-06 03:15:22,947 epoch 322 lr 1.000000e-04
2019-11-06 03:15:23,635 train 000 1.472166e-02 -0.100037
2019-11-06 03:15:33,852 train 050 1.562412e-02 -0.431696
2019-11-06 03:15:44,034 train 100 1.591437e-02 -0.446345
2019-11-06 03:15:54,217 train 150 1.578744e-02 -0.517210
2019-11-06 03:16:04,412 train 200 1.579402e-02 -0.568939
2019-11-06 03:16:14,621 train 250 1.575950e-02 -0.595251
2019-11-06 03:16:24,834 train 300 1.574107e-02 -0.644953
2019-11-06 03:16:35,010 train 350 1.573818e-02 -0.733709
2019-11-06 03:16:45,157 train 400 1.574778e-02 -0.710095
2019-11-06 03:16:55,343 train 450 1.574221e-02 -0.677644
2019-11-06 03:17:05,533 train 500 1.572433e-02 -0.669486
2019-11-06 03:17:15,677 train 550 1.571225e-02 -0.671222
2019-11-06 03:17:25,849 train 600 1.576931e-02 -0.672286
2019-11-06 03:17:36,025 train 650 1.576126e-02 -0.692174
2019-11-06 03:17:46,200 train 700 1.576469e-02 -0.703900
2019-11-06 03:17:56,364 train 750 1.576098e-02 -0.707541
2019-11-06 03:18:06,564 train 800 1.573159e-02 -0.708993
2019-11-06 03:18:16,719 train 850 1.572323e-02 -0.710349
2019-11-06 03:18:19,747 training loss; R2: 1.571189e-02 -0.709072
2019-11-06 03:18:20,308 valid 000 1.404332e-02 -0.030485
2019-11-06 03:18:30,097 valid 050 1.336537e-02 -1.461947
2019-11-06 03:18:38,728 validation loss; R2: 1.324462e-02 -1.413449
2019-11-06 03:18:38,789 epoch 323 lr 1.000000e-04
2019-11-06 03:18:39,496 train 000 1.502664e-02 -0.031689
2019-11-06 03:18:49,725 train 050 1.565184e-02 -0.717907
2019-11-06 03:18:59,835 train 100 1.587725e-02 -0.579311
2019-11-06 03:19:09,996 train 150 1.586534e-02 -0.566593
2019-11-06 03:19:20,171 train 200 1.579171e-02 -0.624554
2019-11-06 03:19:30,238 train 250 1.574629e-02 -0.629852
2019-11-06 03:19:40,369 train 300 1.567838e-02 -0.648902
2019-11-06 03:19:50,543 train 350 1.561838e-02 -0.667452
2019-11-06 03:20:00,624 train 400 1.561226e-02 -0.662085
2019-11-06 03:20:10,752 train 450 1.563059e-02 -0.700028
2019-11-06 03:20:20,917 train 500 1.565481e-02 -0.685267
2019-11-06 03:20:30,955 train 550 1.565661e-02 -0.655441
2019-11-06 03:20:41,082 train 600 1.565266e-02 -0.694515
2019-11-06 03:20:51,229 train 650 1.564725e-02 -0.702739
2019-11-06 03:21:01,290 train 700 1.562485e-02 -0.686581
2019-11-06 03:21:11,387 train 750 1.563887e-02 -0.710369
2019-11-06 03:21:21,560 train 800 1.562033e-02 -0.706434
2019-11-06 03:21:31,662 train 850 1.565022e-02 -0.708272
2019-11-06 03:21:34,670 training loss; R2: 1.564791e-02 -0.775290
2019-11-06 03:21:35,198 valid 000 1.376837e-02 -2.506468
2019-11-06 03:21:45,118 valid 050 1.417633e-02 -3.216587
2019-11-06 03:21:53,770 validation loss; R2: 1.395232e-02 -2.083615
2019-11-06 03:21:53,835 epoch 324 lr 1.000000e-04
2019-11-06 03:21:54,582 train 000 1.601449e-02 -0.882310
2019-11-06 03:22:04,734 train 050 1.539248e-02 -1.257954
2019-11-06 03:22:14,951 train 100 1.566158e-02 -0.874209
2019-11-06 03:22:25,178 train 150 1.572699e-02 -0.873409
2019-11-06 03:22:35,386 train 200 1.566928e-02 -0.784750
2019-11-06 03:22:45,534 train 250 1.561845e-02 -0.775422
2019-11-06 03:22:55,685 train 300 1.571298e-02 -0.777601
2019-11-06 03:23:05,795 train 350 1.569359e-02 -0.799400
2019-11-06 03:23:15,924 train 400 1.568017e-02 -0.836075
2019-11-06 03:23:26,028 train 450 1.569592e-02 -0.808478
2019-11-06 03:23:36,187 train 500 1.569469e-02 -0.795909
2019-11-06 03:23:46,323 train 550 1.571131e-02 -0.798834
2019-11-06 03:23:56,477 train 600 1.570287e-02 -0.783684
2019-11-06 03:24:06,621 train 650 1.568458e-02 -0.775882
2019-11-06 03:24:16,788 train 700 1.566866e-02 -0.768437
2019-11-06 03:24:26,922 train 750 1.567096e-02 -0.765038
2019-11-06 03:24:37,104 train 800 1.567727e-02 -0.767772
2019-11-06 03:24:47,245 train 850 1.567396e-02 -0.756552
2019-11-06 03:24:50,269 training loss; R2: 1.567561e-02 -0.755461
2019-11-06 03:24:50,832 valid 000 1.182090e-02 0.067504
2019-11-06 03:25:00,620 valid 050 1.358989e-02 -0.928356
2019-11-06 03:25:09,290 validation loss; R2: 1.330177e-02 -1.161831
2019-11-06 03:25:09,359 epoch 325 lr 1.000000e-04
2019-11-06 03:25:10,107 train 000 1.657816e-02 -0.464439
2019-11-06 03:25:20,286 train 050 1.589297e-02 -0.523640
2019-11-06 03:25:30,510 train 100 1.590294e-02 -0.687400
2019-11-06 03:25:40,724 train 150 1.579296e-02 -0.686464
2019-11-06 03:25:50,924 train 200 1.585289e-02 -0.721135
2019-11-06 03:26:01,114 train 250 1.583746e-02 -0.702560
2019-11-06 03:26:11,279 train 300 1.589147e-02 -0.747126
2019-11-06 03:26:21,473 train 350 1.578136e-02 -0.734868
2019-11-06 03:26:31,649 train 400 1.576429e-02 -0.710356
2019-11-06 03:26:41,795 train 450 1.576371e-02 -0.710116
2019-11-06 03:26:51,933 train 500 1.574278e-02 -0.732210
2019-11-06 03:27:02,088 train 550 1.571120e-02 -0.710327
2019-11-06 03:27:12,248 train 600 1.568820e-02 -0.684224
2019-11-06 03:27:22,417 train 650 1.570073e-02 -0.662683
2019-11-06 03:27:32,557 train 700 1.568148e-02 -0.674321
2019-11-06 03:27:42,706 train 750 1.568637e-02 -0.736600
2019-11-06 03:27:52,841 train 800 1.568570e-02 -0.725076
2019-11-06 03:28:03,025 train 850 1.570257e-02 -0.730203
2019-11-06 03:28:06,055 training loss; R2: 1.569240e-02 -0.728432
2019-11-06 03:28:06,562 valid 000 1.443015e-02 -3.985424
2019-11-06 03:28:16,381 valid 050 1.362283e-02 -1.108957
2019-11-06 03:28:25,081 validation loss; R2: 1.377009e-02 -1.067480
2019-11-06 03:28:25,148 epoch 326 lr 1.000000e-04
2019-11-06 03:28:25,891 train 000 1.384793e-02 -0.045165
2019-11-06 03:28:36,072 train 050 1.533948e-02 -0.551601
2019-11-06 03:28:46,265 train 100 1.564296e-02 -0.528228
2019-11-06 03:28:56,496 train 150 1.572988e-02 -0.555085
2019-11-06 03:29:06,620 train 200 1.571725e-02 -0.646978
2019-11-06 03:29:16,717 train 250 1.576422e-02 -0.633493
2019-11-06 03:29:26,929 train 300 1.577923e-02 -0.633940
2019-11-06 03:29:37,112 train 350 1.576955e-02 -0.650262
2019-11-06 03:29:47,207 train 400 1.581433e-02 -0.679811
2019-11-06 03:29:57,335 train 450 1.579661e-02 -0.655441
2019-11-06 03:30:07,488 train 500 1.577943e-02 -0.653069
2019-11-06 03:30:17,644 train 550 1.578102e-02 -0.639319
2019-11-06 03:30:27,740 train 600 1.575624e-02 -0.666424
2019-11-06 03:30:37,873 train 650 1.576813e-02 -0.661870
2019-11-06 03:30:48,052 train 700 1.579769e-02 -0.662159
2019-11-06 03:30:58,153 train 750 1.578294e-02 -0.666692
2019-11-06 03:31:08,191 train 800 1.578967e-02 -0.656473
2019-11-06 03:31:18,270 train 850 1.577872e-02 -0.656452
2019-11-06 03:31:21,292 training loss; R2: 1.578571e-02 -0.661591
2019-11-06 03:31:21,882 valid 000 1.326874e-02 -3.716870
2019-11-06 03:31:31,754 valid 050 1.353775e-02 -1.399263
2019-11-06 03:31:40,533 validation loss; R2: 1.338487e-02 -1.697388
2019-11-06 03:31:40,618 epoch 327 lr 1.000000e-04
2019-11-06 03:31:41,373 train 000 1.391538e-02 -0.019605
2019-11-06 03:31:51,446 train 050 1.581188e-02 -1.941954
2019-11-06 03:32:01,525 train 100 1.560671e-02 -1.361719
2019-11-06 03:32:11,681 train 150 1.556525e-02 -1.108857
2019-11-06 03:32:21,811 train 200 1.560999e-02 -0.965431
2019-11-06 03:32:31,924 train 250 1.557317e-02 -0.946382
2019-11-06 03:32:41,998 train 300 1.557959e-02 -0.939399
2019-11-06 03:32:52,137 train 350 1.558653e-02 -0.880709
2019-11-06 03:33:02,312 train 400 1.560210e-02 -0.896377
2019-11-06 03:33:12,486 train 450 1.563355e-02 -0.869788
2019-11-06 03:33:22,550 train 500 1.563561e-02 -0.865548
2019-11-06 03:33:32,630 train 550 1.561172e-02 -0.849871
2019-11-06 03:33:42,778 train 600 1.561061e-02 -0.820861
2019-11-06 03:33:52,896 train 650 1.560271e-02 -0.808339
2019-11-06 03:34:02,962 train 700 1.563828e-02 -1.074245
2019-11-06 03:34:13,086 train 750 1.566367e-02 -1.147339
2019-11-06 03:34:23,245 train 800 1.565293e-02 -1.132532
2019-11-06 03:34:33,334 train 850 1.566590e-02 -1.110279
2019-11-06 03:34:36,338 training loss; R2: 1.567056e-02 -1.114971
2019-11-06 03:34:36,871 valid 000 1.570170e-02 -0.627043
2019-11-06 03:34:46,736 valid 050 1.378059e-02 -1.692856
2019-11-06 03:34:55,516 validation loss; R2: 1.374479e-02 -1.625841
2019-11-06 03:34:55,580 epoch 328 lr 1.000000e-04
2019-11-06 03:34:56,272 train 000 1.793296e-02 -0.070119
2019-11-06 03:35:06,655 train 050 1.557570e-02 -0.757493
2019-11-06 03:35:16,941 train 100 1.556659e-02 -0.675774
2019-11-06 03:35:27,117 train 150 1.575914e-02 -0.651228
2019-11-06 03:35:37,278 train 200 1.561199e-02 -0.630376
2019-11-06 03:35:47,449 train 250 1.562662e-02 -0.722762
2019-11-06 03:35:57,601 train 300 1.564400e-02 -0.747512
2019-11-06 03:36:07,829 train 350 1.561283e-02 -0.744548
2019-11-06 03:36:18,036 train 400 1.559519e-02 -0.826472
2019-11-06 03:36:28,256 train 450 1.561930e-02 -0.812869
2019-11-06 03:36:38,472 train 500 1.564133e-02 -0.817598
2019-11-06 03:36:48,686 train 550 1.564151e-02 -0.820773
2019-11-06 03:36:58,877 train 600 1.563965e-02 -0.820159
2019-11-06 03:37:09,068 train 650 1.566202e-02 -0.797525
2019-11-06 03:37:19,237 train 700 1.565832e-02 -0.797970
2019-11-06 03:37:29,396 train 750 1.563630e-02 -0.795503
2019-11-06 03:37:39,595 train 800 1.567147e-02 -0.781427
2019-11-06 03:37:49,777 train 850 1.564632e-02 -0.778561
2019-11-06 03:37:52,828 training loss; R2: 1.566028e-02 -0.776194
2019-11-06 03:37:53,338 valid 000 1.706974e-02 -0.852156
2019-11-06 03:38:03,208 valid 050 1.542304e-02 -2.067103
2019-11-06 03:38:11,884 validation loss; R2: 1.554245e-02 -1.791594
2019-11-06 03:38:11,957 epoch 329 lr 1.000000e-04
2019-11-06 03:38:12,646 train 000 1.866549e-02 -1.983905
2019-11-06 03:38:22,869 train 050 1.549423e-02 -0.825667
2019-11-06 03:38:33,091 train 100 1.573249e-02 -0.654648
2019-11-06 03:38:43,270 train 150 1.559971e-02 -0.647751
2019-11-06 03:38:53,448 train 200 1.557685e-02 -0.698062
2019-11-06 03:39:03,623 train 250 1.554726e-02 -0.665035
2019-11-06 03:39:13,780 train 300 1.559247e-02 -0.655064
2019-11-06 03:39:23,934 train 350 1.561881e-02 -0.858470
2019-11-06 03:39:34,108 train 400 1.561379e-02 -0.892475
2019-11-06 03:39:44,276 train 450 1.564079e-02 -0.839285
2019-11-06 03:39:54,451 train 500 1.570640e-02 -0.846109
2019-11-06 03:40:04,605 train 550 1.569607e-02 -0.945033
2019-11-06 03:40:14,810 train 600 1.569595e-02 -0.934709
2019-11-06 03:40:24,998 train 650 1.568393e-02 -0.909487
2019-11-06 03:40:35,210 train 700 1.567929e-02 -0.891503
2019-11-06 03:40:45,409 train 750 1.570316e-02 -0.872045
2019-11-06 03:40:55,619 train 800 1.571323e-02 -0.870513
2019-11-06 03:41:05,792 train 850 1.569726e-02 -0.879241
2019-11-06 03:41:08,836 training loss; R2: 1.569874e-02 -0.876401
2019-11-06 03:41:09,347 valid 000 1.589673e-02 -2.233761
2019-11-06 03:41:19,176 valid 050 1.466069e-02 -1.351696
2019-11-06 03:41:27,947 validation loss; R2: 1.443289e-02 -1.244542
2019-11-06 03:41:28,016 epoch 330 lr 1.000000e-04
2019-11-06 03:41:28,722 train 000 1.439195e-02 -1.318549
2019-11-06 03:41:38,840 train 050 1.567730e-02 -0.661792
2019-11-06 03:41:48,957 train 100 1.574244e-02 -0.759251
2019-11-06 03:41:59,088 train 150 1.580928e-02 -0.687692
2019-11-06 03:42:09,220 train 200 1.576803e-02 -0.629149
2019-11-06 03:42:19,340 train 250 1.573785e-02 -0.602878
2019-11-06 03:42:29,440 train 300 1.572877e-02 -0.606880
2019-11-06 03:42:39,566 train 350 1.573756e-02 -0.614639
2019-11-06 03:42:49,654 train 400 1.574104e-02 -0.620422
2019-11-06 03:42:59,760 train 450 1.573197e-02 -0.623160
2019-11-06 03:43:09,861 train 500 1.572579e-02 -0.653659
2019-11-06 03:43:19,953 train 550 1.566682e-02 -0.663521
2019-11-06 03:43:30,068 train 600 1.568439e-02 -0.659488
2019-11-06 03:43:40,143 train 650 1.566367e-02 -0.683574
2019-11-06 03:43:50,207 train 700 1.565480e-02 -0.706228
2019-11-06 03:44:00,267 train 750 1.564471e-02 -0.705779
2019-11-06 03:44:10,360 train 800 1.566125e-02 -0.707175
2019-11-06 03:44:20,470 train 850 1.567045e-02 -0.707269
2019-11-06 03:44:23,493 training loss; R2: 1.566873e-02 -0.704741
2019-11-06 03:44:24,064 valid 000 1.244033e-02 -0.335808
2019-11-06 03:44:33,848 valid 050 1.416717e-02 -1.895364
2019-11-06 03:44:42,568 validation loss; R2: 1.410476e-02 -1.766696
2019-11-06 03:44:42,633 epoch 331 lr 1.000000e-04
2019-11-06 03:44:43,301 train 000 1.387785e-02 -0.017494
2019-11-06 03:44:53,485 train 050 1.545809e-02 -0.475974
2019-11-06 03:45:03,620 train 100 1.579278e-02 -0.498801
2019-11-06 03:45:13,757 train 150 1.575475e-02 -0.569520
2019-11-06 03:45:23,886 train 200 1.564023e-02 -0.580438
2019-11-06 03:45:34,064 train 250 1.565189e-02 -0.651114
2019-11-06 03:45:44,124 train 300 1.570230e-02 -0.629170
2019-11-06 03:45:54,286 train 350 1.572967e-02 -0.660492
2019-11-06 03:46:04,437 train 400 1.575335e-02 -0.654622
2019-11-06 03:46:14,566 train 450 1.576259e-02 -0.692476
2019-11-06 03:46:24,704 train 500 1.574178e-02 -0.862715
2019-11-06 03:46:34,832 train 550 1.575266e-02 -0.882447
2019-11-06 03:46:44,983 train 600 1.573404e-02 -0.878019
2019-11-06 03:46:55,124 train 650 1.570944e-02 -0.861813
2019-11-06 03:47:05,265 train 700 1.571312e-02 -0.863367
2019-11-06 03:47:15,413 train 750 1.571771e-02 -0.855106
2019-11-06 03:47:25,571 train 800 1.571038e-02 -0.847198
2019-11-06 03:47:35,736 train 850 1.572593e-02 -0.837566
2019-11-06 03:47:38,756 training loss; R2: 1.573277e-02 -0.830648
2019-11-06 03:47:39,287 valid 000 1.185866e-02 -0.294759
2019-11-06 03:47:49,332 valid 050 1.303346e-02 -0.974087
2019-11-06 03:47:58,208 validation loss; R2: 1.288235e-02 -0.798367
2019-11-06 03:47:58,272 epoch 332 lr 1.000000e-04
2019-11-06 03:47:58,980 train 000 1.643031e-02 -0.889651
2019-11-06 03:48:09,210 train 050 1.575349e-02 -1.060032
2019-11-06 03:48:19,400 train 100 1.594503e-02 -0.882927
2019-11-06 03:48:29,562 train 150 1.582293e-02 -0.890760
2019-11-06 03:48:39,736 train 200 1.587808e-02 -0.825820
2019-11-06 03:48:49,867 train 250 1.584011e-02 -1.081675
2019-11-06 03:49:00,001 train 300 1.578085e-02 -1.132373
2019-11-06 03:49:10,157 train 350 1.570916e-02 -1.137091
2019-11-06 03:49:20,290 train 400 1.568207e-02 -1.060217
2019-11-06 03:49:30,484 train 450 1.568242e-02 -1.021566
2019-11-06 03:49:40,628 train 500 1.567280e-02 -0.965297
2019-11-06 03:49:50,777 train 550 1.567697e-02 -0.940576
2019-11-06 03:50:00,961 train 600 1.567813e-02 -0.913026
2019-11-06 03:50:11,138 train 650 1.570054e-02 -0.895239
2019-11-06 03:50:21,308 train 700 1.569639e-02 -0.880188
2019-11-06 03:50:31,485 train 750 1.568063e-02 -0.866854
2019-11-06 03:50:41,658 train 800 1.568689e-02 -0.870112
2019-11-06 03:50:51,811 train 850 1.570140e-02 -0.849211
2019-11-06 03:50:54,836 training loss; R2: 1.569732e-02 -0.847686
2019-11-06 03:50:55,397 valid 000 1.320753e-02 0.154900
2019-11-06 03:51:05,155 valid 050 1.296573e-02 -1.290195
2019-11-06 03:51:13,806 validation loss; R2: 1.293312e-02 -1.310435
2019-11-06 03:51:13,868 epoch 333 lr 1.000000e-04
2019-11-06 03:51:14,536 train 000 1.711040e-02 -0.317312
2019-11-06 03:51:24,770 train 050 1.607048e-02 -0.667848
2019-11-06 03:51:34,960 train 100 1.579477e-02 -2.491579
2019-11-06 03:51:45,116 train 150 1.578252e-02 -1.861052
2019-11-06 03:51:55,270 train 200 1.567786e-02 -2.747016
2019-11-06 03:52:05,405 train 250 1.573315e-02 -2.322399
2019-11-06 03:52:15,543 train 300 1.578463e-02 -2.024851
2019-11-06 03:52:25,665 train 350 1.571680e-02 -1.850547
2019-11-06 03:52:35,796 train 400 1.576767e-02 -1.704767
2019-11-06 03:52:45,934 train 450 1.576513e-02 -1.607141
2019-11-06 03:52:56,061 train 500 1.571651e-02 -1.504286
2019-11-06 03:53:06,203 train 550 1.571425e-02 -1.467428
2019-11-06 03:53:16,364 train 600 1.570156e-02 -1.403956
2019-11-06 03:53:26,531 train 650 1.569014e-02 -1.357682
2019-11-06 03:53:36,693 train 700 1.569622e-02 -1.309854
2019-11-06 03:53:46,876 train 750 1.568166e-02 -1.267433
2019-11-06 03:53:57,060 train 800 1.570885e-02 -1.230935
2019-11-06 03:54:07,225 train 850 1.570526e-02 -1.190505
2019-11-06 03:54:10,267 training loss; R2: 1.569105e-02 -1.181274
2019-11-06 03:54:10,783 valid 000 1.222294e-02 -3.180964
2019-11-06 03:54:20,557 valid 050 1.379428e-02 -1.413909
2019-11-06 03:54:29,224 validation loss; R2: 1.387451e-02 -1.436552
2019-11-06 03:54:29,288 epoch 334 lr 1.000000e-04
2019-11-06 03:54:30,007 train 000 1.589567e-02 -0.141804
2019-11-06 03:54:40,148 train 050 1.561074e-02 -0.907229
2019-11-06 03:54:50,326 train 100 1.541431e-02 -0.825688
2019-11-06 03:55:00,486 train 150 1.547920e-02 -0.766507
2019-11-06 03:55:10,688 train 200 1.548172e-02 -0.775510
2019-11-06 03:55:20,834 train 250 1.548245e-02 -0.856559
2019-11-06 03:55:30,973 train 300 1.556118e-02 -0.868288
2019-11-06 03:55:41,074 train 350 1.554880e-02 -0.835436
2019-11-06 03:55:51,168 train 400 1.556095e-02 -0.835485
2019-11-06 03:56:01,301 train 450 1.561036e-02 -0.818194
2019-11-06 03:56:11,576 train 500 1.559748e-02 -0.811567
2019-11-06 03:56:21,830 train 550 1.559033e-02 -0.827871
2019-11-06 03:56:32,110 train 600 1.560740e-02 -0.811754
2019-11-06 03:56:42,265 train 650 1.561628e-02 -0.789460
2019-11-06 03:56:52,415 train 700 1.559756e-02 -0.810031
2019-11-06 03:57:02,597 train 750 1.559849e-02 -0.795867
2019-11-06 03:57:12,756 train 800 1.562601e-02 -0.801417
2019-11-06 03:57:22,917 train 850 1.563291e-02 -0.777538
2019-11-06 03:57:25,944 training loss; R2: 1.563688e-02 -0.768691
2019-11-06 03:57:26,455 valid 000 1.358419e-02 -0.404102
2019-11-06 03:57:36,296 valid 050 1.411124e-02 -1.506875
2019-11-06 03:57:44,955 validation loss; R2: 1.399596e-02 -1.486799
2019-11-06 03:57:45,022 epoch 335 lr 1.000000e-04
2019-11-06 03:57:45,738 train 000 1.927584e-02 -1.255809
2019-11-06 03:57:55,848 train 050 1.564889e-02 -0.780222
2019-11-06 03:58:05,920 train 100 1.568169e-02 -0.731452
2019-11-06 03:58:16,097 train 150 1.571904e-02 -0.789456
2019-11-06 03:58:26,210 train 200 1.566952e-02 -0.805316
2019-11-06 03:58:36,287 train 250 1.570092e-02 -0.789383
2019-11-06 03:58:46,416 train 300 1.571852e-02 -0.780124
2019-11-06 03:58:56,580 train 350 1.572399e-02 -0.756771
2019-11-06 03:59:06,634 train 400 1.568314e-02 -0.802856
2019-11-06 03:59:16,700 train 450 1.570511e-02 -0.776503
2019-11-06 03:59:26,878 train 500 1.569577e-02 -0.737721
2019-11-06 03:59:37,004 train 550 1.566302e-02 -0.727839
2019-11-06 03:59:47,061 train 600 1.569415e-02 -0.711158
2019-11-06 03:59:57,209 train 650 1.566486e-02 -0.792492
2019-11-06 04:00:07,393 train 700 1.567675e-02 -0.774254
2019-11-06 04:00:17,452 train 750 1.566856e-02 -0.760113
2019-11-06 04:00:27,540 train 800 1.569364e-02 -0.752576
2019-11-06 04:00:37,670 train 850 1.569765e-02 -0.751230
2019-11-06 04:00:40,693 training loss; R2: 1.569920e-02 -0.749267
2019-11-06 04:00:41,289 valid 000 1.330220e-02 -0.200756
2019-11-06 04:00:51,125 valid 050 1.387262e-02 -0.717488
2019-11-06 04:00:59,850 validation loss; R2: 1.383397e-02 -0.718604
2019-11-06 04:00:59,916 epoch 336 lr 1.000000e-04
2019-11-06 04:01:00,586 train 000 1.655852e-02 -0.479727
2019-11-06 04:01:10,859 train 050 1.566097e-02 -0.714580
2019-11-06 04:01:21,065 train 100 1.567210e-02 -1.003748
2019-11-06 04:01:31,361 train 150 1.569217e-02 -1.042946
2019-11-06 04:01:41,581 train 200 1.564351e-02 -0.936529
2019-11-06 04:01:51,763 train 250 1.567209e-02 -0.916554
2019-11-06 04:02:01,942 train 300 1.571253e-02 -1.426094
2019-11-06 04:02:12,204 train 350 1.576090e-02 -1.301846
2019-11-06 04:02:22,407 train 400 1.575821e-02 -1.222015
2019-11-06 04:02:32,555 train 450 1.573240e-02 -1.163731
2019-11-06 04:02:42,727 train 500 1.571272e-02 -1.104776
2019-11-06 04:02:52,962 train 550 1.569331e-02 -1.061344
2019-11-06 04:03:03,160 train 600 1.570035e-02 -1.026763
2019-11-06 04:03:13,272 train 650 1.571108e-02 -1.000288
2019-11-06 04:03:23,430 train 700 1.570711e-02 -0.979274
2019-11-06 04:03:33,653 train 750 1.573100e-02 -0.943909
2019-11-06 04:03:43,843 train 800 1.573035e-02 -0.929025
2019-11-06 04:03:53,987 train 850 1.573602e-02 -0.948111
2019-11-06 04:03:57,016 training loss; R2: 1.573750e-02 -0.953014
2019-11-06 04:03:57,592 valid 000 2.548296e-02 -0.147252
2019-11-06 04:04:07,392 valid 050 2.710952e-02 -0.348828
2019-11-06 04:04:16,071 validation loss; R2: 2.689503e-02 -0.367048
2019-11-06 04:04:16,134 epoch 337 lr 1.000000e-04
2019-11-06 04:04:16,846 train 000 1.499726e-02 -0.572945
2019-11-06 04:04:27,063 train 050 1.552071e-02 -0.707744
2019-11-06 04:04:37,183 train 100 1.555972e-02 -0.713648
2019-11-06 04:04:47,299 train 150 1.554729e-02 -0.646722
2019-11-06 04:04:57,389 train 200 1.551745e-02 -0.717730
2019-11-06 04:05:07,485 train 250 1.555418e-02 -0.686546
2019-11-06 04:05:17,555 train 300 1.556029e-02 -0.672368
2019-11-06 04:05:27,614 train 350 1.555767e-02 -0.685614
2019-11-06 04:05:37,682 train 400 1.558206e-02 -0.700006
2019-11-06 04:05:47,754 train 450 1.559410e-02 -0.670761
2019-11-06 04:05:57,845 train 500 1.563052e-02 -0.695113
2019-11-06 04:06:07,909 train 550 1.564124e-02 -0.687729
2019-11-06 04:06:17,990 train 600 1.567947e-02 -0.704927
2019-11-06 04:06:28,024 train 650 1.564088e-02 -0.706795
2019-11-06 04:06:38,094 train 700 1.564376e-02 -0.719740
2019-11-06 04:06:48,248 train 750 1.563929e-02 -0.729575
2019-11-06 04:06:58,419 train 800 1.564492e-02 -0.707735
2019-11-06 04:07:08,575 train 850 1.564671e-02 -0.713585
2019-11-06 04:07:11,624 training loss; R2: 1.564920e-02 -0.712326
2019-11-06 04:07:12,148 valid 000 1.374907e-02 -0.149516
2019-11-06 04:07:21,924 valid 050 1.324993e-02 -0.976444
2019-11-06 04:07:30,545 validation loss; R2: 1.339869e-02 -0.943861
2019-11-06 04:07:30,609 epoch 338 lr 1.000000e-04
2019-11-06 04:07:31,299 train 000 1.519900e-02 -0.580940
2019-11-06 04:07:41,503 train 050 1.562656e-02 -0.723089
2019-11-06 04:07:51,602 train 100 1.558680e-02 -0.673705
2019-11-06 04:08:01,686 train 150 1.559802e-02 -0.656757
2019-11-06 04:08:11,817 train 200 1.568879e-02 -0.647424
2019-11-06 04:08:21,913 train 250 1.567509e-02 -0.672856
2019-11-06 04:08:32,027 train 300 1.567823e-02 -0.722020
2019-11-06 04:08:42,167 train 350 1.572315e-02 -0.667681
2019-11-06 04:08:52,312 train 400 1.572389e-02 -0.656445
2019-11-06 04:09:02,472 train 450 1.568071e-02 -0.660187
2019-11-06 04:09:12,604 train 500 1.570632e-02 -0.669815
2019-11-06 04:09:22,736 train 550 1.574563e-02 -0.677707
2019-11-06 04:09:32,865 train 600 1.575502e-02 -0.662349
2019-11-06 04:09:43,015 train 650 1.572637e-02 -0.638568
2019-11-06 04:09:53,144 train 700 1.570987e-02 -0.634849
2019-11-06 04:10:03,267 train 750 1.569005e-02 -0.632951
2019-11-06 04:10:13,390 train 800 1.569492e-02 -0.635117
2019-11-06 04:10:23,545 train 850 1.567938e-02 -0.665850
2019-11-06 04:10:26,565 training loss; R2: 1.567728e-02 -0.672746
2019-11-06 04:10:27,086 valid 000 1.211887e-02 0.075546
2019-11-06 04:10:36,860 valid 050 1.471055e-02 -1.169193
2019-11-06 04:10:45,508 validation loss; R2: 1.450491e-02 -1.632675
2019-11-06 04:10:45,573 epoch 339 lr 1.000000e-04
2019-11-06 04:10:46,301 train 000 1.708202e-02 -8.708892
2019-11-06 04:10:56,529 train 050 1.571603e-02 -0.757065
2019-11-06 04:11:06,716 train 100 1.561858e-02 -0.697631
2019-11-06 04:11:16,877 train 150 1.557489e-02 -0.688970
2019-11-06 04:11:27,035 train 200 1.564313e-02 -0.676858
2019-11-06 04:11:37,219 train 250 1.579151e-02 -0.712802
2019-11-06 04:11:47,381 train 300 1.576305e-02 -0.722718
2019-11-06 04:11:57,529 train 350 1.575923e-02 -0.720212
2019-11-06 04:12:07,670 train 400 1.574679e-02 -0.722446
2019-11-06 04:12:17,834 train 450 1.577261e-02 -0.745911
2019-11-06 04:12:28,011 train 500 1.575406e-02 -0.760422
2019-11-06 04:12:38,183 train 550 1.574639e-02 -0.747191
2019-11-06 04:12:48,393 train 600 1.573547e-02 -0.728237
2019-11-06 04:12:58,614 train 650 1.573408e-02 -0.726024
2019-11-06 04:13:08,784 train 700 1.570847e-02 -0.716331
2019-11-06 04:13:18,908 train 750 1.570147e-02 -0.707352
2019-11-06 04:13:29,027 train 800 1.572336e-02 -0.694882
2019-11-06 04:13:39,143 train 850 1.571149e-02 -0.691332
2019-11-06 04:13:42,155 training loss; R2: 1.570867e-02 -0.690712
2019-11-06 04:13:42,674 valid 000 1.210870e-02 0.167077
2019-11-06 04:13:52,448 valid 050 1.287061e-02 -1.566364
2019-11-06 04:14:01,116 validation loss; R2: 1.275088e-02 -1.441892
2019-11-06 04:14:01,181 epoch 340 lr 1.000000e-04
2019-11-06 04:14:01,900 train 000 1.528160e-02 -0.062330
2019-11-06 04:14:12,139 train 050 1.605241e-02 -1.120720
2019-11-06 04:14:22,333 train 100 1.574954e-02 -0.947007
2019-11-06 04:14:32,502 train 150 1.584126e-02 -0.884952
2019-11-06 04:14:42,658 train 200 1.583479e-02 -0.811482
2019-11-06 04:14:52,817 train 250 1.572964e-02 -0.793635
2019-11-06 04:15:02,918 train 300 1.567519e-02 -0.790499
2019-11-06 04:15:12,966 train 350 1.563871e-02 -0.841499
2019-11-06 04:15:23,077 train 400 1.563104e-02 -0.811902
2019-11-06 04:15:33,194 train 450 1.564088e-02 -0.799716
2019-11-06 04:15:43,356 train 500 1.564634e-02 -0.776668
2019-11-06 04:15:53,501 train 550 1.564220e-02 -0.770976
2019-11-06 04:16:03,641 train 600 1.568060e-02 -0.756656
2019-11-06 04:16:13,761 train 650 1.566753e-02 -0.739080
2019-11-06 04:16:23,914 train 700 1.566217e-02 -0.770204
2019-11-06 04:16:34,050 train 750 1.566873e-02 -0.770055
2019-11-06 04:16:44,192 train 800 1.569332e-02 -0.751288
2019-11-06 04:16:54,373 train 850 1.568742e-02 -0.748075
2019-11-06 04:16:57,394 training loss; R2: 1.569358e-02 -0.756620
2019-11-06 04:16:57,966 valid 000 1.246597e-02 -12.517354
2019-11-06 04:17:07,801 valid 050 1.288326e-02 -1.702643
2019-11-06 04:17:16,430 validation loss; R2: 1.299928e-02 -1.377467
2019-11-06 04:17:16,493 epoch 341 lr 1.000000e-04
2019-11-06 04:17:17,157 train 000 1.326454e-02 -1.225358
2019-11-06 04:17:27,579 train 050 1.551836e-02 -0.840576
2019-11-06 04:17:37,888 train 100 1.554344e-02 -0.836052
2019-11-06 04:17:48,178 train 150 1.546454e-02 -0.684214
2019-11-06 04:17:58,460 train 200 1.553817e-02 -0.670242
2019-11-06 04:18:08,614 train 250 1.548311e-02 -0.693175
2019-11-06 04:18:18,762 train 300 1.553429e-02 -0.736825
2019-11-06 04:18:28,939 train 350 1.556245e-02 -0.746269
2019-11-06 04:18:39,095 train 400 1.557230e-02 -0.719106
2019-11-06 04:18:49,297 train 450 1.561096e-02 -0.718671
2019-11-06 04:18:59,526 train 500 1.559172e-02 -0.711422
2019-11-06 04:19:09,666 train 550 1.562379e-02 -0.747904
2019-11-06 04:19:19,818 train 600 1.559157e-02 -0.733712
2019-11-06 04:19:29,965 train 650 1.562091e-02 -0.744864
2019-11-06 04:19:40,135 train 700 1.563307e-02 -0.727306
2019-11-06 04:19:50,319 train 750 1.564509e-02 -0.729151
2019-11-06 04:20:00,481 train 800 1.562806e-02 -0.712449
2019-11-06 04:20:10,663 train 850 1.563634e-02 -0.699176
2019-11-06 04:20:13,703 training loss; R2: 1.562910e-02 -0.692468
2019-11-06 04:20:14,265 valid 000 1.388405e-02 -1.016396
2019-11-06 04:20:24,033 valid 050 1.315566e-02 -0.780074
2019-11-06 04:20:32,658 validation loss; R2: 1.306328e-02 -0.778622
2019-11-06 04:20:32,723 epoch 342 lr 1.000000e-04
2019-11-06 04:20:33,390 train 000 1.519347e-02 0.004375
2019-11-06 04:20:43,594 train 050 1.560729e-02 -0.776159
2019-11-06 04:20:53,772 train 100 1.563934e-02 -0.687492
2019-11-06 04:21:03,969 train 150 1.574648e-02 -0.639708
2019-11-06 04:21:14,127 train 200 1.568156e-02 -0.636631
2019-11-06 04:21:24,305 train 250 1.563702e-02 -0.662327
2019-11-06 04:21:34,505 train 300 1.559188e-02 -0.663189
2019-11-06 04:21:44,693 train 350 1.562267e-02 -0.671081
2019-11-06 04:21:54,870 train 400 1.564746e-02 -0.691605
2019-11-06 04:22:05,052 train 450 1.568728e-02 -0.714228
2019-11-06 04:22:15,216 train 500 1.567853e-02 -0.728070
2019-11-06 04:22:25,396 train 550 1.568234e-02 -0.704980
2019-11-06 04:22:35,538 train 600 1.569128e-02 -0.708514
2019-11-06 04:22:45,673 train 650 1.567700e-02 -0.696179
2019-11-06 04:22:55,807 train 700 1.568454e-02 -0.695595
2019-11-06 04:23:05,997 train 750 1.564874e-02 -0.693479
2019-11-06 04:23:16,167 train 800 1.563557e-02 -0.724462
2019-11-06 04:23:26,331 train 850 1.563520e-02 -0.731137
2019-11-06 04:23:29,359 training loss; R2: 1.563012e-02 -0.731634
2019-11-06 04:23:29,881 valid 000 1.128957e-02 -1.250525
2019-11-06 04:23:39,829 valid 050 1.357641e-02 -1.236243
2019-11-06 04:23:48,509 validation loss; R2: 1.372925e-02 -1.152281
2019-11-06 04:23:48,572 epoch 343 lr 1.000000e-04
2019-11-06 04:23:49,328 train 000 1.661538e-02 -1.474190
2019-11-06 04:23:59,445 train 050 1.573084e-02 -0.590429
2019-11-06 04:24:09,590 train 100 1.558196e-02 -0.799363
2019-11-06 04:24:19,741 train 150 1.570771e-02 -0.845503
2019-11-06 04:24:29,857 train 200 1.566593e-02 -0.868971
2019-11-06 04:24:39,958 train 250 1.564196e-02 -0.828067
2019-11-06 04:24:50,083 train 300 1.562008e-02 -7.792729
2019-11-06 04:25:00,278 train 350 1.560535e-02 -7.319792
2019-11-06 04:25:10,521 train 400 1.562598e-02 -6.467966
2019-11-06 04:25:20,737 train 450 1.563807e-02 -5.800819
2019-11-06 04:25:30,907 train 500 1.563490e-02 -5.295963
2019-11-06 04:25:41,073 train 550 1.564488e-02 -4.878844
2019-11-06 04:25:51,256 train 600 1.565667e-02 -4.509635
2019-11-06 04:26:01,392 train 650 1.566592e-02 -4.220707
2019-11-06 04:26:11,458 train 700 1.568408e-02 -3.981739
2019-11-06 04:26:21,587 train 750 1.565711e-02 -3.758929
2019-11-06 04:26:31,735 train 800 1.564796e-02 -3.572637
2019-11-06 04:26:41,876 train 850 1.563932e-02 -3.398580
2019-11-06 04:26:44,898 training loss; R2: 1.563544e-02 -3.345357
2019-11-06 04:26:45,415 valid 000 1.223840e-02 -1.403216
2019-11-06 04:26:55,244 valid 050 1.285446e-02 -0.923037
2019-11-06 04:27:03,892 validation loss; R2: 1.287222e-02 -0.937907
2019-11-06 04:27:03,957 epoch 344 lr 1.000000e-04
2019-11-06 04:27:04,642 train 000 1.683480e-02 -0.063814
2019-11-06 04:27:14,784 train 050 1.550836e-02 -0.602392
2019-11-06 04:27:24,938 train 100 1.559374e-02 -0.736476
2019-11-06 04:27:35,100 train 150 1.557105e-02 -0.728384
2019-11-06 04:27:45,257 train 200 1.561542e-02 -0.737049
2019-11-06 04:27:55,335 train 250 1.558495e-02 -0.684522
2019-11-06 04:28:05,433 train 300 1.556628e-02 -0.700998
2019-11-06 04:28:15,606 train 350 1.557126e-02 -0.688831
2019-11-06 04:28:25,745 train 400 1.555187e-02 -0.668523
2019-11-06 04:28:35,913 train 450 1.556393e-02 -11.298000
2019-11-06 04:28:46,114 train 500 1.557724e-02 -10.226681
2019-11-06 04:28:56,299 train 550 1.564057e-02 -10.371280
2019-11-06 04:29:06,476 train 600 1.565526e-02 -9.549026
2019-11-06 04:29:16,647 train 650 1.567429e-02 -8.862435
2019-11-06 04:29:26,834 train 700 1.566490e-02 -8.274152
2019-11-06 04:29:37,031 train 750 1.566295e-02 -7.765498
2019-11-06 04:29:47,202 train 800 1.565167e-02 -7.356636
2019-11-06 04:29:57,396 train 850 1.563972e-02 -6.964357
2019-11-06 04:30:00,438 training loss; R2: 1.563882e-02 -6.858046
2019-11-06 04:30:01,009 valid 000 1.638496e-02 -0.168021
2019-11-06 04:30:10,750 valid 050 1.425252e-02 -1.429049
2019-11-06 04:30:19,437 validation loss; R2: 1.426213e-02 -1.119353
2019-11-06 04:30:19,507 epoch 345 lr 1.000000e-04
2019-11-06 04:30:20,235 train 000 1.494073e-02 -0.509859
2019-11-06 04:30:30,569 train 050 1.539215e-02 -0.875656
2019-11-06 04:30:40,831 train 100 1.559484e-02 -0.807942
2019-11-06 04:30:51,068 train 150 1.563469e-02 -0.694018
2019-11-06 04:31:01,261 train 200 1.565636e-02 -0.699570
2019-11-06 04:31:11,431 train 250 1.561111e-02 -0.653352
2019-11-06 04:31:21,642 train 300 1.558397e-02 -0.685550
2019-11-06 04:31:31,843 train 350 1.558154e-02 -0.697576
2019-11-06 04:31:41,971 train 400 1.558475e-02 -0.689950
2019-11-06 04:31:52,151 train 450 1.561035e-02 -0.704981
2019-11-06 04:32:02,313 train 500 1.563993e-02 -0.683246
2019-11-06 04:32:12,503 train 550 1.561834e-02 -0.680018
2019-11-06 04:32:22,667 train 600 1.561269e-02 -0.683920
2019-11-06 04:32:32,836 train 650 1.561359e-02 -0.676208
2019-11-06 04:32:42,997 train 700 1.561481e-02 -0.673987
2019-11-06 04:32:53,196 train 750 1.562127e-02 -0.661679
2019-11-06 04:33:03,355 train 800 1.561411e-02 -0.652752
2019-11-06 04:33:13,517 train 850 1.559391e-02 -0.652141
2019-11-06 04:33:16,557 training loss; R2: 1.558463e-02 -0.646765
2019-11-06 04:33:17,112 valid 000 1.479862e-02 -0.339940
2019-11-06 04:33:26,902 valid 050 1.647748e-02 -0.339203
2019-11-06 04:33:35,557 validation loss; R2: 1.637009e-02 -0.564767
2019-11-06 04:33:35,620 epoch 346 lr 1.000000e-04
2019-11-06 04:33:36,334 train 000 1.413448e-02 -0.321674
2019-11-06 04:33:46,518 train 050 1.594182e-02 -0.564838
2019-11-06 04:33:56,701 train 100 1.576040e-02 -0.669852
2019-11-06 04:34:06,850 train 150 1.572595e-02 -0.835035
2019-11-06 04:34:17,005 train 200 1.570342e-02 -2.006426
2019-11-06 04:34:27,160 train 250 1.565887e-02 -1.809512
2019-11-06 04:34:37,334 train 300 1.569927e-02 -1.640639
2019-11-06 04:34:47,464 train 350 1.569842e-02 -1.532696
2019-11-06 04:34:57,612 train 400 1.570009e-02 -1.407853
2019-11-06 04:35:07,808 train 450 1.563511e-02 -1.292445
2019-11-06 04:35:17,974 train 500 1.566080e-02 -1.217036
2019-11-06 04:35:28,144 train 550 1.564294e-02 -1.191434
2019-11-06 04:35:38,316 train 600 1.567367e-02 -1.186742
2019-11-06 04:35:48,474 train 650 1.566816e-02 -1.169805
2019-11-06 04:35:58,627 train 700 1.567622e-02 -1.126127
2019-11-06 04:36:08,777 train 750 1.568127e-02 -1.081272
2019-11-06 04:36:18,915 train 800 1.568527e-02 -1.069169
2019-11-06 04:36:29,038 train 850 1.569714e-02 -1.054313
2019-11-06 04:36:32,070 training loss; R2: 1.570770e-02 -1.043482
2019-11-06 04:36:32,653 valid 000 1.322725e-02 -0.324957
2019-11-06 04:36:42,432 valid 050 1.358282e-02 -0.893566
2019-11-06 04:36:51,056 validation loss; R2: 1.364722e-02 -0.797271
2019-11-06 04:36:51,132 epoch 347 lr 1.000000e-04
2019-11-06 04:36:51,885 train 000 1.642572e-02 0.019127
2019-11-06 04:37:02,090 train 050 1.562924e-02 -0.951083
2019-11-06 04:37:12,259 train 100 1.571240e-02 -0.735877
2019-11-06 04:37:22,432 train 150 1.569985e-02 -0.781869
2019-11-06 04:37:32,578 train 200 1.575306e-02 -0.732092
2019-11-06 04:37:42,745 train 250 1.570337e-02 -0.674105
2019-11-06 04:37:52,884 train 300 1.564194e-02 -0.682808
2019-11-06 04:38:03,029 train 350 1.562759e-02 -0.900532
2019-11-06 04:38:13,150 train 400 1.565065e-02 -0.868183
2019-11-06 04:38:23,284 train 450 1.569634e-02 -0.855610
2019-11-06 04:38:33,413 train 500 1.565018e-02 -0.936374
2019-11-06 04:38:43,548 train 550 1.564122e-02 -0.931338
2019-11-06 04:38:53,672 train 600 1.561588e-02 -0.917924
2019-11-06 04:39:03,810 train 650 1.562317e-02 -0.901906
2019-11-06 04:39:13,915 train 700 1.561694e-02 -0.905758
2019-11-06 04:39:24,059 train 750 1.562982e-02 -0.884826
2019-11-06 04:39:34,204 train 800 1.562644e-02 -0.880989
2019-11-06 04:39:44,369 train 850 1.565327e-02 -0.864982
2019-11-06 04:39:47,405 training loss; R2: 1.564310e-02 -0.860330
2019-11-06 04:39:47,916 valid 000 1.407453e-02 0.174822
2019-11-06 04:39:57,700 valid 050 1.678801e-02 -0.646515
2019-11-06 04:40:06,478 validation loss; R2: 1.673533e-02 -0.603243
2019-11-06 04:40:06,556 epoch 348 lr 1.000000e-04
2019-11-06 04:40:07,258 train 000 1.438867e-02 0.157515
2019-11-06 04:40:17,481 train 050 1.583959e-02 -0.521414
2019-11-06 04:40:27,741 train 100 1.573157e-02 -0.560483
2019-11-06 04:40:37,884 train 150 1.575296e-02 -0.514769
2019-11-06 04:40:48,062 train 200 1.572261e-02 -0.586507
2019-11-06 04:40:58,221 train 250 1.563879e-02 -0.616160
2019-11-06 04:41:08,395 train 300 1.563836e-02 -0.673363
2019-11-06 04:41:18,560 train 350 1.566975e-02 -0.623314
2019-11-06 04:41:28,719 train 400 1.570057e-02 -0.633319
2019-11-06 04:41:38,853 train 450 1.569743e-02 -0.620787
2019-11-06 04:41:49,048 train 500 1.571056e-02 -0.637460
2019-11-06 04:41:59,207 train 550 1.569255e-02 -0.685318
2019-11-06 04:42:09,434 train 600 1.568995e-02 -0.702607
2019-11-06 04:42:19,640 train 650 1.566676e-02 -0.746771
2019-11-06 04:42:29,844 train 700 1.568761e-02 -0.732303
2019-11-06 04:42:40,037 train 750 1.565930e-02 -0.736379
2019-11-06 04:42:50,187 train 800 1.564684e-02 -0.720960
2019-11-06 04:43:00,356 train 850 1.565848e-02 -0.717011
2019-11-06 04:43:03,377 training loss; R2: 1.565942e-02 -0.730938
2019-11-06 04:43:03,940 valid 000 1.428288e-02 -6.791437
2019-11-06 04:43:13,685 valid 050 1.291202e-02 -0.881921
2019-11-06 04:43:22,389 validation loss; R2: 1.282092e-02 -1.011317
2019-11-06 04:43:22,463 epoch 349 lr 1.000000e-04
2019-11-06 04:43:23,183 train 000 1.636175e-02 -0.089877
2019-11-06 04:43:33,383 train 050 1.544105e-02 -0.550016
2019-11-06 04:43:43,607 train 100 1.543560e-02 -0.638735
2019-11-06 04:43:53,793 train 150 1.554846e-02 -0.649527
2019-11-06 04:44:03,967 train 200 1.554652e-02 -0.738907
2019-11-06 04:44:14,120 train 250 1.548060e-02 -0.706421
2019-11-06 04:44:24,269 train 300 1.549028e-02 -0.723460
2019-11-06 04:44:34,424 train 350 1.551270e-02 -0.725935
2019-11-06 04:44:44,583 train 400 1.549086e-02 -0.714780
2019-11-06 04:44:54,740 train 450 1.552480e-02 -0.774595
2019-11-06 04:45:04,874 train 500 1.552620e-02 -0.756999
2019-11-06 04:45:15,002 train 550 1.552498e-02 -0.770615
2019-11-06 04:45:25,135 train 600 1.552952e-02 -0.782975
2019-11-06 04:45:35,292 train 650 1.554802e-02 -0.755545
2019-11-06 04:45:45,438 train 700 1.556264e-02 -0.746188
2019-11-06 04:45:55,562 train 750 1.556762e-02 -0.747225
2019-11-06 04:46:05,682 train 800 1.559793e-02 -0.738333
2019-11-06 04:46:15,801 train 850 1.557353e-02 -0.751927
2019-11-06 04:46:18,824 training loss; R2: 1.556128e-02 -0.745761
2019-11-06 04:46:19,486 valid 000 1.163019e-02 0.039114
2019-11-06 04:46:29,120 valid 050 1.288729e-02 -0.704373
2019-11-06 04:46:37,859 validation loss; R2: 1.286588e-02 -0.933265
2019-11-06 04:46:37,930 epoch 350 lr 1.000000e-04
2019-11-06 04:46:38,634 train 000 1.647785e-02 -0.027444
2019-11-06 04:46:48,728 train 050 1.507599e-02 -1.029181
2019-11-06 04:46:58,908 train 100 1.532782e-02 -0.800249
2019-11-06 04:47:09,069 train 150 1.535904e-02 -0.792620
2019-11-06 04:47:19,176 train 200 1.538763e-02 -0.837896
2019-11-06 04:47:29,245 train 250 1.535999e-02 -0.843927
2019-11-06 04:47:39,408 train 300 1.542304e-02 -0.868879
2019-11-06 04:47:49,526 train 350 1.551332e-02 -0.858335
2019-11-06 04:47:59,609 train 400 1.551323e-02 -0.834691
2019-11-06 04:48:09,668 train 450 1.555661e-02 -0.850312
2019-11-06 04:48:19,829 train 500 1.554115e-02 -0.837230
2019-11-06 04:48:29,943 train 550 1.556907e-02 -0.806985
2019-11-06 04:48:40,053 train 600 1.556676e-02 -0.784006
2019-11-06 04:48:50,145 train 650 1.555880e-02 -0.769286
2019-11-06 04:49:00,349 train 700 1.556965e-02 -0.767305
2019-11-06 04:49:10,401 train 750 1.557659e-02 -0.949378
2019-11-06 04:49:20,468 train 800 1.557383e-02 -0.929361
2019-11-06 04:49:30,598 train 850 1.556358e-02 -0.906636
2019-11-06 04:49:33,636 training loss; R2: 1.556526e-02 -0.905551
2019-11-06 04:49:34,208 valid 000 1.440871e-02 -0.645543
2019-11-06 04:49:44,028 valid 050 1.376354e-02 -0.866914
2019-11-06 04:49:52,722 validation loss; R2: 1.369519e-02 -0.870508
2019-11-06 04:49:52,806 epoch 351 lr 1.000000e-04
2019-11-06 04:49:53,484 train 000 1.935270e-02 0.071564
2019-11-06 04:50:03,709 train 050 1.563807e-02 -0.390640
2019-11-06 04:50:13,898 train 100 1.567572e-02 -0.554337
2019-11-06 04:50:24,045 train 150 1.552998e-02 -0.679088
2019-11-06 04:50:34,195 train 200 1.556182e-02 -0.745621
2019-11-06 04:50:44,353 train 250 1.562766e-02 -0.727056
2019-11-06 04:50:54,474 train 300 1.561587e-02 -0.731150
2019-11-06 04:51:04,606 train 350 1.565630e-02 -0.722394
2019-11-06 04:51:14,717 train 400 1.568176e-02 -0.763901
2019-11-06 04:51:24,840 train 450 1.567810e-02 -0.748221
2019-11-06 04:51:34,945 train 500 1.567261e-02 -0.760776
2019-11-06 04:51:45,066 train 550 1.566175e-02 -0.754264
2019-11-06 04:51:55,203 train 600 1.563296e-02 -0.768742
2019-11-06 04:52:05,379 train 650 1.560746e-02 -0.762279
2019-11-06 04:52:15,541 train 700 1.560500e-02 -0.755430
2019-11-06 04:52:25,729 train 750 1.559942e-02 -0.744427
2019-11-06 04:52:35,907 train 800 1.559719e-02 -0.715793
2019-11-06 04:52:46,033 train 850 1.560226e-02 -0.749019
2019-11-06 04:52:49,052 training loss; R2: 1.559393e-02 -0.773766
2019-11-06 04:52:49,613 valid 000 1.087857e-02 -0.416525
2019-11-06 04:52:59,362 valid 050 1.370364e-02 -1.224973
2019-11-06 04:53:08,053 validation loss; R2: 1.370075e-02 -1.330149
2019-11-06 04:53:08,120 epoch 352 lr 1.000000e-04
2019-11-06 04:53:08,844 train 000 1.387310e-02 -0.529011
2019-11-06 04:53:19,101 train 050 1.543039e-02 -0.546917
2019-11-06 04:53:29,349 train 100 1.546066e-02 -0.500612
2019-11-06 04:53:39,560 train 150 1.548586e-02 -0.516306
2019-11-06 04:53:49,783 train 200 1.555537e-02 -0.512512
2019-11-06 04:53:59,928 train 250 1.557083e-02 -0.600122
2019-11-06 04:54:10,077 train 300 1.560974e-02 -0.691936
2019-11-06 04:54:20,192 train 350 1.562853e-02 -0.699109
2019-11-06 04:54:30,314 train 400 1.557881e-02 -0.684066
2019-11-06 04:54:40,387 train 450 1.557094e-02 -0.678214
2019-11-06 04:54:50,508 train 500 1.554618e-02 -0.701776
2019-11-06 04:55:00,626 train 550 1.556756e-02 -0.687106
2019-11-06 04:55:10,785 train 600 1.558119e-02 -0.675305
2019-11-06 04:55:20,941 train 650 1.560705e-02 -0.689443
2019-11-06 04:55:31,097 train 700 1.558595e-02 -0.700248
2019-11-06 04:55:41,247 train 750 1.559041e-02 -0.697850
2019-11-06 04:55:51,437 train 800 1.559521e-02 -0.688827
2019-11-06 04:56:01,653 train 850 1.558941e-02 -0.700637
2019-11-06 04:56:04,716 training loss; R2: 1.559247e-02 -0.708910
2019-11-06 04:56:05,232 valid 000 1.283372e-02 -0.021999
2019-11-06 04:56:15,092 valid 050 1.368475e-02 -0.731364
2019-11-06 04:56:24,002 validation loss; R2: 1.354495e-02 -0.865134
2019-11-06 04:56:24,072 epoch 353 lr 1.000000e-04
2019-11-06 04:56:24,750 train 000 1.327306e-02 -0.073830
2019-11-06 04:56:34,964 train 050 1.550042e-02 -0.548402
2019-11-06 04:56:45,153 train 100 1.530122e-02 -0.678126
2019-11-06 04:56:55,327 train 150 1.547971e-02 -0.669959
2019-11-06 04:57:05,485 train 200 1.545899e-02 -0.712044
2019-11-06 04:57:15,630 train 250 1.552733e-02 -0.854127
2019-11-06 04:57:25,773 train 300 1.557586e-02 -0.812606
2019-11-06 04:57:35,918 train 350 1.553095e-02 -0.761394
2019-11-06 04:57:46,069 train 400 1.561657e-02 -0.778125
2019-11-06 04:57:56,218 train 450 1.561361e-02 -0.762063
2019-11-06 04:58:06,402 train 500 1.561921e-02 -0.766025
2019-11-06 04:58:16,602 train 550 1.565362e-02 -0.958836
2019-11-06 04:58:26,802 train 600 1.566476e-02 -0.916800
2019-11-06 04:58:37,027 train 650 1.565416e-02 -0.889541
2019-11-06 04:58:47,204 train 700 1.565042e-02 -0.874134
2019-11-06 04:58:57,367 train 750 1.564033e-02 -0.857735
2019-11-06 04:59:07,502 train 800 1.561605e-02 -0.856585
2019-11-06 04:59:17,640 train 850 1.559486e-02 -0.852201
2019-11-06 04:59:20,667 training loss; R2: 1.559881e-02 -0.854628
2019-11-06 04:59:21,245 valid 000 1.451993e-02 0.000713
2019-11-06 04:59:31,098 valid 050 1.254719e-02 -1.094636
2019-11-06 04:59:39,813 validation loss; R2: 1.254666e-02 -1.070553
2019-11-06 04:59:39,877 epoch 354 lr 1.000000e-04
2019-11-06 04:59:40,630 train 000 1.445397e-02 -6.965928
2019-11-06 04:59:50,802 train 050 1.540639e-02 -0.755336
2019-11-06 05:00:01,041 train 100 1.562475e-02 -0.714789
2019-11-06 05:00:11,273 train 150 1.552928e-02 -0.710895
2019-11-06 05:00:21,502 train 200 1.544340e-02 -0.827731
2019-11-06 05:00:31,698 train 250 1.548932e-02 -0.797727
2019-11-06 05:00:41,893 train 300 1.551358e-02 -0.727824
2019-11-06 05:00:52,085 train 350 1.549383e-02 -0.716007
2019-11-06 05:01:02,263 train 400 1.553050e-02 -0.712514
2019-11-06 05:01:12,457 train 450 1.553956e-02 -0.681906
2019-11-06 05:01:22,684 train 500 1.556071e-02 -0.656045
2019-11-06 05:01:32,930 train 550 1.561464e-02 -0.648480
2019-11-06 05:01:43,165 train 600 1.561806e-02 -0.682246
2019-11-06 05:01:53,402 train 650 1.560152e-02 -0.679231
2019-11-06 05:02:03,646 train 700 1.559073e-02 -0.677961
2019-11-06 05:02:13,880 train 750 1.557209e-02 -0.695613
2019-11-06 05:02:24,097 train 800 1.559667e-02 -0.692362
2019-11-06 05:02:34,311 train 850 1.560669e-02 -0.709826
2019-11-06 05:02:37,360 training loss; R2: 1.560869e-02 -0.701621
2019-11-06 05:02:37,917 valid 000 1.582220e-02 -1.522738
2019-11-06 05:02:47,691 valid 050 1.438936e-02 -0.610227
2019-11-06 05:02:56,355 validation loss; R2: 1.430375e-02 -0.786783
2019-11-06 05:02:56,417 epoch 355 lr 1.000000e-04
2019-11-06 05:02:57,148 train 000 1.650932e-02 -0.154018
2019-11-06 05:03:07,365 train 050 1.555042e-02 -0.727777
2019-11-06 05:03:17,474 train 100 1.563649e-02 -0.677685
2019-11-06 05:03:27,560 train 150 1.560528e-02 -0.656838
2019-11-06 05:03:37,739 train 200 1.553977e-02 -0.652080
2019-11-06 05:03:47,858 train 250 1.550626e-02 -0.704215
2019-11-06 05:03:57,933 train 300 1.553184e-02 -0.681866
2019-11-06 05:04:08,029 train 350 1.555220e-02 -0.714744
2019-11-06 05:04:18,183 train 400 1.555096e-02 -0.730620
2019-11-06 05:04:28,321 train 450 1.555281e-02 -0.734663
2019-11-06 05:04:38,399 train 500 1.554694e-02 -0.706829
2019-11-06 05:04:48,492 train 550 1.553483e-02 -0.702120
2019-11-06 05:04:58,665 train 600 1.551496e-02 -0.749208
2019-11-06 05:05:08,783 train 650 1.551409e-02 -0.768139
2019-11-06 05:05:18,873 train 700 1.553022e-02 -0.744469
2019-11-06 05:05:28,975 train 750 1.553407e-02 -0.746488
2019-11-06 05:05:39,152 train 800 1.553327e-02 -0.795235
2019-11-06 05:05:49,302 train 850 1.551564e-02 -0.793585
2019-11-06 05:05:52,335 training loss; R2: 1.551124e-02 -0.787488
2019-11-06 05:05:52,849 valid 000 1.225706e-02 -0.355654
2019-11-06 05:06:02,671 valid 050 1.354905e-02 -0.978512
2019-11-06 05:06:11,361 validation loss; R2: 1.332907e-02 -0.971973
2019-11-06 05:06:11,427 epoch 356 lr 1.000000e-04
2019-11-06 05:06:12,143 train 000 1.356422e-02 -2.383656
2019-11-06 05:06:22,333 train 050 1.556955e-02 -0.953672
2019-11-06 05:06:32,496 train 100 1.558981e-02 -0.850635
2019-11-06 05:06:42,657 train 150 1.566702e-02 -0.892752
2019-11-06 05:06:52,805 train 200 1.553985e-02 -0.858471
2019-11-06 05:07:02,956 train 250 1.554831e-02 -0.818679
2019-11-06 05:07:13,124 train 300 1.559631e-02 -0.895604
2019-11-06 05:07:23,277 train 350 1.558383e-02 -0.834200
2019-11-06 05:07:33,428 train 400 1.555559e-02 -0.804944
2019-11-06 05:07:43,570 train 450 1.555318e-02 -0.773409
2019-11-06 05:07:53,713 train 500 1.559477e-02 -6.089167
2019-11-06 05:08:03,861 train 550 1.559470e-02 -5.595224
2019-11-06 05:08:14,012 train 600 1.556398e-02 -5.171988
2019-11-06 05:08:24,150 train 650 1.556060e-02 -5.039762
2019-11-06 05:08:34,309 train 700 1.557786e-02 -4.728434
2019-11-06 05:08:44,458 train 750 1.558480e-02 -4.447430
2019-11-06 05:08:54,588 train 800 1.562642e-02 -4.206834
2019-11-06 05:09:04,730 train 850 1.562111e-02 -3.996502
2019-11-06 05:09:07,748 training loss; R2: 1.561779e-02 -3.938635
2019-11-06 05:09:08,270 valid 000 1.379696e-02 -9.434441
2019-11-06 05:09:18,029 valid 050 1.425325e-02 -0.913614
2019-11-06 05:09:26,680 validation loss; R2: 1.405043e-02 -0.971262
2019-11-06 05:09:26,745 epoch 357 lr 1.000000e-04
2019-11-06 05:09:27,432 train 000 1.581830e-02 -1.028979
2019-11-06 05:09:37,633 train 050 1.548212e-02 -1.127319
2019-11-06 05:09:47,837 train 100 1.539276e-02 -0.894031
2019-11-06 05:09:58,046 train 150 1.534546e-02 -0.770025
2019-11-06 05:10:08,269 train 200 1.535486e-02 -0.720327
2019-11-06 05:10:18,456 train 250 1.533469e-02 -0.739295
2019-11-06 05:10:28,658 train 300 1.535289e-02 -0.784782
2019-11-06 05:10:38,835 train 350 1.538577e-02 -0.774001
2019-11-06 05:10:49,023 train 400 1.541680e-02 -0.896811
2019-11-06 05:10:59,164 train 450 1.546539e-02 -0.869751
2019-11-06 05:11:09,325 train 500 1.548246e-02 -0.835890
2019-11-06 05:11:19,457 train 550 1.550344e-02 -0.844364
2019-11-06 05:11:29,644 train 600 1.550490e-02 -0.814987
2019-11-06 05:11:39,818 train 650 1.552780e-02 -0.837498
2019-11-06 05:11:50,020 train 700 1.550941e-02 -0.830513
2019-11-06 05:12:00,198 train 750 1.552541e-02 -0.804530
2019-11-06 05:12:10,400 train 800 1.549736e-02 -0.796971
2019-11-06 05:12:20,579 train 850 1.550141e-02 -0.801955
2019-11-06 05:12:23,630 training loss; R2: 1.549646e-02 -0.796990
2019-11-06 05:12:24,166 valid 000 1.401760e-02 -0.156377
2019-11-06 05:12:34,002 valid 050 1.325310e-02 -0.870844
2019-11-06 05:12:42,792 validation loss; R2: 1.324787e-02 -0.894102
2019-11-06 05:12:42,857 epoch 358 lr 1.000000e-04
2019-11-06 05:12:43,630 train 000 1.163463e-02 -1.834887
2019-11-06 05:12:53,881 train 050 1.520437e-02 -0.526210
2019-11-06 05:13:04,051 train 100 1.541501e-02 -0.725759
2019-11-06 05:13:14,221 train 150 1.558576e-02 -0.731372
2019-11-06 05:13:24,378 train 200 1.559412e-02 -0.712566
2019-11-06 05:13:34,525 train 250 1.552266e-02 -0.669181
2019-11-06 05:13:44,687 train 300 1.551429e-02 -0.656467
2019-11-06 05:13:54,854 train 350 1.551972e-02 -0.649296
2019-11-06 05:14:04,985 train 400 1.548378e-02 -0.631304
2019-11-06 05:14:15,149 train 450 1.547771e-02 -0.634709
2019-11-06 05:14:25,295 train 500 1.551212e-02 -0.643986
2019-11-06 05:14:35,461 train 550 1.550952e-02 -0.657676
2019-11-06 05:14:45,665 train 600 1.549682e-02 -0.670398
2019-11-06 05:14:55,994 train 650 1.547748e-02 -0.664958
2019-11-06 05:15:06,400 train 700 1.548249e-02 -0.684353
2019-11-06 05:15:16,570 train 750 1.548282e-02 -0.689855
2019-11-06 05:15:26,731 train 800 1.548605e-02 -0.689816
2019-11-06 05:15:36,917 train 850 1.549634e-02 -0.699067
2019-11-06 05:15:39,952 training loss; R2: 1.549086e-02 -0.701208
2019-11-06 05:15:40,527 valid 000 1.228036e-02 -0.358195
2019-11-06 05:15:50,299 valid 050 1.527561e-02 -1.277054
2019-11-06 05:15:59,051 validation loss; R2: 1.504473e-02 -1.367624
2019-11-06 05:15:59,119 epoch 359 lr 1.000000e-04
2019-11-06 05:15:59,799 train 000 1.757187e-02 -0.661341
2019-11-06 05:16:10,061 train 050 1.557084e-02 -0.541512
2019-11-06 05:16:20,299 train 100 1.556171e-02 -0.762662
2019-11-06 05:16:30,500 train 150 1.563014e-02 -0.803568
2019-11-06 05:16:40,693 train 200 1.565881e-02 -0.732742
2019-11-06 05:16:50,851 train 250 1.562362e-02 -0.701257
2019-11-06 05:17:01,031 train 300 1.566804e-02 -0.686668
2019-11-06 05:17:11,202 train 350 1.566362e-02 -0.680378
2019-11-06 05:17:21,377 train 400 1.569076e-02 -0.692720
2019-11-06 05:17:31,562 train 450 1.568601e-02 -0.662200
2019-11-06 05:17:41,743 train 500 1.566014e-02 -0.673312
2019-11-06 05:17:51,831 train 550 1.563902e-02 -0.679574
2019-11-06 05:18:01,928 train 600 1.562208e-02 -0.677322
2019-11-06 05:18:11,986 train 650 1.559724e-02 -0.697000
2019-11-06 05:18:22,057 train 700 1.561545e-02 -0.685808
2019-11-06 05:18:32,132 train 750 1.560847e-02 -0.684613
2019-11-06 05:18:42,201 train 800 1.560502e-02 -0.680269
2019-11-06 05:18:52,262 train 850 1.560981e-02 -0.680992
2019-11-06 05:18:55,272 training loss; R2: 1.560116e-02 -0.679046
2019-11-06 05:18:55,780 valid 000 1.603621e-02 0.181759
2019-11-06 05:19:05,549 valid 050 1.298845e-02 -1.022683
2019-11-06 05:19:14,222 validation loss; R2: 1.283059e-02 -1.250285
2019-11-06 05:19:14,287 epoch 360 lr 1.000000e-04
2019-11-06 05:19:15,011 train 000 1.478687e-02 -0.781754
2019-11-06 05:19:25,145 train 050 1.533610e-02 -0.786541
2019-11-06 05:19:35,235 train 100 1.547893e-02 -0.690810
2019-11-06 05:19:45,326 train 150 1.547270e-02 -1.097024
2019-11-06 05:19:55,398 train 200 1.547843e-02 -1.027882
2019-11-06 05:20:05,498 train 250 1.551233e-02 -0.981560
2019-11-06 05:20:15,575 train 300 1.545097e-02 -0.937094
2019-11-06 05:20:25,651 train 350 1.549687e-02 -0.915226
2019-11-06 05:20:35,720 train 400 1.547984e-02 -0.868262
2019-11-06 05:20:45,803 train 450 1.553747e-02 -0.843930
2019-11-06 05:20:55,893 train 500 1.551722e-02 -0.813401
2019-11-06 05:21:06,053 train 550 1.550271e-02 -0.794471
2019-11-06 05:21:16,245 train 600 1.552244e-02 -0.812765
2019-11-06 05:21:26,433 train 650 1.554317e-02 -0.790843
2019-11-06 05:21:36,606 train 700 1.556294e-02 -0.783606
2019-11-06 05:21:46,782 train 750 1.555974e-02 -0.781797
2019-11-06 05:21:56,955 train 800 1.554755e-02 -0.796159
2019-11-06 05:22:07,124 train 850 1.555180e-02 -0.789004
2019-11-06 05:22:10,163 training loss; R2: 1.555505e-02 -0.778568
2019-11-06 05:22:10,684 valid 000 1.387486e-02 -0.038113
2019-11-06 05:22:20,479 valid 050 1.369846e-02 -0.780264
2019-11-06 05:22:29,165 validation loss; R2: 1.377458e-02 -0.775285
2019-11-06 05:22:29,237 epoch 361 lr 1.000000e-04
2019-11-06 05:22:29,992 train 000 1.766243e-02 -5.426365
2019-11-06 05:22:40,128 train 050 1.571855e-02 -0.934394
2019-11-06 05:22:50,314 train 100 1.556771e-02 -0.748704
2019-11-06 05:23:00,393 train 150 1.557987e-02 -0.660595
2019-11-06 05:23:10,492 train 200 1.558673e-02 -0.781992
2019-11-06 05:23:20,660 train 250 1.559606e-02 -0.722887
2019-11-06 05:23:30,873 train 300 1.555302e-02 -0.701617
2019-11-06 05:23:40,993 train 350 1.559932e-02 -0.675644
2019-11-06 05:23:51,126 train 400 1.554691e-02 -0.778793
2019-11-06 05:24:01,329 train 450 1.558062e-02 -0.790560
2019-11-06 05:24:11,561 train 500 1.553977e-02 -0.807146
2019-11-06 05:24:21,676 train 550 1.556038e-02 -0.792767
2019-11-06 05:24:31,806 train 600 1.552286e-02 -0.789898
2019-11-06 05:24:41,955 train 650 1.550834e-02 -0.780259
2019-11-06 05:24:52,194 train 700 1.549063e-02 -0.787414
2019-11-06 05:25:02,312 train 750 1.549340e-02 -0.772497
2019-11-06 05:25:12,423 train 800 1.551509e-02 -0.784058
2019-11-06 05:25:22,605 train 850 1.553002e-02 -0.789808
2019-11-06 05:25:25,651 training loss; R2: 1.553486e-02 -0.789917
2019-11-06 05:25:26,222 valid 000 1.413635e-02 0.207110
2019-11-06 05:25:36,121 valid 050 1.295062e-02 -0.967981
2019-11-06 05:25:44,783 validation loss; R2: 1.300761e-02 -1.129807
2019-11-06 05:25:44,848 epoch 362 lr 1.000000e-04
2019-11-06 05:25:45,606 train 000 1.589682e-02 -1.825132
2019-11-06 05:25:55,846 train 050 1.529513e-02 -0.664472
2019-11-06 05:26:06,043 train 100 1.552901e-02 -0.633757
2019-11-06 05:26:16,228 train 150 1.552460e-02 -1.706565
2019-11-06 05:26:26,414 train 200 1.551467e-02 -1.493144
2019-11-06 05:26:36,581 train 250 1.554503e-02 -1.303676
2019-11-06 05:26:46,749 train 300 1.555153e-02 -1.163260
2019-11-06 05:26:56,940 train 350 1.556944e-02 -1.123253
2019-11-06 05:27:07,166 train 400 1.553854e-02 -1.081279
2019-11-06 05:27:17,373 train 450 1.555682e-02 -1.015710
2019-11-06 05:27:27,579 train 500 1.553695e-02 -1.029606
2019-11-06 05:27:37,772 train 550 1.552880e-02 -0.995527
2019-11-06 05:27:47,967 train 600 1.556787e-02 -0.969764
2019-11-06 05:27:58,167 train 650 1.553649e-02 -1.022457
2019-11-06 05:28:08,354 train 700 1.553919e-02 -0.997920
2019-11-06 05:28:18,467 train 750 1.551055e-02 -0.990420
2019-11-06 05:28:28,597 train 800 1.550620e-02 -2.094599
2019-11-06 05:28:38,740 train 850 1.551096e-02 -2.011478
2019-11-06 05:28:41,773 training loss; R2: 1.551433e-02 -2.009179
2019-11-06 05:28:42,309 valid 000 1.091608e-02 -0.764672
2019-11-06 05:28:52,159 valid 050 1.318462e-02 -1.214699
2019-11-06 05:29:00,815 validation loss; R2: 1.320617e-02 -1.273697
2019-11-06 05:29:00,880 epoch 363 lr 1.000000e-04
2019-11-06 05:29:01,555 train 000 1.097106e-02 -0.444834
2019-11-06 05:29:11,792 train 050 1.589369e-02 -0.955419
2019-11-06 05:29:21,962 train 100 1.579407e-02 -0.782653
2019-11-06 05:29:32,147 train 150 1.569666e-02 -0.706671
2019-11-06 05:29:42,285 train 200 1.557003e-02 -0.651614
2019-11-06 05:29:52,396 train 250 1.559294e-02 -0.692566
2019-11-06 05:30:02,521 train 300 1.556296e-02 -0.676897
2019-11-06 05:30:12,631 train 350 1.551462e-02 -0.664402
2019-11-06 05:30:22,749 train 400 1.553295e-02 -0.674465
2019-11-06 05:30:32,847 train 450 1.552808e-02 -0.672049
2019-11-06 05:30:42,979 train 500 1.553510e-02 -0.653603
2019-11-06 05:30:53,085 train 550 1.553030e-02 -0.650793
2019-11-06 05:31:03,177 train 600 1.554556e-02 -0.672952
2019-11-06 05:31:13,241 train 650 1.551679e-02 -0.670315
2019-11-06 05:31:23,311 train 700 1.555197e-02 -0.691366
2019-11-06 05:31:33,347 train 750 1.553497e-02 -0.692082
2019-11-06 05:31:43,405 train 800 1.555354e-02 -0.706377
2019-11-06 05:31:53,469 train 850 1.557148e-02 -0.706745
2019-11-06 05:31:56,488 training loss; R2: 1.556799e-02 -0.739809
2019-11-06 05:31:57,007 valid 000 1.360020e-02 -0.773228
2019-11-06 05:32:06,818 valid 050 1.262398e-02 -0.933576
2019-11-06 05:32:15,484 validation loss; R2: 1.276988e-02 -1.069760
2019-11-06 05:32:15,569 epoch 364 lr 1.000000e-04
2019-11-06 05:32:16,342 train 000 1.246839e-02 0.127164
2019-11-06 05:32:26,485 train 050 1.539141e-02 -0.745645
2019-11-06 05:32:36,653 train 100 1.545065e-02 -0.651440
2019-11-06 05:32:46,829 train 150 1.542526e-02 -0.711169
2019-11-06 05:32:56,969 train 200 1.547657e-02 -0.703355
2019-11-06 05:33:07,132 train 250 1.551455e-02 -0.714803
2019-11-06 05:33:17,319 train 300 1.552652e-02 -0.809973
2019-11-06 05:33:27,485 train 350 1.557944e-02 -0.784621
2019-11-06 05:33:37,632 train 400 1.557468e-02 -0.775174
2019-11-06 05:33:47,738 train 450 1.559232e-02 -0.783993
2019-11-06 05:33:57,849 train 500 1.560047e-02 -0.773179
2019-11-06 05:34:07,997 train 550 1.558925e-02 -0.809577
2019-11-06 05:34:18,101 train 600 1.558901e-02 -0.795085
2019-11-06 05:34:28,177 train 650 1.559512e-02 -0.787729
2019-11-06 05:34:38,258 train 700 1.558281e-02 -0.797685
2019-11-06 05:34:48,427 train 750 1.559510e-02 -0.784577
2019-11-06 05:34:58,600 train 800 1.560568e-02 -0.775394
2019-11-06 05:35:08,731 train 850 1.560988e-02 -0.769119
2019-11-06 05:35:11,761 training loss; R2: 1.562278e-02 -0.763366
2019-11-06 05:35:12,329 valid 000 1.474714e-02 0.051958
2019-11-06 05:35:22,115 valid 050 1.399556e-02 -1.157241
2019-11-06 05:35:30,756 validation loss; R2: 1.389214e-02 -2.125863
2019-11-06 05:35:30,823 epoch 365 lr 1.000000e-04
2019-11-06 05:35:31,555 train 000 1.394606e-02 0.062798
2019-11-06 05:35:41,751 train 050 1.581734e-02 -0.728048
2019-11-06 05:35:51,952 train 100 1.585537e-02 -0.681901
2019-11-06 05:36:02,107 train 150 1.584053e-02 -0.690701
2019-11-06 05:36:12,247 train 200 1.580499e-02 -0.639982
2019-11-06 05:36:22,364 train 250 1.574799e-02 -0.632453
2019-11-06 05:36:32,511 train 300 1.570866e-02 -0.588696
2019-11-06 05:36:42,644 train 350 1.572081e-02 -1.434738
2019-11-06 05:36:52,781 train 400 1.564957e-02 -1.343647
2019-11-06 05:37:02,921 train 450 1.559666e-02 -1.299685
2019-11-06 05:37:13,090 train 500 1.558334e-02 -1.240854
2019-11-06 05:37:23,263 train 550 1.560493e-02 -1.169379
2019-11-06 05:37:33,428 train 600 1.559060e-02 -1.169488
2019-11-06 05:37:43,575 train 650 1.558236e-02 -1.137421
2019-11-06 05:37:53,738 train 700 1.560287e-02 -1.103275
2019-11-06 05:38:03,891 train 750 1.560396e-02 -1.068799
2019-11-06 05:38:14,029 train 800 1.561472e-02 -1.044646
2019-11-06 05:38:24,215 train 850 1.560305e-02 -1.060439
2019-11-06 05:38:27,242 training loss; R2: 1.560623e-02 -1.053772
2019-11-06 05:38:27,769 valid 000 1.614907e-02 -0.100157
2019-11-06 05:38:37,543 valid 050 1.614646e-02 -1.510923
2019-11-06 05:38:46,219 validation loss; R2: 1.635447e-02 -1.288278
2019-11-06 05:38:46,290 epoch 366 lr 1.000000e-04
2019-11-06 05:38:47,045 train 000 1.791026e-02 -1.612343
2019-11-06 05:38:57,290 train 050 1.549357e-02 -0.483506
2019-11-06 05:39:07,491 train 100 1.544906e-02 -2.153354
2019-11-06 05:39:17,653 train 150 1.544420e-02 -1.711913
2019-11-06 05:39:27,830 train 200 1.551740e-02 -1.457454
2019-11-06 05:39:37,937 train 250 1.551592e-02 -1.331691
2019-11-06 05:39:48,079 train 300 1.556517e-02 -1.207516
2019-11-06 05:39:58,221 train 350 1.553349e-02 -1.157234
2019-11-06 05:40:08,379 train 400 1.551258e-02 -1.112605
2019-11-06 05:40:18,508 train 450 1.550751e-02 -1.072949
2019-11-06 05:40:28,663 train 500 1.551150e-02 -1.080865
2019-11-06 05:40:38,814 train 550 1.553873e-02 -1.041645
2019-11-06 05:40:48,978 train 600 1.554037e-02 -1.018144
2019-11-06 05:40:59,138 train 650 1.555790e-02 -1.008587
2019-11-06 05:41:09,307 train 700 1.551974e-02 -0.993273
2019-11-06 05:41:19,438 train 750 1.551204e-02 -0.975980
2019-11-06 05:41:29,599 train 800 1.549057e-02 -0.967772
2019-11-06 05:41:39,752 train 850 1.549930e-02 -0.960128
2019-11-06 05:41:42,787 training loss; R2: 1.550621e-02 -0.954082
2019-11-06 05:41:43,331 valid 000 1.173782e-02 -0.421402
2019-11-06 05:41:53,368 valid 050 1.269777e-02 -1.406458
2019-11-06 05:42:01,994 validation loss; R2: 1.296804e-02 -1.440998
2019-11-06 05:42:02,061 epoch 367 lr 1.000000e-04
2019-11-06 05:42:02,781 train 000 1.421206e-02 -0.595611
2019-11-06 05:42:12,998 train 050 1.542498e-02 -0.864365
2019-11-06 05:42:23,166 train 100 1.562895e-02 -0.936156
2019-11-06 05:42:33,244 train 150 1.561100e-02 -1.482532
2019-11-06 05:42:43,305 train 200 1.557540e-02 -1.265412
2019-11-06 05:42:53,458 train 250 1.566833e-02 -1.178597
2019-11-06 05:43:03,589 train 300 1.565501e-02 -1.124426
2019-11-06 05:43:13,648 train 350 1.563731e-02 -1.098867
2019-11-06 05:43:23,724 train 400 1.563421e-02 -1.031691
2019-11-06 05:43:33,881 train 450 1.564339e-02 -1.000695
2019-11-06 05:43:43,956 train 500 1.560878e-02 -0.970373
2019-11-06 05:43:53,988 train 550 1.557181e-02 -0.942941
2019-11-06 05:44:04,096 train 600 1.556809e-02 -0.930163
2019-11-06 05:44:14,239 train 650 1.553725e-02 -0.926934
2019-11-06 05:44:24,266 train 700 1.551719e-02 -0.923883
2019-11-06 05:44:34,388 train 750 1.549669e-02 -0.902496
2019-11-06 05:44:44,573 train 800 1.549845e-02 -0.886122
2019-11-06 05:44:54,697 train 850 1.548990e-02 -0.890992
2019-11-06 05:44:57,698 training loss; R2: 1.548820e-02 -0.891377
2019-11-06 05:44:58,269 valid 000 1.213919e-02 -0.703251
2019-11-06 05:45:08,250 valid 050 1.293010e-02 -1.575604
2019-11-06 05:45:17,001 validation loss; R2: 1.283369e-02 -10.801671
2019-11-06 05:45:17,070 epoch 368 lr 1.000000e-04
2019-11-06 05:45:17,800 train 000 1.585758e-02 -0.287928
2019-11-06 05:45:28,018 train 050 1.550106e-02 -0.794085
2019-11-06 05:45:38,194 train 100 1.553198e-02 -0.715229
2019-11-06 05:45:48,417 train 150 1.558154e-02 -0.750305
2019-11-06 05:45:58,567 train 200 1.557287e-02 -0.771819
2019-11-06 05:46:08,741 train 250 1.556220e-02 -0.739000
2019-11-06 05:46:18,892 train 300 1.554979e-02 -0.741906
2019-11-06 05:46:29,022 train 350 1.556098e-02 -0.726828
2019-11-06 05:46:39,205 train 400 1.555208e-02 -0.699437
2019-11-06 05:46:49,345 train 450 1.554322e-02 -0.713866
2019-11-06 05:46:59,554 train 500 1.550172e-02 -0.710444
2019-11-06 05:47:09,688 train 550 1.549286e-02 -0.699978
2019-11-06 05:47:19,818 train 600 1.548811e-02 -0.694596
2019-11-06 05:47:29,878 train 650 1.548535e-02 -0.721278
2019-11-06 05:47:39,967 train 700 1.548738e-02 -0.717002
2019-11-06 05:47:50,022 train 750 1.550604e-02 -0.711749
2019-11-06 05:48:00,102 train 800 1.548501e-02 -0.721428
2019-11-06 05:48:10,229 train 850 1.549074e-02 -0.742224
2019-11-06 05:48:13,249 training loss; R2: 1.549064e-02 -0.733284
2019-11-06 05:48:13,818 valid 000 1.324209e-02 -2.094635
2019-11-06 05:48:23,803 valid 050 1.263866e-02 -0.554193
2019-11-06 05:48:32,531 validation loss; R2: 1.281441e-02 -0.706383
2019-11-06 05:48:32,596 epoch 369 lr 1.000000e-04
2019-11-06 05:48:33,328 train 000 1.469246e-02 -0.180830
2019-11-06 05:48:43,551 train 050 1.511014e-02 -0.492901
2019-11-06 05:48:53,733 train 100 1.528968e-02 -0.722177
2019-11-06 05:49:03,825 train 150 1.537714e-02 -0.679006
2019-11-06 05:49:13,892 train 200 1.544128e-02 -0.639470
2019-11-06 05:49:24,017 train 250 1.548993e-02 -0.665308
2019-11-06 05:49:34,124 train 300 1.552290e-02 -0.625470
2019-11-06 05:49:44,244 train 350 1.556830e-02 -0.651115
2019-11-06 05:49:54,301 train 400 1.556694e-02 -0.618506
2019-11-06 05:50:04,382 train 450 1.550669e-02 -0.622608
2019-11-06 05:50:14,454 train 500 1.553292e-02 -0.626936
2019-11-06 05:50:24,519 train 550 1.555186e-02 -0.653591
2019-11-06 05:50:34,593 train 600 1.556694e-02 -0.668372
2019-11-06 05:50:44,677 train 650 1.554283e-02 -0.673404
2019-11-06 05:50:54,726 train 700 1.556857e-02 -0.676614
2019-11-06 05:51:04,756 train 750 1.555027e-02 -0.670968
2019-11-06 05:51:14,800 train 800 1.555002e-02 -0.685486
2019-11-06 05:51:24,935 train 850 1.555749e-02 -0.746133
2019-11-06 05:51:27,970 training loss; R2: 1.554445e-02 -0.746679
2019-11-06 05:51:28,497 valid 000 1.554563e-02 0.159801
2019-11-06 05:51:38,229 valid 050 1.511775e-02 -0.691838
2019-11-06 05:51:46,945 validation loss; R2: 1.501854e-02 -0.733214
2019-11-06 05:51:47,026 epoch 370 lr 1.000000e-04
2019-11-06 05:51:47,782 train 000 1.433168e-02 -0.819231
2019-11-06 05:51:57,921 train 050 1.537467e-02 -0.730330
2019-11-06 05:52:08,114 train 100 1.546324e-02 -0.768876
2019-11-06 05:52:18,358 train 150 1.549247e-02 -0.847511
2019-11-06 05:52:28,579 train 200 1.551251e-02 -0.840690
2019-11-06 05:52:38,779 train 250 1.551733e-02 -0.764775
2019-11-06 05:52:48,959 train 300 1.556454e-02 -0.777887
2019-11-06 05:52:59,150 train 350 1.552116e-02 -0.780584
2019-11-06 05:53:09,372 train 400 1.551048e-02 -0.773288
2019-11-06 05:53:19,610 train 450 1.550960e-02 -0.769840
2019-11-06 05:53:29,838 train 500 1.550290e-02 -0.765651
2019-11-06 05:53:40,058 train 550 1.550888e-02 -0.747006
2019-11-06 05:53:50,236 train 600 1.549827e-02 -0.763165
2019-11-06 05:54:00,438 train 650 1.549086e-02 -0.745002
2019-11-06 05:54:10,627 train 700 1.549356e-02 -0.738217
2019-11-06 05:54:20,862 train 750 1.550326e-02 -0.760195
2019-11-06 05:54:31,107 train 800 1.551314e-02 -0.776731
2019-11-06 05:54:41,358 train 850 1.550028e-02 -0.766783
2019-11-06 05:54:44,423 training loss; R2: 1.550863e-02 -0.758042
2019-11-06 05:54:44,929 valid 000 1.408871e-02 -0.777755
2019-11-06 05:54:54,710 valid 050 1.501690e-02 -1.652739
2019-11-06 05:55:03,418 validation loss; R2: 1.509913e-02 -1.682941
2019-11-06 05:55:03,491 epoch 371 lr 1.000000e-04
2019-11-06 05:55:04,251 train 000 1.340619e-02 -0.647440
2019-11-06 05:55:14,443 train 050 1.527288e-02 -1.337530
2019-11-06 05:55:24,681 train 100 1.550877e-02 -1.037911
2019-11-06 05:55:34,900 train 150 1.562106e-02 -1.038671
2019-11-06 05:55:45,115 train 200 1.561393e-02 -0.874741
2019-11-06 05:55:55,330 train 250 1.558423e-02 -0.821307
2019-11-06 05:56:05,520 train 300 1.555090e-02 -0.779532
2019-11-06 05:56:15,707 train 350 1.548124e-02 -0.775328
2019-11-06 05:56:25,877 train 400 1.548016e-02 -0.745666
2019-11-06 05:56:36,034 train 450 1.545693e-02 -0.781957
2019-11-06 05:56:46,195 train 500 1.544079e-02 -0.782476
2019-11-06 05:56:56,361 train 550 1.544962e-02 -0.773926
2019-11-06 05:57:06,514 train 600 1.545928e-02 -0.769331
2019-11-06 05:57:16,650 train 650 1.545056e-02 -0.770712
2019-11-06 05:57:26,794 train 700 1.546884e-02 -0.755411
2019-11-06 05:57:36,918 train 750 1.545220e-02 -0.760677
2019-11-06 05:57:47,078 train 800 1.545819e-02 -0.762904
2019-11-06 05:57:57,236 train 850 1.545611e-02 -0.760203
2019-11-06 05:58:00,257 training loss; R2: 1.544589e-02 -0.764602
2019-11-06 05:58:00,844 valid 000 1.692663e-02 -0.345002
2019-11-06 05:58:10,616 valid 050 1.446997e-02 -1.370254
2019-11-06 05:58:19,277 validation loss; R2: 1.441909e-02 -1.256160
2019-11-06 05:58:19,344 epoch 372 lr 1.000000e-04
2019-11-06 05:58:20,077 train 000 1.511434e-02 -0.235475
2019-11-06 05:58:30,440 train 050 1.577914e-02 -0.644913
2019-11-06 05:58:40,851 train 100 1.566721e-02 -0.683945
2019-11-06 05:58:51,026 train 150 1.574847e-02 -0.685953
2019-11-06 05:59:01,197 train 200 1.576821e-02 -0.917287
2019-11-06 05:59:11,312 train 250 1.567687e-02 -0.920175
2019-11-06 05:59:21,448 train 300 1.565230e-02 -0.847585
2019-11-06 05:59:31,559 train 350 1.558945e-02 -0.806862
2019-11-06 05:59:41,712 train 400 1.562865e-02 -0.789002
2019-11-06 05:59:51,853 train 450 1.563244e-02 -0.826581
2019-11-06 06:00:02,009 train 500 1.561329e-02 -0.831529
2019-11-06 06:00:12,157 train 550 1.560485e-02 -0.811962
2019-11-06 06:00:22,318 train 600 1.556424e-02 -0.804794
2019-11-06 06:00:32,434 train 650 1.556098e-02 -0.774332
2019-11-06 06:00:42,568 train 700 1.555743e-02 -0.779525
2019-11-06 06:00:52,676 train 750 1.555770e-02 -0.757586
2019-11-06 06:01:02,823 train 800 1.558296e-02 -0.740962
2019-11-06 06:01:12,937 train 850 1.560069e-02 -0.777512
2019-11-06 06:01:15,963 training loss; R2: 1.559679e-02 -0.777653
2019-11-06 06:01:16,538 valid 000 1.421335e-02 0.058340
2019-11-06 06:01:26,343 valid 050 1.301805e-02 -0.834189
2019-11-06 06:01:35,000 validation loss; R2: 1.285311e-02 -0.868001
2019-11-06 06:01:35,066 epoch 373 lr 1.000000e-04
2019-11-06 06:01:35,780 train 000 1.531570e-02 -0.035581
2019-11-06 06:01:46,052 train 050 1.529002e-02 -0.604881
2019-11-06 06:01:56,325 train 100 1.523161e-02 -0.637872
2019-11-06 06:02:06,400 train 150 1.525631e-02 -0.662832
2019-11-06 06:02:16,555 train 200 1.530607e-02 -0.643282
2019-11-06 06:02:26,728 train 250 1.531529e-02 -0.709050
2019-11-06 06:02:36,861 train 300 1.540815e-02 -0.862095
2019-11-06 06:02:46,958 train 350 1.544162e-02 -0.857034
2019-11-06 06:02:57,026 train 400 1.543982e-02 -0.826688
2019-11-06 06:03:07,084 train 450 1.546639e-02 -0.783577
2019-11-06 06:03:17,165 train 500 1.551016e-02 -0.774272
2019-11-06 06:03:27,236 train 550 1.552775e-02 -0.812605
2019-11-06 06:03:37,273 train 600 1.553148e-02 -0.795930
2019-11-06 06:03:47,369 train 650 1.552774e-02 -1.109030
2019-11-06 06:03:57,504 train 700 1.552469e-02 -1.079843
2019-11-06 06:04:07,639 train 750 1.553025e-02 -1.053658
2019-11-06 06:04:17,756 train 800 1.550330e-02 -1.016746
2019-11-06 06:04:27,898 train 850 1.549053e-02 -0.993814
2019-11-06 06:04:30,935 training loss; R2: 1.549234e-02 -0.989885
2019-11-06 06:04:31,457 valid 000 1.338168e-02 -2.094393
2019-11-06 06:04:41,517 valid 050 1.272344e-02 -1.577047
2019-11-06 06:04:50,248 validation loss; R2: 1.266185e-02 -1.356991
2019-11-06 06:04:50,311 epoch 374 lr 1.000000e-04
2019-11-06 06:04:51,067 train 000 1.321050e-02 -3.283841
2019-11-06 06:05:01,207 train 050 1.544702e-02 -0.861229
2019-11-06 06:05:11,377 train 100 1.531332e-02 -0.813722
2019-11-06 06:05:21,586 train 150 1.531133e-02 -3.180702
2019-11-06 06:05:31,681 train 200 1.533065e-02 -2.544076
2019-11-06 06:05:41,816 train 250 1.539261e-02 -2.181003
2019-11-06 06:05:52,029 train 300 1.543050e-02 -1.939251
2019-11-06 06:06:02,142 train 350 1.544478e-02 -1.824316
2019-11-06 06:06:12,258 train 400 1.546385e-02 -1.678966
2019-11-06 06:06:22,471 train 450 1.545228e-02 -1.581747
2019-11-06 06:06:32,611 train 500 1.541690e-02 -1.510005
2019-11-06 06:06:42,702 train 550 1.541360e-02 -1.434593
2019-11-06 06:06:52,893 train 600 1.544887e-02 -1.367139
2019-11-06 06:07:03,032 train 650 1.545480e-02 -1.316851
2019-11-06 06:07:13,090 train 700 1.542540e-02 -1.299361
2019-11-06 06:07:23,205 train 750 1.541724e-02 -1.258717
2019-11-06 06:07:33,365 train 800 1.542517e-02 -1.210466
2019-11-06 06:07:43,436 train 850 1.541017e-02 -1.164540
2019-11-06 06:07:46,436 training loss; R2: 1.541697e-02 -1.155778
2019-11-06 06:07:46,996 valid 000 1.280339e-02 -0.079026
2019-11-06 06:07:56,813 valid 050 1.349560e-02 -0.730024
2019-11-06 06:08:05,428 validation loss; R2: 1.356129e-02 -0.750286
2019-11-06 06:08:05,502 epoch 375 lr 1.000000e-04
2019-11-06 06:08:06,173 train 000 1.399309e-02 -0.819093
2019-11-06 06:08:16,338 train 050 1.507281e-02 -0.567638
2019-11-06 06:08:26,412 train 100 1.538878e-02 -0.597379
2019-11-06 06:08:36,549 train 150 1.542451e-02 -0.623081
2019-11-06 06:08:46,671 train 200 1.543633e-02 -0.682152
2019-11-06 06:08:56,751 train 250 1.547025e-02 -0.663448
2019-11-06 06:09:06,810 train 300 1.544608e-02 -0.683833
2019-11-06 06:09:17,017 train 350 1.547594e-02 -0.669733
2019-11-06 06:09:27,108 train 400 1.551736e-02 -0.668838
2019-11-06 06:09:37,176 train 450 1.546195e-02 -0.665743
2019-11-06 06:09:47,332 train 500 1.551474e-02 -0.675203
2019-11-06 06:09:57,468 train 550 1.550110e-02 -0.677888
2019-11-06 06:10:07,512 train 600 1.547983e-02 -0.666249
2019-11-06 06:10:17,638 train 650 1.549503e-02 -0.656751
2019-11-06 06:10:27,782 train 700 1.547692e-02 -0.647580
2019-11-06 06:10:37,816 train 750 1.546785e-02 -0.648714
2019-11-06 06:10:47,969 train 800 1.546230e-02 -0.648313
2019-11-06 06:10:58,174 train 850 1.546526e-02 -0.649827
2019-11-06 06:11:01,209 training loss; R2: 1.546393e-02 -0.645243
2019-11-06 06:11:01,786 valid 000 1.235527e-02 -2.179111
2019-11-06 06:11:11,639 valid 050 1.280569e-02 -0.804419
2019-11-06 06:11:20,312 validation loss; R2: 1.271934e-02 -0.963666
2019-11-06 06:11:20,380 epoch 376 lr 1.000000e-04
2019-11-06 06:11:21,121 train 000 1.451463e-02 -2.001039
2019-11-06 06:11:31,233 train 050 1.536370e-02 -0.740670
2019-11-06 06:11:41,340 train 100 1.553318e-02 -0.760909
2019-11-06 06:11:51,528 train 150 1.560573e-02 -0.693253
2019-11-06 06:12:01,636 train 200 1.552991e-02 -0.668000
2019-11-06 06:12:11,728 train 250 1.555841e-02 -0.654443
2019-11-06 06:12:21,956 train 300 1.554471e-02 -0.680208
2019-11-06 06:12:32,169 train 350 1.554672e-02 -0.653991
2019-11-06 06:12:42,283 train 400 1.554704e-02 -0.634941
2019-11-06 06:12:52,471 train 450 1.554407e-02 -0.692932
2019-11-06 06:13:02,693 train 500 1.550423e-02 -0.792564
2019-11-06 06:13:12,819 train 550 1.549380e-02 -0.777753
2019-11-06 06:13:23,036 train 600 1.549131e-02 -0.779508
2019-11-06 06:13:33,243 train 650 1.549232e-02 -0.764746
2019-11-06 06:13:43,358 train 700 1.549195e-02 -0.760836
2019-11-06 06:13:53,539 train 750 1.548321e-02 -0.747209
2019-11-06 06:14:03,744 train 800 1.547230e-02 -0.732929
2019-11-06 06:14:13,927 train 850 1.548828e-02 -0.722758
2019-11-06 06:14:16,928 training loss; R2: 1.548294e-02 -0.720626
2019-11-06 06:14:17,487 valid 000 1.875116e-02 -1.448175
2019-11-06 06:14:27,284 valid 050 1.547944e-02 -1.112698
2019-11-06 06:14:35,929 validation loss; R2: 1.539451e-02 -1.115760
2019-11-06 06:14:35,993 epoch 377 lr 1.000000e-04
2019-11-06 06:14:36,657 train 000 1.890164e-02 0.065153
2019-11-06 06:14:47,092 train 050 1.578297e-02 -0.521526
2019-11-06 06:14:57,344 train 100 1.567948e-02 -118.900686
2019-11-06 06:15:07,599 train 150 1.568898e-02 -79.778975
2019-11-06 06:15:17,822 train 200 1.563560e-02 -60.104003
2019-11-06 06:15:28,063 train 250 1.557879e-02 -48.262670
2019-11-06 06:15:38,253 train 300 1.555939e-02 -40.381519
2019-11-06 06:15:48,479 train 350 1.550480e-02 -34.699016
2019-11-06 06:15:58,645 train 400 1.552783e-02 -30.494779
2019-11-06 06:16:08,839 train 450 1.554689e-02 -27.210173
2019-11-06 06:16:18,969 train 500 1.554592e-02 -24.564234
2019-11-06 06:16:29,134 train 550 1.554218e-02 -22.400356
2019-11-06 06:16:39,294 train 600 1.551461e-02 -20.594761
2019-11-06 06:16:49,472 train 650 1.550260e-02 -19.077865
2019-11-06 06:16:59,666 train 700 1.551067e-02 -17.762916
2019-11-06 06:17:09,868 train 750 1.549400e-02 -16.631352
2019-11-06 06:17:20,085 train 800 1.549801e-02 -15.726256
2019-11-06 06:17:30,252 train 850 1.548323e-02 -14.845738
2019-11-06 06:17:33,291 training loss; R2: 1.548005e-02 -14.600592
2019-11-06 06:17:33,798 valid 000 1.199384e-02 -0.246828
2019-11-06 06:17:43,635 valid 050 1.230153e-02 -0.912410
2019-11-06 06:17:52,312 validation loss; R2: 1.214977e-02 -0.828552
2019-11-06 06:17:52,378 epoch 378 lr 1.000000e-04
2019-11-06 06:17:53,063 train 000 1.487524e-02 -0.325708
2019-11-06 06:18:03,251 train 050 1.517336e-02 -1.035908
2019-11-06 06:18:13,421 train 100 1.518266e-02 -0.834358
2019-11-06 06:18:23,592 train 150 1.530050e-02 -0.930635
2019-11-06 06:18:33,766 train 200 1.529252e-02 -0.945706
2019-11-06 06:18:43,917 train 250 1.529158e-02 -0.847584
2019-11-06 06:18:54,094 train 300 1.535427e-02 -0.829109
2019-11-06 06:19:04,245 train 350 1.536372e-02 -0.953364
2019-11-06 06:19:14,400 train 400 1.537395e-02 -0.934954
2019-11-06 06:19:24,567 train 450 1.541710e-02 -0.879260
2019-11-06 06:19:34,729 train 500 1.544331e-02 -0.900781
2019-11-06 06:19:44,898 train 550 1.543611e-02 -0.878801
2019-11-06 06:19:55,063 train 600 1.545936e-02 -0.854858
2019-11-06 06:20:05,219 train 650 1.544767e-02 -0.835346
2019-11-06 06:20:15,381 train 700 1.545739e-02 -0.816062
2019-11-06 06:20:25,530 train 750 1.545844e-02 -0.821807
2019-11-06 06:20:35,683 train 800 1.547184e-02 -0.793409
2019-11-06 06:20:45,841 train 850 1.548104e-02 -0.776589
2019-11-06 06:20:48,860 training loss; R2: 1.547612e-02 -0.773208
2019-11-06 06:20:49,412 valid 000 1.260295e-02 -2.024049
2019-11-06 06:20:59,244 valid 050 1.198380e-02 -0.626998
2019-11-06 06:21:07,875 validation loss; R2: 1.198646e-02 -1.528970
2019-11-06 06:21:07,941 epoch 379 lr 1.000000e-04
2019-11-06 06:21:08,663 train 000 1.425125e-02 -0.921836
2019-11-06 06:21:18,934 train 050 1.496902e-02 -1.125506
2019-11-06 06:21:29,137 train 100 1.525804e-02 -1.509727
2019-11-06 06:21:39,347 train 150 1.537254e-02 -1.219735
2019-11-06 06:21:49,528 train 200 1.538920e-02 -1.063409
2019-11-06 06:21:59,707 train 250 1.537842e-02 -0.992681
2019-11-06 06:22:09,861 train 300 1.534507e-02 -0.936673
2019-11-06 06:22:20,021 train 350 1.538303e-02 -0.885756
2019-11-06 06:22:30,155 train 400 1.540418e-02 -0.856385
2019-11-06 06:22:40,307 train 450 1.544131e-02 -0.836002
2019-11-06 06:22:50,481 train 500 1.548882e-02 -0.806411
2019-11-06 06:23:00,640 train 550 1.550909e-02 -0.801645
2019-11-06 06:23:10,823 train 600 1.551751e-02 -0.783721
2019-11-06 06:23:21,023 train 650 1.551380e-02 -0.783349
2019-11-06 06:23:31,214 train 700 1.550496e-02 -0.784022
2019-11-06 06:23:41,357 train 750 1.549623e-02 -0.774390
2019-11-06 06:23:51,544 train 800 1.547118e-02 -0.767517
2019-11-06 06:24:01,699 train 850 1.545820e-02 -0.767397
2019-11-06 06:24:04,732 training loss; R2: 1.545332e-02 -0.763972
2019-11-06 06:24:05,257 valid 000 1.333794e-02 -0.075890
2019-11-06 06:24:15,073 valid 050 1.247891e-02 -1.109869
2019-11-06 06:24:23,762 validation loss; R2: 1.261104e-02 -1.014608
2019-11-06 06:24:23,825 epoch 380 lr 1.000000e-04
2019-11-06 06:24:24,558 train 000 1.426725e-02 -7.182906
2019-11-06 06:24:34,841 train 050 1.601789e-02 -0.731052
2019-11-06 06:24:45,064 train 100 1.570206e-02 -0.757400
2019-11-06 06:24:55,301 train 150 1.567061e-02 -0.682547
2019-11-06 06:25:05,511 train 200 1.555920e-02 -0.657478
2019-11-06 06:25:15,676 train 250 1.560443e-02 -0.684848
2019-11-06 06:25:25,878 train 300 1.560226e-02 -0.744511
2019-11-06 06:25:36,065 train 350 1.558851e-02 -0.738451
2019-11-06 06:25:46,198 train 400 1.557862e-02 -0.728588
2019-11-06 06:25:56,360 train 450 1.559045e-02 -0.728516
2019-11-06 06:26:06,569 train 500 1.558697e-02 -0.721994
2019-11-06 06:26:16,772 train 550 1.559229e-02 -0.741284
2019-11-06 06:26:26,968 train 600 1.558912e-02 -0.735096
2019-11-06 06:26:37,207 train 650 1.556678e-02 -0.717198
2019-11-06 06:26:47,410 train 700 1.556122e-02 -0.705815
2019-11-06 06:26:57,599 train 750 1.556328e-02 -0.706949
2019-11-06 06:27:07,794 train 800 1.553821e-02 -0.706873
2019-11-06 06:27:17,979 train 850 1.551786e-02 -0.711677
2019-11-06 06:27:21,022 training loss; R2: 1.552135e-02 -0.711602
2019-11-06 06:27:21,541 valid 000 1.265853e-02 -0.007771
2019-11-06 06:27:31,316 valid 050 1.293404e-02 -1.202898
2019-11-06 06:27:39,941 validation loss; R2: 1.276985e-02 -1.245137
2019-11-06 06:27:40,027 epoch 381 lr 1.000000e-04
2019-11-06 06:27:40,783 train 000 1.484813e-02 -2.651235
2019-11-06 06:27:50,944 train 050 1.563395e-02 -0.600948
2019-11-06 06:28:01,045 train 100 1.562038e-02 -0.694737
2019-11-06 06:28:11,121 train 150 1.571413e-02 -0.691559
2019-11-06 06:28:21,187 train 200 1.566499e-02 -0.650756
2019-11-06 06:28:31,268 train 250 1.554386e-02 -0.685947
2019-11-06 06:28:41,338 train 300 1.559021e-02 -0.637442
2019-11-06 06:28:51,491 train 350 1.561670e-02 -0.668471
2019-11-06 06:29:01,635 train 400 1.562715e-02 -0.667496
2019-11-06 06:29:11,786 train 450 1.564460e-02 -0.664190
2019-11-06 06:29:21,932 train 500 1.565813e-02 -0.665400
2019-11-06 06:29:32,098 train 550 1.563428e-02 -0.641530
2019-11-06 06:29:42,282 train 600 1.564460e-02 -0.641885
2019-11-06 06:29:52,393 train 650 1.566158e-02 -0.653795
2019-11-06 06:30:02,520 train 700 1.563965e-02 -0.656789
2019-11-06 06:30:12,648 train 750 1.563787e-02 -0.664999
2019-11-06 06:30:22,846 train 800 1.563732e-02 -0.672488
2019-11-06 06:30:33,060 train 850 1.563419e-02 -0.676622
2019-11-06 06:30:36,093 training loss; R2: 1.563988e-02 -0.679868
2019-11-06 06:30:36,601 valid 000 1.257539e-02 -0.526377
2019-11-06 06:30:46,424 valid 050 1.242337e-02 -1.314169
2019-11-06 06:30:55,105 validation loss; R2: 1.246568e-02 -1.097798
2019-11-06 06:30:55,171 epoch 382 lr 1.000000e-04
2019-11-06 06:30:55,927 train 000 1.533076e-02 0.037195
2019-11-06 06:31:06,063 train 050 1.530155e-02 -0.626121
2019-11-06 06:31:16,213 train 100 1.531714e-02 -0.547257
2019-11-06 06:31:26,370 train 150 1.544767e-02 -0.564262
2019-11-06 06:31:36,467 train 200 1.543457e-02 -0.591017
2019-11-06 06:31:46,528 train 250 1.547823e-02 -0.623952
2019-11-06 06:31:56,677 train 300 1.555167e-02 -0.651461
2019-11-06 06:32:06,816 train 350 1.556904e-02 -0.648792
2019-11-06 06:32:16,877 train 400 1.554773e-02 -0.652979
2019-11-06 06:32:26,964 train 450 1.554380e-02 -0.669235
2019-11-06 06:32:37,157 train 500 1.559637e-02 -0.699768
2019-11-06 06:32:47,298 train 550 1.555168e-02 -0.693188
2019-11-06 06:32:57,379 train 600 1.555951e-02 -0.695300
2019-11-06 06:33:07,513 train 650 1.558857e-02 -0.698224
2019-11-06 06:33:17,699 train 700 1.558319e-02 -0.700759
2019-11-06 06:33:27,797 train 750 1.561781e-02 -0.989959
2019-11-06 06:33:37,880 train 800 1.562322e-02 -0.966579
2019-11-06 06:33:48,080 train 850 1.566466e-02 -0.952894
2019-11-06 06:33:51,119 training loss; R2: 1.566343e-02 -0.956328
2019-11-06 06:33:51,636 valid 000 1.286821e-02 -1.009867
2019-11-06 06:34:01,431 valid 050 1.319603e-02 -1.378955
2019-11-06 06:34:10,242 validation loss; R2: 1.319702e-02 -1.465054
2019-11-06 06:34:10,308 epoch 383 lr 1.000000e-04
2019-11-06 06:34:10,992 train 000 1.478198e-02 -0.355529
2019-11-06 06:34:21,199 train 050 1.550392e-02 -0.854228
2019-11-06 06:34:31,390 train 100 1.561877e-02 -0.822355
2019-11-06 06:34:41,499 train 150 1.570007e-02 -0.721492
2019-11-06 06:34:51,582 train 200 1.569158e-02 -0.666923
2019-11-06 06:35:01,658 train 250 1.565939e-02 -0.748856
2019-11-06 06:35:11,743 train 300 1.558471e-02 -0.762875
2019-11-06 06:35:21,945 train 350 1.562081e-02 -0.765631
2019-11-06 06:35:32,157 train 400 1.554570e-02 -0.752074
2019-11-06 06:35:42,392 train 450 1.557325e-02 -0.730836
2019-11-06 06:35:52,599 train 500 1.560009e-02 -0.729934
2019-11-06 06:36:02,794 train 550 1.559923e-02 -0.726045
2019-11-06 06:36:12,986 train 600 1.561623e-02 -0.717146
2019-11-06 06:36:23,153 train 650 1.564817e-02 -0.710297
2019-11-06 06:36:33,322 train 700 1.568012e-02 -0.722039
2019-11-06 06:36:43,467 train 750 1.570300e-02 -0.720000
2019-11-06 06:36:53,640 train 800 1.569299e-02 -0.714919
2019-11-06 06:37:03,790 train 850 1.569128e-02 -0.701746
2019-11-06 06:37:06,838 training loss; R2: 1.568017e-02 -0.703700
2019-11-06 06:37:07,393 valid 000 1.354515e-02 -0.163586
2019-11-06 06:37:17,270 valid 050 1.369424e-02 -1.628029
2019-11-06 06:37:25,928 validation loss; R2: 1.379735e-02 -1.393024
2019-11-06 06:37:25,993 epoch 384 lr 1.000000e-04
2019-11-06 06:37:26,722 train 000 1.483594e-02 -0.961004
2019-11-06 06:37:37,031 train 050 1.560019e-02 -0.914883
2019-11-06 06:37:47,261 train 100 1.572282e-02 -1.541081
2019-11-06 06:37:57,488 train 150 1.574398e-02 -1.274590
2019-11-06 06:38:07,691 train 200 1.572204e-02 -1.035014
2019-11-06 06:38:17,884 train 250 1.571854e-02 -0.944483
2019-11-06 06:38:28,044 train 300 1.573291e-02 -0.885634
2019-11-06 06:38:38,252 train 350 1.573826e-02 -0.865733
2019-11-06 06:38:48,407 train 400 1.570523e-02 -0.903284
2019-11-06 06:38:58,564 train 450 1.567616e-02 -0.894759
2019-11-06 06:39:08,712 train 500 1.566820e-02 -0.883478
2019-11-06 06:39:18,868 train 550 1.566190e-02 -0.892391
2019-11-06 06:39:29,018 train 600 1.567828e-02 -0.883200
2019-11-06 06:39:39,204 train 650 1.569491e-02 -0.860854
2019-11-06 06:39:49,361 train 700 1.568334e-02 -0.839407
2019-11-06 06:39:59,524 train 750 1.570424e-02 -0.839385
2019-11-06 06:40:09,673 train 800 1.572153e-02 -0.818807
2019-11-06 06:40:19,833 train 850 1.574620e-02 -0.848300
2019-11-06 06:40:22,855 training loss; R2: 1.574504e-02 -0.836675
2019-11-06 06:40:23,430 valid 000 1.157824e-02 -0.152664
2019-11-06 06:40:33,294 valid 050 1.358744e-02 -0.746785
2019-11-06 06:40:41,940 validation loss; R2: 1.368520e-02 -0.765606
2019-11-06 06:40:42,003 epoch 385 lr 1.000000e-04
2019-11-06 06:40:42,664 train 000 1.499625e-02 -0.253287
2019-11-06 06:40:52,919 train 050 1.599158e-02 -0.661159
2019-11-06 06:41:03,123 train 100 1.595284e-02 -0.735548
2019-11-06 06:41:13,284 train 150 1.600966e-02 -0.702321
2019-11-06 06:41:23,430 train 200 1.588047e-02 -0.707722
2019-11-06 06:41:33,567 train 250 1.594843e-02 -0.687806
2019-11-06 06:41:43,714 train 300 1.590438e-02 -0.669349
2019-11-06 06:41:53,898 train 350 1.590084e-02 -0.733272
2019-11-06 06:42:04,073 train 400 1.596876e-02 -0.701393
2019-11-06 06:42:14,221 train 450 1.595500e-02 -0.684307
2019-11-06 06:42:24,372 train 500 1.591488e-02 -0.702638
2019-11-06 06:42:34,526 train 550 1.591380e-02 -0.736726
2019-11-06 06:42:44,710 train 600 1.586713e-02 -0.751591
2019-11-06 06:42:54,858 train 650 1.589378e-02 -0.728115
2019-11-06 06:43:05,013 train 700 1.592527e-02 -0.730744
2019-11-06 06:43:15,273 train 750 1.593976e-02 -0.748755
2019-11-06 06:43:25,465 train 800 1.592713e-02 -0.740457
2019-11-06 06:43:35,675 train 850 1.593682e-02 -0.724669
2019-11-06 06:43:38,714 training loss; R2: 1.594575e-02 -0.717606
2019-11-06 06:43:39,245 valid 000 1.314540e-02 -0.677816
2019-11-06 06:43:49,038 valid 050 1.295563e-02 -0.858390
2019-11-06 06:43:57,649 validation loss; R2: 1.294175e-02 -1.669842
2019-11-06 06:43:57,725 epoch 386 lr 1.000000e-04
2019-11-06 06:43:58,430 train 000 1.352636e-02 0.020132
2019-11-06 06:44:08,672 train 050 1.622837e-02 -0.717201
2019-11-06 06:44:18,877 train 100 1.612644e-02 -0.717027
2019-11-06 06:44:29,078 train 150 1.612711e-02 -0.763937
2019-11-06 06:44:39,240 train 200 1.601832e-02 -0.822251
2019-11-06 06:44:49,399 train 250 1.603286e-02 -0.804488
2019-11-06 06:44:59,539 train 300 1.603277e-02 -0.782005
2019-11-06 06:45:09,695 train 350 1.599891e-02 -0.788506
2019-11-06 06:45:19,809 train 400 1.599352e-02 -1.009280
2019-11-06 06:45:29,926 train 450 1.603051e-02 -0.959590
2019-11-06 06:45:40,045 train 500 1.604854e-02 -0.977995
2019-11-06 06:45:50,186 train 550 1.600075e-02 -0.964690
2019-11-06 06:46:00,331 train 600 1.599439e-02 -0.943467
2019-11-06 06:46:10,478 train 650 1.601235e-02 -0.982492
2019-11-06 06:46:20,613 train 700 1.599743e-02 -0.959628
2019-11-06 06:46:30,800 train 750 1.598576e-02 -0.958242
2019-11-06 06:46:40,968 train 800 1.599836e-02 -0.944697
2019-11-06 06:46:51,143 train 850 1.599139e-02 -0.921265
2019-11-06 06:46:54,174 training loss; R2: 1.598815e-02 -0.919060
2019-11-06 06:46:54,690 valid 000 1.172596e-02 0.133587
2019-11-06 06:47:04,479 valid 050 1.335722e-02 -0.898188
2019-11-06 06:47:13,105 validation loss; R2: 1.299382e-02 -0.799785
2019-11-06 06:47:13,171 epoch 387 lr 1.000000e-04
2019-11-06 06:47:13,834 train 000 1.547092e-02 0.137695
2019-11-06 06:47:24,095 train 050 1.629615e-02 -2.638675
2019-11-06 06:47:34,332 train 100 1.593860e-02 -1.578867
2019-11-06 06:47:44,534 train 150 1.606091e-02 -1.377384
2019-11-06 06:47:54,737 train 200 1.604381e-02 -1.247942
2019-11-06 06:48:04,965 train 250 1.608540e-02 -1.146054
2019-11-06 06:48:15,157 train 300 1.606218e-02 -1.060202
2019-11-06 06:48:25,361 train 350 1.603570e-02 -1.057886
2019-11-06 06:48:35,523 train 400 1.599163e-02 -1.055048
2019-11-06 06:48:45,646 train 450 1.603037e-02 -1.024320
2019-11-06 06:48:55,803 train 500 1.604946e-02 -0.998505
2019-11-06 06:49:05,973 train 550 1.600172e-02 -0.965597
2019-11-06 06:49:16,159 train 600 1.601301e-02 -0.939753
2019-11-06 06:49:26,343 train 650 1.601968e-02 -0.930973
2019-11-06 06:49:36,506 train 700 1.596478e-02 -0.913581
2019-11-06 06:49:46,655 train 750 1.595690e-02 -0.886636
2019-11-06 06:49:56,842 train 800 1.596816e-02 -0.869069
2019-11-06 06:50:07,019 train 850 1.597456e-02 -0.853627
2019-11-06 06:50:10,065 training loss; R2: 1.598823e-02 -0.860225
2019-11-06 06:50:10,629 valid 000 1.213890e-02 -0.030108
2019-11-06 06:50:20,489 valid 050 1.348942e-02 -0.871883
2019-11-06 06:50:29,178 validation loss; R2: 1.350543e-02 -1.171634
2019-11-06 06:50:29,244 epoch 388 lr 1.000000e-04
2019-11-06 06:50:29,988 train 000 1.592420e-02 -0.054620
2019-11-06 06:50:40,176 train 050 1.595432e-02 -1.236699
2019-11-06 06:50:50,365 train 100 1.623352e-02 -1.009789
2019-11-06 06:51:00,572 train 150 1.617321e-02 -0.963365
2019-11-06 06:51:10,780 train 200 1.609252e-02 -0.890529
2019-11-06 06:51:21,017 train 250 1.604882e-02 -0.874255
2019-11-06 06:51:31,201 train 300 1.602656e-02 -0.818755
2019-11-06 06:51:41,427 train 350 1.599356e-02 -0.818104
2019-11-06 06:51:51,609 train 400 1.595632e-02 -0.803204
2019-11-06 06:52:01,807 train 450 1.596356e-02 -0.833693
2019-11-06 06:52:11,993 train 500 1.596455e-02 -0.795904
2019-11-06 06:52:22,191 train 550 1.595550e-02 -0.785814
2019-11-06 06:52:32,387 train 600 1.598009e-02 -0.805241
2019-11-06 06:52:42,575 train 650 1.599742e-02 -0.794295
2019-11-06 06:52:52,690 train 700 1.600816e-02 -0.775073
2019-11-06 06:53:02,850 train 750 1.602776e-02 -0.763519
2019-11-06 06:53:13,041 train 800 1.603142e-02 -0.770220
2019-11-06 06:53:23,240 train 850 1.604181e-02 -0.782779
2019-11-06 06:53:26,277 training loss; R2: 1.603134e-02 -0.790501
2019-11-06 06:53:26,888 valid 000 1.544380e-02 0.115649
2019-11-06 06:53:37,125 valid 050 1.330071e-02 -1.024401
2019-11-06 06:53:45,805 validation loss; R2: 1.351291e-02 -1.132745
2019-11-06 06:53:45,868 epoch 389 lr 1.000000e-04
2019-11-06 06:53:46,547 train 000 1.862310e-02 -0.754797
2019-11-06 06:53:56,783 train 050 1.605737e-02 -1.192230
2019-11-06 06:54:06,974 train 100 1.616890e-02 -0.937350
2019-11-06 06:54:17,172 train 150 1.621164e-02 -0.862994
2019-11-06 06:54:27,346 train 200 1.628152e-02 -0.822290
2019-11-06 06:54:37,544 train 250 1.625807e-02 -0.786748
2019-11-06 06:54:47,713 train 300 1.621654e-02 -0.775757
2019-11-06 06:54:57,889 train 350 1.622333e-02 -0.835723
2019-11-06 06:55:08,053 train 400 1.622335e-02 -0.822311
2019-11-06 06:55:18,257 train 450 1.625401e-02 -0.786668
2019-11-06 06:55:28,446 train 500 1.619736e-02 -0.824287
2019-11-06 06:55:38,660 train 550 1.622922e-02 -0.792817
2019-11-06 06:55:48,859 train 600 1.620665e-02 -0.786536
2019-11-06 06:55:59,092 train 650 1.620441e-02 -0.752022
2019-11-06 06:56:09,235 train 700 1.620841e-02 -0.742701
2019-11-06 06:56:19,400 train 750 1.623576e-02 -0.738898
2019-11-06 06:56:29,510 train 800 1.621375e-02 -0.756092
2019-11-06 06:56:39,689 train 850 1.619833e-02 -0.756715
2019-11-06 06:56:42,731 training loss; R2: 1.621169e-02 -0.747690
2019-11-06 06:56:43,269 valid 000 1.291638e-02 0.182998
2019-11-06 06:56:53,155 valid 050 1.309447e-02 -0.938470
2019-11-06 06:57:01,811 validation loss; R2: 1.331377e-02 -1.013981
2019-11-06 06:57:01,875 epoch 390 lr 1.000000e-04
2019-11-06 06:57:02,607 train 000 1.418813e-02 -0.099012
2019-11-06 06:57:12,723 train 050 1.626643e-02 -0.609613
2019-11-06 06:57:22,881 train 100 1.619296e-02 -0.538640
2019-11-06 06:57:32,999 train 150 1.643136e-02 -0.547762
2019-11-06 06:57:43,193 train 200 1.639078e-02 -0.589174
2019-11-06 06:57:53,383 train 250 1.633281e-02 -0.629772
2019-11-06 06:58:03,583 train 300 1.632005e-02 -5.224111
2019-11-06 06:58:13,782 train 350 1.630195e-02 -4.560716
2019-11-06 06:58:23,978 train 400 1.631473e-02 -4.185682
2019-11-06 06:58:34,156 train 450 1.633762e-02 -3.990407
2019-11-06 06:58:44,321 train 500 1.630728e-02 -3.638689
2019-11-06 06:58:54,466 train 550 1.627874e-02 -3.371230
2019-11-06 06:59:04,654 train 600 1.627760e-02 -3.138468
2019-11-06 06:59:14,812 train 650 1.627438e-02 -2.938283
2019-11-06 06:59:24,961 train 700 1.628150e-02 -2.773884
2019-11-06 06:59:35,116 train 750 1.628157e-02 -2.633458
2019-11-06 06:59:45,265 train 800 1.628409e-02 -2.519807
2019-11-06 06:59:55,409 train 850 1.627976e-02 -2.411186
2019-11-06 06:59:58,433 training loss; R2: 1.627297e-02 -2.400220
2019-11-06 06:59:59,013 valid 000 1.405623e-02 -0.511954
2019-11-06 07:00:08,864 valid 050 1.431073e-02 -1.238754
2019-11-06 07:00:17,497 validation loss; R2: 1.440396e-02 -1.393130
2019-11-06 07:00:17,562 epoch 391 lr 1.000000e-04
2019-11-06 07:00:18,230 train 000 1.458328e-02 -0.799376
2019-11-06 07:00:28,481 train 050 1.576499e-02 -0.668331
2019-11-06 07:00:38,704 train 100 1.604753e-02 -0.845134
2019-11-06 07:00:48,879 train 150 1.592916e-02 -0.787570
2019-11-06 07:00:59,087 train 200 1.602670e-02 -0.729752
2019-11-06 07:01:09,267 train 250 1.609530e-02 -0.683447
2019-11-06 07:01:19,482 train 300 1.614911e-02 -0.654481
2019-11-06 07:01:29,679 train 350 1.619097e-02 -0.663144
2019-11-06 07:01:39,905 train 400 1.617649e-02 -0.668953
2019-11-06 07:01:50,104 train 450 1.616441e-02 -0.677348
2019-11-06 07:02:00,305 train 500 1.621138e-02 -0.673939
2019-11-06 07:02:10,466 train 550 1.623161e-02 -0.654368
2019-11-06 07:02:20,636 train 600 1.627325e-02 -0.653009
2019-11-06 07:02:30,822 train 650 1.625546e-02 -0.669144
2019-11-06 07:02:41,040 train 700 1.625164e-02 -0.695645
2019-11-06 07:02:51,245 train 750 1.626974e-02 -0.693965
2019-11-06 07:03:01,457 train 800 1.629086e-02 -0.693490
2019-11-06 07:03:11,656 train 850 1.629524e-02 -0.682388
2019-11-06 07:03:14,712 training loss; R2: 1.629587e-02 -0.678970
2019-11-06 07:03:15,283 valid 000 1.655671e-02 -0.525746
2019-11-06 07:03:25,108 valid 050 1.265526e-02 -0.879956
2019-11-06 07:03:33,797 validation loss; R2: 1.271297e-02 -0.869153
2019-11-06 07:03:33,861 epoch 392 lr 1.000000e-04
2019-11-06 07:03:34,599 train 000 1.618028e-02 -0.452397
2019-11-06 07:03:44,814 train 050 1.607217e-02 -0.923231
2019-11-06 07:03:55,043 train 100 1.625786e-02 -0.676877
2019-11-06 07:04:05,262 train 150 1.632166e-02 -0.793042
2019-11-06 07:04:15,459 train 200 1.630191e-02 -0.750655
2019-11-06 07:04:25,644 train 250 1.643914e-02 -0.732361
2019-11-06 07:04:35,799 train 300 1.645438e-02 -0.760667
2019-11-06 07:04:45,947 train 350 1.657089e-02 -0.751732
2019-11-06 07:04:56,098 train 400 1.655195e-02 -0.833673
2019-11-06 07:05:06,278 train 450 1.656229e-02 -0.825220
2019-11-06 07:05:16,458 train 500 1.652979e-02 -0.790267
2019-11-06 07:05:26,627 train 550 1.651900e-02 -0.817954
2019-11-06 07:05:36,758 train 600 1.650959e-02 -0.797727
2019-11-06 07:05:46,875 train 650 1.650668e-02 -0.784555
2019-11-06 07:05:56,999 train 700 1.650104e-02 -0.755333
2019-11-06 07:06:07,118 train 750 1.651771e-02 -0.755526
2019-11-06 07:06:17,235 train 800 1.651756e-02 -0.735454
2019-11-06 07:06:27,339 train 850 1.650082e-02 -0.732956
2019-11-06 07:06:30,358 training loss; R2: 1.649713e-02 -0.729340
2019-11-06 07:06:30,868 valid 000 1.363615e-02 0.265115
2019-11-06 07:06:40,688 valid 050 1.292377e-02 -0.648969
2019-11-06 07:06:49,375 validation loss; R2: 1.310156e-02 -1.120446
2019-11-06 07:06:49,452 epoch 393 lr 1.000000e-04
2019-11-06 07:06:50,192 train 000 1.571590e-02 -0.331427
2019-11-06 07:07:00,352 train 050 1.682235e-02 -0.453773
2019-11-06 07:07:10,567 train 100 1.715628e-02 -0.668668
2019-11-06 07:07:20,698 train 150 1.691764e-02 -0.646719
2019-11-06 07:07:30,846 train 200 1.687930e-02 -0.675851
2019-11-06 07:07:40,962 train 250 1.677813e-02 -0.623756
2019-11-06 07:07:51,123 train 300 1.673564e-02 -0.703051
2019-11-06 07:08:01,279 train 350 1.676454e-02 -0.684126
2019-11-06 07:08:11,429 train 400 1.669189e-02 -0.668761
2019-11-06 07:08:21,532 train 450 1.672787e-02 -0.675353
2019-11-06 07:08:31,660 train 500 1.668052e-02 -0.726708
2019-11-06 07:08:41,755 train 550 1.666490e-02 -0.757619
2019-11-06 07:08:51,888 train 600 1.669732e-02 -0.745069
2019-11-06 07:09:01,971 train 650 1.667276e-02 -0.745855
2019-11-06 07:09:12,091 train 700 1.665927e-02 -0.758159
2019-11-06 07:09:22,185 train 750 1.666438e-02 -0.791670
2019-11-06 07:09:32,367 train 800 1.664640e-02 -0.788976
2019-11-06 07:09:42,546 train 850 1.662868e-02 -0.775662
2019-11-06 07:09:45,579 training loss; R2: 1.661487e-02 -0.773503
2019-11-06 07:09:46,091 valid 000 1.209642e-02 -0.953513
2019-11-06 07:09:55,910 valid 050 1.300428e-02 -1.105825
2019-11-06 07:10:04,603 validation loss; R2: 1.296537e-02 -1.117234
2019-11-06 07:10:04,675 epoch 394 lr 1.000000e-04
2019-11-06 07:10:05,437 train 000 1.568902e-02 0.045462
2019-11-06 07:10:15,688 train 050 1.643816e-02 -0.902976
2019-11-06 07:10:25,891 train 100 1.666059e-02 -1.409154
2019-11-06 07:10:36,054 train 150 1.659132e-02 -1.229570
2019-11-06 07:10:46,190 train 200 1.676530e-02 -1.048032
2019-11-06 07:10:56,354 train 250 1.683000e-02 -0.943254
2019-11-06 07:11:06,514 train 300 1.688429e-02 -1.052269
2019-11-06 07:11:16,678 train 350 1.686157e-02 -0.993753
2019-11-06 07:11:26,824 train 400 1.677826e-02 -0.989909
2019-11-06 07:11:36,962 train 450 1.675844e-02 -0.942433
2019-11-06 07:11:47,118 train 500 1.669681e-02 -0.899036
2019-11-06 07:11:57,295 train 550 1.669759e-02 -0.871009
2019-11-06 07:12:07,442 train 600 1.668156e-02 -0.835591
2019-11-06 07:12:17,631 train 650 1.672439e-02 -0.854521
2019-11-06 07:12:27,803 train 700 1.671380e-02 -0.855030
2019-11-06 07:12:38,013 train 750 1.666954e-02 -0.840127
2019-11-06 07:12:48,195 train 800 1.664640e-02 -0.838365
2019-11-06 07:12:58,358 train 850 1.663981e-02 -0.836776
2019-11-06 07:13:01,389 training loss; R2: 1.664411e-02 -0.831484
2019-11-06 07:13:01,906 valid 000 1.459916e-02 -0.390653
2019-11-06 07:13:11,755 valid 050 1.443556e-02 -0.933124
2019-11-06 07:13:20,434 validation loss; R2: 1.443812e-02 -2.314934
2019-11-06 07:13:20,498 epoch 395 lr 1.000000e-04
2019-11-06 07:13:21,239 train 000 1.765187e-02 -0.178043
2019-11-06 07:13:31,462 train 050 1.687499e-02 -0.438201
2019-11-06 07:13:41,669 train 100 1.678258e-02 -0.464027
2019-11-06 07:13:51,824 train 150 1.667302e-02 -0.532248
2019-11-06 07:14:01,995 train 200 1.656132e-02 -0.528582
2019-11-06 07:14:12,141 train 250 1.659659e-02 -0.546713
2019-11-06 07:14:22,346 train 300 1.661807e-02 -21.782797
2019-11-06 07:14:32,525 train 350 1.661092e-02 -18.761705
2019-11-06 07:14:42,711 train 400 1.657319e-02 -16.500248
2019-11-06 07:14:52,881 train 450 1.657020e-02 -14.743879
2019-11-06 07:15:03,061 train 500 1.656497e-02 -13.932314
2019-11-06 07:15:13,219 train 550 1.656085e-02 -12.732978
2019-11-06 07:15:23,344 train 600 1.654099e-02 -11.733929
2019-11-06 07:15:33,465 train 650 1.655360e-02 -10.868034
2019-11-06 07:15:43,606 train 700 1.652717e-02 -10.148710
2019-11-06 07:15:53,732 train 750 1.651923e-02 -9.549499
2019-11-06 07:16:03,908 train 800 1.653885e-02 -9.011933
2019-11-06 07:16:14,049 train 850 1.656264e-02 -8.529556
2019-11-06 07:16:17,082 training loss; R2: 1.656506e-02 -8.395242
2019-11-06 07:16:17,645 valid 000 1.240870e-02 -0.312570
2019-11-06 07:16:27,518 valid 050 1.267047e-02 -0.745356
2019-11-06 07:16:36,182 validation loss; R2: 1.277853e-02 -0.782036
2019-11-06 07:16:36,246 epoch 396 lr 1.000000e-04
2019-11-06 07:16:36,993 train 000 2.094014e-02 -0.204654
2019-11-06 07:16:47,203 train 050 1.654424e-02 -0.818872
2019-11-06 07:16:57,414 train 100 1.646681e-02 -0.649599
2019-11-06 07:17:07,621 train 150 1.650398e-02 -0.648428
2019-11-06 07:17:17,806 train 200 1.651102e-02 -0.720850
2019-11-06 07:17:28,034 train 250 1.659157e-02 -0.726201
2019-11-06 07:17:38,239 train 300 1.665447e-02 -0.720703
2019-11-06 07:17:48,415 train 350 1.663039e-02 -0.701662
2019-11-06 07:17:58,603 train 400 1.658292e-02 -0.736249
2019-11-06 07:18:08,796 train 450 1.654226e-02 -0.758293
2019-11-06 07:18:18,980 train 500 1.654459e-02 -0.757710
2019-11-06 07:18:29,178 train 550 1.656200e-02 -0.747646
2019-11-06 07:18:39,363 train 600 1.658226e-02 -0.759854
2019-11-06 07:18:49,565 train 650 1.658484e-02 -0.742958
2019-11-06 07:18:59,727 train 700 1.659279e-02 -0.721315
2019-11-06 07:19:09,920 train 750 1.658282e-02 -0.737517
2019-11-06 07:19:20,137 train 800 1.656038e-02 -0.737007
2019-11-06 07:19:30,350 train 850 1.658833e-02 -0.741877
2019-11-06 07:19:33,386 training loss; R2: 1.659832e-02 -0.737955
2019-11-06 07:19:33,914 valid 000 1.650495e-02 -0.287007
2019-11-06 07:19:43,759 valid 050 1.539648e-02 -4.515570
2019-11-06 07:19:52,427 validation loss; R2: 1.539415e-02 -2.988798
2019-11-06 07:19:52,509 epoch 397 lr 1.000000e-04
2019-11-06 07:19:53,174 train 000 1.793738e-02 0.083920
2019-11-06 07:20:03,414 train 050 1.707038e-02 -0.890893
2019-11-06 07:20:13,593 train 100 1.685803e-02 -0.702327
2019-11-06 07:20:23,749 train 150 1.684878e-02 -0.675165
2019-11-06 07:20:33,910 train 200 1.685656e-02 -0.630833
2019-11-06 07:20:44,062 train 250 1.693231e-02 -0.663717
2019-11-06 07:20:54,212 train 300 1.697247e-02 -0.676794
2019-11-06 07:21:04,374 train 350 1.698051e-02 -0.701481
2019-11-06 07:21:14,539 train 400 1.696477e-02 -0.677974
2019-11-06 07:21:24,684 train 450 1.696555e-02 -0.687943
2019-11-06 07:21:34,872 train 500 1.691480e-02 -0.705296
2019-11-06 07:21:45,050 train 550 1.690994e-02 -0.692241
2019-11-06 07:21:55,256 train 600 1.692976e-02 -0.711167
2019-11-06 07:22:05,469 train 650 1.691721e-02 -0.712186
2019-11-06 07:22:15,678 train 700 1.690367e-02 -0.713412
2019-11-06 07:22:25,843 train 750 1.690795e-02 -0.711056
2019-11-06 07:22:36,015 train 800 1.692699e-02 -0.704716
2019-11-06 07:22:46,158 train 850 1.692784e-02 -0.701092
2019-11-06 07:22:49,194 training loss; R2: 1.693237e-02 -0.695406
2019-11-06 07:22:49,708 valid 000 1.113917e-02 -2.381297
2019-11-06 07:22:59,528 valid 050 1.266207e-02 -1.106292
2019-11-06 07:23:08,174 validation loss; R2: 1.298675e-02 -1.198129
2019-11-06 07:23:08,246 epoch 398 lr 1.000000e-04
2019-11-06 07:23:08,908 train 000 2.076443e-02 -1.188831
2019-11-06 07:23:19,144 train 050 1.753489e-02 -0.524413
2019-11-06 07:23:29,302 train 100 1.732187e-02 -0.536489
2019-11-06 07:23:39,478 train 150 1.724472e-02 -0.515572
2019-11-06 07:23:49,623 train 200 1.722037e-02 -0.679991
2019-11-06 07:23:59,793 train 250 1.716937e-02 -0.682074
2019-11-06 07:24:09,950 train 300 1.708921e-02 -0.685632
2019-11-06 07:24:20,157 train 350 1.701634e-02 -0.676352
2019-11-06 07:24:30,288 train 400 1.703690e-02 -0.667140
2019-11-06 07:24:40,443 train 450 1.701746e-02 -0.675706
2019-11-06 07:24:50,577 train 500 1.702757e-02 -0.675924
2019-11-06 07:25:00,723 train 550 1.699448e-02 -0.651328
2019-11-06 07:25:10,885 train 600 1.700566e-02 -0.639014
2019-11-06 07:25:21,035 train 650 1.698341e-02 -0.630436
2019-11-06 07:25:31,189 train 700 1.693844e-02 -0.649489
2019-11-06 07:25:41,355 train 750 1.692118e-02 -0.685348
2019-11-06 07:25:51,539 train 800 1.692997e-02 -0.679842
2019-11-06 07:26:01,699 train 850 1.691894e-02 -0.675068
2019-11-06 07:26:04,726 training loss; R2: 1.690997e-02 -0.673522
2019-11-06 07:26:05,309 valid 000 1.324370e-02 -0.629327
2019-11-06 07:26:15,074 valid 050 1.269613e-02 -0.756009
2019-11-06 07:26:23,788 validation loss; R2: 1.280909e-02 -0.852650
2019-11-06 07:26:23,862 epoch 399 lr 1.000000e-04
2019-11-06 07:26:24,625 train 000 1.840674e-02 0.031544
2019-11-06 07:26:34,808 train 050 1.651557e-02 -1.001069
2019-11-06 07:26:44,983 train 100 1.688583e-02 -0.889289
2019-11-06 07:26:55,142 train 150 1.698973e-02 -0.757945
2019-11-06 07:27:05,310 train 200 1.711006e-02 -0.751633
2019-11-06 07:27:15,464 train 250 1.705351e-02 -0.704063
2019-11-06 07:27:25,593 train 300 1.716591e-02 -0.720577
2019-11-06 07:27:35,662 train 350 1.717974e-02 -0.707752
2019-11-06 07:27:45,730 train 400 1.716936e-02 -0.842544
2019-11-06 07:27:55,804 train 450 1.716959e-02 -0.838887
2019-11-06 07:28:05,917 train 500 1.720325e-02 -0.835121
2019-11-06 07:28:16,071 train 550 1.720045e-02 -0.817527
2019-11-06 07:28:26,187 train 600 1.718686e-02 -0.798982
2019-11-06 07:28:36,326 train 650 1.719277e-02 -0.792580
2019-11-06 07:28:46,466 train 700 1.720093e-02 -0.786800
2019-11-06 07:28:56,612 train 750 1.720678e-02 -0.768209
2019-11-06 07:29:06,738 train 800 1.722183e-02 -0.761057
2019-11-06 07:29:16,856 train 850 1.724366e-02 -0.741175
2019-11-06 07:29:19,880 training loss; R2: 1.724824e-02 -0.747943
2019-11-06 07:29:20,467 valid 000 1.551804e-02 -1.092496
2019-11-06 07:29:30,430 valid 050 1.308551e-02 -11.654902
2019-11-06 07:29:39,063 validation loss; R2: 1.303886e-02 -6.372395
2019-11-06 07:29:39,128 epoch 400 lr 1.000000e-04
2019-11-06 07:29:39,845 train 000 1.885335e-02 0.080610
2019-11-06 07:29:49,975 train 050 1.760548e-02 -0.510672
2019-11-06 07:30:00,055 train 100 1.753268e-02 -2.314885
2019-11-06 07:30:10,249 train 150 1.747091e-02 -2.585222
2019-11-06 07:30:20,387 train 200 1.736130e-02 -2.115396
2019-11-06 07:30:30,443 train 250 1.736655e-02 -1.920376
2019-11-06 07:30:40,575 train 300 1.735620e-02 -1.675788
2019-11-06 07:30:50,744 train 350 1.739270e-02 -1.546534
2019-11-06 07:31:00,830 train 400 1.736902e-02 -1.445381
2019-11-06 07:31:10,891 train 450 1.732417e-02 -1.363009
2019-11-06 07:31:21,007 train 500 1.738556e-02 -1.269183
2019-11-06 07:31:31,171 train 550 1.736680e-02 -1.196182
2019-11-06 07:31:41,241 train 600 1.734518e-02 -1.175210
2019-11-06 07:31:51,348 train 650 1.733791e-02 -1.134197
2019-11-06 07:32:01,592 train 700 1.731060e-02 -1.089025
2019-11-06 07:32:11,696 train 750 1.728676e-02 -1.044444
2019-11-06 07:32:21,853 train 800 1.726724e-02 -1.026626
2019-11-06 07:32:31,888 train 850 1.725322e-02 -1.011618
2019-11-06 07:32:34,897 training loss; R2: 1.726976e-02 -1.003870
2019-11-06 07:32:35,459 valid 000 1.190329e-02 0.157801
2019-11-06 07:32:45,241 valid 050 1.315611e-02 -0.925947
2019-11-06 07:32:53,894 validation loss; R2: 1.303011e-02 -1.138798
2019-11-06 07:32:53,965 epoch 401 lr 1.000000e-04
2019-11-06 07:32:54,643 train 000 1.665916e-02 -1.023799
2019-11-06 07:33:04,796 train 050 1.748271e-02 -0.650390
2019-11-06 07:33:14,891 train 100 1.730085e-02 -0.827465
2019-11-06 07:33:24,995 train 150 1.734706e-02 -0.796637
2019-11-06 07:33:35,077 train 200 1.733153e-02 -0.743175
2019-11-06 07:33:45,214 train 250 1.727811e-02 -0.704106
2019-11-06 07:33:55,360 train 300 1.735141e-02 -0.681717
2019-11-06 07:34:05,505 train 350 1.735391e-02 -0.659204
2019-11-06 07:34:15,626 train 400 1.730359e-02 -0.625983
2019-11-06 07:34:25,782 train 450 1.730897e-02 -0.624188
2019-11-06 07:34:35,951 train 500 1.730209e-02 -0.611357
2019-11-06 07:34:46,140 train 550 1.728010e-02 -0.625722
2019-11-06 07:34:56,318 train 600 1.726712e-02 -0.621054
2019-11-06 07:35:06,511 train 650 1.722662e-02 -0.648801
2019-11-06 07:35:16,683 train 700 1.720472e-02 -0.662873
2019-11-06 07:35:26,868 train 750 1.723998e-02 -0.673887
2019-11-06 07:35:37,034 train 800 1.723188e-02 -0.655275
2019-11-06 07:35:47,182 train 850 1.721269e-02 -0.645664
2019-11-06 07:35:50,226 training loss; R2: 1.722044e-02 -0.648512
2019-11-06 07:35:50,796 valid 000 1.297435e-02 -0.305690
2019-11-06 07:36:00,564 valid 050 1.460801e-02 -1.062441
2019-11-06 07:36:09,185 validation loss; R2: 1.461901e-02 -1.058731
2019-11-06 07:36:09,250 epoch 402 lr 1.000000e-04
2019-11-06 07:36:09,993 train 000 1.633088e-02 -0.246186
2019-11-06 07:36:20,118 train 050 1.728143e-02 -0.528769
2019-11-06 07:36:30,255 train 100 1.712449e-02 -0.598746
2019-11-06 07:36:40,449 train 150 1.717091e-02 -0.570658
2019-11-06 07:36:50,612 train 200 1.703800e-02 -0.623242
2019-11-06 07:37:00,691 train 250 1.707199e-02 -0.641490
2019-11-06 07:37:10,873 train 300 1.707693e-02 -0.678320
2019-11-06 07:37:20,996 train 350 1.714075e-02 -0.684358
2019-11-06 07:37:31,046 train 400 1.709650e-02 -0.688648
2019-11-06 07:37:41,174 train 450 1.711037e-02 -0.686501
2019-11-06 07:37:51,279 train 500 1.712435e-02 -0.815245
2019-11-06 07:38:01,330 train 550 1.709327e-02 -0.813830
2019-11-06 07:38:11,562 train 600 1.711081e-02 -0.796640
2019-11-06 07:38:21,773 train 650 1.711640e-02 -0.812216
2019-11-06 07:38:31,949 train 700 1.710977e-02 -0.825767
2019-11-06 07:38:42,122 train 750 1.712336e-02 -0.824384
2019-11-06 07:38:52,326 train 800 1.713277e-02 -0.811098
2019-11-06 07:39:02,486 train 850 1.712019e-02 -0.811563
2019-11-06 07:39:05,517 training loss; R2: 1.711674e-02 -0.808721
2019-11-06 07:39:06,080 valid 000 1.554716e-02 -0.241775
2019-11-06 07:39:15,895 valid 050 1.764420e-02 -0.385066
2019-11-06 07:39:24,567 validation loss; R2: 1.757602e-02 -0.379482
2019-11-06 07:39:24,634 epoch 403 lr 1.000000e-04
2019-11-06 07:39:25,302 train 000 2.120345e-02 -2.805582
2019-11-06 07:39:35,533 train 050 1.739089e-02 -0.465708
2019-11-06 07:39:45,724 train 100 1.725888e-02 -0.498388
2019-11-06 07:39:55,894 train 150 1.739513e-02 -0.515444
2019-11-06 07:40:06,058 train 200 1.736466e-02 -0.564019
2019-11-06 07:40:16,193 train 250 1.735359e-02 -0.568756
2019-11-06 07:40:26,337 train 300 1.732837e-02 -0.614765
2019-11-06 07:40:36,466 train 350 1.726223e-02 -0.587516
2019-11-06 07:40:46,622 train 400 1.720430e-02 -0.613863
2019-11-06 07:40:56,794 train 450 1.715675e-02 -0.623847
2019-11-06 07:41:06,974 train 500 1.716189e-02 -0.604931
2019-11-06 07:41:17,128 train 550 1.713381e-02 -0.615760
2019-11-06 07:41:27,318 train 600 1.711658e-02 -0.609956
2019-11-06 07:41:37,494 train 650 1.714265e-02 -0.598909
2019-11-06 07:41:47,663 train 700 1.714123e-02 -0.615809
2019-11-06 07:41:57,803 train 750 1.714721e-02 -0.603474
2019-11-06 07:42:07,990 train 800 1.715798e-02 -0.617425
2019-11-06 07:42:18,173 train 850 1.718642e-02 -0.627782
2019-11-06 07:42:21,191 training loss; R2: 1.718822e-02 -0.625373
2019-11-06 07:42:21,707 valid 000 1.193915e-02 -0.185110
2019-11-06 07:42:31,558 valid 050 1.323701e-02 -0.594222
2019-11-06 07:42:40,184 validation loss; R2: 1.320589e-02 -0.854069
2019-11-06 07:42:40,256 epoch 404 lr 1.000000e-04
2019-11-06 07:42:41,004 train 000 1.841090e-02 -0.002987
2019-11-06 07:42:51,251 train 050 1.721931e-02 -0.726489
2019-11-06 07:43:01,455 train 100 1.726602e-02 -0.667118
2019-11-06 07:43:11,670 train 150 1.727466e-02 -0.624479
2019-11-06 07:43:21,858 train 200 1.727001e-02 -0.632755
2019-11-06 07:43:32,047 train 250 1.735259e-02 -0.667995
2019-11-06 07:43:42,225 train 300 1.724076e-02 -0.657498
2019-11-06 07:43:52,448 train 350 1.730683e-02 -0.666739
2019-11-06 07:44:02,614 train 400 1.727055e-02 -0.652367
2019-11-06 07:44:12,791 train 450 1.724498e-02 -0.682251
2019-11-06 07:44:22,998 train 500 1.727769e-02 -0.682722
2019-11-06 07:44:33,191 train 550 1.725168e-02 -0.673206
2019-11-06 07:44:43,419 train 600 1.724277e-02 -0.688678
2019-11-06 07:44:53,544 train 650 1.723515e-02 -0.674861
2019-11-06 07:45:03,715 train 700 1.724664e-02 -0.676469
2019-11-06 07:45:13,856 train 750 1.724741e-02 -0.671295
2019-11-06 07:45:24,040 train 800 1.723168e-02 -0.670150
2019-11-06 07:45:34,191 train 850 1.724105e-02 -0.661829
2019-11-06 07:45:37,221 training loss; R2: 1.726012e-02 -0.662009
2019-11-06 07:45:37,737 valid 000 1.502778e-02 0.202250
2019-11-06 07:45:47,546 valid 050 1.359582e-02 -0.983718
2019-11-06 07:45:56,222 validation loss; R2: 1.350148e-02 -0.940419
2019-11-06 07:45:56,302 epoch 405 lr 1.000000e-04
2019-11-06 07:45:56,965 train 000 1.850629e-02 -0.446133
2019-11-06 07:46:07,205 train 050 1.664163e-02 -0.741478
2019-11-06 07:46:17,381 train 100 1.676978e-02 -0.887384
2019-11-06 07:46:27,555 train 150 1.686605e-02 -0.791340
2019-11-06 07:46:37,701 train 200 1.704839e-02 -0.718013
2019-11-06 07:46:47,873 train 250 1.716323e-02 -0.710243
2019-11-06 07:46:58,033 train 300 1.723119e-02 -0.684745
2019-11-06 07:47:08,215 train 350 1.731723e-02 -0.735097
2019-11-06 07:47:18,373 train 400 1.732743e-02 -0.722190
2019-11-06 07:47:28,544 train 450 1.730059e-02 -0.710479
2019-11-06 07:47:38,707 train 500 1.725213e-02 -0.716682
2019-11-06 07:47:48,900 train 550 1.726569e-02 -0.700342
2019-11-06 07:47:59,091 train 600 1.727706e-02 -0.717240
2019-11-06 07:48:09,290 train 650 1.726430e-02 -0.724796
2019-11-06 07:48:19,428 train 700 1.726007e-02 -0.705689
2019-11-06 07:48:29,580 train 750 1.723019e-02 -0.700297
2019-11-06 07:48:39,739 train 800 1.723647e-02 -0.690113
2019-11-06 07:48:49,905 train 850 1.723685e-02 -0.695525
2019-11-06 07:48:52,935 training loss; R2: 1.723578e-02 -0.693414
2019-11-06 07:48:53,458 valid 000 1.386231e-02 -0.276239
2019-11-06 07:49:03,270 valid 050 1.245505e-02 -1.227547
2019-11-06 07:49:11,915 validation loss; R2: 1.248446e-02 -1.149585
2019-11-06 07:49:11,990 epoch 406 lr 1.000000e-04
2019-11-06 07:49:12,730 train 000 1.898217e-02 -1.271386
2019-11-06 07:49:22,946 train 050 1.751056e-02 -0.530829
2019-11-06 07:49:33,134 train 100 1.740028e-02 -0.535554
2019-11-06 07:49:43,309 train 150 1.732491e-02 -0.613693
2019-11-06 07:49:53,484 train 200 1.731060e-02 -0.578354
2019-11-06 07:50:03,650 train 250 1.741589e-02 -0.559153
2019-11-06 07:50:13,806 train 300 1.744533e-02 -0.677793
2019-11-06 07:50:23,960 train 350 1.744058e-02 -0.661875
2019-11-06 07:50:34,111 train 400 1.741734e-02 -0.716289
2019-11-06 07:50:44,318 train 450 1.739150e-02 -0.713964
2019-11-06 07:50:54,505 train 500 1.737895e-02 -0.703404
2019-11-06 07:51:04,671 train 550 1.733830e-02 -0.692690
2019-11-06 07:51:14,827 train 600 1.736204e-02 -0.695871
2019-11-06 07:51:24,970 train 650 1.734230e-02 -0.695336
2019-11-06 07:51:35,124 train 700 1.735738e-02 -0.688086
2019-11-06 07:51:45,294 train 750 1.734916e-02 -0.695560
2019-11-06 07:51:55,414 train 800 1.735130e-02 -0.699275
2019-11-06 07:52:05,531 train 850 1.733565e-02 -0.689729
2019-11-06 07:52:08,558 training loss; R2: 1.733617e-02 -0.689851
2019-11-06 07:52:09,093 valid 000 1.349076e-02 0.024753
2019-11-06 07:52:19,285 valid 050 1.448204e-02 -1.771439
2019-11-06 07:52:27,944 validation loss; R2: 1.435515e-02 -1.753221
2019-11-06 07:52:28,016 epoch 407 lr 1.000000e-04
2019-11-06 07:52:28,752 train 000 2.132129e-02 -0.193064
2019-11-06 07:52:38,999 train 050 1.698639e-02 -0.689510
2019-11-06 07:52:49,180 train 100 1.713938e-02 -0.639380
2019-11-06 07:52:59,364 train 150 1.736186e-02 -1.053124
2019-11-06 07:53:09,544 train 200 1.730749e-02 -0.911614
2019-11-06 07:53:19,713 train 250 1.734751e-02 -0.871575
2019-11-06 07:53:29,857 train 300 1.735691e-02 -0.830385
2019-11-06 07:53:40,023 train 350 1.733016e-02 -0.798708
2019-11-06 07:53:50,156 train 400 1.734810e-02 -0.776070
2019-11-06 07:54:00,322 train 450 1.733207e-02 -0.758315
2019-11-06 07:54:10,465 train 500 1.736568e-02 -0.737498
2019-11-06 07:54:20,624 train 550 1.733878e-02 -0.734937
2019-11-06 07:54:30,795 train 600 1.737649e-02 -0.727064
2019-11-06 07:54:41,010 train 650 1.740517e-02 -0.713888
2019-11-06 07:54:51,191 train 700 1.736572e-02 -0.704575
2019-11-06 07:55:01,390 train 750 1.737304e-02 -0.688466
2019-11-06 07:55:11,559 train 800 1.737634e-02 -0.707276
2019-11-06 07:55:21,764 train 850 1.736737e-02 -0.713097
2019-11-06 07:55:24,807 training loss; R2: 1.737366e-02 -0.718411
2019-11-06 07:55:25,377 valid 000 1.499123e-02 -2.301659
2019-11-06 07:55:35,207 valid 050 1.411764e-02 -0.702911
2019-11-06 07:55:43,840 validation loss; R2: 1.411327e-02 -0.556235
2019-11-06 07:55:43,907 epoch 408 lr 1.000000e-04
2019-11-06 07:55:44,635 train 000 1.688172e-02 -0.453933
2019-11-06 07:55:54,831 train 050 1.780775e-02 -0.709414
2019-11-06 07:56:04,998 train 100 1.776286e-02 -0.931142
2019-11-06 07:56:15,142 train 150 1.775599e-02 -0.850912
2019-11-06 07:56:25,293 train 200 1.771113e-02 -0.813478
2019-11-06 07:56:35,435 train 250 1.766883e-02 -0.753802
2019-11-06 07:56:45,576 train 300 1.768228e-02 -0.796714
2019-11-06 07:56:55,730 train 350 1.763395e-02 -0.773645
2019-11-06 07:57:05,888 train 400 1.757018e-02 -0.796892
2019-11-06 07:57:16,019 train 450 1.761489e-02 -0.781420
2019-11-06 07:57:26,138 train 500 1.759896e-02 -0.743807
2019-11-06 07:57:36,273 train 550 1.756028e-02 -0.716947
2019-11-06 07:57:46,399 train 600 1.755757e-02 -0.828803
2019-11-06 07:57:56,545 train 650 1.755267e-02 -0.797028
2019-11-06 07:58:06,666 train 700 1.753334e-02 -0.786003
2019-11-06 07:58:16,787 train 750 1.755769e-02 -0.772795
2019-11-06 07:58:26,908 train 800 1.758652e-02 -0.750784
2019-11-06 07:58:37,049 train 850 1.757881e-02 -0.739213
2019-11-06 07:58:40,069 training loss; R2: 1.757764e-02 -0.732853
2019-11-06 07:58:40,633 valid 000 1.472072e-02 -0.669400
2019-11-06 07:58:50,433 valid 050 1.406817e-02 -1.107315
2019-11-06 07:58:59,049 validation loss; R2: 1.418389e-02 -1.022971
2019-11-06 07:58:59,114 epoch 409 lr 1.000000e-04
2019-11-06 07:58:59,820 train 000 1.765402e-02 -0.431385
2019-11-06 07:59:10,166 train 050 1.756458e-02 -0.564466
2019-11-06 07:59:20,480 train 100 1.726873e-02 -0.663725
2019-11-06 07:59:30,764 train 150 1.727183e-02 -0.754082
2019-11-06 07:59:41,058 train 200 1.720349e-02 -2.367001
2019-11-06 07:59:51,369 train 250 1.718336e-02 -2.025883
2019-11-06 08:00:01,683 train 300 1.717178e-02 -1.777972
2019-11-06 08:00:12,014 train 350 1.725785e-02 -1.586676
2019-11-06 08:00:22,339 train 400 1.729806e-02 -1.454651
2019-11-06 08:00:32,668 train 450 1.732323e-02 -1.374707
2019-11-06 08:00:42,966 train 500 1.729506e-02 -1.323564
2019-11-06 08:00:53,142 train 550 1.731972e-02 -1.492450
2019-11-06 08:01:03,292 train 600 1.732484e-02 -1.439654
2019-11-06 08:01:13,413 train 650 1.731834e-02 -1.377272
2019-11-06 08:01:23,469 train 700 1.735354e-02 -1.311336
2019-11-06 08:01:33,649 train 750 1.738033e-02 -1.267816
2019-11-06 08:01:43,859 train 800 1.740102e-02 -1.216537
2019-11-06 08:01:54,028 train 850 1.739295e-02 -1.187568
2019-11-06 08:01:57,068 training loss; R2: 1.739733e-02 -1.188181
2019-11-06 08:01:57,640 valid 000 1.404927e-02 -0.352046
2019-11-06 08:02:07,457 valid 050 1.677548e-02 -0.618491
2019-11-06 08:02:16,142 validation loss; R2: 1.703670e-02 -0.542822
2019-11-06 08:02:16,208 epoch 410 lr 1.000000e-04
2019-11-06 08:02:16,937 train 000 1.581297e-02 -0.804307
2019-11-06 08:02:27,062 train 050 1.729808e-02 -0.663229
2019-11-06 08:02:37,291 train 100 1.735795e-02 -0.819972
2019-11-06 08:02:47,436 train 150 1.745172e-02 -0.912461
2019-11-06 08:02:57,598 train 200 1.742665e-02 -0.770023
2019-11-06 08:03:07,855 train 250 1.740089e-02 -0.746258
2019-11-06 08:03:18,053 train 300 1.746873e-02 -0.747116
2019-11-06 08:03:28,264 train 350 1.739299e-02 -0.749021
2019-11-06 08:03:38,451 train 400 1.739616e-02 -0.782205
2019-11-06 08:03:48,630 train 450 1.738536e-02 -0.741978
2019-11-06 08:03:58,816 train 500 1.736204e-02 -0.716420
2019-11-06 08:04:09,004 train 550 1.734461e-02 -0.716042
2019-11-06 08:04:19,179 train 600 1.732054e-02 -0.711186
2019-11-06 08:04:29,378 train 650 1.732868e-02 -0.697817
2019-11-06 08:04:39,579 train 700 1.730319e-02 -0.699149
2019-11-06 08:04:49,749 train 750 1.730650e-02 -0.701969
2019-11-06 08:04:59,907 train 800 1.734989e-02 -0.700328
2019-11-06 08:05:10,058 train 850 1.734941e-02 -0.696843
2019-11-06 08:05:13,082 training loss; R2: 1.734200e-02 -0.694303
2019-11-06 08:05:13,644 valid 000 1.656858e-02 -0.083023
2019-11-06 08:05:23,480 valid 050 1.741558e-02 -1.205069
2019-11-06 08:05:32,109 validation loss; R2: 1.760613e-02 -1.405991
2019-11-06 08:05:32,172 epoch 411 lr 1.000000e-04
2019-11-06 08:05:32,887 train 000 1.258169e-02 -0.530781
2019-11-06 08:05:43,079 train 050 1.762355e-02 -0.430651
2019-11-06 08:05:53,247 train 100 1.754326e-02 -0.512644
2019-11-06 08:06:03,421 train 150 1.756320e-02 -0.529608
2019-11-06 08:06:13,561 train 200 1.749834e-02 -0.499268
2019-11-06 08:06:23,737 train 250 1.744172e-02 -0.522488
2019-11-06 08:06:33,879 train 300 1.748563e-02 -0.627554
2019-11-06 08:06:44,040 train 350 1.753973e-02 -0.698868
2019-11-06 08:06:54,177 train 400 1.748157e-02 -0.684935
2019-11-06 08:07:04,336 train 450 1.742845e-02 -0.682071
2019-11-06 08:07:14,465 train 500 1.740669e-02 -0.677927
2019-11-06 08:07:24,607 train 550 1.740698e-02 -0.674834
2019-11-06 08:07:34,774 train 600 1.741361e-02 -0.680576
2019-11-06 08:07:44,925 train 650 1.742769e-02 -0.674483
2019-11-06 08:07:55,059 train 700 1.741926e-02 -0.668416
2019-11-06 08:08:05,218 train 750 1.740412e-02 -0.679453
2019-11-06 08:08:15,352 train 800 1.742140e-02 -0.685353
2019-11-06 08:08:25,524 train 850 1.741748e-02 -0.696366
2019-11-06 08:08:28,565 training loss; R2: 1.741101e-02 -0.697734
2019-11-06 08:08:29,095 valid 000 1.496173e-02 -0.491424
2019-11-06 08:08:38,931 valid 050 1.567024e-02 -1.106259
2019-11-06 08:08:47,616 validation loss; R2: 1.587090e-02 -1.143341
2019-11-06 08:08:47,703 epoch 412 lr 1.000000e-04
2019-11-06 08:08:48,427 train 000 1.601162e-02 -0.107753
2019-11-06 08:08:58,573 train 050 1.721617e-02 -0.470074
2019-11-06 08:09:08,721 train 100 1.715505e-02 -0.703984
2019-11-06 08:09:18,901 train 150 1.724682e-02 -0.673171
2019-11-06 08:09:29,084 train 200 1.726763e-02 -0.616203
2019-11-06 08:09:39,191 train 250 1.729811e-02 -0.603545
2019-11-06 08:09:49,276 train 300 1.722682e-02 -0.620294
2019-11-06 08:09:59,435 train 350 1.724155e-02 -0.660488
2019-11-06 08:10:09,570 train 400 1.729349e-02 -0.645856
2019-11-06 08:10:19,683 train 450 1.731316e-02 -0.630194
2019-11-06 08:10:29,783 train 500 1.730567e-02 -0.620268
2019-11-06 08:10:39,897 train 550 1.734803e-02 -0.634180
2019-11-06 08:10:50,082 train 600 1.739679e-02 -0.626641
2019-11-06 08:11:00,274 train 650 1.742922e-02 -0.618259
2019-11-06 08:11:10,386 train 700 1.745191e-02 -0.614109
2019-11-06 08:11:20,492 train 750 1.743122e-02 -0.604646
2019-11-06 08:11:30,604 train 800 1.742111e-02 -0.611651
2019-11-06 08:11:40,756 train 850 1.741127e-02 -0.608409
2019-11-06 08:11:43,781 training loss; R2: 1.741720e-02 -0.608422
2019-11-06 08:11:44,340 valid 000 1.080091e-02 0.008182
2019-11-06 08:11:54,164 valid 050 1.245487e-02 -0.398916
2019-11-06 08:12:02,858 validation loss; R2: 1.251572e-02 -0.584601
2019-11-06 08:12:02,923 epoch 413 lr 1.000000e-04
2019-11-06 08:12:03,615 train 000 1.918714e-02 0.029483
2019-11-06 08:12:13,742 train 050 1.744463e-02 -0.695948
2019-11-06 08:12:23,894 train 100 1.740017e-02 -0.675224
2019-11-06 08:12:34,073 train 150 1.736142e-02 -0.909203
2019-11-06 08:12:44,224 train 200 1.737675e-02 -0.869638
2019-11-06 08:12:54,372 train 250 1.732846e-02 -0.818352
2019-11-06 08:13:04,547 train 300 1.728596e-02 -0.769019
2019-11-06 08:13:14,756 train 350 1.729396e-02 -0.735029
2019-11-06 08:13:24,938 train 400 1.733040e-02 -0.727250
2019-11-06 08:13:35,113 train 450 1.738189e-02 -0.718874
2019-11-06 08:13:45,272 train 500 1.742725e-02 -0.701699
2019-11-06 08:13:55,430 train 550 1.743998e-02 -0.694197
2019-11-06 08:14:05,586 train 600 1.747583e-02 -0.678156
2019-11-06 08:14:15,757 train 650 1.749386e-02 -0.677584
2019-11-06 08:14:25,932 train 700 1.746948e-02 -0.680402
2019-11-06 08:14:36,131 train 750 1.747007e-02 -0.689395
2019-11-06 08:14:46,308 train 800 1.747984e-02 -0.692306
2019-11-06 08:14:56,466 train 850 1.746412e-02 -0.692520
2019-11-06 08:14:59,497 training loss; R2: 1.746761e-02 -0.690378
2019-11-06 08:15:00,091 valid 000 1.410555e-02 0.168437
2019-11-06 08:15:09,721 valid 050 1.369066e-02 -0.741962
2019-11-06 08:15:18,619 validation loss; R2: 1.346370e-02 -0.984826
2019-11-06 08:15:18,683 epoch 414 lr 1.000000e-04
2019-11-06 08:15:19,443 train 000 1.712704e-02 -0.468034
2019-11-06 08:15:29,804 train 050 1.743103e-02 -0.765638
2019-11-06 08:15:40,034 train 100 1.760456e-02 -0.782475
2019-11-06 08:15:50,240 train 150 1.752499e-02 -0.805002
2019-11-06 08:16:00,414 train 200 1.739856e-02 -0.799099
2019-11-06 08:16:10,618 train 250 1.748492e-02 -0.745940
2019-11-06 08:16:20,771 train 300 1.749276e-02 -0.713931
2019-11-06 08:16:30,979 train 350 1.752403e-02 -0.686350
2019-11-06 08:16:41,181 train 400 1.758027e-02 -0.680116
2019-11-06 08:16:51,411 train 450 1.753382e-02 -0.660233
2019-11-06 08:17:01,606 train 500 1.748339e-02 -0.655040
2019-11-06 08:17:11,808 train 550 1.746310e-02 -0.656801
2019-11-06 08:17:21,924 train 600 1.748718e-02 -0.666549
2019-11-06 08:17:32,065 train 650 1.750956e-02 -0.664389
2019-11-06 08:17:42,173 train 700 1.752937e-02 -0.682415
2019-11-06 08:17:52,288 train 750 1.755942e-02 -0.683656
2019-11-06 08:18:02,421 train 800 1.754581e-02 -0.708638
2019-11-06 08:18:12,605 train 850 1.753387e-02 -0.696774
2019-11-06 08:18:15,642 training loss; R2: 1.753697e-02 -0.696048
2019-11-06 08:18:16,215 valid 000 1.604423e-02 0.087580
2019-11-06 08:18:26,021 valid 050 1.330812e-02 -1.227721
2019-11-06 08:18:34,746 validation loss; R2: 1.349813e-02 -1.331378
2019-11-06 08:18:34,817 epoch 415 lr 1.000000e-04
2019-11-06 08:18:35,487 train 000 1.572305e-02 -0.497510
2019-11-06 08:18:45,743 train 050 1.749598e-02 -0.545162
2019-11-06 08:18:55,916 train 100 1.760870e-02 -0.738109
2019-11-06 08:19:06,107 train 150 1.752566e-02 -0.641886
2019-11-06 08:19:16,278 train 200 1.742373e-02 -0.697397
2019-11-06 08:19:26,434 train 250 1.743086e-02 -0.647799
2019-11-06 08:19:36,597 train 300 1.739985e-02 -1.708822
2019-11-06 08:19:46,747 train 350 1.737389e-02 -1.587996
2019-11-06 08:19:56,917 train 400 1.733981e-02 -1.486091
2019-11-06 08:20:07,054 train 450 1.733273e-02 -1.398762
2019-11-06 08:20:17,166 train 500 1.734859e-02 -1.334389
2019-11-06 08:20:27,312 train 550 1.733334e-02 -1.277516
2019-11-06 08:20:37,462 train 600 1.736321e-02 -1.199475
2019-11-06 08:20:47,604 train 650 1.730105e-02 -1.163696
2019-11-06 08:20:57,754 train 700 1.730723e-02 -1.121220
2019-11-06 08:21:07,928 train 750 1.731749e-02 -1.109906
2019-11-06 08:21:18,119 train 800 1.731750e-02 -1.082669
2019-11-06 08:21:28,327 train 850 1.733199e-02 -1.055720
2019-11-06 08:21:31,364 training loss; R2: 1.734040e-02 -1.042837
2019-11-06 08:21:31,908 valid 000 1.210838e-02 -1.743767
2019-11-06 08:21:41,686 valid 050 1.327394e-02 -0.896382
2019-11-06 08:21:50,362 validation loss; R2: 1.321023e-02 -1.284652
2019-11-06 08:21:50,430 epoch 416 lr 1.000000e-04
2019-11-06 08:21:51,147 train 000 1.864839e-02 0.090038
2019-11-06 08:22:01,444 train 050 1.747306e-02 -0.476331
2019-11-06 08:22:11,667 train 100 1.735987e-02 -0.553466
2019-11-06 08:22:21,856 train 150 1.742675e-02 -0.599029
2019-11-06 08:22:32,020 train 200 1.736753e-02 -0.592460
2019-11-06 08:22:42,210 train 250 1.738312e-02 -0.652206
2019-11-06 08:22:52,392 train 300 1.733462e-02 -0.669175
2019-11-06 08:23:02,610 train 350 1.733359e-02 -0.647897
2019-11-06 08:23:12,749 train 400 1.731170e-02 -0.630849
2019-11-06 08:23:22,916 train 450 1.734152e-02 -0.627643
2019-11-06 08:23:33,043 train 500 1.736416e-02 -0.615696
2019-11-06 08:23:43,206 train 550 1.738873e-02 -0.608705
2019-11-06 08:23:53,343 train 600 1.733980e-02 -0.612089
2019-11-06 08:24:03,532 train 650 1.735179e-02 -0.602873
2019-11-06 08:24:13,663 train 700 1.734438e-02 -0.601969
2019-11-06 08:24:23,820 train 750 1.738888e-02 -0.619115
2019-11-06 08:24:33,967 train 800 1.740322e-02 -0.618140
2019-11-06 08:24:44,113 train 850 1.741954e-02 -0.621582
2019-11-06 08:24:47,135 training loss; R2: 1.742260e-02 -0.617901
2019-11-06 08:24:47,644 valid 000 1.613922e-02 -0.966422
2019-11-06 08:24:57,465 valid 050 1.314609e-02 -1.285436
2019-11-06 08:25:06,205 validation loss; R2: 1.318892e-02 -1.263857
2019-11-06 08:25:06,273 epoch 417 lr 1.000000e-04
2019-11-06 08:25:06,942 train 000 1.618160e-02 -0.115584
2019-11-06 08:25:17,169 train 050 1.741771e-02 -3.762523
2019-11-06 08:25:27,378 train 100 1.739057e-02 -2.299378
2019-11-06 08:25:37,554 train 150 1.747366e-02 -1.762573
2019-11-06 08:25:47,742 train 200 1.747090e-02 -1.478111
2019-11-06 08:25:57,906 train 250 1.743093e-02 -1.289506
2019-11-06 08:26:08,081 train 300 1.748664e-02 -1.168648
2019-11-06 08:26:18,249 train 350 1.750217e-02 -1.104798
2019-11-06 08:26:28,429 train 400 1.751977e-02 -1.078562
2019-11-06 08:26:38,601 train 450 1.755819e-02 -1.028209
2019-11-06 08:26:48,783 train 500 1.754712e-02 -0.992789
2019-11-06 08:26:58,880 train 550 1.759243e-02 -0.953297
2019-11-06 08:27:09,022 train 600 1.760804e-02 -0.909014
2019-11-06 08:27:19,154 train 650 1.761419e-02 -0.875947
2019-11-06 08:27:29,302 train 700 1.762790e-02 -0.860402
2019-11-06 08:27:39,423 train 750 1.760245e-02 -0.837048
2019-11-06 08:27:49,556 train 800 1.758723e-02 -0.812057
2019-11-06 08:27:59,690 train 850 1.756246e-02 -0.830936
2019-11-06 08:28:02,716 training loss; R2: 1.756017e-02 -0.823586
2019-11-06 08:28:03,317 valid 000 2.386263e-02 -0.952351
2019-11-06 08:28:13,163 valid 050 2.212992e-02 -1.589252
2019-11-06 08:28:21,918 validation loss; R2: 2.219016e-02 -1.709008
2019-11-06 08:28:21,983 epoch 418 lr 1.000000e-04
2019-11-06 08:28:22,701 train 000 1.742322e-02 -0.598453
2019-11-06 08:28:32,885 train 050 1.754130e-02 -0.581435
2019-11-06 08:28:43,038 train 100 1.755294e-02 -0.631821
2019-11-06 08:28:53,157 train 150 1.758871e-02 -0.657212
2019-11-06 08:29:03,266 train 200 1.765424e-02 -0.763573
2019-11-06 08:29:13,382 train 250 1.758747e-02 -0.802111
2019-11-06 08:29:23,496 train 300 1.753729e-02 -0.777411
2019-11-06 08:29:33,623 train 350 1.750654e-02 -0.783679
2019-11-06 08:29:43,767 train 400 1.752638e-02 -0.768453
2019-11-06 08:29:53,951 train 450 1.751336e-02 -0.728484
2019-11-06 08:30:04,063 train 500 1.748397e-02 -0.748328
2019-11-06 08:30:14,245 train 550 1.749804e-02 -0.761151
2019-11-06 08:30:24,432 train 600 1.755396e-02 -0.758244
2019-11-06 08:30:34,602 train 650 1.752876e-02 -0.746468
2019-11-06 08:30:44,784 train 700 1.749698e-02 -0.733006
2019-11-06 08:30:54,986 train 750 1.747654e-02 -0.716552
2019-11-06 08:31:05,155 train 800 1.747848e-02 -0.730100
2019-11-06 08:31:15,320 train 850 1.745736e-02 -0.715902
2019-11-06 08:31:18,360 training loss; R2: 1.745970e-02 -0.712030
2019-11-06 08:31:18,873 valid 000 1.360946e-02 -0.008340
2019-11-06 08:31:28,700 valid 050 1.312664e-02 -1.274608
2019-11-06 08:31:37,348 validation loss; R2: 1.321234e-02 -1.298748
2019-11-06 08:31:37,412 epoch 419 lr 1.000000e-04
2019-11-06 08:31:38,144 train 000 1.852128e-02 -0.021872
2019-11-06 08:31:48,324 train 050 1.743795e-02 -0.538207
2019-11-06 08:31:58,543 train 100 1.736670e-02 -0.598149
2019-11-06 08:32:08,705 train 150 1.737949e-02 -0.566961
2019-11-06 08:32:18,887 train 200 1.727485e-02 -0.564530
2019-11-06 08:32:29,042 train 250 1.732285e-02 -0.604373
2019-11-06 08:32:39,208 train 300 1.744670e-02 -0.699224
2019-11-06 08:32:49,320 train 350 1.751339e-02 -0.690524
2019-11-06 08:32:59,453 train 400 1.756819e-02 -0.667179
2019-11-06 08:33:09,560 train 450 1.755083e-02 -0.655322
2019-11-06 08:33:19,674 train 500 1.751988e-02 -38.595340
2019-11-06 08:33:29,768 train 550 1.750224e-02 -35.172263
2019-11-06 08:33:39,954 train 600 1.746833e-02 -32.282025
2019-11-06 08:33:50,143 train 650 1.745185e-02 -29.859241
2019-11-06 08:34:00,362 train 700 1.745104e-02 -27.776168
2019-11-06 08:34:10,560 train 750 1.743507e-02 -25.963473
2019-11-06 08:34:20,773 train 800 1.743152e-02 -24.384745
2019-11-06 08:34:30,989 train 850 1.742360e-02 -22.992531
2019-11-06 08:34:34,038 training loss; R2: 1.745030e-02 -22.605050
2019-11-06 08:34:34,582 valid 000 1.273402e-02 -0.105057
2019-11-06 08:34:44,490 valid 050 1.306972e-02 -0.702569
2019-11-06 08:34:53,589 validation loss; R2: 1.311586e-02 -1.070761
2019-11-06 08:34:53,653 epoch 420 lr 1.000000e-04
2019-11-06 08:34:54,374 train 000 1.900043e-02 -0.363780
2019-11-06 08:35:04,643 train 050 1.739982e-02 -0.790690
2019-11-06 08:35:14,878 train 100 1.766649e-02 -0.686525
2019-11-06 08:35:25,090 train 150 1.745167e-02 -0.670831
2019-11-06 08:35:35,291 train 200 1.737533e-02 -0.647159
2019-11-06 08:35:45,454 train 250 1.746056e-02 -0.647985
2019-11-06 08:35:55,604 train 300 1.756623e-02 -0.692524
2019-11-06 08:36:05,759 train 350 1.752955e-02 -0.698713
2019-11-06 08:36:15,932 train 400 1.750100e-02 -0.695177
2019-11-06 08:36:26,101 train 450 1.749636e-02 -0.687817
2019-11-06 08:36:36,319 train 500 1.746875e-02 -0.672908
2019-11-06 08:36:46,532 train 550 1.748309e-02 -0.665812
2019-11-06 08:36:56,716 train 600 1.750052e-02 -0.651307
2019-11-06 08:37:06,916 train 650 1.750782e-02 -0.639958
2019-11-06 08:37:17,090 train 700 1.749841e-02 -0.699834
2019-11-06 08:37:27,270 train 750 1.752989e-02 -0.691711
2019-11-06 08:37:37,434 train 800 1.754558e-02 -0.695466
2019-11-06 08:37:47,574 train 850 1.753459e-02 -0.676278
2019-11-06 08:37:50,597 training loss; R2: 1.753280e-02 -0.679951
2019-11-06 08:37:51,170 valid 000 1.289571e-02 -0.327870
2019-11-06 08:38:00,905 valid 050 1.275250e-02 -0.681181
2019-11-06 08:38:09,626 validation loss; R2: 1.289155e-02 -0.687598
2019-11-06 08:38:09,694 epoch 421 lr 1.000000e-04
2019-11-06 08:38:10,371 train 000 1.906228e-02 -0.069805
2019-11-06 08:38:20,600 train 050 1.746549e-02 -6.515762
2019-11-06 08:38:30,762 train 100 1.737776e-02 -3.653478
2019-11-06 08:38:40,926 train 150 1.738007e-02 -2.684858
2019-11-06 08:38:51,093 train 200 1.736076e-02 -2.182354
2019-11-06 08:39:01,237 train 250 1.740903e-02 -1.870226
2019-11-06 08:39:11,453 train 300 1.740432e-02 -1.684897
2019-11-06 08:39:21,630 train 350 1.743971e-02 -1.557080
2019-11-06 08:39:31,865 train 400 1.743047e-02 -1.469612
2019-11-06 08:39:42,039 train 450 1.744681e-02 -1.386359
2019-11-06 08:39:52,247 train 500 1.744469e-02 -1.323157
2019-11-06 08:40:02,443 train 550 1.748261e-02 -1.263223
2019-11-06 08:40:12,639 train 600 1.752201e-02 -1.202282
2019-11-06 08:40:22,842 train 650 1.754987e-02 -1.145921
2019-11-06 08:40:33,015 train 700 1.753673e-02 -1.110582
2019-11-06 08:40:43,213 train 750 1.752102e-02 -1.077455
2019-11-06 08:40:53,359 train 800 1.753724e-02 -1.063783
2019-11-06 08:41:03,516 train 850 1.755116e-02 -1.075397
2019-11-06 08:41:06,558 training loss; R2: 1.754855e-02 -1.066069
2019-11-06 08:41:07,069 valid 000 1.526895e-02 -0.721215
2019-11-06 08:41:16,882 valid 050 1.315000e-02 -1.061121
2019-11-06 08:41:25,500 validation loss; R2: 1.302185e-02 -1.536825
2019-11-06 08:41:25,570 epoch 422 lr 1.000000e-04
2019-11-06 08:41:26,302 train 000 1.496378e-02 -2.724298
2019-11-06 08:41:36,543 train 050 1.704971e-02 -11.282133
2019-11-06 08:41:46,795 train 100 1.715200e-02 -5.993694
2019-11-06 08:41:57,025 train 150 1.725820e-02 -4.295050
2019-11-06 08:42:07,268 train 200 1.716481e-02 -3.382304
2019-11-06 08:42:17,468 train 250 1.711287e-02 -2.822660
2019-11-06 08:42:27,674 train 300 1.718981e-02 -2.446484
2019-11-06 08:42:37,871 train 350 1.723217e-02 -2.176784
2019-11-06 08:42:48,064 train 400 1.724691e-02 -2.032307
2019-11-06 08:42:58,241 train 450 1.727112e-02 -1.875734
2019-11-06 08:43:08,422 train 500 1.728774e-02 -1.775448
2019-11-06 08:43:18,578 train 550 1.727904e-02 -1.767764
2019-11-06 08:43:28,756 train 600 1.731674e-02 -1.675493
2019-11-06 08:43:38,945 train 650 1.728838e-02 -1.608515
2019-11-06 08:43:49,138 train 700 1.728972e-02 -1.545011
2019-11-06 08:43:59,347 train 750 1.730295e-02 -1.480500
2019-11-06 08:44:09,578 train 800 1.731705e-02 -1.439602
2019-11-06 08:44:19,780 train 850 1.733619e-02 -1.405682
2019-11-06 08:44:22,813 training loss; R2: 1.734255e-02 -1.397242
2019-11-06 08:44:23,337 valid 000 1.574897e-02 -0.199548
2019-11-06 08:44:33,152 valid 050 1.288307e-02 -0.898236
2019-11-06 08:44:41,818 validation loss; R2: 1.289915e-02 -0.924231
2019-11-06 08:44:41,882 epoch 423 lr 1.000000e-04
2019-11-06 08:44:42,614 train 000 1.466928e-02 -0.348177
2019-11-06 08:44:52,801 train 050 1.712668e-02 -0.721704
2019-11-06 08:45:03,007 train 100 1.731840e-02 -0.776459
2019-11-06 08:45:13,178 train 150 1.739691e-02 -0.782708
2019-11-06 08:45:23,367 train 200 1.743399e-02 -0.771497
2019-11-06 08:45:33,540 train 250 1.743914e-02 -0.721256
2019-11-06 08:45:43,700 train 300 1.744341e-02 -0.696696
2019-11-06 08:45:53,853 train 350 1.741602e-02 -0.678229
2019-11-06 08:46:04,030 train 400 1.740746e-02 -0.666002
2019-11-06 08:46:14,205 train 450 1.739305e-02 -0.672227
2019-11-06 08:46:24,384 train 500 1.744150e-02 -0.667606
2019-11-06 08:46:34,552 train 550 1.743928e-02 -0.667329
2019-11-06 08:46:44,653 train 600 1.745766e-02 -0.649473
2019-11-06 08:46:54,846 train 650 1.746580e-02 -0.632131
2019-11-06 08:47:05,004 train 700 1.746999e-02 -0.641378
2019-11-06 08:47:15,182 train 750 1.748891e-02 -0.636897
2019-11-06 08:47:25,325 train 800 1.750409e-02 -0.626786
2019-11-06 08:47:35,499 train 850 1.747364e-02 -0.618098
2019-11-06 08:47:38,543 training loss; R2: 1.747240e-02 -0.616488
2019-11-06 08:47:39,101 valid 000 1.737440e-02 -0.355032
2019-11-06 08:47:48,914 valid 050 1.429893e-02 -1.257491
2019-11-06 08:47:57,612 validation loss; R2: 1.424359e-02 -1.111676
2019-11-06 08:47:57,674 epoch 424 lr 1.000000e-04
2019-11-06 08:47:58,337 train 000 1.875914e-02 -0.001422
2019-11-06 08:48:08,534 train 050 1.764979e-02 -0.753711
2019-11-06 08:48:18,695 train 100 1.730420e-02 -0.579163
2019-11-06 08:48:28,823 train 150 1.735383e-02 -0.657465
2019-11-06 08:48:38,998 train 200 1.737483e-02 -0.846464
2019-11-06 08:48:49,204 train 250 1.754939e-02 -0.780031
2019-11-06 08:48:59,387 train 300 1.749020e-02 -0.727578
2019-11-06 08:49:09,592 train 350 1.745938e-02 -0.749427
2019-11-06 08:49:19,804 train 400 1.747600e-02 -1.287898
2019-11-06 08:49:30,038 train 450 1.745511e-02 -1.275236
2019-11-06 08:49:40,263 train 500 1.745304e-02 -1.219865
2019-11-06 08:49:50,478 train 550 1.747590e-02 -1.159721
2019-11-06 08:50:00,708 train 600 1.748458e-02 -1.110528
2019-11-06 08:50:10,875 train 650 1.748739e-02 -1.073015
2019-11-06 08:50:21,048 train 700 1.749376e-02 -1.076743
2019-11-06 08:50:31,181 train 750 1.748924e-02 -1.051842
2019-11-06 08:50:41,362 train 800 1.749689e-02 -1.017301
2019-11-06 08:50:51,533 train 850 1.749675e-02 -1.003551
2019-11-06 08:50:54,571 training loss; R2: 1.749858e-02 -0.998685
2019-11-06 08:50:55,094 valid 000 1.340008e-02 -2.217450
2019-11-06 08:51:04,954 valid 050 1.619409e-02 -1.395094
2019-11-06 08:51:13,638 validation loss; R2: 1.606990e-02 -1.316101
2019-11-06 08:51:13,702 epoch 425 lr 1.000000e-04
2019-11-06 08:51:14,388 train 000 1.948542e-02 -0.365652
2019-11-06 08:51:24,547 train 050 1.772593e-02 -0.544512
2019-11-06 08:51:34,711 train 100 1.761574e-02 -0.570609
2019-11-06 08:51:44,901 train 150 1.749409e-02 -0.517960
2019-11-06 08:51:54,973 train 200 1.761821e-02 -0.556990
2019-11-06 08:52:05,130 train 250 1.759726e-02 -0.514049
2019-11-06 08:52:15,290 train 300 1.754178e-02 -0.531803
2019-11-06 08:52:25,360 train 350 1.754795e-02 -0.527432
2019-11-06 08:52:35,491 train 400 1.763675e-02 -0.532037
2019-11-06 08:52:45,642 train 450 1.769143e-02 -0.543440
2019-11-06 08:52:55,843 train 500 1.767948e-02 -0.558868
2019-11-06 08:53:06,058 train 550 1.762796e-02 -0.554352
2019-11-06 08:53:16,222 train 600 1.762283e-02 -0.563756
2019-11-06 08:53:26,397 train 650 1.762971e-02 -0.555696
2019-11-06 08:53:36,555 train 700 1.761895e-02 -0.558347
2019-11-06 08:53:46,815 train 750 1.761657e-02 -0.562567
2019-11-06 08:53:56,930 train 800 1.762357e-02 -0.576876
2019-11-06 08:54:07,106 train 850 1.765346e-02 -0.595148
2019-11-06 08:54:10,148 training loss; R2: 1.765526e-02 -0.588413
2019-11-06 08:54:10,667 valid 000 1.362514e-02 -1.288849
2019-11-06 08:54:20,485 valid 050 1.419598e-02 -1.098195
2019-11-06 08:54:29,148 validation loss; R2: 1.407872e-02 -0.986488
2019-11-06 08:54:29,215 epoch 426 lr 1.000000e-04
2019-11-06 08:54:29,890 train 000 1.974267e-02 -0.369320
2019-11-06 08:54:40,123 train 050 1.847604e-02 -0.556190
2019-11-06 08:54:50,352 train 100 1.814293e-02 -0.517671
2019-11-06 08:55:00,520 train 150 1.782078e-02 -0.755800
2019-11-06 08:55:10,730 train 200 1.775890e-02 -0.729166
2019-11-06 08:55:20,894 train 250 1.778869e-02 -0.714867
2019-11-06 08:55:31,081 train 300 1.777236e-02 -0.682178
2019-11-06 08:55:41,243 train 350 1.779152e-02 -0.685789
2019-11-06 08:55:51,418 train 400 1.779967e-02 -0.691647
2019-11-06 08:56:01,564 train 450 1.777945e-02 -0.688596
2019-11-06 08:56:11,731 train 500 1.777189e-02 -0.702420
2019-11-06 08:56:21,870 train 550 1.777212e-02 -0.694694
2019-11-06 08:56:32,043 train 600 1.781674e-02 -0.738443
2019-11-06 08:56:42,201 train 650 1.775530e-02 -0.713584
2019-11-06 08:56:52,397 train 700 1.774037e-02 -0.698910
2019-11-06 08:57:02,571 train 750 1.772729e-02 -0.710470
2019-11-06 08:57:12,759 train 800 1.769883e-02 -0.703184
2019-11-06 08:57:22,928 train 850 1.769581e-02 -0.715015
2019-11-06 08:57:25,967 training loss; R2: 1.769723e-02 -0.710715
2019-11-06 08:57:26,529 valid 000 2.728524e-02 -2.595588
2019-11-06 08:57:36,304 valid 050 2.848287e-02 -1.750558
2019-11-06 08:57:44,929 validation loss; R2: 2.798648e-02 -1.749585
2019-11-06 08:57:44,997 epoch 427 lr 1.000000e-04
2019-11-06 08:57:45,692 train 000 1.805210e-02 -5.440053
2019-11-06 08:57:55,907 train 050 1.781705e-02 -0.838203
2019-11-06 08:58:06,080 train 100 1.767074e-02 -0.705077
2019-11-06 08:58:16,250 train 150 1.762829e-02 -0.731557
2019-11-06 08:58:26,414 train 200 1.771700e-02 -0.825373
2019-11-06 08:58:36,601 train 250 1.769269e-02 -0.807532
2019-11-06 08:58:46,729 train 300 1.774417e-02 -1.035470
2019-11-06 08:58:56,868 train 350 1.772178e-02 -0.961991
2019-11-06 08:59:07,004 train 400 1.773106e-02 -0.897118
2019-11-06 08:59:17,155 train 450 1.768521e-02 -0.869270
2019-11-06 08:59:27,302 train 500 1.767766e-02 -0.833898
2019-11-06 08:59:37,415 train 550 1.764267e-02 -0.813500
2019-11-06 08:59:47,531 train 600 1.761520e-02 -0.799508
2019-11-06 08:59:57,651 train 650 1.759150e-02 -0.776429
2019-11-06 09:00:07,785 train 700 1.756304e-02 -0.763006
2019-11-06 09:00:17,900 train 750 1.754746e-02 -0.745030
2019-11-06 09:00:28,035 train 800 1.752872e-02 -0.723434
2019-11-06 09:00:38,154 train 850 1.751090e-02 -0.727796
2019-11-06 09:00:41,198 training loss; R2: 1.750620e-02 -0.737569
2019-11-06 09:00:41,768 valid 000 1.647528e-02 -0.368454
2019-11-06 09:00:51,585 valid 050 1.406908e-02 -1.246688
2019-11-06 09:01:00,275 validation loss; R2: 1.411409e-02 -0.932551
2019-11-06 09:01:00,344 epoch 428 lr 1.000000e-04
2019-11-06 09:01:01,051 train 000 1.660771e-02 0.073705
2019-11-06 09:01:11,257 train 050 1.801881e-02 -0.472512
2019-11-06 09:01:21,467 train 100 1.801678e-02 -0.445242
2019-11-06 09:01:31,634 train 150 1.774301e-02 -0.541026
2019-11-06 09:01:41,810 train 200 1.758126e-02 -0.566981
2019-11-06 09:01:51,977 train 250 1.773752e-02 -0.575260
2019-11-06 09:02:02,136 train 300 1.779657e-02 -0.582592
2019-11-06 09:02:12,294 train 350 1.784133e-02 -0.589300
2019-11-06 09:02:22,457 train 400 1.784441e-02 -0.569060
2019-11-06 09:02:32,633 train 450 1.783758e-02 -0.566027
2019-11-06 09:02:42,816 train 500 1.784005e-02 -0.585272
2019-11-06 09:02:52,974 train 550 1.781430e-02 -0.576597
2019-11-06 09:03:03,135 train 600 1.782301e-02 -0.736511
2019-11-06 09:03:13,304 train 650 1.783824e-02 -0.732767
2019-11-06 09:03:23,471 train 700 1.786284e-02 -0.749414
2019-11-06 09:03:33,600 train 750 1.784324e-02 -0.732353
2019-11-06 09:03:43,752 train 800 1.784738e-02 -0.724184
2019-11-06 09:03:53,897 train 850 1.783241e-02 -0.708009
2019-11-06 09:03:56,929 training loss; R2: 1.782633e-02 -0.706379
2019-11-06 09:03:57,531 valid 000 1.654418e-02 -2.463917
2019-11-06 09:04:07,296 valid 050 1.839898e-02 -1.094489
2019-11-06 09:04:15,931 validation loss; R2: 1.837936e-02 -1.297970
2019-11-06 09:04:15,995 epoch 429 lr 1.000000e-04
2019-11-06 09:04:16,728 train 000 1.915148e-02 -0.054604
2019-11-06 09:04:26,919 train 050 1.837256e-02 -1.213800
2019-11-06 09:04:37,114 train 100 1.803132e-02 -0.807868
2019-11-06 09:04:47,310 train 150 1.785082e-02 -0.724018
2019-11-06 09:04:57,488 train 200 1.788683e-02 -0.739564
2019-11-06 09:05:07,677 train 250 1.781980e-02 -0.764643
2019-11-06 09:05:17,874 train 300 1.778319e-02 -0.758263
2019-11-06 09:05:28,061 train 350 1.777228e-02 -0.743765
2019-11-06 09:05:38,261 train 400 1.771336e-02 -0.720415
2019-11-06 09:05:48,413 train 450 1.769653e-02 -0.701439
2019-11-06 09:05:58,585 train 500 1.771109e-02 -0.674930
2019-11-06 09:06:08,744 train 550 1.768849e-02 -0.664708
2019-11-06 09:06:18,908 train 600 1.767611e-02 -0.669400
2019-11-06 09:06:29,053 train 650 1.766656e-02 -0.655916
2019-11-06 09:06:39,238 train 700 1.765601e-02 -0.659269
2019-11-06 09:06:49,401 train 750 1.765868e-02 -0.673002
2019-11-06 09:06:59,562 train 800 1.766411e-02 -0.673837
2019-11-06 09:07:09,718 train 850 1.768907e-02 -0.666792
2019-11-06 09:07:12,763 training loss; R2: 1.768767e-02 -0.674703
2019-11-06 09:07:13,286 valid 000 2.294271e-02 -0.115014
2019-11-06 09:07:23,118 valid 050 2.209228e-02 -0.552174
2019-11-06 09:07:31,807 validation loss; R2: 2.221689e-02 -0.525982
2019-11-06 09:07:31,872 epoch 430 lr 1.000000e-04
2019-11-06 09:07:32,545 train 000 1.727326e-02 0.072249
2019-11-06 09:07:42,802 train 050 1.792474e-02 -0.482934
2019-11-06 09:07:53,007 train 100 1.786631e-02 -0.525603
2019-11-06 09:08:03,186 train 150 1.773319e-02 -0.607825
2019-11-06 09:08:13,371 train 200 1.769152e-02 -1.090926
2019-11-06 09:08:23,553 train 250 1.769679e-02 -1.010485
2019-11-06 09:08:33,733 train 300 1.779258e-02 -0.963833
2019-11-06 09:08:43,904 train 350 1.778739e-02 -0.919493
2019-11-06 09:08:54,076 train 400 1.775844e-02 -0.879026
2019-11-06 09:09:04,238 train 450 1.775992e-02 -0.843245
2019-11-06 09:09:14,406 train 500 1.776217e-02 -0.823178
2019-11-06 09:09:24,590 train 550 1.774580e-02 -0.822411
2019-11-06 09:09:34,770 train 600 1.772021e-02 -0.826418
2019-11-06 09:09:44,951 train 650 1.770364e-02 -0.810914
2019-11-06 09:09:55,145 train 700 1.768657e-02 -0.789329
2019-11-06 09:10:05,329 train 750 1.767596e-02 -0.782108
2019-11-06 09:10:15,510 train 800 1.768817e-02 -0.770926
2019-11-06 09:10:25,693 train 850 1.767042e-02 -0.760115
2019-11-06 09:10:28,732 training loss; R2: 1.766035e-02 -0.756722
2019-11-06 09:10:29,313 valid 000 1.512495e-02 -0.066201
2019-11-06 09:10:39,089 valid 050 1.329646e-02 -1.345381
2019-11-06 09:10:47,763 validation loss; R2: 1.324025e-02 -0.997836
2019-11-06 09:10:47,834 epoch 431 lr 1.000000e-04
2019-11-06 09:10:48,516 train 000 1.514855e-02 -0.258768
2019-11-06 09:10:58,783 train 050 1.771863e-02 -0.563869
2019-11-06 09:11:08,963 train 100 1.737732e-02 -0.619509
2019-11-06 09:11:19,152 train 150 1.747566e-02 -0.604649
2019-11-06 09:11:29,335 train 200 1.748042e-02 -0.568572
2019-11-06 09:11:39,519 train 250 1.745867e-02 -0.570862
2019-11-06 09:11:49,702 train 300 1.755271e-02 -0.627105
2019-11-06 09:11:59,835 train 350 1.757590e-02 -0.625319
2019-11-06 09:12:09,998 train 400 1.765505e-02 -0.629842
2019-11-06 09:12:20,158 train 450 1.767308e-02 -0.652307
2019-11-06 09:12:30,325 train 500 1.763725e-02 -0.669381
2019-11-06 09:12:40,463 train 550 1.760177e-02 -0.653082
2019-11-06 09:12:50,632 train 600 1.759927e-02 -0.660826
2019-11-06 09:13:00,747 train 650 1.759094e-02 -0.644528
2019-11-06 09:13:10,901 train 700 1.757123e-02 -0.645237
2019-11-06 09:13:21,040 train 750 1.755973e-02 -0.637136
2019-11-06 09:13:31,223 train 800 1.756021e-02 -0.631657
2019-11-06 09:13:41,388 train 850 1.755386e-02 -1.074857
2019-11-06 09:13:44,418 training loss; R2: 1.754992e-02 -1.064895
2019-11-06 09:13:44,931 valid 000 1.340093e-02 -0.190056
2019-11-06 09:13:54,729 valid 050 1.348371e-02 -0.774551
2019-11-06 09:14:03,397 validation loss; R2: 1.355935e-02 -0.736556
2019-11-06 09:14:03,464 epoch 432 lr 1.000000e-04
2019-11-06 09:14:04,195 train 000 1.606394e-02 -2.793398
2019-11-06 09:14:14,403 train 050 1.728988e-02 -0.889175
2019-11-06 09:14:24,589 train 100 1.719892e-02 -0.848682
2019-11-06 09:14:34,766 train 150 1.732022e-02 -0.711237
2019-11-06 09:14:44,930 train 200 1.746936e-02 -0.679461
2019-11-06 09:14:55,077 train 250 1.748533e-02 -0.719754
2019-11-06 09:15:05,243 train 300 1.756234e-02 -0.694010
2019-11-06 09:15:15,400 train 350 1.748691e-02 -0.654891
2019-11-06 09:15:25,535 train 400 1.744104e-02 -0.670062
2019-11-06 09:15:35,700 train 450 1.742002e-02 -0.687566
2019-11-06 09:15:45,878 train 500 1.742144e-02 -0.831343
2019-11-06 09:15:56,056 train 550 1.743765e-02 -0.822878
2019-11-06 09:16:06,243 train 600 1.745228e-02 -0.797790
2019-11-06 09:16:16,574 train 650 1.746576e-02 -0.783688
2019-11-06 09:16:26,835 train 700 1.745543e-02 -0.783166
2019-11-06 09:16:37,172 train 750 1.743665e-02 -0.866710
2019-11-06 09:16:47,436 train 800 1.743856e-02 -0.855352
2019-11-06 09:16:57,687 train 850 1.745562e-02 -0.866664
2019-11-06 09:17:00,750 training loss; R2: 1.746579e-02 -0.861253
2019-11-06 09:17:01,265 valid 000 1.485450e-02 0.071298
2019-11-06 09:17:11,278 valid 050 1.410585e-02 -0.650924
2019-11-06 09:17:20,067 validation loss; R2: 1.394375e-02 -0.916034
2019-11-06 09:17:20,132 epoch 433 lr 1.000000e-04
2019-11-06 09:17:20,824 train 000 1.621961e-02 -0.150753
2019-11-06 09:17:30,972 train 050 1.773761e-02 -0.789571
2019-11-06 09:17:41,193 train 100 1.786214e-02 -0.671653
2019-11-06 09:17:51,247 train 150 1.761977e-02 -0.610498
2019-11-06 09:18:01,515 train 200 1.763250e-02 -0.585884
2019-11-06 09:18:11,743 train 250 1.767473e-02 -0.586375
2019-11-06 09:18:21,926 train 300 1.767062e-02 -0.604917
2019-11-06 09:18:32,031 train 350 1.768136e-02 -0.575998
2019-11-06 09:18:42,443 train 400 1.776341e-02 -0.583609
2019-11-06 09:18:52,936 train 450 1.779212e-02 -0.580472
2019-11-06 09:19:03,078 train 500 1.775992e-02 -0.583543
2019-11-06 09:19:13,275 train 550 1.772794e-02 -0.569117
2019-11-06 09:19:23,434 train 600 1.772328e-02 -0.571186
2019-11-06 09:19:33,614 train 650 1.770599e-02 -0.594268
2019-11-06 09:19:43,778 train 700 1.767403e-02 -0.636505
2019-11-06 09:19:53,951 train 750 1.767567e-02 -0.630030
2019-11-06 09:20:04,106 train 800 1.766894e-02 -0.664791
2019-11-06 09:20:14,265 train 850 1.766154e-02 -0.666256
2019-11-06 09:20:17,293 training loss; R2: 1.765713e-02 -0.660714
2019-11-06 09:20:17,845 valid 000 1.273837e-02 0.044130
2019-11-06 09:20:27,574 valid 050 1.543801e-02 -1.117680
2019-11-06 09:20:36,205 validation loss; R2: 1.519514e-02 -1.064080
2019-11-06 09:20:36,271 epoch 434 lr 1.000000e-04
2019-11-06 09:20:37,019 train 000 1.779675e-02 -1.155651
2019-11-06 09:20:47,067 train 050 1.733425e-02 -0.604012
2019-11-06 09:20:57,286 train 100 1.762771e-02 -0.534939
2019-11-06 09:21:07,316 train 150 1.778568e-02 -0.528813
2019-11-06 09:21:17,464 train 200 1.779623e-02 -0.589869
2019-11-06 09:21:27,522 train 250 1.776683e-02 -0.553593
2019-11-06 09:21:37,612 train 300 1.768860e-02 -0.561223
2019-11-06 09:21:47,709 train 350 1.770125e-02 -0.596356
2019-11-06 09:21:57,754 train 400 1.775677e-02 -0.606533
2019-11-06 09:22:07,892 train 450 1.774018e-02 -0.610943
2019-11-06 09:22:17,965 train 500 1.773147e-02 -0.605480
2019-11-06 09:22:28,047 train 550 1.770086e-02 -0.606459
2019-11-06 09:22:38,210 train 600 1.762980e-02 -0.610067
2019-11-06 09:22:48,254 train 650 1.762905e-02 -0.604516
2019-11-06 09:22:58,351 train 700 1.765279e-02 -0.604707
2019-11-06 09:23:08,524 train 750 1.763051e-02 -0.611784
2019-11-06 09:23:18,561 train 800 1.762473e-02 -0.613335
2019-11-06 09:23:28,659 train 850 1.762408e-02 -0.626851
2019-11-06 09:23:31,683 training loss; R2: 1.762905e-02 -0.621614
2019-11-06 09:23:32,211 valid 000 1.226068e-02 -1.432966
2019-11-06 09:23:41,974 valid 050 1.330652e-02 -0.744603
2019-11-06 09:23:50,603 validation loss; R2: 1.334509e-02 -0.766339
2019-11-06 09:23:50,668 epoch 435 lr 1.000000e-04
2019-11-06 09:23:51,409 train 000 1.475813e-02 -1.928769
2019-11-06 09:24:01,535 train 050 1.761319e-02 -0.674544
2019-11-06 09:24:11,728 train 100 1.772952e-02 -0.547443
2019-11-06 09:24:21,889 train 150 1.770225e-02 -0.575119
2019-11-06 09:24:32,037 train 200 1.764477e-02 -0.599695
2019-11-06 09:24:42,172 train 250 1.765254e-02 -0.646132
2019-11-06 09:24:52,255 train 300 1.764959e-02 -0.633736
2019-11-06 09:25:02,342 train 350 1.770532e-02 -0.628092
2019-11-06 09:25:12,490 train 400 1.765427e-02 -0.599545
