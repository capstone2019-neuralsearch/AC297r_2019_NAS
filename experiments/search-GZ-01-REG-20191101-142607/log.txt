2019-11-01 14:26:08,019 gpu device = 1
2019-11-01 14:26:08,019 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=20, cutout=False, cutout_length=16, data='../data', dataset='galaxy-zoo', drop_path_prob=0.3, epochs=50, gpu=1, grad_clip=5, init_channels=16, layers=8, learning_rate=0.001, learning_rate_min=0.0001, model_path='saved_models', momentum=0.9, report_freq=50, save='search-GALAXY_ZOO-20191101-142607', seed=2, train_portion=0.5, unrolled=True, weight_decay=0.0003)
2019-11-01 14:26:11,548 param size = 1.937557MB
2019-11-01 14:26:11,559 epoch 0 lr 1.000000e-03
2019-11-01 14:26:11,560 genotype = Genotype(normal=[('dil_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('max_pool_3x3', 0), ('dil_conv_3x3', 0), ('avg_pool_3x3', 2), ('sep_conv_5x5', 3), ('dil_conv_3x3', 2)], normal_concat=range(2, 6), reduce=[('avg_pool_3x3', 1), ('max_pool_3x3', 0), ('dil_conv_3x3', 1), ('sep_conv_5x5', 2), ('max_pool_3x3', 1), ('dil_conv_3x3', 0), ('dil_conv_3x3', 3), ('dil_conv_5x5', 4)], reduce_concat=range(2, 6))
2019-11-01 14:26:11,563 
alphas_normal = Variable containing:
 0.1251  0.1250  0.1249  0.1249  0.1251  0.1251  0.1250  0.1248
 0.1250  0.1248  0.1250  0.1249  0.1250  0.1251  0.1250  0.1252
 0.1248  0.1252  0.1248  0.1251  0.1251  0.1251  0.1250  0.1249
 0.1248  0.1250  0.1248  0.1249  0.1252  0.1253  0.1250  0.1250
 0.1252  0.1250  0.1250  0.1249  0.1251  0.1249  0.1249  0.1250
 0.1250  0.1250  0.1248  0.1250  0.1251  0.1250  0.1253  0.1249
 0.1251  0.1248  0.1250  0.1251  0.1250  0.1250  0.1252  0.1248
 0.1249  0.1250  0.1252  0.1252  0.1251  0.1248  0.1249  0.1251
 0.1250  0.1252  0.1250  0.1251  0.1249  0.1249  0.1249  0.1250
 0.1250  0.1250  0.1251  0.1250  0.1250  0.1249  0.1250  0.1249
 0.1251  0.1251  0.1251  0.1250  0.1248  0.1250  0.1249  0.1251
 0.1251  0.1252  0.1249  0.1249  0.1250  0.1249  0.1252  0.1249
 0.1249  0.1250  0.1250  0.1251  0.1250  0.1253  0.1248  0.1249
 0.1251  0.1250  0.1248  0.1250  0.1251  0.1249  0.1250  0.1251
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 14:26:11,564 
alphas_reduce = Variable containing:
 0.1250  0.1252  0.1249  0.1249  0.1250  0.1251  0.1249  0.1250
 0.1250  0.1249  0.1252  0.1251  0.1249  0.1249  0.1251  0.1250
 0.1252  0.1251  0.1249  0.1250  0.1251  0.1249  0.1249  0.1249
 0.1250  0.1249  0.1250  0.1249  0.1250  0.1249  0.1252  0.1250
 0.1249  0.1250  0.1250  0.1250  0.1248  0.1252  0.1252  0.1250
 0.1251  0.1247  0.1249  0.1250  0.1251  0.1250  0.1252  0.1250
 0.1249  0.1253  0.1248  0.1249  0.1250  0.1250  0.1251  0.1250
 0.1249  0.1250  0.1249  0.1249  0.1250  0.1252  0.1252  0.1250
 0.1251  0.1250  0.1249  0.1250  0.1252  0.1249  0.1251  0.1248
 0.1252  0.1250  0.1249  0.1249  0.1250  0.1250  0.1249  0.1250
 0.1250  0.1250  0.1250  0.1249  0.1251  0.1249  0.1250  0.1251
 0.1251  0.1249  0.1250  0.1250  0.1249  0.1250  0.1252  0.1250
 0.1250  0.1249  0.1249  0.1249  0.1251  0.1249  0.1252  0.1251
 0.1252  0.1250  0.1249  0.1250  0.1247  0.1249  0.1250  0.1252
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 14:26:20,707 train 000 1.244066e-01 -44.198577
2019-11-01 14:29:03,976 train 050 1.005091e-01 -35.105318
2019-11-01 14:31:38,431 train 100 8.985247e-02 -31.935040
2019-11-01 14:34:12,804 train 150 8.317525e-02 -28.447715
2019-11-01 14:36:47,463 train 200 7.918120e-02 -23.792900
2019-11-01 14:39:21,699 train 250 7.641551e-02 -20.789606
2019-11-01 14:41:56,509 train 300 7.380358e-02 -18.417822
2019-11-01 14:44:31,000 train 350 7.165513e-02 -17.367883
2019-11-01 14:47:05,848 train 400 6.967322e-02 -16.063501
2019-11-01 14:49:40,285 train 450 6.780873e-02 -15.080884
2019-11-01 14:52:14,466 train 500 6.621300e-02 -14.120675
2019-11-01 14:54:48,373 train 550 6.470163e-02 -13.359333
2019-11-01 14:57:22,135 train 600 6.325302e-02 -12.677843
2019-11-01 15:00:01,679 train 650 6.195617e-02 -12.014709
2019-11-01 15:02:49,329 train 700 6.076331e-02 -11.707241
2019-11-01 15:05:36,815 train 750 5.953951e-02 -11.248444
2019-11-01 15:08:24,529 train 800 5.840428e-02 -10.746571
2019-11-01 15:11:02,853 train 850 5.735664e-02 -10.437528
2019-11-01 15:13:41,636 train 900 5.638935e-02 -10.079299
2019-11-01 15:16:17,265 train 950 5.545184e-02 -9.774027
2019-11-01 15:18:51,115 train 1000 5.459014e-02 -9.461131
2019-11-01 15:21:24,662 train 1050 5.367925e-02 -9.219751
2019-11-01 15:23:58,248 train 1100 5.282451e-02 -8.926376
2019-11-01 15:26:31,910 train 1150 5.199212e-02 -8.686178
2019-11-01 15:29:06,368 train 1200 5.122298e-02 -8.637359
2019-11-01 15:31:40,301 train 1250 5.044253e-02 -8.663916
2019-11-01 15:34:14,490 train 1300 4.970976e-02 -8.416851
2019-11-01 15:36:49,160 train 1350 4.905953e-02 -8.195913
2019-11-01 15:39:24,221 train 1400 4.842427e-02 -8.034257
2019-11-01 15:41:58,856 train 1450 4.777808e-02 -7.847629
2019-11-01 15:44:33,777 train 1500 4.710214e-02 -7.697838
2019-11-01 15:46:39,392 train_acc (R^2 for regression) -7.691779
2019-11-01 15:46:39,862 valid 000 2.681868e-02 -4.408828
2019-11-01 15:46:47,619 valid 050 2.809317e-02 -2.586600
2019-11-01 15:46:55,310 valid 100 2.782019e-02 -2.660145
2019-11-01 15:47:02,997 valid 150 2.795213e-02 -2.695981
2019-11-01 15:47:10,704 valid 200 2.782568e-02 -2.594205
2019-11-01 15:47:18,405 valid 250 2.784972e-02 -2.574395
2019-11-01 15:47:26,098 valid 300 2.795876e-02 -16.513250
2019-11-01 15:47:33,835 valid 350 2.800432e-02 -14.758866
2019-11-01 15:47:41,549 valid 400 2.791587e-02 -13.227500
2019-11-01 15:47:49,185 valid 450 2.784293e-02 -12.193058
2019-11-01 15:47:58,644 valid 500 2.786229e-02 -11.240037
2019-11-01 15:48:08,082 valid 550 2.790870e-02 -10.410409
2019-11-01 15:48:17,527 valid 600 2.784755e-02 -9.763088
2019-11-01 15:48:26,960 valid 650 2.792275e-02 -9.565471
2019-11-01 15:48:36,387 valid 700 2.808014e-02 -9.124447
2019-11-01 15:48:45,810 valid 750 2.806815e-02 -8.704743
2019-11-01 15:48:55,223 valid 800 2.814686e-02 -8.334837
2019-11-01 15:49:04,694 valid 850 2.815840e-02 -8.019386
2019-11-01 15:49:14,171 valid 900 2.815877e-02 -7.724842
2019-11-01 15:49:23,646 valid 950 2.816782e-02 -7.541756
2019-11-01 15:49:33,101 valid 1000 2.815027e-02 -7.711141
2019-11-01 15:49:42,638 valid 1050 2.814470e-02 -7.540386
2019-11-01 15:49:52,149 valid 1100 2.812241e-02 -7.412460
2019-11-01 15:50:01,678 valid 1150 2.815058e-02 -7.416632
2019-11-01 15:50:09,661 valid 1200 2.808605e-02 -7.191723
2019-11-01 15:50:17,342 valid 1250 2.808890e-02 -7.371003
2019-11-01 15:50:25,023 valid 1300 2.809398e-02 -7.433102
2019-11-01 15:50:32,775 valid 1350 2.808188e-02 -7.255491
2019-11-01 15:50:40,493 valid 1400 2.806412e-02 -7.318855
2019-11-01 15:50:48,213 valid 1450 2.808740e-02 -7.167689
2019-11-01 15:50:55,941 valid 1500 2.807797e-02 -7.019082
2019-11-01 15:51:01,944 valid_acc (R^2 for regression) -6.939911
2019-11-01 15:51:02,060 epoch 1 lr 9.991120e-04
2019-11-01 15:51:02,061 genotype = Genotype(normal=[('sep_conv_5x5', 0), ('dil_conv_5x5', 1), ('dil_conv_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('dil_conv_5x5', 4), ('sep_conv_5x5', 3)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('dil_conv_5x5', 1), ('dil_conv_3x3', 2), ('dil_conv_5x5', 3), ('sep_conv_3x3', 0), ('sep_conv_5x5', 4), ('dil_conv_3x3', 2)], reduce_concat=range(2, 6))
2019-11-01 15:51:02,062 
alphas_normal = Variable containing:
 0.1267  0.1165  0.1211  0.1237  0.1254  0.1326  0.1252  0.1287
 0.1276  0.1153  0.1195  0.1225  0.1287  0.1281  0.1273  0.1311
 0.1269  0.1174  0.1191  0.1222  0.1269  0.1264  0.1334  0.1277
 0.1262  0.1194  0.1210  0.1231  0.1260  0.1331  0.1236  0.1275
 0.1289  0.1164  0.1179  0.1233  0.1313  0.1309  0.1247  0.1266
 0.1257  0.1182  0.1226  0.1246  0.1262  0.1307  0.1271  0.1249
 0.1264  0.1189  0.1233  0.1248  0.1248  0.1313  0.1271  0.1236
 0.1277  0.1176  0.1209  0.1258  0.1276  0.1293  0.1241  0.1270
 0.1271  0.1160  0.1190  0.1219  0.1303  0.1289  0.1275  0.1294
 0.1281  0.1176  0.1218  0.1243  0.1251  0.1311  0.1270  0.1250
 0.1313  0.1172  0.1202  0.1216  0.1306  0.1268  0.1264  0.1258
 0.1292  0.1141  0.1157  0.1218  0.1294  0.1316  0.1285  0.1296
 0.1294  0.1135  0.1147  0.1179  0.1307  0.1342  0.1296  0.1299
 0.1319  0.1138  0.1150  0.1162  0.1303  0.1301  0.1285  0.1343
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 15:51:02,064 
alphas_reduce = Variable containing:
 0.1256  0.1219  0.1239  0.1209  0.1257  0.1334  0.1241  0.1244
 0.1250  0.1203  0.1214  0.1203  0.1292  0.1271  0.1278  0.1289
 0.1248  0.1234  0.1252  0.1232  0.1264  0.1268  0.1240  0.1262
 0.1237  0.1226  0.1241  0.1236  0.1242  0.1280  0.1252  0.1286
 0.1255  0.1214  0.1242  0.1257  0.1241  0.1269  0.1275  0.1247
 0.1252  0.1231  0.1235  0.1243  0.1274  0.1254  0.1250  0.1261
 0.1230  0.1270  0.1263  0.1244  0.1256  0.1243  0.1242  0.1251
 0.1251  0.1217  0.1236  0.1254  0.1263  0.1269  0.1240  0.1269
 0.1252  0.1205  0.1228  0.1244  0.1243  0.1269  0.1252  0.1307
 0.1240  0.1243  0.1260  0.1238  0.1273  0.1236  0.1261  0.1250
 0.1255  0.1219  0.1220  0.1259  0.1254  0.1271  0.1254  0.1266
 0.1263  0.1199  0.1221  0.1250  0.1253  0.1266  0.1279  0.1269
 0.1264  0.1209  0.1231  0.1254  0.1259  0.1268  0.1254  0.1261
 0.1245  0.1200  0.1216  0.1237  0.1257  0.1299  0.1264  0.1281
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 15:51:05,413 train 000 3.191048e-02 -1.456819
2019-11-01 15:53:41,584 train 050 2.828650e-02 -18.858388
2019-11-01 15:56:14,721 train 100 2.779484e-02 -10.816639
2019-11-01 15:58:47,390 train 150 2.732426e-02 -7.932114
2019-11-01 16:01:20,273 train 200 2.716838e-02 -15.876043
2019-11-01 16:04:01,084 train 250 2.687538e-02 -13.195078
2019-11-01 16:06:42,076 train 300 2.665843e-02 -11.462003
2019-11-01 16:09:14,461 train 350 2.643261e-02 -10.065369
2019-11-01 16:11:48,809 train 400 2.628918e-02 -9.021834
2019-11-01 16:14:23,307 train 450 2.596546e-02 -8.263022
2019-11-01 16:17:03,858 train 500 2.565844e-02 -7.624320
2019-11-01 16:19:44,992 train 550 2.545498e-02 -7.083941
2019-11-01 16:22:22,431 train 600 2.528598e-02 -6.750132
2019-11-01 16:24:57,401 train 650 2.509927e-02 -6.347929
2019-11-01 16:27:29,420 train 700 2.494433e-02 -6.068285
2019-11-01 16:30:01,086 train 750 2.476974e-02 -5.785970
2019-11-01 16:32:34,435 train 800 2.461364e-02 -5.514087
2019-11-01 16:35:10,181 train 850 2.440899e-02 -5.297304
2019-11-01 16:37:45,622 train 900 2.429714e-02 -5.159542
2019-11-01 16:40:20,725 train 950 2.412900e-02 -4.956820
2019-11-01 16:42:55,539 train 1000 2.397868e-02 -5.135493
2019-11-01 16:45:30,223 train 1050 2.382732e-02 -4.969614
2019-11-01 16:48:04,966 train 1100 2.369556e-02 -4.821408
2019-11-01 16:50:39,842 train 1150 2.356223e-02 -4.724473
2019-11-01 16:53:14,420 train 1200 2.342620e-02 -4.607093
2019-11-01 16:55:48,821 train 1250 2.329398e-02 -4.490715
2019-11-01 16:58:23,423 train 1300 2.321034e-02 -4.389233
2019-11-01 17:01:03,996 train 1350 2.307865e-02 -4.276652
2019-11-01 17:03:41,705 train 1400 2.297223e-02 -4.205540
2019-11-01 17:06:16,026 train 1450 2.286928e-02 -4.243225
2019-11-01 17:08:50,397 train 1500 2.272765e-02 -4.160450
2019-11-01 17:10:56,359 train_acc (R^2 for regression) -4.090877
2019-11-01 17:10:56,878 valid 000 1.838920e-02 -4.761455
2019-11-01 17:11:06,124 valid 050 1.896468e-02 -1.263974
2019-11-01 17:11:14,218 valid 100 1.871756e-02 -1.258099
2019-11-01 17:11:22,240 valid 150 1.869524e-02 -1.447014
2019-11-01 17:11:30,246 valid 200 1.852366e-02 -1.429743
2019-11-01 17:11:38,320 valid 250 1.852240e-02 -1.494945
2019-11-01 17:11:46,436 valid 300 1.859205e-02 -1.569289
2019-11-01 17:11:54,502 valid 350 1.853934e-02 -1.501329
2019-11-01 17:12:02,522 valid 400 1.852409e-02 -1.568909
2019-11-01 17:12:10,523 valid 450 1.861022e-02 -2.928078
2019-11-01 17:12:18,455 valid 500 1.867642e-02 -2.791717
2019-11-01 17:12:26,303 valid 550 1.869026e-02 -2.665887
2019-11-01 17:12:34,150 valid 600 1.867297e-02 -2.524857
2019-11-01 17:12:42,073 valid 650 1.866878e-02 -2.416770
2019-11-01 17:12:49,907 valid 700 1.864382e-02 -2.392711
2019-11-01 17:12:57,719 valid 750 1.865416e-02 -2.343327
2019-11-01 17:13:05,553 valid 800 1.862138e-02 -2.324728
2019-11-01 17:13:13,420 valid 850 1.863341e-02 -2.293823
2019-11-01 17:13:21,259 valid 900 1.856819e-02 -2.216029
2019-11-01 17:13:29,102 valid 950 1.859639e-02 -2.197911
2019-11-01 17:13:36,951 valid 1000 1.858752e-02 -2.148390
2019-11-01 17:13:44,822 valid 1050 1.860834e-02 -2.159388
2019-11-01 17:13:52,643 valid 1100 1.861457e-02 -2.148164
2019-11-01 17:14:00,517 valid 1150 1.863558e-02 -2.291361
2019-11-01 17:14:08,348 valid 1200 1.863641e-02 -2.298488
2019-11-01 17:14:16,196 valid 1250 1.863533e-02 -2.384182
2019-11-01 17:14:24,076 valid 1300 1.863036e-02 -2.353781
2019-11-01 17:14:31,985 valid 1350 1.862781e-02 -2.325713
2019-11-01 17:14:39,888 valid 1400 1.861745e-02 -2.291040
2019-11-01 17:14:47,767 valid 1450 1.862901e-02 -2.337491
2019-11-01 17:14:55,659 valid 1500 1.865373e-02 -2.323573
2019-11-01 17:15:01,776 valid_acc (R^2 for regression) -2.998708
2019-11-01 17:15:01,904 epoch 2 lr 9.964516e-04
2019-11-01 17:15:01,905 genotype = Genotype(normal=[('sep_conv_5x5', 0), ('dil_conv_3x3', 1), ('dil_conv_3x3', 0), ('sep_conv_5x5', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 3), ('sep_conv_5x5', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('dil_conv_5x5', 3), ('sep_conv_5x5', 2), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2)], reduce_concat=range(2, 6))
2019-11-01 17:15:01,907 
alphas_normal = Variable containing:
 0.1263  0.1177  0.1205  0.1229  0.1240  0.1328  0.1255  0.1302
 0.1272  0.1176  0.1185  0.1221  0.1291  0.1294  0.1294  0.1267
 0.1267  0.1199  0.1203  0.1231  0.1275  0.1235  0.1324  0.1266
 0.1252  0.1220  0.1217  0.1232  0.1269  0.1310  0.1220  0.1281
 0.1263  0.1184  0.1181  0.1229  0.1322  0.1323  0.1257  0.1242
 0.1238  0.1212  0.1254  0.1266  0.1257  0.1282  0.1246  0.1245
 0.1267  0.1187  0.1227  0.1236  0.1248  0.1324  0.1264  0.1247
 0.1262  0.1200  0.1233  0.1263  0.1269  0.1296  0.1227  0.1249
 0.1251  0.1174  0.1207  0.1230  0.1285  0.1289  0.1283  0.1281
 0.1274  0.1193  0.1215  0.1236  0.1259  0.1327  0.1245  0.1251
 0.1288  0.1195  0.1207  0.1221  0.1287  0.1267  0.1275  0.1259
 0.1280  0.1148  0.1155  0.1217  0.1291  0.1339  0.1292  0.1278
 0.1274  0.1153  0.1156  0.1191  0.1304  0.1362  0.1293  0.1268
 0.1293  0.1155  0.1166  0.1172  0.1296  0.1289  0.1311  0.1318
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 17:15:01,908 
alphas_reduce = Variable containing:
 0.1242  0.1208  0.1218  0.1218  0.1256  0.1341  0.1251  0.1266
 0.1258  0.1197  0.1196  0.1190  0.1319  0.1267  0.1271  0.1302
 0.1250  0.1215  0.1225  0.1255  0.1251  0.1289  0.1246  0.1268
 0.1242  0.1227  0.1239  0.1231  0.1248  0.1299  0.1233  0.1280
 0.1251  0.1232  0.1230  0.1251  0.1233  0.1270  0.1266  0.1266
 0.1253  0.1246  0.1239  0.1253  0.1260  0.1259  0.1253  0.1237
 0.1246  0.1259  0.1245  0.1248  0.1240  0.1254  0.1245  0.1264
 0.1250  0.1245  0.1242  0.1256  0.1244  0.1270  0.1244  0.1249
 0.1247  0.1249  0.1243  0.1246  0.1228  0.1271  0.1243  0.1273
 0.1247  0.1241  0.1246  0.1239  0.1271  0.1246  0.1265  0.1245
 0.1258  0.1222  0.1214  0.1258  0.1254  0.1281  0.1253  0.1260
 0.1253  0.1228  0.1218  0.1244  0.1242  0.1273  0.1264  0.1279
 0.1257  0.1248  0.1246  0.1254  0.1238  0.1271  0.1254  0.1233
 0.1246  0.1233  0.1229  0.1239  0.1256  0.1272  0.1265  0.1259
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 17:15:05,278 train 000 2.286615e-02 -0.161434
2019-11-01 17:17:43,077 train 050 1.925554e-02 -1.408488
2019-11-01 17:20:19,852 train 100 1.910857e-02 -19.582764
2019-11-01 17:22:56,228 train 150 1.925103e-02 -16.224599
2019-11-01 17:25:34,958 train 200 1.946821e-02 -13.487539
2019-11-01 17:28:11,256 train 250 1.942166e-02 -11.052097
2019-11-01 17:30:45,110 train 300 1.920442e-02 -9.390018
2019-11-01 17:33:19,247 train 350 1.914561e-02 -15.446159
2019-11-01 17:35:53,368 train 400 1.911884e-02 -13.782895
2019-11-01 17:38:29,665 train 450 1.893953e-02 -12.450017
2019-11-01 17:41:06,932 train 500 1.884277e-02 -11.586234
2019-11-01 17:43:43,908 train 550 1.872778e-02 -10.663666
2019-11-01 17:46:21,544 train 600 1.860339e-02 -9.857671
2019-11-01 17:48:57,329 train 650 1.855934e-02 -9.170728
2019-11-01 17:51:32,914 train 700 1.845396e-02 -8.610339
2019-11-01 17:54:08,116 train 750 1.837180e-02 -8.104100
2019-11-01 17:56:41,558 train 800 1.836630e-02 -7.710182
2019-11-01 17:59:17,147 train 850 1.833706e-02 -7.325718
2019-11-01 18:01:52,508 train 900 1.831383e-02 -6.972652
2019-11-01 18:04:28,225 train 950 1.825558e-02 -6.893350
2019-11-01 18:07:03,269 train 1000 1.821824e-02 -6.773749
2019-11-01 18:09:38,968 train 1050 1.816570e-02 -6.532813
2019-11-01 18:12:14,703 train 1100 1.812975e-02 -6.307763
2019-11-01 18:14:50,915 train 1150 1.808521e-02 -6.103793
2019-11-01 18:17:26,993 train 1200 1.806398e-02 -6.524035
2019-11-01 18:20:02,485 train 1250 1.805690e-02 -6.303824
2019-11-01 18:22:38,595 train 1300 1.805373e-02 -6.096957
2019-11-01 18:25:14,906 train 1350 1.804125e-02 -5.911746
2019-11-01 18:27:48,376 train 1400 1.801354e-02 -5.931757
2019-11-01 18:30:22,761 train 1450 1.797918e-02 -5.772830
2019-11-01 18:32:59,341 train 1500 1.795783e-02 -5.612541
2019-11-01 18:35:01,488 train_acc (R^2 for regression) -5.500213
2019-11-01 18:35:01,979 valid 000 2.315555e-02 -1.630527
2019-11-01 18:35:10,198 valid 050 1.702173e-02 -1.560386
2019-11-01 18:35:18,386 valid 100 1.708768e-02 -1.376637
2019-11-01 18:35:26,627 valid 150 1.684806e-02 -2.314821
2019-11-01 18:35:34,820 valid 200 1.695647e-02 -1.942909
2019-11-01 18:35:43,050 valid 250 1.704815e-02 -2.274199
2019-11-01 18:35:51,238 valid 300 1.726176e-02 -6.500235
2019-11-01 18:35:59,474 valid 350 1.723486e-02 -5.962994
2019-11-01 18:36:07,712 valid 400 1.716405e-02 -11.958260
2019-11-01 18:36:15,943 valid 450 1.716850e-02 -12.223488
2019-11-01 18:36:24,359 valid 500 1.711820e-02 -11.119578
2019-11-01 18:36:32,754 valid 550 1.708796e-02 -10.257734
2019-11-01 18:36:41,240 valid 600 1.704922e-02 -9.551768
2019-11-01 18:36:50,922 valid 650 1.700722e-02 -8.911005
2019-11-01 18:37:01,029 valid 700 1.705964e-02 -8.375558
2019-11-01 18:37:11,113 valid 750 1.709942e-02 -7.918178
2019-11-01 18:37:21,142 valid 800 1.705624e-02 -7.525937
2019-11-01 18:37:31,204 valid 850 1.708243e-02 -7.174426
2019-11-01 18:37:41,248 valid 900 1.711131e-02 -6.847014
2019-11-01 18:37:51,319 valid 950 1.711526e-02 -6.611654
2019-11-01 18:38:01,142 valid 1000 1.710551e-02 -6.335794
2019-11-01 18:38:10,901 valid 1050 1.713402e-02 -6.105663
2019-11-01 18:38:20,592 valid 1100 1.714727e-02 -5.901259
2019-11-01 18:38:30,300 valid 1150 1.713740e-02 -5.707979
2019-11-01 18:38:40,008 valid 1200 1.713962e-02 -5.550025
2019-11-01 18:38:48,428 valid 1250 1.713613e-02 -5.390393
2019-11-01 18:38:56,353 valid 1300 1.716596e-02 -5.243438
2019-11-01 18:39:04,245 valid 1350 1.718806e-02 -5.101250
2019-11-01 18:39:12,125 valid 1400 1.716925e-02 -4.964095
2019-11-01 18:39:20,024 valid 1450 1.716798e-02 -4.854731
2019-11-01 18:39:27,890 valid 1500 1.717302e-02 -4.741581
2019-11-01 18:39:34,014 valid_acc (R^2 for regression) -4.663527
2019-11-01 18:39:34,142 epoch 3 lr 9.920293e-04
2019-11-01 18:39:34,144 genotype = Genotype(normal=[('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_3x3', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 3), ('sep_conv_5x5', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('sep_conv_5x5', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 0), ('dil_conv_5x5', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2)], reduce_concat=range(2, 6))
2019-11-01 18:39:34,146 
alphas_normal = Variable containing:
 0.1264  0.1197  0.1212  0.1229  0.1227  0.1310  0.1254  0.1307
 0.1252  0.1200  0.1198  0.1230  0.1289  0.1303  0.1292  0.1237
 0.1272  0.1216  0.1213  0.1238  0.1286  0.1236  0.1290  0.1250
 0.1239  0.1230  0.1220  0.1233  0.1261  0.1292  0.1249  0.1276
 0.1259  0.1209  0.1197  0.1235  0.1309  0.1291  0.1258  0.1242
 0.1240  0.1212  0.1247  0.1252  0.1270  0.1282  0.1240  0.1256
 0.1249  0.1197  0.1231  0.1238  0.1261  0.1339  0.1256  0.1230
 0.1253  0.1213  0.1238  0.1256  0.1248  0.1297  0.1234  0.1260
 0.1244  0.1197  0.1224  0.1236  0.1274  0.1279  0.1276  0.1270
 0.1267  0.1204  0.1218  0.1237  0.1278  0.1311  0.1245  0.1241
 0.1284  0.1196  0.1197  0.1211  0.1292  0.1278  0.1283  0.1260
 0.1273  0.1171  0.1175  0.1230  0.1261  0.1321  0.1283  0.1286
 0.1270  0.1166  0.1164  0.1192  0.1297  0.1358  0.1295  0.1257
 0.1276  0.1168  0.1177  0.1181  0.1300  0.1295  0.1317  0.1287
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 18:39:34,147 
alphas_reduce = Variable containing:
 0.1241  0.1215  0.1214  0.1244  0.1295  0.1296  0.1244  0.1251
 0.1264  0.1212  0.1205  0.1195  0.1316  0.1277  0.1239  0.1292
 0.1255  0.1223  0.1222  0.1262  0.1244  0.1278  0.1250  0.1265
 0.1243  0.1237  0.1245  0.1247  0.1236  0.1276  0.1256  0.1259
 0.1248  0.1231  0.1225  0.1246  0.1248  0.1261  0.1284  0.1257
 0.1252  0.1244  0.1234  0.1248  0.1256  0.1275  0.1245  0.1246
 0.1237  0.1257  0.1243  0.1244  0.1256  0.1250  0.1243  0.1268
 0.1249  0.1246  0.1231  0.1245  0.1242  0.1275  0.1232  0.1279
 0.1252  0.1257  0.1242  0.1247  0.1236  0.1265  0.1233  0.1268
 0.1258  0.1233  0.1235  0.1266  0.1247  0.1263  0.1253  0.1244
 0.1247  0.1223  0.1218  0.1270  0.1245  0.1285  0.1253  0.1259
 0.1260  0.1240  0.1224  0.1242  0.1243  0.1257  0.1254  0.1281
 0.1252  0.1249  0.1232  0.1236  0.1250  0.1271  0.1268  0.1241
 0.1247  0.1241  0.1230  0.1236  0.1258  0.1268  0.1261  0.1260
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 18:39:37,535 train 000 1.541144e-02 -0.582969
2019-11-01 18:42:13,366 train 050 1.636847e-02 -1.128541
2019-11-01 18:45:01,258 train 100 1.695130e-02 -1.166567
2019-11-01 18:47:51,196 train 150 1.701185e-02 -15.761372
2019-11-01 18:50:29,633 train 200 1.683134e-02 -12.441431
2019-11-01 18:53:08,151 train 250 1.689026e-02 -10.184397
2019-11-01 18:55:46,559 train 300 1.682304e-02 -8.710947
2019-11-01 18:58:25,536 train 350 1.688358e-02 -7.643881
2019-11-01 19:01:09,907 train 400 1.679310e-02 -8.187671
2019-11-01 19:04:07,013 train 450 1.675982e-02 -7.436305
2019-11-01 19:07:01,285 train 500 1.683961e-02 -7.261914
2019-11-01 19:09:41,987 train 550 1.676648e-02 -6.830375
2019-11-01 19:12:21,661 train 600 1.673750e-02 -6.542418
2019-11-01 19:15:02,724 train 650 1.671522e-02 -6.188292
2019-11-01 19:17:44,318 train 700 1.671441e-02 -5.855583
2019-11-01 19:20:23,059 train 750 1.671184e-02 -5.530914
2019-11-01 19:23:02,460 train 800 1.670265e-02 -5.562862
2019-11-01 19:25:43,224 train 850 1.666873e-02 -5.285422
2019-11-01 19:28:22,690 train 900 1.663365e-02 -5.050091
2019-11-01 19:31:00,944 train 950 1.660962e-02 -4.826605
2019-11-01 19:33:40,738 train 1000 1.659651e-02 -4.629434
2019-11-01 19:36:20,197 train 1050 1.657539e-02 -4.531465
2019-11-01 19:39:04,351 train 1100 1.656211e-02 -4.369497
2019-11-01 19:41:46,959 train 1150 1.655883e-02 -4.271673
2019-11-01 19:44:28,574 train 1200 1.654476e-02 -4.136934
2019-11-01 19:47:11,631 train 1250 1.656035e-02 -4.013717
2019-11-01 19:49:53,655 train 1300 1.654331e-02 -3.885730
2019-11-01 19:52:34,271 train 1350 1.653438e-02 -3.767146
2019-11-01 19:55:17,265 train 1400 1.653840e-02 -3.678196
2019-11-01 19:58:01,915 train 1450 1.654929e-02 -3.591057
2019-11-01 20:00:47,860 train 1500 1.656064e-02 -3.534479
2019-11-01 20:02:54,076 train_acc (R^2 for regression) -3.461391
2019-11-01 20:02:54,538 valid 000 1.629000e-02 -0.953883
2019-11-01 20:03:03,015 valid 050 1.582491e-02 -0.688518
2019-11-01 20:03:11,489 valid 100 1.601285e-02 -1.212224
2019-11-01 20:03:19,941 valid 150 1.594302e-02 -1.120108
2019-11-01 20:03:28,827 valid 200 1.620444e-02 -32.810258
2019-11-01 20:03:37,033 valid 250 1.639835e-02 -26.427859
2019-11-01 20:03:45,239 valid 300 1.645354e-02 -22.182075
2019-11-01 20:03:53,419 valid 350 1.645667e-02 -19.160292
2019-11-01 20:04:01,560 valid 400 1.651610e-02 -17.023726
2019-11-01 20:04:09,768 valid 450 1.647535e-02 -15.386731
2019-11-01 20:04:17,956 valid 500 1.646055e-02 -13.988462
2019-11-01 20:04:26,133 valid 550 1.647003e-02 -12.844229
2019-11-01 20:04:34,237 valid 600 1.644363e-02 -11.861878
2019-11-01 20:04:42,302 valid 650 1.645354e-02 -11.032696
2019-11-01 20:04:50,320 valid 700 1.651451e-02 -10.322946
2019-11-01 20:04:58,319 valid 750 1.649364e-02 -9.721345
2019-11-01 20:05:06,333 valid 800 1.655338e-02 -9.239188
2019-11-01 20:05:14,333 valid 850 1.652943e-02 -9.065459
2019-11-01 20:05:22,354 valid 900 1.656986e-02 -8.654537
2019-11-01 20:05:30,320 valid 950 1.654028e-02 -8.256014
2019-11-01 20:05:38,338 valid 1000 1.652406e-02 -7.896847
2019-11-01 20:05:46,305 valid 1050 1.654791e-02 -7.549786
2019-11-01 20:05:54,299 valid 1100 1.652801e-02 -7.274967
2019-11-01 20:06:02,296 valid 1150 1.650068e-02 -7.211361
2019-11-01 20:06:10,259 valid 1200 1.651159e-02 -6.963500
2019-11-01 20:06:18,259 valid 1250 1.652151e-02 -6.726971
2019-11-01 20:06:26,232 valid 1300 1.651365e-02 -6.595619
2019-11-01 20:06:34,211 valid 1350 1.650003e-02 -6.410433
2019-11-01 20:06:42,267 valid 1400 1.652441e-02 -6.238105
2019-11-01 20:06:50,313 valid 1450 1.651033e-02 -6.061114
2019-11-01 20:06:58,387 valid 1500 1.649356e-02 -5.889793
2019-11-01 20:07:04,633 valid_acc (R^2 for regression) -5.769453
2019-11-01 20:07:04,817 epoch 4 lr 9.858624e-04
2019-11-01 20:07:04,817 genotype = Genotype(normal=[('sep_conv_5x5', 0), ('dil_conv_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 3), ('sep_conv_3x3', 1)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('dil_conv_5x5', 1), ('sep_conv_5x5', 2), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2)], reduce_concat=range(2, 6))
2019-11-01 20:07:04,819 
alphas_normal = Variable containing:
 0.1251  0.1209  0.1227  0.1235  0.1219  0.1317  0.1243  0.1299
 0.1273  0.1201  0.1192  0.1220  0.1268  0.1297  0.1303  0.1247
 0.1257  0.1237  0.1227  0.1237  0.1279  0.1247  0.1266  0.1249
 0.1255  0.1232  0.1228  0.1243  0.1239  0.1268  0.1260  0.1276
 0.1258  0.1230  0.1215  0.1239  0.1276  0.1275  0.1271  0.1236
 0.1231  0.1218  0.1249  0.1247  0.1270  0.1286  0.1240  0.1259
 0.1253  0.1215  0.1243  0.1245  0.1248  0.1297  0.1257  0.1242
 0.1256  0.1230  0.1244  0.1258  0.1252  0.1274  0.1226  0.1260
 0.1242  0.1221  0.1235  0.1242  0.1270  0.1263  0.1259  0.1268
 0.1254  0.1218  0.1232  0.1245  0.1273  0.1281  0.1239  0.1257
 0.1275  0.1207  0.1208  0.1215  0.1300  0.1281  0.1274  0.1240
 0.1257  0.1189  0.1193  0.1229  0.1271  0.1296  0.1291  0.1273
 0.1268  0.1198  0.1193  0.1218  0.1275  0.1312  0.1282  0.1255
 0.1263  0.1201  0.1204  0.1202  0.1277  0.1297  0.1294  0.1262
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 20:07:04,820 
alphas_reduce = Variable containing:
 0.1245  0.1221  0.1223  0.1258  0.1279  0.1287  0.1236  0.1252
 0.1247  0.1217  0.1209  0.1207  0.1328  0.1281  0.1243  0.1267
 0.1244  0.1226  0.1230  0.1235  0.1238  0.1293  0.1274  0.1260
 0.1240  0.1239  0.1244  0.1252  0.1235  0.1282  0.1260  0.1248
 0.1249  0.1244  0.1242  0.1253  0.1237  0.1257  0.1261  0.1256
 0.1256  0.1238  0.1238  0.1231  0.1253  0.1278  0.1255  0.1252
 0.1247  0.1254  0.1247  0.1246  0.1246  0.1236  0.1242  0.1282
 0.1246  0.1241  0.1238  0.1250  0.1235  0.1279  0.1240  0.1270
 0.1251  0.1257  0.1255  0.1258  0.1221  0.1244  0.1239  0.1276
 0.1264  0.1237  0.1238  0.1256  0.1248  0.1263  0.1250  0.1244
 0.1254  0.1238  0.1238  0.1247  0.1242  0.1288  0.1251  0.1242
 0.1255  0.1228  0.1226  0.1243  0.1237  0.1262  0.1270  0.1278
 0.1258  0.1238  0.1236  0.1242  0.1251  0.1269  0.1276  0.1231
 0.1255  0.1238  0.1233  0.1236  0.1246  0.1248  0.1273  0.1270
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 20:07:08,170 train 000 1.538081e-02 -1.067559
2019-11-01 20:09:49,475 train 050 1.607282e-02 -1.067616
2019-11-01 20:12:31,358 train 100 1.594697e-02 -4.949708
2019-11-01 20:15:14,576 train 150 1.591493e-02 -3.614822
2019-11-01 20:17:57,629 train 200 1.578669e-02 -2.933992
2019-11-01 20:20:39,944 train 250 1.579597e-02 -3.053820
2019-11-01 20:23:21,969 train 300 1.578119e-02 -2.691928
2019-11-01 20:26:03,448 train 350 1.573398e-02 -3.018797
2019-11-01 20:28:46,165 train 400 1.565759e-02 -2.716082
2019-11-01 20:31:27,937 train 450 1.566477e-02 -2.501648
2019-11-01 20:34:08,864 train 500 1.570284e-02 -6.012551
2019-11-01 20:36:50,780 train 550 1.570702e-02 -5.634131
2019-11-01 20:39:32,301 train 600 1.565430e-02 -5.237391
2019-11-01 20:42:14,025 train 650 1.569970e-02 -5.830488
2019-11-01 20:44:55,791 train 700 1.565046e-02 -6.109356
2019-11-01 20:47:38,255 train 750 1.569788e-02 -5.809175
2019-11-01 20:50:20,472 train 800 1.572384e-02 -5.505839
2019-11-01 20:53:00,815 train 850 1.572163e-02 -5.228079
2019-11-01 20:55:42,880 train 900 1.579454e-02 -5.003051
2019-11-01 20:58:26,178 train 950 1.579035e-02 -5.060075
2019-11-01 21:01:08,210 train 1000 1.579102e-02 -5.944411
2019-11-01 21:03:49,134 train 1050 1.578838e-02 -5.806918
2019-11-01 21:06:30,872 train 1100 1.580695e-02 -5.874542
2019-11-01 21:09:12,981 train 1150 1.579338e-02 -5.642061
2019-11-01 21:11:54,754 train 1200 1.580048e-02 -5.444081
2019-11-01 21:14:37,389 train 1250 1.580855e-02 -5.259689
2019-11-01 21:17:17,563 train 1300 1.582470e-02 -5.080613
2019-11-01 21:19:57,719 train 1350 1.580619e-02 -4.942080
2019-11-01 21:22:39,320 train 1400 1.582706e-02 -4.785180
2019-11-01 21:25:20,492 train 1450 1.583332e-02 -4.659075
2019-11-01 21:28:03,502 train 1500 1.582425e-02 -6.011518
2019-11-01 21:30:13,462 train_acc (R^2 for regression) -5.880300
2019-11-01 21:30:13,980 valid 000 1.688335e-02 -1.886542
2019-11-01 21:30:22,307 valid 050 1.654056e-02 -1.073066
2019-11-01 21:30:30,613 valid 100 1.635752e-02 -0.950986
2019-11-01 21:30:38,924 valid 150 1.636070e-02 -2.076496
2019-11-01 21:30:47,220 valid 200 1.643557e-02 -1.931695
2019-11-01 21:30:55,524 valid 250 1.631705e-02 -2.171166
2019-11-01 21:31:03,777 valid 300 1.626377e-02 -1.960257
2019-11-01 21:31:12,085 valid 350 1.627032e-02 -1.811108
2019-11-01 21:31:20,425 valid 400 1.626699e-02 -2.070094
2019-11-01 21:31:28,815 valid 450 1.633988e-02 -2.311781
2019-11-01 21:31:37,277 valid 500 1.631088e-02 -2.241369
2019-11-01 21:31:45,517 valid 550 1.635900e-02 -2.115160
2019-11-01 21:31:53,864 valid 600 1.634960e-02 -2.113085
2019-11-01 21:32:02,187 valid 650 1.630684e-02 -2.024188
2019-11-01 21:32:10,606 valid 700 1.633087e-02 -1.938179
2019-11-01 21:32:18,970 valid 750 1.628735e-02 -1.882868
2019-11-01 21:32:27,299 valid 800 1.629928e-02 -1.848575
2019-11-01 21:32:35,708 valid 850 1.632703e-02 -1.799843
2019-11-01 21:32:44,148 valid 900 1.631391e-02 -1.763771
2019-11-01 21:32:52,705 valid 950 1.627743e-02 -1.788524
2019-11-01 21:33:01,244 valid 1000 1.628197e-02 -1.781688
2019-11-01 21:33:09,847 valid 1050 1.629674e-02 -1.743599
2019-11-01 21:33:18,359 valid 1100 1.629426e-02 -1.693373
2019-11-01 21:33:26,948 valid 1150 1.627406e-02 -1.663861
2019-11-01 21:33:35,489 valid 1200 1.628131e-02 -1.646764
2019-11-01 21:33:44,029 valid 1250 1.626473e-02 -1.699124
2019-11-01 21:33:52,545 valid 1300 1.624791e-02 -1.669564
2019-11-01 21:34:01,010 valid 1350 1.623251e-02 -1.684436
2019-11-01 21:34:09,490 valid 1400 1.624542e-02 -1.660593
2019-11-01 21:34:17,989 valid 1450 1.624220e-02 -1.960358
2019-11-01 21:34:26,502 valid 1500 1.625484e-02 -1.923337
2019-11-01 21:34:33,107 valid_acc (R^2 for regression) -1.899978
2019-11-01 21:34:33,244 epoch 5 lr 9.779754e-04
2019-11-01 21:34:33,245 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_3x3', 2), ('sep_conv_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 3), ('sep_conv_5x5', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 0), ('dil_conv_5x5', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2)], reduce_concat=range(2, 6))
2019-11-01 21:34:33,247 
alphas_normal = Variable containing:
 0.1251  0.1218  0.1233  0.1245  0.1223  0.1296  0.1250  0.1284
 0.1258  0.1212  0.1205  0.1225  0.1248  0.1310  0.1299  0.1242
 0.1252  0.1241  0.1240  0.1246  0.1286  0.1246  0.1250  0.1239
 0.1251  0.1229  0.1218  0.1228  0.1258  0.1279  0.1255  0.1283
 0.1252  0.1246  0.1223  0.1246  0.1301  0.1263  0.1243  0.1226
 0.1236  0.1235  0.1248  0.1248  0.1259  0.1283  0.1229  0.1261
 0.1251  0.1218  0.1229  0.1232  0.1271  0.1298  0.1256  0.1244
 0.1248  0.1242  0.1248  0.1258  0.1248  0.1274  0.1237  0.1246
 0.1245  0.1237  0.1246  0.1248  0.1264  0.1262  0.1250  0.1249
 0.1271  0.1219  0.1231  0.1243  0.1270  0.1278  0.1246  0.1242
 0.1280  0.1206  0.1201  0.1211  0.1285  0.1282  0.1289  0.1245
 0.1259  0.1196  0.1193  0.1230  0.1282  0.1295  0.1259  0.1286
 0.1268  0.1194  0.1186  0.1203  0.1294  0.1313  0.1280  0.1262
 0.1263  0.1201  0.1199  0.1199  0.1294  0.1299  0.1285  0.1261
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 21:34:33,248 
alphas_reduce = Variable containing:
 0.1245  0.1232  0.1227  0.1260  0.1277  0.1272  0.1244  0.1243
 0.1261  0.1243  0.1228  0.1205  0.1295  0.1267  0.1230  0.1271
 0.1258  0.1233  0.1232  0.1246  0.1246  0.1277  0.1246  0.1261
 0.1252  0.1229  0.1237  0.1244  0.1242  0.1277  0.1261  0.1259
 0.1251  0.1235  0.1225  0.1241  0.1259  0.1251  0.1297  0.1240
 0.1253  0.1246  0.1236  0.1260  0.1236  0.1269  0.1251  0.1248
 0.1241  0.1258  0.1249  0.1242  0.1260  0.1241  0.1246  0.1263
 0.1242  0.1253  0.1236  0.1242  0.1236  0.1279  0.1229  0.1284
 0.1248  0.1266  0.1252  0.1251  0.1225  0.1261  0.1240  0.1257
 0.1257  0.1239  0.1237  0.1260  0.1247  0.1265  0.1252  0.1244
 0.1254  0.1238  0.1228  0.1238  0.1224  0.1287  0.1273  0.1259
 0.1250  0.1248  0.1232  0.1246  0.1241  0.1263  0.1254  0.1266
 0.1246  0.1256  0.1242  0.1242  0.1255  0.1260  0.1263  0.1236
 0.1238  0.1263  0.1242  0.1244  0.1253  0.1253  0.1257  0.1250
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 21:34:36,811 train 000 1.386852e-02 -0.205394
2019-11-01 21:37:18,554 train 050 1.584389e-02 -0.529062
2019-11-01 21:40:04,817 train 100 1.588675e-02 -0.596949
2019-11-01 21:42:48,712 train 150 1.570423e-02 -0.667451
2019-11-01 21:45:33,271 train 200 1.551518e-02 -1.140839
2019-11-01 21:48:17,044 train 250 1.563460e-02 -1.064431
2019-11-01 21:50:59,857 train 300 1.552050e-02 -1.078271
2019-11-01 21:53:39,634 train 350 1.558723e-02 -1.070144
2019-11-01 21:56:19,052 train 400 1.561264e-02 -1.053495
2019-11-01 21:58:56,514 train 450 1.563483e-02 -1.265173
2019-11-01 22:01:33,961 train 500 1.563308e-02 -1.603114
2019-11-01 22:04:11,283 train 550 1.561352e-02 -1.526014
2019-11-01 22:06:49,010 train 600 1.554596e-02 -1.514888
2019-11-01 22:09:33,052 train 650 1.553381e-02 -1.551345
2019-11-01 22:12:15,261 train 700 1.556361e-02 -1.487547
2019-11-01 22:15:00,227 train 750 1.555781e-02 -1.476047
2019-11-01 22:17:44,987 train 800 1.554770e-02 -1.516267
2019-11-01 22:20:28,222 train 850 1.552486e-02 -1.468080
2019-11-01 22:23:10,906 train 900 1.553915e-02 -1.424323
2019-11-01 22:25:55,141 train 950 1.547885e-02 -1.966774
2019-11-01 22:28:38,425 train 1000 1.545373e-02 -1.894916
2019-11-01 22:31:22,895 train 1050 1.543668e-02 -1.841214
2019-11-01 22:34:06,671 train 1100 1.545551e-02 -1.795391
2019-11-01 22:36:49,606 train 1150 1.543216e-02 -2.409555
2019-11-01 22:39:32,927 train 1200 1.542857e-02 -2.376740
2019-11-01 22:42:16,860 train 1250 1.544843e-02 -2.325435
2019-11-01 22:44:59,841 train 1300 1.542721e-02 -2.383678
2019-11-01 22:47:42,212 train 1350 1.541093e-02 -2.317805
2019-11-01 22:50:24,753 train 1400 1.539204e-02 -2.362962
2019-11-01 22:53:06,831 train 1450 1.540728e-02 -2.310107
2019-11-01 22:55:49,614 train 1500 1.539579e-02 -2.303643
2019-11-01 22:57:56,917 train_acc (R^2 for regression) -2.271510
2019-11-01 22:57:57,418 valid 000 1.805997e-02 -0.288409
2019-11-01 22:58:05,956 valid 050 1.512417e-02 -0.618325
2019-11-01 22:58:14,488 valid 100 1.506705e-02 -0.712439
2019-11-01 22:58:23,002 valid 150 1.530070e-02 -0.828551
2019-11-01 22:58:31,523 valid 200 1.525169e-02 -0.953351
2019-11-01 22:58:40,050 valid 250 1.515136e-02 -0.994272
2019-11-01 22:58:48,653 valid 300 1.521461e-02 -9.195530
2019-11-01 22:58:57,204 valid 350 1.524468e-02 -8.192624
2019-11-01 22:59:05,768 valid 400 1.518283e-02 -7.250017
2019-11-01 22:59:14,331 valid 450 1.512159e-02 -6.523467
2019-11-01 22:59:22,922 valid 500 1.509281e-02 -5.920302
2019-11-01 22:59:31,454 valid 550 1.512700e-02 -5.495594
2019-11-01 22:59:39,992 valid 600 1.514216e-02 -5.106867
2019-11-01 22:59:48,498 valid 650 1.512225e-02 -4.812805
2019-11-01 22:59:57,026 valid 700 1.509282e-02 -4.543989
2019-11-01 23:00:05,611 valid 750 1.508055e-02 -4.337679
2019-11-01 23:00:14,147 valid 800 1.509179e-02 -4.139560
2019-11-01 23:00:22,717 valid 850 1.508884e-02 -3.942399
2019-11-01 23:00:31,221 valid 900 1.506663e-02 -3.766378
2019-11-01 23:00:39,755 valid 950 1.502979e-02 -3.701894
2019-11-01 23:00:48,275 valid 1000 1.505577e-02 -3.570955
2019-11-01 23:00:56,844 valid 1050 1.508580e-02 -3.473918
2019-11-01 23:01:05,360 valid 1100 1.507798e-02 -3.358492
2019-11-01 23:01:13,885 valid 1150 1.507499e-02 -3.261977
2019-11-01 23:01:22,437 valid 1200 1.512050e-02 -3.176838
2019-11-01 23:01:31,018 valid 1250 1.514942e-02 -3.111131
2019-11-01 23:01:39,559 valid 1300 1.514853e-02 -3.021345
2019-11-01 23:01:48,074 valid 1350 1.515007e-02 -2.981998
2019-11-01 23:01:56,620 valid 1400 1.512101e-02 -2.913280
2019-11-01 23:02:05,073 valid 1450 1.509883e-02 -2.922638
2019-11-01 23:02:13,573 valid 1500 1.510837e-02 -2.844151
2019-11-01 23:02:20,195 valid_acc (R^2 for regression) -2.795212
2019-11-01 23:02:20,325 epoch 6 lr 9.683994e-04
2019-11-01 23:02:20,326 genotype = Genotype(normal=[('dil_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_3x3', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 3), ('sep_conv_3x3', 1)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_5x5', 0), ('dil_conv_3x3', 2), ('dil_conv_5x5', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('dil_conv_3x3', 3)], reduce_concat=range(2, 6))
2019-11-01 23:02:20,328 
alphas_normal = Variable containing:
 0.1259  0.1225  0.1232  0.1238  0.1209  0.1291  0.1238  0.1309
 0.1255  0.1213  0.1207  0.1228  0.1266  0.1303  0.1291  0.1236
 0.1265  0.1243  0.1230  0.1236  0.1302  0.1232  0.1240  0.1251
 0.1246  0.1245  0.1241  0.1244  0.1231  0.1272  0.1261  0.1261
 0.1250  0.1249  0.1223  0.1240  0.1289  0.1268  0.1239  0.1242
 0.1227  0.1240  0.1254  0.1249  0.1259  0.1280  0.1221  0.1271
 0.1250  0.1226  0.1241  0.1241  0.1260  0.1291  0.1257  0.1234
 0.1248  0.1249  0.1249  0.1256  0.1236  0.1262  0.1239  0.1261
 0.1238  0.1243  0.1249  0.1245  0.1279  0.1248  0.1253  0.1246
 0.1263  0.1221  0.1231  0.1242  0.1276  0.1275  0.1240  0.1253
 0.1266  0.1203  0.1204  0.1214  0.1303  0.1284  0.1276  0.1251
 0.1264  0.1200  0.1198  0.1232  0.1266  0.1298  0.1261  0.1282
 0.1272  0.1202  0.1195  0.1213  0.1260  0.1319  0.1295  0.1244
 0.1259  0.1210  0.1210  0.1209  0.1275  0.1302  0.1279  0.1256
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 23:02:20,330 
alphas_reduce = Variable containing:
 0.1237  0.1227  0.1222  0.1286  0.1299  0.1259  0.1232  0.1237
 0.1268  0.1225  0.1210  0.1193  0.1325  0.1300  0.1219  0.1261
 0.1245  0.1237  0.1230  0.1251  0.1241  0.1290  0.1253  0.1252
 0.1245  0.1232  0.1233  0.1258  0.1250  0.1279  0.1262  0.1241
 0.1249  0.1250  0.1240  0.1249  0.1236  0.1253  0.1281  0.1241
 0.1246  0.1243  0.1236  0.1256  0.1248  0.1270  0.1259  0.1241
 0.1248  0.1254  0.1240  0.1252  0.1261  0.1239  0.1241  0.1265
 0.1246  0.1247  0.1231  0.1242  0.1238  0.1273  0.1241  0.1281
 0.1248  0.1269  0.1258  0.1254  0.1225  0.1249  0.1238  0.1259
 0.1262  0.1238  0.1234  0.1262  0.1243  0.1267  0.1256  0.1238
 0.1252  0.1238  0.1230  0.1245  0.1236  0.1291  0.1265  0.1245
 0.1256  0.1233  0.1224  0.1241  0.1245  0.1264  0.1262  0.1274
 0.1252  0.1249  0.1233  0.1238  0.1263  0.1259  0.1278  0.1227
 0.1250  0.1253  0.1237  0.1235  0.1259  0.1239  0.1261  0.1265
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-01 23:02:23,861 train 000 1.464472e-02 -0.287856
2019-11-01 23:05:07,192 train 050 1.511606e-02 -0.740706
2019-11-01 23:07:49,691 train 100 1.512013e-02 -0.933037
2019-11-01 23:10:32,236 train 150 1.502861e-02 -3.023076
2019-11-01 23:13:15,589 train 200 1.510343e-02 -4.007708
2019-11-01 23:15:58,862 train 250 1.519611e-02 -3.354609
2019-11-01 23:18:41,898 train 300 1.518623e-02 -2.896565
2019-11-01 23:21:25,539 train 350 1.512750e-02 -2.620717
2019-11-01 23:24:08,570 train 400 1.520907e-02 -4.691869
2019-11-01 23:26:52,228 train 450 1.525947e-02 -8.010995
2019-11-01 23:29:34,800 train 500 1.527431e-02 -7.373291
2019-11-01 23:32:20,372 train 550 1.523689e-02 -6.783709
2019-11-01 23:35:04,973 train 600 1.520054e-02 -6.602736
2019-11-01 23:37:49,115 train 650 1.522987e-02 -6.184849
2019-11-01 23:40:33,058 train 700 1.519833e-02 -5.842361
2019-11-01 23:43:16,378 train 750 1.521195e-02 -5.565581
2019-11-01 23:46:00,397 train 800 1.516021e-02 -5.267418
2019-11-01 23:48:42,693 train 850 1.516772e-02 -4.978522
2019-11-01 23:51:26,517 train 900 1.515274e-02 -4.763737
2019-11-01 23:54:09,753 train 950 1.515171e-02 -4.557671
2019-11-01 23:56:54,408 train 1000 1.516198e-02 -4.374752
2019-11-01 23:59:38,986 train 1050 1.517018e-02 -4.469042
2019-11-02 00:02:22,186 train 1100 1.515077e-02 -4.298645
2019-11-02 00:05:06,571 train 1150 1.514066e-02 -4.150231
2019-11-02 00:07:50,149 train 1200 1.512469e-02 -4.032328
2019-11-02 00:10:34,458 train 1250 1.509266e-02 -3.897960
2019-11-02 00:13:17,950 train 1300 1.507991e-02 -3.778552
2019-11-02 00:16:01,732 train 1350 1.507570e-02 -3.667456
2019-11-02 00:18:44,965 train 1400 1.509292e-02 -3.760285
2019-11-02 00:21:28,263 train 1450 1.508472e-02 -3.655169
2019-11-02 00:24:11,609 train 1500 1.510652e-02 -3.546704
2019-11-02 00:26:19,359 train_acc (R^2 for regression) -3.483446
2019-11-02 00:26:19,838 valid 000 1.341980e-02 -2.133464
2019-11-02 00:26:28,382 valid 050 1.462847e-02 -1.394329
2019-11-02 00:26:36,899 valid 100 1.426206e-02 -0.976744
2019-11-02 00:26:45,483 valid 150 1.414618e-02 -4.536155
2019-11-02 00:26:54,039 valid 200 1.413461e-02 -3.622230
2019-11-02 00:27:02,621 valid 250 1.421664e-02 -3.117352
2019-11-02 00:27:11,145 valid 300 1.423841e-02 -3.695621
2019-11-02 00:27:19,672 valid 350 1.428276e-02 -3.304942
2019-11-02 00:27:28,189 valid 400 1.428357e-02 -3.037644
2019-11-02 00:27:36,798 valid 450 1.431706e-02 -2.751953
2019-11-02 00:27:45,343 valid 500 1.433611e-02 -2.755819
2019-11-02 00:27:53,891 valid 550 1.432941e-02 -4.328328
2019-11-02 00:28:02,441 valid 600 1.436582e-02 -4.054987
2019-11-02 00:28:10,972 valid 650 1.435677e-02 -3.856130
2019-11-02 00:28:19,517 valid 700 1.435356e-02 -3.662043
2019-11-02 00:28:28,049 valid 750 1.432842e-02 -3.467431
2019-11-02 00:28:36,567 valid 800 1.435773e-02 -3.318160
2019-11-02 00:28:45,140 valid 850 1.432989e-02 -3.162197
2019-11-02 00:28:53,697 valid 900 1.433755e-02 -3.054222
2019-11-02 00:29:02,247 valid 950 1.436805e-02 -2.952312
2019-11-02 00:29:10,785 valid 1000 1.436425e-02 -2.953590
2019-11-02 00:29:19,360 valid 1050 1.440112e-02 -2.844123
2019-11-02 00:29:27,882 valid 1100 1.440878e-02 -2.836887
2019-11-02 00:29:36,415 valid 1150 1.440267e-02 -2.741959
2019-11-02 00:29:44,954 valid 1200 1.438397e-02 -2.664631
2019-11-02 00:29:53,478 valid 1250 1.439551e-02 -2.587114
2019-11-02 00:30:02,010 valid 1300 1.439227e-02 -2.513863
2019-11-02 00:30:10,578 valid 1350 1.438324e-02 -2.451125
2019-11-02 00:30:19,151 valid 1400 1.439314e-02 -2.383629
2019-11-02 00:30:27,688 valid 1450 1.439124e-02 -2.327327
2019-11-02 00:30:36,223 valid 1500 1.440121e-02 -2.266581
2019-11-02 00:30:42,887 valid_acc (R^2 for regression) -2.226127
2019-11-02 00:30:43,023 epoch 7 lr 9.571722e-04
2019-11-02 00:30:43,024 genotype = Genotype(normal=[('dil_conv_3x3', 1), ('dil_conv_5x5', 0), ('sep_conv_3x3', 2), ('sep_conv_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('sep_conv_5x5', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('dil_conv_3x3', 3)], reduce_concat=range(2, 6))
2019-11-02 00:30:43,026 
alphas_normal = Variable containing:
 0.1256  0.1241  0.1249  0.1250  0.1208  0.1273  0.1231  0.1292
 0.1254  0.1220  0.1206  0.1225  0.1266  0.1303  0.1306  0.1221
 0.1259  0.1248  0.1243  0.1246  0.1284  0.1236  0.1229  0.1256
 0.1242  0.1246  0.1239  0.1244  0.1249  0.1266  0.1247  0.1268
 0.1247  0.1241  0.1218  0.1236  0.1289  0.1278  0.1255  0.1236
 0.1228  0.1240  0.1255  0.1248  0.1240  0.1287  0.1230  0.1272
 0.1260  0.1226  0.1235  0.1240  0.1254  0.1293  0.1248  0.1245
 0.1246  0.1245  0.1243  0.1251  0.1261  0.1268  0.1234  0.1251
 0.1245  0.1243  0.1246  0.1248  0.1270  0.1262  0.1251  0.1236
 0.1258  0.1233  0.1249  0.1257  0.1265  0.1257  0.1237  0.1246
 0.1281  0.1215  0.1212  0.1219  0.1276  0.1278  0.1269  0.1250
 0.1256  0.1199  0.1198  0.1223  0.1263  0.1322  0.1257  0.1282
 0.1271  0.1208  0.1203  0.1218  0.1259  0.1297  0.1294  0.1249
 0.1259  0.1215  0.1215  0.1216  0.1277  0.1303  0.1277  0.1239
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 00:30:43,028 
alphas_reduce = Variable containing:
 0.1241  0.1231  0.1227  0.1279  0.1295  0.1250  0.1228  0.1248
 0.1267  0.1223  0.1211  0.1189  0.1320  0.1310  0.1222  0.1257
 0.1257  0.1238  0.1235  0.1252  0.1235  0.1282  0.1241  0.1260
 0.1245  0.1225  0.1228  0.1260  0.1255  0.1278  0.1272  0.1238
 0.1249  0.1247  0.1236  0.1245  0.1240  0.1243  0.1294  0.1246
 0.1247  0.1236  0.1228  0.1259  0.1240  0.1271  0.1263  0.1256
 0.1241  0.1253  0.1238  0.1245  0.1266  0.1244  0.1245  0.1267
 0.1245  0.1252  0.1238  0.1246  0.1233  0.1279  0.1228  0.1278
 0.1248  0.1265  0.1257  0.1254  0.1220  0.1269  0.1238  0.1248
 0.1257  0.1242  0.1241  0.1260  0.1244  0.1259  0.1256  0.1239
 0.1257  0.1239  0.1236  0.1239  0.1235  0.1279  0.1263  0.1252
 0.1248  0.1240  0.1229  0.1241  0.1241  0.1266  0.1265  0.1271
 0.1251  0.1248  0.1243  0.1245  0.1255  0.1251  0.1275  0.1231
 0.1247  0.1248  0.1241  0.1242  0.1259  0.1242  0.1266  0.1255
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 00:30:46,645 train 000 1.912050e-02 -0.558487
2019-11-02 00:33:30,253 train 050 1.463114e-02 -0.928197
2019-11-02 00:36:13,882 train 100 1.481657e-02 -36.514253
2019-11-02 00:38:56,936 train 150 1.464838e-02 -30.310476
2019-11-02 00:41:40,904 train 200 1.453129e-02 -23.000706
2019-11-02 00:44:23,774 train 250 1.450482e-02 -18.558372
2019-11-02 00:47:06,585 train 300 1.452658e-02 -15.873195
2019-11-02 00:49:50,316 train 350 1.461301e-02 -14.051362
2019-11-02 00:52:33,402 train 400 1.469679e-02 -12.368400
2019-11-02 00:55:16,575 train 450 1.482255e-02 -11.061505
2019-11-02 00:58:00,013 train 500 1.482378e-02 -10.021016
2019-11-02 01:00:44,017 train 550 1.481343e-02 -9.155192
2019-11-02 01:03:30,860 train 600 1.480890e-02 -8.449369
2019-11-02 01:06:15,175 train 650 1.478412e-02 -9.134310
2019-11-02 01:08:57,769 train 700 1.477088e-02 -8.532361
2019-11-02 01:11:41,416 train 750 1.479003e-02 -8.046446
2019-11-02 01:14:25,282 train 800 1.478877e-02 -7.574522
2019-11-02 01:17:08,608 train 850 1.478250e-02 -8.820399
2019-11-02 01:19:50,956 train 900 1.477431e-02 -8.377520
2019-11-02 01:22:34,859 train 950 1.474008e-02 -8.010788
2019-11-02 01:25:19,233 train 1000 1.473073e-02 -7.793697
2019-11-02 01:28:03,804 train 1050 1.471813e-02 -7.473637
2019-11-02 01:30:48,024 train 1100 1.474460e-02 -7.358083
2019-11-02 01:33:31,006 train 1150 1.475950e-02 -7.090231
2019-11-02 01:36:14,456 train 1200 1.475920e-02 -6.846614
2019-11-02 01:38:58,136 train 1250 1.476393e-02 -6.600823
2019-11-02 01:41:41,799 train 1300 1.475201e-02 -6.619725
2019-11-02 01:44:26,183 train 1350 1.475002e-02 -6.400303
2019-11-02 01:47:09,906 train 1400 1.474853e-02 -6.198320
2019-11-02 01:49:52,348 train 1450 1.475319e-02 -6.007475
2019-11-02 01:52:36,371 train 1500 1.473507e-02 -6.023565
2019-11-02 01:54:44,408 train_acc (R^2 for regression) -5.890464
2019-11-02 01:54:44,890 valid 000 1.433022e-02 -1.479606
2019-11-02 01:54:53,468 valid 050 1.339894e-02 -0.540753
2019-11-02 01:55:02,044 valid 100 1.392866e-02 -0.543175
2019-11-02 01:55:10,589 valid 150 1.377162e-02 -0.531442
2019-11-02 01:55:19,098 valid 200 1.407797e-02 -0.609228
2019-11-02 01:55:27,606 valid 250 1.411690e-02 -0.608683
2019-11-02 01:55:36,093 valid 300 1.421343e-02 -0.603668
2019-11-02 01:55:44,546 valid 350 1.424470e-02 -5.067331
2019-11-02 01:55:53,073 valid 400 1.420360e-02 -4.499550
2019-11-02 01:56:01,578 valid 450 1.419340e-02 -4.064592
2019-11-02 01:56:10,095 valid 500 1.414128e-02 -3.821137
2019-11-02 01:56:18,584 valid 550 1.411896e-02 -3.545367
2019-11-02 01:56:27,085 valid 600 1.413488e-02 -3.431327
2019-11-02 01:56:35,608 valid 650 1.412126e-02 -3.222643
2019-11-02 01:56:44,183 valid 700 1.414610e-02 -3.046502
2019-11-02 01:56:52,671 valid 750 1.414885e-02 -2.883015
2019-11-02 01:57:01,178 valid 800 1.414045e-02 -2.736840
2019-11-02 01:57:09,670 valid 850 1.410361e-02 -2.644508
2019-11-02 01:57:18,193 valid 900 1.407855e-02 -2.529473
2019-11-02 01:57:26,717 valid 950 1.405501e-02 -2.439957
2019-11-02 01:57:35,237 valid 1000 1.401374e-02 -2.343935
2019-11-02 01:57:43,777 valid 1050 1.401161e-02 -2.256229
2019-11-02 01:57:52,309 valid 1100 1.399512e-02 -2.172346
2019-11-02 01:58:00,847 valid 1150 1.401030e-02 -2.907808
2019-11-02 01:58:09,382 valid 1200 1.402711e-02 -2.821036
2019-11-02 01:58:17,941 valid 1250 1.399910e-02 -2.769809
2019-11-02 01:58:26,391 valid 1300 1.400555e-02 -3.556156
2019-11-02 01:58:34,914 valid 1350 1.399169e-02 -3.462516
2019-11-02 01:58:43,373 valid 1400 1.398782e-02 -3.360419
2019-11-02 01:58:51,847 valid 1450 1.399616e-02 -3.275064
2019-11-02 01:59:00,292 valid 1500 1.398352e-02 -3.182302
2019-11-02 01:59:06,819 valid_acc (R^2 for regression) -3.128660
2019-11-02 01:59:06,961 epoch 8 lr 9.443380e-04
2019-11-02 01:59:06,962 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_3x3', 2), ('dil_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 3), ('sep_conv_5x5', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_5x5', 1), ('dil_conv_3x3', 2), ('sep_conv_5x5', 0), ('dil_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-02 01:59:06,963 
alphas_normal = Variable containing:
 0.1263  0.1238  0.1242  0.1247  0.1213  0.1291  0.1230  0.1276
 0.1252  0.1220  0.1206  0.1223  0.1237  0.1313  0.1308  0.1242
 0.1262  0.1258  0.1249  0.1253  0.1269  0.1252  0.1233  0.1224
 0.1246  0.1249  0.1229  0.1241  0.1233  0.1268  0.1263  0.1272
 0.1244  0.1253  0.1234  0.1247  0.1282  0.1258  0.1236  0.1247
 0.1240  0.1242  0.1248  0.1244  0.1243  0.1292  0.1252  0.1239
 0.1259  0.1224  0.1224  0.1229  0.1267  0.1286  0.1241  0.1272
 0.1259  0.1241  0.1237  0.1252  0.1249  0.1260  0.1255  0.1246
 0.1260  0.1232  0.1229  0.1232  0.1285  0.1263  0.1255  0.1244
 0.1252  0.1226  0.1230  0.1241  0.1244  0.1294  0.1244  0.1269
 0.1262  0.1234  0.1226  0.1234  0.1263  0.1256  0.1268  0.1257
 0.1251  0.1198  0.1191  0.1222  0.1299  0.1307  0.1247  0.1285
 0.1263  0.1210  0.1201  0.1220  0.1257  0.1308  0.1282  0.1259
 0.1262  0.1216  0.1212  0.1216  0.1274  0.1301  0.1256  0.1263
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 01:59:06,965 
alphas_reduce = Variable containing:
 0.1259  0.1233  0.1228  0.1252  0.1278  0.1269  0.1242  0.1238
 0.1244  0.1243  0.1235  0.1223  0.1305  0.1281  0.1210  0.1258
 0.1246  0.1240  0.1242  0.1242  0.1263  0.1268  0.1246  0.1253
 0.1245  0.1226  0.1228  0.1258  0.1256  0.1284  0.1252  0.1250
 0.1253  0.1240  0.1228  0.1251  0.1254  0.1256  0.1272  0.1247
 0.1245  0.1246  0.1239  0.1247  0.1246  0.1277  0.1264  0.1235
 0.1253  0.1250  0.1238  0.1242  0.1246  0.1254  0.1243  0.1274
 0.1246  0.1256  0.1230  0.1245  0.1252  0.1263  0.1250  0.1258
 0.1247  0.1270  0.1249  0.1250  0.1232  0.1258  0.1241  0.1254
 0.1254  0.1237  0.1234  0.1253  0.1263  0.1280  0.1241  0.1239
 0.1244  0.1247  0.1238  0.1251  0.1246  0.1267  0.1264  0.1242
 0.1259  0.1236  0.1222  0.1248  0.1270  0.1261  0.1259  0.1245
 0.1252  0.1244  0.1231  0.1243  0.1256  0.1274  0.1261  0.1239
 0.1248  0.1250  0.1239  0.1242  0.1238  0.1265  0.1254  0.1264
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 01:59:10,452 train 000 1.321065e-02 -0.191983
2019-11-02 02:01:52,310 train 050 1.415082e-02 -0.936906
2019-11-02 02:04:35,962 train 100 1.420051e-02 -0.810591
2019-11-02 02:07:20,411 train 150 1.452036e-02 -1.842680
2019-11-02 02:10:03,101 train 200 1.452238e-02 -1.520322
2019-11-02 02:12:45,968 train 250 1.443807e-02 -1.318830
2019-11-02 02:15:28,871 train 300 1.445102e-02 -3.464619
2019-11-02 02:18:12,338 train 350 1.434284e-02 -3.065696
2019-11-02 02:20:56,978 train 400 1.433476e-02 -2.753605
2019-11-02 02:23:40,971 train 450 1.437468e-02 -6.328473
2019-11-02 02:26:24,395 train 500 1.441209e-02 -5.781237
2019-11-02 02:29:08,995 train 550 1.443902e-02 -5.353067
2019-11-02 02:31:54,357 train 600 1.446836e-02 -4.967411
2019-11-02 02:34:39,677 train 650 1.450328e-02 -4.629552
2019-11-02 02:37:22,276 train 700 1.449473e-02 -32.090441
2019-11-02 02:40:05,657 train 750 1.449914e-02 -29.979701
2019-11-02 02:42:48,315 train 800 1.450766e-02 -28.228227
2019-11-02 02:45:30,389 train 850 1.450005e-02 -26.634854
2019-11-02 02:48:14,336 train 900 1.449742e-02 -25.194396
2019-11-02 02:50:57,540 train 950 1.448625e-02 -23.915423
2019-11-02 02:53:39,789 train 1000 1.451189e-02 -22.755443
2019-11-02 02:56:22,244 train 1050 1.453688e-02 -21.690971
2019-11-02 02:59:06,187 train 1100 1.449743e-02 -20.736850
2019-11-02 03:01:47,944 train 1150 1.448109e-02 -19.854026
2019-11-02 03:04:31,520 train 1200 1.447289e-02 -19.057727
2019-11-02 03:07:15,740 train 1250 1.448565e-02 -18.321633
2019-11-02 03:09:58,924 train 1300 1.449907e-02 -17.667825
2019-11-02 03:12:40,820 train 1350 1.448225e-02 -17.062475
2019-11-02 03:15:24,199 train 1400 1.448018e-02 -16.487227
2019-11-02 03:18:07,155 train 1450 1.447423e-02 -15.952552
2019-11-02 03:20:50,184 train 1500 1.448399e-02 -15.439131
2019-11-02 03:22:57,637 train_acc (R^2 for regression) -15.077002
2019-11-02 03:22:58,082 valid 000 1.221721e-02 -0.243657
2019-11-02 03:23:06,571 valid 050 1.409782e-02 -1.115573
2019-11-02 03:23:15,086 valid 100 1.383483e-02 -0.935915
2019-11-02 03:23:23,589 valid 150 1.371555e-02 -0.819163
2019-11-02 03:23:32,158 valid 200 1.365656e-02 -0.831056
2019-11-02 03:23:40,676 valid 250 1.374477e-02 -0.813351
2019-11-02 03:23:49,172 valid 300 1.375991e-02 -0.772957
2019-11-02 03:23:57,660 valid 350 1.384178e-02 -0.746769
2019-11-02 03:24:06,136 valid 400 1.374874e-02 -0.722822
2019-11-02 03:24:14,630 valid 450 1.369587e-02 -1.109298
2019-11-02 03:24:23,122 valid 500 1.374323e-02 -1.071583
2019-11-02 03:24:31,855 valid 550 1.377676e-02 -1.028026
2019-11-02 03:24:40,420 valid 600 1.376560e-02 -1.027723
2019-11-02 03:24:48,939 valid 650 1.373782e-02 -1.024029
2019-11-02 03:24:57,443 valid 700 1.371366e-02 -1.007116
2019-11-02 03:25:06,004 valid 750 1.371255e-02 -1.013749
2019-11-02 03:25:14,534 valid 800 1.369885e-02 -0.998684
2019-11-02 03:25:23,122 valid 850 1.370334e-02 -0.975406
2019-11-02 03:25:31,678 valid 900 1.371301e-02 -0.955811
2019-11-02 03:25:40,184 valid 950 1.368167e-02 -0.945538
2019-11-02 03:25:48,641 valid 1000 1.367163e-02 -0.937360
2019-11-02 03:25:57,103 valid 1050 1.371415e-02 -0.928181
2019-11-02 03:26:05,580 valid 1100 1.372943e-02 -0.988058
2019-11-02 03:26:14,106 valid 1150 1.370564e-02 -1.090308
2019-11-02 03:26:22,633 valid 1200 1.370206e-02 -1.114641
2019-11-02 03:26:31,101 valid 1250 1.372685e-02 -1.257128
2019-11-02 03:26:39,610 valid 1300 1.371960e-02 -1.242402
2019-11-02 03:26:48,070 valid 1350 1.370354e-02 -1.219943
2019-11-02 03:26:56,591 valid 1400 1.370847e-02 -1.194843
2019-11-02 03:27:05,067 valid 1450 1.372916e-02 -1.174967
2019-11-02 03:27:13,613 valid 1500 1.374497e-02 -1.157395
2019-11-02 03:27:20,249 valid_acc (R^2 for regression) -2.391507
2019-11-02 03:27:20,440 epoch 9 lr 9.299476e-04
2019-11-02 03:27:20,441 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('sep_conv_3x3', 2), ('sep_conv_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('sep_conv_5x5', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_3x3', 0), ('dil_conv_3x3', 2), ('dil_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 2), ('sep_conv_5x5', 0)], reduce_concat=range(2, 6))
2019-11-02 03:27:20,443 
alphas_normal = Variable containing:
 0.1264  0.1245  0.1243  0.1244  0.1213  0.1274  0.1230  0.1287
 0.1252  0.1234  0.1217  0.1230  0.1251  0.1306  0.1302  0.1210
 0.1255  0.1258  0.1247  0.1249  0.1268  0.1247  0.1229  0.1246
 0.1255  0.1254  0.1236  0.1239  0.1248  0.1262  0.1238  0.1267
 0.1248  0.1256  0.1228  0.1240  0.1302  0.1250  0.1237  0.1239
 0.1235  0.1239  0.1245  0.1240  0.1264  0.1286  0.1240  0.1251
 0.1246  0.1243  0.1241  0.1242  0.1263  0.1290  0.1216  0.1260
 0.1236  0.1259  0.1248  0.1251  0.1231  0.1269  0.1253  0.1252
 0.1234  0.1251  0.1250  0.1246  0.1273  0.1272  0.1234  0.1240
 0.1247  0.1237  0.1253  0.1261  0.1262  0.1273  0.1234  0.1233
 0.1289  0.1215  0.1206  0.1214  0.1284  0.1283  0.1265  0.1244
 0.1252  0.1206  0.1202  0.1224  0.1280  0.1304  0.1253  0.1279
 0.1275  0.1213  0.1211  0.1220  0.1272  0.1287  0.1277  0.1245
 0.1248  0.1224  0.1223  0.1226  0.1275  0.1304  0.1277  0.1223
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 03:27:20,444 
alphas_reduce = Variable containing:
 0.1248  0.1221  0.1215  0.1274  0.1302  0.1242  0.1257  0.1241
 0.1257  0.1228  0.1215  0.1212  0.1302  0.1306  0.1234  0.1246
 0.1252  0.1235  0.1240  0.1254  0.1237  0.1274  0.1258  0.1250
 0.1250  0.1220  0.1225  0.1261  0.1243  0.1260  0.1283  0.1259
 0.1255  0.1243  0.1232  0.1245  0.1235  0.1250  0.1295  0.1245
 0.1249  0.1236  0.1231  0.1265  0.1244  0.1274  0.1253  0.1249
 0.1239  0.1251  0.1243  0.1247  0.1264  0.1241  0.1247  0.1269
 0.1243  0.1261  0.1243  0.1243  0.1237  0.1256  0.1226  0.1291
 0.1249  0.1266  0.1259  0.1256  0.1213  0.1268  0.1233  0.1256
 0.1258  0.1242  0.1247  0.1243  0.1245  0.1274  0.1265  0.1228
 0.1253  0.1238  0.1232  0.1238  0.1255  0.1269  0.1264  0.1251
 0.1253  0.1236  0.1231  0.1243  0.1244  0.1277  0.1244  0.1271
 0.1250  0.1254  0.1248  0.1255  0.1251  0.1267  0.1257  0.1218
 0.1249  0.1241  0.1230  0.1234  0.1263  0.1252  0.1260  0.1270
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 03:27:23,861 train 000 1.385310e-02 -0.039235
2019-11-02 03:30:07,653 train 050 1.495998e-02 -0.736878
2019-11-02 03:32:51,246 train 100 1.454022e-02 -0.564402
2019-11-02 03:35:33,350 train 150 1.452938e-02 -0.786920
2019-11-02 03:38:16,457 train 200 1.451542e-02 -1.727370
2019-11-02 03:40:59,779 train 250 1.450799e-02 -1.469533
2019-11-02 03:43:42,415 train 300 1.451801e-02 -1.614998
2019-11-02 03:46:25,253 train 350 1.454015e-02 -1.477914
2019-11-02 03:49:08,936 train 400 1.452093e-02 -1.360270
2019-11-02 03:51:52,602 train 450 1.451248e-02 -1.316975
2019-11-02 03:54:35,403 train 500 1.445851e-02 -1.716003
2019-11-02 03:57:18,560 train 550 1.443356e-02 -1.601944
2019-11-02 04:00:02,243 train 600 1.445414e-02 -1.513953
2019-11-02 04:02:48,046 train 650 1.446263e-02 -1.460355
2019-11-02 04:05:32,059 train 700 1.446362e-02 -1.400074
2019-11-02 04:08:16,062 train 750 1.446542e-02 -1.365446
2019-11-02 04:11:00,038 train 800 1.443380e-02 -1.326593
2019-11-02 04:13:42,883 train 850 1.443802e-02 -1.454539
2019-11-02 04:16:26,911 train 900 1.440150e-02 -1.434949
2019-11-02 04:19:12,191 train 950 1.439628e-02 -1.389106
2019-11-02 04:21:54,806 train 1000 1.438335e-02 -1.341233
2019-11-02 04:24:37,514 train 1050 1.437856e-02 -1.299255
2019-11-02 04:27:19,445 train 1100 1.437049e-02 -1.281960
2019-11-02 04:30:02,540 train 1150 1.439491e-02 -1.261942
2019-11-02 04:32:44,674 train 1200 1.441612e-02 -1.235786
2019-11-02 04:35:27,819 train 1250 1.439576e-02 -1.201884
2019-11-02 04:38:11,908 train 1300 1.439080e-02 -1.212915
2019-11-02 04:40:54,817 train 1350 1.438171e-02 -1.192679
2019-11-02 04:43:37,808 train 1400 1.436862e-02 -1.171997
2019-11-02 04:46:21,307 train 1450 1.436051e-02 -1.194933
2019-11-02 04:49:04,729 train 1500 1.435163e-02 -1.754518
2019-11-02 04:51:11,185 train_acc (R^2 for regression) -1.726843
2019-11-02 04:51:11,687 valid 000 1.403009e-02 -0.480766
2019-11-02 04:51:20,246 valid 050 1.358824e-02 -1.287473
2019-11-02 04:51:28,777 valid 100 1.379213e-02 -1.596504
2019-11-02 04:51:37,294 valid 150 1.387324e-02 -1.222253
2019-11-02 04:51:45,835 valid 200 1.382475e-02 -8.289728
2019-11-02 04:51:54,315 valid 250 1.372124e-02 -6.761130
2019-11-02 04:52:02,833 valid 300 1.368129e-02 -5.736416
2019-11-02 04:52:11,342 valid 350 1.366636e-02 -4.994386
2019-11-02 04:52:19,853 valid 400 1.359013e-02 -4.442530
2019-11-02 04:52:28,328 valid 450 1.353995e-02 -4.026236
2019-11-02 04:52:36,841 valid 500 1.351746e-02 -3.692150
2019-11-02 04:52:45,334 valid 550 1.348657e-02 -3.435263
2019-11-02 04:52:53,878 valid 600 1.351388e-02 -3.200731
2019-11-02 04:53:02,368 valid 650 1.348872e-02 -2.982799
2019-11-02 04:53:10,896 valid 700 1.351478e-02 -2.826988
2019-11-02 04:53:19,444 valid 750 1.350472e-02 -2.728460
2019-11-02 04:53:27,983 valid 800 1.350427e-02 -2.596690
2019-11-02 04:53:36,517 valid 850 1.353386e-02 -2.533460
2019-11-02 04:53:45,017 valid 900 1.355502e-02 -2.440862
2019-11-02 04:53:53,526 valid 950 1.356247e-02 -2.372304
2019-11-02 04:54:02,012 valid 1000 1.354280e-02 -2.296766
2019-11-02 04:54:10,517 valid 1050 1.356655e-02 -2.228477
2019-11-02 04:54:18,983 valid 1100 1.357522e-02 -2.155182
2019-11-02 04:54:27,499 valid 1150 1.361000e-02 -2.091713
2019-11-02 04:54:35,992 valid 1200 1.358177e-02 -2.024415
2019-11-02 04:54:44,521 valid 1250 1.360261e-02 -1.968867
2019-11-02 04:54:53,012 valid 1300 1.361272e-02 -2.136300
2019-11-02 04:55:01,477 valid 1350 1.359800e-02 -2.085888
2019-11-02 04:55:09,980 valid 1400 1.358800e-02 -2.149705
2019-11-02 04:55:18,552 valid 1450 1.361257e-02 -2.094488
2019-11-02 04:55:27,077 valid 1500 1.363227e-02 -2.039322
2019-11-02 04:55:33,723 valid_acc (R^2 for regression) -1.998774
2019-11-02 04:55:33,859 epoch 10 lr 9.140576e-04
2019-11-02 04:55:33,860 genotype = Genotype(normal=[('dil_conv_3x3', 1), ('dil_conv_5x5', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('sep_conv_3x3', 3), ('sep_conv_5x5', 4), ('sep_conv_5x5', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_3x3', 0), ('sep_conv_5x5', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 2), ('dil_conv_5x5', 1), ('sep_conv_5x5', 1), ('dil_conv_3x3', 2)], reduce_concat=range(2, 6))
2019-11-02 04:55:33,862 
alphas_normal = Variable containing:
 0.1245  0.1262  0.1257  0.1253  0.1197  0.1284  0.1214  0.1289
 0.1271  0.1235  0.1204  0.1213  0.1247  0.1299  0.1314  0.1217
 0.1254  0.1266  0.1252  0.1248  0.1261  0.1243  0.1223  0.1253
 0.1260  0.1255  0.1227  0.1232  0.1241  0.1272  0.1259  0.1253
 0.1245  0.1255  0.1221  0.1233  0.1285  0.1269  0.1254  0.1238
 0.1229  0.1250  0.1256  0.1250  0.1270  0.1265  0.1227  0.1253
 0.1259  0.1235  0.1237  0.1233  0.1254  0.1281  0.1244  0.1257
 0.1253  0.1263  0.1251  0.1252  0.1251  0.1259  0.1233  0.1238
 0.1242  0.1253  0.1247  0.1237  0.1279  0.1271  0.1236  0.1235
 0.1248  0.1249  0.1261  0.1266  0.1253  0.1271  0.1220  0.1233
 0.1268  0.1231  0.1226  0.1228  0.1293  0.1272  0.1254  0.1228
 0.1250  0.1217  0.1209  0.1233  0.1281  0.1296  0.1262  0.1253
 0.1251  0.1227  0.1217  0.1234  0.1274  0.1289  0.1270  0.1238
 0.1240  0.1238  0.1230  0.1235  0.1265  0.1298  0.1264  0.1229
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 04:55:33,863 
alphas_reduce = Variable containing:
 0.1246  0.1216  0.1214  0.1280  0.1296  0.1241  0.1261  0.1247
 0.1255  0.1222  0.1211  0.1199  0.1317  0.1319  0.1218  0.1259
 0.1253  0.1241  0.1239  0.1256  0.1251  0.1276  0.1240  0.1244
 0.1251  0.1230  0.1232  0.1264  0.1258  0.1259  0.1265  0.1241
 0.1244  0.1258  0.1248  0.1249  0.1231  0.1261  0.1274  0.1235
 0.1252  0.1241  0.1236  0.1245  0.1245  0.1265  0.1264  0.1251
 0.1249  0.1253  0.1242  0.1232  0.1267  0.1242  0.1241  0.1274
 0.1238  0.1262  0.1249  0.1244  0.1230  0.1277  0.1225  0.1275
 0.1248  0.1268  0.1257  0.1256  0.1226  0.1260  0.1243  0.1241
 0.1258  0.1240  0.1238  0.1247  0.1243  0.1272  0.1260  0.1243
 0.1261  0.1243  0.1238  0.1242  0.1236  0.1274  0.1272  0.1233
 0.1248  0.1239  0.1229  0.1240  0.1258  0.1265  0.1272  0.1249
 0.1253  0.1245  0.1236  0.1243  0.1265  0.1269  0.1264  0.1225
 0.1247  0.1245  0.1232  0.1232  0.1256  0.1246  0.1271  0.1270
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 04:55:37,407 train 000 1.349276e-02 -0.978268
2019-11-02 04:58:19,401 train 050 1.387243e-02 -0.919711
2019-11-02 05:01:01,674 train 100 1.412250e-02 -4.657149
2019-11-02 05:03:45,047 train 150 1.413077e-02 -3.463068
2019-11-02 05:06:29,128 train 200 1.422426e-02 -2.795029
2019-11-02 05:09:12,083 train 250 1.444318e-02 -2.351123
2019-11-02 05:11:56,240 train 300 1.433946e-02 -2.206724
2019-11-02 05:14:37,280 train 350 1.427959e-02 -1.958719
2019-11-02 05:17:20,119 train 400 1.426056e-02 -1.847999
2019-11-02 05:20:03,372 train 450 1.423865e-02 -1.719400
2019-11-02 05:22:45,261 train 500 1.422403e-02 -1.697905
2019-11-02 05:25:28,536 train 550 1.430993e-02 -1.989648
2019-11-02 05:28:12,694 train 600 1.427702e-02 -1.885297
2019-11-02 05:30:59,094 train 650 1.430034e-02 -1.799736
2019-11-02 05:33:44,271 train 700 1.430734e-02 -1.707359
2019-11-02 05:36:27,523 train 750 1.430233e-02 -1.626215
2019-11-02 05:39:11,688 train 800 1.429545e-02 -1.551065
2019-11-02 05:41:54,762 train 850 1.430222e-02 -1.501013
2019-11-02 05:44:37,636 train 900 1.425067e-02 -1.454713
2019-11-02 05:47:20,902 train 950 1.421706e-02 -1.395817
2019-11-02 05:50:04,122 train 1000 1.420830e-02 -1.360052
2019-11-02 05:52:47,529 train 1050 1.419594e-02 -1.313828
2019-11-02 05:55:30,061 train 1100 1.418771e-02 -1.894236
2019-11-02 05:58:12,865 train 1150 1.416299e-02 -2.420160
2019-11-02 06:00:55,666 train 1200 1.412808e-02 -2.374270
2019-11-02 06:03:38,947 train 1250 1.414079e-02 -2.309860
2019-11-02 06:06:21,696 train 1300 1.414776e-02 -2.236877
2019-11-02 06:09:05,388 train 1350 1.413850e-02 -2.183513
2019-11-02 06:11:48,233 train 1400 1.411907e-02 -2.123749
2019-11-02 06:14:31,585 train 1450 1.412871e-02 -2.082253
2019-11-02 06:17:15,115 train 1500 1.413295e-02 -2.031425
2019-11-02 06:19:23,102 train_acc (R^2 for regression) -1.989409
2019-11-02 06:19:23,589 valid 000 1.060808e-02 -0.421263
2019-11-02 06:19:32,153 valid 050 1.285467e-02 -0.700221
2019-11-02 06:19:40,674 valid 100 1.308873e-02 -0.600799
2019-11-02 06:19:49,236 valid 150 1.310085e-02 -0.558686
2019-11-02 06:19:57,818 valid 200 1.308634e-02 -0.590032
2019-11-02 06:20:06,298 valid 250 1.319416e-02 -0.641810
2019-11-02 06:20:14,746 valid 300 1.321882e-02 -0.640562
2019-11-02 06:20:23,232 valid 350 1.327078e-02 -0.619010
2019-11-02 06:20:31,672 valid 400 1.323874e-02 -0.639698
2019-11-02 06:20:40,134 valid 450 1.327365e-02 -0.717338
2019-11-02 06:20:48,627 valid 500 1.327411e-02 -0.696742
2019-11-02 06:20:57,055 valid 550 1.327126e-02 -1.446440
2019-11-02 06:21:05,511 valid 600 1.322884e-02 -1.360116
2019-11-02 06:21:13,965 valid 650 1.324828e-02 -1.284443
2019-11-02 06:21:22,431 valid 700 1.327081e-02 -1.220190
2019-11-02 06:21:30,883 valid 750 1.326879e-02 -1.173840
2019-11-02 06:21:39,391 valid 800 1.323868e-02 -1.272185
2019-11-02 06:21:47,852 valid 850 1.326955e-02 -1.213568
2019-11-02 06:21:56,362 valid 900 1.328543e-02 -1.175162
2019-11-02 06:22:04,834 valid 950 1.330401e-02 -1.136988
2019-11-02 06:22:13,311 valid 1000 1.330117e-02 -1.126938
2019-11-02 06:22:21,755 valid 1050 1.330332e-02 -1.174879
2019-11-02 06:22:30,227 valid 1100 1.327978e-02 -1.219582
2019-11-02 06:22:38,676 valid 1150 1.328068e-02 -1.184895
2019-11-02 06:22:47,172 valid 1200 1.329464e-02 -1.189514
2019-11-02 06:22:55,685 valid 1250 1.332705e-02 -1.257168
2019-11-02 06:23:04,213 valid 1300 1.332322e-02 -1.228800
2019-11-02 06:23:12,727 valid 1350 1.331756e-02 -1.225869
2019-11-02 06:23:21,283 valid 1400 1.330311e-02 -1.225465
2019-11-02 06:23:29,826 valid 1450 1.330383e-02 -1.418096
2019-11-02 06:23:38,374 valid 1500 1.331545e-02 -1.397235
2019-11-02 06:23:44,996 valid_acc (R^2 for regression) -1.397735
2019-11-02 06:23:45,131 epoch 11 lr 8.967310e-04
2019-11-02 06:23:45,132 genotype = Genotype(normal=[('sep_conv_5x5', 1), ('dil_conv_5x5', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_5x5', 4), ('sep_conv_5x5', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 0), ('dil_conv_5x5', 2), ('sep_conv_5x5', 0), ('sep_conv_5x5', 3), ('sep_conv_5x5', 0)], reduce_concat=range(2, 6))
2019-11-02 06:23:45,135 
alphas_normal = Variable containing:
 0.1262  0.1244  0.1239  0.1240  0.1219  0.1276  0.1227  0.1293
 0.1258  0.1230  0.1206  0.1219  0.1256  0.1305  0.1304  0.1220
 0.1258  0.1259  0.1248  0.1246  0.1263  0.1249  0.1218  0.1259
 0.1255  0.1244  0.1228  0.1234  0.1243  0.1288  0.1256  0.1252
 0.1237  0.1256  0.1225  0.1237  0.1290  0.1253  0.1249  0.1252
 0.1243  0.1237  0.1241  0.1241  0.1252  0.1283  0.1235  0.1268
 0.1257  0.1235  0.1237  0.1236  0.1248  0.1289  0.1242  0.1256
 0.1254  0.1249  0.1236  0.1244  0.1254  0.1267  0.1247  0.1249
 0.1244  0.1245  0.1238  0.1235  0.1275  0.1272  0.1245  0.1246
 0.1259  0.1227  0.1239  0.1249  0.1262  0.1278  0.1240  0.1246
 0.1258  0.1228  0.1226  0.1231  0.1277  0.1269  0.1265  0.1246
 0.1247  0.1217  0.1210  0.1232  0.1290  0.1294  0.1249  0.1261
 0.1256  0.1227  0.1223  0.1235  0.1274  0.1284  0.1266  0.1235
 0.1245  0.1231  0.1228  0.1233  0.1269  0.1299  0.1257  0.1237
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 06:23:45,136 
alphas_reduce = Variable containing:
 0.1249  0.1212  0.1212  0.1278  0.1284  0.1240  0.1262  0.1263
 0.1250  0.1234  0.1218  0.1213  0.1307  0.1304  0.1216  0.1258
 0.1254  0.1237  0.1232  0.1253  0.1246  0.1270  0.1261  0.1247
 0.1248  0.1238  0.1236  0.1257  0.1254  0.1268  0.1251  0.1248
 0.1252  0.1258  0.1234  0.1253  0.1243  0.1260  0.1274  0.1226
 0.1249  0.1241  0.1236  0.1247  0.1245  0.1274  0.1266  0.1242
 0.1247  0.1250  0.1237  0.1247  0.1250  0.1250  0.1257  0.1262
 0.1244  0.1266  0.1240  0.1246  0.1241  0.1255  0.1231  0.1276
 0.1249  0.1262  0.1248  0.1251  0.1239  0.1257  0.1248  0.1245
 0.1259  0.1235  0.1232  0.1253  0.1249  0.1274  0.1253  0.1244
 0.1247  0.1244  0.1234  0.1251  0.1246  0.1269  0.1264  0.1245
 0.1254  0.1245  0.1230  0.1247  0.1248  0.1269  0.1249  0.1259
 0.1253  0.1246  0.1235  0.1243  0.1261  0.1280  0.1260  0.1222
 0.1243  0.1241  0.1232  0.1236  0.1266  0.1251  0.1267  0.1263
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 06:23:48,821 train 000 1.476709e-02 -1.030955
2019-11-02 06:26:31,432 train 050 1.384025e-02 -0.508608
2019-11-02 06:29:14,392 train 100 1.358172e-02 -0.570176
2019-11-02 06:31:57,685 train 150 1.367493e-02 -0.505522
2019-11-02 06:34:41,128 train 200 1.385987e-02 -4.382287
2019-11-02 06:37:23,692 train 250 1.388628e-02 -3.648309
2019-11-02 06:40:07,636 train 300 1.395995e-02 -3.692959
2019-11-02 06:42:50,440 train 350 1.395631e-02 -3.243594
2019-11-02 06:45:34,754 train 400 1.397517e-02 -2.893635
2019-11-02 06:48:17,733 train 450 1.397048e-02 -2.616647
2019-11-02 06:51:01,184 train 500 1.397599e-02 -2.384448
2019-11-02 06:53:44,891 train 550 1.397511e-02 -2.216157
2019-11-02 06:56:27,875 train 600 1.394433e-02 -2.104668
2019-11-02 06:59:12,370 train 650 1.393548e-02 -1.991978
2019-11-02 07:01:59,089 train 700 1.395456e-02 -4.711586
2019-11-02 07:04:41,879 train 750 1.396794e-02 -4.418635
2019-11-02 07:07:24,962 train 800 1.396820e-02 -4.178355
2019-11-02 07:10:07,507 train 850 1.395899e-02 -3.967245
2019-11-02 07:12:51,634 train 900 1.393640e-02 -3.771104
2019-11-02 07:15:35,200 train 950 1.393469e-02 -3.619284
2019-11-02 07:18:17,230 train 1000 1.391055e-02 -4.189514
2019-11-02 07:20:58,831 train 1050 1.390234e-02 -4.855808
2019-11-02 07:23:40,851 train 1100 1.390855e-02 -4.650624
2019-11-02 07:26:24,015 train 1150 1.390269e-02 -4.465135
2019-11-02 07:29:07,220 train 1200 1.387988e-02 -4.313007
2019-11-02 07:31:51,039 train 1250 1.390180e-02 -4.173780
2019-11-02 07:34:33,837 train 1300 1.392213e-02 -4.596153
2019-11-02 07:37:16,879 train 1350 1.391691e-02 -4.459380
2019-11-02 07:40:00,245 train 1400 1.390703e-02 -4.315975
2019-11-02 07:42:44,107 train 1450 1.390186e-02 -4.213676
2019-11-02 07:45:27,183 train 1500 1.389683e-02 -4.113740
2019-11-02 07:47:35,016 train_acc (R^2 for regression) -4.024250
2019-11-02 07:47:35,511 valid 000 1.579875e-02 -0.422862
2019-11-02 07:47:44,040 valid 050 1.355545e-02 -0.831788
2019-11-02 07:47:52,571 valid 100 1.346770e-02 -2.538092
2019-11-02 07:48:01,090 valid 150 1.337293e-02 -1.882894
2019-11-02 07:48:09,620 valid 200 1.341401e-02 -1.520115
2019-11-02 07:48:18,136 valid 250 1.337927e-02 -1.318299
2019-11-02 07:48:26,646 valid 300 1.331209e-02 -1.172793
2019-11-02 07:48:35,154 valid 350 1.338293e-02 -1.075368
2019-11-02 07:48:43,654 valid 400 1.336061e-02 -0.986999
2019-11-02 07:48:52,168 valid 450 1.340822e-02 -4.214583
2019-11-02 07:49:00,659 valid 500 1.342135e-02 -3.832352
2019-11-02 07:49:09,119 valid 550 1.341183e-02 -3.518205
2019-11-02 07:49:17,567 valid 600 1.346239e-02 -3.273414
2019-11-02 07:49:26,082 valid 650 1.340669e-02 -3.611679
2019-11-02 07:49:34,592 valid 700 1.340825e-02 -3.435053
2019-11-02 07:49:43,122 valid 750 1.337348e-02 -3.265913
2019-11-02 07:49:51,631 valid 800 1.333233e-02 -3.082803
2019-11-02 07:50:00,190 valid 850 1.330716e-02 -2.918882
2019-11-02 07:50:08,687 valid 900 1.329391e-02 -2.817260
2019-11-02 07:50:17,211 valid 950 1.328448e-02 -2.746565
2019-11-02 07:50:25,710 valid 1000 1.328836e-02 -2.661422
2019-11-02 07:50:34,212 valid 1050 1.330425e-02 -2.567091
2019-11-02 07:50:42,724 valid 1100 1.332274e-02 -2.482987
2019-11-02 07:50:51,250 valid 1150 1.331968e-02 -2.398816
2019-11-02 07:50:59,815 valid 1200 1.331364e-02 -2.324188
2019-11-02 07:51:08,338 valid 1250 1.331815e-02 -2.294126
2019-11-02 07:51:16,836 valid 1300 1.333065e-02 -2.228386
2019-11-02 07:51:25,289 valid 1350 1.329725e-02 -2.199922
2019-11-02 07:51:33,825 valid 1400 1.331779e-02 -2.133752
2019-11-02 07:51:42,285 valid 1450 1.333438e-02 -2.086294
2019-11-02 07:51:50,725 valid 1500 1.332034e-02 -2.029141
2019-11-02 07:51:57,317 valid_acc (R^2 for regression) -1.984770
2019-11-02 07:51:57,450 epoch 12 lr 8.780359e-04
2019-11-02 07:51:57,451 genotype = Genotype(normal=[('dil_conv_5x5', 0), ('dil_conv_3x3', 1), ('sep_conv_3x3', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('sep_conv_5x5', 3), ('sep_conv_5x5', 4), ('sep_conv_5x5', 2)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_3x3', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2), ('dil_conv_5x5', 1), ('sep_conv_5x5', 3), ('sep_conv_5x5', 2)], reduce_concat=range(2, 6))
2019-11-02 07:51:57,453 
alphas_normal = Variable containing:
 0.1255  0.1240  0.1246  0.1246  0.1205  0.1270  0.1216  0.1322
 0.1259  0.1228  0.1203  0.1215  0.1251  0.1306  0.1322  0.1216
 0.1254  0.1250  0.1250  0.1251  0.1272  0.1250  0.1218  0.1256
 0.1257  0.1242  0.1232  0.1239  0.1244  0.1281  0.1257  0.1248
 0.1244  0.1248  0.1225  0.1236  0.1293  0.1270  0.1240  0.1243
 0.1241  0.1235  0.1247  0.1247  0.1253  0.1275  0.1233  0.1268
 0.1262  0.1230  0.1230  0.1233  0.1257  0.1299  0.1236  0.1252
 0.1254  0.1253  0.1246  0.1254  0.1247  0.1263  0.1248  0.1235
 0.1244  0.1239  0.1238  0.1235  0.1277  0.1279  0.1240  0.1248
 0.1252  0.1230  0.1248  0.1255  0.1269  0.1274  0.1232  0.1241
 0.1273  0.1223  0.1219  0.1223  0.1276  0.1272  0.1262  0.1253
 0.1250  0.1220  0.1214  0.1238  0.1277  0.1290  0.1258  0.1253
 0.1253  0.1223  0.1217  0.1230  0.1264  0.1285  0.1285  0.1244
 0.1240  0.1241  0.1236  0.1240  0.1251  0.1298  0.1260  0.1233
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 07:51:57,454 
alphas_reduce = Variable containing:
 0.1247  0.1221  0.1227  0.1280  0.1299  0.1234  0.1250  0.1241
 0.1259  0.1212  0.1211  0.1210  0.1314  0.1326  0.1213  0.1254
 0.1246  0.1239  0.1241  0.1260  0.1246  0.1275  0.1242  0.1251
 0.1250  0.1227  0.1230  0.1252  0.1267  0.1276  0.1262  0.1236
 0.1251  0.1249  0.1242  0.1253  0.1244  0.1250  0.1285  0.1225
 0.1255  0.1228  0.1223  0.1262  0.1246  0.1263  0.1270  0.1252
 0.1240  0.1251  0.1247  0.1241  0.1270  0.1240  0.1241  0.1271
 0.1247  0.1244  0.1246  0.1254  0.1243  0.1265  0.1228  0.1274
 0.1250  0.1254  0.1247  0.1251  0.1226  0.1259  0.1248  0.1264
 0.1259  0.1233  0.1235  0.1257  0.1240  0.1265  0.1265  0.1247
 0.1254  0.1253  0.1249  0.1252  0.1229  0.1267  0.1258  0.1240
 0.1244  0.1245  0.1239  0.1244  0.1249  0.1267  0.1261  0.1252
 0.1248  0.1249  0.1243  0.1244  0.1247  0.1273  0.1260  0.1236
 0.1244  0.1256  0.1252  0.1251  0.1266  0.1231  0.1251  0.1248
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 07:52:00,989 train 000 2.008863e-02 0.113343
2019-11-02 07:54:43,855 train 050 1.387051e-02 -2.245732
2019-11-02 07:57:26,780 train 100 1.380201e-02 -1.603622
2019-11-02 08:00:09,908 train 150 1.377596e-02 -1.243703
2019-11-02 08:02:52,800 train 200 1.373034e-02 -9.701860
2019-11-02 08:05:36,092 train 250 1.353795e-02 -7.877371
2019-11-02 08:08:18,399 train 300 1.363134e-02 -6.676644
2019-11-02 08:11:00,349 train 350 1.367773e-02 -5.809084
2019-11-02 08:13:42,748 train 400 1.368407e-02 -5.123950
2019-11-02 08:16:26,437 train 450 1.369467e-02 -4.603556
2019-11-02 08:19:09,951 train 500 1.370652e-02 -4.245894
2019-11-02 08:21:53,753 train 550 1.369019e-02 -3.915655
2019-11-02 08:24:36,613 train 600 1.365546e-02 -3.851771
2019-11-02 08:27:19,073 train 650 1.365968e-02 -160.520818
2019-11-02 08:30:05,132 train 700 1.370592e-02 -149.096145
2019-11-02 08:32:48,317 train 750 1.372702e-02 -139.273421
2019-11-02 08:35:31,472 train 800 1.372234e-02 -130.643808
2019-11-02 08:38:15,522 train 850 1.369555e-02 -122.987582
2019-11-02 08:40:57,389 train 900 1.372048e-02 -116.206761
2019-11-02 08:43:39,799 train 950 1.371864e-02 -110.122286
2019-11-02 08:46:22,081 train 1000 1.371863e-02 -104.796026
2019-11-02 08:49:05,157 train 1050 1.373233e-02 -99.935631
2019-11-02 08:51:48,680 train 1100 1.370830e-02 -95.418137
2019-11-02 08:54:31,092 train 1150 1.370137e-02 -91.301837
2019-11-02 08:57:14,891 train 1200 1.368741e-02 -87.521853
2019-11-02 08:59:57,666 train 1250 1.369169e-02 -84.045630
2019-11-02 09:02:40,837 train 1300 1.370704e-02 -80.823812
2019-11-02 09:05:23,989 train 1350 1.370706e-02 -77.853737
2019-11-02 09:08:07,385 train 1400 1.372674e-02 -75.109069
2019-11-02 09:10:50,721 train 1450 1.372164e-02 -72.595225
2019-11-02 09:13:34,962 train 1500 1.372759e-02 -71.268221
2019-11-02 09:15:41,552 train_acc (R^2 for regression) -70.062423
2019-11-02 09:15:42,071 valid 000 1.138262e-02 -0.144711
2019-11-02 09:15:50,606 valid 050 1.329840e-02 -0.692594
2019-11-02 09:15:59,090 valid 100 1.326088e-02 -0.848769
2019-11-02 09:16:07,597 valid 150 1.315105e-02 -0.831921
2019-11-02 09:16:16,105 valid 200 1.318502e-02 -0.768899
2019-11-02 09:16:24,618 valid 250 1.309278e-02 -0.728011
2019-11-02 09:16:33,120 valid 300 1.304898e-02 -0.656091
2019-11-02 09:16:41,626 valid 350 1.315308e-02 -0.657511
2019-11-02 09:16:50,085 valid 400 1.312957e-02 -5.042948
2019-11-02 09:16:58,484 valid 450 1.311901e-02 -4.589245
2019-11-02 09:17:06,896 valid 500 1.312293e-02 -4.168020
2019-11-02 09:17:15,311 valid 550 1.309469e-02 -3.839052
2019-11-02 09:17:23,814 valid 600 1.308735e-02 -3.560126
2019-11-02 09:17:32,242 valid 650 1.305467e-02 -3.309826
2019-11-02 09:17:40,648 valid 700 1.306967e-02 -3.104594
2019-11-02 09:17:49,031 valid 750 1.309352e-02 -2.918825
2019-11-02 09:17:57,517 valid 800 1.310700e-02 -2.782698
2019-11-02 09:18:05,992 valid 850 1.309635e-02 -2.643070
2019-11-02 09:18:14,505 valid 900 1.307353e-02 -2.596041
2019-11-02 09:18:23,077 valid 950 1.307668e-02 -2.482548
2019-11-02 09:18:31,584 valid 1000 1.308516e-02 -2.748317
2019-11-02 09:18:40,017 valid 1050 1.306452e-02 -2.630668
2019-11-02 09:18:48,485 valid 1100 1.307552e-02 -2.536445
2019-11-02 09:18:56,906 valid 1150 1.307827e-02 -2.436700
2019-11-02 09:19:05,382 valid 1200 1.305796e-02 -2.352424
2019-11-02 09:19:13,810 valid 1250 1.306133e-02 -2.272833
2019-11-02 09:19:22,279 valid 1300 1.307171e-02 -2.199738
2019-11-02 09:19:30,704 valid 1350 1.307998e-02 -2.141975
2019-11-02 09:19:39,154 valid 1400 1.307876e-02 -2.081540
2019-11-02 09:19:47,563 valid 1450 1.307250e-02 -2.073823
2019-11-02 09:19:55,998 valid 1500 1.306710e-02 -2.020226
2019-11-02 09:20:02,561 valid_acc (R^2 for regression) -1.982238
2019-11-02 09:20:02,698 epoch 13 lr 8.580462e-04
2019-11-02 09:20:02,698 genotype = Genotype(normal=[('dil_conv_3x3', 1), ('dil_conv_5x5', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 1), ('sep_conv_5x5', 1), ('sep_conv_3x3', 3), ('sep_conv_5x5', 2), ('sep_conv_5x5', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_5x5', 1), ('sep_conv_3x3', 0), ('sep_conv_5x5', 0), ('dil_conv_3x3', 2), ('sep_conv_5x5', 2), ('max_pool_3x3', 3), ('sep_conv_5x5', 1), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))
2019-11-02 09:20:02,700 
alphas_normal = Variable containing:
 0.1257  0.1236  0.1239  0.1238  0.1212  0.1280  0.1219  0.1319
 0.1263  0.1220  0.1203  0.1216  0.1258  0.1305  0.1322  0.1213
 0.1258  0.1247  0.1245  0.1250  0.1276  0.1235  0.1218  0.1270
 0.1251  0.1238  0.1231  0.1234  0.1255  0.1283  0.1259  0.1250
 0.1242  0.1250  0.1226  0.1240  0.1285  0.1268  0.1243  0.1245
 0.1246  0.1241  0.1249  0.1249  0.1245  0.1269  0.1238  0.1264
 0.1260  0.1232  0.1231  0.1231  0.1256  0.1303  0.1241  0.1247
 0.1250  0.1250  0.1246  0.1253  0.1257  0.1259  0.1238  0.1247
 0.1243  0.1242  0.1240  0.1242  0.1278  0.1265  0.1240  0.1251
 0.1252  0.1236  0.1247  0.1254  0.1261  0.1258  0.1240  0.1252
 0.1271  0.1227  0.1225  0.1230  0.1278  0.1262  0.1267  0.1240
 0.1242  0.1215  0.1214  0.1228  0.1288  0.1301  0.1249  0.1263
 0.1254  0.1220  0.1220  0.1235  0.1270  0.1275  0.1277  0.1249
 0.1249  0.1235  0.1233  0.1235  0.1259  0.1287  0.1266  0.1238
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 09:20:02,702 
alphas_reduce = Variable containing:
 0.1256  0.1222  0.1226  0.1275  0.1307  0.1233  0.1256  0.1226
 0.1244  0.1215  0.1217  0.1218  0.1291  0.1312  0.1234  0.1270
 0.1256  0.1241  0.1242  0.1251  0.1252  0.1281  0.1235  0.1243
 0.1251  0.1225  0.1227  0.1255  0.1256  0.1273  0.1259  0.1255
 0.1251  0.1253  0.1243  0.1251  0.1236  0.1253  0.1280  0.1232
 0.1249  0.1245  0.1238  0.1245  0.1250  0.1264  0.1260  0.1250
 0.1250  0.1250  0.1239  0.1245  0.1247  0.1254  0.1249  0.1266
 0.1244  0.1261  0.1242  0.1250  0.1236  0.1278  0.1225  0.1264
 0.1247  0.1267  0.1255  0.1258  0.1230  0.1266  0.1236  0.1241
 0.1254  0.1238  0.1238  0.1254  0.1246  0.1267  0.1249  0.1252
 0.1253  0.1243  0.1241  0.1241  0.1239  0.1270  0.1266  0.1248
 0.1248  0.1247  0.1239  0.1246  0.1250  0.1262  0.1260  0.1248
 0.1251  0.1250  0.1242  0.1245  0.1244  0.1267  0.1265  0.1236
 0.1242  0.1247  0.1243  0.1245  0.1261  0.1252  0.1255  0.1255
[torch.cuda.FloatTensor of size 14x8 (GPU 1)]

2019-11-02 09:20:06,209 train 000 1.311193e-02 -2.997879
2019-11-02 09:22:48,792 train 050 1.352089e-02 -0.715128
2019-11-02 09:25:29,771 train 100 1.331253e-02 -0.863993
2019-11-02 09:28:12,135 train 150 1.349896e-02 -0.733480
2019-11-02 09:30:53,903 train 200 1.349275e-02 -0.640753
