2019-11-04 09:41:48,751 gpu device = 1
2019-11-04 09:41:48,752 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=128, cutout=False, cutout_length=16, data='../data', dataset='GalaxyZoo', drop_path_prob=0.5, epochs=2000, gpu=1, grad_clip=5, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', random=False, report_freq=50, save='eval-GalaxyZoo-Run01-C16_L08_WD1E-5_DROP50_BS128-20191104-094148', seed=0, weight_decay=1e-05)
2019-11-04 09:41:52,074 param size = 9.723733MB
2019-11-04 09:41:52,076 epoch 0 lr 1.000000e-03
2019-11-04 09:41:55,024 train 000 4.054125e-02 -1.942514
2019-11-04 09:42:13,783 train 050 3.661361e-02 -1.784150
2019-11-04 09:42:33,617 train 100 2.930756e-02 -1.083857
2019-11-04 09:42:53,295 train 150 2.646748e-02 -0.961141
2019-11-04 09:43:12,983 train 200 2.445330e-02 -0.870695
2019-11-04 09:43:33,401 train 250 2.315219e-02 -0.812838
2019-11-04 09:43:54,407 train 300 2.227702e-02 -0.761125
2019-11-04 09:44:15,656 train 350 2.169092e-02 -0.720566
2019-11-04 09:44:36,515 train 400 2.113503e-02 -0.692414
2019-11-04 09:44:50,302 training loss; R2: 2.083543e-02 -0.688669
2019-11-04 09:44:51,338 valid 000 4.831622e-02 -0.596106
2019-11-04 09:45:10,696 validation loss; R2: 4.921174e-02 -0.626164
2019-11-04 09:45:10,776 epoch 1 lr 9.999994e-04
2019-11-04 09:45:12,018 train 000 2.167779e-02 -1.052296
2019-11-04 09:45:33,190 train 050 1.662409e-02 -0.533646
2019-11-04 09:45:54,515 train 100 1.642998e-02 -0.417596
2019-11-04 09:46:15,557 train 150 1.611646e-02 -0.359387
2019-11-04 09:46:36,815 train 200 1.595506e-02 -0.323704
2019-11-04 09:46:57,440 train 250 1.581061e-02 -0.326853
2019-11-04 09:47:17,406 train 300 1.568947e-02 -0.345466
2019-11-04 09:47:37,302 train 350 1.553753e-02 -0.332886
2019-11-04 09:47:57,019 train 400 1.535162e-02 -0.334005
2019-11-04 09:48:09,910 training loss; R2: 1.521549e-02 -0.326414
2019-11-04 09:48:10,919 valid 000 1.695913e-02 -0.012121
2019-11-04 09:48:29,066 validation loss; R2: 1.842557e-02 -0.153182
2019-11-04 09:48:29,173 epoch 2 lr 9.999975e-04
2019-11-04 09:48:30,258 train 000 1.686004e-02 -0.997795
2019-11-04 09:48:51,015 train 050 1.373042e-02 -0.413959
2019-11-04 09:49:12,171 train 100 1.378224e-02 -0.324965
2019-11-04 09:49:33,347 train 150 1.401992e-02 -0.310517
2019-11-04 09:49:54,508 train 200 1.395914e-02 -0.297502
2019-11-04 09:50:15,698 train 250 1.397904e-02 -0.283946
2019-11-04 09:50:36,777 train 300 1.385368e-02 -0.272583
2019-11-04 09:50:57,869 train 350 1.371858e-02 -0.279422
2019-11-04 09:51:18,997 train 400 1.363903e-02 -0.272302
2019-11-04 09:51:32,540 training loss; R2: 1.359190e-02 -0.267197
2019-11-04 09:51:33,577 valid 000 1.497502e-02 -0.243526
2019-11-04 09:51:52,613 validation loss; R2: 1.478076e-02 -0.441016
2019-11-04 09:51:52,724 epoch 3 lr 9.999944e-04
2019-11-04 09:51:53,885 train 000 1.221941e-02 -0.002340
2019-11-04 09:52:15,078 train 050 1.407914e-02 -0.149838
2019-11-04 09:52:36,149 train 100 1.373193e-02 -0.182897
2019-11-04 09:52:57,134 train 150 1.345249e-02 -0.231088
2019-11-04 09:53:18,284 train 200 1.324808e-02 -0.233744
2019-11-04 09:53:39,452 train 250 1.314633e-02 -0.257702
2019-11-04 09:54:00,623 train 300 1.301327e-02 -0.258185
2019-11-04 09:54:21,795 train 350 1.291305e-02 -0.251370
2019-11-04 09:54:42,995 train 400 1.287861e-02 -0.272120
2019-11-04 09:54:56,622 training loss; R2: 1.284376e-02 -0.261209
2019-11-04 09:54:57,671 valid 000 1.376241e-02 -0.191732
2019-11-04 09:55:16,741 validation loss; R2: 1.346486e-02 -0.361053
2019-11-04 09:55:16,843 epoch 4 lr 9.999901e-04
2019-11-04 09:55:17,979 train 000 1.263693e-02 0.146648
2019-11-04 09:55:39,130 train 050 1.234018e-02 -0.173214
2019-11-04 09:56:00,152 train 100 1.237333e-02 -0.216658
2019-11-04 09:56:21,362 train 150 1.225822e-02 -0.216199
2019-11-04 09:56:42,473 train 200 1.218858e-02 -0.273168
2019-11-04 09:57:03,583 train 250 1.220906e-02 -0.279590
2019-11-04 09:57:24,680 train 300 1.218165e-02 -0.284922
2019-11-04 09:57:45,799 train 350 1.216522e-02 -0.306020
2019-11-04 09:58:06,933 train 400 1.215472e-02 -0.302348
2019-11-04 09:58:20,502 training loss; R2: 1.212638e-02 -0.311716
2019-11-04 09:58:21,528 valid 000 1.192224e-02 0.052260
2019-11-04 09:58:40,680 validation loss; R2: 1.214639e-02 -0.121092
2019-11-04 09:58:40,787 epoch 5 lr 9.999846e-04
2019-11-04 09:58:41,972 train 000 1.096755e-02 -0.422885
2019-11-04 09:59:03,223 train 050 1.226925e-02 -0.299491
2019-11-04 09:59:24,417 train 100 1.210730e-02 -0.324144
2019-11-04 09:59:45,562 train 150 1.202290e-02 -0.279458
2019-11-04 10:00:06,655 train 200 1.198201e-02 -0.257497
2019-11-04 10:00:27,801 train 250 1.199610e-02 -0.248365
2019-11-04 10:00:48,825 train 300 1.200153e-02 -0.231348
2019-11-04 10:01:09,779 train 350 1.197549e-02 -0.231308
2019-11-04 10:01:30,818 train 400 1.198414e-02 -0.244927
2019-11-04 10:01:44,324 training loss; R2: 1.199444e-02 -0.475467
2019-11-04 10:01:45,322 valid 000 1.818000e-02 -0.237981
2019-11-04 10:02:04,425 validation loss; R2: 1.750269e-02 -0.346082
2019-11-04 10:02:04,534 epoch 6 lr 9.999778e-04
2019-11-04 10:02:05,749 train 000 1.226105e-02 -1.279521
2019-11-04 10:02:27,026 train 050 2.584050e-02 -0.340592
2019-11-04 10:02:48,145 train 100 3.050891e-02 -0.878005
2019-11-04 10:03:09,231 train 150 2.936971e-02 -0.934040
2019-11-04 10:03:30,320 train 200 2.780363e-02 -0.775772
2019-11-04 10:03:51,495 train 250 2.608930e-02 -0.674285
2019-11-04 10:04:12,625 train 300 2.472292e-02 -0.606235
2019-11-04 10:04:33,753 train 350 2.368404e-02 -0.554049
2019-11-04 10:04:54,817 train 400 2.281899e-02 -0.563172
2019-11-04 10:05:08,338 training loss; R2: 2.234729e-02 -0.533257
2019-11-04 10:05:09,359 valid 000 1.532523e-02 -0.240483
2019-11-04 10:05:28,405 validation loss; R2: 1.697557e-02 -0.462137
2019-11-04 10:05:28,511 epoch 7 lr 9.999698e-04
2019-11-04 10:05:29,638 train 000 1.696832e-02 -0.351341
2019-11-04 10:05:50,875 train 050 1.607300e-02 -0.350340
2019-11-04 10:06:11,970 train 100 1.582211e-02 -0.294695
2019-11-04 10:06:33,066 train 150 1.555161e-02 -0.290455
2019-11-04 10:06:54,079 train 200 1.532755e-02 -0.322721
2019-11-04 10:07:15,101 train 250 1.516918e-02 -0.326850
2019-11-04 10:07:36,100 train 300 1.513258e-02 -0.352208
2019-11-04 10:07:57,139 train 350 1.503630e-02 -0.329904
2019-11-04 10:08:18,114 train 400 1.489692e-02 -0.327756
2019-11-04 10:08:31,606 training loss; R2: 1.488863e-02 -0.327637
2019-11-04 10:08:32,598 valid 000 1.973115e-02 -0.301343
2019-11-04 10:08:51,792 validation loss; R2: 2.085689e-02 -0.504817
2019-11-04 10:08:51,906 epoch 8 lr 9.999605e-04
2019-11-04 10:08:53,126 train 000 1.580524e-02 -0.126503
2019-11-04 10:09:14,200 train 050 1.801460e-02 -0.490223
2019-11-04 10:09:35,285 train 100 1.638064e-02 -0.448732
2019-11-04 10:09:56,370 train 150 1.558412e-02 -0.395402
2019-11-04 10:10:17,475 train 200 1.508109e-02 -0.387810
2019-11-04 10:10:38,652 train 250 1.479037e-02 -0.387956
2019-11-04 10:10:59,769 train 300 1.452122e-02 -0.382428
2019-11-04 10:11:20,806 train 350 1.439758e-02 -0.365366
2019-11-04 10:11:41,849 train 400 1.424217e-02 -0.353512
2019-11-04 10:11:55,357 training loss; R2: 1.417358e-02 -0.338738
2019-11-04 10:11:56,403 valid 000 1.252330e-02 0.013246
2019-11-04 10:12:15,708 validation loss; R2: 1.325946e-02 -0.160063
2019-11-04 10:12:15,809 epoch 9 lr 9.999500e-04
2019-11-04 10:12:16,986 train 000 1.392670e-02 -0.151731
2019-11-04 10:12:38,606 train 050 1.332718e-02 -0.326198
2019-11-04 10:12:59,767 train 100 1.342234e-02 -0.268190
2019-11-04 10:13:20,673 train 150 1.325726e-02 -0.272731
2019-11-04 10:13:41,698 train 200 1.312664e-02 -0.270156
2019-11-04 10:14:02,668 train 250 1.305256e-02 -0.261851
2019-11-04 10:14:23,813 train 300 1.306374e-02 -0.249951
2019-11-04 10:14:44,942 train 350 1.305427e-02 -0.257618
2019-11-04 10:15:05,955 train 400 1.298157e-02 -0.246285
2019-11-04 10:15:19,387 training loss; R2: 1.294483e-02 -0.255243
2019-11-04 10:15:20,411 valid 000 2.030772e-02 -0.702888
2019-11-04 10:15:39,547 validation loss; R2: 1.880590e-02 -1.058201
2019-11-04 10:15:39,667 epoch 10 lr 9.999383e-04
2019-11-04 10:15:40,794 train 000 1.172285e-02 -0.190891
2019-11-04 10:16:02,222 train 050 1.257377e-02 -0.304479
2019-11-04 10:16:23,601 train 100 1.248605e-02 -0.398637
2019-11-04 10:16:45,165 train 150 1.242313e-02 -0.336350
2019-11-04 10:17:06,719 train 200 1.296216e-02 -0.350540
2019-11-04 10:17:28,306 train 250 1.293248e-02 -0.375370
2019-11-04 10:17:49,829 train 300 1.292135e-02 -0.377615
2019-11-04 10:18:11,145 train 350 1.291658e-02 -0.364108
2019-11-04 10:18:32,511 train 400 1.287832e-02 -0.345508
2019-11-04 10:18:46,342 training loss; R2: 1.285163e-02 -0.337390
2019-11-04 10:18:47,413 valid 000 1.229071e-02 -0.104294
2019-11-04 10:19:06,513 validation loss; R2: 1.239627e-02 -0.323386
2019-11-04 10:19:06,619 epoch 11 lr 9.999254e-04
2019-11-04 10:19:07,775 train 000 1.274717e-02 -0.771505
2019-11-04 10:19:29,152 train 050 1.273936e-02 -0.331393
2019-11-04 10:19:50,410 train 100 1.256718e-02 -0.274167
2019-11-04 10:20:11,552 train 150 1.246980e-02 -0.284747
2019-11-04 10:20:32,707 train 200 1.245547e-02 -0.300411
2019-11-04 10:20:53,854 train 250 1.240706e-02 -0.315461
2019-11-04 10:21:15,047 train 300 1.237357e-02 -0.299922
2019-11-04 10:21:36,117 train 350 1.245477e-02 -0.270029
2019-11-04 10:21:57,225 train 400 1.244974e-02 -0.284471
2019-11-04 10:22:10,823 training loss; R2: 1.241246e-02 -0.295194
2019-11-04 10:22:11,895 valid 000 1.145590e-02 0.081043
2019-11-04 10:22:30,862 validation loss; R2: 1.212470e-02 -0.075294
2019-11-04 10:22:30,963 epoch 12 lr 9.999112e-04
2019-11-04 10:22:32,174 train 000 1.162068e-02 0.115978
2019-11-04 10:22:53,431 train 050 1.238566e-02 -0.184462
2019-11-04 10:23:14,484 train 100 1.241457e-02 -0.207064
2019-11-04 10:23:35,513 train 150 1.229555e-02 -0.268214
2019-11-04 10:23:56,597 train 200 1.224505e-02 -0.275698
2019-11-04 10:24:17,692 train 250 1.223279e-02 -0.278851
2019-11-04 10:24:38,814 train 300 1.223817e-02 -0.275514
2019-11-04 10:24:59,988 train 350 1.238938e-02 -0.265622
2019-11-04 10:25:21,248 train 400 1.242452e-02 -0.266514
2019-11-04 10:25:34,777 training loss; R2: 1.239908e-02 -0.262729
2019-11-04 10:25:35,817 valid 000 1.440711e-02 0.112386
2019-11-04 10:25:54,780 validation loss; R2: 1.437476e-02 0.032878
2019-11-04 10:25:54,885 epoch 13 lr 9.998958e-04
2019-11-04 10:25:56,101 train 000 1.322633e-02 0.076686
2019-11-04 10:26:17,591 train 050 1.231054e-02 -0.326764
2019-11-04 10:26:39,109 train 100 1.225509e-02 -0.326365
2019-11-04 10:27:00,469 train 150 1.217387e-02 -0.352821
2019-11-04 10:27:21,568 train 200 1.211938e-02 -0.339958
2019-11-04 10:27:42,806 train 250 1.210749e-02 -0.313723
2019-11-04 10:28:04,060 train 300 1.208643e-02 -0.303147
2019-11-04 10:28:25,207 train 350 1.207842e-02 -0.294738
2019-11-04 10:28:46,173 train 400 1.206527e-02 -0.291150
2019-11-04 10:28:59,654 training loss; R2: 1.204553e-02 -0.276833
2019-11-04 10:29:00,683 valid 000 1.329871e-02 -0.356900
2019-11-04 10:29:19,691 validation loss; R2: 1.290911e-02 -0.686943
2019-11-04 10:29:19,784 epoch 14 lr 9.998791e-04
2019-11-04 10:29:20,998 train 000 1.289432e-02 -0.145450
2019-11-04 10:29:41,907 train 050 1.215076e-02 -0.238331
2019-11-04 10:30:03,191 train 100 1.208072e-02 -0.257882
2019-11-04 10:30:24,156 train 150 1.203893e-02 -0.245935
2019-11-04 10:30:45,229 train 200 1.190891e-02 -0.215793
2019-11-04 10:31:06,530 train 250 1.188276e-02 -0.233703
2019-11-04 10:31:27,787 train 300 1.185743e-02 -0.227117
2019-11-04 10:31:48,802 train 350 1.184463e-02 -0.244187
2019-11-04 10:32:09,781 train 400 1.186378e-02 -0.246920
2019-11-04 10:32:23,166 training loss; R2: 1.189410e-02 -0.250114
2019-11-04 10:32:24,212 valid 000 1.520429e-02 -0.099321
2019-11-04 10:32:43,221 validation loss; R2: 1.477689e-02 -0.236187
2019-11-04 10:32:43,327 epoch 15 lr 9.998612e-04
2019-11-04 10:32:44,551 train 000 1.325539e-02 -2.040818
2019-11-04 10:33:05,935 train 050 1.196305e-02 -0.239389
2019-11-04 10:33:27,050 train 100 1.189595e-02 -0.206550
2019-11-04 10:33:48,260 train 150 1.184487e-02 -0.256573
2019-11-04 10:34:09,428 train 200 1.185097e-02 -0.249676
2019-11-04 10:34:30,628 train 250 1.190127e-02 -0.219966
2019-11-04 10:34:51,733 train 300 1.191601e-02 -0.239410
2019-11-04 10:35:12,722 train 350 1.193200e-02 -0.246126
2019-11-04 10:35:33,783 train 400 1.194791e-02 -0.264451
2019-11-04 10:35:47,265 training loss; R2: 1.214084e-02 -0.264708
2019-11-04 10:35:48,357 valid 000 2.295405e-02 -0.084900
2019-11-04 10:36:07,392 validation loss; R2: 2.496137e-02 -0.153936
2019-11-04 10:36:07,499 epoch 16 lr 9.998421e-04
2019-11-04 10:36:08,741 train 000 1.624214e-02 0.146635
2019-11-04 10:36:29,995 train 050 9.034223e-02 -24.667850
2019-11-04 10:36:51,161 train 100 9.590310e-02 -29.370645
2019-11-04 10:37:12,350 train 150 9.817835e-02 -28.824057
2019-11-04 10:37:33,520 train 200 9.941343e-02 -23.870719
2019-11-04 10:37:54,671 train 250 1.002136e-01 -20.481913
2019-11-04 10:38:15,806 train 300 1.008160e-01 -17.895974
2019-11-04 10:38:36,996 train 350 1.011534e-01 -16.467739
2019-11-04 10:38:58,143 train 400 1.014603e-01 -15.001626
2019-11-04 10:39:11,614 training loss; R2: 1.016325e-01 -14.291351
2019-11-04 10:39:12,650 valid 000 1.053454e-01 -3.637855
2019-11-04 10:39:31,818 validation loss; R2: 1.049023e-01 -4.390098
2019-11-04 10:39:31,923 epoch 17 lr 9.998217e-04
2019-11-04 10:39:33,107 train 000 1.065234e-01 -3.740322
2019-11-04 10:39:54,306 train 050 1.066759e-01 -4.503157
2019-11-04 10:40:15,459 train 100 1.047819e-01 -5.546047
2019-11-04 10:40:36,574 train 150 1.043206e-01 -5.198509
2019-11-04 10:40:57,674 train 200 1.036861e-01 -6.122537
2019-11-04 10:41:18,759 train 250 1.035533e-01 -5.911839
2019-11-04 10:41:39,895 train 300 1.036328e-01 -5.772589
2019-11-04 10:42:01,024 train 350 1.035325e-01 -5.493717
2019-11-04 10:42:22,190 train 400 1.074441e-01 -6.231008
2019-11-04 10:42:35,698 training loss; R2: 1.075135e-01 -6.231181
2019-11-04 10:42:36,721 valid 000 1.292825e-01 -12.301484
2019-11-04 10:42:55,912 validation loss; R2: 1.237198e-01 -10.738657
2019-11-04 10:42:56,020 epoch 18 lr 9.998002e-04
2019-11-04 10:42:57,243 train 000 1.146528e-01 -7.755967
2019-11-04 10:43:18,608 train 050 1.076512e-01 -5.952866
2019-11-04 10:43:39,611 train 100 1.070535e-01 -5.831482
2019-11-04 10:44:00,748 train 150 1.087873e-01 -6.388145
2019-11-04 10:44:21,829 train 200 1.111792e-01 -6.672444
2019-11-04 10:44:43,007 train 250 1.099177e-01 -6.302941
2019-11-04 10:45:04,230 train 300 1.090839e-01 -8.823540
2019-11-04 10:45:25,424 train 350 1.083981e-01 -11.176690
2019-11-04 10:45:46,582 train 400 1.078911e-01 -13.710905
2019-11-04 10:45:59,963 training loss; R2: 1.076527e-01 -14.639321
2019-11-04 10:46:00,995 valid 000 1.027591e-01 -22.323236
2019-11-04 10:46:20,090 validation loss; R2: 1.049528e-01 -34.612631
2019-11-04 10:46:20,195 epoch 19 lr 9.997773e-04
2019-11-04 10:46:21,368 train 000 1.023586e-01 -35.366702
2019-11-04 10:46:43,011 train 050 1.050035e-01 -29.786172
2019-11-04 10:47:04,199 train 100 1.047105e-01 -28.776963
2019-11-04 10:47:25,378 train 150 1.046959e-01 -27.747147
2019-11-04 10:47:46,531 train 200 1.046431e-01 -27.758592
2019-11-04 10:48:07,652 train 250 1.046430e-01 -28.732038
2019-11-04 10:48:28,775 train 300 1.046257e-01 -29.237755
2019-11-04 10:48:49,846 train 350 1.046128e-01 -28.759840
2019-11-04 10:49:10,947 train 400 1.046353e-01 -28.860321
2019-11-04 10:49:24,416 training loss; R2: 1.046458e-01 -28.716843
2019-11-04 10:49:25,403 valid 000 1.029570e-01 -22.375713
2019-11-04 10:49:44,730 validation loss; R2: 1.049749e-01 -34.647533
2019-11-04 10:49:44,845 epoch 20 lr 9.997533e-04
2019-11-04 10:49:46,054 train 000 1.014384e-01 -14.353903
2019-11-04 10:50:07,306 train 050 1.047254e-01 -28.778188
2019-11-04 10:50:28,384 train 100 9.729517e-02 -26.103465
2019-11-04 10:50:49,340 train 150 9.319149e-02 -25.798852
2019-11-04 10:51:10,405 train 200 9.128864e-02 -25.285617
2019-11-04 10:51:31,429 train 250 9.016803e-02 -24.837845
2019-11-04 10:51:52,629 train 300 8.932969e-02 -25.241576
2019-11-04 10:52:13,840 train 350 8.864175e-02 -25.365902
2019-11-04 10:52:34,939 train 400 8.807132e-02 -25.292482
2019-11-04 10:52:48,048 training loss; R2: 8.776714e-02 -25.295250
2019-11-04 10:52:49,101 valid 000 8.290528e-02 -26.330176
2019-11-04 10:53:08,066 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 10:53:08,179 epoch 21 lr 9.997280e-04
2019-11-04 10:53:09,384 train 000 7.911001e-02 -23.923934
2019-11-04 10:53:30,647 train 050 8.466339e-02 -24.389432
2019-11-04 10:53:51,764 train 100 8.507622e-02 -24.425084
2019-11-04 10:54:12,849 train 150 8.520478e-02 -24.955400
2019-11-04 10:54:34,098 train 200 8.534888e-02 -24.615986
2019-11-04 10:54:55,349 train 250 8.523314e-02 -24.598848
2019-11-04 10:55:16,617 train 300 8.515786e-02 -24.257162
2019-11-04 10:55:37,922 train 350 8.515119e-02 -24.230043
2019-11-04 10:55:59,130 train 400 8.506157e-02 -24.400246
2019-11-04 10:56:12,561 training loss; R2: 8.503260e-02 -24.696389
2019-11-04 10:56:13,543 valid 000 8.290528e-02 -26.330176
2019-11-04 10:56:33,028 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 10:56:33,144 epoch 22 lr 9.997015e-04
2019-11-04 10:56:34,348 train 000 8.502207e-02 -24.165226
2019-11-04 10:56:55,848 train 050 8.570665e-02 -27.912391
2019-11-04 10:57:17,004 train 100 8.546750e-02 -24.947279
2019-11-04 10:57:38,141 train 150 8.979857e-02 -21.327648
2019-11-04 10:57:59,274 train 200 8.851375e-02 -22.173296
2019-11-04 10:58:20,381 train 250 8.782744e-02 -23.028241
2019-11-04 10:58:41,520 train 300 8.725027e-02 -23.301511
2019-11-04 10:59:02,633 train 350 8.687825e-02 -23.564001
2019-11-04 10:59:23,708 train 400 8.658138e-02 -23.529193
2019-11-04 10:59:36,889 training loss; R2: 8.650262e-02 -23.431043
2019-11-04 10:59:37,996 valid 000 8.290528e-02 -26.330176
2019-11-04 10:59:57,045 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 10:59:57,152 epoch 23 lr 9.996737e-04
2019-11-04 10:59:58,358 train 000 9.024461e-02 -28.840161
2019-11-04 11:00:19,496 train 050 8.449318e-02 -25.110335
2019-11-04 11:00:40,477 train 100 8.433988e-02 -24.339546
2019-11-04 11:01:01,494 train 150 8.453720e-02 -24.431559
2019-11-04 11:01:22,526 train 200 8.470596e-02 -24.248906
2019-11-04 11:01:43,574 train 250 8.460624e-02 -24.395951
2019-11-04 11:02:04,572 train 300 8.460774e-02 -24.375965
2019-11-04 11:02:25,546 train 350 8.473242e-02 -24.361900
2019-11-04 11:02:46,522 train 400 8.480426e-02 -24.729578
2019-11-04 11:02:59,932 training loss; R2: 8.484099e-02 -24.876256
2019-11-04 11:03:01,003 valid 000 8.290790e-02 -26.330244
2019-11-04 11:03:20,154 validation loss; R2: 8.442407e-02 -24.544897
2019-11-04 11:03:20,259 epoch 24 lr 9.996447e-04
2019-11-04 11:03:21,422 train 000 8.183108e-02 -30.128011
2019-11-04 11:03:42,645 train 050 8.494376e-02 -23.906814
2019-11-04 11:04:03,653 train 100 8.681427e-02 -22.883263
2019-11-04 11:04:24,540 train 150 8.793447e-02 -22.346664
2019-11-04 11:04:45,576 train 200 8.715789e-02 -23.421572
2019-11-04 11:05:06,591 train 250 8.676419e-02 -23.148581
2019-11-04 11:05:27,744 train 300 8.669313e-02 -23.823714
2019-11-04 11:05:48,946 train 350 8.661515e-02 -23.731871
2019-11-04 11:06:09,892 train 400 8.641085e-02 -23.907170
2019-11-04 11:06:23,116 training loss; R2: 8.627577e-02 -24.113537
2019-11-04 11:06:24,152 valid 000 8.290528e-02 -26.330176
2019-11-04 11:06:43,318 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:06:43,424 epoch 25 lr 9.996145e-04
2019-11-04 11:06:44,664 train 000 8.779966e-02 -4.541329
2019-11-04 11:07:05,726 train 050 8.490102e-02 -24.198501
2019-11-04 11:07:26,633 train 100 8.476436e-02 -25.373893
2019-11-04 11:07:47,541 train 150 8.453637e-02 -24.210365
2019-11-04 11:08:08,605 train 200 8.477164e-02 -24.569569
2019-11-04 11:08:29,642 train 250 8.474938e-02 -24.363462
2019-11-04 11:08:50,722 train 300 8.449664e-02 -24.081302
2019-11-04 11:09:11,791 train 350 8.448186e-02 -24.019811
2019-11-04 11:09:32,886 train 400 8.460018e-02 -24.033620
2019-11-04 11:09:46,265 training loss; R2: 8.462516e-02 -24.172516
2019-11-04 11:09:47,278 valid 000 8.290528e-02 -26.330176
2019-11-04 11:10:06,378 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:10:06,487 epoch 26 lr 9.995831e-04
2019-11-04 11:10:07,654 train 000 8.640060e-02 -25.393090
2019-11-04 11:10:28,723 train 050 8.513072e-02 -22.707950
2019-11-04 11:10:49,789 train 100 8.489268e-02 -23.513146
2019-11-04 11:11:10,843 train 150 8.607468e-02 -23.263972
2019-11-04 11:11:31,901 train 200 8.591359e-02 -23.621603
2019-11-04 11:11:52,948 train 250 8.594786e-02 -24.149953
2019-11-04 11:12:13,995 train 300 8.579500e-02 -24.212249
2019-11-04 11:12:34,968 train 350 8.565052e-02 -24.260313
2019-11-04 11:12:55,952 train 400 8.554214e-02 -24.292413
2019-11-04 11:13:09,384 training loss; R2: 8.547688e-02 -24.299032
2019-11-04 11:13:10,381 valid 000 8.290528e-02 -26.330176
2019-11-04 11:13:29,473 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:13:29,583 epoch 27 lr 9.995504e-04
2019-11-04 11:13:30,753 train 000 8.669375e-02 -12.784939
2019-11-04 11:13:52,062 train 050 8.548407e-02 -27.200363
2019-11-04 11:14:13,254 train 100 8.556518e-02 -24.486784
2019-11-04 11:14:34,428 train 150 8.534827e-02 -24.607875
2019-11-04 11:14:55,611 train 200 8.547379e-02 -24.144739
2019-11-04 11:15:16,748 train 250 8.532208e-02 -23.112852
2019-11-04 11:15:37,829 train 300 8.526483e-02 -22.962169
2019-11-04 11:15:58,855 train 350 8.524527e-02 -23.144591
2019-11-04 11:16:19,997 train 400 8.526876e-02 -23.762113
2019-11-04 11:16:33,351 training loss; R2: 8.517473e-02 -23.756734
2019-11-04 11:16:34,382 valid 000 8.290528e-02 -26.330176
2019-11-04 11:16:53,642 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:16:53,747 epoch 28 lr 9.995165e-04
2019-11-04 11:16:54,976 train 000 8.870790e-02 -29.872122
2019-11-04 11:17:16,160 train 050 8.492300e-02 -23.548312
2019-11-04 11:17:37,241 train 100 8.504593e-02 -23.272301
2019-11-04 11:17:58,285 train 150 8.504607e-02 -24.049213
2019-11-04 11:18:19,524 train 200 8.614199e-02 -22.907712
2019-11-04 11:18:40,660 train 250 9.079070e-02 -19.350896
2019-11-04 11:19:01,901 train 300 9.303616e-02 -16.780198
2019-11-04 11:19:23,114 train 350 9.452210e-02 -14.996726
2019-11-04 11:19:44,210 train 400 9.562553e-02 -13.726172
2019-11-04 11:19:57,492 training loss; R2: 9.624249e-02 -13.026599
2019-11-04 11:19:58,589 valid 000 1.026617e-01 -4.665574
2019-11-04 11:20:17,918 validation loss; R2: 1.029104e-01 -4.612697
2019-11-04 11:20:18,036 epoch 29 lr 9.994813e-04
2019-11-04 11:20:19,251 train 000 1.068061e-01 -4.241774
2019-11-04 11:20:40,784 train 050 1.038003e-01 -5.004204
2019-11-04 11:21:02,035 train 100 9.747383e-02 -11.186514
2019-11-04 11:21:23,250 train 150 9.331266e-02 -15.751513
2019-11-04 11:21:44,439 train 200 9.121142e-02 -18.174609
2019-11-04 11:22:05,614 train 250 9.005398e-02 -19.466054
2019-11-04 11:22:26,726 train 300 8.920330e-02 -20.599829
2019-11-04 11:22:47,809 train 350 8.853683e-02 -21.197028
2019-11-04 11:23:08,828 train 400 8.810432e-02 -21.540821
2019-11-04 11:23:22,135 training loss; R2: 8.787114e-02 -21.562160
2019-11-04 11:23:23,195 valid 000 8.290528e-02 -26.330176
2019-11-04 11:23:42,364 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:23:42,467 epoch 30 lr 9.994449e-04
2019-11-04 11:23:43,628 train 000 8.056683e-02 -23.802649
2019-11-04 11:24:04,854 train 050 8.543550e-02 -21.135144
2019-11-04 11:24:25,971 train 100 8.522845e-02 -22.409654
2019-11-04 11:24:46,997 train 150 8.517260e-02 -23.292839
2019-11-04 11:25:08,100 train 200 8.502256e-02 -23.057408
2019-11-04 11:25:29,169 train 250 8.497122e-02 -23.266085
2019-11-04 11:25:50,306 train 300 8.490094e-02 -23.722538
2019-11-04 11:26:11,433 train 350 8.517344e-02 -23.289898
2019-11-04 11:26:32,538 train 400 8.534505e-02 -23.437882
2019-11-04 11:26:45,727 training loss; R2: 8.584126e-02 -23.515091
2019-11-04 11:26:46,696 valid 000 9.763511e-02 -17.532093
2019-11-04 11:27:05,922 validation loss; R2: 9.942132e-02 -16.947618
2019-11-04 11:27:06,036 epoch 31 lr 9.994073e-04
2019-11-04 11:27:07,163 train 000 9.396172e-02 -32.696069
2019-11-04 11:27:28,281 train 050 8.764062e-02 -25.635017
2019-11-04 11:27:49,282 train 100 8.747415e-02 -24.556800
2019-11-04 11:28:10,246 train 150 8.746848e-02 -24.006767
2019-11-04 11:28:31,354 train 200 8.714254e-02 -24.819331
2019-11-04 11:28:52,491 train 250 8.690273e-02 -24.413267
2019-11-04 11:29:13,629 train 300 8.666088e-02 -24.253722
2019-11-04 11:29:34,687 train 350 8.640847e-02 -24.310350
2019-11-04 11:29:55,817 train 400 8.619811e-02 -24.296432
2019-11-04 11:30:09,105 training loss; R2: 8.612338e-02 -24.098427
2019-11-04 11:30:10,076 valid 000 8.290528e-02 -26.330176
2019-11-04 11:30:29,171 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:30:29,278 epoch 32 lr 9.993685e-04
2019-11-04 11:30:30,386 train 000 8.335538e-02 -35.062052
2019-11-04 11:30:51,594 train 050 8.484949e-02 -25.874818
2019-11-04 11:31:12,766 train 100 8.471849e-02 -25.247839
2019-11-04 11:31:33,800 train 150 8.484138e-02 -24.538749
2019-11-04 11:31:54,839 train 200 8.501350e-02 -24.288147
2019-11-04 11:32:15,968 train 250 8.496669e-02 -24.465448
2019-11-04 11:32:37,089 train 300 8.497026e-02 -24.196490
2019-11-04 11:32:58,080 train 350 8.964791e-02 -25.611880
2019-11-04 11:33:18,984 train 400 9.862703e-02 -28.665918
2019-11-04 11:33:32,297 training loss; R2: 1.032967e-01 -31.138110
2019-11-04 11:33:33,336 valid 000 1.583837e-01 -29.901633
2019-11-04 11:33:52,576 validation loss; R2: 1.621172e-01 -71.318596
2019-11-04 11:33:52,681 epoch 33 lr 9.993284e-04
2019-11-04 11:33:53,805 train 000 1.624801e-01 -25.173758
2019-11-04 11:34:15,150 train 050 1.611388e-01 -48.659945
2019-11-04 11:34:36,402 train 100 1.612876e-01 -49.695190
2019-11-04 11:34:57,608 train 150 1.614433e-01 -49.654833
2019-11-04 11:35:18,774 train 200 1.614923e-01 -49.868207
2019-11-04 11:35:39,902 train 250 1.614178e-01 -53.540116
2019-11-04 11:36:01,046 train 300 1.612794e-01 -52.553082
2019-11-04 11:36:21,989 train 350 1.612478e-01 -52.756945
2019-11-04 11:36:42,988 train 400 1.612870e-01 -52.321000
2019-11-04 11:36:56,508 training loss; R2: 1.599342e-01 -50.803897
2019-11-04 11:36:57,539 valid 000 8.290528e-02 -26.330176
2019-11-04 11:37:16,770 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:37:16,879 epoch 34 lr 9.992871e-04
2019-11-04 11:37:18,012 train 000 9.016963e-02 -24.864343
2019-11-04 11:37:39,343 train 050 8.615401e-02 -26.509448
2019-11-04 11:38:00,445 train 100 8.578514e-02 -24.318262
2019-11-04 11:38:21,584 train 150 8.568288e-02 -24.420485
2019-11-04 11:38:42,807 train 200 8.561934e-02 -24.746737
2019-11-04 11:39:03,920 train 250 8.595908e-02 -24.136454
2019-11-04 11:39:24,921 train 300 8.645845e-02 -23.558277
2019-11-04 11:39:45,915 train 350 8.615003e-02 -23.894681
2019-11-04 11:40:06,938 train 400 8.597570e-02 -24.040499
2019-11-04 11:40:20,319 training loss; R2: 8.593384e-02 -23.753667
2019-11-04 11:40:21,394 valid 000 8.290528e-02 -26.330176
2019-11-04 11:40:41,135 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:40:41,249 epoch 35 lr 9.992445e-04
2019-11-04 11:40:42,447 train 000 8.370421e-02 -21.980724
2019-11-04 11:41:03,676 train 050 8.493965e-02 -26.322316
2019-11-04 11:41:24,932 train 100 8.444681e-02 -24.776503
2019-11-04 11:41:46,083 train 150 8.481259e-02 -24.917294
2019-11-04 11:42:07,242 train 200 8.488180e-02 -24.572996
2019-11-04 11:42:28,244 train 250 8.490675e-02 -24.590093
2019-11-04 11:42:49,235 train 300 8.503788e-02 -24.312215
2019-11-04 11:43:10,341 train 350 8.517210e-02 -24.116870
2019-11-04 11:43:31,396 train 400 8.546487e-02 -23.683663
2019-11-04 11:43:44,828 training loss; R2: 8.545320e-02 -23.669156
2019-11-04 11:43:45,943 valid 000 8.290528e-02 -26.330176
2019-11-04 11:44:05,397 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:44:05,502 epoch 36 lr 9.992008e-04
2019-11-04 11:44:06,714 train 000 9.180370e-02 -21.636891
2019-11-04 11:44:27,819 train 050 8.551348e-02 -23.131690
2019-11-04 11:44:48,819 train 100 8.564633e-02 -23.245861
2019-11-04 11:45:09,816 train 150 8.584701e-02 -23.555302
2019-11-04 11:45:30,816 train 200 8.618986e-02 -23.701836
2019-11-04 11:45:51,957 train 250 8.895268e-02 -21.380346
2019-11-04 11:46:13,054 train 300 9.104805e-02 -18.258206
2019-11-04 11:46:34,105 train 350 9.249739e-02 -16.016411
2019-11-04 11:46:54,976 train 400 9.366376e-02 -14.338265
2019-11-04 11:47:08,333 training loss; R2: 9.426836e-02 -13.482782
2019-11-04 11:47:09,403 valid 000 1.004478e-01 -2.489664
2019-11-04 11:47:29,323 validation loss; R2: 1.022349e-01 -2.688078
2019-11-04 11:47:29,418 epoch 37 lr 9.991558e-04
2019-11-04 11:47:30,669 train 000 1.022464e-01 -2.504393
2019-11-04 11:47:51,958 train 050 1.015779e-01 -2.496438
2019-11-04 11:48:13,185 train 100 1.015644e-01 -2.467722
2019-11-04 11:48:34,374 train 150 1.014421e-01 -2.478076
2019-11-04 11:48:55,546 train 200 1.015595e-01 -2.488796
2019-11-04 11:49:16,679 train 250 1.014916e-01 -2.496769
2019-11-04 11:49:37,796 train 300 1.016344e-01 -2.503974
2019-11-04 11:49:58,881 train 350 1.016845e-01 -2.656596
2019-11-04 11:50:19,679 train 400 1.003201e-01 -4.534447
2019-11-04 11:50:32,849 training loss; R2: 9.916960e-02 -5.976555
2019-11-04 11:50:33,919 valid 000 8.290528e-02 -26.330176
2019-11-04 11:50:53,316 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:50:53,424 epoch 38 lr 9.991095e-04
2019-11-04 11:50:54,586 train 000 8.407708e-02 -20.916666
2019-11-04 11:51:15,820 train 050 8.522309e-02 -23.704358
2019-11-04 11:51:36,945 train 100 8.492059e-02 -23.129817
2019-11-04 11:51:58,078 train 150 8.494476e-02 -24.125587
2019-11-04 11:52:19,081 train 200 8.726932e-02 -22.192690
2019-11-04 11:52:40,181 train 250 9.061951e-02 -18.709774
2019-11-04 11:53:01,379 train 300 9.274946e-02 -16.360203
2019-11-04 11:53:22,616 train 350 9.417327e-02 -14.638122
2019-11-04 11:53:43,496 train 400 9.532727e-02 -13.312506
2019-11-04 11:53:56,816 training loss; R2: 9.588262e-02 -12.641769
2019-11-04 11:53:57,886 valid 000 1.019562e-01 -3.466040
2019-11-04 11:54:17,191 validation loss; R2: 1.037604e-01 -4.299891
2019-11-04 11:54:17,296 epoch 39 lr 9.990621e-04
2019-11-04 11:54:18,509 train 000 1.053017e-01 -5.143390
2019-11-04 11:54:39,675 train 050 1.027932e-01 -4.564270
2019-11-04 11:55:00,811 train 100 1.025666e-01 -4.910250
2019-11-04 11:55:21,880 train 150 1.023432e-01 -4.679625
2019-11-04 11:55:42,963 train 200 1.028486e-01 -4.623572
2019-11-04 11:56:04,110 train 250 1.006946e-01 -6.640153
2019-11-04 11:56:25,218 train 300 9.810771e-02 -9.696432
2019-11-04 11:56:46,345 train 350 9.615383e-02 -12.314025
2019-11-04 11:57:07,255 train 400 9.486709e-02 -13.734569
2019-11-04 11:57:20,655 training loss; R2: 9.420217e-02 -14.576422
2019-11-04 11:57:21,679 valid 000 8.290528e-02 -26.330176
2019-11-04 11:57:41,067 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 11:57:41,172 epoch 40 lr 9.990134e-04
2019-11-04 11:57:42,375 train 000 8.233454e-02 -22.773601
2019-11-04 11:58:03,558 train 050 8.608232e-02 -25.303795
2019-11-04 11:58:24,578 train 100 8.594563e-02 -24.276245
2019-11-04 11:58:45,665 train 150 8.646218e-02 -22.289100
2019-11-04 11:59:06,731 train 200 8.690496e-02 -21.378441
2019-11-04 11:59:27,913 train 250 8.675365e-02 -21.393269
2019-11-04 11:59:49,111 train 300 8.644832e-02 -21.591500
2019-11-04 12:00:10,311 train 350 8.623247e-02 -22.132914
2019-11-04 12:00:31,239 train 400 8.602842e-02 -22.488726
2019-11-04 12:00:44,694 training loss; R2: 8.599263e-02 -22.617046
2019-11-04 12:00:45,783 valid 000 8.276397e-02 -26.263857
2019-11-04 12:01:05,282 validation loss; R2: 8.436977e-02 -24.507651
2019-11-04 12:01:05,394 epoch 41 lr 9.989634e-04
2019-11-04 12:01:06,584 train 000 8.940746e-02 -22.390030
2019-11-04 12:01:27,824 train 050 8.448531e-02 -23.894775
2019-11-04 12:01:48,887 train 100 8.447440e-02 -23.881391
2019-11-04 12:02:09,923 train 150 8.545803e-02 -22.513102
2019-11-04 12:02:30,971 train 200 8.523904e-02 -22.905136
2019-11-04 12:02:52,058 train 250 8.519382e-02 -23.346897
2019-11-04 12:03:13,189 train 300 8.566701e-02 -22.859677
2019-11-04 12:03:34,308 train 350 8.594058e-02 -22.615190
2019-11-04 12:03:55,146 train 400 8.706278e-02 -21.567581
2019-11-04 12:04:08,649 training loss; R2: 8.825647e-02 -20.311760
2019-11-04 12:04:09,683 valid 000 1.026617e-01 -4.665574
2019-11-04 12:04:28,848 validation loss; R2: 1.029104e-01 -4.612697
2019-11-04 12:04:28,951 epoch 42 lr 9.989123e-04
2019-11-04 12:04:30,080 train 000 1.050085e-01 -2.375416
2019-11-04 12:04:51,232 train 050 9.236352e-02 -16.517706
2019-11-04 12:05:12,295 train 100 8.881937e-02 -21.126018
2019-11-04 12:05:33,437 train 150 8.743775e-02 -22.534911
2019-11-04 12:05:54,574 train 200 8.670656e-02 -22.307686
2019-11-04 12:06:15,675 train 250 8.641904e-02 -23.230743
2019-11-04 12:06:36,755 train 300 8.619089e-02 -23.155193
2019-11-04 12:06:57,818 train 350 8.595244e-02 -23.434646
2019-11-04 12:07:18,655 train 400 8.587211e-02 -23.457782
2019-11-04 12:07:32,077 training loss; R2: 8.579200e-02 -23.496478
2019-11-04 12:07:33,067 valid 000 8.290528e-02 -26.330176
2019-11-04 12:07:52,273 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:07:52,396 epoch 43 lr 9.988599e-04
2019-11-04 12:07:53,509 train 000 8.548343e-02 -20.679939
2019-11-04 12:08:14,765 train 050 8.560674e-02 -23.223433
2019-11-04 12:08:35,879 train 100 8.582646e-02 -23.768922
2019-11-04 12:08:56,954 train 150 8.533248e-02 -23.564291
2019-11-04 12:09:17,988 train 200 8.519914e-02 -24.689166
2019-11-04 12:09:39,105 train 250 8.532100e-02 -24.896852
2019-11-04 12:10:00,102 train 300 8.524477e-02 -25.139721
2019-11-04 12:10:21,000 train 350 8.495446e-02 -25.011249
2019-11-04 12:10:41,803 train 400 8.492576e-02 -24.611115
2019-11-04 12:10:55,296 training loss; R2: 8.485960e-02 -24.499452
2019-11-04 12:10:56,313 valid 000 8.290528e-02 -26.330176
2019-11-04 12:11:15,800 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:11:15,919 epoch 44 lr 9.988063e-04
2019-11-04 12:11:17,096 train 000 8.144742e-02 -10.982869
2019-11-04 12:11:38,384 train 050 8.497801e-02 -25.227189
2019-11-04 12:11:59,581 train 100 8.635310e-02 -24.060820
2019-11-04 12:12:20,750 train 150 8.593025e-02 -25.076034
2019-11-04 12:12:41,832 train 200 8.562219e-02 -25.108836
2019-11-04 12:13:02,945 train 250 8.547681e-02 -24.987172
2019-11-04 12:13:24,060 train 300 8.531519e-02 -24.716033
2019-11-04 12:13:45,121 train 350 8.526916e-02 -24.364032
2019-11-04 12:14:05,875 train 400 8.525185e-02 -24.489894
2019-11-04 12:14:19,562 training loss; R2: 8.523724e-02 -24.380367
2019-11-04 12:14:20,581 valid 000 8.290528e-02 -26.330176
2019-11-04 12:14:39,882 validation loss; R2: 8.443607e-02 -24.540873
2019-11-04 12:14:39,987 epoch 45 lr 9.987514e-04
2019-11-04 12:14:41,181 train 000 8.863266e-02 -31.921956
2019-11-04 12:15:02,652 train 050 8.539943e-02 -24.468111
2019-11-04 12:15:23,687 train 100 8.584246e-02 -25.089593
2019-11-04 12:15:44,774 train 150 8.526704e-02 -24.096884
2019-11-04 12:16:05,890 train 200 8.513249e-02 -24.295787
2019-11-04 12:16:26,940 train 250 8.515125e-02 -23.809757
2019-11-04 12:16:47,937 train 300 8.523922e-02 -23.931084
2019-11-04 12:17:09,026 train 350 8.520323e-02 -24.368539
2019-11-04 12:17:30,085 train 400 8.514775e-02 -24.628259
2019-11-04 12:17:43,553 training loss; R2: 8.510031e-02 -24.722524
2019-11-04 12:17:44,629 valid 000 8.290528e-02 -26.330176
2019-11-04 12:18:03,872 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:18:03,988 epoch 46 lr 9.986953e-04
2019-11-04 12:18:05,220 train 000 8.771469e-02 -35.681481
2019-11-04 12:18:26,407 train 050 8.452072e-02 -26.566363
2019-11-04 12:18:47,587 train 100 8.478020e-02 -25.830690
2019-11-04 12:19:08,789 train 150 8.444472e-02 -25.360021
2019-11-04 12:19:29,688 train 200 8.457719e-02 -24.889108
2019-11-04 12:19:50,578 train 250 8.471767e-02 -24.938320
2019-11-04 12:20:11,654 train 300 8.481065e-02 -24.902140
2019-11-04 12:20:32,778 train 350 8.486922e-02 -24.970393
2019-11-04 12:20:53,685 train 400 8.486628e-02 -24.946505
2019-11-04 12:21:07,264 training loss; R2: 8.488810e-02 -24.719249
2019-11-04 12:21:08,308 valid 000 8.290528e-02 -26.330176
2019-11-04 12:21:27,746 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:21:27,851 epoch 47 lr 9.986380e-04
2019-11-04 12:21:29,069 train 000 8.311003e-02 -8.567034
2019-11-04 12:21:50,462 train 050 8.576550e-02 -22.400087
2019-11-04 12:22:11,751 train 100 8.537567e-02 -24.131709
2019-11-04 12:22:32,833 train 150 8.521285e-02 -24.909546
2019-11-04 12:22:54,099 train 200 8.523759e-02 -25.003810
2019-11-04 12:23:15,556 train 250 8.513524e-02 -24.779554
2019-11-04 12:23:36,732 train 300 8.508608e-02 -25.157651
2019-11-04 12:23:57,937 train 350 8.506701e-02 -24.761251
2019-11-04 12:24:18,844 train 400 8.498334e-02 -24.665096
2019-11-04 12:24:32,308 training loss; R2: 8.587727e-02 -23.324933
2019-11-04 12:24:33,395 valid 000 1.019562e-01 -3.466040
2019-11-04 12:24:52,541 validation loss; R2: 1.037604e-01 -4.299891
2019-11-04 12:24:52,652 epoch 48 lr 9.985795e-04
2019-11-04 12:24:53,854 train 000 1.053157e-01 -5.328340
2019-11-04 12:25:15,162 train 050 1.029495e-01 -4.580628
2019-11-04 12:25:36,345 train 100 1.030049e-01 -4.760156
2019-11-04 12:25:57,472 train 150 1.030294e-01 -4.950973
2019-11-04 12:26:18,611 train 200 1.031011e-01 -4.811832
2019-11-04 12:26:39,759 train 250 1.032682e-01 -4.803433
2019-11-04 12:27:00,870 train 300 1.032966e-01 -4.839073
2019-11-04 12:27:21,853 train 350 1.032029e-01 -4.781647
2019-11-04 12:27:42,607 train 400 1.033310e-01 -4.757083
2019-11-04 12:27:56,094 training loss; R2: 1.033378e-01 -4.747815
2019-11-04 12:27:57,158 valid 000 1.019562e-01 -3.466040
2019-11-04 12:28:16,300 validation loss; R2: 1.037604e-01 -4.299891
2019-11-04 12:28:16,392 epoch 49 lr 9.985197e-04
2019-11-04 12:28:17,511 train 000 1.048022e-01 -4.299235
2019-11-04 12:28:38,684 train 050 1.034601e-01 -4.332087
2019-11-04 12:28:59,710 train 100 1.036589e-01 -4.357050
2019-11-04 12:29:20,774 train 150 1.038113e-01 -4.722759
2019-11-04 12:29:41,715 train 200 1.010403e-01 -7.240245
2019-11-04 12:30:02,825 train 250 9.803904e-02 -10.723732
2019-11-04 12:30:23,900 train 300 9.583095e-02 -13.079654
2019-11-04 12:30:44,990 train 350 9.428884e-02 -14.517006
2019-11-04 12:31:05,874 train 400 9.316692e-02 -15.831976
2019-11-04 12:31:19,640 training loss; R2: 9.263023e-02 -16.373241
2019-11-04 12:31:20,716 valid 000 8.290528e-02 -26.330176
2019-11-04 12:31:40,895 validation loss; R2: 8.444314e-02 -24.529602
2019-11-04 12:31:41,001 epoch 50 lr 9.984587e-04
2019-11-04 12:31:42,199 train 000 8.553968e-02 -47.347296
2019-11-04 12:32:03,517 train 050 8.712572e-02 -23.405865
2019-11-04 12:32:24,670 train 100 8.650538e-02 -23.233303
2019-11-04 12:32:45,781 train 150 8.598035e-02 -23.480144
2019-11-04 12:33:06,937 train 200 8.579231e-02 -23.714898
2019-11-04 12:33:28,054 train 250 8.577728e-02 -23.814955
2019-11-04 12:33:49,128 train 300 8.719964e-02 -22.131380
2019-11-04 12:34:10,174 train 350 8.939368e-02 -19.548686
2019-11-04 12:34:31,089 train 400 9.122802e-02 -17.685075
2019-11-04 12:34:44,639 training loss; R2: 9.208146e-02 -16.704715
2019-11-04 12:34:45,714 valid 000 1.019562e-01 -3.466040
2019-11-04 12:35:05,761 validation loss; R2: 1.037604e-01 -4.299891
2019-11-04 12:35:05,869 epoch 51 lr 9.983964e-04
2019-11-04 12:35:07,029 train 000 1.042234e-01 -6.856781
2019-11-04 12:35:28,198 train 050 1.035046e-01 -4.873699
2019-11-04 12:35:49,274 train 100 1.034539e-01 -4.888414
2019-11-04 12:36:10,484 train 150 1.015538e-01 -6.584933
2019-11-04 12:36:31,669 train 200 9.753902e-02 -11.100281
2019-11-04 12:36:52,693 train 250 9.495634e-02 -13.684813
2019-11-04 12:37:13,668 train 300 9.322638e-02 -15.986538
2019-11-04 12:37:34,613 train 350 9.208387e-02 -17.379675
2019-11-04 12:37:55,226 train 400 9.120982e-02 -18.364906
2019-11-04 12:38:08,817 training loss; R2: 9.073116e-02 -18.656022
2019-11-04 12:38:09,884 valid 000 8.290528e-02 -26.330176
2019-11-04 12:38:29,463 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:38:29,568 epoch 52 lr 9.983330e-04
2019-11-04 12:38:30,720 train 000 8.458438e-02 -17.344806
2019-11-04 12:38:52,242 train 050 8.465059e-02 -25.524019
2019-11-04 12:39:13,452 train 100 8.511586e-02 -24.973473
2019-11-04 12:39:34,783 train 150 8.514907e-02 -25.057418
2019-11-04 12:39:56,085 train 200 8.497750e-02 -24.711878
2019-11-04 12:40:17,337 train 250 8.498455e-02 -24.566699
2019-11-04 12:40:38,535 train 300 8.495794e-02 -24.501852
2019-11-04 12:40:59,535 train 350 8.502017e-02 -24.701869
2019-11-04 12:41:19,856 train 400 8.497250e-02 -24.760968
2019-11-04 12:41:33,202 training loss; R2: 8.490147e-02 -24.696588
2019-11-04 12:41:34,239 valid 000 8.290528e-02 -26.330176
2019-11-04 12:41:53,090 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:41:53,200 epoch 53 lr 9.982683e-04
2019-11-04 12:41:54,328 train 000 9.346402e-02 -63.475091
2019-11-04 12:42:15,216 train 050 8.445784e-02 -24.727663
2019-11-04 12:42:36,167 train 100 8.458283e-02 -25.271750
2019-11-04 12:42:57,208 train 150 8.574360e-02 -24.181729
2019-11-04 12:43:18,217 train 200 8.586928e-02 -23.556431
2019-11-04 12:43:39,223 train 250 8.589927e-02 -22.973928
2019-11-04 12:44:00,230 train 300 8.589452e-02 -23.040114
2019-11-04 12:44:21,200 train 350 8.587659e-02 -23.419890
2019-11-04 12:44:41,697 train 400 8.595369e-02 -23.240918
2019-11-04 12:44:55,252 training loss; R2: 8.610522e-02 -23.329377
2019-11-04 12:44:56,306 valid 000 8.670855e-02 -22.127444
2019-11-04 12:45:15,479 validation loss; R2: 8.761422e-02 -21.117578
2019-11-04 12:45:15,583 epoch 54 lr 9.982023e-04
2019-11-04 12:45:16,703 train 000 8.706061e-02 -18.435672
2019-11-04 12:45:37,966 train 050 8.508119e-02 -25.400203
2019-11-04 12:45:59,062 train 100 8.499317e-02 -26.061328
2019-11-04 12:46:20,116 train 150 8.500908e-02 -25.194988
2019-11-04 12:46:41,196 train 200 8.500274e-02 -24.667447
2019-11-04 12:47:02,285 train 250 8.503299e-02 -25.006506
2019-11-04 12:47:23,315 train 300 8.501817e-02 -25.098653
2019-11-04 12:47:44,299 train 350 8.501027e-02 -25.007664
2019-11-04 12:48:04,847 train 400 8.497490e-02 -24.836254
2019-11-04 12:48:18,482 training loss; R2: 8.492393e-02 -24.776633
2019-11-04 12:48:19,569 valid 000 8.286270e-02 -26.305449
2019-11-04 12:48:39,161 validation loss; R2: 8.439286e-02 -24.521619
2019-11-04 12:48:39,268 epoch 55 lr 9.981352e-04
2019-11-04 12:48:40,454 train 000 8.684999e-02 -6.358925
2019-11-04 12:49:01,477 train 050 8.591928e-02 -23.368829
2019-11-04 12:49:22,491 train 100 8.585811e-02 -24.375048
2019-11-04 12:49:43,560 train 150 8.569316e-02 -24.904880
2019-11-04 12:50:04,747 train 200 8.560213e-02 -25.706683
2019-11-04 12:50:25,852 train 250 8.530312e-02 -24.976059
2019-11-04 12:50:46,938 train 300 8.525744e-02 -24.602126
2019-11-04 12:51:07,956 train 350 8.517562e-02 -24.373681
2019-11-04 12:51:28,738 train 400 8.519056e-02 -24.452954
2019-11-04 12:51:42,294 training loss; R2: 8.517175e-02 -24.402603
2019-11-04 12:51:43,368 valid 000 8.290528e-02 -26.330176
2019-11-04 12:52:02,644 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:52:02,744 epoch 56 lr 9.980668e-04
2019-11-04 12:52:03,933 train 000 8.627546e-02 -27.162198
2019-11-04 12:52:25,339 train 050 8.505944e-02 -24.272202
2019-11-04 12:52:46,493 train 100 8.365702e-02 -22.752362
2019-11-04 12:53:07,684 train 150 8.414574e-02 -23.586958
2019-11-04 12:53:28,795 train 200 8.433487e-02 -24.057196
2019-11-04 12:53:49,970 train 250 8.445491e-02 -24.396321
2019-11-04 12:54:11,007 train 300 8.455515e-02 -24.402131
2019-11-04 12:54:32,031 train 350 8.464384e-02 -24.175671
2019-11-04 12:54:52,757 train 400 8.580944e-02 -23.704893
2019-11-04 12:55:06,267 training loss; R2: 8.592989e-02 -23.328485
2019-11-04 12:55:07,347 valid 000 8.290528e-02 -26.330176
2019-11-04 12:55:26,745 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 12:55:26,852 epoch 57 lr 9.979972e-04
2019-11-04 12:55:28,064 train 000 8.284556e-02 -44.640987
2019-11-04 12:55:49,364 train 050 8.429267e-02 -25.083729
2019-11-04 12:56:10,485 train 100 8.440857e-02 -23.492720
2019-11-04 12:56:31,490 train 150 8.488108e-02 -23.625011
2019-11-04 12:56:52,542 train 200 8.494198e-02 -23.862428
2019-11-04 12:57:13,501 train 250 8.492951e-02 -23.811440
2019-11-04 12:57:34,506 train 300 8.483053e-02 -24.388781
2019-11-04 12:57:55,475 train 350 8.487462e-02 -24.606375
2019-11-04 12:58:16,239 train 400 8.493458e-02 -24.149629
2019-11-04 12:58:29,888 training loss; R2: 8.493031e-02 -24.275869
2019-11-04 12:58:30,892 valid 000 8.290510e-02 -26.330171
2019-11-04 12:58:50,385 validation loss; R2: 8.443702e-02 -24.545139
2019-11-04 12:58:50,494 epoch 58 lr 9.979264e-04
2019-11-04 12:58:51,624 train 000 8.311364e-02 -14.514309
2019-11-04 12:59:13,027 train 050 8.464037e-02 -22.992591
2019-11-04 12:59:34,233 train 100 9.710651e-02 -58.811116
2019-11-04 12:59:55,404 train 150 1.020158e-01 -68.877667
2019-11-04 13:00:16,559 train 200 1.042494e-01 -77.675784
2019-11-04 13:00:37,737 train 250 1.053945e-01 -74.994396
2019-11-04 13:00:58,930 train 300 1.068837e-01 -82.925453
2019-11-04 13:01:19,773 train 350 1.070127e-01 -78.518282
2019-11-04 13:01:40,171 train 400 1.067683e-01 -72.117854
2019-11-04 13:01:53,692 training loss; R2: 1.067294e-01 -69.015545
2019-11-04 13:01:54,678 valid 000 1.054701e-01 -17.221087
2019-11-04 13:02:13,810 validation loss; R2: 1.075951e-01 -31.823786
2019-11-04 13:02:13,924 epoch 59 lr 9.978543e-04
2019-11-04 13:02:15,084 train 000 1.018500e-01 -63.105002
2019-11-04 13:02:36,186 train 050 1.058607e-01 -36.389507
2019-11-04 13:02:57,575 train 100 1.004399e-01 -52.538387
2019-11-04 13:03:18,783 train 150 9.587269e-02 -46.211783
2019-11-04 13:03:40,029 train 200 9.329278e-02 -40.665164
2019-11-04 13:04:01,242 train 250 9.142654e-02 -37.127874
2019-11-04 13:04:22,422 train 300 9.023905e-02 -34.993505
2019-11-04 13:04:43,593 train 350 8.953226e-02 -33.425368
2019-11-04 13:05:04,647 train 400 8.896504e-02 -32.202305
2019-11-04 13:05:18,311 training loss; R2: 8.868669e-02 -31.753978
2019-11-04 13:05:19,311 valid 000 8.290528e-02 -26.330176
2019-11-04 13:05:38,955 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:05:39,065 epoch 60 lr 9.977810e-04
2019-11-04 13:05:40,260 train 000 8.280113e-02 -22.151600
2019-11-04 13:06:01,556 train 050 8.464027e-02 -25.040879
2019-11-04 13:06:22,803 train 100 8.474882e-02 -24.575203
2019-11-04 13:06:43,969 train 150 8.619949e-02 -31.493849
2019-11-04 13:07:05,161 train 200 8.832927e-02 -44.253122
2019-11-04 13:07:26,346 train 250 8.804623e-02 -42.695239
2019-11-04 13:07:47,506 train 300 8.750032e-02 -39.196010
2019-11-04 13:08:08,654 train 350 8.717787e-02 -37.058725
2019-11-04 13:08:29,428 train 400 8.698622e-02 -35.445699
2019-11-04 13:08:42,904 training loss; R2: 8.685307e-02 -34.826398
2019-11-04 13:08:43,982 valid 000 8.290522e-02 -26.330174
2019-11-04 13:09:03,246 validation loss; R2: 8.443721e-02 -24.545143
2019-11-04 13:09:03,352 epoch 61 lr 9.977065e-04
2019-11-04 13:09:04,566 train 000 8.652186e-02 -9.094950
2019-11-04 13:09:25,723 train 050 8.473398e-02 -24.403076
2019-11-04 13:09:46,880 train 100 8.518738e-02 -25.513406
2019-11-04 13:10:08,014 train 150 8.503047e-02 -24.672714
2019-11-04 13:10:29,129 train 200 8.512554e-02 -24.825676
2019-11-04 13:10:50,269 train 250 8.498460e-02 -24.643633
2019-11-04 13:11:11,364 train 300 8.488492e-02 -24.511003
2019-11-04 13:11:32,375 train 350 8.486805e-02 -24.590374
2019-11-04 13:11:53,281 train 400 8.488303e-02 -24.662852
2019-11-04 13:12:06,942 training loss; R2: 8.497503e-02 -24.609435
2019-11-04 13:12:07,994 valid 000 8.290528e-02 -26.330176
2019-11-04 13:12:27,527 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:12:27,635 epoch 62 lr 9.976307e-04
2019-11-04 13:12:28,798 train 000 8.797052e-02 -36.193031
2019-11-04 13:12:50,072 train 050 8.469184e-02 -27.983845
2019-11-04 13:13:11,236 train 100 8.490491e-02 -25.964719
2019-11-04 13:13:32,381 train 150 8.514897e-02 -25.066468
2019-11-04 13:13:53,477 train 200 8.491577e-02 -24.773925
2019-11-04 13:14:14,584 train 250 8.488210e-02 -24.847718
2019-11-04 13:14:35,686 train 300 8.488779e-02 -24.686020
2019-11-04 13:14:56,638 train 350 8.484139e-02 -24.711081
2019-11-04 13:15:17,536 train 400 8.490405e-02 -24.733699
2019-11-04 13:15:31,315 training loss; R2: 8.490203e-02 -24.588107
2019-11-04 13:15:32,329 valid 000 8.290528e-02 -26.330176
2019-11-04 13:15:51,729 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:15:51,835 epoch 63 lr 9.975537e-04
2019-11-04 13:15:53,002 train 000 8.744139e-02 -19.550237
2019-11-04 13:16:14,212 train 050 8.484396e-02 -25.426331
2019-11-04 13:16:35,647 train 100 8.654309e-02 -42.967610
2019-11-04 13:16:56,997 train 150 9.461851e-02 -102.269074
2019-11-04 13:17:18,236 train 200 9.647763e-02 -108.579488
2019-11-04 13:17:39,508 train 250 9.544587e-02 -106.574062
2019-11-04 13:18:00,760 train 300 9.555797e-02 -99.809495
2019-11-04 13:18:21,730 train 350 9.561223e-02 -87.775243
2019-11-04 13:18:42,543 train 400 9.466977e-02 -79.533480
2019-11-04 13:18:55,973 training loss; R2: 9.425004e-02 -75.182688
2019-11-04 13:18:57,028 valid 000 8.290528e-02 -26.330176
2019-11-04 13:19:16,164 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:19:16,269 epoch 64 lr 9.974755e-04
2019-11-04 13:19:17,472 train 000 9.049589e-02 -25.883560
2019-11-04 13:19:38,614 train 050 8.681112e-02 -20.665848
2019-11-04 13:19:59,687 train 100 8.697213e-02 -21.066271
2019-11-04 13:20:20,773 train 150 8.730518e-02 -20.892756
2019-11-04 13:20:41,821 train 200 8.731178e-02 -20.706652
2019-11-04 13:21:02,913 train 250 8.745072e-02 -21.074141
2019-11-04 13:21:23,906 train 300 8.757100e-02 -21.003544
2019-11-04 13:21:44,824 train 350 8.738011e-02 -21.115611
2019-11-04 13:22:05,533 train 400 8.719029e-02 -21.428310
2019-11-04 13:22:19,056 training loss; R2: 8.707498e-02 -21.551888
2019-11-04 13:22:20,092 valid 000 8.927089e-02 -24.936222
2019-11-04 13:22:39,408 validation loss; R2: 8.910326e-02 -23.767176
2019-11-04 13:22:39,516 epoch 65 lr 9.973961e-04
2019-11-04 13:22:40,725 train 000 8.741849e-02 -13.675755
2019-11-04 13:23:01,854 train 050 8.593496e-02 -22.219344
2019-11-04 13:23:22,874 train 100 8.521964e-02 -23.277457
2019-11-04 13:23:43,880 train 150 8.527083e-02 -23.974114
2019-11-04 13:24:04,843 train 200 8.506467e-02 -23.903206
2019-11-04 13:24:25,849 train 250 8.512608e-02 -23.986003
2019-11-04 13:24:46,760 train 300 8.526959e-02 -24.269646
2019-11-04 13:25:07,746 train 350 8.525856e-02 -24.547765
2019-11-04 13:25:28,936 train 400 8.519094e-02 -24.773830
2019-11-04 13:25:42,619 training loss; R2: 8.511967e-02 -24.569271
2019-11-04 13:25:43,680 valid 000 8.290527e-02 -26.330169
2019-11-04 13:26:03,165 validation loss; R2: 8.443729e-02 -24.545139
2019-11-04 13:26:03,284 epoch 66 lr 9.973154e-04
2019-11-04 13:26:04,431 train 000 8.786696e-02 -13.489997
2019-11-04 13:26:25,959 train 050 8.458862e-02 -24.301996
2019-11-04 13:26:47,689 train 100 8.468963e-02 -24.795615
2019-11-04 13:27:09,133 train 150 8.489734e-02 -24.899289
2019-11-04 13:27:30,626 train 200 8.492367e-02 -24.602200
2019-11-04 13:27:52,062 train 250 8.493656e-02 -24.512323
2019-11-04 13:28:13,474 train 300 8.489510e-02 -24.205987
2019-11-04 13:28:34,405 train 350 8.491598e-02 -24.127851
2019-11-04 13:28:55,037 train 400 8.489292e-02 -24.165876
2019-11-04 13:29:08,559 training loss; R2: 8.535040e-02 -23.991276
2019-11-04 13:29:09,538 valid 000 8.290528e-02 -26.330176
2019-11-04 13:29:28,664 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:29:28,766 epoch 67 lr 9.972335e-04
2019-11-04 13:29:29,941 train 000 8.799044e-02 -34.071804
2019-11-04 13:29:51,255 train 050 8.438197e-02 -22.392958
2019-11-04 13:30:12,440 train 100 8.485285e-02 -23.636846
2019-11-04 13:30:33,544 train 150 8.607369e-02 -23.353015
2019-11-04 13:30:54,551 train 200 9.108756e-02 -18.818896
2019-11-04 13:31:15,535 train 250 9.326500e-02 -16.175533
2019-11-04 13:31:36,514 train 300 9.221373e-02 -17.239492
2019-11-04 13:31:57,485 train 350 9.127834e-02 -18.473913
2019-11-04 13:32:18,413 train 400 9.060585e-02 -19.409036
2019-11-04 13:32:31,857 training loss; R2: 9.017917e-02 -19.671833
2019-11-04 13:32:32,881 valid 000 8.290528e-02 -26.330176
2019-11-04 13:32:52,120 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:32:52,228 epoch 68 lr 9.971504e-04
2019-11-04 13:32:53,361 train 000 8.650165e-02 -23.148504
2019-11-04 13:33:14,488 train 050 8.460935e-02 -26.859951
2019-11-04 13:33:35,572 train 100 8.493038e-02 -26.580254
2019-11-04 13:33:56,616 train 150 8.523173e-02 -25.566951
2019-11-04 13:34:17,666 train 200 8.521112e-02 -25.749767
2019-11-04 13:34:38,686 train 250 8.495634e-02 -25.316372
2019-11-04 13:34:59,791 train 300 8.506080e-02 -25.519960
2019-11-04 13:35:20,711 train 350 8.500010e-02 -25.004300
2019-11-04 13:35:41,582 train 400 8.499777e-02 -24.538623
2019-11-04 13:35:55,138 training loss; R2: 8.500536e-02 -24.334054
2019-11-04 13:35:56,126 valid 000 8.290528e-02 -26.330176
2019-11-04 13:36:15,294 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:36:15,404 epoch 69 lr 9.970660e-04
2019-11-04 13:36:16,591 train 000 8.778090e-02 -35.708565
2019-11-04 13:36:37,713 train 050 8.504448e-02 -24.904707
2019-11-04 13:36:58,877 train 100 8.518361e-02 -24.902962
2019-11-04 13:37:20,031 train 150 8.507341e-02 -24.725154
2019-11-04 13:37:41,115 train 200 8.511920e-02 -25.358864
2019-11-04 13:38:02,211 train 250 8.680376e-02 -24.662444
2019-11-04 13:38:23,259 train 300 8.645763e-02 -24.410967
2019-11-04 13:38:44,157 train 350 8.614564e-02 -24.089180
2019-11-04 13:39:05,038 train 400 8.604507e-02 -24.115423
2019-11-04 13:39:18,609 training loss; R2: 8.591134e-02 -24.205353
2019-11-04 13:39:19,695 valid 000 8.290528e-02 -26.330176
2019-11-04 13:39:38,898 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:39:39,008 epoch 70 lr 9.969805e-04
2019-11-04 13:39:40,207 train 000 8.205435e-02 -31.570758
2019-11-04 13:40:01,594 train 050 8.506797e-02 -26.978369
2019-11-04 13:40:22,814 train 100 8.527343e-02 -26.205542
2019-11-04 13:40:44,028 train 150 8.528242e-02 -26.422503
2019-11-04 13:41:05,232 train 200 8.523485e-02 -26.269289
2019-11-04 13:41:26,428 train 250 8.511306e-02 -25.579538
2019-11-04 13:41:47,565 train 300 8.496707e-02 -25.506561
2019-11-04 13:42:08,062 train 350 8.486027e-02 -25.092538
2019-11-04 13:42:28,567 train 400 8.489719e-02 -25.018729
2019-11-04 13:42:42,090 training loss; R2: 8.488647e-02 -24.794276
2019-11-04 13:42:43,080 valid 000 8.290528e-02 -26.330176
2019-11-04 13:43:02,377 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:43:02,491 epoch 71 lr 9.968937e-04
2019-11-04 13:43:03,632 train 000 8.618469e-02 -19.819115
2019-11-04 13:43:25,027 train 050 8.499955e-02 -25.829943
2019-11-04 13:43:46,500 train 100 8.463832e-02 -24.990034
2019-11-04 13:44:08,196 train 150 8.692359e-02 -21.525377
2019-11-04 13:44:29,639 train 200 8.637722e-02 -22.969623
2019-11-04 13:44:50,956 train 250 8.609035e-02 -23.180297
2019-11-04 13:45:12,553 train 300 8.587372e-02 -23.310913
2019-11-04 13:45:33,603 train 350 8.590069e-02 -23.785853
2019-11-04 13:45:54,789 train 400 8.576505e-02 -23.637603
2019-11-04 13:46:08,331 training loss; R2: 8.565782e-02 -23.555709
2019-11-04 13:46:09,365 valid 000 8.290528e-02 -26.330176
2019-11-04 13:46:28,835 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:46:28,943 epoch 72 lr 9.968057e-04
2019-11-04 13:46:30,076 train 000 8.422402e-02 -29.369183
2019-11-04 13:46:51,551 train 050 8.437294e-02 -26.637478
2019-11-04 13:47:12,905 train 100 8.467462e-02 -25.405767
2019-11-04 13:47:34,062 train 150 8.454263e-02 -25.036025
2019-11-04 13:47:55,359 train 200 8.464548e-02 -25.303757
2019-11-04 13:48:16,475 train 250 8.470458e-02 -25.061556
2019-11-04 13:48:37,636 train 300 8.473957e-02 -25.173507
2019-11-04 13:48:58,500 train 350 8.479144e-02 -24.725968
2019-11-04 13:49:19,470 train 400 8.490267e-02 -24.382163
2019-11-04 13:49:32,981 training loss; R2: 8.503391e-02 -24.184373
2019-11-04 13:49:34,000 valid 000 8.290528e-02 -26.330176
2019-11-04 13:49:53,278 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:49:53,398 epoch 73 lr 9.967164e-04
2019-11-04 13:49:54,579 train 000 8.996141e-02 -17.460637
2019-11-04 13:50:16,149 train 050 8.716771e-02 -22.981871
2019-11-04 13:50:38,059 train 100 8.673008e-02 -24.443304
2019-11-04 13:50:59,146 train 150 8.591441e-02 -23.966698
2019-11-04 13:51:20,340 train 200 8.583585e-02 -24.359892
2019-11-04 13:51:41,625 train 250 8.555312e-02 -23.773928
2019-11-04 13:52:02,710 train 300 8.541079e-02 -23.667770
2019-11-04 13:52:23,505 train 350 8.525855e-02 -23.985104
2019-11-04 13:52:44,623 train 400 8.522695e-02 -23.893520
2019-11-04 13:52:58,287 training loss; R2: 8.521030e-02 -23.805530
2019-11-04 13:52:59,284 valid 000 8.120342e-02 -26.271081
2019-11-04 13:53:18,683 validation loss; R2: 8.207071e-02 -24.486722
2019-11-04 13:53:18,790 epoch 74 lr 9.966259e-04
2019-11-04 13:53:19,924 train 000 9.364408e-02 -34.617781
2019-11-04 13:53:41,311 train 050 8.680563e-02 -26.454911
2019-11-04 13:54:02,350 train 100 8.568867e-02 -23.691900
2019-11-04 13:54:23,362 train 150 8.557652e-02 -23.855935
2019-11-04 13:54:44,268 train 200 8.526536e-02 -24.071451
2019-11-04 13:55:05,263 train 250 8.514450e-02 -24.435595
2019-11-04 13:55:26,311 train 300 8.501650e-02 -24.302317
2019-11-04 13:55:47,086 train 350 8.498701e-02 -24.542108
2019-11-04 13:56:08,157 train 400 8.499682e-02 -24.355045
2019-11-04 13:56:21,739 training loss; R2: 8.501462e-02 -24.536342
2019-11-04 13:56:22,744 valid 000 8.290528e-02 -26.330176
2019-11-04 13:56:42,181 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 13:56:42,287 epoch 75 lr 9.965342e-04
2019-11-04 13:56:43,497 train 000 8.614238e-02 -28.172960
2019-11-04 13:57:04,694 train 050 8.447180e-02 -24.391942
2019-11-04 13:57:25,858 train 100 8.461644e-02 -22.721356
2019-11-04 13:57:47,006 train 150 8.490368e-02 -24.606955
2019-11-04 13:58:08,119 train 200 8.492754e-02 -24.749741
2019-11-04 13:58:29,033 train 250 8.495837e-02 -24.407720
2019-11-04 13:58:50,207 train 300 8.485926e-02 -24.501479
2019-11-04 13:59:11,406 train 350 8.409720e-02 -23.557432
2019-11-04 13:59:32,569 train 400 8.432917e-02 -23.840005
2019-11-04 13:59:46,131 training loss; R2: 8.461872e-02 -23.539714
2019-11-04 13:59:47,192 valid 000 1.012882e-01 -2.520546
2019-11-04 14:00:06,553 validation loss; R2: 1.023813e-01 -2.730108
2019-11-04 14:00:06,664 epoch 76 lr 9.964413e-04
2019-11-04 14:00:07,874 train 000 9.418150e-02 -11.519322
2019-11-04 14:00:29,134 train 050 8.845365e-02 -22.336503
2019-11-04 14:00:50,152 train 100 8.667082e-02 -22.515107
2019-11-04 14:01:11,271 train 150 8.643204e-02 -23.173270
2019-11-04 14:01:32,400 train 200 8.603722e-02 -22.951206
2019-11-04 14:01:53,613 train 250 8.650512e-02 -24.611730
2019-11-04 14:02:14,678 train 300 8.909611e-02 -26.757969
2019-11-04 14:02:35,366 train 350 8.911267e-02 -27.050583
2019-11-04 14:02:56,548 train 400 8.870383e-02 -26.687276
2019-11-04 14:03:10,112 training loss; R2: 8.850751e-02 -26.493498
2019-11-04 14:03:11,157 valid 000 8.290528e-02 -26.330176
2019-11-04 14:03:30,737 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:03:30,848 epoch 77 lr 9.963472e-04
2019-11-04 14:03:32,019 train 000 8.430938e-02 -31.188076
2019-11-04 14:03:53,513 train 050 8.528576e-02 -23.351500
2019-11-04 14:04:14,855 train 100 8.520116e-02 -24.370237
2019-11-04 14:04:36,175 train 150 8.505027e-02 -23.311018
2019-11-04 14:04:57,484 train 200 8.505884e-02 -23.501111
2019-11-04 14:05:18,786 train 250 8.507090e-02 -24.073518
2019-11-04 14:05:40,083 train 300 8.505291e-02 -23.935855
2019-11-04 14:06:00,979 train 350 8.511410e-02 -24.278991
2019-11-04 14:06:22,120 train 400 8.524378e-02 -24.422921
2019-11-04 14:06:35,917 training loss; R2: 8.524894e-02 -24.654305
2019-11-04 14:06:36,995 valid 000 8.290528e-02 -26.330176
2019-11-04 14:06:56,388 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:06:56,495 epoch 78 lr 9.962518e-04
2019-11-04 14:06:57,649 train 000 8.667715e-02 -41.084996
2019-11-04 14:07:19,009 train 050 1.024604e-01 -25.086473
2019-11-04 14:07:40,250 train 100 1.076900e-01 -25.187584
2019-11-04 14:08:01,480 train 150 1.099659e-01 -25.620777
2019-11-04 14:08:22,779 train 200 1.108538e-01 -25.816407
2019-11-04 14:08:44,002 train 250 1.113671e-01 -26.432208
2019-11-04 14:09:04,971 train 300 1.116818e-01 -26.180796
2019-11-04 14:09:25,607 train 350 1.119128e-01 -26.121979
2019-11-04 14:09:46,586 train 400 1.112598e-01 -25.805866
2019-11-04 14:10:00,355 training loss; R2: 1.114111e-01 -25.547538
2019-11-04 14:10:01,406 valid 000 1.158977e-01 -27.208482
2019-11-04 14:10:20,603 validation loss; R2: 1.131010e-01 -25.107484
2019-11-04 14:10:20,715 epoch 79 lr 9.961552e-04
2019-11-04 14:10:21,893 train 000 1.137235e-01 -27.932081
2019-11-04 14:10:43,065 train 050 1.131076e-01 -20.899178
2019-11-04 14:11:04,155 train 100 1.132295e-01 -22.846779
2019-11-04 14:11:25,233 train 150 1.132957e-01 -23.815445
2019-11-04 14:11:46,301 train 200 1.133593e-01 -23.328180
2019-11-04 14:12:07,364 train 250 1.134731e-01 -23.956675
2019-11-04 14:12:28,404 train 300 1.134848e-01 -23.990777
2019-11-04 14:12:49,235 train 350 1.135308e-01 -24.405672
2019-11-04 14:13:10,310 train 400 1.135263e-01 -24.446296
2019-11-04 14:13:23,920 training loss; R2: 1.135003e-01 -24.342646
2019-11-04 14:13:24,995 valid 000 1.158977e-01 -27.208482
2019-11-04 14:13:44,418 validation loss; R2: 1.131010e-01 -25.107484
2019-11-04 14:13:44,524 epoch 80 lr 9.960574e-04
2019-11-04 14:13:45,717 train 000 1.115404e-01 -31.801183
2019-11-04 14:14:06,910 train 050 1.135895e-01 -24.207924
2019-11-04 14:14:27,981 train 100 1.117551e-01 -23.682484
2019-11-04 14:14:49,126 train 150 1.126111e-01 -25.035050
2019-11-04 14:15:10,239 train 200 1.131219e-01 -25.857032
2019-11-04 14:15:31,468 train 250 1.131865e-01 -25.615793
2019-11-04 14:15:52,634 train 300 1.133384e-01 -25.367224
2019-11-04 14:16:13,135 train 350 1.133391e-01 -25.429841
2019-11-04 14:16:34,518 train 400 1.133740e-01 -25.185507
2019-11-04 14:16:48,277 training loss; R2: 1.134056e-01 -25.247510
2019-11-04 14:16:49,360 valid 000 1.158977e-01 -27.208482
2019-11-04 14:17:08,834 validation loss; R2: 1.131010e-01 -25.107484
2019-11-04 14:17:08,943 epoch 81 lr 9.959583e-04
2019-11-04 14:17:10,148 train 000 1.103018e-01 -10.724561
2019-11-04 14:17:31,375 train 050 1.142163e-01 -26.998347
2019-11-04 14:17:52,279 train 100 1.137842e-01 -25.748546
2019-11-04 14:18:13,142 train 150 1.138121e-01 -25.381744
2019-11-04 14:18:34,163 train 200 1.138584e-01 -24.853611
2019-11-04 14:18:55,171 train 250 1.130644e-01 -25.191372
2019-11-04 14:19:16,369 train 300 1.088571e-01 -24.791395
2019-11-04 14:19:37,185 train 350 1.055167e-01 -25.388956
2019-11-04 14:19:58,346 train 400 1.030198e-01 -25.255808
2019-11-04 14:20:11,798 training loss; R2: 1.016703e-01 -25.310380
2019-11-04 14:20:12,893 valid 000 8.290528e-02 -26.330176
2019-11-04 14:20:32,342 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:20:32,445 epoch 82 lr 9.958580e-04
2019-11-04 14:20:33,604 train 000 8.405080e-02 -8.948614
2019-11-04 14:20:54,825 train 050 8.429342e-02 -24.408861
2019-11-04 14:21:15,870 train 100 8.481821e-02 -24.639697
2019-11-04 14:21:36,974 train 150 8.495512e-02 -25.322996
2019-11-04 14:21:58,081 train 200 8.488195e-02 -24.678961
2019-11-04 14:22:19,172 train 250 8.481237e-02 -24.489308
2019-11-04 14:22:40,219 train 300 8.484021e-02 -24.391528
2019-11-04 14:23:00,934 train 350 8.483135e-02 -24.268191
2019-11-04 14:23:21,904 train 400 8.482766e-02 -24.215882
2019-11-04 14:23:35,424 training loss; R2: 8.490148e-02 -24.408948
2019-11-04 14:23:36,480 valid 000 8.290528e-02 -26.330176
2019-11-04 14:23:56,130 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:23:56,239 epoch 83 lr 9.957565e-04
2019-11-04 14:23:57,415 train 000 8.155512e-02 -40.291761
2019-11-04 14:24:18,778 train 050 8.520379e-02 -24.691681
2019-11-04 14:24:39,953 train 100 8.469335e-02 -24.775829
2019-11-04 14:25:01,036 train 150 8.780761e-02 -23.005013
2019-11-04 14:25:22,093 train 200 8.710009e-02 -23.748345
2019-11-04 14:25:43,202 train 250 8.659351e-02 -23.674620
2019-11-04 14:26:04,056 train 300 8.632538e-02 -23.808847
2019-11-04 14:26:24,683 train 350 8.618613e-02 -23.945231
2019-11-04 14:26:45,753 train 400 8.603146e-02 -23.930143
2019-11-04 14:26:59,283 training loss; R2: 8.592832e-02 -24.043851
2019-11-04 14:27:00,286 valid 000 8.290528e-02 -26.330176
2019-11-04 14:27:19,618 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:27:19,714 epoch 84 lr 9.956538e-04
2019-11-04 14:27:20,907 train 000 8.922698e-02 -46.391263
2019-11-04 14:27:42,246 train 050 8.456581e-02 -25.040690
2019-11-04 14:28:03,379 train 100 8.469001e-02 -24.191986
2019-11-04 14:28:24,507 train 150 8.547006e-02 -23.905631
2019-11-04 14:28:45,701 train 200 8.570621e-02 -23.637315
2019-11-04 14:29:06,718 train 250 8.895974e-02 -21.599738
2019-11-04 14:29:27,593 train 300 9.187468e-02 -19.862604
2019-11-04 14:29:48,295 train 350 9.393786e-02 -18.611889
2019-11-04 14:30:09,484 train 400 9.533036e-02 -17.789358
2019-11-04 14:30:23,055 training loss; R2: 9.611908e-02 -17.380774
2019-11-04 14:30:24,068 valid 000 1.045350e-01 -15.467850
2019-11-04 14:30:43,724 validation loss; R2: 1.048586e-01 -12.139716
2019-11-04 14:30:43,833 epoch 85 lr 9.955499e-04
2019-11-04 14:30:45,025 train 000 1.057984e-01 -12.799139
2019-11-04 14:31:06,250 train 050 1.063637e-01 -12.092446
2019-11-04 14:31:27,405 train 100 1.059913e-01 -12.175790
2019-11-04 14:31:48,527 train 150 1.080094e-01 -11.952002
2019-11-04 14:32:09,611 train 200 1.074860e-01 -11.662922
2019-11-04 14:32:30,735 train 250 1.070986e-01 -11.506107
2019-11-04 14:32:51,739 train 300 1.070185e-01 -11.464278
2019-11-04 14:33:12,906 train 350 1.070013e-01 -11.481085
2019-11-04 14:33:33,868 train 400 1.068433e-01 -11.601504
2019-11-04 14:33:47,308 training loss; R2: 1.068197e-01 -11.539939
2019-11-04 14:33:48,368 valid 000 1.045347e-01 -15.467666
2019-11-04 14:34:07,919 validation loss; R2: 1.048583e-01 -12.139572
2019-11-04 14:34:08,024 epoch 86 lr 9.954447e-04
2019-11-04 14:34:09,223 train 000 1.055573e-01 -7.776096
2019-11-04 14:34:30,360 train 050 1.063839e-01 -11.021407
2019-11-04 14:34:51,431 train 100 1.050130e-01 -25.408215
2019-11-04 14:35:12,666 train 150 9.841658e-02 -25.270583
2019-11-04 14:35:33,990 train 200 9.505683e-02 -25.628050
2019-11-04 14:35:54,999 train 250 9.304012e-02 -25.572336
2019-11-04 14:36:15,946 train 300 9.157218e-02 -25.203950
2019-11-04 14:36:36,750 train 350 9.070885e-02 -25.353825
2019-11-04 14:36:57,933 train 400 9.008965e-02 -25.236496
2019-11-04 14:37:11,531 training loss; R2: 8.968493e-02 -25.125304
2019-11-04 14:37:12,577 valid 000 8.290528e-02 -26.330176
2019-11-04 14:37:31,906 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:37:31,997 epoch 87 lr 9.953383e-04
2019-11-04 14:37:33,242 train 000 8.471067e-02 -43.097433
2019-11-04 14:37:54,580 train 050 8.479815e-02 -23.900516
2019-11-04 14:38:16,069 train 100 8.504629e-02 -23.986136
2019-11-04 14:38:37,779 train 150 8.530769e-02 -23.897628
2019-11-04 14:38:58,989 train 200 8.519116e-02 -23.819515
2019-11-04 14:39:20,182 train 250 8.523224e-02 -23.998663
2019-11-04 14:39:41,209 train 300 8.542693e-02 -24.189193
2019-11-04 14:40:02,291 train 350 8.520809e-02 -24.522828
2019-11-04 14:40:23,754 train 400 8.512361e-02 -24.477011
2019-11-04 14:40:37,215 training loss; R2: 8.511681e-02 -24.424382
2019-11-04 14:40:38,282 valid 000 8.290528e-02 -26.330176
2019-11-04 14:40:57,599 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:40:57,708 epoch 88 lr 9.952307e-04
2019-11-04 14:40:58,927 train 000 8.438648e-02 -24.605131
2019-11-04 14:41:19,799 train 050 8.536497e-02 -26.360842
2019-11-04 14:41:40,955 train 100 8.511272e-02 -26.654087
2019-11-04 14:42:02,209 train 150 8.476692e-02 -25.765654
2019-11-04 14:42:23,076 train 200 8.483537e-02 -25.819251
2019-11-04 14:42:44,042 train 250 8.483745e-02 -25.263141
2019-11-04 14:43:04,848 train 300 8.484244e-02 -25.114525
2019-11-04 14:43:25,800 train 350 8.483479e-02 -24.822534
2019-11-04 14:43:46,841 train 400 8.484484e-02 -24.702826
2019-11-04 14:44:00,388 training loss; R2: 8.490271e-02 -24.548783
2019-11-04 14:44:01,499 valid 000 8.290528e-02 -26.330176
2019-11-04 14:44:20,941 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:44:21,047 epoch 89 lr 9.951219e-04
2019-11-04 14:44:22,279 train 000 8.587489e-02 -14.461232
2019-11-04 14:44:43,635 train 050 8.460826e-02 -22.995734
2019-11-04 14:45:04,828 train 100 8.531029e-02 -24.943150
2019-11-04 14:45:25,997 train 150 8.516082e-02 -24.900738
2019-11-04 14:45:47,230 train 200 8.505645e-02 -24.971710
2019-11-04 14:46:08,477 train 250 8.516708e-02 -25.179877
2019-11-04 14:46:29,644 train 300 8.506651e-02 -25.131418
2019-11-04 14:46:50,573 train 350 8.500677e-02 -24.993242
2019-11-04 14:47:11,626 train 400 8.492978e-02 -24.815353
2019-11-04 14:47:25,288 training loss; R2: 8.489389e-02 -24.748572
2019-11-04 14:47:26,291 valid 000 8.290528e-02 -26.330176
2019-11-04 14:47:45,615 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:47:45,719 epoch 90 lr 9.950118e-04
2019-11-04 14:47:46,909 train 000 8.148322e-02 -34.406282
2019-11-04 14:48:08,098 train 050 8.466497e-02 -24.779240
2019-11-04 14:48:29,177 train 100 8.488415e-02 -24.293732
2019-11-04 14:48:50,254 train 150 8.492589e-02 -24.478040
2019-11-04 14:49:11,384 train 200 8.485910e-02 -24.589278
2019-11-04 14:49:32,572 train 250 8.475876e-02 -24.743903
2019-11-04 14:49:53,991 train 300 8.485989e-02 -24.668355
2019-11-04 14:50:14,993 train 350 8.486000e-02 -24.644412
2019-11-04 14:50:36,202 train 400 8.487454e-02 -24.567780
2019-11-04 14:50:49,847 training loss; R2: 8.482447e-02 -24.498013
2019-11-04 14:50:50,900 valid 000 8.290453e-02 -26.330154
2019-11-04 14:51:10,190 validation loss; R2: 8.443497e-02 -24.545096
2019-11-04 14:51:10,294 epoch 91 lr 9.949006e-04
2019-11-04 14:51:11,456 train 000 8.470345e-02 -28.844699
2019-11-04 14:51:32,892 train 050 8.433587e-02 -24.430590
2019-11-04 14:51:54,167 train 100 8.447267e-02 -24.258183
2019-11-04 14:52:15,392 train 150 8.485618e-02 -24.386622
2019-11-04 14:52:36,620 train 200 8.487340e-02 -24.119709
2019-11-04 14:52:57,812 train 250 8.486082e-02 -24.107256
2019-11-04 14:53:18,811 train 300 8.489606e-02 -23.952265
2019-11-04 14:53:39,862 train 350 8.483365e-02 -24.042602
2019-11-04 14:54:00,983 train 400 8.484823e-02 -24.224320
2019-11-04 14:54:14,589 training loss; R2: 8.486224e-02 -24.371162
2019-11-04 14:54:15,628 valid 000 8.290528e-02 -26.330176
2019-11-04 14:54:34,850 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:54:34,962 epoch 92 lr 9.947881e-04
2019-11-04 14:54:36,113 train 000 8.785392e-02 -25.127257
2019-11-04 14:54:57,555 train 050 8.693820e-02 -23.599093
2019-11-04 14:55:18,736 train 100 8.665685e-02 -24.165783
2019-11-04 14:55:39,885 train 150 8.617940e-02 -24.390777
2019-11-04 14:56:01,100 train 200 8.588768e-02 -24.180635
2019-11-04 14:56:22,334 train 250 8.558901e-02 -24.827856
2019-11-04 14:56:43,409 train 300 8.626100e-02 -24.722751
2019-11-04 14:57:04,401 train 350 8.613006e-02 -24.751682
2019-11-04 14:57:25,856 train 400 8.589091e-02 -24.550234
2019-11-04 14:57:39,421 training loss; R2: 8.583367e-02 -24.517840
2019-11-04 14:57:40,450 valid 000 8.290528e-02 -26.330176
2019-11-04 14:57:59,641 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 14:57:59,741 epoch 93 lr 9.946743e-04
2019-11-04 14:58:00,918 train 000 8.687414e-02 -48.214426
2019-11-04 14:58:21,977 train 050 8.510966e-02 -25.100034
2019-11-04 14:58:42,910 train 100 8.511247e-02 -25.904225
2019-11-04 14:59:03,888 train 150 8.489202e-02 -20.914301
2019-11-04 14:59:24,847 train 200 8.845616e-02 -17.080372
2019-11-04 14:59:45,976 train 250 8.817190e-02 -17.905955
2019-11-04 15:00:07,123 train 300 8.789648e-02 -18.663634
2019-11-04 15:00:28,153 train 350 8.756949e-02 -19.224326
2019-11-04 15:00:49,212 train 400 8.747810e-02 -19.810012
2019-11-04 15:01:02,771 training loss; R2: 8.737149e-02 -19.847161
2019-11-04 15:01:03,857 valid 000 8.384078e-02 -8.837709
2019-11-04 15:01:23,113 validation loss; R2: 8.450775e-02 -10.609073
2019-11-04 15:01:23,223 epoch 94 lr 9.945594e-04
2019-11-04 15:01:24,466 train 000 9.946151e-02 -5.583643
2019-11-04 15:01:45,639 train 050 1.029297e-01 -35.722313
2019-11-04 15:02:06,814 train 100 1.025789e-01 -23.633879
2019-11-04 15:02:27,962 train 150 1.033308e-01 -22.381439
2019-11-04 15:02:49,073 train 200 1.035260e-01 -25.312300
2019-11-04 15:03:10,172 train 250 1.022095e-01 -27.175919
2019-11-04 15:03:31,218 train 300 1.001633e-01 -27.518622
2019-11-04 15:03:52,720 train 350 9.866473e-02 -27.544799
2019-11-04 15:04:14,025 train 400 9.749618e-02 -27.725937
2019-11-04 15:04:27,530 training loss; R2: 9.676875e-02 -27.544583
2019-11-04 15:04:28,607 valid 000 8.835834e-02 -17.245950
2019-11-04 15:04:48,006 validation loss; R2: 9.032549e-02 -16.978288
2019-11-04 15:04:48,107 epoch 95 lr 9.944432e-04
2019-11-04 15:04:49,296 train 000 8.139502e-02 -32.117008
2019-11-04 15:05:10,514 train 050 9.240271e-02 -28.788591
2019-11-04 15:05:31,579 train 100 9.348237e-02 -29.180911
2019-11-04 15:05:52,656 train 150 9.065527e-02 -27.451983
2019-11-04 15:06:13,748 train 200 8.922924e-02 -26.734103
2019-11-04 15:06:34,692 train 250 8.831292e-02 -26.084677
2019-11-04 15:06:55,689 train 300 8.785150e-02 -25.809707
2019-11-04 15:07:16,653 train 350 8.733074e-02 -25.396408
2019-11-04 15:07:37,855 train 400 8.677530e-02 -25.056621
2019-11-04 15:07:51,448 training loss; R2: 8.660320e-02 -25.037270
2019-11-04 15:07:52,529 valid 000 8.289713e-02 -26.329819
2019-11-04 15:08:11,917 validation loss; R2: 8.442841e-02 -24.544846
2019-11-04 15:08:12,037 epoch 96 lr 9.943259e-04
2019-11-04 15:08:13,281 train 000 8.619627e-02 -11.242729
2019-11-04 15:08:34,513 train 050 8.606250e-02 -24.697781
2019-11-04 15:08:55,689 train 100 8.767692e-02 -23.091770
2019-11-04 15:09:16,919 train 150 8.716326e-02 -23.383247
2019-11-04 15:09:38,167 train 200 8.665654e-02 -23.723260
2019-11-04 15:09:59,134 train 250 8.629144e-02 -23.973698
2019-11-04 15:10:20,159 train 300 8.602737e-02 -24.062446
2019-11-04 15:10:41,254 train 350 8.583889e-02 -24.318160
2019-11-04 15:11:02,440 train 400 8.534787e-02 -23.897280
2019-11-04 15:11:16,057 training loss; R2: 8.498836e-02 -23.878357
2019-11-04 15:11:17,153 valid 000 8.290528e-02 -26.330176
2019-11-04 15:11:36,677 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:11:36,802 epoch 97 lr 9.942073e-04
2019-11-04 15:11:37,963 train 000 8.628844e-02 -9.222359
2019-11-04 15:11:59,420 train 050 8.396103e-02 -22.280896
2019-11-04 15:12:20,716 train 100 8.440076e-02 -24.111788
2019-11-04 15:12:42,011 train 150 8.438719e-02 -24.061382
2019-11-04 15:13:03,274 train 200 8.452494e-02 -24.376420
2019-11-04 15:13:24,127 train 250 8.600834e-02 -25.235931
2019-11-04 15:13:44,988 train 300 8.880248e-02 -25.146398
2019-11-04 15:14:05,897 train 350 8.833175e-02 -24.978323
2019-11-04 15:14:27,004 train 400 8.784694e-02 -24.703564
2019-11-04 15:14:40,587 training loss; R2: 8.764482e-02 -24.654122
2019-11-04 15:14:41,672 valid 000 8.290528e-02 -26.330176
2019-11-04 15:15:01,180 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:15:01,278 epoch 98 lr 9.940875e-04
2019-11-04 15:15:02,471 train 000 8.586905e-02 -55.433030
2019-11-04 15:15:23,739 train 050 8.509518e-02 -25.510284
2019-11-04 15:15:44,849 train 100 8.476086e-02 -23.946570
2019-11-04 15:16:06,016 train 150 8.492396e-02 -25.006499
2019-11-04 15:16:27,147 train 200 8.497742e-02 -24.411799
2019-11-04 15:16:48,229 train 250 8.465325e-02 -24.389226
2019-11-04 15:17:09,029 train 300 8.476549e-02 -24.326434
2019-11-04 15:17:29,910 train 350 8.485307e-02 -24.355060
2019-11-04 15:17:50,944 train 400 8.492139e-02 -24.446293
2019-11-04 15:18:04,415 training loss; R2: 8.491073e-02 -24.458548
2019-11-04 15:18:05,525 valid 000 8.290528e-02 -26.330176
2019-11-04 15:18:24,973 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:18:25,080 epoch 99 lr 9.939664e-04
2019-11-04 15:18:26,301 train 000 8.574331e-02 -36.167681
2019-11-04 15:18:47,513 train 050 8.537001e-02 -26.096006
2019-11-04 15:19:08,452 train 100 8.601109e-02 -24.846282
2019-11-04 15:19:29,434 train 150 8.617850e-02 -23.862558
2019-11-04 15:19:50,452 train 200 8.608154e-02 -23.250407
2019-11-04 15:20:11,377 train 250 8.582903e-02 -22.776059
2019-11-04 15:20:32,361 train 300 8.565475e-02 -23.180431
2019-11-04 15:20:53,477 train 350 8.550125e-02 -23.479449
2019-11-04 15:21:14,534 train 400 8.548388e-02 -23.659228
2019-11-04 15:21:28,084 training loss; R2: 8.551011e-02 -23.718006
2019-11-04 15:21:29,184 valid 000 8.290528e-02 -26.330176
2019-11-04 15:21:48,633 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:21:48,739 epoch 100 lr 9.938442e-04
2019-11-04 15:21:49,908 train 000 8.358489e-02 -9.507379
2019-11-04 15:22:11,118 train 050 8.449166e-02 -26.452327
2019-11-04 15:22:32,341 train 100 8.465530e-02 -25.409457
2019-11-04 15:22:53,462 train 150 8.485054e-02 -26.858275
2019-11-04 15:23:14,563 train 200 8.493264e-02 -26.562444
2019-11-04 15:23:35,513 train 250 8.499793e-02 -26.095953
2019-11-04 15:23:56,230 train 300 8.485797e-02 -25.545412
2019-11-04 15:24:17,177 train 350 8.490215e-02 -25.528826
2019-11-04 15:24:38,397 train 400 8.486332e-02 -25.503628
2019-11-04 15:24:52,048 training loss; R2: 8.489985e-02 -25.502099
2019-11-04 15:24:53,133 valid 000 8.290527e-02 -26.330163
2019-11-04 15:25:12,469 validation loss; R2: 8.443728e-02 -24.545133
2019-11-04 15:25:12,578 epoch 101 lr 9.937207e-04
2019-11-04 15:25:13,779 train 000 8.287692e-02 -28.482442
2019-11-04 15:25:34,788 train 050 8.911476e-02 -27.499628
2019-11-04 15:25:55,839 train 100 8.728252e-02 -27.609669
2019-11-04 15:26:16,825 train 150 8.657197e-02 -26.733824
2019-11-04 15:26:37,937 train 200 8.627198e-02 -26.388427
2019-11-04 15:26:58,964 train 250 8.606604e-02 -25.874002
2019-11-04 15:27:19,925 train 300 8.583945e-02 -25.670296
2019-11-04 15:27:40,966 train 350 8.572643e-02 -25.504573
2019-11-04 15:28:02,189 train 400 8.562543e-02 -25.350100
2019-11-04 15:28:15,797 training loss; R2: 8.555728e-02 -25.129955
2019-11-04 15:28:16,869 valid 000 8.290528e-02 -26.330176
2019-11-04 15:28:36,280 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:28:36,391 epoch 102 lr 9.935960e-04
2019-11-04 15:28:37,571 train 000 8.506114e-02 -26.084388
2019-11-04 15:28:58,724 train 050 8.450648e-02 -25.174772
2019-11-04 15:29:19,974 train 100 8.477754e-02 -24.136134
2019-11-04 15:29:41,012 train 150 8.490142e-02 -24.158951
2019-11-04 15:30:02,196 train 200 8.520997e-02 -24.115146
2019-11-04 15:30:23,297 train 250 8.509225e-02 -24.067614
2019-11-04 15:30:44,064 train 300 8.499935e-02 -23.991301
2019-11-04 15:31:05,083 train 350 8.502205e-02 -24.376276
2019-11-04 15:31:26,269 train 400 8.503150e-02 -24.275073
2019-11-04 15:31:39,880 training loss; R2: 8.502678e-02 -24.286890
2019-11-04 15:31:40,997 valid 000 8.290528e-02 -26.330176
2019-11-04 15:32:00,512 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:32:00,609 epoch 103 lr 9.934701e-04
2019-11-04 15:32:01,878 train 000 8.493645e-02 -20.450803
2019-11-04 15:32:23,036 train 050 8.487179e-02 -23.289086
2019-11-04 15:32:44,140 train 100 8.453399e-02 -23.363838
2019-11-04 15:33:05,344 train 150 8.521204e-02 -23.620592
2019-11-04 15:33:26,724 train 200 8.494409e-02 -23.717120
2019-11-04 15:33:47,652 train 250 8.504819e-02 -23.866750
2019-11-04 15:34:08,165 train 300 8.503376e-02 -24.093422
2019-11-04 15:34:29,496 train 350 8.516870e-02 -24.206641
2019-11-04 15:34:51,051 train 400 8.507423e-02 -24.398408
2019-11-04 15:35:04,695 training loss; R2: 8.504396e-02 -24.427489
2019-11-04 15:35:05,774 valid 000 8.290528e-02 -26.330176
2019-11-04 15:35:25,120 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:35:25,228 epoch 104 lr 9.933430e-04
2019-11-04 15:35:26,427 train 000 8.313161e-02 -35.406238
2019-11-04 15:35:47,653 train 050 8.483940e-02 -25.092822
2019-11-04 15:36:08,782 train 100 8.510981e-02 -24.857466
2019-11-04 15:36:29,788 train 150 8.482118e-02 -24.985243
2019-11-04 15:36:50,738 train 200 8.502970e-02 -24.482918
2019-11-04 15:37:11,615 train 250 8.497553e-02 -24.831772
2019-11-04 15:37:32,182 train 300 8.496573e-02 -24.529109
2019-11-04 15:37:53,245 train 350 8.493823e-02 -24.605252
2019-11-04 15:38:14,345 train 400 8.490502e-02 -24.660491
2019-11-04 15:38:27,911 training loss; R2: 8.491949e-02 -24.728980
2019-11-04 15:38:29,037 valid 000 8.290528e-02 -26.330176
2019-11-04 15:38:48,296 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:38:48,392 epoch 105 lr 9.932146e-04
2019-11-04 15:38:49,596 train 000 8.326845e-02 -26.235101
2019-11-04 15:39:10,833 train 050 8.490969e-02 -24.177224
2019-11-04 15:39:31,877 train 100 8.511939e-02 -25.740372
2019-11-04 15:39:52,894 train 150 8.513975e-02 -25.361659
2019-11-04 15:40:13,971 train 200 8.509394e-02 -24.403021
2019-11-04 15:40:34,877 train 250 8.506407e-02 -24.374373
2019-11-04 15:40:55,698 train 300 8.494467e-02 -24.495014
2019-11-04 15:41:16,897 train 350 8.499415e-02 -24.321005
2019-11-04 15:41:38,109 train 400 8.493641e-02 -24.308602
2019-11-04 15:41:51,690 training loss; R2: 8.492481e-02 -24.486462
2019-11-04 15:41:52,755 valid 000 6.175469e-02 -11.800078
2019-11-04 15:42:12,126 validation loss; R2: 6.258746e-02 -12.910438
2019-11-04 15:42:12,231 epoch 106 lr 9.930851e-04
2019-11-04 15:42:13,426 train 000 8.803270e-02 -22.295551
2019-11-04 15:42:34,786 train 050 9.569287e-02 -7.783261
2019-11-04 15:42:56,601 train 100 9.723803e-02 -6.778815
2019-11-04 15:43:18,138 train 150 9.875574e-02 -5.176846
2019-11-04 15:43:39,312 train 200 9.869468e-02 -5.085302
2019-11-04 15:44:00,307 train 250 9.696721e-02 -7.407588
2019-11-04 15:44:21,031 train 300 9.568521e-02 -9.322760
2019-11-04 15:44:42,069 train 350 9.425379e-02 -11.885171
2019-11-04 15:45:03,223 train 400 9.317417e-02 -13.277385
2019-11-04 15:45:16,801 training loss; R2: 9.253463e-02 -14.032419
2019-11-04 15:45:17,881 valid 000 8.290528e-02 -26.330175
2019-11-04 15:45:37,341 validation loss; R2: 8.443730e-02 -24.545145
2019-11-04 15:45:37,461 epoch 107 lr 9.929543e-04
2019-11-04 15:45:38,662 train 000 8.268528e-02 -14.488391
2019-11-04 15:46:00,066 train 050 8.463016e-02 -22.515059
2019-11-04 15:46:21,266 train 100 8.450024e-02 -22.970887
2019-11-04 15:46:42,756 train 150 8.453865e-02 -23.738223
