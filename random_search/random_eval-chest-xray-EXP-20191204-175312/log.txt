2019-12-04 17:53:12,748 gpu device = 3
2019-12-04 17:53:12,748 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-175312', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 17:53:19,947 param size = 0.204638MB
2019-12-04 17:53:19,950 epoch 0 lr 1.000000e-03
2019-12-04 17:53:21,775 train 000 7.108253e-01 -1.925801
2019-12-04 17:53:33,093 train 050 3.204714e-01 -106.947403
2019-12-04 17:53:44,359 train 100 2.568250e-01 -157.906685
2019-12-04 17:53:55,621 train 150 2.342515e-01 -172.161481
2019-12-04 17:54:06,891 train 200 2.206926e-01 -184.970486
2019-12-04 17:54:18,194 train 250 2.122765e-01 -192.865914
2019-12-04 17:54:29,690 train 300 2.060886e-01 -196.894994
2019-12-04 17:54:41,186 train 350 2.008427e-01 -199.394167
2019-12-04 17:54:52,676 train 400 1.973671e-01 -203.929693
2019-12-04 17:55:04,166 train 450 1.947349e-01 -204.865567
2019-12-04 17:55:15,658 train 500 1.920169e-01 -207.894658
2019-12-04 17:55:27,144 train 550 1.902587e-01 -210.028494
2019-12-04 17:55:38,643 train 600 1.891769e-01 -210.466972
2019-12-04 17:55:50,135 train 650 1.872303e-01 -210.381189
2019-12-04 17:56:01,625 train 700 1.864549e-01 -211.069300
2019-12-04 17:56:13,120 train 750 1.853760e-01 -212.341064
2019-12-04 17:56:24,617 train 800 1.840849e-01 -213.175057
2019-12-04 17:56:36,117 train 850 1.829015e-01 -214.359193
2019-12-04 17:56:46,049 training loss; R2: 1.826183e-01 -214.159119
2019-12-04 17:56:46,188 valid 000 1.679289e-01 -251.507589
2019-12-04 17:56:48,599 valid 050 1.760116e-01 -193.009595
2019-12-04 17:56:51,035 validation loss; R2: 1.806245e-01 -199.631635
2019-12-04 17:56:51,050 epoch 1 lr 1.000000e-03
2019-12-04 17:56:51,419 train 000 1.634570e-01 -146.810367
2019-12-04 17:57:02,920 train 050 1.656793e-01 -208.533526
2019-12-04 17:57:14,413 train 100 1.687137e-01 -218.569134
2019-12-04 17:57:25,903 train 150 1.685038e-01 -224.601882
2019-12-04 17:57:37,396 train 200 1.692094e-01 -226.763657
2019-12-04 17:57:48,889 train 250 1.691807e-01 -223.169182
2019-12-04 17:58:00,378 train 300 1.687282e-01 -225.125899
2019-12-04 17:58:11,872 train 350 1.679637e-01 -226.967847
2019-12-04 17:58:23,363 train 400 1.670751e-01 -227.079773
2019-12-04 17:58:34,857 train 450 1.672594e-01 -227.016940
2019-12-04 17:58:46,353 train 500 1.665919e-01 -228.172023
2019-12-04 17:58:57,843 train 550 1.659279e-01 -226.447144
2019-12-04 17:59:09,330 train 600 1.657018e-01 -228.646582
2019-12-04 17:59:20,818 train 650 1.663754e-01 -228.935450
2019-12-04 17:59:32,313 train 700 1.660770e-01 -228.688266
2019-12-04 17:59:43,803 train 750 1.658867e-01 -228.650848
2019-12-04 17:59:55,293 train 800 1.659829e-01 -229.115922
2019-12-04 18:00:06,784 train 850 1.661379e-01 -227.806119
2019-12-04 18:00:15,922 training loss; R2: 1.664616e-01 -227.538093
2019-12-04 18:00:16,059 valid 000 1.840136e-01 -305.117333
2019-12-04 18:00:18,469 valid 050 1.852195e-01 -227.022490
2019-12-04 18:00:20,781 validation loss; R2: 1.807473e-01 -213.294720
2019-12-04 18:00:20,795 epoch 2 lr 1.000000e-03
2019-12-04 18:00:21,106 train 000 1.374853e-01 -206.899293
2019-12-04 18:00:32,584 train 050 1.638446e-01 -225.675392
2019-12-04 18:00:44,064 train 100 1.665596e-01 -230.891205
2019-12-04 18:00:55,549 train 150 1.666914e-01 -232.823261
2019-12-04 18:01:07,032 train 200 1.661683e-01 -232.104030
2019-12-04 18:01:18,518 train 250 1.656775e-01 -228.830084
2019-12-04 18:01:30,003 train 300 1.663219e-01 -225.382469
2019-12-04 18:01:41,486 train 350 1.661764e-01 -225.447383
2019-12-04 18:01:52,969 train 400 1.661627e-01 -227.332069
2019-12-04 18:02:04,449 train 450 1.661185e-01 -227.586273
2019-12-04 18:02:15,930 train 500 1.657733e-01 -229.005504
2019-12-04 18:02:27,405 train 550 1.649698e-01 -228.979034
2019-12-04 18:02:38,894 train 600 1.646201e-01 -228.168927
2019-12-04 18:02:50,372 train 650 1.645793e-01 -229.092291
2019-12-04 18:03:01,832 train 700 1.649989e-01 -228.235976
2019-12-04 18:03:13,102 train 750 1.649632e-01 -228.270888
2019-12-04 18:03:24,365 train 800 1.647719e-01 -228.527925
2019-12-04 18:03:35,638 train 850 1.649864e-01 -228.731845
2019-12-04 18:03:44,606 training loss; R2: 1.648018e-01 -228.864565
2019-12-04 18:03:44,740 valid 000 2.201665e-01 -293.938248
2019-12-04 18:03:47,147 valid 050 1.871655e-01 -257.838573
2019-12-04 18:03:49,458 validation loss; R2: 1.804475e-01 -240.003329
2019-12-04 18:03:49,471 epoch 3 lr 1.000000e-03
2019-12-04 18:03:49,780 train 000 1.538632e-01 -301.821546
2019-12-04 18:04:01,052 train 050 1.664362e-01 -243.478417
2019-12-04 18:04:12,321 train 100 1.664090e-01 -233.149129
2019-12-04 18:04:23,594 train 150 1.657221e-01 -235.707113
2019-12-04 18:04:34,879 train 200 1.656914e-01 -237.376047
2019-12-04 18:04:46,174 train 250 1.654982e-01 -235.481604
2019-12-04 18:04:57,461 train 300 1.652520e-01 -232.681062
2019-12-04 18:05:08,740 train 350 1.650055e-01 -232.940939
2019-12-04 18:05:20,014 train 400 1.645003e-01 -232.812569
2019-12-04 18:05:31,293 train 450 1.643267e-01 -231.753569
2019-12-04 18:05:42,572 train 500 1.639712e-01 -232.171752
2019-12-04 18:05:53,848 train 550 1.638275e-01 -231.283455
2019-12-04 18:06:05,126 train 600 1.640189e-01 -231.018418
2019-12-04 18:06:16,408 train 650 1.641668e-01 -229.774731
2019-12-04 18:06:27,696 train 700 1.641787e-01 -230.495057
2019-12-04 18:06:38,975 train 750 1.643967e-01 -231.097341
2019-12-04 18:06:50,254 train 800 1.645141e-01 -231.119851
2019-12-04 18:07:01,536 train 850 1.641935e-01 -230.316016
2019-12-04 18:07:10,507 training loss; R2: 1.641767e-01 -231.313388
2019-12-04 18:07:10,643 valid 000 1.937992e-01 -162.448860
2019-12-04 18:07:13,051 valid 050 1.767834e-01 -218.483446
2019-12-04 18:07:15,360 validation loss; R2: 1.778494e-01 -216.687116
2019-12-04 18:07:15,374 epoch 4 lr 1.000000e-03
2019-12-04 18:07:15,689 train 000 1.713978e-01 -159.651650
2019-12-04 18:07:26,972 train 050 1.708376e-01 -220.888628
2019-12-04 18:07:38,248 train 100 1.676421e-01 -238.670493
2019-12-04 18:07:49,531 train 150 1.669497e-01 -232.948462
2019-12-04 18:08:00,796 train 200 1.655823e-01 -234.839906
2019-12-04 18:08:12,054 train 250 1.645197e-01 -232.578302
2019-12-04 18:08:23,310 train 300 1.639546e-01 -231.579718
2019-12-04 18:08:34,567 train 350 1.644586e-01 -234.306911
2019-12-04 18:08:45,825 train 400 1.641025e-01 -234.848902
2019-12-04 18:08:57,080 train 450 1.645293e-01 -234.162963
2019-12-04 18:09:08,339 train 500 1.650210e-01 -233.473125
2019-12-04 18:09:19,594 train 550 1.650351e-01 -233.392550
2019-12-04 18:09:30,850 train 600 1.644880e-01 -232.268831
2019-12-04 18:09:42,106 train 650 1.643323e-01 -231.398946
2019-12-04 18:09:53,358 train 700 1.639186e-01 -231.329783
2019-12-04 18:10:04,609 train 750 1.640662e-01 -230.960876
2019-12-04 18:10:15,866 train 800 1.640821e-01 -230.962320
2019-12-04 18:10:27,122 train 850 1.639058e-01 -231.620910
2019-12-04 18:10:36,072 training loss; R2: 1.635286e-01 -232.356501
2019-12-04 18:10:36,225 valid 000 1.761950e-01 -340.069606
2019-12-04 18:10:38,633 valid 050 1.788463e-01 -252.803208
2019-12-04 18:10:40,942 validation loss; R2: 1.800242e-01 -249.603465
2019-12-04 18:10:40,956 epoch 5 lr 1.000000e-03
2019-12-04 18:10:41,264 train 000 1.665335e-01 -271.998527
2019-12-04 18:10:52,520 train 050 1.618454e-01 -234.885316
2019-12-04 18:11:03,779 train 100 1.618443e-01 -225.640019
2019-12-04 18:11:15,039 train 150 1.625137e-01 -226.711545
2019-12-04 18:11:26,292 train 200 1.624054e-01 -229.163447
2019-12-04 18:11:37,547 train 250 1.608637e-01 -229.439973
2019-12-04 18:11:48,802 train 300 1.611320e-01 -230.267902
2019-12-04 18:12:00,060 train 350 1.617433e-01 -232.044242
2019-12-04 18:12:11,327 train 400 1.623727e-01 -231.444388
2019-12-04 18:12:22,598 train 450 1.625211e-01 -232.022321
2019-12-04 18:12:33,877 train 500 1.620651e-01 -232.455590
2019-12-04 18:12:45,147 train 550 1.631488e-01 -231.995985
2019-12-04 18:12:56,411 train 600 1.631234e-01 -231.547968
2019-12-04 18:13:07,687 train 650 1.632044e-01 -231.826948
2019-12-04 18:13:18,956 train 700 1.634863e-01 -232.925560
2019-12-04 18:13:30,222 train 750 1.633180e-01 -232.392447
2019-12-04 18:13:41,495 train 800 1.630600e-01 -231.699887
2019-12-04 18:13:52,777 train 850 1.629780e-01 -231.008550
2019-12-04 18:14:01,752 training loss; R2: 1.630394e-01 -231.769904
2019-12-04 18:14:01,894 valid 000 1.589537e-01 -223.558983
2019-12-04 18:14:04,302 valid 050 1.804956e-01 -236.711703
2019-12-04 18:14:06,611 validation loss; R2: 1.761122e-01 -233.879402
2019-12-04 18:14:06,625 epoch 6 lr 1.000000e-03
2019-12-04 18:14:06,936 train 000 1.938220e-01 -265.745251
2019-12-04 18:14:18,211 train 050 1.654087e-01 -221.630216
2019-12-04 18:14:29,485 train 100 1.655012e-01 -223.793571
2019-12-04 18:14:40,758 train 150 1.629633e-01 -228.133975
2019-12-04 18:14:52,033 train 200 1.630215e-01 -226.812160
2019-12-04 18:15:03,305 train 250 1.623576e-01 -229.857696
2019-12-04 18:15:14,573 train 300 1.631489e-01 -229.429558
2019-12-04 18:15:25,845 train 350 1.639917e-01 -229.517331
2019-12-04 18:15:37,117 train 400 1.643320e-01 -231.863482
2019-12-04 18:15:48,462 train 450 1.637847e-01 -230.787396
2019-12-04 18:15:59,947 train 500 1.638112e-01 -232.132952
2019-12-04 18:16:11,426 train 550 1.628654e-01 -232.282022
2019-12-04 18:16:22,909 train 600 1.632626e-01 -231.463050
2019-12-04 18:16:34,390 train 650 1.634302e-01 -232.705311
2019-12-04 18:16:45,872 train 700 1.627122e-01 -232.433148
2019-12-04 18:16:57,350 train 750 1.628436e-01 -231.969031
2019-12-04 18:17:08,834 train 800 1.622520e-01 -233.272610
2019-12-04 18:17:20,319 train 850 1.623012e-01 -233.078980
2019-12-04 18:17:29,456 training loss; R2: 1.624041e-01 -232.991290
2019-12-04 18:17:29,590 valid 000 1.390632e+00 -12478.367903
2019-12-04 18:17:32,001 valid 050 1.171193e+00 -9974.895879
2019-12-04 18:17:34,314 validation loss; R2: 1.155124e+00 -10233.527920
2019-12-04 18:17:34,334 epoch 7 lr 1.000000e-03
2019-12-04 18:17:34,651 train 000 1.479766e-01 -173.084509
2019-12-04 18:17:46,138 train 050 1.668613e-01 -232.902403
2019-12-04 18:17:57,615 train 100 1.629547e-01 -238.474921
2019-12-04 18:18:09,091 train 150 1.630727e-01 -236.314964
2019-12-04 18:18:20,571 train 200 1.628502e-01 -236.999076
2019-12-04 18:18:32,054 train 250 1.633893e-01 -232.973878
2019-12-04 18:18:43,538 train 300 1.627775e-01 -232.520261
2019-12-04 18:18:55,010 train 350 1.633656e-01 -234.298338
2019-12-04 18:19:06,482 train 400 1.633446e-01 -234.186107
2019-12-04 18:19:17,957 train 450 1.630970e-01 -232.933080
2019-12-04 18:19:29,429 train 500 1.631505e-01 -232.971353
2019-12-04 18:19:40,910 train 550 1.629166e-01 -233.831665
2019-12-04 18:19:52,392 train 600 1.629204e-01 -234.126380
2019-12-04 18:20:03,865 train 650 1.624064e-01 -233.753451
2019-12-04 18:20:15,339 train 700 1.618554e-01 -234.884013
2019-12-04 18:20:26,810 train 750 1.616884e-01 -236.027284
2019-12-04 18:20:38,288 train 800 1.623032e-01 -236.454517
2019-12-04 18:20:49,770 train 850 1.617934e-01 -237.176025
2019-12-04 18:20:58,874 training loss; R2: 1.617714e-01 -236.509145
2019-12-04 18:20:59,016 valid 000 1.429056e+01 -12591.413358
2019-12-04 18:21:01,425 valid 050 1.448755e+01 -8985.524827
2019-12-04 18:21:03,738 validation loss; R2: 1.447178e+01 -9334.481963
2019-12-04 18:21:03,752 epoch 8 lr 1.000000e-03
2019-12-04 18:21:04,068 train 000 1.417624e-01 -223.811316
2019-12-04 18:21:15,332 train 050 1.553953e-01 -231.953560
2019-12-04 18:21:26,600 train 100 1.606081e-01 -239.130250
2019-12-04 18:21:37,870 train 150 1.611096e-01 -235.894416
2019-12-04 18:21:49,142 train 200 1.620285e-01 -236.374254
2019-12-04 18:22:00,407 train 250 1.624780e-01 -231.418129
2019-12-04 18:22:11,679 train 300 1.637510e-01 -235.800378
2019-12-04 18:22:22,960 train 350 1.629778e-01 -233.722280
2019-12-04 18:22:34,238 train 400 1.628887e-01 -234.851325
2019-12-04 18:22:45,507 train 450 1.631088e-01 -234.279807
2019-12-04 18:22:56,772 train 500 1.627866e-01 -236.447752
2019-12-04 18:23:08,045 train 550 1.618526e-01 -235.529660
2019-12-04 18:23:19,317 train 600 1.613128e-01 -238.172469
2019-12-04 18:23:30,586 train 650 1.612206e-01 -238.114279
2019-12-04 18:23:41,854 train 700 1.613438e-01 -238.709237
2019-12-04 18:23:53,125 train 750 1.610142e-01 -237.626551
2019-12-04 18:24:04,391 train 800 1.609682e-01 -238.142488
2019-12-04 18:24:15,659 train 850 1.608965e-01 -238.425894
2019-12-04 18:24:24,623 training loss; R2: 1.613084e-01 -238.444316
2019-12-04 18:24:24,759 valid 000 1.058778e+00 -23007.976860
2019-12-04 18:24:27,166 valid 050 1.057885e+00 -14224.292632
2019-12-04 18:24:29,475 validation loss; R2: 1.085195e+00 -13969.620940
2019-12-04 18:24:29,489 epoch 9 lr 1.000000e-03
2019-12-04 18:24:29,799 train 000 2.230362e-01 -137.059783
2019-12-04 18:24:41,053 train 050 1.633338e-01 -232.014429
2019-12-04 18:24:52,311 train 100 1.616411e-01 -240.050915
2019-12-04 18:25:03,570 train 150 1.611457e-01 -239.998954
2019-12-04 18:25:14,826 train 200 1.607475e-01 -239.273505
2019-12-04 18:25:26,081 train 250 1.617077e-01 -238.992633
2019-12-04 18:25:37,336 train 300 1.623237e-01 -242.491854
2019-12-04 18:25:48,586 train 350 1.630443e-01 -239.481526
2019-12-04 18:25:59,842 train 400 1.633766e-01 -239.491433
2019-12-04 18:26:11,095 train 450 1.625219e-01 -239.767334
2019-12-04 18:26:22,347 train 500 1.621293e-01 -238.771525
2019-12-04 18:26:33,600 train 550 1.623411e-01 -238.305932
2019-12-04 18:26:44,852 train 600 1.621148e-01 -239.305761
2019-12-04 18:26:56,104 train 650 1.615576e-01 -239.190656
2019-12-04 18:27:07,356 train 700 1.616006e-01 -239.848017
2019-12-04 18:27:18,611 train 750 1.611300e-01 -238.980381
2019-12-04 18:27:29,868 train 800 1.607718e-01 -238.647121
2019-12-04 18:27:41,123 train 850 1.606577e-01 -239.278115
2019-12-04 18:27:50,075 training loss; R2: 1.608219e-01 -239.653752
2019-12-04 18:27:50,208 valid 000 4.846663e-01 -541.715041
2019-12-04 18:27:52,615 valid 050 4.797765e-01 -782.766546
2019-12-04 18:27:54,924 validation loss; R2: 4.882945e-01 -809.782932
2019-12-04 18:27:54,938 epoch 10 lr 1.000000e-03
2019-12-04 18:27:55,247 train 000 1.721020e-01 -184.873839
2019-12-04 18:28:06,499 train 050 1.650386e-01 -249.405453
2019-12-04 18:28:17,754 train 100 1.602761e-01 -249.147831
2019-12-04 18:28:29,005 train 150 1.611759e-01 -250.339255
2019-12-04 18:28:40,255 train 200 1.608657e-01 -246.769671
2019-12-04 18:28:51,508 train 250 1.609134e-01 -244.522776
2019-12-04 18:29:02,764 train 300 1.596971e-01 -244.016158
2019-12-04 18:29:14,017 train 350 1.593977e-01 -243.457461
2019-12-04 18:29:25,274 train 400 1.595228e-01 -243.639066
2019-12-04 18:29:36,536 train 450 1.596294e-01 -243.639670
2019-12-04 18:29:47,797 train 500 1.596926e-01 -243.226525
2019-12-04 18:29:59,048 train 550 1.598911e-01 -243.975667
2019-12-04 18:30:10,299 train 600 1.598383e-01 -243.296208
2019-12-04 18:30:21,556 train 650 1.597724e-01 -241.979758
2019-12-04 18:30:32,808 train 700 1.596541e-01 -241.783490
2019-12-04 18:30:44,060 train 750 1.595991e-01 -242.200433
2019-12-04 18:30:55,312 train 800 1.598852e-01 -242.935914
2019-12-04 18:31:06,571 train 850 1.600402e-01 -242.667562
2019-12-04 18:31:15,525 training loss; R2: 1.601530e-01 -243.029882
2019-12-04 18:31:15,661 valid 000 7.343508e+00 -1272.206270
2019-12-04 18:31:18,074 valid 050 7.089655e+00 -1776.986765
2019-12-04 18:31:20,387 validation loss; R2: 7.080089e+00 -1924.955540
2019-12-04 18:31:20,400 epoch 11 lr 1.000000e-03
2019-12-04 18:31:20,710 train 000 1.996282e-01 -323.903384
2019-12-04 18:31:31,965 train 050 1.597237e-01 -241.973802
2019-12-04 18:31:43,225 train 100 1.600645e-01 -233.421069
2019-12-04 18:31:54,483 train 150 1.596202e-01 -240.296199
2019-12-04 18:32:05,738 train 200 1.607489e-01 -239.181376
2019-12-04 18:32:16,997 train 250 1.603936e-01 -239.209569
2019-12-04 18:32:28,246 train 300 1.607261e-01 -242.743930
2019-12-04 18:32:39,499 train 350 1.598950e-01 -240.997900
2019-12-04 18:32:50,750 train 400 1.603439e-01 -240.288199
2019-12-04 18:33:01,994 train 450 1.602725e-01 -240.331189
2019-12-04 18:33:13,239 train 500 1.601770e-01 -240.339156
2019-12-04 18:33:24,489 train 550 1.599379e-01 -241.001133
2019-12-04 18:33:35,743 train 600 1.594932e-01 -242.342602
2019-12-04 18:33:46,992 train 650 1.600155e-01 -241.581902
2019-12-04 18:33:58,239 train 700 1.599106e-01 -242.551018
2019-12-04 18:34:09,485 train 750 1.598069e-01 -242.714161
2019-12-04 18:34:20,734 train 800 1.601939e-01 -243.235294
2019-12-04 18:34:31,978 train 850 1.596403e-01 -242.685075
2019-12-04 18:34:40,926 training loss; R2: 1.596866e-01 -243.002615
2019-12-04 18:34:41,060 valid 000 5.398702e+00 -912.474435
2019-12-04 18:34:43,466 valid 050 5.516522e+00 -1325.885452
2019-12-04 18:34:45,774 validation loss; R2: 5.521288e+00 -1306.733691
2019-12-04 18:34:45,792 epoch 12 lr 1.000000e-03
2019-12-04 18:34:46,101 train 000 1.917949e-01 -108.613761
2019-12-04 18:34:57,352 train 050 1.570840e-01 -248.226157
2019-12-04 18:35:08,602 train 100 1.598927e-01 -245.359493
2019-12-04 18:35:19,849 train 150 1.608050e-01 -246.090604
2019-12-04 18:35:31,101 train 200 1.607576e-01 -242.558836
2019-12-04 18:35:42,353 train 250 1.596147e-01 -242.418188
2019-12-04 18:35:53,602 train 300 1.594047e-01 -241.033723
2019-12-04 18:36:04,853 train 350 1.592174e-01 -243.066116
2019-12-04 18:36:16,096 train 400 1.592847e-01 -241.745951
2019-12-04 18:36:27,341 train 450 1.596303e-01 -242.391584
2019-12-04 18:36:38,587 train 500 1.603003e-01 -242.740666
2019-12-04 18:36:49,838 train 550 1.599415e-01 -244.022124
2019-12-04 18:37:01,088 train 600 1.597170e-01 -243.506854
2019-12-04 18:37:12,341 train 650 1.595905e-01 -244.087082
2019-12-04 18:37:23,597 train 700 1.598236e-01 -242.789545
2019-12-04 18:37:34,849 train 750 1.596729e-01 -242.455423
2019-12-04 18:37:46,104 train 800 1.594190e-01 -242.817896
2019-12-04 18:37:57,361 train 850 1.591748e-01 -242.280986
2019-12-04 18:38:06,312 training loss; R2: 1.591704e-01 -242.629574
2019-12-04 18:38:06,451 valid 000 4.158536e-01 -182.290795
2019-12-04 18:38:08,858 valid 050 4.247129e-01 -229.395366
2019-12-04 18:38:11,166 validation loss; R2: 4.201178e-01 -243.925920
2019-12-04 18:38:11,180 epoch 13 lr 1.000000e-03
2019-12-04 18:38:11,490 train 000 1.660289e-01 -521.957671
2019-12-04 18:38:22,734 train 050 1.591693e-01 -253.322340
2019-12-04 18:38:33,970 train 100 1.616088e-01 -245.522303
2019-12-04 18:38:45,207 train 150 1.593131e-01 -251.009963
2019-12-04 18:38:56,441 train 200 1.597776e-01 -247.919849
2019-12-04 18:39:07,675 train 250 1.595265e-01 -249.245753
2019-12-04 18:39:18,912 train 300 1.594667e-01 -249.940984
2019-12-04 18:39:30,154 train 350 1.588788e-01 -250.131534
2019-12-04 18:39:41,392 train 400 1.590230e-01 -250.946084
2019-12-04 18:39:52,634 train 450 1.586352e-01 -248.983282
2019-12-04 18:40:03,867 train 500 1.589292e-01 -248.414274
2019-12-04 18:40:15,103 train 550 1.586507e-01 -247.059788
2019-12-04 18:40:26,339 train 600 1.587727e-01 -247.567136
2019-12-04 18:40:37,571 train 650 1.585356e-01 -246.884407
2019-12-04 18:40:48,808 train 700 1.584669e-01 -246.727129
2019-12-04 18:41:00,046 train 750 1.580011e-01 -246.287391
2019-12-04 18:41:11,289 train 800 1.580827e-01 -247.277940
2019-12-04 18:41:22,531 train 850 1.584149e-01 -248.665190
2019-12-04 18:41:31,476 training loss; R2: 1.585552e-01 -247.945683
2019-12-04 18:41:31,611 valid 000 3.981690e+00 -296.716374
2019-12-04 18:41:34,018 valid 050 3.971314e+00 -745.656028
2019-12-04 18:41:36,326 validation loss; R2: 3.966627e+00 -773.395108
2019-12-04 18:41:36,339 epoch 14 lr 1.000000e-03
2019-12-04 18:41:36,645 train 000 1.276061e-01 -205.301937
2019-12-04 18:41:47,889 train 050 1.590052e-01 -256.333794
2019-12-04 18:41:59,131 train 100 1.562624e-01 -248.684355
2019-12-04 18:42:10,371 train 150 1.562060e-01 -243.814097
2019-12-04 18:42:21,611 train 200 1.559812e-01 -247.684957
2019-12-04 18:42:32,858 train 250 1.576781e-01 -246.082863
2019-12-04 18:42:44,109 train 300 1.565656e-01 -247.697878
2019-12-04 18:42:55,355 train 350 1.565416e-01 -249.333190
2019-12-04 18:43:06,603 train 400 1.561589e-01 -249.134503
2019-12-04 18:43:17,853 train 450 1.572263e-01 -249.751066
2019-12-04 18:43:29,099 train 500 1.569439e-01 -248.417971
2019-12-04 18:43:40,345 train 550 1.570092e-01 -246.345485
2019-12-04 18:43:51,591 train 600 1.572098e-01 -245.987310
2019-12-04 18:44:02,833 train 650 1.574479e-01 -246.848176
2019-12-04 18:44:14,074 train 700 1.572995e-01 -247.068972
2019-12-04 18:44:25,321 train 750 1.575743e-01 -246.471802
2019-12-04 18:44:36,570 train 800 1.577181e-01 -246.971756
2019-12-04 18:44:47,819 train 850 1.581008e-01 -247.576472
2019-12-04 18:44:56,767 training loss; R2: 1.581761e-01 -247.695629
2019-12-04 18:44:56,899 valid 000 4.142953e-01 -101.517357
2019-12-04 18:44:59,305 valid 050 4.076531e-01 -192.484183
2019-12-04 18:45:01,614 validation loss; R2: 4.014898e-01 -181.868324
2019-12-04 18:45:01,628 epoch 15 lr 1.000000e-03
2019-12-04 18:45:01,938 train 000 1.142415e-01 -179.461011
2019-12-04 18:45:13,182 train 050 1.541219e-01 -261.857104
2019-12-04 18:45:24,424 train 100 1.570158e-01 -260.185149
2019-12-04 18:45:35,670 train 150 1.559660e-01 -254.788289
2019-12-04 18:45:46,918 train 200 1.569024e-01 -255.684331
2019-12-04 18:45:58,167 train 250 1.573643e-01 -257.749667
2019-12-04 18:46:09,408 train 300 1.568021e-01 -252.194289
2019-12-04 18:46:20,655 train 350 1.568815e-01 -253.950642
2019-12-04 18:46:31,897 train 400 1.564722e-01 -252.941821
2019-12-04 18:46:43,139 train 450 1.564138e-01 -250.869542
2019-12-04 18:46:54,381 train 500 1.563376e-01 -250.027904
2019-12-04 18:47:05,618 train 550 1.564632e-01 -253.638500
2019-12-04 18:47:16,855 train 600 1.574120e-01 -254.008948
2019-12-04 18:47:28,116 train 650 1.574345e-01 -253.312620
2019-12-04 18:47:39,353 train 700 1.574907e-01 -253.374862
2019-12-04 18:47:50,596 train 750 1.576728e-01 -252.888268
2019-12-04 18:48:01,833 train 800 1.581251e-01 -252.759242
2019-12-04 18:48:13,073 train 850 1.575104e-01 -252.285920
2019-12-04 18:48:22,018 training loss; R2: 1.573807e-01 -252.777051
2019-12-04 18:48:22,150 valid 000 1.090308e+00 -75.873270
2019-12-04 18:48:24,557 valid 050 1.143794e+00 -103.281363
2019-12-04 18:48:26,866 validation loss; R2: 1.142071e+00 -106.574058
