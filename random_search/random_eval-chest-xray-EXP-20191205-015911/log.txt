2019-12-05 01:59:11,676 gpu device = 3
2019-12-05 01:59:11,677 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191205-015911', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-05 01:59:18,872 param size = 0.269118MB
2019-12-05 01:59:18,875 epoch 0 lr 1.000000e-03
2019-12-05 01:59:20,891 train 000 7.200263e-01 -2.386104
2019-12-05 01:59:35,735 train 050 3.893923e-01 -47.228022
2019-12-05 01:59:50,484 train 100 2.923568e-01 -116.574364
2019-12-05 02:00:05,227 train 150 2.580439e-01 -143.711506
2019-12-05 02:00:19,974 train 200 2.380601e-01 -161.921735
2019-12-05 02:00:34,715 train 250 2.257614e-01 -171.436964
2019-12-05 02:00:49,453 train 300 2.176788e-01 -180.283619
2019-12-05 02:01:04,182 train 350 2.110911e-01 -185.711066
2019-12-05 02:01:18,915 train 400 2.062836e-01 -190.455616
2019-12-05 02:01:33,645 train 450 2.024204e-01 -195.929211
2019-12-05 02:01:48,382 train 500 1.995480e-01 -199.397872
2019-12-05 02:02:03,118 train 550 1.972810e-01 -201.890963
2019-12-05 02:02:17,858 train 600 1.957628e-01 -205.450820
2019-12-05 02:02:32,594 train 650 1.939329e-01 -206.855058
2019-12-05 02:02:47,337 train 700 1.919577e-01 -208.612230
2019-12-05 02:03:02,083 train 750 1.913725e-01 -210.229328
2019-12-05 02:03:16,829 train 800 1.900762e-01 -210.241932
2019-12-05 02:03:31,578 train 850 1.891922e-01 -211.527505
2019-12-05 02:03:44,204 training loss; R2: 1.884573e-01 -213.563002
2019-12-05 02:03:44,358 valid 000 1.657313e-01 -273.274882
2019-12-05 02:03:47,399 valid 050 1.811702e-01 -208.387655
2019-12-05 02:03:50,472 validation loss; R2: 1.804925e-01 -208.458199
2019-12-05 02:03:50,491 epoch 1 lr 1.000000e-03
2019-12-05 02:03:50,991 train 000 1.372004e-01 -163.307528
2019-12-05 02:04:05,737 train 050 1.775264e-01 -223.255218
2019-12-05 02:04:20,482 train 100 1.736840e-01 -226.724882
2019-12-05 02:04:35,223 train 150 1.735405e-01 -225.967695
2019-12-05 02:04:49,964 train 200 1.712487e-01 -228.752909
2019-12-05 02:05:04,702 train 250 1.707716e-01 -233.156023
2019-12-05 02:05:19,442 train 300 1.691104e-01 -232.836906
2019-12-05 02:05:34,184 train 350 1.698715e-01 -231.219529
2019-12-05 02:05:48,923 train 400 1.693386e-01 -232.425965
2019-12-05 02:06:03,659 train 450 1.692679e-01 -233.678231
2019-12-05 02:06:18,397 train 500 1.689742e-01 -235.576758
2019-12-05 02:06:33,140 train 550 1.691465e-01 -235.001167
2019-12-05 02:06:47,891 train 600 1.688437e-01 -234.979887
2019-12-05 02:07:02,869 train 650 1.694266e-01 -234.431140
2019-12-05 02:07:17,928 train 700 1.699331e-01 -234.950893
2019-12-05 02:07:32,985 train 750 1.697205e-01 -236.205954
2019-12-05 02:07:48,059 train 800 1.700218e-01 -235.545337
2019-12-05 02:08:03,115 train 850 1.701823e-01 -235.630511
2019-12-05 02:08:15,097 training loss; R2: 1.702881e-01 -235.908818
2019-12-05 02:08:15,242 valid 000 2.391915e-01 -133.337515
2019-12-05 02:08:18,288 valid 050 1.775177e-01 -192.147425
2019-12-05 02:08:21,211 validation loss; R2: 1.798904e-01 -194.567955
2019-12-05 02:08:21,232 epoch 2 lr 1.000000e-03
2019-12-05 02:08:21,623 train 000 1.458803e-01 -279.195555
2019-12-05 02:08:36,399 train 050 1.702791e-01 -227.634990
2019-12-05 02:08:51,160 train 100 1.701216e-01 -228.044766
2019-12-05 02:09:05,916 train 150 1.709248e-01 -233.520046
2019-12-05 02:09:20,673 train 200 1.711007e-01 -234.819098
2019-12-05 02:09:35,425 train 250 1.709704e-01 -234.200241
2019-12-05 02:09:50,175 train 300 1.702100e-01 -233.775699
2019-12-05 02:10:04,926 train 350 1.701562e-01 -235.778080
2019-12-05 02:10:19,676 train 400 1.697217e-01 -236.582131
2019-12-05 02:10:34,422 train 450 1.696866e-01 -236.273078
2019-12-05 02:10:49,173 train 500 1.690902e-01 -236.333064
2019-12-05 02:11:03,930 train 550 1.696346e-01 -235.764802
2019-12-05 02:11:18,682 train 600 1.696861e-01 -235.879351
2019-12-05 02:11:33,433 train 650 1.693019e-01 -235.336141
2019-12-05 02:11:48,177 train 700 1.694497e-01 -235.229937
2019-12-05 02:12:02,925 train 750 1.690281e-01 -235.594651
2019-12-05 02:12:17,670 train 800 1.686742e-01 -235.486815
2019-12-05 02:12:32,418 train 850 1.683735e-01 -235.468678
2019-12-05 02:12:44,158 training loss; R2: 1.682600e-01 -235.834626
2019-12-05 02:12:44,305 valid 000 2.437629e-01 -166.642622
2019-12-05 02:12:47,349 valid 050 1.814184e-01 -231.718060
2019-12-05 02:12:50,269 validation loss; R2: 1.780569e-01 -225.171341
2019-12-05 02:12:50,291 epoch 3 lr 1.000000e-03
2019-12-05 02:12:50,677 train 000 1.667909e-01 -209.296949
2019-12-05 02:13:05,430 train 050 1.660625e-01 -230.408068
2019-12-05 02:13:20,181 train 100 1.666601e-01 -237.386124
2019-12-05 02:13:34,930 train 150 1.647610e-01 -234.354011
2019-12-05 02:13:49,682 train 200 1.649129e-01 -232.351919
2019-12-05 02:14:04,434 train 250 1.664715e-01 -234.452115
2019-12-05 02:14:19,185 train 300 1.671190e-01 -235.528430
2019-12-05 02:14:33,935 train 350 1.679563e-01 -238.711648
2019-12-05 02:14:48,687 train 400 1.680818e-01 -239.571253
2019-12-05 02:15:03,439 train 450 1.685953e-01 -238.777641
2019-12-05 02:15:18,234 train 500 1.687622e-01 -238.095883
2019-12-05 02:15:33,288 train 550 1.684905e-01 -239.127650
2019-12-05 02:15:48,347 train 600 1.682447e-01 -237.430844
2019-12-05 02:16:03,404 train 650 1.680850e-01 -236.260679
2019-12-05 02:16:18,460 train 700 1.677915e-01 -237.518749
2019-12-05 02:16:33,414 train 750 1.678815e-01 -238.600854
2019-12-05 02:16:48,155 train 800 1.672760e-01 -239.894071
2019-12-05 02:17:02,884 train 850 1.671680e-01 -239.761045
2019-12-05 02:17:14,601 training loss; R2: 1.673214e-01 -239.675452
2019-12-05 02:17:14,755 valid 000 1.994518e-01 -160.008356
2019-12-05 02:17:17,797 valid 050 1.789224e-01 -213.048773
2019-12-05 02:17:20,716 validation loss; R2: 1.771424e-01 -207.119646
2019-12-05 02:17:20,739 epoch 4 lr 1.000000e-03
2019-12-05 02:17:21,121 train 000 1.458418e-01 -252.227203
2019-12-05 02:17:35,863 train 050 1.681503e-01 -255.904147
2019-12-05 02:17:50,606 train 100 1.649651e-01 -254.846073
2019-12-05 02:18:05,339 train 150 1.651147e-01 -251.618975
2019-12-05 02:18:20,074 train 200 1.652982e-01 -246.682334
2019-12-05 02:18:34,821 train 250 1.647273e-01 -246.716671
2019-12-05 02:18:49,560 train 300 1.647207e-01 -247.459936
2019-12-05 02:19:04,293 train 350 1.655080e-01 -242.955977
2019-12-05 02:19:19,025 train 400 1.662801e-01 -243.659240
2019-12-05 02:19:33,763 train 450 1.657503e-01 -242.614745
2019-12-05 02:19:48,513 train 500 1.656929e-01 -242.606637
2019-12-05 02:20:03,262 train 550 1.661022e-01 -243.437294
2019-12-05 02:20:18,006 train 600 1.664529e-01 -243.067793
2019-12-05 02:20:32,754 train 650 1.666257e-01 -243.170605
2019-12-05 02:20:47,493 train 700 1.662041e-01 -241.006934
2019-12-05 02:21:02,229 train 750 1.666818e-01 -242.391588
2019-12-05 02:21:17,016 train 800 1.668820e-01 -241.511889
2019-12-05 02:21:32,069 train 850 1.668684e-01 -240.580026
2019-12-05 02:21:44,050 training loss; R2: 1.665332e-01 -240.001975
2019-12-05 02:21:44,196 valid 000 2.162187e-01 -125.034211
2019-12-05 02:21:47,243 valid 050 1.849391e-01 -152.309626
2019-12-05 02:21:50,166 validation loss; R2: 1.842576e-01 -162.094206
2019-12-05 02:21:50,186 epoch 5 lr 1.000000e-03
2019-12-05 02:21:50,580 train 000 1.495232e-01 -245.683718
2019-12-05 02:22:05,634 train 050 1.676507e-01 -245.142247
2019-12-05 02:22:20,668 train 100 1.684329e-01 -239.012612
2019-12-05 02:22:35,694 train 150 1.662597e-01 -236.598132
2019-12-05 02:22:50,501 train 200 1.659965e-01 -237.620653
2019-12-05 02:23:05,215 train 250 1.667639e-01 -239.267129
2019-12-05 02:23:19,931 train 300 1.680454e-01 -241.093324
2019-12-05 02:23:34,649 train 350 1.674664e-01 -240.956104
2019-12-05 02:23:49,368 train 400 1.672377e-01 -241.335103
2019-12-05 02:24:04,090 train 450 1.669072e-01 -242.162602
2019-12-05 02:24:18,801 train 500 1.663792e-01 -242.335827
2019-12-05 02:24:33,516 train 550 1.662084e-01 -241.538262
2019-12-05 02:24:48,229 train 600 1.659410e-01 -241.863580
2019-12-05 02:25:02,941 train 650 1.657438e-01 -242.366988
2019-12-05 02:25:17,650 train 700 1.661147e-01 -241.583847
2019-12-05 02:25:32,365 train 750 1.659288e-01 -241.686789
2019-12-05 02:25:47,083 train 800 1.657216e-01 -242.091243
2019-12-05 02:26:01,794 train 850 1.657002e-01 -242.952785
2019-12-05 02:26:13,494 training loss; R2: 1.660045e-01 -243.047531
2019-12-05 02:26:13,641 valid 000 1.963495e-01 -170.722255
2019-12-05 02:26:16,681 valid 050 1.911198e-01 -152.471780
2019-12-05 02:26:19,599 validation loss; R2: 1.900533e-01 -150.125841
2019-12-05 02:26:19,618 epoch 6 lr 1.000000e-03
2019-12-05 02:26:20,018 train 000 2.071062e-01 -159.809926
2019-12-05 02:26:34,737 train 050 1.671262e-01 -226.070839
2019-12-05 02:26:49,464 train 100 1.676865e-01 -232.289989
2019-12-05 02:27:04,195 train 150 1.656282e-01 -229.773884
2019-12-05 02:27:18,921 train 200 1.647598e-01 -232.451025
2019-12-05 02:27:33,635 train 250 1.648269e-01 -234.344263
2019-12-05 02:27:48,347 train 300 1.661626e-01 -235.457924
2019-12-05 02:28:03,055 train 350 1.662998e-01 -233.821733
2019-12-05 02:28:17,766 train 400 1.665939e-01 -235.640196
2019-12-05 02:28:32,504 train 450 1.665268e-01 -235.873990
2019-12-05 02:28:47,543 train 500 1.664363e-01 -238.880162
2019-12-05 02:29:02,574 train 550 1.662110e-01 -239.071140
2019-12-05 02:29:17,602 train 600 1.660627e-01 -239.075504
2019-12-05 02:29:32,638 train 650 1.657533e-01 -238.529557
2019-12-05 02:29:47,659 train 700 1.655861e-01 -238.892653
2019-12-05 02:30:02,681 train 750 1.653248e-01 -240.351076
2019-12-05 02:30:17,702 train 800 1.649444e-01 -240.241399
2019-12-05 02:30:32,730 train 850 1.647159e-01 -241.147850
2019-12-05 02:30:44,525 training loss; R2: 1.648662e-01 -240.667860
2019-12-05 02:30:44,676 valid 000 2.032801e-01 -320.324501
2019-12-05 02:30:47,717 valid 050 1.796221e-01 -192.303264
2019-12-05 02:30:50,634 validation loss; R2: 1.769255e-01 -193.629676
2019-12-05 02:30:50,653 epoch 7 lr 1.000000e-03
2019-12-05 02:30:51,034 train 000 1.394147e-01 -274.037525
2019-12-05 02:31:05,742 train 050 1.644823e-01 -246.836999
2019-12-05 02:31:20,449 train 100 1.661460e-01 -252.759469
2019-12-05 02:31:35,154 train 150 1.664817e-01 -256.105837
2019-12-05 02:31:49,857 train 200 1.665162e-01 -252.786932
2019-12-05 02:32:04,563 train 250 1.653159e-01 -250.707514
2019-12-05 02:32:19,271 train 300 1.656858e-01 -248.978636
2019-12-05 02:32:33,980 train 350 1.651219e-01 -246.831318
2019-12-05 02:32:48,689 train 400 1.648478e-01 -246.262177
2019-12-05 02:33:03,394 train 450 1.643344e-01 -246.101613
2019-12-05 02:33:18,100 train 500 1.643478e-01 -244.050240
2019-12-05 02:33:32,809 train 550 1.644649e-01 -243.795282
2019-12-05 02:33:47,520 train 600 1.639967e-01 -244.222277
2019-12-05 02:34:02,241 train 650 1.642157e-01 -245.029854
2019-12-05 02:34:16,959 train 700 1.643216e-01 -243.986685
2019-12-05 02:34:31,676 train 750 1.642632e-01 -243.301831
2019-12-05 02:34:46,389 train 800 1.645775e-01 -243.663461
2019-12-05 02:35:01,101 train 850 1.645090e-01 -242.770784
2019-12-05 02:35:12,804 training loss; R2: 1.642186e-01 -242.845084
2019-12-05 02:35:12,947 valid 000 2.341178e-01 -660.013846
2019-12-05 02:35:15,989 valid 050 1.889346e-01 -285.836742
2019-12-05 02:35:18,906 validation loss; R2: 1.875315e-01 -283.554224
2019-12-05 02:35:18,926 epoch 8 lr 1.000000e-03
2019-12-05 02:35:19,310 train 000 1.554104e-01 -149.061149
2019-12-05 02:35:34,024 train 050 1.698549e-01 -257.632379
2019-12-05 02:35:48,739 train 100 1.638098e-01 -246.748281
2019-12-05 02:36:03,452 train 150 1.625353e-01 -243.248178
2019-12-05 02:36:18,166 train 200 1.618798e-01 -250.351352
2019-12-05 02:36:32,877 train 250 1.627175e-01 -250.717717
2019-12-05 02:36:47,593 train 300 1.622712e-01 -250.006513
2019-12-05 02:37:02,311 train 350 1.629273e-01 -249.325942
2019-12-05 02:37:17,035 train 400 1.632025e-01 -249.352030
2019-12-05 02:37:31,746 train 450 1.630795e-01 -252.705894
2019-12-05 02:37:46,456 train 500 1.641599e-01 -250.904016
2019-12-05 02:38:01,170 train 550 1.637778e-01 -248.700446
2019-12-05 02:38:15,881 train 600 1.635953e-01 -248.346796
2019-12-05 02:38:30,588 train 650 1.634662e-01 -248.363192
2019-12-05 02:38:45,298 train 700 1.636249e-01 -247.438425
2019-12-05 02:39:00,004 train 750 1.636231e-01 -247.520553
2019-12-05 02:39:14,710 train 800 1.636726e-01 -246.747644
2019-12-05 02:39:29,422 train 850 1.636493e-01 -247.193710
2019-12-05 02:39:41,125 training loss; R2: 1.634958e-01 -248.117791
2019-12-05 02:39:41,269 valid 000 1.714289e-01 -316.381345
2019-12-05 02:39:44,311 valid 050 1.765645e-01 -231.714146
2019-12-05 02:39:47,228 validation loss; R2: 1.790944e-01 -232.873226
2019-12-05 02:39:47,247 epoch 9 lr 1.000000e-03
2019-12-05 02:39:47,633 train 000 1.370831e-01 -244.840600
2019-12-05 02:40:02,342 train 050 1.664634e-01 -245.426293
2019-12-05 02:40:17,048 train 100 1.654225e-01 -242.972618
2019-12-05 02:40:31,754 train 150 1.654858e-01 -238.844912
2019-12-05 02:40:46,464 train 200 1.649381e-01 -239.111142
2019-12-05 02:41:01,174 train 250 1.640049e-01 -239.595398
2019-12-05 02:41:15,878 train 300 1.641575e-01 -238.744873
2019-12-05 02:41:30,580 train 350 1.641444e-01 -243.200640
2019-12-05 02:41:45,290 train 400 1.639415e-01 -244.265361
2019-12-05 02:41:59,994 train 450 1.638402e-01 -243.756159
2019-12-05 02:42:14,698 train 500 1.636865e-01 -245.574824
2019-12-05 02:42:29,400 train 550 1.632735e-01 -246.588323
2019-12-05 02:42:44,100 train 600 1.627779e-01 -246.462120
2019-12-05 02:42:58,805 train 650 1.627635e-01 -246.458873
2019-12-05 02:43:13,504 train 700 1.628078e-01 -247.141330
2019-12-05 02:43:28,203 train 750 1.630952e-01 -246.371882
2019-12-05 02:43:42,910 train 800 1.633112e-01 -245.512310
2019-12-05 02:43:57,615 train 850 1.635534e-01 -246.643835
2019-12-05 02:44:09,308 training loss; R2: 1.633548e-01 -246.583612
2019-12-05 02:44:09,459 valid 000 6.030226e-01 -1180.023158
2019-12-05 02:44:12,498 valid 050 6.006974e-01 -1139.704546
2019-12-05 02:44:15,414 validation loss; R2: 6.069683e-01 -1279.037352
2019-12-05 02:44:15,432 epoch 10 lr 1.000000e-03
2019-12-05 02:44:15,814 train 000 1.658536e-01 -94.563118
2019-12-05 02:44:30,516 train 050 1.585332e-01 -246.328742
2019-12-05 02:44:45,217 train 100 1.578369e-01 -246.637383
2019-12-05 02:44:59,917 train 150 1.590403e-01 -248.161876
2019-12-05 02:45:14,616 train 200 1.600353e-01 -248.669211
2019-12-05 02:45:29,317 train 250 1.612761e-01 -249.515260
2019-12-05 02:45:44,020 train 300 1.607454e-01 -253.134885
2019-12-05 02:45:58,714 train 350 1.614697e-01 -253.483873
2019-12-05 02:46:13,407 train 400 1.604224e-01 -251.899721
2019-12-05 02:46:28,102 train 450 1.608125e-01 -250.598625
2019-12-05 02:46:42,795 train 500 1.618113e-01 -251.455353
2019-12-05 02:46:57,493 train 550 1.618652e-01 -251.119526
2019-12-05 02:47:12,197 train 600 1.619998e-01 -250.921826
2019-12-05 02:47:26,898 train 650 1.620874e-01 -250.209818
2019-12-05 02:47:41,600 train 700 1.625246e-01 -249.571302
2019-12-05 02:47:56,308 train 750 1.623555e-01 -249.393090
2019-12-05 02:48:11,012 train 800 1.624087e-01 -248.947291
2019-12-05 02:48:25,707 train 850 1.627492e-01 -248.903448
2019-12-05 02:48:37,403 training loss; R2: 1.626422e-01 -249.293250
2019-12-05 02:48:37,545 valid 000 1.494513e-01 -180.533499
2019-12-05 02:48:40,586 valid 050 1.783990e-01 -202.127475
2019-12-05 02:48:43,504 validation loss; R2: 1.770366e-01 -204.674549
2019-12-05 02:48:43,523 epoch 11 lr 1.000000e-03
2019-12-05 02:48:43,902 train 000 1.500722e-01 -354.091702
2019-12-05 02:48:58,592 train 050 1.583467e-01 -248.715855
2019-12-05 02:49:13,277 train 100 1.589027e-01 -251.352651
2019-12-05 02:49:27,965 train 150 1.591879e-01 -260.485175
2019-12-05 02:49:42,973 train 200 1.603213e-01 -260.228219
2019-12-05 02:49:57,977 train 250 1.592440e-01 -260.543500
2019-12-05 02:50:12,981 train 300 1.597267e-01 -258.612798
2019-12-05 02:50:27,986 train 350 1.602204e-01 -258.110298
2019-12-05 02:50:42,992 train 400 1.598656e-01 -256.120355
2019-12-05 02:50:57,996 train 450 1.600478e-01 -255.629202
2019-12-05 02:51:13,004 train 500 1.608643e-01 -254.596286
2019-12-05 02:51:28,013 train 550 1.610642e-01 -251.775338
2019-12-05 02:51:43,026 train 600 1.608574e-01 -252.281320
2019-12-05 02:51:58,034 train 650 1.614978e-01 -252.926987
2019-12-05 02:52:13,044 train 700 1.620279e-01 -253.054618
2019-12-05 02:52:28,047 train 750 1.616904e-01 -253.271090
2019-12-05 02:52:43,049 train 800 1.619981e-01 -253.521367
2019-12-05 02:52:58,050 train 850 1.619444e-01 -253.733601
2019-12-05 02:53:09,979 training loss; R2: 1.616523e-01 -254.037342
2019-12-05 02:53:10,122 valid 000 8.168113e-01 -1449.985679
2019-12-05 02:53:13,164 valid 050 7.859747e-01 -2650.190455
2019-12-05 02:53:16,081 validation loss; R2: 7.952801e-01 -2876.747562
2019-12-05 02:53:16,101 epoch 12 lr 1.000000e-03
2019-12-05 02:53:16,487 train 000 1.605228e-01 -421.665917
2019-12-05 02:53:31,478 train 050 1.561794e-01 -253.954531
2019-12-05 02:53:46,462 train 100 1.586416e-01 -253.650872
2019-12-05 02:54:01,453 train 150 1.581520e-01 -250.796264
2019-12-05 02:54:16,444 train 200 1.605242e-01 -251.014971
2019-12-05 02:54:31,443 train 250 1.593293e-01 -245.579617
2019-12-05 02:54:46,445 train 300 1.589360e-01 -244.162004
2019-12-05 02:55:01,449 train 350 1.599342e-01 -246.061129
2019-12-05 02:55:16,449 train 400 1.615480e-01 -247.913813
2019-12-05 02:55:31,447 train 450 1.615793e-01 -248.468726
2019-12-05 02:55:46,448 train 500 1.608546e-01 -248.581576
2019-12-05 02:56:01,449 train 550 1.612155e-01 -249.248752
2019-12-05 02:56:16,450 train 600 1.608507e-01 -249.129943
2019-12-05 02:56:31,449 train 650 1.609555e-01 -248.214142
2019-12-05 02:56:46,456 train 700 1.605435e-01 -248.938495
2019-12-05 02:57:01,457 train 750 1.604106e-01 -249.980990
2019-12-05 02:57:16,464 train 800 1.606258e-01 -250.973512
2019-12-05 02:57:31,469 train 850 1.610907e-01 -251.873208
2019-12-05 02:57:43,408 training loss; R2: 1.612009e-01 -250.881728
2019-12-05 02:57:43,559 valid 000 3.855391e+00 -827.575477
2019-12-05 02:57:46,603 valid 050 3.879593e+00 -771.905500
2019-12-05 02:57:49,523 validation loss; R2: 3.875549e+00 -814.538379
2019-12-05 02:57:49,547 epoch 13 lr 1.000000e-03
2019-12-05 02:57:49,943 train 000 1.451432e-01 -135.019893
2019-12-05 02:58:04,964 train 050 1.607278e-01 -248.478119
2019-12-05 02:58:19,984 train 100 1.597770e-01 -265.529292
2019-12-05 02:58:35,002 train 150 1.575898e-01 -257.902180
2019-12-05 02:58:50,027 train 200 1.585704e-01 -261.212401
2019-12-05 02:59:05,053 train 250 1.603260e-01 -259.516252
2019-12-05 02:59:20,074 train 300 1.611068e-01 -260.590338
2019-12-05 02:59:35,081 train 350 1.607153e-01 -259.828809
2019-12-05 02:59:50,099 train 400 1.612887e-01 -258.448754
2019-12-05 03:00:05,119 train 450 1.608609e-01 -256.371824
2019-12-05 03:00:20,143 train 500 1.608145e-01 -255.727860
2019-12-05 03:00:35,160 train 550 1.610793e-01 -253.398228
2019-12-05 03:00:50,183 train 600 1.613021e-01 -252.194774
2019-12-05 03:01:05,200 train 650 1.612222e-01 -250.428424
2019-12-05 03:01:20,218 train 700 1.608715e-01 -252.399889
2019-12-05 03:01:35,237 train 750 1.608130e-01 -251.599899
2019-12-05 03:01:50,251 train 800 1.611272e-01 -250.963616
2019-12-05 03:02:05,263 train 850 1.612531e-01 -249.734113
2019-12-05 03:02:17,211 training loss; R2: 1.609395e-01 -250.132874
2019-12-05 03:02:17,359 valid 000 5.021086e-01 -340.775863
2019-12-05 03:02:20,403 valid 050 4.562330e-01 -461.041588
2019-12-05 03:02:23,319 validation loss; R2: 4.575100e-01 -464.815454
2019-12-05 03:02:23,338 epoch 14 lr 1.000000e-03
2019-12-05 03:02:23,721 train 000 1.360784e-01 -238.412723
2019-12-05 03:02:38,414 train 050 1.556890e-01 -258.020203
2019-12-05 03:02:53,104 train 100 1.557406e-01 -260.753281
2019-12-05 03:03:07,793 train 150 1.583415e-01 -256.530588
2019-12-05 03:03:22,485 train 200 1.589404e-01 -256.235956
2019-12-05 03:03:37,176 train 250 1.594582e-01 -258.139350
2019-12-05 03:03:51,864 train 300 1.593243e-01 -259.203979
2019-12-05 03:04:06,572 train 350 1.594357e-01 -259.072309
2019-12-05 03:04:21,284 train 400 1.599609e-01 -258.421512
2019-12-05 03:04:35,989 train 450 1.603897e-01 -258.143825
2019-12-05 03:04:50,691 train 500 1.602685e-01 -258.128031
2019-12-05 03:05:05,379 train 550 1.603885e-01 -257.675005
2019-12-05 03:05:20,075 train 600 1.600600e-01 -258.497563
2019-12-05 03:05:34,759 train 650 1.599997e-01 -257.161580
2019-12-05 03:05:49,451 train 700 1.604138e-01 -256.107085
2019-12-05 03:06:04,136 train 750 1.604165e-01 -254.117087
2019-12-05 03:06:18,822 train 800 1.604082e-01 -253.718712
2019-12-05 03:06:33,515 train 850 1.603545e-01 -253.743666
2019-12-05 03:06:45,208 training loss; R2: 1.602711e-01 -254.601136
2019-12-05 03:06:45,361 valid 000 2.304188e+00 -1266.374814
2019-12-05 03:06:48,401 valid 050 2.383741e+00 -5648.711324
2019-12-05 03:06:51,319 validation loss; R2: 2.412296e+00 -6225.072792
2019-12-05 03:06:51,344 epoch 15 lr 1.000000e-03
2019-12-05 03:06:51,730 train 000 2.104152e-01 -235.334827
2019-12-05 03:07:06,416 train 050 1.602578e-01 -261.609273
2019-12-05 03:07:21,098 train 100 1.609454e-01 -261.196042
2019-12-05 03:07:35,785 train 150 1.609129e-01 -255.805354
2019-12-05 03:07:50,472 train 200 1.615178e-01 -250.462396
2019-12-05 03:08:05,157 train 250 1.595942e-01 -253.688792
2019-12-05 03:08:19,835 train 300 1.601835e-01 -255.724963
2019-12-05 03:08:34,504 train 350 1.594525e-01 -256.657352
2019-12-05 03:08:49,185 train 400 1.595770e-01 -258.135477
2019-12-05 03:09:03,854 train 450 1.597835e-01 -258.327514
2019-12-05 03:09:18,525 train 500 1.601951e-01 -256.730328
2019-12-05 03:09:33,194 train 550 1.599556e-01 -256.408439
2019-12-05 03:09:47,859 train 600 1.599004e-01 -257.543863
2019-12-05 03:10:02,529 train 650 1.597349e-01 -257.705535
2019-12-05 03:10:17,195 train 700 1.600433e-01 -256.229817
2019-12-05 03:10:31,862 train 750 1.602264e-01 -255.699195
2019-12-05 03:10:46,535 train 800 1.600503e-01 -256.244648
2019-12-05 03:11:01,202 train 850 1.596457e-01 -256.834430
2019-12-05 03:11:12,869 training loss; R2: 1.595471e-01 -256.834683
2019-12-05 03:11:13,018 valid 000 1.718272e-01 -177.434643
2019-12-05 03:11:16,058 valid 050 2.515679e-01 -341.892807
2019-12-05 03:11:18,974 validation loss; R2: 2.560993e-01 -342.790173
