2019-12-04 21:58:49,547 gpu device = 3
2019-12-04 21:58:49,547 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-215849', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 21:58:56,788 param size = 0.246974MB
2019-12-04 21:58:56,791 epoch 0 lr 1.000000e-03
2019-12-04 21:58:58,662 train 000 6.899365e-01 -0.623793
2019-12-04 21:59:11,359 train 050 5.414656e-01 -6.195839
2019-12-04 21:59:23,989 train 100 3.698617e-01 -65.277480
2019-12-04 21:59:36,632 train 150 3.051884e-01 -110.311336
2019-12-04 21:59:49,291 train 200 2.704583e-01 -131.692041
2019-12-04 22:00:01,940 train 250 2.511985e-01 -148.620871
2019-12-04 22:00:14,722 train 300 2.375143e-01 -159.873570
2019-12-04 22:00:27,643 train 350 2.274698e-01 -169.191773
2019-12-04 22:00:40,566 train 400 2.202121e-01 -174.810280
2019-12-04 22:00:53,484 train 450 2.152725e-01 -178.939362
2019-12-04 22:01:06,405 train 500 2.112668e-01 -182.444212
2019-12-04 22:01:19,223 train 550 2.068070e-01 -183.856867
2019-12-04 22:01:31,879 train 600 2.034066e-01 -186.144236
2019-12-04 22:01:44,545 train 650 2.008125e-01 -187.818629
2019-12-04 22:01:57,211 train 700 1.981404e-01 -189.764965
2019-12-04 22:02:09,859 train 750 1.961177e-01 -191.595739
2019-12-04 22:02:22,506 train 800 1.944141e-01 -193.744837
2019-12-04 22:02:35,154 train 850 1.929393e-01 -194.528375
2019-12-04 22:02:46,032 training loss; R2: 1.917670e-01 -194.429820
2019-12-04 22:02:46,190 valid 000 1.947931e-01 -262.553610
2019-12-04 22:02:48,811 valid 050 1.829665e-01 -209.509124
2019-12-04 22:02:51,460 validation loss; R2: 1.797722e-01 -195.165404
2019-12-04 22:02:51,478 epoch 1 lr 1.000000e-03
2019-12-04 22:02:51,887 train 000 2.206696e-01 -164.484563
2019-12-04 22:03:04,529 train 050 1.694936e-01 -200.579048
2019-12-04 22:03:17,166 train 100 1.648531e-01 -204.628497
2019-12-04 22:03:29,815 train 150 1.656567e-01 -206.560587
2019-12-04 22:03:42,457 train 200 1.658821e-01 -210.293992
2019-12-04 22:03:55,105 train 250 1.674897e-01 -215.747534
2019-12-04 22:04:07,754 train 300 1.676595e-01 -217.247860
2019-12-04 22:04:20,398 train 350 1.673006e-01 -217.021351
2019-12-04 22:04:33,049 train 400 1.679373e-01 -220.199137
2019-12-04 22:04:45,696 train 450 1.680238e-01 -219.638674
2019-12-04 22:04:58,343 train 500 1.677306e-01 -220.254235
2019-12-04 22:05:10,989 train 550 1.675190e-01 -221.963717
2019-12-04 22:05:23,639 train 600 1.665301e-01 -222.005673
2019-12-04 22:05:36,285 train 650 1.664795e-01 -221.381272
2019-12-04 22:05:48,931 train 700 1.666832e-01 -221.275860
2019-12-04 22:06:01,577 train 750 1.660560e-01 -220.305519
2019-12-04 22:06:14,225 train 800 1.662497e-01 -220.926564
2019-12-04 22:06:26,869 train 850 1.658523e-01 -219.418127
2019-12-04 22:06:36,928 training loss; R2: 1.658664e-01 -218.775509
2019-12-04 22:06:37,071 valid 000 1.666076e-01 -463.908139
2019-12-04 22:06:39,693 valid 050 1.833042e-01 -242.096108
2019-12-04 22:06:42,208 validation loss; R2: 1.799297e-01 -232.975756
2019-12-04 22:06:42,225 epoch 2 lr 1.000000e-03
2019-12-04 22:06:42,564 train 000 1.556477e-01 -157.453742
2019-12-04 22:06:55,206 train 050 1.634971e-01 -222.796659
2019-12-04 22:07:07,848 train 100 1.664210e-01 -228.209921
2019-12-04 22:07:20,491 train 150 1.669404e-01 -220.184079
2019-12-04 22:07:33,135 train 200 1.653049e-01 -221.611891
2019-12-04 22:07:45,780 train 250 1.664369e-01 -220.904440
2019-12-04 22:07:58,416 train 300 1.668874e-01 -221.570691
2019-12-04 22:08:11,058 train 350 1.662713e-01 -220.839745
2019-12-04 22:08:23,714 train 400 1.663276e-01 -221.289042
2019-12-04 22:08:36,366 train 450 1.663706e-01 -221.660023
2019-12-04 22:08:49,026 train 500 1.664369e-01 -221.973250
2019-12-04 22:09:01,680 train 550 1.657055e-01 -221.742685
2019-12-04 22:09:14,318 train 600 1.653136e-01 -221.604926
2019-12-04 22:09:26,963 train 650 1.648025e-01 -221.997728
2019-12-04 22:09:39,605 train 700 1.649451e-01 -222.779632
2019-12-04 22:09:52,246 train 750 1.644356e-01 -222.383850
2019-12-04 22:10:04,876 train 800 1.646671e-01 -222.431471
2019-12-04 22:10:17,511 train 850 1.645077e-01 -222.902178
2019-12-04 22:10:27,569 training loss; R2: 1.644940e-01 -223.331285
2019-12-04 22:10:27,705 valid 000 1.899250e-01 -315.958860
2019-12-04 22:10:30,326 valid 050 1.798248e-01 -218.989542
2019-12-04 22:10:32,840 validation loss; R2: 1.773596e-01 -220.709723
2019-12-04 22:10:32,861 epoch 3 lr 1.000000e-03
2019-12-04 22:10:33,203 train 000 1.606859e-01 -100.003742
2019-12-04 22:10:45,848 train 050 1.611563e-01 -208.028649
2019-12-04 22:10:58,488 train 100 1.626972e-01 -205.574585
2019-12-04 22:11:11,131 train 150 1.647130e-01 -210.775055
2019-12-04 22:11:23,777 train 200 1.651194e-01 -212.586029
2019-12-04 22:11:36,417 train 250 1.637067e-01 -215.898391
2019-12-04 22:11:49,063 train 300 1.645731e-01 -220.785926
2019-12-04 22:12:01,703 train 350 1.646913e-01 -223.188550
2019-12-04 22:12:14,352 train 400 1.650884e-01 -225.127392
2019-12-04 22:12:26,993 train 450 1.651454e-01 -224.336158
2019-12-04 22:12:39,640 train 500 1.645579e-01 -224.420842
2019-12-04 22:12:52,291 train 550 1.642404e-01 -224.545870
2019-12-04 22:13:04,942 train 600 1.641302e-01 -222.967441
2019-12-04 22:13:17,593 train 650 1.638430e-01 -222.107568
2019-12-04 22:13:30,241 train 700 1.637646e-01 -221.819545
2019-12-04 22:13:42,893 train 750 1.634706e-01 -223.685112
2019-12-04 22:13:55,544 train 800 1.637085e-01 -223.611449
2019-12-04 22:14:08,190 train 850 1.637680e-01 -222.913714
2019-12-04 22:14:18,248 training loss; R2: 1.635920e-01 -223.575684
2019-12-04 22:14:18,384 valid 000 1.786436e-01 -247.933780
2019-12-04 22:14:21,004 valid 050 1.794473e-01 -207.535419
2019-12-04 22:14:23,518 validation loss; R2: 1.765786e-01 -217.098957
2019-12-04 22:14:23,535 epoch 4 lr 1.000000e-03
2019-12-04 22:14:23,878 train 000 1.958401e-01 -268.426867
2019-12-04 22:14:36,511 train 050 1.646846e-01 -239.268770
2019-12-04 22:14:49,153 train 100 1.643755e-01 -233.430244
2019-12-04 22:15:01,797 train 150 1.652445e-01 -229.226668
2019-12-04 22:15:14,439 train 200 1.634300e-01 -229.464331
2019-12-04 22:15:27,086 train 250 1.624722e-01 -229.187823
2019-12-04 22:15:39,725 train 300 1.641601e-01 -228.044087
2019-12-04 22:15:52,371 train 350 1.644710e-01 -227.725189
2019-12-04 22:16:05,010 train 400 1.640673e-01 -227.871946
2019-12-04 22:16:17,647 train 450 1.637568e-01 -228.551215
2019-12-04 22:16:30,292 train 500 1.637041e-01 -228.482802
2019-12-04 22:16:42,938 train 550 1.632089e-01 -228.337837
2019-12-04 22:16:55,579 train 600 1.632671e-01 -228.930371
2019-12-04 22:17:08,217 train 650 1.630727e-01 -228.898135
2019-12-04 22:17:20,856 train 700 1.627688e-01 -230.020712
2019-12-04 22:17:33,501 train 750 1.629561e-01 -231.662337
2019-12-04 22:17:46,155 train 800 1.629636e-01 -231.517474
2019-12-04 22:17:58,797 train 850 1.626055e-01 -230.624171
2019-12-04 22:18:08,850 training loss; R2: 1.624043e-01 -230.648554
2019-12-04 22:18:08,993 valid 000 1.880113e-01 -169.154295
2019-12-04 22:18:11,613 valid 050 1.729757e-01 -225.138192
2019-12-04 22:18:14,127 validation loss; R2: 1.766758e-01 -227.820843
2019-12-04 22:18:14,145 epoch 5 lr 1.000000e-03
2019-12-04 22:18:14,488 train 000 1.841220e-01 -221.913588
2019-12-04 22:18:27,133 train 050 1.659014e-01 -227.678983
2019-12-04 22:18:39,775 train 100 1.644655e-01 -234.183983
2019-12-04 22:18:52,416 train 150 1.646872e-01 -234.421067
2019-12-04 22:19:05,063 train 200 1.635617e-01 -233.597629
2019-12-04 22:19:17,702 train 250 1.636285e-01 -231.300330
2019-12-04 22:19:30,339 train 300 1.633917e-01 -236.883069
2019-12-04 22:19:42,977 train 350 1.642178e-01 -238.258650
2019-12-04 22:19:55,615 train 400 1.634561e-01 -237.882707
2019-12-04 22:20:08,252 train 450 1.632125e-01 -237.902789
2019-12-04 22:20:20,885 train 500 1.627529e-01 -238.641289
2019-12-04 22:20:33,521 train 550 1.620616e-01 -239.487621
2019-12-04 22:20:46,157 train 600 1.612459e-01 -241.605868
2019-12-04 22:20:58,789 train 650 1.613094e-01 -241.253436
2019-12-04 22:21:11,421 train 700 1.610119e-01 -240.602701
2019-12-04 22:21:24,058 train 750 1.609411e-01 -242.307413
2019-12-04 22:21:36,690 train 800 1.608495e-01 -242.268435
2019-12-04 22:21:49,327 train 850 1.606547e-01 -242.312529
2019-12-04 22:21:59,372 training loss; R2: 1.609945e-01 -242.371212
2019-12-04 22:21:59,509 valid 000 2.990896e-01 -1114.554770
2019-12-04 22:22:02,129 valid 050 2.849002e-01 -688.985750
2019-12-04 22:22:04,642 validation loss; R2: 2.864730e-01 -696.551777
2019-12-04 22:22:04,659 epoch 6 lr 1.000000e-03
2019-12-04 22:22:05,002 train 000 1.531984e-01 -105.981783
2019-12-04 22:22:17,638 train 050 1.662358e-01 -249.778224
2019-12-04 22:22:30,273 train 100 1.637077e-01 -239.591718
2019-12-04 22:22:42,931 train 150 1.614570e-01 -239.364401
2019-12-04 22:22:55,568 train 200 1.623746e-01 -242.987579
2019-12-04 22:23:08,196 train 250 1.616553e-01 -243.686319
2019-12-04 22:23:20,827 train 300 1.605788e-01 -246.457291
2019-12-04 22:23:33,452 train 350 1.607365e-01 -244.641311
2019-12-04 22:23:46,088 train 400 1.601673e-01 -243.351907
2019-12-04 22:23:58,972 train 450 1.605106e-01 -241.239069
2019-12-04 22:24:11,916 train 500 1.601514e-01 -241.868834
2019-12-04 22:24:24,856 train 550 1.594794e-01 -242.078313
2019-12-04 22:24:37,792 train 600 1.594217e-01 -241.478612
2019-12-04 22:24:50,719 train 650 1.595408e-01 -243.466091
2019-12-04 22:25:03,652 train 700 1.596019e-01 -245.566966
2019-12-04 22:25:16,582 train 750 1.599663e-01 -245.860317
2019-12-04 22:25:29,509 train 800 1.600859e-01 -245.136930
2019-12-04 22:25:42,435 train 850 1.599047e-01 -246.144300
2019-12-04 22:25:52,716 training loss; R2: 1.597414e-01 -246.304061
2019-12-04 22:25:52,852 valid 000 4.061667e-01 -4280.927422
2019-12-04 22:25:55,474 valid 050 4.958128e-01 -2563.557864
2019-12-04 22:25:57,989 validation loss; R2: 4.864922e-01 -2591.810275
2019-12-04 22:25:58,008 epoch 7 lr 1.000000e-03
2019-12-04 22:25:58,358 train 000 1.603654e-01 -191.683983
2019-12-04 22:26:11,245 train 050 1.606617e-01 -240.305141
2019-12-04 22:26:24,130 train 100 1.596387e-01 -250.149088
2019-12-04 22:26:37,010 train 150 1.617701e-01 -250.227276
2019-12-04 22:26:49,891 train 200 1.592560e-01 -253.293359
2019-12-04 22:27:02,772 train 250 1.589804e-01 -252.553810
2019-12-04 22:27:15,654 train 300 1.587892e-01 -252.498736
2019-12-04 22:27:28,535 train 350 1.585802e-01 -252.163192
2019-12-04 22:27:41,433 train 400 1.586678e-01 -249.418366
2019-12-04 22:27:54,311 train 450 1.585318e-01 -250.273829
2019-12-04 22:28:06,923 train 500 1.583908e-01 -247.860830
2019-12-04 22:28:19,533 train 550 1.584578e-01 -248.501121
2019-12-04 22:28:32,142 train 600 1.586274e-01 -247.386973
2019-12-04 22:28:44,749 train 650 1.592884e-01 -247.784731
2019-12-04 22:28:57,358 train 700 1.592963e-01 -247.980110
2019-12-04 22:29:09,964 train 750 1.589562e-01 -248.508294
2019-12-04 22:29:22,568 train 800 1.585636e-01 -248.053731
2019-12-04 22:29:35,166 train 850 1.586371e-01 -248.611720
2019-12-04 22:29:45,191 training loss; R2: 1.588531e-01 -248.481697
2019-12-04 22:29:45,337 valid 000 3.183378e-01 -1183.410060
2019-12-04 22:29:47,956 valid 050 3.509336e-01 -1535.562040
2019-12-04 22:29:50,468 validation loss; R2: 3.537419e-01 -1525.278391
2019-12-04 22:29:50,489 epoch 8 lr 1.000000e-03
2019-12-04 22:29:50,833 train 000 1.615326e-01 -161.084322
2019-12-04 22:30:03,443 train 050 1.605670e-01 -259.076891
2019-12-04 22:30:16,050 train 100 1.608397e-01 -255.309072
2019-12-04 22:30:28,657 train 150 1.585710e-01 -249.076542
2019-12-04 22:30:41,264 train 200 1.582955e-01 -247.469554
2019-12-04 22:30:53,878 train 250 1.566869e-01 -248.269309
2019-12-04 22:31:06,491 train 300 1.567297e-01 -248.668016
2019-12-04 22:31:19,103 train 350 1.567967e-01 -248.718983
2019-12-04 22:31:31,708 train 400 1.567520e-01 -248.398850
2019-12-04 22:31:44,315 train 450 1.570431e-01 -250.752429
2019-12-04 22:31:56,925 train 500 1.575757e-01 -249.751911
2019-12-04 22:32:09,529 train 550 1.577296e-01 -249.043017
2019-12-04 22:32:22,139 train 600 1.577388e-01 -249.264670
2019-12-04 22:32:34,747 train 650 1.574895e-01 -249.772344
2019-12-04 22:32:47,356 train 700 1.572975e-01 -251.103958
2019-12-04 22:32:59,964 train 750 1.576397e-01 -250.790434
2019-12-04 22:33:12,573 train 800 1.577971e-01 -250.396129
2019-12-04 22:33:25,176 train 850 1.577318e-01 -249.471134
2019-12-04 22:33:35,197 training loss; R2: 1.581316e-01 -249.811578
2019-12-04 22:33:35,334 valid 000 1.081612e+00 -12050.189622
2019-12-04 22:33:37,954 valid 050 1.230722e+00 -11372.781739
2019-12-04 22:33:40,467 validation loss; R2: 1.256752e+00 -11325.724401
2019-12-04 22:33:40,492 epoch 9 lr 1.000000e-03
2019-12-04 22:33:40,829 train 000 1.466652e-01 -84.918897
2019-12-04 22:33:53,431 train 050 1.525144e-01 -262.121179
2019-12-04 22:34:06,037 train 100 1.521445e-01 -259.103323
2019-12-04 22:34:18,637 train 150 1.531111e-01 -249.761230
2019-12-04 22:34:31,525 train 200 1.552588e-01 -251.934492
2019-12-04 22:34:44,411 train 250 1.554896e-01 -251.794708
2019-12-04 22:34:57,301 train 300 1.561079e-01 -256.532407
2019-12-04 22:35:10,190 train 350 1.560724e-01 -256.012889
2019-12-04 22:35:23,074 train 400 1.570148e-01 -255.161450
2019-12-04 22:35:35,756 train 450 1.561585e-01 -255.120900
2019-12-04 22:35:48,353 train 500 1.564575e-01 -254.484451
2019-12-04 22:36:00,950 train 550 1.570109e-01 -254.226726
2019-12-04 22:36:13,549 train 600 1.567056e-01 -254.246283
2019-12-04 22:36:26,144 train 650 1.564697e-01 -256.441232
2019-12-04 22:36:38,737 train 700 1.566576e-01 -254.741616
2019-12-04 22:36:51,334 train 750 1.570894e-01 -254.503120
2019-12-04 22:37:03,923 train 800 1.573902e-01 -253.601135
2019-12-04 22:37:16,520 train 850 1.574151e-01 -253.550200
2019-12-04 22:37:26,535 training loss; R2: 1.574337e-01 -251.672326
2019-12-04 22:37:26,684 valid 000 3.467141e-01 -1448.098528
2019-12-04 22:37:29,301 valid 050 4.445665e-01 -1470.833471
2019-12-04 22:37:31,813 validation loss; R2: 4.510188e-01 -1494.831342
2019-12-04 22:37:31,830 epoch 10 lr 1.000000e-03
2019-12-04 22:37:32,171 train 000 1.093653e-01 -142.598198
2019-12-04 22:37:44,761 train 050 1.610108e-01 -259.013904
2019-12-04 22:37:57,353 train 100 1.567447e-01 -258.589076
2019-12-04 22:38:09,947 train 150 1.560322e-01 -259.903287
2019-12-04 22:38:22,537 train 200 1.575447e-01 -256.897629
2019-12-04 22:38:35,129 train 250 1.575815e-01 -255.360578
2019-12-04 22:38:47,743 train 300 1.580990e-01 -253.735609
2019-12-04 22:39:00,353 train 350 1.579704e-01 -255.548174
2019-12-04 22:39:12,954 train 400 1.579236e-01 -251.363322
2019-12-04 22:39:25,551 train 450 1.578321e-01 -253.302179
2019-12-04 22:39:38,152 train 500 1.577649e-01 -253.331735
2019-12-04 22:39:50,751 train 550 1.573127e-01 -254.540112
2019-12-04 22:40:03,345 train 600 1.574557e-01 -254.952230
2019-12-04 22:40:15,950 train 650 1.573257e-01 -256.071455
2019-12-04 22:40:28,549 train 700 1.573407e-01 -256.533656
2019-12-04 22:40:41,139 train 750 1.572871e-01 -256.256456
2019-12-04 22:40:53,728 train 800 1.570620e-01 -256.036816
2019-12-04 22:41:06,320 train 850 1.571014e-01 -255.401437
2019-12-04 22:41:16,336 training loss; R2: 1.567542e-01 -256.517516
2019-12-04 22:41:16,473 valid 000 2.210349e-01 -312.192396
2019-12-04 22:41:19,091 valid 050 2.383823e-01 -165.053966
2019-12-04 22:41:21,602 validation loss; R2: 2.377937e-01 -169.086621
2019-12-04 22:41:21,620 epoch 11 lr 1.000000e-03
2019-12-04 22:41:21,963 train 000 1.488186e-01 -222.642583
2019-12-04 22:41:34,554 train 050 1.564376e-01 -271.252553
2019-12-04 22:41:47,140 train 100 1.565247e-01 -265.643640
2019-12-04 22:41:59,729 train 150 1.544602e-01 -263.986526
2019-12-04 22:42:12,319 train 200 1.551588e-01 -264.449617
2019-12-04 22:42:24,907 train 250 1.555908e-01 -264.753977
2019-12-04 22:42:37,496 train 300 1.556333e-01 -262.826007
2019-12-04 22:42:50,084 train 350 1.552432e-01 -264.188837
2019-12-04 22:43:02,671 train 400 1.553177e-01 -263.289829
2019-12-04 22:43:15,263 train 450 1.554391e-01 -262.082490
2019-12-04 22:43:27,855 train 500 1.554136e-01 -260.361596
2019-12-04 22:43:40,445 train 550 1.556617e-01 -261.491697
2019-12-04 22:43:53,041 train 600 1.558237e-01 -261.892849
2019-12-04 22:44:05,627 train 650 1.562571e-01 -260.328781
2019-12-04 22:44:18,209 train 700 1.562576e-01 -261.359329
2019-12-04 22:44:30,801 train 750 1.562546e-01 -261.672541
2019-12-04 22:44:43,387 train 800 1.560921e-01 -261.209522
2019-12-04 22:44:55,972 train 850 1.563571e-01 -261.302204
2019-12-04 22:45:05,987 training loss; R2: 1.563459e-01 -260.438177
2019-12-04 22:45:06,126 valid 000 1.925170e-01 -326.934656
2019-12-04 22:45:08,744 valid 050 2.009818e-01 -340.450630
2019-12-04 22:45:11,256 validation loss; R2: 2.011668e-01 -344.132094
2019-12-04 22:45:11,274 epoch 12 lr 1.000000e-03
2019-12-04 22:45:11,613 train 000 1.094259e-01 -218.651018
2019-12-04 22:45:24,198 train 050 1.575171e-01 -259.030809
2019-12-04 22:45:36,789 train 100 1.559631e-01 -257.412129
2019-12-04 22:45:49,372 train 150 1.559156e-01 -255.235308
2019-12-04 22:46:01,958 train 200 1.551409e-01 -257.742258
2019-12-04 22:46:14,549 train 250 1.536061e-01 -259.365434
2019-12-04 22:46:27,133 train 300 1.545919e-01 -259.792641
2019-12-04 22:46:39,715 train 350 1.550979e-01 -262.409962
2019-12-04 22:46:52,299 train 400 1.551407e-01 -262.565540
2019-12-04 22:47:04,877 train 450 1.552303e-01 -262.295479
2019-12-04 22:47:17,461 train 500 1.554178e-01 -263.015944
2019-12-04 22:47:30,046 train 550 1.554155e-01 -262.535899
2019-12-04 22:47:42,628 train 600 1.553633e-01 -262.737561
2019-12-04 22:47:55,223 train 650 1.555260e-01 -263.064673
2019-12-04 22:48:07,814 train 700 1.552574e-01 -262.546548
2019-12-04 22:48:20,399 train 750 1.554065e-01 -263.319863
2019-12-04 22:48:32,988 train 800 1.557600e-01 -263.843509
2019-12-04 22:48:45,577 train 850 1.557776e-01 -263.303981
2019-12-04 22:48:55,586 training loss; R2: 1.558207e-01 -262.581714
2019-12-04 22:48:55,724 valid 000 1.659787e-01 -229.834401
2019-12-04 22:48:58,341 valid 050 1.966498e-01 -368.211249
2019-12-04 22:49:00,854 validation loss; R2: 1.923771e-01 -375.499513
2019-12-04 22:49:00,872 epoch 13 lr 1.000000e-03
2019-12-04 22:49:01,213 train 000 1.381092e-01 -169.240045
2019-12-04 22:49:13,796 train 050 1.524599e-01 -259.815534
2019-12-04 22:49:26,381 train 100 1.549736e-01 -261.019041
2019-12-04 22:49:38,963 train 150 1.558148e-01 -264.453276
2019-12-04 22:49:51,558 train 200 1.562276e-01 -264.491887
2019-12-04 22:50:04,142 train 250 1.555859e-01 -265.466706
2019-12-04 22:50:16,729 train 300 1.556043e-01 -263.594505
2019-12-04 22:50:29,316 train 350 1.560104e-01 -262.784190
2019-12-04 22:50:41,898 train 400 1.562151e-01 -260.735723
2019-12-04 22:50:54,477 train 450 1.566660e-01 -261.636117
2019-12-04 22:51:07,069 train 500 1.571576e-01 -262.878128
2019-12-04 22:51:19,655 train 550 1.567845e-01 -263.157983
2019-12-04 22:51:32,236 train 600 1.563008e-01 -262.227895
2019-12-04 22:51:44,820 train 650 1.557124e-01 -264.229720
2019-12-04 22:51:57,404 train 700 1.556545e-01 -265.786164
2019-12-04 22:52:09,984 train 750 1.557400e-01 -265.227935
2019-12-04 22:52:22,561 train 800 1.555416e-01 -264.772095
2019-12-04 22:52:35,134 train 850 1.553499e-01 -264.583577
2019-12-04 22:52:45,140 training loss; R2: 1.552409e-01 -264.044804
2019-12-04 22:52:45,277 valid 000 2.424250e-01 -461.706504
2019-12-04 22:52:47,893 valid 050 1.842263e-01 -217.910846
2019-12-04 22:52:50,404 validation loss; R2: 1.865966e-01 -210.942139
2019-12-04 22:52:50,422 epoch 14 lr 1.000000e-03
2019-12-04 22:52:50,762 train 000 1.027342e-01 -212.059362
2019-12-04 22:53:03,345 train 050 1.511026e-01 -242.219185
2019-12-04 22:53:15,925 train 100 1.535370e-01 -264.969571
2019-12-04 22:53:28,514 train 150 1.537017e-01 -266.962751
2019-12-04 22:53:41,103 train 200 1.526655e-01 -267.602212
2019-12-04 22:53:53,682 train 250 1.522642e-01 -267.709596
2019-12-04 22:54:06,259 train 300 1.529001e-01 -265.561313
2019-12-04 22:54:18,839 train 350 1.530993e-01 -265.576240
2019-12-04 22:54:31,418 train 400 1.535727e-01 -264.218747
2019-12-04 22:54:43,994 train 450 1.534626e-01 -263.757109
2019-12-04 22:54:56,579 train 500 1.533883e-01 -265.278164
2019-12-04 22:55:09,169 train 550 1.538568e-01 -264.838761
2019-12-04 22:55:21,747 train 600 1.544134e-01 -265.228180
2019-12-04 22:55:34,330 train 650 1.544191e-01 -264.991128
2019-12-04 22:55:46,912 train 700 1.546513e-01 -264.890816
2019-12-04 22:55:59,485 train 750 1.543163e-01 -264.353975
2019-12-04 22:56:12,068 train 800 1.543092e-01 -262.927979
2019-12-04 22:56:24,646 train 850 1.544345e-01 -263.892706
2019-12-04 22:56:34,651 training loss; R2: 1.547656e-01 -264.858592
2019-12-04 22:56:34,791 valid 000 2.143881e-01 -365.951864
2019-12-04 22:56:37,408 valid 050 1.805648e-01 -284.040468
2019-12-04 22:56:39,919 validation loss; R2: 1.767923e-01 -287.239960
2019-12-04 22:56:39,939 epoch 15 lr 1.000000e-03
2019-12-04 22:56:40,285 train 000 1.380295e-01 -95.703597
2019-12-04 22:56:52,860 train 050 1.508874e-01 -254.912673
2019-12-04 22:57:05,434 train 100 1.543389e-01 -257.017008
2019-12-04 22:57:18,024 train 150 1.556578e-01 -262.948041
2019-12-04 22:57:30,605 train 200 1.552712e-01 -262.727043
2019-12-04 22:57:43,191 train 250 1.546542e-01 -266.042268
2019-12-04 22:57:55,769 train 300 1.537970e-01 -267.153062
2019-12-04 22:58:08,353 train 350 1.543423e-01 -267.603605
2019-12-04 22:58:20,926 train 400 1.540235e-01 -268.702964
2019-12-04 22:58:33,500 train 450 1.538728e-01 -267.853229
2019-12-04 22:58:46,078 train 500 1.544969e-01 -266.554389
2019-12-04 22:58:58,899 train 550 1.545450e-01 -266.519019
2019-12-04 22:59:11,758 train 600 1.547217e-01 -267.119832
2019-12-04 22:59:24,605 train 650 1.547131e-01 -267.345434
2019-12-04 22:59:37,459 train 700 1.549225e-01 -267.649931
2019-12-04 22:59:50,313 train 750 1.547802e-01 -267.624721
2019-12-04 23:00:03,164 train 800 1.545594e-01 -268.898122
2019-12-04 23:00:15,906 train 850 1.543401e-01 -269.155826
2019-12-04 23:00:25,915 training loss; R2: 1.541937e-01 -269.907531
2019-12-04 23:00:26,065 valid 000 1.439348e-01 -110.640448
2019-12-04 23:00:28,682 valid 050 1.705880e-01 -215.876078
2019-12-04 23:00:31,193 validation loss; R2: 1.708409e-01 -217.942428
