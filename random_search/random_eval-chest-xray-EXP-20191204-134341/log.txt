2019-12-04 13:43:41,224 gpu device = 3
2019-12-04 13:43:41,225 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-134341', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 13:43:48,612 param size = 0.245822MB
2019-12-04 13:43:48,616 epoch 0 lr 1.000000e-03
2019-12-04 13:43:50,495 train 000 7.110066e-01 -1.049038
2019-12-04 13:44:04,534 train 050 5.727530e-01 -5.377100
2019-12-04 13:44:18,422 train 100 3.971807e-01 -54.734616
2019-12-04 13:44:32,322 train 150 3.236458e-01 -96.861469
2019-12-04 13:44:46,221 train 200 2.863953e-01 -123.959365
2019-12-04 13:45:00,118 train 250 2.621242e-01 -141.838988
2019-12-04 13:45:14,017 train 300 2.474686e-01 -155.331561
2019-12-04 13:45:27,916 train 350 2.362417e-01 -163.625461
2019-12-04 13:45:41,811 train 400 2.287493e-01 -171.010964
2019-12-04 13:45:55,706 train 450 2.230937e-01 -176.802183
2019-12-04 13:46:09,601 train 500 2.187354e-01 -182.487730
2019-12-04 13:46:23,491 train 550 2.149153e-01 -184.710601
2019-12-04 13:46:37,383 train 600 2.109067e-01 -187.627072
2019-12-04 13:46:51,281 train 650 2.081562e-01 -190.231710
2019-12-04 13:47:05,188 train 700 2.050050e-01 -192.322278
2019-12-04 13:47:19,099 train 750 2.030685e-01 -194.399637
2019-12-04 13:47:33,007 train 800 2.009431e-01 -196.528770
2019-12-04 13:47:46,913 train 850 1.991188e-01 -197.296950
2019-12-04 13:47:58,759 training loss; R2: 1.975192e-01 -198.538834
2019-12-04 13:47:58,891 valid 000 1.748890e-01 -375.729151
2019-12-04 13:48:01,723 valid 050 1.837724e-01 -237.709386
2019-12-04 13:48:04,572 validation loss; R2: 1.819692e-01 -235.261847
2019-12-04 13:48:04,591 epoch 1 lr 1.000000e-03
2019-12-04 13:48:05,088 train 000 1.874485e-01 -227.523396
2019-12-04 13:48:18,987 train 050 1.718259e-01 -220.458584
2019-12-04 13:48:32,890 train 100 1.748055e-01 -219.253086
2019-12-04 13:48:46,794 train 150 1.723927e-01 -220.274268
2019-12-04 13:49:00,687 train 200 1.726010e-01 -216.479187
2019-12-04 13:49:14,574 train 250 1.722011e-01 -219.594927
2019-12-04 13:49:28,475 train 300 1.706655e-01 -222.315537
2019-12-04 13:49:42,376 train 350 1.703756e-01 -225.165981
2019-12-04 13:49:56,279 train 400 1.700191e-01 -226.365976
2019-12-04 13:50:10,181 train 450 1.693027e-01 -226.442074
2019-12-04 13:50:24,100 train 500 1.693201e-01 -225.448876
2019-12-04 13:50:38,007 train 550 1.695319e-01 -226.051692
2019-12-04 13:50:51,913 train 600 1.695337e-01 -227.757058
2019-12-04 13:51:05,823 train 650 1.693199e-01 -227.219727
2019-12-04 13:51:19,727 train 700 1.695884e-01 -227.001846
2019-12-04 13:51:33,637 train 750 1.692548e-01 -226.210508
2019-12-04 13:51:47,547 train 800 1.691405e-01 -226.143316
2019-12-04 13:52:01,454 train 850 1.688636e-01 -226.233548
2019-12-04 13:52:12,519 training loss; R2: 1.690112e-01 -226.198910
2019-12-04 13:52:12,644 valid 000 1.876188e-01 -142.305754
2019-12-04 13:52:15,478 valid 050 1.854381e-01 -168.528771
2019-12-04 13:52:18,196 validation loss; R2: 1.840767e-01 -169.882899
2019-12-04 13:52:18,220 epoch 2 lr 1.000000e-03
2019-12-04 13:52:18,572 train 000 1.706893e-01 -303.219045
2019-12-04 13:52:32,492 train 050 1.709432e-01 -244.808250
2019-12-04 13:52:46,416 train 100 1.665899e-01 -238.966066
2019-12-04 13:53:00,328 train 150 1.677247e-01 -233.087675
2019-12-04 13:53:14,255 train 200 1.677627e-01 -234.518522
2019-12-04 13:53:28,169 train 250 1.692828e-01 -228.410099
2019-12-04 13:53:42,089 train 300 1.689708e-01 -225.174259
2019-12-04 13:53:56,011 train 350 1.688126e-01 -224.886977
2019-12-04 13:54:09,937 train 400 1.689071e-01 -225.963971
2019-12-04 13:54:23,864 train 450 1.681880e-01 -225.830491
2019-12-04 13:54:37,786 train 500 1.675970e-01 -226.178974
2019-12-04 13:54:51,707 train 550 1.676764e-01 -226.442877
2019-12-04 13:55:05,642 train 600 1.676471e-01 -226.387473
2019-12-04 13:55:19,571 train 650 1.679143e-01 -225.062442
2019-12-04 13:55:33,487 train 700 1.680887e-01 -225.644650
2019-12-04 13:55:47,409 train 750 1.681849e-01 -226.053984
2019-12-04 13:56:01,331 train 800 1.678732e-01 -226.920053
2019-12-04 13:56:15,253 train 850 1.678197e-01 -227.238418
2019-12-04 13:56:26,329 training loss; R2: 1.677599e-01 -226.288262
2019-12-04 13:56:26,455 valid 000 1.539647e-01 -192.248854
2019-12-04 13:56:29,294 valid 050 1.802811e-01 -197.956163
2019-12-04 13:56:32,014 validation loss; R2: 1.780976e-01 -208.863791
2019-12-04 13:56:32,033 epoch 3 lr 1.000000e-03
2019-12-04 13:56:32,380 train 000 1.961978e-01 -131.532523
2019-12-04 13:56:46,305 train 050 1.698399e-01 -228.243808
2019-12-04 13:57:00,235 train 100 1.729699e-01 -218.801795
2019-12-04 13:57:14,155 train 150 1.686954e-01 -213.627096
2019-12-04 13:57:28,065 train 200 1.670180e-01 -220.905114
2019-12-04 13:57:41,980 train 250 1.676819e-01 -222.566874
2019-12-04 13:57:55,899 train 300 1.679259e-01 -222.354116
2019-12-04 13:58:09,817 train 350 1.678950e-01 -224.122141
2019-12-04 13:58:23,737 train 400 1.682498e-01 -223.230329
2019-12-04 13:58:37,649 train 450 1.683369e-01 -225.849740
2019-12-04 13:58:51,560 train 500 1.683994e-01 -225.943761
2019-12-04 13:59:05,470 train 550 1.675732e-01 -226.390530
2019-12-04 13:59:19,389 train 600 1.678093e-01 -226.173121
2019-12-04 13:59:33,303 train 650 1.676423e-01 -225.585214
2019-12-04 13:59:47,214 train 700 1.677001e-01 -225.353866
2019-12-04 14:00:01,142 train 750 1.680616e-01 -226.423844
2019-12-04 14:00:15,059 train 800 1.679185e-01 -226.789457
2019-12-04 14:00:28,975 train 850 1.673457e-01 -226.831735
2019-12-04 14:00:40,064 training loss; R2: 1.668410e-01 -227.564654
2019-12-04 14:00:40,193 valid 000 1.494265e-01 -193.444533
2019-12-04 14:00:43,028 valid 050 1.730209e-01 -223.836057
2019-12-04 14:00:45,748 validation loss; R2: 1.778492e-01 -234.996380
2019-12-04 14:00:45,767 epoch 4 lr 1.000000e-03
2019-12-04 14:00:46,118 train 000 1.559214e-01 -198.899077
2019-12-04 14:01:00,046 train 050 1.702280e-01 -220.159485
2019-12-04 14:01:13,986 train 100 1.688723e-01 -225.962784
2019-12-04 14:01:27,908 train 150 1.660082e-01 -229.264649
2019-12-04 14:01:41,833 train 200 1.646304e-01 -227.141096
2019-12-04 14:01:55,760 train 250 1.637852e-01 -227.828588
2019-12-04 14:02:09,687 train 300 1.652195e-01 -226.906958
2019-12-04 14:02:23,615 train 350 1.657866e-01 -226.537149
2019-12-04 14:02:37,529 train 400 1.658650e-01 -226.938740
2019-12-04 14:02:51,439 train 450 1.660362e-01 -223.053708
2019-12-04 14:03:05,340 train 500 1.659378e-01 -224.481442
2019-12-04 14:03:19,242 train 550 1.660370e-01 -226.249222
2019-12-04 14:03:33,145 train 600 1.661257e-01 -226.564156
2019-12-04 14:03:47,048 train 650 1.660033e-01 -226.908371
2019-12-04 14:04:00,948 train 700 1.658176e-01 -227.427688
2019-12-04 14:04:14,840 train 750 1.658432e-01 -226.812848
2019-12-04 14:04:28,734 train 800 1.657633e-01 -228.000581
2019-12-04 14:04:42,634 train 850 1.660458e-01 -228.014020
2019-12-04 14:04:53,692 training loss; R2: 1.661360e-01 -227.887831
2019-12-04 14:04:53,824 valid 000 2.293705e-01 -191.342957
2019-12-04 14:04:56,655 valid 050 1.774289e-01 -201.426991
2019-12-04 14:04:59,374 validation loss; R2: 1.769811e-01 -207.048356
2019-12-04 14:04:59,393 epoch 5 lr 1.000000e-03
2019-12-04 14:04:59,746 train 000 1.649594e-01 -158.693343
2019-12-04 14:05:13,644 train 050 1.662459e-01 -239.072205
2019-12-04 14:05:27,538 train 100 1.677228e-01 -236.188123
2019-12-04 14:05:41,421 train 150 1.682963e-01 -240.579266
2019-12-04 14:05:55,306 train 200 1.668293e-01 -236.254134
2019-12-04 14:06:09,183 train 250 1.663418e-01 -237.603805
2019-12-04 14:06:23,076 train 300 1.656930e-01 -235.316400
2019-12-04 14:06:36,964 train 350 1.657273e-01 -236.551674
2019-12-04 14:06:50,851 train 400 1.661487e-01 -234.597185
2019-12-04 14:07:04,738 train 450 1.658575e-01 -234.162469
2019-12-04 14:07:18,623 train 500 1.654917e-01 -233.307417
2019-12-04 14:07:32,519 train 550 1.655695e-01 -233.278691
2019-12-04 14:07:46,401 train 600 1.648553e-01 -232.796078
2019-12-04 14:08:00,284 train 650 1.648206e-01 -232.947857
2019-12-04 14:08:14,169 train 700 1.653173e-01 -233.219286
2019-12-04 14:08:28,057 train 750 1.653438e-01 -233.236577
2019-12-04 14:08:41,957 train 800 1.652392e-01 -233.041267
2019-12-04 14:08:55,851 train 850 1.652111e-01 -233.223566
2019-12-04 14:09:06,903 training loss; R2: 1.655282e-01 -232.950379
2019-12-04 14:09:07,037 valid 000 1.962661e-01 -155.961782
2019-12-04 14:09:09,870 valid 050 1.771765e-01 -215.540056
2019-12-04 14:09:12,588 validation loss; R2: 1.769852e-01 -217.261598
2019-12-04 14:09:12,606 epoch 6 lr 1.000000e-03
2019-12-04 14:09:12,956 train 000 1.511416e-01 -301.649093
2019-12-04 14:09:26,853 train 050 1.696492e-01 -225.776274
2019-12-04 14:09:40,749 train 100 1.682393e-01 -227.918755
2019-12-04 14:09:54,635 train 150 1.663441e-01 -229.959682
2019-12-04 14:10:08,524 train 200 1.657509e-01 -228.559241
2019-12-04 14:10:22,405 train 250 1.660035e-01 -230.742107
2019-12-04 14:10:36,305 train 300 1.656668e-01 -234.481577
2019-12-04 14:10:50,188 train 350 1.652170e-01 -235.388764
2019-12-04 14:11:04,081 train 400 1.653683e-01 -234.240040
2019-12-04 14:11:17,974 train 450 1.652903e-01 -234.031451
2019-12-04 14:11:31,873 train 500 1.651310e-01 -233.407832
2019-12-04 14:11:45,767 train 550 1.647646e-01 -235.017316
2019-12-04 14:11:59,649 train 600 1.645920e-01 -235.410680
2019-12-04 14:12:13,527 train 650 1.648252e-01 -234.383272
2019-12-04 14:12:27,400 train 700 1.648058e-01 -234.057979
2019-12-04 14:12:41,285 train 750 1.649706e-01 -233.453413
2019-12-04 14:12:55,173 train 800 1.650244e-01 -233.768941
2019-12-04 14:13:09,066 train 850 1.651448e-01 -234.349086
2019-12-04 14:13:20,115 training loss; R2: 1.650617e-01 -234.639051
2019-12-04 14:13:20,239 valid 000 1.984130e-01 -167.534473
2019-12-04 14:13:23,069 valid 050 1.794192e-01 -180.081956
2019-12-04 14:13:25,789 validation loss; R2: 1.775426e-01 -182.889484
2019-12-04 14:13:25,808 epoch 7 lr 1.000000e-03
2019-12-04 14:13:26,154 train 000 1.852902e-01 -252.599659
2019-12-04 14:13:40,050 train 050 1.688088e-01 -224.452617
2019-12-04 14:13:53,939 train 100 1.680297e-01 -219.504331
2019-12-04 14:14:07,823 train 150 1.686909e-01 -228.120059
2019-12-04 14:14:21,714 train 200 1.680802e-01 -227.076192
2019-12-04 14:14:35,595 train 250 1.681721e-01 -230.405283
2019-12-04 14:14:49,483 train 300 1.658008e-01 -230.549099
2019-12-04 14:15:03,370 train 350 1.668571e-01 -232.799871
2019-12-04 14:15:17,254 train 400 1.667263e-01 -233.537766
2019-12-04 14:15:31,141 train 450 1.664535e-01 -232.730241
2019-12-04 14:15:45,027 train 500 1.662575e-01 -232.692756
2019-12-04 14:15:58,904 train 550 1.655091e-01 -233.104872
2019-12-04 14:16:12,788 train 600 1.656293e-01 -232.980429
2019-12-04 14:16:26,669 train 650 1.650991e-01 -233.673310
2019-12-04 14:16:40,554 train 700 1.648596e-01 -233.660547
2019-12-04 14:16:54,427 train 750 1.652198e-01 -233.076736
2019-12-04 14:17:08,304 train 800 1.651093e-01 -231.274398
2019-12-04 14:17:22,176 train 850 1.649417e-01 -231.116251
2019-12-04 14:17:33,206 training loss; R2: 1.647328e-01 -230.524888
2019-12-04 14:17:33,328 valid 000 1.470956e-01 -113.718005
2019-12-04 14:17:36,157 valid 050 1.735970e-01 -197.079473
2019-12-04 14:17:38,873 validation loss; R2: 1.763392e-01 -194.715969
2019-12-04 14:17:38,892 epoch 8 lr 1.000000e-03
2019-12-04 14:17:39,237 train 000 1.334193e-01 -277.800107
2019-12-04 14:17:53,086 train 050 1.666858e-01 -257.820640
2019-12-04 14:18:06,956 train 100 1.671933e-01 -249.771787
2019-12-04 14:18:20,811 train 150 1.648648e-01 -247.736613
2019-12-04 14:18:34,663 train 200 1.644799e-01 -243.137193
2019-12-04 14:18:48,516 train 250 1.651927e-01 -240.051731
2019-12-04 14:19:02,366 train 300 1.653461e-01 -243.036319
2019-12-04 14:19:16,227 train 350 1.658865e-01 -243.390677
2019-12-04 14:19:30,084 train 400 1.656335e-01 -242.335976
2019-12-04 14:19:43,946 train 450 1.654017e-01 -240.976723
2019-12-04 14:19:57,809 train 500 1.653907e-01 -241.186591
2019-12-04 14:20:11,667 train 550 1.650735e-01 -242.732683
2019-12-04 14:20:25,529 train 600 1.649211e-01 -242.100655
2019-12-04 14:20:39,400 train 650 1.644610e-01 -243.382159
2019-12-04 14:20:53,267 train 700 1.648756e-01 -241.353642
2019-12-04 14:21:07,133 train 750 1.649950e-01 -240.222184
2019-12-04 14:21:20,998 train 800 1.646245e-01 -239.916111
2019-12-04 14:21:34,855 train 850 1.640797e-01 -240.457491
2019-12-04 14:21:45,886 training loss; R2: 1.641036e-01 -239.810184
2019-12-04 14:21:46,010 valid 000 1.962214e-01 -271.362844
2019-12-04 14:21:48,844 valid 050 1.711690e-01 -210.084241
2019-12-04 14:21:51,560 validation loss; R2: 1.756453e-01 -212.494299
2019-12-04 14:21:51,588 epoch 9 lr 1.000000e-03
2019-12-04 14:21:51,944 train 000 1.683823e-01 -138.943634
2019-12-04 14:22:05,828 train 050 1.636751e-01 -244.928441
2019-12-04 14:22:19,709 train 100 1.619429e-01 -245.774198
2019-12-04 14:22:33,586 train 150 1.638568e-01 -240.089031
2019-12-04 14:22:47,455 train 200 1.629784e-01 -241.934332
2019-12-04 14:23:01,597 train 250 1.633310e-01 -241.912385
2019-12-04 14:23:15,773 train 300 1.637245e-01 -241.928057
2019-12-04 14:23:29,936 train 350 1.636730e-01 -243.842653
2019-12-04 14:23:44,108 train 400 1.638890e-01 -241.997089
2019-12-04 14:23:58,268 train 450 1.639440e-01 -241.347861
2019-12-04 14:24:12,425 train 500 1.639388e-01 -240.339959
2019-12-04 14:24:26,584 train 550 1.641107e-01 -240.620647
2019-12-04 14:24:40,756 train 600 1.637729e-01 -239.425350
2019-12-04 14:24:54,908 train 650 1.640323e-01 -240.529066
2019-12-04 14:25:09,071 train 700 1.635017e-01 -240.074840
2019-12-04 14:25:23,246 train 750 1.632949e-01 -240.086329
2019-12-04 14:25:37,470 train 800 1.634441e-01 -239.640371
2019-12-04 14:25:51,708 train 850 1.635670e-01 -240.304205
2019-12-04 14:26:03,040 training loss; R2: 1.637168e-01 -240.340030
2019-12-04 14:26:03,169 valid 000 8.652796e+00 -39084.350636
2019-12-04 14:26:05,997 valid 050 8.316634e+00 -34517.286834
2019-12-04 14:26:08,711 validation loss; R2: 8.301699e+00 -32042.537721
2019-12-04 14:26:08,731 epoch 10 lr 1.000000e-03
2019-12-04 14:26:09,093 train 000 1.455330e-01 -270.187407
2019-12-04 14:26:23,333 train 050 1.643343e-01 -229.322428
2019-12-04 14:26:37,564 train 100 1.584748e-01 -245.800149
2019-12-04 14:26:51,807 train 150 1.579937e-01 -249.418409
2019-12-04 14:27:06,049 train 200 1.596599e-01 -247.620524
2019-12-04 14:27:20,289 train 250 1.599272e-01 -249.212516
2019-12-04 14:27:34,519 train 300 1.610060e-01 -246.746844
2019-12-04 14:27:48,715 train 350 1.621652e-01 -244.247355
2019-12-04 14:28:02,888 train 400 1.630037e-01 -242.262926
2019-12-04 14:28:17,120 train 450 1.628941e-01 -240.900632
2019-12-04 14:28:31,351 train 500 1.630102e-01 -240.753845
2019-12-04 14:28:45,551 train 550 1.629463e-01 -241.335210
2019-12-04 14:28:59,789 train 600 1.629016e-01 -241.297959
2019-12-04 14:29:14,023 train 650 1.628427e-01 -242.396267
2019-12-04 14:29:28,250 train 700 1.628072e-01 -241.534115
2019-12-04 14:29:42,493 train 750 1.630691e-01 -241.216482
2019-12-04 14:29:56,696 train 800 1.630333e-01 -241.536940
2019-12-04 14:30:10,938 train 850 1.629755e-01 -241.518369
2019-12-04 14:30:22,281 training loss; R2: 1.631290e-01 -241.487317
2019-12-04 14:30:22,413 valid 000 4.246864e+00 -122970.682900
2019-12-04 14:30:25,242 valid 050 4.663687e+00 -130139.657609
2019-12-04 14:30:27,959 validation loss; R2: 4.628444e+00 -142919.988394
2019-12-04 14:30:27,978 epoch 11 lr 1.000000e-03
2019-12-04 14:30:28,345 train 000 1.547696e-01 -410.118664
2019-12-04 14:30:42,360 train 050 1.633942e-01 -241.593118
2019-12-04 14:30:56,290 train 100 1.606480e-01 -231.376217
2019-12-04 14:31:10,222 train 150 1.633323e-01 -233.798919
2019-12-04 14:31:24,145 train 200 1.656442e-01 -236.144427
2019-12-04 14:31:38,099 train 250 1.658521e-01 -235.711698
2019-12-04 14:31:52,066 train 300 1.642805e-01 -235.794532
2019-12-04 14:32:06,018 train 350 1.644458e-01 -236.021123
2019-12-04 14:32:19,961 train 400 1.646729e-01 -236.849382
2019-12-04 14:32:33,898 train 450 1.636678e-01 -236.039028
2019-12-04 14:32:47,846 train 500 1.630546e-01 -238.236392
2019-12-04 14:33:01,788 train 550 1.626427e-01 -238.615652
2019-12-04 14:33:15,740 train 600 1.629376e-01 -238.629396
2019-12-04 14:33:29,692 train 650 1.628656e-01 -238.689530
2019-12-04 14:33:43,631 train 700 1.623688e-01 -237.781582
2019-12-04 14:33:57,575 train 750 1.621762e-01 -237.851195
2019-12-04 14:34:11,514 train 800 1.621031e-01 -237.239196
2019-12-04 14:34:25,448 train 850 1.621657e-01 -238.051425
2019-12-04 14:34:36,531 training loss; R2: 1.619569e-01 -238.447877
2019-12-04 14:34:36,662 valid 000 9.011833e+02 -36822386.003360
2019-12-04 14:34:39,488 valid 050 8.993939e+02 -37279238.461413
2019-12-04 14:34:42,203 validation loss; R2: 9.002571e+02 -36926039.982316
2019-12-04 14:34:42,222 epoch 12 lr 1.000000e-03
2019-12-04 14:34:42,593 train 000 1.708379e-01 -150.024260
2019-12-04 14:34:56,639 train 050 1.656146e-01 -240.588262
2019-12-04 14:35:10,868 train 100 1.653461e-01 -248.625011
2019-12-04 14:35:25,091 train 150 1.654302e-01 -241.966785
2019-12-04 14:35:39,307 train 200 1.656714e-01 -237.983775
2019-12-04 14:35:53,529 train 250 1.650453e-01 -238.371533
2019-12-04 14:36:07,742 train 300 1.656274e-01 -239.457932
2019-12-04 14:36:21,975 train 350 1.656495e-01 -239.155493
2019-12-04 14:36:36,141 train 400 1.650016e-01 -240.409581
2019-12-04 14:36:50,040 train 450 1.652137e-01 -240.392698
2019-12-04 14:37:03,963 train 500 1.647968e-01 -240.729297
2019-12-04 14:37:17,916 train 550 1.646029e-01 -241.543280
2019-12-04 14:37:31,840 train 600 1.641293e-01 -241.155233
2019-12-04 14:37:45,750 train 650 1.639570e-01 -240.787437
2019-12-04 14:37:59,680 train 700 1.639217e-01 -241.871963
2019-12-04 14:38:13,601 train 750 1.635447e-01 -241.183267
2019-12-04 14:38:27,514 train 800 1.633390e-01 -241.235599
2019-12-04 14:38:41,579 train 850 1.634300e-01 -240.928941
2019-12-04 14:38:52,734 training loss; R2: 1.634612e-01 -241.405379
2019-12-04 14:38:52,865 valid 000 1.002393e+02 -58653310.929109
2019-12-04 14:38:55,691 valid 050 9.248157e+01 -39539761.118150
2019-12-04 14:38:58,406 validation loss; R2: 9.276109e+01 -40933934.774290
2019-12-04 14:38:58,426 epoch 13 lr 1.000000e-03
2019-12-04 14:38:58,798 train 000 1.585721e-01 -267.803640
2019-12-04 14:39:12,751 train 050 1.633013e-01 -246.104213
2019-12-04 14:39:26,684 train 100 1.630923e-01 -238.185872
2019-12-04 14:39:40,602 train 150 1.625638e-01 -237.718423
2019-12-04 14:39:54,530 train 200 1.636117e-01 -237.750118
2019-12-04 14:40:08,448 train 250 1.639501e-01 -241.683243
2019-12-04 14:40:22,366 train 300 1.644412e-01 -238.965016
2019-12-04 14:40:36,292 train 350 1.634412e-01 -237.394016
2019-12-04 14:40:50,217 train 400 1.634150e-01 -238.271406
2019-12-04 14:41:04,138 train 450 1.635220e-01 -240.618532
2019-12-04 14:41:18,062 train 500 1.631250e-01 -239.894386
2019-12-04 14:41:31,980 train 550 1.631736e-01 -240.754026
2019-12-04 14:41:45,902 train 600 1.626869e-01 -238.861609
2019-12-04 14:41:59,832 train 650 1.627997e-01 -239.907919
2019-12-04 14:42:13,914 train 700 1.622622e-01 -239.063740
2019-12-04 14:42:28,159 train 750 1.620257e-01 -239.580814
2019-12-04 14:42:42,396 train 800 1.620950e-01 -239.020714
2019-12-04 14:42:56,547 train 850 1.619491e-01 -239.307162
2019-12-04 14:43:07,627 training loss; R2: 1.625098e-01 -238.999182
2019-12-04 14:43:07,765 valid 000 1.942921e+02 -1406724.270822
2019-12-04 14:43:10,589 valid 050 1.915032e+02 -2441260.230222
2019-12-04 14:43:13,302 validation loss; R2: 1.918087e+02 -2516306.789084
2019-12-04 14:43:13,322 epoch 14 lr 1.000000e-03
2019-12-04 14:43:13,681 train 000 1.658675e-01 -170.287295
2019-12-04 14:43:27,606 train 050 1.627161e-01 -237.093968
2019-12-04 14:43:41,532 train 100 1.624919e-01 -246.930447
2019-12-04 14:43:55,443 train 150 1.614989e-01 -247.351187
2019-12-04 14:44:09,361 train 200 1.613906e-01 -246.103072
2019-12-04 14:44:23,268 train 250 1.625038e-01 -250.825963
2019-12-04 14:44:37,234 train 300 1.620287e-01 -247.642028
2019-12-04 14:44:51,470 train 350 1.609972e-01 -245.478706
2019-12-04 14:45:05,708 train 400 1.610386e-01 -245.835250
2019-12-04 14:45:19,940 train 450 1.611549e-01 -246.401839
2019-12-04 14:45:34,165 train 500 1.614515e-01 -245.844741
2019-12-04 14:45:48,200 train 550 1.614121e-01 -246.408109
2019-12-04 14:46:02,103 train 600 1.615934e-01 -246.195648
2019-12-04 14:46:16,011 train 650 1.616851e-01 -246.635431
2019-12-04 14:46:29,906 train 700 1.612379e-01 -245.702800
2019-12-04 14:46:43,831 train 750 1.613998e-01 -245.163589
2019-12-04 14:46:57,737 train 800 1.613855e-01 -245.050395
2019-12-04 14:47:11,656 train 850 1.620749e-01 -244.304982
2019-12-04 14:47:22,728 training loss; R2: 1.621442e-01 -243.143652
2019-12-04 14:47:22,864 valid 000 5.368478e+02 -10950184.726938
2019-12-04 14:47:25,688 valid 050 5.427105e+02 -11084639.707608
2019-12-04 14:47:28,402 validation loss; R2: 5.424312e+02 -10967020.476880
2019-12-04 14:47:28,423 epoch 15 lr 1.000000e-03
2019-12-04 14:47:28,787 train 000 1.842595e-01 -285.694804
2019-12-04 14:47:42,700 train 050 1.728721e-01 -225.422979
2019-12-04 14:47:56,614 train 100 1.680485e-01 -224.527107
2019-12-04 14:48:10,522 train 150 1.670466e-01 -230.193508
2019-12-04 14:48:24,429 train 200 1.661318e-01 -231.890380
2019-12-04 14:48:38,335 train 250 1.662532e-01 -234.248627
2019-12-04 14:48:52,242 train 300 1.661234e-01 -232.937440
2019-12-04 14:49:06,164 train 350 1.654800e-01 -234.837093
2019-12-04 14:49:20,084 train 400 1.649424e-01 -234.587366
2019-12-04 14:49:33,999 train 450 1.641493e-01 -236.139078
2019-12-04 14:49:47,913 train 500 1.630995e-01 -235.305509
2019-12-04 14:50:01,826 train 550 1.626504e-01 -238.293692
2019-12-04 14:50:15,753 train 600 1.624976e-01 -239.585439
2019-12-04 14:50:29,683 train 650 1.624428e-01 -239.398015
2019-12-04 14:50:43,598 train 700 1.621985e-01 -239.096150
2019-12-04 14:50:57,512 train 750 1.622109e-01 -239.575225
2019-12-04 14:51:11,423 train 800 1.621655e-01 -239.611693
2019-12-04 14:51:25,330 train 850 1.620625e-01 -240.305098
2019-12-04 14:51:36,403 training loss; R2: 1.620901e-01 -241.379993
2019-12-04 14:51:36,533 valid 000 1.615335e+03 -85941859.915276
2019-12-04 14:51:39,356 valid 050 1.623534e+03 -99472922.621430
2019-12-04 14:51:42,067 validation loss; R2: 1.625326e+03 -106653436.886042
