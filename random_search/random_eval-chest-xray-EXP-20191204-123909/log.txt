2019-12-04 12:39:09,581 gpu device = 3
2019-12-04 12:39:09,581 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-123909', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 12:39:16,945 param size = 0.215774MB
2019-12-04 12:39:16,948 epoch 0 lr 1.000000e-03
2019-12-04 12:39:18,794 train 000 6.958178e-01 -2.156727
2019-12-04 12:39:31,969 train 050 3.755748e-01 -72.457294
2019-12-04 12:39:45,232 train 100 3.064880e-01 -114.231102
2019-12-04 12:39:58,598 train 150 2.672196e-01 -141.022223
2019-12-04 12:40:11,968 train 200 2.462199e-01 -157.537022
2019-12-04 12:40:25,361 train 250 2.318087e-01 -168.937840
2019-12-04 12:40:38,748 train 300 2.238754e-01 -176.818769
2019-12-04 12:40:52,142 train 350 2.168715e-01 -180.679307
2019-12-04 12:41:05,539 train 400 2.119031e-01 -184.579093
2019-12-04 12:41:18,956 train 450 2.074822e-01 -189.728716
2019-12-04 12:41:32,269 train 500 2.040838e-01 -192.833295
2019-12-04 12:41:45,453 train 550 2.014179e-01 -194.806367
2019-12-04 12:41:58,644 train 600 1.985579e-01 -195.632810
2019-12-04 12:42:11,831 train 650 1.960667e-01 -196.825685
2019-12-04 12:42:25,022 train 700 1.939542e-01 -199.056958
2019-12-04 12:42:38,221 train 750 1.924566e-01 -200.730811
2019-12-04 12:42:51,422 train 800 1.907704e-01 -202.069764
2019-12-04 12:43:04,626 train 850 1.895428e-01 -202.831953
2019-12-04 12:43:15,913 training loss; R2: 1.884706e-01 -203.340921
2019-12-04 12:43:16,045 valid 000 1.882783e-01 -190.148169
2019-12-04 12:43:18,808 valid 050 1.828040e-01 -208.675259
2019-12-04 12:43:21,592 validation loss; R2: 1.815948e-01 -202.792087
2019-12-04 12:43:21,609 epoch 1 lr 1.000000e-03
2019-12-04 12:43:21,973 train 000 1.195947e-01 -73.260935
2019-12-04 12:43:35,161 train 050 1.612731e-01 -216.856369
2019-12-04 12:43:48,339 train 100 1.656227e-01 -222.317568
2019-12-04 12:44:01,534 train 150 1.663028e-01 -220.124306
2019-12-04 12:44:14,763 train 200 1.666348e-01 -223.459868
2019-12-04 12:44:27,977 train 250 1.670248e-01 -223.106141
2019-12-04 12:44:41,152 train 300 1.675821e-01 -220.961470
2019-12-04 12:44:54,346 train 350 1.687926e-01 -220.138536
2019-12-04 12:45:07,564 train 400 1.685382e-01 -221.038555
2019-12-04 12:45:20,753 train 450 1.686838e-01 -220.484410
2019-12-04 12:45:33,952 train 500 1.683578e-01 -219.852462
2019-12-04 12:45:47,146 train 550 1.686421e-01 -218.955332
2019-12-04 12:46:00,333 train 600 1.683757e-01 -219.625806
2019-12-04 12:46:13,550 train 650 1.688357e-01 -219.377963
2019-12-04 12:46:26,759 train 700 1.686014e-01 -218.915964
2019-12-04 12:46:39,961 train 750 1.680647e-01 -219.411754
2019-12-04 12:46:53,177 train 800 1.679025e-01 -219.800205
2019-12-04 12:47:06,399 train 850 1.676753e-01 -220.553988
2019-12-04 12:47:16,901 training loss; R2: 1.680024e-01 -219.943316
2019-12-04 12:47:17,025 valid 000 1.583432e-01 -136.615389
2019-12-04 12:47:19,794 valid 050 1.820202e-01 -171.230329
2019-12-04 12:47:22,452 validation loss; R2: 1.823577e-01 -172.632969
2019-12-04 12:47:22,469 epoch 2 lr 1.000000e-03
2019-12-04 12:47:22,801 train 000 1.560901e-01 -132.792261
2019-12-04 12:47:35,990 train 050 1.610531e-01 -216.544957
2019-12-04 12:47:49,173 train 100 1.612477e-01 -220.431293
2019-12-04 12:48:02,370 train 150 1.647224e-01 -219.471931
2019-12-04 12:48:15,672 train 200 1.650586e-01 -218.883736
2019-12-04 12:48:29,107 train 250 1.646800e-01 -221.212132
2019-12-04 12:48:42,344 train 300 1.648263e-01 -223.860928
2019-12-04 12:48:55,560 train 350 1.656637e-01 -223.812669
2019-12-04 12:49:08,767 train 400 1.654386e-01 -224.651738
2019-12-04 12:49:21,967 train 450 1.657980e-01 -226.675820
2019-12-04 12:49:35,183 train 500 1.659295e-01 -226.952276
2019-12-04 12:49:48,403 train 550 1.660118e-01 -227.028184
2019-12-04 12:50:01,630 train 600 1.661983e-01 -225.821877
2019-12-04 12:50:14,848 train 650 1.662483e-01 -225.777583
2019-12-04 12:50:28,064 train 700 1.661044e-01 -225.378896
2019-12-04 12:50:41,283 train 750 1.663438e-01 -225.532749
2019-12-04 12:50:54,500 train 800 1.661291e-01 -224.315012
2019-12-04 12:51:07,719 train 850 1.660639e-01 -223.769409
2019-12-04 12:51:18,231 training loss; R2: 1.663600e-01 -224.327688
2019-12-04 12:51:18,355 valid 000 1.948248e-01 -143.161714
2019-12-04 12:51:21,126 valid 050 1.881822e-01 -244.135135
2019-12-04 12:51:23,785 validation loss; R2: 1.860200e-01 -237.392066
2019-12-04 12:51:23,803 epoch 3 lr 1.000000e-03
2019-12-04 12:51:24,136 train 000 1.452818e-01 -187.019600
2019-12-04 12:51:37,368 train 050 1.732307e-01 -217.489523
2019-12-04 12:51:50,593 train 100 1.695559e-01 -223.659649
2019-12-04 12:52:03,812 train 150 1.680620e-01 -226.265991
2019-12-04 12:52:17,036 train 200 1.668942e-01 -227.621957
2019-12-04 12:52:30,271 train 250 1.671644e-01 -227.028047
2019-12-04 12:52:43,502 train 300 1.670789e-01 -226.768779
2019-12-04 12:52:56,730 train 350 1.662985e-01 -225.072019
2019-12-04 12:53:09,941 train 400 1.670366e-01 -225.225187
2019-12-04 12:53:23,168 train 450 1.669383e-01 -222.515483
2019-12-04 12:53:36,381 train 500 1.659928e-01 -225.712464
2019-12-04 12:53:49,612 train 550 1.656187e-01 -225.755128
2019-12-04 12:54:02,826 train 600 1.656525e-01 -226.530431
2019-12-04 12:54:16,045 train 650 1.654989e-01 -227.535819
2019-12-04 12:54:29,262 train 700 1.657445e-01 -227.987907
2019-12-04 12:54:42,494 train 750 1.657425e-01 -227.264603
2019-12-04 12:54:55,714 train 800 1.656426e-01 -225.991581
2019-12-04 12:55:08,925 train 850 1.653000e-01 -226.588772
2019-12-04 12:55:19,450 training loss; R2: 1.650233e-01 -226.618935
2019-12-04 12:55:19,573 valid 000 1.742610e-01 -146.552131
2019-12-04 12:55:22,347 valid 050 1.729544e-01 -234.760952
2019-12-04 12:55:25,004 validation loss; R2: 1.819424e-01 -240.141137
2019-12-04 12:55:25,020 epoch 4 lr 1.000000e-03
2019-12-04 12:55:25,354 train 000 1.399162e-01 -269.514296
2019-12-04 12:55:38,559 train 050 1.662810e-01 -238.565264
2019-12-04 12:55:51,756 train 100 1.666863e-01 -236.509116
2019-12-04 12:56:04,962 train 150 1.648091e-01 -240.735596
2019-12-04 12:56:18,150 train 200 1.634204e-01 -235.918398
2019-12-04 12:56:31,339 train 250 1.626785e-01 -233.160477
2019-12-04 12:56:44,544 train 300 1.627923e-01 -233.779357
2019-12-04 12:56:57,739 train 350 1.628048e-01 -232.383084
2019-12-04 12:57:10,946 train 400 1.631357e-01 -231.148883
2019-12-04 12:57:24,150 train 450 1.631927e-01 -230.965436
2019-12-04 12:57:37,351 train 500 1.628204e-01 -232.615618
2019-12-04 12:57:50,561 train 550 1.631707e-01 -232.221813
2019-12-04 12:58:03,768 train 600 1.632284e-01 -233.194277
2019-12-04 12:58:16,959 train 650 1.634730e-01 -231.801704
2019-12-04 12:58:30,160 train 700 1.637260e-01 -231.681408
2019-12-04 12:58:43,350 train 750 1.636923e-01 -230.545410
2019-12-04 12:58:56,547 train 800 1.638743e-01 -230.789874
2019-12-04 12:59:09,758 train 850 1.643553e-01 -231.442936
2019-12-04 12:59:20,254 training loss; R2: 1.644471e-01 -231.211281
2019-12-04 12:59:20,375 valid 000 1.964617e-01 -100.642778
2019-12-04 12:59:23,143 valid 050 1.781452e-01 -237.144664
2019-12-04 12:59:25,801 validation loss; R2: 1.785951e-01 -247.761216
2019-12-04 12:59:25,824 epoch 5 lr 1.000000e-03
2019-12-04 12:59:26,157 train 000 1.218588e-01 -88.506030
2019-12-04 12:59:39,365 train 050 1.579002e-01 -240.297173
2019-12-04 12:59:52,569 train 100 1.599150e-01 -230.979382
2019-12-04 13:00:05,770 train 150 1.623964e-01 -233.682624
2019-12-04 13:00:18,957 train 200 1.605208e-01 -234.406242
2019-12-04 13:00:32,169 train 250 1.605284e-01 -235.416009
2019-12-04 13:00:45,524 train 300 1.615059e-01 -234.691042
2019-12-04 13:00:58,972 train 350 1.616211e-01 -233.988546
2019-12-04 13:01:12,425 train 400 1.618485e-01 -233.540270
2019-12-04 13:01:25,866 train 450 1.626569e-01 -234.245734
2019-12-04 13:01:39,304 train 500 1.622580e-01 -233.658858
2019-12-04 13:01:52,753 train 550 1.631394e-01 -232.197299
2019-12-04 13:02:06,198 train 600 1.632546e-01 -231.445547
2019-12-04 13:02:19,635 train 650 1.633611e-01 -231.560841
2019-12-04 13:02:33,075 train 700 1.631904e-01 -230.749647
2019-12-04 13:02:46,513 train 750 1.632398e-01 -231.138238
2019-12-04 13:02:59,959 train 800 1.634263e-01 -231.942714
2019-12-04 13:03:13,398 train 850 1.638050e-01 -231.052781
2019-12-04 13:03:24,127 training loss; R2: 1.638088e-01 -230.406091
2019-12-04 13:03:24,247 valid 000 1.597429e-01 -133.951679
2019-12-04 13:03:27,018 valid 050 1.811325e-01 -184.147807
2019-12-04 13:03:29,679 validation loss; R2: 1.813782e-01 -186.231979
2019-12-04 13:03:29,702 epoch 6 lr 1.000000e-03
2019-12-04 13:03:30,046 train 000 1.538284e-01 -126.757470
2019-12-04 13:03:43,244 train 050 1.641740e-01 -225.666834
2019-12-04 13:03:56,451 train 100 1.630302e-01 -219.018867
2019-12-04 13:04:09,667 train 150 1.629718e-01 -223.268888
2019-12-04 13:04:22,876 train 200 1.632649e-01 -226.591364
2019-12-04 13:04:36,078 train 250 1.619902e-01 -230.092330
2019-12-04 13:04:49,282 train 300 1.624954e-01 -228.397993
2019-12-04 13:05:02,496 train 350 1.624652e-01 -231.190846
2019-12-04 13:05:15,706 train 400 1.623261e-01 -231.611215
2019-12-04 13:05:28,914 train 450 1.624136e-01 -230.493713
2019-12-04 13:05:42,099 train 500 1.625146e-01 -229.620517
2019-12-04 13:05:55,302 train 550 1.626518e-01 -230.586939
2019-12-04 13:06:08,502 train 600 1.625944e-01 -232.087930
2019-12-04 13:06:21,706 train 650 1.631161e-01 -232.558246
2019-12-04 13:06:34,901 train 700 1.627257e-01 -234.043666
2019-12-04 13:06:48,122 train 750 1.628307e-01 -233.948708
2019-12-04 13:07:01,346 train 800 1.625524e-01 -233.341345
2019-12-04 13:07:14,567 train 850 1.627403e-01 -233.852650
2019-12-04 13:07:25,067 training loss; R2: 1.630537e-01 -232.962977
2019-12-04 13:07:25,186 valid 000 7.348738e+00 -3677.033152
2019-12-04 13:07:27,953 valid 050 7.180077e+00 -2956.882521
2019-12-04 13:07:30,610 validation loss; R2: 7.191441e+00 -3056.826533
2019-12-04 13:07:30,626 epoch 7 lr 1.000000e-03
2019-12-04 13:07:30,959 train 000 2.131961e-01 -307.579696
2019-12-04 13:07:44,142 train 050 1.603168e-01 -221.459237
2019-12-04 13:07:57,343 train 100 1.609366e-01 -231.025995
2019-12-04 13:08:10,534 train 150 1.615839e-01 -238.981059
2019-12-04 13:08:23,741 train 200 1.605667e-01 -236.665043
2019-12-04 13:08:36,915 train 250 1.610688e-01 -235.458008
2019-12-04 13:08:50,113 train 300 1.623933e-01 -235.432922
2019-12-04 13:09:03,295 train 350 1.618859e-01 -235.270846
2019-12-04 13:09:16,481 train 400 1.633952e-01 -237.001726
2019-12-04 13:09:29,672 train 450 1.629200e-01 -236.777356
2019-12-04 13:09:42,866 train 500 1.621538e-01 -237.318693
2019-12-04 13:09:56,052 train 550 1.626041e-01 -238.423814
2019-12-04 13:10:09,250 train 600 1.623393e-01 -236.306340
2019-12-04 13:10:22,433 train 650 1.617914e-01 -236.716418
2019-12-04 13:10:35,618 train 700 1.619408e-01 -236.627388
2019-12-04 13:10:48,830 train 750 1.619928e-01 -236.472975
2019-12-04 13:11:02,018 train 800 1.620567e-01 -236.019344
2019-12-04 13:11:15,220 train 850 1.622642e-01 -236.494484
2019-12-04 13:11:25,729 training loss; R2: 1.620587e-01 -236.331944
2019-12-04 13:11:25,859 valid 000 1.448054e-01 -208.604840
2019-12-04 13:11:28,622 valid 050 1.802913e-01 -256.842441
2019-12-04 13:11:31,278 validation loss; R2: 1.785447e-01 -256.579753
2019-12-04 13:11:31,303 epoch 8 lr 1.000000e-03
2019-12-04 13:11:31,636 train 000 1.933218e-01 -282.490577
2019-12-04 13:11:44,823 train 050 1.686194e-01 -224.552333
2019-12-04 13:11:58,029 train 100 1.608564e-01 -234.418200
2019-12-04 13:12:11,208 train 150 1.630910e-01 -231.597341
2019-12-04 13:12:24,402 train 200 1.635703e-01 -232.508785
2019-12-04 13:12:37,584 train 250 1.632184e-01 -228.728609
2019-12-04 13:12:50,748 train 300 1.631059e-01 -229.486448
2019-12-04 13:13:03,920 train 350 1.628024e-01 -230.238373
2019-12-04 13:13:17,092 train 400 1.627004e-01 -233.213209
2019-12-04 13:13:30,254 train 450 1.627876e-01 -233.457415
2019-12-04 13:13:43,448 train 500 1.630104e-01 -232.252324
2019-12-04 13:13:56,652 train 550 1.625894e-01 -230.872274
2019-12-04 13:14:09,836 train 600 1.631140e-01 -231.700061
2019-12-04 13:14:23,017 train 650 1.628103e-01 -230.677977
2019-12-04 13:14:36,434 train 700 1.621007e-01 -232.111392
2019-12-04 13:14:49,861 train 750 1.617158e-01 -232.706431
2019-12-04 13:15:03,292 train 800 1.614319e-01 -233.055552
2019-12-04 13:15:16,713 train 850 1.616267e-01 -233.381307
2019-12-04 13:15:27,279 training loss; R2: 1.615845e-01 -233.256028
2019-12-04 13:15:27,401 valid 000 1.835554e-01 -155.757513
2019-12-04 13:15:30,163 valid 050 1.906016e-01 -132.878225
2019-12-04 13:15:32,812 validation loss; R2: 1.915985e-01 -131.871315
2019-12-04 13:15:32,828 epoch 9 lr 1.000000e-03
2019-12-04 13:15:33,160 train 000 1.704784e-01 -154.492781
2019-12-04 13:15:46,350 train 050 1.671314e-01 -220.455372
2019-12-04 13:15:59,522 train 100 1.627548e-01 -231.989290
2019-12-04 13:16:12,703 train 150 1.623451e-01 -234.167127
2019-12-04 13:16:25,883 train 200 1.630880e-01 -233.839347
2019-12-04 13:16:39,062 train 250 1.622359e-01 -235.976105
2019-12-04 13:16:52,245 train 300 1.621415e-01 -237.390478
2019-12-04 13:17:05,424 train 350 1.619514e-01 -238.591791
2019-12-04 13:17:18,593 train 400 1.613682e-01 -239.391388
2019-12-04 13:17:31,775 train 450 1.615418e-01 -236.996486
2019-12-04 13:17:44,962 train 500 1.617974e-01 -238.822749
2019-12-04 13:17:58,141 train 550 1.616744e-01 -239.521449
2019-12-04 13:18:11,311 train 600 1.616962e-01 -239.874580
2019-12-04 13:18:24,465 train 650 1.610173e-01 -241.600615
2019-12-04 13:18:37,623 train 700 1.611504e-01 -241.834780
2019-12-04 13:18:50,768 train 750 1.605155e-01 -241.637917
2019-12-04 13:19:03,935 train 800 1.605940e-01 -241.634650
2019-12-04 13:19:17,111 train 850 1.605887e-01 -241.188513
2019-12-04 13:19:27,592 training loss; R2: 1.608890e-01 -240.984991
2019-12-04 13:19:27,712 valid 000 2.181721e+00 -1802.525605
2019-12-04 13:19:30,473 valid 050 2.229005e+00 -2760.270482
2019-12-04 13:19:33,122 validation loss; R2: 2.221234e+00 -2680.693897
2019-12-04 13:19:33,143 epoch 10 lr 1.000000e-03
2019-12-04 13:19:33,485 train 000 1.417225e-01 -198.250056
2019-12-04 13:19:46,653 train 050 1.546206e-01 -235.050750
2019-12-04 13:19:59,814 train 100 1.557579e-01 -236.771221
2019-12-04 13:20:12,981 train 150 1.587225e-01 -238.517016
2019-12-04 13:20:26,134 train 200 1.597720e-01 -236.147984
2019-12-04 13:20:39,298 train 250 1.608599e-01 -236.551886
2019-12-04 13:20:52,449 train 300 1.609941e-01 -233.243874
2019-12-04 13:21:05,614 train 350 1.609821e-01 -235.175353
2019-12-04 13:21:18,773 train 400 1.599003e-01 -235.903860
2019-12-04 13:21:31,921 train 450 1.590920e-01 -235.756543
2019-12-04 13:21:45,081 train 500 1.592047e-01 -239.337783
2019-12-04 13:21:58,279 train 550 1.593443e-01 -238.731727
2019-12-04 13:22:11,461 train 600 1.595355e-01 -240.908037
2019-12-04 13:22:24,652 train 650 1.600607e-01 -241.034331
2019-12-04 13:22:37,843 train 700 1.601870e-01 -240.751207
2019-12-04 13:22:51,035 train 750 1.603813e-01 -240.929853
2019-12-04 13:23:04,220 train 800 1.606457e-01 -241.185065
2019-12-04 13:23:17,404 train 850 1.606663e-01 -241.266251
2019-12-04 13:23:27,895 training loss; R2: 1.607795e-01 -239.814341
2019-12-04 13:23:28,018 valid 000 1.640465e+00 -2791.871124
2019-12-04 13:23:30,785 valid 050 1.543541e+00 -2230.305384
2019-12-04 13:23:33,439 validation loss; R2: 1.548139e+00 -2189.928552
2019-12-04 13:23:33,455 epoch 11 lr 1.000000e-03
2019-12-04 13:23:33,786 train 000 1.710796e-01 -229.549238
2019-12-04 13:23:46,964 train 050 1.557106e-01 -236.154865
2019-12-04 13:24:00,153 train 100 1.594173e-01 -237.150035
2019-12-04 13:24:13,316 train 150 1.617228e-01 -233.911134
2019-12-04 13:24:26,496 train 200 1.617596e-01 -237.433883
2019-12-04 13:24:39,668 train 250 1.630906e-01 -235.768221
2019-12-04 13:24:52,843 train 300 1.621788e-01 -235.460286
2019-12-04 13:25:06,017 train 350 1.622022e-01 -236.878476
2019-12-04 13:25:19,197 train 400 1.616456e-01 -235.510216
2019-12-04 13:25:32,416 train 450 1.614312e-01 -235.639902
2019-12-04 13:25:45,616 train 500 1.612413e-01 -237.766416
2019-12-04 13:25:58,772 train 550 1.615671e-01 -237.489183
2019-12-04 13:26:11,938 train 600 1.607105e-01 -236.967517
2019-12-04 13:26:25,100 train 650 1.606162e-01 -237.512004
2019-12-04 13:26:38,269 train 700 1.601416e-01 -237.532460
2019-12-04 13:26:51,439 train 750 1.601641e-01 -238.504690
2019-12-04 13:27:04,614 train 800 1.600796e-01 -238.552269
2019-12-04 13:27:17,784 train 850 1.602908e-01 -239.481439
2019-12-04 13:27:28,251 training loss; R2: 1.602689e-01 -238.158967
2019-12-04 13:27:28,370 valid 000 3.299192e-01 -415.979658
2019-12-04 13:27:31,135 valid 050 3.462600e-01 -507.590038
2019-12-04 13:27:33,789 validation loss; R2: 3.415080e-01 -509.522572
2019-12-04 13:27:33,804 epoch 12 lr 1.000000e-03
2019-12-04 13:27:34,137 train 000 1.784090e-01 -127.779145
2019-12-04 13:27:47,284 train 050 1.611347e-01 -235.018406
2019-12-04 13:28:00,444 train 100 1.596500e-01 -230.948200
2019-12-04 13:28:13,584 train 150 1.620809e-01 -228.282877
2019-12-04 13:28:26,739 train 200 1.599390e-01 -233.591528
2019-12-04 13:28:39,942 train 250 1.592655e-01 -235.195798
2019-12-04 13:28:53,203 train 300 1.597760e-01 -239.122953
2019-12-04 13:29:06,462 train 350 1.602543e-01 -239.872118
2019-12-04 13:29:19,697 train 400 1.609597e-01 -241.812313
2019-12-04 13:29:32,923 train 450 1.605221e-01 -242.994597
2019-12-04 13:29:46,149 train 500 1.609815e-01 -242.075841
2019-12-04 13:29:59,379 train 550 1.605984e-01 -241.368999
2019-12-04 13:30:12,597 train 600 1.605986e-01 -239.523387
2019-12-04 13:30:25,832 train 650 1.602859e-01 -238.672391
2019-12-04 13:30:39,051 train 700 1.598901e-01 -237.494331
2019-12-04 13:30:52,263 train 750 1.603458e-01 -237.571454
2019-12-04 13:31:05,491 train 800 1.597258e-01 -237.237684
2019-12-04 13:31:18,712 train 850 1.595754e-01 -238.196058
2019-12-04 13:31:29,271 training loss; R2: 1.598279e-01 -238.651522
2019-12-04 13:31:29,400 valid 000 2.140207e-01 -497.145145
2019-12-04 13:31:32,166 valid 050 2.396708e-01 -339.282518
2019-12-04 13:31:34,821 validation loss; R2: 2.420052e-01 -340.398761
2019-12-04 13:31:34,837 epoch 13 lr 1.000000e-03
2019-12-04 13:31:35,177 train 000 1.539593e-01 -327.577527
2019-12-04 13:31:48,556 train 050 1.637554e-01 -221.752689
2019-12-04 13:32:01,909 train 100 1.635717e-01 -228.420984
2019-12-04 13:32:15,269 train 150 1.625101e-01 -230.169330
2019-12-04 13:32:28,554 train 200 1.608380e-01 -233.655785
2019-12-04 13:32:41,814 train 250 1.610097e-01 -234.690895
2019-12-04 13:32:55,121 train 300 1.601428e-01 -235.166689
2019-12-04 13:33:08,368 train 350 1.611244e-01 -236.550531
2019-12-04 13:33:21,596 train 400 1.612496e-01 -237.345944
2019-12-04 13:33:34,867 train 450 1.611545e-01 -239.271061
2019-12-04 13:33:48,138 train 500 1.602687e-01 -239.554918
2019-12-04 13:34:01,412 train 550 1.597692e-01 -240.371950
2019-12-04 13:34:14,647 train 600 1.600248e-01 -239.965572
2019-12-04 13:34:27,869 train 650 1.600422e-01 -237.715941
2019-12-04 13:34:41,110 train 700 1.596070e-01 -236.900515
2019-12-04 13:34:54,384 train 750 1.597288e-01 -238.036237
2019-12-04 13:35:07,679 train 800 1.595852e-01 -237.429291
2019-12-04 13:35:20,992 train 850 1.596915e-01 -238.186266
2019-12-04 13:35:31,524 training loss; R2: 1.596464e-01 -238.583551
2019-12-04 13:35:31,649 valid 000 1.638626e-01 -355.622796
2019-12-04 13:35:34,406 valid 050 1.775114e-01 -256.146371
2019-12-04 13:35:37,058 validation loss; R2: 1.747891e-01 -258.825511
2019-12-04 13:35:37,074 epoch 14 lr 1.000000e-03
2019-12-04 13:35:37,415 train 000 1.286173e-01 -99.895942
2019-12-04 13:35:50,665 train 050 1.572696e-01 -251.271976
2019-12-04 13:36:04,018 train 100 1.575261e-01 -242.774244
2019-12-04 13:36:17,251 train 150 1.607800e-01 -245.703569
2019-12-04 13:36:30,493 train 200 1.604068e-01 -239.612154
2019-12-04 13:36:43,765 train 250 1.605537e-01 -239.582197
2019-12-04 13:36:57,040 train 300 1.609999e-01 -238.730408
2019-12-04 13:37:10,334 train 350 1.603620e-01 -236.289372
2019-12-04 13:37:23,589 train 400 1.608545e-01 -238.258235
2019-12-04 13:37:36,960 train 450 1.608516e-01 -238.212958
2019-12-04 13:37:50,272 train 500 1.603447e-01 -238.391824
2019-12-04 13:38:03,555 train 550 1.593037e-01 -237.628612
2019-12-04 13:38:16,786 train 600 1.596864e-01 -239.196477
2019-12-04 13:38:29,987 train 650 1.597515e-01 -239.959473
2019-12-04 13:38:43,171 train 700 1.597687e-01 -240.089807
2019-12-04 13:38:56,358 train 750 1.592616e-01 -239.765146
2019-12-04 13:39:09,547 train 800 1.590761e-01 -241.567642
2019-12-04 13:39:22,741 train 850 1.595484e-01 -243.243978
2019-12-04 13:39:33,243 training loss; R2: 1.595291e-01 -242.750566
2019-12-04 13:39:33,371 valid 000 2.278629e-01 -259.154397
2019-12-04 13:39:36,127 valid 050 1.915261e-01 -337.496725
2019-12-04 13:39:38,777 validation loss; R2: 1.890735e-01 -345.584061
2019-12-04 13:39:38,798 epoch 15 lr 1.000000e-03
2019-12-04 13:39:39,137 train 000 1.474163e-01 -336.341488
2019-12-04 13:39:52,359 train 050 1.560030e-01 -249.809063
2019-12-04 13:40:05,559 train 100 1.599802e-01 -255.838549
2019-12-04 13:40:18,754 train 150 1.604200e-01 -253.822761
2019-12-04 13:40:31,963 train 200 1.587112e-01 -254.526120
2019-12-04 13:40:45,153 train 250 1.575908e-01 -250.258603
2019-12-04 13:40:58,350 train 300 1.580104e-01 -251.014665
2019-12-04 13:41:11,558 train 350 1.584557e-01 -248.596997
2019-12-04 13:41:24,771 train 400 1.591331e-01 -248.028743
2019-12-04 13:41:37,964 train 450 1.592233e-01 -248.024680
2019-12-04 13:41:51,152 train 500 1.590340e-01 -246.665377
2019-12-04 13:42:04,339 train 550 1.589043e-01 -244.455040
2019-12-04 13:42:17,526 train 600 1.597486e-01 -244.377922
2019-12-04 13:42:30,707 train 650 1.594045e-01 -243.218854
2019-12-04 13:42:43,897 train 700 1.595370e-01 -243.331667
2019-12-04 13:42:57,095 train 750 1.594933e-01 -242.140690
2019-12-04 13:43:10,298 train 800 1.591036e-01 -243.569530
2019-12-04 13:43:23,484 train 850 1.589433e-01 -244.778740
2019-12-04 13:43:33,969 training loss; R2: 1.591501e-01 -244.455880
2019-12-04 13:43:34,095 valid 000 2.448991e-01 -302.212353
2019-12-04 13:43:36,856 valid 050 1.966526e-01 -279.276558
2019-12-04 13:43:39,503 validation loss; R2: 1.940400e-01 -286.083938
