2019-12-04 14:51:53,667 gpu device = 3
2019-12-04 14:51:53,667 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-145153', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 14:52:01,441 param size = 0.246142MB
2019-12-04 14:52:01,445 epoch 0 lr 1.000000e-03
2019-12-04 14:52:03,365 train 000 6.777568e-01 -1.888036
2019-12-04 14:52:18,007 train 050 3.795094e-01 -59.725874
2019-12-04 14:52:32,504 train 100 3.025349e-01 -107.613694
2019-12-04 14:52:47,008 train 150 2.635145e-01 -138.670118
2019-12-04 14:53:01,511 train 200 2.412887e-01 -157.853503
2019-12-04 14:53:16,011 train 250 2.292966e-01 -175.172002
2019-12-04 14:53:30,524 train 300 2.195240e-01 -184.301280
2019-12-04 14:53:45,064 train 350 2.133615e-01 -188.118261
2019-12-04 14:53:59,609 train 400 2.085826e-01 -192.265254
2019-12-04 14:54:14,154 train 450 2.047389e-01 -197.178904
2019-12-04 14:54:28,695 train 500 2.014729e-01 -196.133376
2019-12-04 14:54:43,236 train 550 1.991537e-01 -198.622084
2019-12-04 14:54:57,782 train 600 1.965275e-01 -200.872994
2019-12-04 14:55:12,324 train 650 1.945448e-01 -203.423389
2019-12-04 14:55:26,876 train 700 1.931589e-01 -204.251685
2019-12-04 14:55:41,424 train 750 1.918268e-01 -205.580366
2019-12-04 14:55:55,970 train 800 1.902399e-01 -207.910404
2019-12-04 14:56:10,517 train 850 1.889487e-01 -208.377015
2019-12-04 14:56:22,882 training loss; R2: 1.880786e-01 -209.678673
2019-12-04 14:56:23,019 valid 000 1.742877e-01 -377.638170
2019-12-04 14:56:25,957 valid 050 1.847292e-01 -222.967756
2019-12-04 14:56:28,908 validation loss; R2: 1.836781e-01 -210.456564
2019-12-04 14:56:28,926 epoch 1 lr 1.000000e-03
2019-12-04 14:56:29,442 train 000 2.022198e-01 -214.286639
2019-12-04 14:56:43,980 train 050 1.646613e-01 -213.367178
2019-12-04 14:56:58,519 train 100 1.670466e-01 -218.020008
2019-12-04 14:57:13,065 train 150 1.689399e-01 -214.623016
2019-12-04 14:57:27,612 train 200 1.683607e-01 -214.468462
2019-12-04 14:57:42,158 train 250 1.686253e-01 -219.272815
2019-12-04 14:57:56,714 train 300 1.690928e-01 -219.917810
2019-12-04 14:58:11,265 train 350 1.685363e-01 -222.195406
2019-12-04 14:58:25,811 train 400 1.696187e-01 -222.239579
2019-12-04 14:58:40,356 train 450 1.701600e-01 -222.443667
2019-12-04 14:58:54,896 train 500 1.699168e-01 -221.748387
2019-12-04 14:59:09,441 train 550 1.703078e-01 -221.641103
2019-12-04 14:59:23,984 train 600 1.700649e-01 -222.001160
2019-12-04 14:59:38,520 train 650 1.702451e-01 -222.839527
2019-12-04 14:59:53,057 train 700 1.703967e-01 -222.008007
2019-12-04 15:00:07,592 train 750 1.703020e-01 -221.852575
2019-12-04 15:00:22,124 train 800 1.697882e-01 -221.999801
2019-12-04 15:00:36,678 train 850 1.699161e-01 -222.484442
2019-12-04 15:00:48,240 training loss; R2: 1.695333e-01 -222.788942
2019-12-04 15:00:48,369 valid 000 1.965196e-01 -383.754241
2019-12-04 15:00:51,308 valid 050 1.865289e-01 -238.852892
2019-12-04 15:00:54,133 validation loss; R2: 1.873997e-01 -233.052599
2019-12-04 15:00:54,151 epoch 2 lr 1.000000e-03
2019-12-04 15:00:54,514 train 000 2.107705e-01 -319.191364
2019-12-04 15:01:09,054 train 050 1.663071e-01 -225.357372
2019-12-04 15:01:23,587 train 100 1.685257e-01 -231.772001
2019-12-04 15:01:38,112 train 150 1.696001e-01 -228.045945
2019-12-04 15:01:52,658 train 200 1.668088e-01 -229.585348
2019-12-04 15:02:07,200 train 250 1.672546e-01 -227.542110
2019-12-04 15:02:21,742 train 300 1.675393e-01 -228.991548
2019-12-04 15:02:36,283 train 350 1.672951e-01 -228.919649
2019-12-04 15:02:50,815 train 400 1.669485e-01 -229.047021
2019-12-04 15:03:05,365 train 450 1.667231e-01 -230.954852
2019-12-04 15:03:19,902 train 500 1.666643e-01 -231.339910
2019-12-04 15:03:34,445 train 550 1.671581e-01 -230.535234
2019-12-04 15:03:48,988 train 600 1.673937e-01 -231.782696
2019-12-04 15:04:03,529 train 650 1.672268e-01 -230.412454
2019-12-04 15:04:18,069 train 700 1.671277e-01 -230.557852
2019-12-04 15:04:32,608 train 750 1.672285e-01 -230.868304
2019-12-04 15:04:47,150 train 800 1.675135e-01 -229.723294
2019-12-04 15:05:01,698 train 850 1.676621e-01 -229.832100
2019-12-04 15:05:13,269 training loss; R2: 1.676957e-01 -229.997927
2019-12-04 15:05:13,398 valid 000 1.498097e-01 -256.474887
2019-12-04 15:05:16,334 valid 050 1.800993e-01 -200.893232
2019-12-04 15:05:19,150 validation loss; R2: 1.789729e-01 -202.580219
2019-12-04 15:05:19,168 epoch 3 lr 1.000000e-03
2019-12-04 15:05:19,531 train 000 1.323681e-01 -199.726319
2019-12-04 15:05:34,068 train 050 1.649393e-01 -230.454024
2019-12-04 15:05:48,607 train 100 1.637950e-01 -235.522097
2019-12-04 15:06:03,140 train 150 1.636136e-01 -233.817137
2019-12-04 15:06:17,672 train 200 1.645622e-01 -237.090129
2019-12-04 15:06:32,206 train 250 1.647131e-01 -236.203578
2019-12-04 15:06:46,729 train 300 1.657849e-01 -236.590629
2019-12-04 15:07:01,259 train 350 1.664978e-01 -234.292651
2019-12-04 15:07:15,787 train 400 1.673436e-01 -233.866053
2019-12-04 15:07:30,322 train 450 1.670410e-01 -231.768979
2019-12-04 15:07:44,848 train 500 1.665274e-01 -231.967152
2019-12-04 15:07:59,371 train 550 1.661708e-01 -230.857107
2019-12-04 15:08:13,890 train 600 1.666953e-01 -231.025360
2019-12-04 15:08:28,411 train 650 1.666065e-01 -231.233060
2019-12-04 15:08:42,927 train 700 1.663607e-01 -231.340805
2019-12-04 15:08:57,466 train 750 1.662820e-01 -231.625497
2019-12-04 15:09:12,005 train 800 1.666838e-01 -231.574014
2019-12-04 15:09:26,543 train 850 1.666380e-01 -232.188779
2019-12-04 15:09:38,093 training loss; R2: 1.666584e-01 -232.638828
2019-12-04 15:09:38,222 valid 000 2.057182e-01 -215.115114
2019-12-04 15:09:41,156 valid 050 1.850670e-01 -243.744267
2019-12-04 15:09:43,973 validation loss; R2: 1.865490e-01 -238.011818
2019-12-04 15:09:43,991 epoch 4 lr 1.000000e-03
2019-12-04 15:09:44,354 train 000 1.505194e-01 -358.937783
2019-12-04 15:09:58,872 train 050 1.677347e-01 -227.939222
2019-12-04 15:10:13,389 train 100 1.683383e-01 -233.618624
2019-12-04 15:10:27,906 train 150 1.672144e-01 -232.033904
2019-12-04 15:10:42,422 train 200 1.676990e-01 -232.455702
2019-12-04 15:10:56,944 train 250 1.666727e-01 -230.295567
2019-12-04 15:11:11,460 train 300 1.657029e-01 -229.521208
2019-12-04 15:11:25,975 train 350 1.659361e-01 -226.639358
2019-12-04 15:11:40,487 train 400 1.661410e-01 -228.872782
2019-12-04 15:11:55,000 train 450 1.655540e-01 -233.525735
2019-12-04 15:12:09,513 train 500 1.654361e-01 -231.427506
2019-12-04 15:12:24,023 train 550 1.660292e-01 -232.238227
2019-12-04 15:12:38,540 train 600 1.663216e-01 -233.071164
2019-12-04 15:12:53,052 train 650 1.660365e-01 -233.485359
2019-12-04 15:13:07,562 train 700 1.658345e-01 -233.163677
2019-12-04 15:13:22,078 train 750 1.656633e-01 -233.765840
2019-12-04 15:13:36,594 train 800 1.654425e-01 -233.929416
2019-12-04 15:13:51,124 train 850 1.654542e-01 -233.931244
2019-12-04 15:14:02,675 training loss; R2: 1.654673e-01 -233.898148
2019-12-04 15:14:02,803 valid 000 1.539162e-01 -182.030741
2019-12-04 15:14:05,743 valid 050 1.779394e-01 -201.016781
2019-12-04 15:14:08,562 validation loss; R2: 1.764476e-01 -200.566736
2019-12-04 15:14:08,581 epoch 5 lr 1.000000e-03
2019-12-04 15:14:08,943 train 000 1.271186e-01 -179.697614
2019-12-04 15:14:23,463 train 050 1.629725e-01 -235.488422
2019-12-04 15:14:37,983 train 100 1.667208e-01 -232.213063
2019-12-04 15:14:52,496 train 150 1.663899e-01 -231.797529
2019-12-04 15:15:07,011 train 200 1.656922e-01 -232.745253
2019-12-04 15:15:21,524 train 250 1.662376e-01 -233.910964
2019-12-04 15:15:36,036 train 300 1.660788e-01 -235.319923
2019-12-04 15:15:50,546 train 350 1.660396e-01 -236.720133
2019-12-04 15:16:05,055 train 400 1.660351e-01 -238.040072
2019-12-04 15:16:19,573 train 450 1.655848e-01 -236.657700
2019-12-04 15:16:34,079 train 500 1.652798e-01 -236.044634
2019-12-04 15:16:48,596 train 550 1.653055e-01 -237.372718
2019-12-04 15:17:03,103 train 600 1.649274e-01 -236.515419
2019-12-04 15:17:17,607 train 650 1.649214e-01 -237.216765
2019-12-04 15:17:32,113 train 700 1.649716e-01 -235.454567
2019-12-04 15:17:46,617 train 750 1.646005e-01 -236.528866
2019-12-04 15:18:01,124 train 800 1.648827e-01 -236.225863
2019-12-04 15:18:15,631 train 850 1.648354e-01 -236.616439
2019-12-04 15:18:27,174 training loss; R2: 1.646745e-01 -235.640530
2019-12-04 15:18:27,304 valid 000 2.099174e-01 -279.658104
2019-12-04 15:18:30,239 valid 050 1.735328e-01 -218.863878
2019-12-04 15:18:33,056 validation loss; R2: 1.762116e-01 -220.446647
2019-12-04 15:18:33,073 epoch 6 lr 1.000000e-03
2019-12-04 15:18:33,442 train 000 1.844963e-01 -214.463893
2019-12-04 15:18:47,949 train 050 1.651243e-01 -248.723738
2019-12-04 15:19:02,460 train 100 1.593137e-01 -243.256516
2019-12-04 15:19:16,970 train 150 1.605142e-01 -237.617580
2019-12-04 15:19:31,493 train 200 1.614495e-01 -239.802100
2019-12-04 15:19:46,008 train 250 1.617680e-01 -241.174217
2019-12-04 15:20:00,529 train 300 1.617825e-01 -239.483075
2019-12-04 15:20:15,043 train 350 1.612531e-01 -241.168818
2019-12-04 15:20:29,565 train 400 1.620227e-01 -240.581232
2019-12-04 15:20:44,082 train 450 1.617852e-01 -241.069986
2019-12-04 15:20:58,596 train 500 1.619487e-01 -243.133774
2019-12-04 15:21:13,112 train 550 1.628558e-01 -243.108109
2019-12-04 15:21:27,635 train 600 1.631475e-01 -241.583263
2019-12-04 15:21:42,152 train 650 1.636197e-01 -241.624150
2019-12-04 15:21:56,686 train 700 1.639605e-01 -240.844612
2019-12-04 15:22:11,211 train 750 1.640644e-01 -240.639053
2019-12-04 15:22:25,716 train 800 1.637802e-01 -240.306951
2019-12-04 15:22:40,228 train 850 1.638573e-01 -240.362252
2019-12-04 15:22:51,773 training loss; R2: 1.639418e-01 -239.548571
2019-12-04 15:22:51,903 valid 000 1.689452e-01 -301.791977
2019-12-04 15:22:54,842 valid 050 1.762299e-01 -217.961292
2019-12-04 15:22:57,660 validation loss; R2: 1.750389e-01 -223.154442
2019-12-04 15:22:57,678 epoch 7 lr 1.000000e-03
2019-12-04 15:22:58,042 train 000 1.705628e-01 -337.734426
2019-12-04 15:23:12,563 train 050 1.630142e-01 -238.673967
2019-12-04 15:23:27,085 train 100 1.606660e-01 -244.903978
2019-12-04 15:23:41,692 train 150 1.611058e-01 -243.650806
2019-12-04 15:23:56,227 train 200 1.629977e-01 -246.160053
2019-12-04 15:24:10,758 train 250 1.642705e-01 -245.322845
2019-12-04 15:24:25,286 train 300 1.633431e-01 -242.949666
2019-12-04 15:24:39,812 train 350 1.627822e-01 -243.270117
2019-12-04 15:24:54,354 train 400 1.635060e-01 -244.752959
2019-12-04 15:25:08,898 train 450 1.635613e-01 -241.553469
2019-12-04 15:25:23,425 train 500 1.643769e-01 -241.471250
2019-12-04 15:25:37,956 train 550 1.644298e-01 -241.110077
2019-12-04 15:25:52,486 train 600 1.641226e-01 -241.614743
2019-12-04 15:26:07,018 train 650 1.640973e-01 -242.291913
2019-12-04 15:26:21,538 train 700 1.638851e-01 -240.607814
2019-12-04 15:26:36,048 train 750 1.635607e-01 -241.711530
2019-12-04 15:26:50,556 train 800 1.634391e-01 -242.276042
2019-12-04 15:27:05,124 train 850 1.632880e-01 -242.703228
2019-12-04 15:27:16,713 training loss; R2: 1.630433e-01 -243.039006
2019-12-04 15:27:16,845 valid 000 2.134071e-01 -289.387878
2019-12-04 15:27:19,782 valid 050 1.816372e-01 -240.921949
2019-12-04 15:27:22,599 validation loss; R2: 1.775787e-01 -247.561522
2019-12-04 15:27:22,619 epoch 8 lr 1.000000e-03
2019-12-04 15:27:22,984 train 000 1.623418e-01 -188.614724
2019-12-04 15:27:37,525 train 050 1.643763e-01 -232.000277
2019-12-04 15:27:52,066 train 100 1.625208e-01 -233.813886
2019-12-04 15:28:06,620 train 150 1.601964e-01 -245.572053
2019-12-04 15:28:21,148 train 200 1.617247e-01 -249.889309
2019-12-04 15:28:35,653 train 250 1.620011e-01 -252.702186
2019-12-04 15:28:50,155 train 300 1.616854e-01 -252.830543
2019-12-04 15:29:04,659 train 350 1.624849e-01 -253.936674
2019-12-04 15:29:19,163 train 400 1.623912e-01 -252.283769
2019-12-04 15:29:33,671 train 450 1.618272e-01 -251.753825
2019-12-04 15:29:48,179 train 500 1.616173e-01 -251.610844
2019-12-04 15:30:02,690 train 550 1.614395e-01 -251.743908
2019-12-04 15:30:17,206 train 600 1.618391e-01 -250.534680
2019-12-04 15:30:31,719 train 650 1.619450e-01 -250.150260
2019-12-04 15:30:46,228 train 700 1.620901e-01 -249.916664
2019-12-04 15:31:00,733 train 750 1.618657e-01 -248.938218
2019-12-04 15:31:15,239 train 800 1.623962e-01 -248.037094
2019-12-04 15:31:29,744 train 850 1.627254e-01 -247.445133
2019-12-04 15:31:41,286 training loss; R2: 1.623439e-01 -247.906726
2019-12-04 15:31:41,414 valid 000 1.321569e-01 -157.224730
2019-12-04 15:31:44,349 valid 050 1.724302e-01 -211.833398
2019-12-04 15:31:47,164 validation loss; R2: 1.737859e-01 -218.118836
2019-12-04 15:31:47,182 epoch 9 lr 1.000000e-03
2019-12-04 15:31:47,550 train 000 1.796257e-01 -147.193852
2019-12-04 15:32:02,068 train 050 1.590453e-01 -243.402452
2019-12-04 15:32:16,582 train 100 1.580838e-01 -238.664161
2019-12-04 15:32:31,090 train 150 1.606025e-01 -248.762924
2019-12-04 15:32:45,598 train 200 1.590663e-01 -249.997716
2019-12-04 15:33:00,105 train 250 1.596425e-01 -247.827000
2019-12-04 15:33:14,620 train 300 1.608695e-01 -252.264078
2019-12-04 15:33:29,124 train 350 1.618908e-01 -251.422530
2019-12-04 15:33:43,628 train 400 1.615992e-01 -251.992202
2019-12-04 15:33:58,137 train 450 1.619517e-01 -251.010323
2019-12-04 15:34:12,651 train 500 1.616302e-01 -252.065818
2019-12-04 15:34:27,159 train 550 1.617961e-01 -250.903577
2019-12-04 15:34:41,649 train 600 1.618009e-01 -250.461466
2019-12-04 15:34:56,145 train 650 1.620070e-01 -250.133705
2019-12-04 15:35:10,640 train 700 1.619960e-01 -249.527575
2019-12-04 15:35:25,141 train 750 1.620208e-01 -249.891526
2019-12-04 15:35:39,634 train 800 1.621338e-01 -250.813181
2019-12-04 15:35:54,130 train 850 1.619848e-01 -250.392491
2019-12-04 15:36:05,675 training loss; R2: 1.618117e-01 -250.263811
2019-12-04 15:36:05,810 valid 000 2.196780e-01 -194.400276
2019-12-04 15:36:08,746 valid 050 1.770691e-01 -231.548058
2019-12-04 15:36:11,561 validation loss; R2: 1.733804e-01 -219.512142
2019-12-04 15:36:11,579 epoch 10 lr 1.000000e-03
2019-12-04 15:36:11,943 train 000 2.025506e-01 -261.039279
2019-12-04 15:36:26,440 train 050 1.602988e-01 -237.525624
2019-12-04 15:36:40,942 train 100 1.636462e-01 -239.169028
2019-12-04 15:36:55,433 train 150 1.631034e-01 -245.790827
2019-12-04 15:37:09,938 train 200 1.633693e-01 -248.282143
2019-12-04 15:37:24,447 train 250 1.632748e-01 -248.099681
2019-12-04 15:37:38,953 train 300 1.639216e-01 -248.078518
2019-12-04 15:37:53,459 train 350 1.623727e-01 -247.523575
2019-12-04 15:38:07,957 train 400 1.623034e-01 -247.355502
2019-12-04 15:38:22,458 train 450 1.617767e-01 -248.278999
2019-12-04 15:38:36,960 train 500 1.615690e-01 -248.568413
2019-12-04 15:38:51,455 train 550 1.617444e-01 -247.692319
2019-12-04 15:39:05,953 train 600 1.616558e-01 -249.993033
2019-12-04 15:39:20,459 train 650 1.616381e-01 -250.176279
2019-12-04 15:39:34,958 train 700 1.615066e-01 -249.491412
2019-12-04 15:39:49,456 train 750 1.612597e-01 -249.072982
2019-12-04 15:40:03,956 train 800 1.613019e-01 -248.228156
2019-12-04 15:40:18,448 train 850 1.613582e-01 -247.666947
2019-12-04 15:40:29,980 training loss; R2: 1.612486e-01 -247.659928
2019-12-04 15:40:30,107 valid 000 1.714333e-01 -314.010172
2019-12-04 15:40:33,042 valid 050 1.709255e-01 -217.835603
2019-12-04 15:40:35,857 validation loss; R2: 1.743100e-01 -219.955127
2019-12-04 15:40:35,876 epoch 11 lr 1.000000e-03
2019-12-04 15:40:36,239 train 000 2.010949e-01 -336.579847
2019-12-04 15:40:50,735 train 050 1.602124e-01 -256.799988
2019-12-04 15:41:05,223 train 100 1.649205e-01 -242.645485
2019-12-04 15:41:19,714 train 150 1.639526e-01 -238.754019
2019-12-04 15:41:34,199 train 200 1.628321e-01 -241.733296
2019-12-04 15:41:48,693 train 250 1.630077e-01 -242.615688
2019-12-04 15:42:03,179 train 300 1.617710e-01 -246.089632
2019-12-04 15:42:17,664 train 350 1.619518e-01 -248.164263
2019-12-04 15:42:32,153 train 400 1.619419e-01 -250.278663
2019-12-04 15:42:46,645 train 450 1.624754e-01 -249.219483
2019-12-04 15:43:01,142 train 500 1.624606e-01 -248.948944
2019-12-04 15:43:15,649 train 550 1.616265e-01 -249.583977
2019-12-04 15:43:30,156 train 600 1.609784e-01 -250.119520
2019-12-04 15:43:44,667 train 650 1.608613e-01 -249.506882
2019-12-04 15:43:59,170 train 700 1.610129e-01 -249.204170
2019-12-04 15:44:13,670 train 750 1.609506e-01 -248.288805
2019-12-04 15:44:28,172 train 800 1.611098e-01 -248.915085
2019-12-04 15:44:42,677 train 850 1.610514e-01 -249.932018
2019-12-04 15:44:54,215 training loss; R2: 1.609770e-01 -250.115813
2019-12-04 15:44:54,348 valid 000 1.679340e-01 -229.397540
2019-12-04 15:44:57,282 valid 050 1.691120e-01 -224.494921
2019-12-04 15:45:00,097 validation loss; R2: 1.728855e-01 -215.918434
2019-12-04 15:45:00,116 epoch 12 lr 1.000000e-03
2019-12-04 15:45:00,482 train 000 1.731202e-01 -415.517400
2019-12-04 15:45:14,980 train 050 1.637165e-01 -248.412896
2019-12-04 15:45:29,479 train 100 1.628052e-01 -237.663697
2019-12-04 15:45:43,980 train 150 1.605754e-01 -244.721106
2019-12-04 15:45:58,480 train 200 1.612830e-01 -245.778277
2019-12-04 15:46:12,976 train 250 1.609608e-01 -248.678853
2019-12-04 15:46:27,472 train 300 1.612321e-01 -249.170830
2019-12-04 15:46:41,968 train 350 1.602940e-01 -247.947323
2019-12-04 15:46:56,462 train 400 1.613492e-01 -248.438745
2019-12-04 15:47:10,958 train 450 1.609951e-01 -248.619655
2019-12-04 15:47:25,452 train 500 1.615154e-01 -247.225324
2019-12-04 15:47:39,941 train 550 1.612167e-01 -246.578099
2019-12-04 15:47:54,437 train 600 1.609810e-01 -246.934270
2019-12-04 15:48:08,927 train 650 1.609850e-01 -248.838178
2019-12-04 15:48:23,417 train 700 1.604019e-01 -248.440160
2019-12-04 15:48:37,911 train 750 1.606551e-01 -248.842494
2019-12-04 15:48:52,401 train 800 1.607036e-01 -249.471784
2019-12-04 15:49:06,894 train 850 1.604620e-01 -248.675744
2019-12-04 15:49:18,426 training loss; R2: 1.603678e-01 -249.854768
2019-12-04 15:49:18,559 valid 000 2.089237e-01 -308.444340
2019-12-04 15:49:21,494 valid 050 2.495735e-01 -593.722476
2019-12-04 15:49:24,309 validation loss; R2: 2.480666e-01 -591.927175
2019-12-04 15:49:24,327 epoch 13 lr 1.000000e-03
2019-12-04 15:49:24,692 train 000 1.513577e-01 -192.345174
2019-12-04 15:49:39,184 train 050 1.626885e-01 -260.460559
2019-12-04 15:49:53,671 train 100 1.654786e-01 -259.605351
2019-12-04 15:50:08,151 train 150 1.642747e-01 -251.063640
2019-12-04 15:50:22,636 train 200 1.615151e-01 -246.644886
2019-12-04 15:50:37,116 train 250 1.613822e-01 -245.074710
2019-12-04 15:50:51,600 train 300 1.604542e-01 -245.122749
2019-12-04 15:51:06,081 train 350 1.603559e-01 -244.928914
2019-12-04 15:51:20,565 train 400 1.605167e-01 -246.609447
2019-12-04 15:51:35,057 train 450 1.610495e-01 -245.994702
2019-12-04 15:51:49,536 train 500 1.607949e-01 -245.533305
2019-12-04 15:52:04,024 train 550 1.604038e-01 -245.519048
2019-12-04 15:52:18,497 train 600 1.598869e-01 -247.232098
2019-12-04 15:52:32,967 train 650 1.594575e-01 -247.241373
2019-12-04 15:52:47,432 train 700 1.597007e-01 -248.291932
2019-12-04 15:53:01,908 train 750 1.601368e-01 -248.763252
2019-12-04 15:53:16,421 train 800 1.602620e-01 -248.282681
2019-12-04 15:53:30,886 train 850 1.601107e-01 -250.146553
2019-12-04 15:53:42,395 training loss; R2: 1.599199e-01 -250.401218
2019-12-04 15:53:42,529 valid 000 2.121371e-01 -311.659831
2019-12-04 15:53:45,463 valid 050 2.033748e-01 -318.373213
2019-12-04 15:53:48,277 validation loss; R2: 2.039581e-01 -322.454169
2019-12-04 15:53:48,295 epoch 14 lr 1.000000e-03
2019-12-04 15:53:48,659 train 000 1.766601e-01 -148.422927
2019-12-04 15:54:03,129 train 050 1.620248e-01 -225.291381
2019-12-04 15:54:17,592 train 100 1.616756e-01 -238.728435
2019-12-04 15:54:32,052 train 150 1.632385e-01 -240.226434
2019-12-04 15:54:46,525 train 200 1.630021e-01 -238.807445
2019-12-04 15:55:00,996 train 250 1.628573e-01 -240.914983
2019-12-04 15:55:15,467 train 300 1.617486e-01 -245.564012
2019-12-04 15:55:29,940 train 350 1.613082e-01 -244.684812
2019-12-04 15:55:44,417 train 400 1.604578e-01 -249.107498
2019-12-04 15:55:58,897 train 450 1.601480e-01 -251.555158
2019-12-04 15:56:13,373 train 500 1.600724e-01 -253.243152
2019-12-04 15:56:27,850 train 550 1.605892e-01 -252.001020
2019-12-04 15:56:42,327 train 600 1.601145e-01 -252.440390
2019-12-04 15:56:56,811 train 650 1.601446e-01 -251.811604
2019-12-04 15:57:11,286 train 700 1.601611e-01 -251.290831
2019-12-04 15:57:25,764 train 750 1.596039e-01 -251.084510
2019-12-04 15:57:40,243 train 800 1.595529e-01 -251.288637
2019-12-04 15:57:54,723 train 850 1.594134e-01 -250.986924
2019-12-04 15:58:06,238 training loss; R2: 1.596628e-01 -250.820336
2019-12-04 15:58:06,379 valid 000 2.432200e-01 -194.364437
2019-12-04 15:58:09,312 valid 050 2.287633e-01 -236.935021
2019-12-04 15:58:12,124 validation loss; R2: 2.235754e-01 -229.349974
2019-12-04 15:58:12,142 epoch 15 lr 1.000000e-03
2019-12-04 15:58:12,505 train 000 1.332892e-01 -185.179091
2019-12-04 15:58:26,978 train 050 1.560713e-01 -231.265624
2019-12-04 15:58:41,455 train 100 1.622891e-01 -229.522299
2019-12-04 15:58:55,926 train 150 1.615257e-01 -235.244660
2019-12-04 15:59:10,398 train 200 1.595460e-01 -242.502387
2019-12-04 15:59:24,870 train 250 1.588286e-01 -251.737230
2019-12-04 15:59:39,345 train 300 1.592468e-01 -250.346922
2019-12-04 15:59:53,818 train 350 1.596335e-01 -250.401954
2019-12-04 16:00:08,286 train 400 1.595729e-01 -252.644916
2019-12-04 16:00:22,765 train 450 1.587425e-01 -251.174208
2019-12-04 16:00:37,232 train 500 1.587489e-01 -251.533400
2019-12-04 16:00:51,703 train 550 1.583773e-01 -251.023667
2019-12-04 16:01:06,173 train 600 1.581217e-01 -250.776617
2019-12-04 16:01:20,651 train 650 1.581712e-01 -251.395603
2019-12-04 16:01:35,133 train 700 1.584419e-01 -250.396933
2019-12-04 16:01:49,606 train 750 1.588254e-01 -251.011891
2019-12-04 16:02:04,081 train 800 1.584705e-01 -252.107778
2019-12-04 16:02:18,552 train 850 1.587645e-01 -253.054773
2019-12-04 16:02:30,067 training loss; R2: 1.593081e-01 -253.373079
2019-12-04 16:02:30,199 valid 000 1.432927e-01 -408.876305
2019-12-04 16:02:33,130 valid 050 2.006536e-01 -426.048085
2019-12-04 16:02:35,944 validation loss; R2: 1.982918e-01 -424.771184
