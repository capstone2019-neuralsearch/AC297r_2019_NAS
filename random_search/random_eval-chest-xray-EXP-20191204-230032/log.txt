2019-12-04 23:00:32,893 gpu device = 3
2019-12-04 23:00:32,893 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-230032', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 23:00:40,099 param size = 0.166398MB
2019-12-04 23:00:40,102 epoch 0 lr 1.000000e-03
2019-12-04 23:00:41,890 train 000 7.668630e-01 -3.243209
2019-12-04 23:00:51,781 train 050 3.192792e-01 -108.129218
2019-12-04 23:01:01,625 train 100 2.552201e-01 -158.936325
2019-12-04 23:01:11,636 train 150 2.307597e-01 -190.913015
2019-12-04 23:01:21,579 train 200 2.186873e-01 -202.378671
2019-12-04 23:01:31,440 train 250 2.103883e-01 -209.722338
2019-12-04 23:01:41,301 train 300 2.046679e-01 -210.132215
2019-12-04 23:01:51,166 train 350 2.003205e-01 -213.954408
2019-12-04 23:02:01,031 train 400 1.967677e-01 -214.843931
2019-12-04 23:02:10,894 train 450 1.944841e-01 -215.743718
2019-12-04 23:02:20,755 train 500 1.925235e-01 -218.371870
2019-12-04 23:02:30,617 train 550 1.904332e-01 -219.584913
2019-12-04 23:02:40,479 train 600 1.891087e-01 -219.379779
2019-12-04 23:02:50,339 train 650 1.881380e-01 -220.500227
2019-12-04 23:03:00,202 train 700 1.867962e-01 -220.284777
2019-12-04 23:03:10,061 train 750 1.858109e-01 -221.433748
2019-12-04 23:03:19,925 train 800 1.849547e-01 -222.501988
2019-12-04 23:03:29,791 train 850 1.842271e-01 -222.691745
2019-12-04 23:03:38,406 training loss; R2: 1.834017e-01 -222.928182
2019-12-04 23:03:38,560 valid 000 1.513422e-01 -274.085333
2019-12-04 23:03:40,721 valid 050 1.785845e-01 -234.370296
2019-12-04 23:03:42,931 validation loss; R2: 1.808829e-01 -236.102920
2019-12-04 23:03:42,951 epoch 1 lr 1.000000e-03
2019-12-04 23:03:43,285 train 000 1.544945e-01 -290.058877
2019-12-04 23:03:53,154 train 050 1.757809e-01 -230.005213
2019-12-04 23:04:03,017 train 100 1.746534e-01 -228.069474
2019-12-04 23:04:12,882 train 150 1.738876e-01 -225.732194
2019-12-04 23:04:22,750 train 200 1.728511e-01 -228.100529
2019-12-04 23:04:32,608 train 250 1.715912e-01 -226.124378
2019-12-04 23:04:42,474 train 300 1.716436e-01 -226.848973
2019-12-04 23:04:52,340 train 350 1.707047e-01 -227.489347
2019-12-04 23:05:02,202 train 400 1.702894e-01 -225.912172
2019-12-04 23:05:12,059 train 450 1.703248e-01 -226.294781
2019-12-04 23:05:21,924 train 500 1.699986e-01 -227.360678
2019-12-04 23:05:31,786 train 550 1.691896e-01 -228.612330
2019-12-04 23:05:41,679 train 600 1.690714e-01 -229.743404
2019-12-04 23:05:51,699 train 650 1.694216e-01 -230.523765
2019-12-04 23:06:01,719 train 700 1.698147e-01 -229.494467
2019-12-04 23:06:11,732 train 750 1.695678e-01 -229.311743
2019-12-04 23:06:21,749 train 800 1.696204e-01 -228.877926
2019-12-04 23:06:31,759 train 850 1.694674e-01 -229.259547
2019-12-04 23:06:39,724 training loss; R2: 1.691892e-01 -229.015671
2019-12-04 23:06:39,852 valid 000 1.774042e-01 -248.981086
2019-12-04 23:06:42,013 valid 050 1.784411e-01 -223.423880
2019-12-04 23:06:44,087 validation loss; R2: 1.785794e-01 -221.535266
2019-12-04 23:06:44,099 epoch 2 lr 1.000000e-03
2019-12-04 23:06:44,382 train 000 1.459157e-01 -254.826964
2019-12-04 23:06:54,251 train 050 1.634514e-01 -241.262828
2019-12-04 23:07:04,127 train 100 1.684059e-01 -242.843023
2019-12-04 23:07:13,999 train 150 1.659199e-01 -241.722517
2019-12-04 23:07:23,862 train 200 1.662320e-01 -238.110517
2019-12-04 23:07:33,738 train 250 1.657107e-01 -238.771756
2019-12-04 23:07:43,612 train 300 1.663090e-01 -237.013908
2019-12-04 23:07:53,482 train 350 1.659525e-01 -239.436946
2019-12-04 23:08:03,352 train 400 1.670265e-01 -239.680988
2019-12-04 23:08:13,214 train 450 1.671376e-01 -238.677283
2019-12-04 23:08:23,080 train 500 1.670106e-01 -239.592529
2019-12-04 23:08:32,947 train 550 1.668946e-01 -239.321198
2019-12-04 23:08:42,809 train 600 1.666764e-01 -238.237635
2019-12-04 23:08:52,674 train 650 1.671093e-01 -237.124010
2019-12-04 23:09:02,543 train 700 1.673354e-01 -236.816734
2019-12-04 23:09:12,412 train 750 1.674192e-01 -236.163628
2019-12-04 23:09:22,276 train 800 1.675937e-01 -234.728036
2019-12-04 23:09:32,139 train 850 1.680284e-01 -234.632302
2019-12-04 23:09:39,988 training loss; R2: 1.680572e-01 -234.018006
2019-12-04 23:09:40,116 valid 000 2.404854e-01 -205.070563
2019-12-04 23:09:42,275 valid 050 1.794191e-01 -231.616488
2019-12-04 23:09:44,347 validation loss; R2: 1.798389e-01 -230.343061
2019-12-04 23:09:44,366 epoch 3 lr 1.000000e-03
2019-12-04 23:09:44,648 train 000 2.054674e-01 -184.052138
2019-12-04 23:09:54,513 train 050 1.674680e-01 -242.077187
2019-12-04 23:10:04,381 train 100 1.647472e-01 -233.349122
2019-12-04 23:10:14,245 train 150 1.666442e-01 -237.006312
2019-12-04 23:10:24,114 train 200 1.674190e-01 -232.331234
2019-12-04 23:10:33,985 train 250 1.681417e-01 -232.455152
2019-12-04 23:10:43,854 train 300 1.678903e-01 -234.492057
2019-12-04 23:10:53,719 train 350 1.677475e-01 -233.587238
2019-12-04 23:11:03,581 train 400 1.673005e-01 -232.829004
2019-12-04 23:11:13,445 train 450 1.675030e-01 -231.346022
2019-12-04 23:11:23,313 train 500 1.671813e-01 -231.834107
2019-12-04 23:11:33,175 train 550 1.669588e-01 -231.547319
2019-12-04 23:11:43,039 train 600 1.669795e-01 -231.952062
2019-12-04 23:11:52,912 train 650 1.669167e-01 -233.339154
2019-12-04 23:12:02,780 train 700 1.672723e-01 -233.272838
2019-12-04 23:12:12,647 train 750 1.671103e-01 -232.954078
2019-12-04 23:12:22,515 train 800 1.673695e-01 -232.321557
2019-12-04 23:12:32,385 train 850 1.675561e-01 -232.944019
2019-12-04 23:12:40,236 training loss; R2: 1.674766e-01 -232.200461
2019-12-04 23:12:40,362 valid 000 1.872366e-01 -276.425609
2019-12-04 23:12:42,522 valid 050 1.824095e-01 -253.518281
2019-12-04 23:12:44,594 validation loss; R2: 1.785225e-01 -247.663719
2019-12-04 23:12:44,611 epoch 4 lr 1.000000e-03
2019-12-04 23:12:44,893 train 000 2.122011e-01 -279.127936
2019-12-04 23:12:54,758 train 050 1.659154e-01 -239.377489
2019-12-04 23:13:04,624 train 100 1.659142e-01 -235.093814
2019-12-04 23:13:14,486 train 150 1.657884e-01 -238.995047
2019-12-04 23:13:24,347 train 200 1.664191e-01 -238.727960
2019-12-04 23:13:34,208 train 250 1.674010e-01 -236.751946
2019-12-04 23:13:44,067 train 300 1.676466e-01 -238.155527
2019-12-04 23:13:53,927 train 350 1.673263e-01 -239.173961
2019-12-04 23:14:03,787 train 400 1.667066e-01 -239.186461
2019-12-04 23:14:13,651 train 450 1.668528e-01 -237.648229
2019-12-04 23:14:23,514 train 500 1.665957e-01 -238.743915
2019-12-04 23:14:33,378 train 550 1.669026e-01 -239.256616
2019-12-04 23:14:43,236 train 600 1.671267e-01 -238.191295
2019-12-04 23:14:53,095 train 650 1.670837e-01 -237.961072
2019-12-04 23:15:02,955 train 700 1.668182e-01 -237.222502
2019-12-04 23:15:12,816 train 750 1.669744e-01 -237.656274
2019-12-04 23:15:22,676 train 800 1.672833e-01 -237.502692
2019-12-04 23:15:32,538 train 850 1.668649e-01 -237.682379
2019-12-04 23:15:40,382 training loss; R2: 1.668572e-01 -237.557505
2019-12-04 23:15:40,508 valid 000 1.481112e-01 -201.411690
2019-12-04 23:15:42,667 valid 050 1.767003e-01 -282.607060
2019-12-04 23:15:44,739 validation loss; R2: 1.776194e-01 -255.711536
2019-12-04 23:15:44,750 epoch 5 lr 1.000000e-03
2019-12-04 23:15:45,030 train 000 1.542984e-01 -200.309139
2019-12-04 23:15:54,896 train 050 1.628450e-01 -234.237377
2019-12-04 23:16:04,756 train 100 1.650114e-01 -237.180679
2019-12-04 23:16:14,615 train 150 1.666489e-01 -236.458543
2019-12-04 23:16:24,479 train 200 1.648962e-01 -235.714975
2019-12-04 23:16:34,342 train 250 1.640115e-01 -234.746965
2019-12-04 23:16:44,209 train 300 1.644159e-01 -233.861036
2019-12-04 23:16:54,070 train 350 1.654712e-01 -234.334832
2019-12-04 23:17:03,939 train 400 1.649060e-01 -233.457238
2019-12-04 23:17:13,802 train 450 1.654276e-01 -233.159371
2019-12-04 23:17:23,653 train 500 1.656819e-01 -232.835348
2019-12-04 23:17:33,505 train 550 1.661119e-01 -235.129412
2019-12-04 23:17:43,358 train 600 1.664509e-01 -236.237518
2019-12-04 23:17:53,207 train 650 1.669131e-01 -235.488801
2019-12-04 23:18:03,058 train 700 1.669081e-01 -235.126865
2019-12-04 23:18:12,916 train 750 1.666561e-01 -235.851655
2019-12-04 23:18:22,790 train 800 1.664475e-01 -236.493945
2019-12-04 23:18:32,665 train 850 1.658387e-01 -237.033274
2019-12-04 23:18:40,519 training loss; R2: 1.660660e-01 -237.355226
2019-12-04 23:18:40,649 valid 000 1.860764e-01 -240.144227
2019-12-04 23:18:42,807 valid 050 1.780457e-01 -218.847814
2019-12-04 23:18:44,879 validation loss; R2: 1.768499e-01 -222.384562
2019-12-04 23:18:44,895 epoch 6 lr 1.000000e-03
2019-12-04 23:18:45,177 train 000 2.012223e-01 -147.971198
2019-12-04 23:18:55,039 train 050 1.608973e-01 -232.127474
2019-12-04 23:19:04,897 train 100 1.619668e-01 -236.245018
2019-12-04 23:19:14,757 train 150 1.627255e-01 -235.435533
2019-12-04 23:19:24,613 train 200 1.653845e-01 -234.195084
2019-12-04 23:19:34,466 train 250 1.661491e-01 -232.230259
2019-12-04 23:19:44,319 train 300 1.647876e-01 -233.851883
2019-12-04 23:19:54,175 train 350 1.641531e-01 -235.579141
2019-12-04 23:20:04,024 train 400 1.639465e-01 -236.145950
2019-12-04 23:20:13,865 train 450 1.636247e-01 -235.746223
2019-12-04 23:20:23,706 train 500 1.637039e-01 -237.076372
2019-12-04 23:20:33,552 train 550 1.643754e-01 -239.468055
2019-12-04 23:20:43,410 train 600 1.649726e-01 -239.672229
2019-12-04 23:20:53,268 train 650 1.650242e-01 -239.698619
2019-12-04 23:21:03,123 train 700 1.650280e-01 -239.737622
2019-12-04 23:21:12,974 train 750 1.652605e-01 -239.155207
2019-12-04 23:21:22,827 train 800 1.653565e-01 -239.637951
2019-12-04 23:21:32,686 train 850 1.653646e-01 -239.913698
2019-12-04 23:21:40,528 training loss; R2: 1.655279e-01 -238.999178
2019-12-04 23:21:40,655 valid 000 2.189421e-01 -237.878911
2019-12-04 23:21:42,813 valid 050 1.760799e-01 -240.442865
2019-12-04 23:21:44,885 validation loss; R2: 1.764709e-01 -247.916601
2019-12-04 23:21:44,896 epoch 7 lr 1.000000e-03
2019-12-04 23:21:45,180 train 000 1.652055e-01 -182.209951
2019-12-04 23:21:55,038 train 050 1.648561e-01 -228.085655
2019-12-04 23:22:04,900 train 100 1.648955e-01 -229.977026
2019-12-04 23:22:14,815 train 150 1.637057e-01 -235.464756
2019-12-04 23:22:24,833 train 200 1.629929e-01 -236.605681
2019-12-04 23:22:34,845 train 250 1.624644e-01 -234.838698
2019-12-04 23:22:44,858 train 300 1.630266e-01 -236.537664
2019-12-04 23:22:54,864 train 350 1.633763e-01 -236.211630
2019-12-04 23:23:04,877 train 400 1.631954e-01 -232.148216
2019-12-04 23:23:14,884 train 450 1.641676e-01 -232.031161
2019-12-04 23:23:24,890 train 500 1.639192e-01 -231.713894
2019-12-04 23:23:34,895 train 550 1.640026e-01 -231.937705
2019-12-04 23:23:44,909 train 600 1.640754e-01 -232.378455
2019-12-04 23:23:54,917 train 650 1.641502e-01 -231.923478
2019-12-04 23:24:04,928 train 700 1.643502e-01 -231.778345
2019-12-04 23:24:14,938 train 750 1.648567e-01 -231.886529
2019-12-04 23:24:24,944 train 800 1.650052e-01 -232.126995
2019-12-04 23:24:34,951 train 850 1.647678e-01 -233.966571
2019-12-04 23:24:42,911 training loss; R2: 1.648176e-01 -235.136905
2019-12-04 23:24:43,039 valid 000 1.988281e-01 -230.376303
2019-12-04 23:24:45,203 valid 050 1.733245e-01 -226.738201
2019-12-04 23:24:47,277 validation loss; R2: 1.744534e-01 -230.975374
2019-12-04 23:24:47,294 epoch 8 lr 1.000000e-03
2019-12-04 23:24:47,583 train 000 1.340391e-01 -157.177877
2019-12-04 23:24:57,580 train 050 1.640743e-01 -241.958396
2019-12-04 23:25:07,578 train 100 1.660104e-01 -249.370355
2019-12-04 23:25:17,575 train 150 1.639764e-01 -253.538818
2019-12-04 23:25:27,573 train 200 1.645207e-01 -252.728355
2019-12-04 23:25:37,569 train 250 1.635725e-01 -249.963711
2019-12-04 23:25:47,573 train 300 1.646188e-01 -247.955755
2019-12-04 23:25:57,584 train 350 1.645248e-01 -247.237366
2019-12-04 23:26:07,596 train 400 1.652365e-01 -245.959729
2019-12-04 23:26:17,550 train 450 1.650902e-01 -247.006623
2019-12-04 23:26:27,403 train 500 1.654148e-01 -246.916368
2019-12-04 23:26:37,341 train 550 1.654885e-01 -245.670144
2019-12-04 23:26:47,297 train 600 1.647352e-01 -245.380464
2019-12-04 23:26:57,148 train 650 1.644521e-01 -242.986095
2019-12-04 23:27:06,997 train 700 1.643007e-01 -243.260164
2019-12-04 23:27:16,845 train 750 1.641766e-01 -243.573152
2019-12-04 23:27:26,694 train 800 1.640707e-01 -244.528418
2019-12-04 23:27:36,551 train 850 1.639576e-01 -244.467496
2019-12-04 23:27:44,399 training loss; R2: 1.641449e-01 -244.954551
2019-12-04 23:27:44,527 valid 000 1.833860e-01 -245.209004
2019-12-04 23:27:46,689 valid 050 1.771596e-01 -222.046897
2019-12-04 23:27:48,763 validation loss; R2: 1.747888e-01 -220.921387
2019-12-04 23:27:48,775 epoch 9 lr 1.000000e-03
2019-12-04 23:27:49,062 train 000 1.118038e-01 -108.166793
2019-12-04 23:27:59,068 train 050 1.609139e-01 -245.040378
2019-12-04 23:28:09,076 train 100 1.580887e-01 -238.968933
2019-12-04 23:28:19,090 train 150 1.598512e-01 -242.002325
2019-12-04 23:28:29,105 train 200 1.592636e-01 -239.016039
2019-12-04 23:28:39,121 train 250 1.594791e-01 -239.088468
2019-12-04 23:28:49,088 train 300 1.613910e-01 -239.523504
2019-12-04 23:28:58,942 train 350 1.615987e-01 -239.510429
2019-12-04 23:29:08,795 train 400 1.617261e-01 -236.658620
2019-12-04 23:29:18,643 train 450 1.614756e-01 -241.120112
2019-12-04 23:29:28,498 train 500 1.623444e-01 -242.034562
2019-12-04 23:29:38,356 train 550 1.630691e-01 -241.372819
2019-12-04 23:29:48,212 train 600 1.629106e-01 -241.509531
2019-12-04 23:29:58,063 train 650 1.632720e-01 -242.334265
2019-12-04 23:30:07,916 train 700 1.628561e-01 -243.039759
2019-12-04 23:30:17,763 train 750 1.634130e-01 -242.567920
2019-12-04 23:30:27,610 train 800 1.635135e-01 -242.758637
2019-12-04 23:30:37,454 train 850 1.634307e-01 -242.170749
2019-12-04 23:30:45,286 training loss; R2: 1.634215e-01 -242.698479
2019-12-04 23:30:45,417 valid 000 1.651389e-01 -327.956212
2019-12-04 23:30:47,576 valid 050 1.754849e-01 -204.890015
2019-12-04 23:30:49,647 validation loss; R2: 1.754661e-01 -197.379329
2019-12-04 23:30:49,659 epoch 10 lr 1.000000e-03
2019-12-04 23:30:49,942 train 000 1.998124e-01 -307.152419
2019-12-04 23:30:59,784 train 050 1.626387e-01 -265.665726
2019-12-04 23:31:09,624 train 100 1.628026e-01 -244.278401
2019-12-04 23:31:19,464 train 150 1.601635e-01 -244.850536
2019-12-04 23:31:29,306 train 200 1.601291e-01 -240.944132
2019-12-04 23:31:39,153 train 250 1.613752e-01 -241.189115
2019-12-04 23:31:48,996 train 300 1.615230e-01 -239.598529
2019-12-04 23:31:58,838 train 350 1.634879e-01 -240.941947
2019-12-04 23:32:08,679 train 400 1.631776e-01 -239.569282
2019-12-04 23:32:18,521 train 450 1.631049e-01 -240.199305
2019-12-04 23:32:28,361 train 500 1.627572e-01 -239.976596
2019-12-04 23:32:38,200 train 550 1.622195e-01 -241.315048
2019-12-04 23:32:48,038 train 600 1.618187e-01 -243.063503
2019-12-04 23:32:57,877 train 650 1.613025e-01 -243.521159
2019-12-04 23:33:07,821 train 700 1.616054e-01 -242.905795
2019-12-04 23:33:17,819 train 750 1.621039e-01 -242.464991
2019-12-04 23:33:27,821 train 800 1.619693e-01 -241.908603
2019-12-04 23:33:37,822 train 850 1.624463e-01 -240.789679
2019-12-04 23:33:45,775 training loss; R2: 1.626657e-01 -240.340334
2019-12-04 23:33:45,913 valid 000 1.778865e-01 -205.026526
2019-12-04 23:33:48,074 valid 050 1.756678e-01 -233.254190
2019-12-04 23:33:50,148 validation loss; R2: 1.728812e-01 -226.473027
2019-12-04 23:33:50,160 epoch 11 lr 1.000000e-03
2019-12-04 23:33:50,445 train 000 1.760638e-01 -270.766809
2019-12-04 23:34:00,444 train 050 1.655591e-01 -255.772331
2019-12-04 23:34:10,444 train 100 1.645828e-01 -252.429369
2019-12-04 23:34:20,287 train 150 1.651005e-01 -247.858002
2019-12-04 23:34:30,122 train 200 1.630790e-01 -252.464773
2019-12-04 23:34:39,962 train 250 1.626988e-01 -248.757658
2019-12-04 23:34:49,800 train 300 1.633152e-01 -244.990423
2019-12-04 23:34:59,637 train 350 1.628777e-01 -247.303191
2019-12-04 23:35:09,474 train 400 1.631278e-01 -247.654998
2019-12-04 23:35:19,307 train 450 1.627892e-01 -247.322067
2019-12-04 23:35:29,141 train 500 1.627027e-01 -246.698292
2019-12-04 23:35:38,980 train 550 1.615836e-01 -246.993727
2019-12-04 23:35:48,814 train 600 1.617681e-01 -246.434068
2019-12-04 23:35:58,651 train 650 1.618082e-01 -245.276247
2019-12-04 23:36:08,484 train 700 1.618617e-01 -244.135607
2019-12-04 23:36:18,324 train 750 1.621182e-01 -244.254846
2019-12-04 23:36:28,164 train 800 1.622146e-01 -243.922954
2019-12-04 23:36:38,002 train 850 1.621213e-01 -243.890585
2019-12-04 23:36:45,829 training loss; R2: 1.620047e-01 -244.679451
2019-12-04 23:36:45,964 valid 000 2.155067e-01 -196.174689
2019-12-04 23:36:48,122 valid 050 1.706860e-01 -203.150046
2019-12-04 23:36:50,192 validation loss; R2: 1.735380e-01 -198.523353
2019-12-04 23:36:50,206 epoch 12 lr 1.000000e-03
2019-12-04 23:36:50,487 train 000 1.742538e-01 -392.907041
2019-12-04 23:37:00,332 train 050 1.591770e-01 -271.748807
2019-12-04 23:37:10,167 train 100 1.633149e-01 -263.565242
2019-12-04 23:37:20,002 train 150 1.621650e-01 -258.377122
2019-12-04 23:37:29,837 train 200 1.612506e-01 -252.779613
2019-12-04 23:37:39,670 train 250 1.611484e-01 -250.559306
2019-12-04 23:37:49,502 train 300 1.607879e-01 -248.239263
2019-12-04 23:37:59,335 train 350 1.600158e-01 -247.194516
2019-12-04 23:38:09,168 train 400 1.604901e-01 -246.460944
2019-12-04 23:38:19,004 train 450 1.611979e-01 -245.990950
2019-12-04 23:38:28,831 train 500 1.609685e-01 -246.886556
2019-12-04 23:38:38,660 train 550 1.610206e-01 -246.520410
2019-12-04 23:38:48,490 train 600 1.611748e-01 -245.658555
2019-12-04 23:38:58,318 train 650 1.615195e-01 -246.647097
2019-12-04 23:39:08,149 train 700 1.615014e-01 -246.455242
2019-12-04 23:39:17,976 train 750 1.617219e-01 -246.364812
2019-12-04 23:39:27,801 train 800 1.616661e-01 -246.262354
2019-12-04 23:39:37,629 train 850 1.617180e-01 -245.862434
2019-12-04 23:39:45,446 training loss; R2: 1.615800e-01 -245.872483
2019-12-04 23:39:45,573 valid 000 2.049282e-01 -336.579189
2019-12-04 23:39:47,730 valid 050 1.672579e-01 -224.422057
2019-12-04 23:39:49,800 validation loss; R2: 1.729314e-01 -220.671996
2019-12-04 23:39:49,811 epoch 13 lr 1.000000e-03
2019-12-04 23:39:50,091 train 000 1.679734e-01 -205.266973
2019-12-04 23:39:59,921 train 050 1.692774e-01 -232.031463
2019-12-04 23:40:09,751 train 100 1.659641e-01 -242.173319
2019-12-04 23:40:19,585 train 150 1.635481e-01 -242.719194
2019-12-04 23:40:29,412 train 200 1.611295e-01 -242.997836
2019-12-04 23:40:39,244 train 250 1.609695e-01 -243.122293
2019-12-04 23:40:49,077 train 300 1.620337e-01 -242.113815
2019-12-04 23:40:58,907 train 350 1.622131e-01 -241.701121
2019-12-04 23:41:08,746 train 400 1.616986e-01 -241.846403
2019-12-04 23:41:18,587 train 450 1.616897e-01 -240.856141
2019-12-04 23:41:28,424 train 500 1.613615e-01 -240.901004
2019-12-04 23:41:38,260 train 550 1.612827e-01 -240.676919
2019-12-04 23:41:48,095 train 600 1.613772e-01 -241.717734
2019-12-04 23:41:57,933 train 650 1.612748e-01 -242.056452
2019-12-04 23:42:07,757 train 700 1.612792e-01 -242.233329
2019-12-04 23:42:17,576 train 750 1.611170e-01 -242.880792
2019-12-04 23:42:27,419 train 800 1.611954e-01 -242.592172
2019-12-04 23:42:37,404 train 850 1.612280e-01 -242.999372
2019-12-04 23:42:45,341 training loss; R2: 1.612379e-01 -243.855865
2019-12-04 23:42:45,477 valid 000 1.769997e-01 -175.857761
2019-12-04 23:42:47,637 valid 050 1.727411e-01 -182.136579
2019-12-04 23:42:49,710 validation loss; R2: 1.730278e-01 -192.218835
2019-12-04 23:42:49,722 epoch 14 lr 1.000000e-03
2019-12-04 23:42:50,008 train 000 1.446042e-01 -205.098593
2019-12-04 23:42:59,996 train 050 1.609940e-01 -237.939427
2019-12-04 23:43:09,967 train 100 1.659046e-01 -239.477027
2019-12-04 23:43:19,943 train 150 1.621533e-01 -246.995712
2019-12-04 23:43:29,916 train 200 1.605225e-01 -244.285174
2019-12-04 23:43:39,895 train 250 1.593707e-01 -245.574347
2019-12-04 23:43:49,870 train 300 1.595445e-01 -246.762568
2019-12-04 23:43:59,845 train 350 1.602940e-01 -247.300810
2019-12-04 23:44:09,827 train 400 1.605386e-01 -245.519868
2019-12-04 23:44:19,817 train 450 1.611214e-01 -245.534816
2019-12-04 23:44:29,813 train 500 1.609470e-01 -244.897262
2019-12-04 23:44:39,803 train 550 1.602230e-01 -246.599487
2019-12-04 23:44:49,776 train 600 1.600420e-01 -246.516946
2019-12-04 23:44:59,748 train 650 1.604448e-01 -246.496743
2019-12-04 23:45:09,718 train 700 1.600805e-01 -246.504635
2019-12-04 23:45:19,690 train 750 1.606996e-01 -246.762156
2019-12-04 23:45:29,661 train 800 1.606528e-01 -246.295100
2019-12-04 23:45:39,632 train 850 1.610456e-01 -245.603241
2019-12-04 23:45:47,572 training loss; R2: 1.609467e-01 -245.073404
2019-12-04 23:45:47,705 valid 000 1.798063e-01 -195.327474
2019-12-04 23:45:49,865 valid 050 1.699081e-01 -228.989214
2019-12-04 23:45:51,937 validation loss; R2: 1.731468e-01 -230.306350
2019-12-04 23:45:51,948 epoch 15 lr 1.000000e-03
2019-12-04 23:45:52,229 train 000 1.856315e-01 -276.298020
2019-12-04 23:46:02,211 train 050 1.653592e-01 -246.710996
2019-12-04 23:46:12,188 train 100 1.633852e-01 -248.157305
2019-12-04 23:46:22,157 train 150 1.636039e-01 -252.033703
2019-12-04 23:46:32,129 train 200 1.619184e-01 -247.040121
2019-12-04 23:46:42,099 train 250 1.626080e-01 -250.121347
2019-12-04 23:46:52,069 train 300 1.612003e-01 -249.654631
2019-12-04 23:47:02,043 train 350 1.608856e-01 -251.758120
2019-12-04 23:47:12,020 train 400 1.609121e-01 -254.057703
2019-12-04 23:47:22,002 train 450 1.607162e-01 -253.820273
2019-12-04 23:47:31,975 train 500 1.602155e-01 -251.707458
2019-12-04 23:47:41,951 train 550 1.606358e-01 -250.331065
2019-12-04 23:47:51,924 train 600 1.603794e-01 -250.289709
2019-12-04 23:48:01,899 train 650 1.602988e-01 -251.283518
2019-12-04 23:48:11,873 train 700 1.603602e-01 -250.710277
2019-12-04 23:48:21,849 train 750 1.603509e-01 -250.566662
2019-12-04 23:48:31,820 train 800 1.598794e-01 -250.573743
2019-12-04 23:48:41,807 train 850 1.601212e-01 -250.430921
2019-12-04 23:48:49,745 training loss; R2: 1.605158e-01 -249.203794
2019-12-04 23:48:49,872 valid 000 1.956969e-01 -134.977750
2019-12-04 23:48:52,032 valid 050 1.740923e-01 -187.132063
2019-12-04 23:48:54,101 validation loss; R2: 1.737610e-01 -189.890717
