2019-12-04 20:49:42,178 gpu device = 3
2019-12-04 20:49:42,178 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-204942', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 20:49:49,460 param size = 0.260990MB
2019-12-04 20:49:49,464 epoch 0 lr 1.000000e-03
2019-12-04 20:49:51,418 train 000 6.762145e-01 -2.370098
2019-12-04 20:50:05,589 train 050 3.697886e-01 -73.593503
2019-12-04 20:50:19,700 train 100 2.949674e-01 -116.747901
2019-12-04 20:50:33,814 train 150 2.593310e-01 -140.538432
2019-12-04 20:50:47,927 train 200 2.396934e-01 -155.601645
2019-12-04 20:51:02,050 train 250 2.273363e-01 -166.883921
2019-12-04 20:51:16,176 train 300 2.181744e-01 -175.843495
2019-12-04 20:51:30,309 train 350 2.098573e-01 -182.887870
2019-12-04 20:51:44,443 train 400 2.052852e-01 -189.112430
2019-12-04 20:51:58,574 train 450 2.011318e-01 -194.121704
2019-12-04 20:52:12,702 train 500 1.986768e-01 -196.297418
2019-12-04 20:52:26,836 train 550 1.965155e-01 -198.947861
2019-12-04 20:52:40,973 train 600 1.952886e-01 -199.893404
2019-12-04 20:52:55,107 train 650 1.929560e-01 -201.408944
2019-12-04 20:53:09,243 train 700 1.912122e-01 -202.835381
2019-12-04 20:53:23,379 train 750 1.899972e-01 -203.565310
2019-12-04 20:53:37,519 train 800 1.888083e-01 -204.912493
2019-12-04 20:53:51,663 train 850 1.877223e-01 -205.101065
2019-12-04 20:54:03,794 training loss; R2: 1.868260e-01 -205.804623
2019-12-04 20:54:03,964 valid 000 1.944095e-01 -311.315671
2019-12-04 20:54:06,945 valid 050 1.818919e-01 -191.562803
2019-12-04 20:54:09,939 validation loss; R2: 1.815731e-01 -196.208199
2019-12-04 20:54:09,957 epoch 1 lr 1.000000e-03
2019-12-04 20:54:10,392 train 000 2.003087e-01 -199.939136
2019-12-04 20:54:24,523 train 050 1.700986e-01 -209.633175
2019-12-04 20:54:38,654 train 100 1.718633e-01 -213.681433
2019-12-04 20:54:52,789 train 150 1.698822e-01 -221.883295
2019-12-04 20:55:06,927 train 200 1.687529e-01 -221.178690
2019-12-04 20:55:21,066 train 250 1.683717e-01 -219.791228
2019-12-04 20:55:35,201 train 300 1.675406e-01 -223.254301
2019-12-04 20:55:49,333 train 350 1.678697e-01 -222.500431
2019-12-04 20:56:03,472 train 400 1.680190e-01 -226.611455
2019-12-04 20:56:17,609 train 450 1.682715e-01 -225.942017
2019-12-04 20:56:31,744 train 500 1.684019e-01 -226.084120
2019-12-04 20:56:45,883 train 550 1.682329e-01 -227.248480
2019-12-04 20:57:00,026 train 600 1.686222e-01 -226.387418
2019-12-04 20:57:14,178 train 650 1.686326e-01 -227.206691
2019-12-04 20:57:28,317 train 700 1.682886e-01 -227.164123
2019-12-04 20:57:42,453 train 750 1.681654e-01 -225.581982
2019-12-04 20:57:56,590 train 800 1.681043e-01 -225.942629
2019-12-04 20:58:10,730 train 850 1.682749e-01 -225.484849
2019-12-04 20:58:22,113 training loss; R2: 1.682478e-01 -226.968860
2019-12-04 20:58:22,268 valid 000 1.600633e-01 -113.465801
2019-12-04 20:58:25,259 valid 050 1.801377e-01 -199.186041
2019-12-04 20:58:28,128 validation loss; R2: 1.820229e-01 -202.319282
2019-12-04 20:58:28,146 epoch 2 lr 1.000000e-03
2019-12-04 20:58:28,515 train 000 1.521218e-01 -114.039461
2019-12-04 20:58:42,748 train 050 1.683239e-01 -226.328843
2019-12-04 20:58:57,039 train 100 1.679265e-01 -225.808176
2019-12-04 20:59:11,546 train 150 1.663834e-01 -224.059146
2019-12-04 20:59:26,031 train 200 1.686369e-01 -222.682758
2019-12-04 20:59:40,246 train 250 1.689138e-01 -225.787735
2019-12-04 20:59:54,413 train 300 1.677460e-01 -227.758001
2019-12-04 21:00:08,617 train 350 1.683371e-01 -225.987551
2019-12-04 21:00:22,796 train 400 1.675853e-01 -225.291259
2019-12-04 21:00:36,962 train 450 1.670596e-01 -226.858102
2019-12-04 21:00:51,145 train 500 1.673134e-01 -226.704373
2019-12-04 21:01:05,331 train 550 1.667344e-01 -228.151280
2019-12-04 21:01:19,523 train 600 1.666803e-01 -226.975324
2019-12-04 21:01:33,667 train 650 1.664856e-01 -226.387217
2019-12-04 21:01:47,799 train 700 1.664425e-01 -226.395264
2019-12-04 21:02:01,939 train 750 1.664345e-01 -225.537302
2019-12-04 21:02:16,077 train 800 1.664651e-01 -227.185528
2019-12-04 21:02:30,214 train 850 1.662957e-01 -227.784885
2019-12-04 21:02:41,460 training loss; R2: 1.660916e-01 -227.669964
2019-12-04 21:02:41,604 valid 000 1.682449e-01 -209.548923
2019-12-04 21:02:44,586 valid 050 1.857887e-01 -220.724118
2019-12-04 21:02:47,447 validation loss; R2: 1.794286e-01 -219.498556
2019-12-04 21:02:47,463 epoch 3 lr 1.000000e-03
2019-12-04 21:02:47,829 train 000 1.988863e-01 -368.782167
2019-12-04 21:03:01,962 train 050 1.600862e-01 -229.453658
2019-12-04 21:03:16,094 train 100 1.636662e-01 -234.411566
2019-12-04 21:03:30,228 train 150 1.654743e-01 -225.731807
2019-12-04 21:03:44,434 train 200 1.649609e-01 -222.678980
2019-12-04 21:03:58,854 train 250 1.659461e-01 -219.831489
2019-12-04 21:04:13,269 train 300 1.664264e-01 -220.748416
2019-12-04 21:04:27,683 train 350 1.650919e-01 -225.702212
2019-12-04 21:04:42,097 train 400 1.655347e-01 -225.022433
2019-12-04 21:04:56,515 train 450 1.658481e-01 -225.966426
2019-12-04 21:05:10,928 train 500 1.656054e-01 -227.470163
2019-12-04 21:05:25,341 train 550 1.660230e-01 -227.590616
2019-12-04 21:05:39,751 train 600 1.656951e-01 -226.767290
2019-12-04 21:05:54,158 train 650 1.658177e-01 -226.079169
2019-12-04 21:06:08,564 train 700 1.658527e-01 -227.131517
2019-12-04 21:06:22,968 train 750 1.657065e-01 -226.415198
2019-12-04 21:06:37,380 train 800 1.650226e-01 -227.429794
2019-12-04 21:06:51,793 train 850 1.650907e-01 -227.763113
2019-12-04 21:07:03,259 training loss; R2: 1.647494e-01 -227.359644
2019-12-04 21:07:03,403 valid 000 2.055984e-01 -213.446541
2019-12-04 21:07:06,386 valid 050 1.762793e-01 -229.613754
2019-12-04 21:07:09,248 validation loss; R2: 1.785309e-01 -217.273663
2019-12-04 21:07:09,266 epoch 4 lr 1.000000e-03
2019-12-04 21:07:09,639 train 000 1.664971e-01 -274.501448
2019-12-04 21:07:24,052 train 050 1.644591e-01 -213.403107
2019-12-04 21:07:38,465 train 100 1.623943e-01 -231.835953
2019-12-04 21:07:52,878 train 150 1.620340e-01 -233.025667
2019-12-04 21:08:07,158 train 200 1.631382e-01 -229.399183
2019-12-04 21:08:21,291 train 250 1.625678e-01 -230.939377
2019-12-04 21:08:35,422 train 300 1.631878e-01 -231.361595
2019-12-04 21:08:49,558 train 350 1.626755e-01 -232.126711
2019-12-04 21:09:03,693 train 400 1.623377e-01 -230.846720
2019-12-04 21:09:17,828 train 450 1.621382e-01 -231.993778
2019-12-04 21:09:31,964 train 500 1.626062e-01 -230.650687
2019-12-04 21:09:46,096 train 550 1.625470e-01 -231.437535
2019-12-04 21:10:00,231 train 600 1.632085e-01 -231.391340
2019-12-04 21:10:14,368 train 650 1.636431e-01 -231.801173
2019-12-04 21:10:28,502 train 700 1.635278e-01 -231.225395
2019-12-04 21:10:42,637 train 750 1.639060e-01 -230.886241
2019-12-04 21:10:56,778 train 800 1.639602e-01 -231.352392
2019-12-04 21:11:10,909 train 850 1.635809e-01 -231.954500
2019-12-04 21:11:22,151 training loss; R2: 1.636332e-01 -231.898196
2019-12-04 21:11:22,300 valid 000 1.501762e-01 -306.446083
2019-12-04 21:11:25,281 valid 050 1.836086e-01 -226.483969
2019-12-04 21:11:28,142 validation loss; R2: 1.788240e-01 -242.380302
2019-12-04 21:11:28,162 epoch 5 lr 1.000000e-03
2019-12-04 21:11:28,534 train 000 2.003319e-01 -512.079899
2019-12-04 21:11:42,711 train 050 1.605970e-01 -231.951149
2019-12-04 21:11:57,123 train 100 1.619758e-01 -226.346144
2019-12-04 21:12:11,420 train 150 1.611553e-01 -231.564770
2019-12-04 21:12:25,549 train 200 1.622729e-01 -230.437376
2019-12-04 21:12:39,689 train 250 1.624413e-01 -233.306041
2019-12-04 21:12:53,824 train 300 1.628869e-01 -233.927676
2019-12-04 21:13:07,957 train 350 1.623970e-01 -231.905985
2019-12-04 21:13:22,125 train 400 1.623235e-01 -232.626665
2019-12-04 21:13:36,254 train 450 1.626390e-01 -233.727684
2019-12-04 21:13:50,391 train 500 1.629735e-01 -233.268970
2019-12-04 21:14:04,525 train 550 1.628737e-01 -232.712865
2019-12-04 21:14:18,659 train 600 1.633498e-01 -232.012963
2019-12-04 21:14:32,793 train 650 1.633816e-01 -232.564906
2019-12-04 21:14:46,929 train 700 1.630671e-01 -233.848712
2019-12-04 21:15:01,056 train 750 1.629631e-01 -234.955371
2019-12-04 21:15:15,181 train 800 1.627792e-01 -234.724787
2019-12-04 21:15:29,313 train 850 1.626924e-01 -234.610785
2019-12-04 21:15:40,554 training loss; R2: 1.627834e-01 -235.323662
2019-12-04 21:15:40,699 valid 000 1.717390e-01 -216.346744
2019-12-04 21:15:43,679 valid 050 1.839003e-01 -207.614409
2019-12-04 21:15:46,540 validation loss; R2: 1.798853e-01 -211.327395
2019-12-04 21:15:46,557 epoch 6 lr 1.000000e-03
2019-12-04 21:15:46,930 train 000 1.890322e-01 -274.437183
2019-12-04 21:16:01,055 train 050 1.663440e-01 -218.748405
2019-12-04 21:16:15,183 train 100 1.618090e-01 -231.005433
2019-12-04 21:16:29,316 train 150 1.637690e-01 -233.837388
2019-12-04 21:16:43,441 train 200 1.639616e-01 -234.535025
2019-12-04 21:16:57,562 train 250 1.643072e-01 -239.207069
2019-12-04 21:17:11,685 train 300 1.633397e-01 -235.890409
2019-12-04 21:17:25,805 train 350 1.625307e-01 -239.731782
2019-12-04 21:17:39,928 train 400 1.629368e-01 -239.672401
2019-12-04 21:17:54,048 train 450 1.616389e-01 -237.498841
2019-12-04 21:18:08,175 train 500 1.615954e-01 -238.142114
2019-12-04 21:18:22,304 train 550 1.616615e-01 -237.500629
2019-12-04 21:18:36,425 train 600 1.615298e-01 -238.003413
2019-12-04 21:18:50,558 train 650 1.612111e-01 -237.969875
2019-12-04 21:19:04,721 train 700 1.616793e-01 -239.019170
2019-12-04 21:19:19,206 train 750 1.617502e-01 -238.511697
2019-12-04 21:19:33,356 train 800 1.619641e-01 -239.021783
2019-12-04 21:19:47,500 train 850 1.621491e-01 -238.761931
2019-12-04 21:19:58,743 training loss; R2: 1.620418e-01 -238.496984
2019-12-04 21:19:58,888 valid 000 3.487161e-01 -75.547706
2019-12-04 21:20:01,869 valid 050 3.498907e-01 -71.979979
2019-12-04 21:20:04,733 validation loss; R2: 3.471795e-01 -69.227246
2019-12-04 21:20:04,750 epoch 7 lr 1.000000e-03
2019-12-04 21:20:05,120 train 000 2.122448e-01 -224.726712
2019-12-04 21:20:19,265 train 050 1.650438e-01 -228.752765
2019-12-04 21:20:33,407 train 100 1.627003e-01 -239.952665
2019-12-04 21:20:47,540 train 150 1.619625e-01 -241.300349
2019-12-04 21:21:01,671 train 200 1.609510e-01 -238.612932
2019-12-04 21:21:15,803 train 250 1.622756e-01 -236.278061
2019-12-04 21:21:29,954 train 300 1.616367e-01 -231.941934
2019-12-04 21:21:44,098 train 350 1.626695e-01 -234.056239
2019-12-04 21:21:58,237 train 400 1.627356e-01 -235.627771
2019-12-04 21:22:12,372 train 450 1.619730e-01 -234.055315
2019-12-04 21:22:26,501 train 500 1.624098e-01 -234.000103
2019-12-04 21:22:40,635 train 550 1.620352e-01 -233.715058
2019-12-04 21:22:54,763 train 600 1.621421e-01 -233.209130
2019-12-04 21:23:08,896 train 650 1.622407e-01 -233.433843
2019-12-04 21:23:23,029 train 700 1.619173e-01 -232.719631
2019-12-04 21:23:37,317 train 750 1.619418e-01 -234.914206
2019-12-04 21:23:51,738 train 800 1.615839e-01 -234.383512
2019-12-04 21:24:05,997 train 850 1.614671e-01 -234.396097
2019-12-04 21:24:17,261 training loss; R2: 1.613732e-01 -235.774522
2019-12-04 21:24:17,405 valid 000 2.307968e-01 -89.022596
2019-12-04 21:24:20,387 valid 050 2.130173e-01 -205.957077
2019-12-04 21:24:23,247 validation loss; R2: 2.195316e-01 -202.731547
2019-12-04 21:24:23,263 epoch 8 lr 1.000000e-03
2019-12-04 21:24:23,632 train 000 1.960013e-01 -233.372982
2019-12-04 21:24:37,784 train 050 1.508629e-01 -218.480287
2019-12-04 21:24:51,966 train 100 1.566417e-01 -226.905600
2019-12-04 21:25:06,104 train 150 1.587935e-01 -234.519078
2019-12-04 21:25:20,237 train 200 1.583983e-01 -231.791645
2019-12-04 21:25:34,374 train 250 1.601063e-01 -231.423161
2019-12-04 21:25:48,507 train 300 1.592799e-01 -236.704654
2019-12-04 21:26:02,632 train 350 1.597669e-01 -237.935414
2019-12-04 21:26:16,761 train 400 1.603087e-01 -238.142969
2019-12-04 21:26:30,875 train 450 1.606296e-01 -240.009226
2019-12-04 21:26:44,989 train 500 1.603749e-01 -240.292783
2019-12-04 21:26:59,096 train 550 1.607698e-01 -240.963094
2019-12-04 21:27:13,206 train 600 1.604084e-01 -241.142442
2019-12-04 21:27:27,318 train 650 1.604227e-01 -241.110313
2019-12-04 21:27:41,452 train 700 1.600094e-01 -241.546273
2019-12-04 21:27:55,579 train 750 1.600633e-01 -241.486254
2019-12-04 21:28:09,705 train 800 1.603335e-01 -241.931038
2019-12-04 21:28:23,825 train 850 1.603840e-01 -241.556333
2019-12-04 21:28:35,062 training loss; R2: 1.606990e-01 -241.466094
2019-12-04 21:28:35,216 valid 000 3.226362e-01 -50.425107
2019-12-04 21:28:38,196 valid 050 3.294475e-01 -46.093912
2019-12-04 21:28:41,056 validation loss; R2: 3.310630e-01 -47.155817
2019-12-04 21:28:41,074 epoch 9 lr 1.000000e-03
2019-12-04 21:28:41,448 train 000 1.959273e-01 -217.680861
2019-12-04 21:28:55,572 train 050 1.670833e-01 -238.321518
2019-12-04 21:29:09,696 train 100 1.607905e-01 -238.962018
2019-12-04 21:29:23,817 train 150 1.600986e-01 -241.020304
2019-12-04 21:29:37,939 train 200 1.606486e-01 -245.502704
2019-12-04 21:29:52,064 train 250 1.608420e-01 -239.639400
2019-12-04 21:30:06,186 train 300 1.599615e-01 -238.092771
2019-12-04 21:30:20,314 train 350 1.592528e-01 -237.900708
2019-12-04 21:30:34,439 train 400 1.591070e-01 -238.601034
2019-12-04 21:30:48,556 train 450 1.587769e-01 -239.893291
2019-12-04 21:31:02,673 train 500 1.588801e-01 -239.726019
2019-12-04 21:31:16,792 train 550 1.592279e-01 -239.970143
2019-12-04 21:31:30,913 train 600 1.593698e-01 -239.371118
2019-12-04 21:31:45,031 train 650 1.599618e-01 -240.214051
2019-12-04 21:31:59,149 train 700 1.600596e-01 -239.837861
2019-12-04 21:32:13,265 train 750 1.600706e-01 -239.289144
2019-12-04 21:32:27,377 train 800 1.600313e-01 -239.247403
2019-12-04 21:32:41,492 train 850 1.602494e-01 -240.227847
2019-12-04 21:32:52,721 training loss; R2: 1.600687e-01 -240.140833
2019-12-04 21:32:52,875 valid 000 2.038434e-01 -411.619218
2019-12-04 21:32:55,856 valid 050 2.302969e-01 -358.408089
2019-12-04 21:32:58,717 validation loss; R2: 2.323348e-01 -353.334482
2019-12-04 21:32:58,735 epoch 10 lr 1.000000e-03
2019-12-04 21:32:59,109 train 000 1.891385e-01 -273.019208
2019-12-04 21:33:13,230 train 050 1.565748e-01 -214.035763
2019-12-04 21:33:27,346 train 100 1.564352e-01 -238.661773
2019-12-04 21:33:41,470 train 150 1.562308e-01 -236.890942
2019-12-04 21:33:55,589 train 200 1.574187e-01 -240.308585
2019-12-04 21:34:09,708 train 250 1.574615e-01 -238.944974
2019-12-04 21:34:23,823 train 300 1.593121e-01 -241.370648
2019-12-04 21:34:37,934 train 350 1.582853e-01 -244.225030
2019-12-04 21:34:52,045 train 400 1.576679e-01 -241.365245
2019-12-04 21:35:06,154 train 450 1.581707e-01 -241.674538
2019-12-04 21:35:20,273 train 500 1.584363e-01 -240.374218
2019-12-04 21:35:34,383 train 550 1.587303e-01 -239.310170
2019-12-04 21:35:48,492 train 600 1.589710e-01 -239.158229
2019-12-04 21:36:02,603 train 650 1.590568e-01 -240.011832
2019-12-04 21:36:16,717 train 700 1.591538e-01 -240.537967
2019-12-04 21:36:30,833 train 750 1.592495e-01 -240.579519
2019-12-04 21:36:44,947 train 800 1.592277e-01 -240.995186
2019-12-04 21:36:59,059 train 850 1.592437e-01 -240.921703
2019-12-04 21:37:10,288 training loss; R2: 1.592256e-01 -242.038878
2019-12-04 21:37:10,432 valid 000 2.886004e+00 -270.930435
2019-12-04 21:37:13,411 valid 050 2.954037e+00 -201.777093
2019-12-04 21:37:16,270 validation loss; R2: 2.941161e+00 -205.207419
2019-12-04 21:37:16,287 epoch 11 lr 1.000000e-03
2019-12-04 21:37:16,659 train 000 1.689860e-01 -264.426913
2019-12-04 21:37:30,779 train 050 1.558403e-01 -242.109823
2019-12-04 21:37:44,901 train 100 1.558519e-01 -250.451876
2019-12-04 21:37:59,017 train 150 1.576658e-01 -247.157432
2019-12-04 21:38:13,128 train 200 1.578261e-01 -242.939370
2019-12-04 21:38:27,238 train 250 1.578789e-01 -241.787060
2019-12-04 21:38:41,351 train 300 1.585660e-01 -241.915657
2019-12-04 21:38:55,457 train 350 1.577101e-01 -246.521425
2019-12-04 21:39:09,564 train 400 1.581344e-01 -244.558505
2019-12-04 21:39:23,672 train 450 1.584690e-01 -244.537853
2019-12-04 21:39:37,781 train 500 1.590249e-01 -242.636722
2019-12-04 21:39:51,895 train 550 1.584767e-01 -243.946600
2019-12-04 21:40:06,006 train 600 1.589130e-01 -243.971645
2019-12-04 21:40:20,119 train 650 1.590461e-01 -244.290662
2019-12-04 21:40:34,233 train 700 1.588558e-01 -244.773947
2019-12-04 21:40:48,350 train 750 1.586000e-01 -244.529891
2019-12-04 21:41:02,462 train 800 1.586356e-01 -244.059246
2019-12-04 21:41:16,566 train 850 1.584525e-01 -245.510323
2019-12-04 21:41:27,790 training loss; R2: 1.586491e-01 -245.167190
2019-12-04 21:41:27,935 valid 000 8.639723e-01 -497.072606
2019-12-04 21:41:30,913 valid 050 8.006673e-01 -954.917276
2019-12-04 21:41:33,771 validation loss; R2: 8.075223e-01 -945.036775
2019-12-04 21:41:33,789 epoch 12 lr 1.000000e-03
2019-12-04 21:41:34,161 train 000 1.222746e-01 -209.368507
2019-12-04 21:41:48,276 train 050 1.549781e-01 -234.444081
2019-12-04 21:42:02,381 train 100 1.598511e-01 -235.230229
2019-12-04 21:42:16,481 train 150 1.589719e-01 -237.679024
2019-12-04 21:42:30,581 train 200 1.584010e-01 -236.208154
2019-12-04 21:42:44,688 train 250 1.583110e-01 -237.001848
2019-12-04 21:42:58,794 train 300 1.582778e-01 -238.547426
2019-12-04 21:43:12,899 train 350 1.576415e-01 -240.220996
2019-12-04 21:43:27,006 train 400 1.580256e-01 -239.514388
2019-12-04 21:43:41,115 train 450 1.583118e-01 -240.071294
2019-12-04 21:43:55,221 train 500 1.588313e-01 -240.906200
2019-12-04 21:44:09,325 train 550 1.588834e-01 -241.225852
2019-12-04 21:44:23,436 train 600 1.588408e-01 -241.385302
2019-12-04 21:44:37,544 train 650 1.589383e-01 -243.778587
2019-12-04 21:44:51,656 train 700 1.587809e-01 -243.914600
2019-12-04 21:45:05,766 train 750 1.586371e-01 -244.271084
2019-12-04 21:45:19,874 train 800 1.586562e-01 -244.979682
2019-12-04 21:45:33,985 train 850 1.583025e-01 -244.407741
2019-12-04 21:45:45,222 training loss; R2: 1.582063e-01 -244.134118
2019-12-04 21:45:45,364 valid 000 2.078322e+00 -241.101566
2019-12-04 21:45:48,342 valid 050 2.110296e+00 -271.284456
2019-12-04 21:45:51,199 validation loss; R2: 2.112145e+00 -281.079440
2019-12-04 21:45:51,217 epoch 13 lr 1.000000e-03
2019-12-04 21:45:51,584 train 000 1.494322e-01 -266.618611
2019-12-04 21:46:05,678 train 050 1.527784e-01 -258.412804
2019-12-04 21:46:19,772 train 100 1.554909e-01 -250.585466
2019-12-04 21:46:33,870 train 150 1.554396e-01 -248.099723
2019-12-04 21:46:47,974 train 200 1.569951e-01 -251.225804
2019-12-04 21:47:02,075 train 250 1.558133e-01 -252.277294
2019-12-04 21:47:16,173 train 300 1.562937e-01 -254.216347
2019-12-04 21:47:30,276 train 350 1.567353e-01 -254.104268
2019-12-04 21:47:44,376 train 400 1.568071e-01 -253.910918
2019-12-04 21:47:58,472 train 450 1.569859e-01 -253.583586
2019-12-04 21:48:12,565 train 500 1.571605e-01 -251.925498
2019-12-04 21:48:26,655 train 550 1.571867e-01 -251.105740
2019-12-04 21:48:41,020 train 600 1.577319e-01 -249.743940
2019-12-04 21:48:55,397 train 650 1.576596e-01 -248.826324
2019-12-04 21:49:09,778 train 700 1.575098e-01 -249.018542
2019-12-04 21:49:24,162 train 750 1.576517e-01 -248.263280
2019-12-04 21:49:38,545 train 800 1.578815e-01 -247.988475
2019-12-04 21:49:52,925 train 850 1.577680e-01 -248.309076
2019-12-04 21:50:04,362 training loss; R2: 1.574195e-01 -249.310724
2019-12-04 21:50:04,509 valid 000 1.895317e-01 -181.882543
2019-12-04 21:50:07,489 valid 050 1.953707e-01 -135.901659
2019-12-04 21:50:10,346 validation loss; R2: 1.938083e-01 -137.820292
2019-12-04 21:50:10,363 epoch 14 lr 1.000000e-03
2019-12-04 21:50:10,734 train 000 1.440505e-01 -383.197407
2019-12-04 21:50:24,840 train 050 1.610367e-01 -251.477563
2019-12-04 21:50:38,933 train 100 1.609073e-01 -237.213734
2019-12-04 21:50:53,028 train 150 1.616905e-01 -244.512989
2019-12-04 21:51:07,121 train 200 1.578590e-01 -251.951157
2019-12-04 21:51:21,214 train 250 1.574706e-01 -252.630551
2019-12-04 21:51:35,312 train 300 1.572324e-01 -252.118978
2019-12-04 21:51:49,407 train 350 1.562766e-01 -253.018048
2019-12-04 21:52:03,511 train 400 1.566460e-01 -253.409880
2019-12-04 21:52:17,605 train 450 1.565894e-01 -255.268990
2019-12-04 21:52:31,707 train 500 1.568788e-01 -255.019838
2019-12-04 21:52:45,809 train 550 1.565789e-01 -254.327663
2019-12-04 21:52:59,905 train 600 1.564051e-01 -254.623027
2019-12-04 21:53:14,005 train 650 1.568584e-01 -255.220762
2019-12-04 21:53:28,109 train 700 1.568727e-01 -253.408806
2019-12-04 21:53:42,210 train 750 1.566198e-01 -254.648753
2019-12-04 21:53:56,562 train 800 1.566387e-01 -254.481887
2019-12-04 21:54:10,941 train 850 1.571773e-01 -253.658300
2019-12-04 21:54:22,375 training loss; R2: 1.571907e-01 -253.347708
2019-12-04 21:54:22,527 valid 000 1.775661e-01 -328.737532
2019-12-04 21:54:25,509 valid 050 2.039059e-01 -296.213980
2019-12-04 21:54:28,369 validation loss; R2: 2.025485e-01 -292.350909
2019-12-04 21:54:28,387 epoch 15 lr 1.000000e-03
2019-12-04 21:54:28,763 train 000 1.392078e-01 -258.171289
2019-12-04 21:54:43,144 train 050 1.518743e-01 -259.390608
2019-12-04 21:54:57,537 train 100 1.570500e-01 -255.351080
2019-12-04 21:55:11,931 train 150 1.582667e-01 -254.621908
2019-12-04 21:55:26,320 train 200 1.578951e-01 -251.757376
2019-12-04 21:55:40,706 train 250 1.578566e-01 -256.508281
2019-12-04 21:55:55,094 train 300 1.577838e-01 -254.494694
2019-12-04 21:56:09,487 train 350 1.582176e-01 -254.203728
2019-12-04 21:56:23,725 train 400 1.573013e-01 -254.820884
2019-12-04 21:56:37,841 train 450 1.570380e-01 -254.575559
2019-12-04 21:56:51,939 train 500 1.570136e-01 -254.672706
2019-12-04 21:57:06,041 train 550 1.571413e-01 -254.584925
2019-12-04 21:57:20,148 train 600 1.568395e-01 -253.167284
2019-12-04 21:57:34,248 train 650 1.571569e-01 -253.303978
2019-12-04 21:57:48,368 train 700 1.567340e-01 -252.017664
2019-12-04 21:58:02,474 train 750 1.566510e-01 -251.083399
2019-12-04 21:58:16,590 train 800 1.565412e-01 -251.229589
2019-12-04 21:58:30,703 train 850 1.564380e-01 -252.132804
2019-12-04 21:58:41,918 training loss; R2: 1.564392e-01 -251.989607
2019-12-04 21:58:42,063 valid 000 2.256242e-01 -235.199026
2019-12-04 21:58:45,041 valid 050 2.069820e-01 -343.610035
2019-12-04 21:58:47,900 validation loss; R2: 2.091858e-01 -360.309916
