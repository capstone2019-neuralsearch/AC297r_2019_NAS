2019-12-04 16:51:05,332 gpu device = 3
2019-12-04 16:51:05,332 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-165105', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 16:51:12,610 param size = 0.237246MB
2019-12-04 16:51:12,613 epoch 0 lr 1.000000e-03
2019-12-04 16:51:14,429 train 000 6.923522e-01 -0.800707
2019-12-04 16:51:27,226 train 050 5.559821e-01 -6.026417
2019-12-04 16:51:39,981 train 100 3.844892e-01 -58.312254
2019-12-04 16:51:52,761 train 150 3.130952e-01 -101.209600
2019-12-04 16:52:05,480 train 200 2.754254e-01 -128.038162
2019-12-04 16:52:18,210 train 250 2.554254e-01 -144.796149
2019-12-04 16:52:30,943 train 300 2.417476e-01 -157.095832
2019-12-04 16:52:43,682 train 350 2.315205e-01 -164.474541
2019-12-04 16:52:56,420 train 400 2.245884e-01 -173.275339
2019-12-04 16:53:09,169 train 450 2.186555e-01 -176.875488
2019-12-04 16:53:21,912 train 500 2.136648e-01 -181.539823
2019-12-04 16:53:34,652 train 550 2.095090e-01 -184.013780
2019-12-04 16:53:47,395 train 600 2.059931e-01 -186.694440
2019-12-04 16:54:00,135 train 650 2.037692e-01 -188.467092
2019-12-04 16:54:12,873 train 700 2.012151e-01 -189.381640
2019-12-04 16:54:25,613 train 750 1.986174e-01 -190.291506
2019-12-04 16:54:38,359 train 800 1.962027e-01 -193.156269
2019-12-04 16:54:51,102 train 850 1.946547e-01 -195.025136
2019-12-04 16:55:02,059 training loss; R2: 1.934430e-01 -196.302277
2019-12-04 16:55:02,187 valid 000 1.550435e-01 -286.749966
2019-12-04 16:55:04,845 valid 050 1.803431e-01 -224.717641
2019-12-04 16:55:07,530 validation loss; R2: 1.792435e-01 -229.838680
2019-12-04 16:55:07,550 epoch 1 lr 1.000000e-03
2019-12-04 16:55:07,938 train 000 2.197724e-01 -330.383314
2019-12-04 16:55:20,687 train 050 1.638897e-01 -209.216131
2019-12-04 16:55:33,435 train 100 1.640453e-01 -216.127552
2019-12-04 16:55:46,180 train 150 1.647804e-01 -218.510097
2019-12-04 16:55:58,921 train 200 1.644011e-01 -222.657153
2019-12-04 16:56:11,667 train 250 1.644461e-01 -221.050831
2019-12-04 16:56:24,416 train 300 1.637592e-01 -224.874709
2019-12-04 16:56:37,165 train 350 1.639994e-01 -223.917496
2019-12-04 16:56:49,917 train 400 1.650795e-01 -223.129774
2019-12-04 16:57:02,664 train 450 1.657296e-01 -221.697309
2019-12-04 16:57:15,416 train 500 1.665117e-01 -220.354893
2019-12-04 16:57:28,166 train 550 1.667212e-01 -219.659368
2019-12-04 16:57:40,916 train 600 1.666859e-01 -219.270208
2019-12-04 16:57:53,665 train 650 1.667301e-01 -219.247900
2019-12-04 16:58:06,410 train 700 1.669012e-01 -220.032118
2019-12-04 16:58:19,151 train 750 1.667917e-01 -220.111193
2019-12-04 16:58:31,901 train 800 1.665872e-01 -220.202741
2019-12-04 16:58:44,642 train 850 1.666268e-01 -220.888294
2019-12-04 16:58:54,782 training loss; R2: 1.664262e-01 -220.557231
2019-12-04 16:58:54,905 valid 000 1.541803e-01 -142.440608
2019-12-04 16:58:57,563 valid 050 1.760579e-01 -205.593012
2019-12-04 16:59:00,114 validation loss; R2: 1.778476e-01 -217.205806
2019-12-04 16:59:00,131 epoch 2 lr 1.000000e-03
2019-12-04 16:59:00,456 train 000 1.420344e-01 -220.466036
2019-12-04 16:59:13,185 train 050 1.655379e-01 -241.854252
2019-12-04 16:59:25,923 train 100 1.660792e-01 -234.143043
2019-12-04 16:59:38,657 train 150 1.657689e-01 -232.333962
2019-12-04 16:59:51,394 train 200 1.644583e-01 -233.354040
2019-12-04 17:00:04,133 train 250 1.649944e-01 -232.375114
2019-12-04 17:00:16,867 train 300 1.657682e-01 -231.727141
2019-12-04 17:00:29,603 train 350 1.653127e-01 -229.170632
2019-12-04 17:00:42,333 train 400 1.654673e-01 -228.264646
2019-12-04 17:00:55,066 train 450 1.655320e-01 -228.223249
2019-12-04 17:01:07,795 train 500 1.658452e-01 -229.715104
2019-12-04 17:01:20,523 train 550 1.656823e-01 -229.624197
2019-12-04 17:01:33,248 train 600 1.649414e-01 -229.426077
2019-12-04 17:01:45,994 train 650 1.648047e-01 -228.177866
2019-12-04 17:01:58,738 train 700 1.647193e-01 -228.586566
2019-12-04 17:02:11,491 train 750 1.647910e-01 -228.801547
2019-12-04 17:02:24,254 train 800 1.648549e-01 -228.665703
2019-12-04 17:02:37,005 train 850 1.650107e-01 -228.254581
2019-12-04 17:02:47,141 training loss; R2: 1.648993e-01 -228.514564
2019-12-04 17:02:47,262 valid 000 1.935046e-01 -195.572684
2019-12-04 17:02:49,921 valid 050 1.755114e-01 -205.905760
2019-12-04 17:02:52,471 validation loss; R2: 1.792454e-01 -202.708224
2019-12-04 17:02:52,488 epoch 3 lr 1.000000e-03
2019-12-04 17:02:52,816 train 000 1.459376e-01 -254.425735
2019-12-04 17:03:05,559 train 050 1.666182e-01 -237.491718
2019-12-04 17:03:18,301 train 100 1.653755e-01 -229.378744
2019-12-04 17:03:31,039 train 150 1.628034e-01 -230.465522
2019-12-04 17:03:43,786 train 200 1.633605e-01 -231.801688
2019-12-04 17:03:56,529 train 250 1.636432e-01 -230.356143
2019-12-04 17:04:09,269 train 300 1.626676e-01 -231.519893
2019-12-04 17:04:22,010 train 350 1.623066e-01 -230.695255
2019-12-04 17:04:34,748 train 400 1.618168e-01 -233.288019
2019-12-04 17:04:47,489 train 450 1.618656e-01 -233.154891
2019-12-04 17:05:00,232 train 500 1.625997e-01 -231.661055
2019-12-04 17:05:12,977 train 550 1.631602e-01 -230.313361
2019-12-04 17:05:25,722 train 600 1.633618e-01 -228.542025
2019-12-04 17:05:38,467 train 650 1.636211e-01 -228.471021
2019-12-04 17:05:51,214 train 700 1.639403e-01 -228.095567
2019-12-04 17:06:03,958 train 750 1.638552e-01 -228.548334
2019-12-04 17:06:16,701 train 800 1.638585e-01 -228.174756
2019-12-04 17:06:29,444 train 850 1.640666e-01 -227.418136
2019-12-04 17:06:39,582 training loss; R2: 1.641773e-01 -227.392405
2019-12-04 17:06:39,708 valid 000 2.865185e-01 -311.197494
2019-12-04 17:06:42,366 valid 050 2.868364e-01 -324.171058
2019-12-04 17:06:44,917 validation loss; R2: 2.878143e-01 -321.400199
2019-12-04 17:06:44,941 epoch 4 lr 1.000000e-03
2019-12-04 17:06:45,269 train 000 1.519632e-01 -360.534025
2019-12-04 17:06:58,013 train 050 1.541717e-01 -243.989216
2019-12-04 17:07:10,756 train 100 1.587033e-01 -242.963011
2019-12-04 17:07:23,502 train 150 1.607024e-01 -233.623837
2019-12-04 17:07:36,249 train 200 1.613072e-01 -235.256929
2019-12-04 17:07:49,004 train 250 1.616614e-01 -233.122143
2019-12-04 17:08:01,756 train 300 1.606767e-01 -233.570937
2019-12-04 17:08:14,538 train 350 1.597063e-01 -234.131525
2019-12-04 17:08:27,306 train 400 1.603391e-01 -234.334317
2019-12-04 17:08:40,078 train 450 1.611100e-01 -234.041182
2019-12-04 17:08:52,846 train 500 1.615101e-01 -231.921515
2019-12-04 17:09:05,608 train 550 1.621690e-01 -231.289686
2019-12-04 17:09:18,367 train 600 1.627508e-01 -229.752479
2019-12-04 17:09:31,133 train 650 1.632284e-01 -229.083591
2019-12-04 17:09:43,894 train 700 1.632958e-01 -228.641860
2019-12-04 17:09:56,641 train 750 1.633715e-01 -229.230962
2019-12-04 17:10:09,389 train 800 1.632276e-01 -228.868423
2019-12-04 17:10:22,147 train 850 1.633619e-01 -229.195731
2019-12-04 17:10:32,291 training loss; R2: 1.633901e-01 -229.063996
2019-12-04 17:10:32,420 valid 000 1.828636e-01 -191.667597
2019-12-04 17:10:35,078 valid 050 1.797673e-01 -233.065626
2019-12-04 17:10:37,628 validation loss; R2: 1.801971e-01 -228.121570
2019-12-04 17:10:37,645 epoch 5 lr 1.000000e-03
2019-12-04 17:10:37,971 train 000 1.645657e-01 -161.116827
2019-12-04 17:10:50,716 train 050 1.579147e-01 -222.963719
2019-12-04 17:11:03,460 train 100 1.634418e-01 -228.422740
2019-12-04 17:11:16,213 train 150 1.618476e-01 -231.448007
2019-12-04 17:11:28,947 train 200 1.644708e-01 -228.201670
2019-12-04 17:11:41,682 train 250 1.634781e-01 -227.320177
2019-12-04 17:11:54,416 train 300 1.639637e-01 -225.511355
2019-12-04 17:12:07,151 train 350 1.635065e-01 -224.583212
2019-12-04 17:12:19,883 train 400 1.627639e-01 -223.867916
2019-12-04 17:12:32,619 train 450 1.626053e-01 -228.348702
2019-12-04 17:12:45,356 train 500 1.629547e-01 -225.656592
2019-12-04 17:12:58,087 train 550 1.635867e-01 -226.237448
2019-12-04 17:13:10,813 train 600 1.630249e-01 -226.449577
2019-12-04 17:13:23,539 train 650 1.627968e-01 -228.706578
2019-12-04 17:13:36,262 train 700 1.624891e-01 -228.660556
2019-12-04 17:13:48,988 train 750 1.625411e-01 -229.661723
2019-12-04 17:14:01,708 train 800 1.626944e-01 -229.692719
2019-12-04 17:14:14,433 train 850 1.627302e-01 -229.013855
2019-12-04 17:14:24,554 training loss; R2: 1.627609e-01 -229.436353
2019-12-04 17:14:24,679 valid 000 1.262903e-01 -257.442141
2019-12-04 17:14:27,337 valid 050 1.729760e-01 -234.523536
2019-12-04 17:14:29,887 validation loss; R2: 1.779457e-01 -245.512160
2019-12-04 17:14:29,908 epoch 6 lr 1.000000e-03
2019-12-04 17:14:30,234 train 000 1.232924e-01 -156.526691
2019-12-04 17:14:42,958 train 050 1.649228e-01 -224.573197
2019-12-04 17:14:55,681 train 100 1.587776e-01 -226.126141
2019-12-04 17:15:08,411 train 150 1.615992e-01 -229.722284
2019-12-04 17:15:21,134 train 200 1.607865e-01 -228.593242
2019-12-04 17:15:33,854 train 250 1.616721e-01 -228.241856
2019-12-04 17:15:46,576 train 300 1.603403e-01 -228.623371
2019-12-04 17:15:59,295 train 350 1.602527e-01 -229.033221
2019-12-04 17:16:12,010 train 400 1.599630e-01 -232.763667
2019-12-04 17:16:24,727 train 450 1.598009e-01 -232.729153
2019-12-04 17:16:37,441 train 500 1.598412e-01 -234.581535
2019-12-04 17:16:50,155 train 550 1.603321e-01 -234.727536
2019-12-04 17:17:02,877 train 600 1.609084e-01 -233.277163
2019-12-04 17:17:15,600 train 650 1.607387e-01 -233.686565
2019-12-04 17:17:28,323 train 700 1.613234e-01 -233.847806
2019-12-04 17:17:41,044 train 750 1.619136e-01 -232.352523
2019-12-04 17:17:53,759 train 800 1.619441e-01 -232.355553
2019-12-04 17:18:06,476 train 850 1.622882e-01 -232.898915
2019-12-04 17:18:16,588 training loss; R2: 1.622288e-01 -234.056390
2019-12-04 17:18:16,710 valid 000 1.579482e+00 -810.003021
2019-12-04 17:18:19,367 valid 050 1.531313e+00 -735.457916
2019-12-04 17:18:21,917 validation loss; R2: 1.520137e+00 -738.236588
2019-12-04 17:18:21,934 epoch 7 lr 1.000000e-03
2019-12-04 17:18:22,260 train 000 1.692906e-01 -402.738874
2019-12-04 17:18:34,981 train 050 1.587273e-01 -221.319355
2019-12-04 17:18:47,697 train 100 1.596095e-01 -231.018467
2019-12-04 17:19:00,410 train 150 1.575739e-01 -233.605011
2019-12-04 17:19:13,128 train 200 1.596088e-01 -241.068943
2019-12-04 17:19:25,840 train 250 1.602499e-01 -242.027839
2019-12-04 17:19:38,552 train 300 1.602771e-01 -244.411053
2019-12-04 17:19:51,262 train 350 1.600606e-01 -244.117976
2019-12-04 17:20:03,982 train 400 1.600983e-01 -242.974511
2019-12-04 17:20:16,693 train 450 1.597824e-01 -241.140557
2019-12-04 17:20:29,412 train 500 1.600208e-01 -239.858479
2019-12-04 17:20:42,129 train 550 1.604336e-01 -239.790657
2019-12-04 17:20:54,845 train 600 1.612141e-01 -239.635508
2019-12-04 17:21:07,560 train 650 1.614455e-01 -240.011420
2019-12-04 17:21:20,278 train 700 1.612522e-01 -238.458077
2019-12-04 17:21:32,999 train 750 1.610968e-01 -237.838663
2019-12-04 17:21:45,731 train 800 1.617140e-01 -237.727423
2019-12-04 17:21:58,458 train 850 1.616457e-01 -237.373958
2019-12-04 17:22:08,583 training loss; R2: 1.618744e-01 -236.164629
2019-12-04 17:22:08,707 valid 000 9.647061e+00 -5212.172719
2019-12-04 17:22:11,365 valid 050 9.601070e+00 -6418.634274
2019-12-04 17:22:13,915 validation loss; R2: 9.642650e+00 -6488.131166
2019-12-04 17:22:13,931 epoch 8 lr 1.000000e-03
2019-12-04 17:22:14,258 train 000 1.156086e-01 -227.782790
2019-12-04 17:22:26,965 train 050 1.610238e-01 -235.412652
2019-12-04 17:22:39,672 train 100 1.615554e-01 -240.578477
2019-12-04 17:22:52,378 train 150 1.628154e-01 -235.125367
2019-12-04 17:23:05,081 train 200 1.630179e-01 -237.595365
2019-12-04 17:23:17,789 train 250 1.634083e-01 -237.676583
2019-12-04 17:23:30,504 train 300 1.627487e-01 -235.326042
2019-12-04 17:23:43,212 train 350 1.621599e-01 -238.117559
2019-12-04 17:23:55,921 train 400 1.618869e-01 -236.562748
2019-12-04 17:24:08,632 train 450 1.623278e-01 -235.009586
2019-12-04 17:24:21,342 train 500 1.615855e-01 -235.442032
2019-12-04 17:24:34,050 train 550 1.614813e-01 -235.828755
2019-12-04 17:24:46,760 train 600 1.614782e-01 -235.428032
2019-12-04 17:24:59,466 train 650 1.612713e-01 -235.885125
2019-12-04 17:25:12,182 train 700 1.613085e-01 -235.267677
2019-12-04 17:25:24,888 train 750 1.611395e-01 -235.286085
2019-12-04 17:25:37,592 train 800 1.614635e-01 -234.551579
2019-12-04 17:25:50,301 train 850 1.613365e-01 -234.135293
2019-12-04 17:26:00,412 training loss; R2: 1.612704e-01 -234.870338
2019-12-04 17:26:00,535 valid 000 2.944822e+00 -72304.342303
2019-12-04 17:26:03,193 valid 050 2.656981e+00 -90259.401584
2019-12-04 17:26:05,744 validation loss; R2: 2.617759e+00 -88301.709590
2019-12-04 17:26:05,761 epoch 9 lr 1.000000e-03
2019-12-04 17:26:06,087 train 000 1.903145e-01 -287.193609
2019-12-04 17:26:18,782 train 050 1.582544e-01 -222.715295
2019-12-04 17:26:31,478 train 100 1.574448e-01 -248.781385
2019-12-04 17:26:44,172 train 150 1.578067e-01 -242.972762
2019-12-04 17:26:56,866 train 200 1.596959e-01 -241.875450
2019-12-04 17:27:09,559 train 250 1.600997e-01 -240.403103
2019-12-04 17:27:22,250 train 300 1.610750e-01 -238.277775
2019-12-04 17:27:34,946 train 350 1.613025e-01 -235.890838
2019-12-04 17:27:47,640 train 400 1.613781e-01 -235.034469
2019-12-04 17:28:00,337 train 450 1.606745e-01 -235.356433
2019-12-04 17:28:13,032 train 500 1.615369e-01 -235.007684
2019-12-04 17:28:25,722 train 550 1.614355e-01 -235.279699
2019-12-04 17:28:38,409 train 600 1.605751e-01 -235.655873
2019-12-04 17:28:51,103 train 650 1.613117e-01 -236.958764
2019-12-04 17:29:03,787 train 700 1.609907e-01 -237.324591
2019-12-04 17:29:16,472 train 750 1.605189e-01 -236.436372
2019-12-04 17:29:29,157 train 800 1.607291e-01 -236.599114
2019-12-04 17:29:41,849 train 850 1.609776e-01 -236.794719
2019-12-04 17:29:51,939 training loss; R2: 1.610964e-01 -237.185249
2019-12-04 17:29:52,061 valid 000 6.184436e+01 -3765050.775205
2019-12-04 17:29:54,717 valid 050 6.556360e+01 -2302950.244890
2019-12-04 17:29:57,265 validation loss; R2: 6.531191e+01 -2428760.477932
2019-12-04 17:29:57,282 epoch 10 lr 1.000000e-03
2019-12-04 17:29:57,607 train 000 1.223360e-01 -174.967441
2019-12-04 17:30:10,307 train 050 1.582594e-01 -230.249202
2019-12-04 17:30:22,999 train 100 1.577955e-01 -236.970575
2019-12-04 17:30:35,691 train 150 1.595035e-01 -233.118265
2019-12-04 17:30:48,376 train 200 1.611026e-01 -237.755673
2019-12-04 17:31:01,070 train 250 1.603494e-01 -237.410604
2019-12-04 17:31:13,750 train 300 1.602349e-01 -239.014808
2019-12-04 17:31:26,439 train 350 1.610144e-01 -238.450270
2019-12-04 17:31:39,128 train 400 1.596610e-01 -240.099356
2019-12-04 17:31:51,817 train 450 1.608450e-01 -241.322507
2019-12-04 17:32:04,511 train 500 1.603401e-01 -240.131763
2019-12-04 17:32:17,202 train 550 1.605591e-01 -239.201420
2019-12-04 17:32:29,896 train 600 1.602237e-01 -239.619824
2019-12-04 17:32:42,593 train 650 1.600641e-01 -238.498423
2019-12-04 17:32:55,300 train 700 1.601689e-01 -238.512514
2019-12-04 17:33:07,997 train 750 1.605120e-01 -237.602646
2019-12-04 17:33:20,696 train 800 1.604540e-01 -237.054238
2019-12-04 17:33:33,404 train 850 1.604260e-01 -238.230685
2019-12-04 17:33:43,529 training loss; R2: 1.605625e-01 -237.815313
2019-12-04 17:33:43,653 valid 000 2.352887e+02 -658642.237054
2019-12-04 17:33:46,311 valid 050 2.356455e+02 -1165973.952134
2019-12-04 17:33:48,861 validation loss; R2: 2.355644e+02 -1224393.040924
2019-12-04 17:33:48,879 epoch 11 lr 1.000000e-03
2019-12-04 17:33:49,205 train 000 1.483185e-01 -262.203631
2019-12-04 17:34:01,928 train 050 1.629688e-01 -236.714615
2019-12-04 17:34:14,638 train 100 1.623585e-01 -238.094690
2019-12-04 17:34:27,373 train 150 1.612129e-01 -241.843369
2019-12-04 17:34:40,115 train 200 1.615178e-01 -239.621360
2019-12-04 17:34:52,844 train 250 1.620530e-01 -240.189443
2019-12-04 17:35:05,580 train 300 1.611877e-01 -239.986196
2019-12-04 17:35:18,297 train 350 1.618468e-01 -239.202594
2019-12-04 17:35:31,031 train 400 1.613798e-01 -241.208028
2019-12-04 17:35:43,775 train 450 1.607268e-01 -239.860887
2019-12-04 17:35:56,525 train 500 1.605588e-01 -240.694410
2019-12-04 17:36:09,275 train 550 1.603726e-01 -240.632316
2019-12-04 17:36:22,027 train 600 1.603337e-01 -240.614773
2019-12-04 17:36:34,776 train 650 1.606449e-01 -239.810003
2019-12-04 17:36:47,528 train 700 1.603050e-01 -240.558140
2019-12-04 17:37:00,261 train 750 1.602834e-01 -240.372513
2019-12-04 17:37:13,004 train 800 1.607102e-01 -240.404802
2019-12-04 17:37:25,740 train 850 1.600630e-01 -240.970620
2019-12-04 17:37:35,872 training loss; R2: 1.600385e-01 -241.005678
2019-12-04 17:37:35,995 valid 000 6.756985e+01 -2573529.797339
2019-12-04 17:37:38,652 valid 050 6.522110e+01 -3753156.025200
2019-12-04 17:37:41,201 validation loss; R2: 6.536015e+01 -4067788.650512
2019-12-04 17:37:41,218 epoch 12 lr 1.000000e-03
2019-12-04 17:37:41,545 train 000 1.811867e-01 -185.290752
2019-12-04 17:37:54,310 train 050 1.577680e-01 -234.272982
2019-12-04 17:38:07,083 train 100 1.595867e-01 -232.987288
2019-12-04 17:38:19,853 train 150 1.570573e-01 -238.622580
2019-12-04 17:38:32,623 train 200 1.582113e-01 -239.163671
2019-12-04 17:38:45,367 train 250 1.596204e-01 -237.562445
2019-12-04 17:38:58,108 train 300 1.593330e-01 -238.006104
2019-12-04 17:39:10,849 train 350 1.593281e-01 -241.868970
2019-12-04 17:39:23,588 train 400 1.583875e-01 -242.893020
2019-12-04 17:39:36,339 train 450 1.583939e-01 -243.550832
2019-12-04 17:39:49,119 train 500 1.581442e-01 -243.976274
2019-12-04 17:40:01,943 train 550 1.587884e-01 -245.465897
2019-12-04 17:40:14,726 train 600 1.590961e-01 -245.227779
2019-12-04 17:40:27,482 train 650 1.593979e-01 -243.791662
2019-12-04 17:40:40,236 train 700 1.594489e-01 -244.073531
2019-12-04 17:40:52,991 train 750 1.596869e-01 -243.907607
2019-12-04 17:41:05,753 train 800 1.597311e-01 -243.782520
2019-12-04 17:41:18,513 train 850 1.596741e-01 -244.639420
2019-12-04 17:41:28,668 training loss; R2: 1.594758e-01 -245.060773
2019-12-04 17:41:28,789 valid 000 2.020632e+02 -21288956.529783
2019-12-04 17:41:31,447 valid 050 1.923281e+02 -13658615.527301
2019-12-04 17:41:33,996 validation loss; R2: 1.935600e+02 -14097043.181843
2019-12-04 17:41:34,021 epoch 13 lr 1.000000e-03
2019-12-04 17:41:34,350 train 000 1.612666e-01 -374.452037
2019-12-04 17:41:47,121 train 050 1.640740e-01 -232.357848
2019-12-04 17:41:59,904 train 100 1.622767e-01 -240.355327
2019-12-04 17:42:12,667 train 150 1.597631e-01 -235.256038
2019-12-04 17:42:25,420 train 200 1.586440e-01 -238.432932
2019-12-04 17:42:38,184 train 250 1.587823e-01 -237.895281
2019-12-04 17:42:50,949 train 300 1.585248e-01 -237.963750
2019-12-04 17:43:03,708 train 350 1.591057e-01 -237.819310
2019-12-04 17:43:16,457 train 400 1.593657e-01 -239.318056
2019-12-04 17:43:29,197 train 450 1.602414e-01 -239.912932
2019-12-04 17:43:41,941 train 500 1.600718e-01 -243.179070
2019-12-04 17:43:54,690 train 550 1.597311e-01 -241.955100
2019-12-04 17:44:07,432 train 600 1.594481e-01 -240.907583
2019-12-04 17:44:20,285 train 650 1.595633e-01 -241.125962
2019-12-04 17:44:33,076 train 700 1.594526e-01 -241.793362
2019-12-04 17:44:45,864 train 750 1.594462e-01 -241.941290
2019-12-04 17:44:58,604 train 800 1.592363e-01 -242.528263
2019-12-04 17:45:11,352 train 850 1.587714e-01 -242.668531
2019-12-04 17:45:21,486 training loss; R2: 1.590086e-01 -243.125896
2019-12-04 17:45:21,608 valid 000 6.341396e+02 -13704734.822722
2019-12-04 17:45:24,264 valid 050 6.454078e+02 -20122840.217637
2019-12-04 17:45:26,813 validation loss; R2: 6.453567e+02 -21012486.677049
2019-12-04 17:45:26,829 epoch 14 lr 1.000000e-03
2019-12-04 17:45:27,153 train 000 1.950526e-01 -178.792216
2019-12-04 17:45:39,905 train 050 1.627367e-01 -249.543981
2019-12-04 17:45:52,654 train 100 1.606429e-01 -248.392379
2019-12-04 17:46:05,381 train 150 1.596277e-01 -248.398294
2019-12-04 17:46:18,096 train 200 1.597632e-01 -244.809090
2019-12-04 17:46:30,843 train 250 1.610678e-01 -243.335576
2019-12-04 17:46:43,594 train 300 1.606949e-01 -241.310993
2019-12-04 17:46:56,326 train 350 1.611243e-01 -242.039547
2019-12-04 17:47:09,025 train 400 1.612480e-01 -243.313645
2019-12-04 17:47:21,720 train 450 1.617012e-01 -241.542279
2019-12-04 17:47:34,461 train 500 1.613585e-01 -240.641614
2019-12-04 17:47:47,203 train 550 1.612390e-01 -243.037461
2019-12-04 17:47:59,947 train 600 1.609475e-01 -241.562821
2019-12-04 17:48:12,685 train 650 1.608975e-01 -241.142211
2019-12-04 17:48:25,428 train 700 1.607739e-01 -242.015660
2019-12-04 17:48:38,170 train 750 1.602487e-01 -241.579518
2019-12-04 17:48:50,912 train 800 1.598042e-01 -242.478250
2019-12-04 17:49:03,667 train 850 1.598608e-01 -241.893966
2019-12-04 17:49:13,808 training loss; R2: 1.597729e-01 -241.996812
2019-12-04 17:49:13,936 valid 000 3.769052e+02 -1818666.543363
2019-12-04 17:49:16,595 valid 050 3.743061e+02 -3492950.136680
2019-12-04 17:49:19,146 validation loss; R2: 3.740364e+02 -3342731.203735
2019-12-04 17:49:19,171 epoch 15 lr 1.000000e-03
2019-12-04 17:49:19,501 train 000 1.405789e-01 -220.085054
2019-12-04 17:49:32,244 train 050 1.538936e-01 -238.965173
2019-12-04 17:49:44,992 train 100 1.542891e-01 -247.259056
2019-12-04 17:49:57,731 train 150 1.562388e-01 -241.276388
2019-12-04 17:50:10,472 train 200 1.547224e-01 -237.311257
2019-12-04 17:50:23,203 train 250 1.549315e-01 -240.290194
2019-12-04 17:50:35,932 train 300 1.556018e-01 -242.005245
2019-12-04 17:50:48,653 train 350 1.565816e-01 -244.166622
2019-12-04 17:51:01,336 train 400 1.569833e-01 -244.414430
2019-12-04 17:51:14,009 train 450 1.573139e-01 -244.800816
2019-12-04 17:51:26,685 train 500 1.583371e-01 -242.068183
2019-12-04 17:51:39,358 train 550 1.596987e-01 -240.254206
2019-12-04 17:51:52,046 train 600 1.597022e-01 -240.248327
2019-12-04 17:52:04,771 train 650 1.598495e-01 -239.555921
2019-12-04 17:52:17,498 train 700 1.597402e-01 -240.466524
2019-12-04 17:52:30,224 train 750 1.600203e-01 -240.115262
2019-12-04 17:52:42,939 train 800 1.595216e-01 -239.137934
2019-12-04 17:52:55,664 train 850 1.594653e-01 -239.467489
2019-12-04 17:53:05,760 training loss; R2: 1.597125e-01 -239.336291
2019-12-04 17:53:05,885 valid 000 2.817231e+01 -674165.784984
2019-12-04 17:53:08,542 valid 050 2.917571e+01 -640483.440618
2019-12-04 17:53:11,090 validation loss; R2: 2.913914e+01 -607003.803739
