2019-12-04 16:02:37,593 gpu device = 3
2019-12-04 16:02:37,593 args = Namespace(arch='DATASET', auxiliary=False, auxiliary_weight=0.4, batch_size=40, cutout=False, cutout_length=16, data='../data', dataset='chest-xray', drop_path_prob=0.2, epochs=16, fc1_size=1024, fc2_size=1024, folder_name='chest-xray', gpu=3, grad_clip=5, gz_dtree=False, init_channels=16, layers=8, learning_rate=0.001, model_path='saved_models', momentum=0.9, optimizer='Adam', primitives='Default', random=True, report_freq=50, save='random_eval-chest-xray-EXP-20191204-160237', seed=0, train_portion=0.9, use_xarray=True, weight_decay=1e-06)
2019-12-04 16:02:45,057 param size = 0.180286MB
2019-12-04 16:02:45,060 epoch 0 lr 1.000000e-03
2019-12-04 16:02:46,770 train 000 7.727542e-01 -4.005899
2019-12-04 16:02:56,670 train 050 3.663416e-01 -82.832635
2019-12-04 16:03:06,549 train 100 2.874468e-01 -151.195538
2019-12-04 16:03:16,416 train 150 2.552857e-01 -172.182483
2019-12-04 16:03:26,287 train 200 2.349732e-01 -181.994617
2019-12-04 16:03:36,171 train 250 2.219891e-01 -190.761929
2019-12-04 16:03:46,063 train 300 2.125602e-01 -199.596241
2019-12-04 16:03:55,960 train 350 2.065231e-01 -202.552503
2019-12-04 16:04:05,855 train 400 2.018612e-01 -204.242997
2019-12-04 16:04:15,736 train 450 1.991725e-01 -204.489463
2019-12-04 16:04:25,619 train 500 1.961105e-01 -207.727336
2019-12-04 16:04:35,501 train 550 1.931837e-01 -209.236992
2019-12-04 16:04:45,385 train 600 1.913879e-01 -211.436672
2019-12-04 16:04:55,264 train 650 1.892218e-01 -210.656164
2019-12-04 16:05:05,143 train 700 1.877688e-01 -211.616494
2019-12-04 16:05:15,019 train 750 1.863665e-01 -213.161235
2019-12-04 16:05:24,902 train 800 1.853079e-01 -214.267197
2019-12-04 16:05:34,782 train 850 1.841812e-01 -214.929552
2019-12-04 16:05:43,310 training loss; R2: 1.832443e-01 -215.554978
2019-12-04 16:05:43,431 valid 000 1.970327e-01 -373.805076
2019-12-04 16:05:45,578 valid 050 1.770613e-01 -251.892098
2019-12-04 16:05:47,773 validation loss; R2: 1.822770e-01 -252.723539
2019-12-04 16:05:47,785 epoch 1 lr 1.000000e-03
2019-12-04 16:05:48,079 train 000 1.441972e-01 -386.276937
2019-12-04 16:05:57,976 train 050 1.662980e-01 -236.244671
2019-12-04 16:06:07,863 train 100 1.639972e-01 -238.873292
2019-12-04 16:06:17,758 train 150 1.662431e-01 -232.511353
2019-12-04 16:06:27,649 train 200 1.674082e-01 -232.534560
2019-12-04 16:06:37,548 train 250 1.679000e-01 -230.193597
2019-12-04 16:06:47,442 train 300 1.671522e-01 -229.756837
2019-12-04 16:06:57,339 train 350 1.662800e-01 -228.648730
2019-12-04 16:07:07,232 train 400 1.669091e-01 -228.402119
2019-12-04 16:07:17,124 train 450 1.654926e-01 -230.146642
2019-12-04 16:07:27,018 train 500 1.644479e-01 -232.197329
2019-12-04 16:07:36,925 train 550 1.646591e-01 -231.811562
2019-12-04 16:07:46,838 train 600 1.645701e-01 -231.689618
2019-12-04 16:07:56,740 train 650 1.648271e-01 -231.768685
2019-12-04 16:08:06,633 train 700 1.650226e-01 -232.472182
2019-12-04 16:08:16,527 train 750 1.650199e-01 -232.896653
2019-12-04 16:08:26,422 train 800 1.653525e-01 -233.371086
2019-12-04 16:08:36,323 train 850 1.655197e-01 -233.949401
2019-12-04 16:08:44,190 training loss; R2: 1.655156e-01 -232.964036
2019-12-04 16:08:44,300 valid 000 1.959195e-01 -286.670316
2019-12-04 16:08:46,448 valid 050 1.861998e-01 -244.142474
2019-12-04 16:08:48,511 validation loss; R2: 1.825723e-01 -227.876339
2019-12-04 16:08:48,523 epoch 2 lr 1.000000e-03
2019-12-04 16:08:48,788 train 000 1.766385e-01 -208.394912
2019-12-04 16:08:58,685 train 050 1.621294e-01 -243.011785
2019-12-04 16:09:08,579 train 100 1.618478e-01 -222.742872
2019-12-04 16:09:18,476 train 150 1.616351e-01 -226.016154
2019-12-04 16:09:28,370 train 200 1.617678e-01 -226.817695
2019-12-04 16:09:38,421 train 250 1.640601e-01 -225.166504
2019-12-04 16:09:48,532 train 300 1.654825e-01 -224.969763
2019-12-04 16:09:58,636 train 350 1.659612e-01 -224.045847
2019-12-04 16:10:08,747 train 400 1.658926e-01 -225.471447
2019-12-04 16:10:18,835 train 450 1.652837e-01 -225.430017
2019-12-04 16:10:28,923 train 500 1.652191e-01 -227.005698
2019-12-04 16:10:38,863 train 550 1.650322e-01 -227.480969
2019-12-04 16:10:48,760 train 600 1.649217e-01 -226.395839
2019-12-04 16:10:58,649 train 650 1.646655e-01 -226.992687
2019-12-04 16:11:08,549 train 700 1.640999e-01 -226.865103
2019-12-04 16:11:18,444 train 750 1.643757e-01 -226.889814
2019-12-04 16:11:28,349 train 800 1.644291e-01 -228.017961
2019-12-04 16:11:38,240 train 850 1.645971e-01 -228.106445
2019-12-04 16:11:46,109 training loss; R2: 1.644219e-01 -227.048853
2019-12-04 16:11:46,219 valid 000 2.369371e-01 -137.371630
2019-12-04 16:11:48,377 valid 050 1.797665e-01 -255.830441
2019-12-04 16:11:50,443 validation loss; R2: 1.853080e-01 -258.652098
2019-12-04 16:11:50,455 epoch 3 lr 1.000000e-03
2019-12-04 16:11:50,721 train 000 1.249674e-01 -217.625044
2019-12-04 16:12:00,621 train 050 1.697491e-01 -222.266766
2019-12-04 16:12:10,525 train 100 1.668475e-01 -229.307400
2019-12-04 16:12:20,433 train 150 1.655769e-01 -240.376418
2019-12-04 16:12:30,386 train 200 1.651322e-01 -240.628499
2019-12-04 16:12:40,496 train 250 1.660434e-01 -239.488297
2019-12-04 16:12:50,593 train 300 1.648598e-01 -240.587092
2019-12-04 16:13:00,696 train 350 1.640189e-01 -241.948540
2019-12-04 16:13:10,633 train 400 1.636652e-01 -240.697544
2019-12-04 16:13:20,527 train 450 1.636377e-01 -237.078211
2019-12-04 16:13:30,408 train 500 1.634177e-01 -236.786115
2019-12-04 16:13:40,294 train 550 1.631534e-01 -236.163073
2019-12-04 16:13:50,178 train 600 1.633935e-01 -234.949055
2019-12-04 16:14:00,066 train 650 1.636537e-01 -235.551357
2019-12-04 16:14:09,951 train 700 1.637309e-01 -234.892401
2019-12-04 16:14:19,849 train 750 1.636188e-01 -234.834589
2019-12-04 16:14:29,746 train 800 1.635126e-01 -235.153802
2019-12-04 16:14:39,633 train 850 1.637837e-01 -234.829770
2019-12-04 16:14:47,493 training loss; R2: 1.635540e-01 -234.448457
2019-12-04 16:14:47,605 valid 000 2.005716e-01 -308.245362
2019-12-04 16:14:49,754 valid 050 1.766793e-01 -222.637016
2019-12-04 16:14:51,815 validation loss; R2: 1.800291e-01 -223.366711
2019-12-04 16:14:51,827 epoch 4 lr 1.000000e-03
2019-12-04 16:14:52,091 train 000 1.560133e-01 -276.187370
2019-12-04 16:15:01,998 train 050 1.579864e-01 -232.824066
2019-12-04 16:15:11,906 train 100 1.590141e-01 -231.665786
2019-12-04 16:15:21,794 train 150 1.611543e-01 -230.388980
2019-12-04 16:15:31,684 train 200 1.604536e-01 -231.929022
2019-12-04 16:15:41,566 train 250 1.613432e-01 -233.172818
2019-12-04 16:15:51,450 train 300 1.624152e-01 -234.766417
2019-12-04 16:16:01,335 train 350 1.637841e-01 -231.876790
2019-12-04 16:16:11,219 train 400 1.632102e-01 -234.717314
2019-12-04 16:16:21,101 train 450 1.629042e-01 -234.042902
2019-12-04 16:16:30,988 train 500 1.632565e-01 -233.021930
2019-12-04 16:16:40,862 train 550 1.632674e-01 -234.877182
2019-12-04 16:16:50,738 train 600 1.628547e-01 -233.967625
2019-12-04 16:17:00,610 train 650 1.628828e-01 -233.278243
2019-12-04 16:17:10,499 train 700 1.629082e-01 -234.320291
2019-12-04 16:17:20,388 train 750 1.631051e-01 -234.471665
2019-12-04 16:17:30,265 train 800 1.632585e-01 -233.999383
2019-12-04 16:17:40,148 train 850 1.627423e-01 -234.247330
2019-12-04 16:17:48,009 training loss; R2: 1.627091e-01 -234.383312
2019-12-04 16:17:48,116 valid 000 1.943944e-01 -203.227044
2019-12-04 16:17:50,263 valid 050 1.796228e-01 -245.642302
2019-12-04 16:17:52,324 validation loss; R2: 1.746591e-01 -232.744932
2019-12-04 16:17:52,336 epoch 5 lr 1.000000e-03
2019-12-04 16:17:52,601 train 000 1.412962e-01 -163.301780
2019-12-04 16:18:02,495 train 050 1.615526e-01 -255.540633
2019-12-04 16:18:12,384 train 100 1.624315e-01 -252.535994
2019-12-04 16:18:22,274 train 150 1.641711e-01 -240.083337
2019-12-04 16:18:32,166 train 200 1.638781e-01 -240.376146
2019-12-04 16:18:42,060 train 250 1.631395e-01 -236.715589
2019-12-04 16:18:51,959 train 300 1.633613e-01 -235.386927
2019-12-04 16:19:01,844 train 350 1.638556e-01 -231.453769
2019-12-04 16:19:11,725 train 400 1.640762e-01 -232.299868
2019-12-04 16:19:21,609 train 450 1.634518e-01 -233.806624
2019-12-04 16:19:31,486 train 500 1.631777e-01 -234.909630
2019-12-04 16:19:41,367 train 550 1.627221e-01 -236.148001
2019-12-04 16:19:51,241 train 600 1.626451e-01 -236.261813
2019-12-04 16:20:01,117 train 650 1.627250e-01 -236.527916
2019-12-04 16:20:10,989 train 700 1.624778e-01 -236.652709
2019-12-04 16:20:20,864 train 750 1.618731e-01 -236.458457
2019-12-04 16:20:30,742 train 800 1.619038e-01 -236.566979
2019-12-04 16:20:40,619 train 850 1.616703e-01 -236.106446
2019-12-04 16:20:48,476 training loss; R2: 1.614787e-01 -236.013726
2019-12-04 16:20:48,586 valid 000 1.625222e-01 -206.764118
2019-12-04 16:20:50,734 valid 050 1.716678e-01 -232.139803
2019-12-04 16:20:52,794 validation loss; R2: 1.751424e-01 -227.030477
2019-12-04 16:20:52,812 epoch 6 lr 1.000000e-03
2019-12-04 16:20:53,076 train 000 1.470865e-01 -197.080538
2019-12-04 16:21:02,951 train 050 1.619644e-01 -223.848773
2019-12-04 16:21:12,822 train 100 1.619375e-01 -241.193938
2019-12-04 16:21:22,711 train 150 1.614310e-01 -242.713194
2019-12-04 16:21:32,614 train 200 1.601794e-01 -241.043974
2019-12-04 16:21:42,492 train 250 1.603775e-01 -240.322577
2019-12-04 16:21:52,452 train 300 1.602137e-01 -238.520783
2019-12-04 16:22:02,342 train 350 1.607116e-01 -240.112151
2019-12-04 16:22:12,219 train 400 1.607550e-01 -241.154123
2019-12-04 16:22:22,099 train 450 1.615237e-01 -241.296611
2019-12-04 16:22:31,998 train 500 1.617172e-01 -242.715168
2019-12-04 16:22:41,881 train 550 1.624218e-01 -241.989356
2019-12-04 16:22:51,764 train 600 1.622552e-01 -241.379436
2019-12-04 16:23:01,645 train 650 1.618418e-01 -241.014095
2019-12-04 16:23:11,526 train 700 1.615831e-01 -240.731706
2019-12-04 16:23:21,406 train 750 1.613682e-01 -240.952398
2019-12-04 16:23:31,285 train 800 1.613510e-01 -241.390783
2019-12-04 16:23:41,165 train 850 1.608964e-01 -242.006714
2019-12-04 16:23:49,017 training loss; R2: 1.603624e-01 -242.809297
2019-12-04 16:23:49,125 valid 000 1.697114e-01 -135.223050
2019-12-04 16:23:51,272 valid 050 1.823262e-01 -219.818906
2019-12-04 16:23:53,332 validation loss; R2: 1.777929e-01 -213.244987
2019-12-04 16:23:53,344 epoch 7 lr 1.000000e-03
2019-12-04 16:23:53,604 train 000 1.544133e-01 -258.098886
2019-12-04 16:24:03,468 train 050 1.529453e-01 -243.636942
2019-12-04 16:24:13,331 train 100 1.560724e-01 -245.306120
2019-12-04 16:24:23,212 train 150 1.585078e-01 -238.774031
2019-12-04 16:24:33,078 train 200 1.584054e-01 -234.794582
2019-12-04 16:24:42,947 train 250 1.592082e-01 -231.946252
2019-12-04 16:24:52,817 train 300 1.590568e-01 -234.465034
2019-12-04 16:25:02,693 train 350 1.597718e-01 -235.236290
2019-12-04 16:25:12,566 train 400 1.589590e-01 -237.425494
2019-12-04 16:25:22,453 train 450 1.587984e-01 -239.429481
2019-12-04 16:25:32,333 train 500 1.588371e-01 -240.951412
2019-12-04 16:25:42,205 train 550 1.588898e-01 -241.777396
2019-12-04 16:25:52,071 train 600 1.590368e-01 -242.624874
2019-12-04 16:26:01,948 train 650 1.589561e-01 -243.515766
2019-12-04 16:26:11,829 train 700 1.590380e-01 -243.635610
2019-12-04 16:26:21,716 train 750 1.594569e-01 -243.403118
2019-12-04 16:26:31,599 train 800 1.597927e-01 -242.845383
2019-12-04 16:26:41,468 train 850 1.596855e-01 -242.586891
2019-12-04 16:26:49,316 training loss; R2: 1.597357e-01 -242.119032
2019-12-04 16:26:49,425 valid 000 8.049259e-01 -1056.245837
2019-12-04 16:26:51,571 valid 050 8.381815e-01 -699.661144
2019-12-04 16:26:53,630 validation loss; R2: 8.476696e-01 -689.666707
2019-12-04 16:26:53,641 epoch 8 lr 1.000000e-03
2019-12-04 16:26:53,907 train 000 1.562375e-01 -170.585097
2019-12-04 16:27:03,800 train 050 1.628647e-01 -252.541938
2019-12-04 16:27:13,677 train 100 1.643450e-01 -255.883371
2019-12-04 16:27:23,570 train 150 1.631235e-01 -249.906857
2019-12-04 16:27:33,646 train 200 1.626264e-01 -251.544452
2019-12-04 16:27:43,709 train 250 1.603154e-01 -251.282099
2019-12-04 16:27:53,770 train 300 1.603148e-01 -251.167269
2019-12-04 16:28:03,835 train 350 1.599850e-01 -250.849595
2019-12-04 16:28:13,900 train 400 1.597125e-01 -249.316237
2019-12-04 16:28:23,961 train 450 1.591011e-01 -248.988669
2019-12-04 16:28:34,027 train 500 1.588708e-01 -248.520432
2019-12-04 16:28:44,103 train 550 1.585145e-01 -248.617222
2019-12-04 16:28:54,192 train 600 1.587933e-01 -247.743803
2019-12-04 16:29:04,096 train 650 1.588143e-01 -247.289007
2019-12-04 16:29:13,973 train 700 1.585806e-01 -245.825400
2019-12-04 16:29:23,855 train 750 1.583772e-01 -246.286141
2019-12-04 16:29:33,730 train 800 1.588272e-01 -245.736149
2019-12-04 16:29:43,636 train 850 1.587382e-01 -247.006281
2019-12-04 16:29:51,499 training loss; R2: 1.588798e-01 -246.397879
2019-12-04 16:29:51,625 valid 000 2.077896e-01 -310.913455
2019-12-04 16:29:53,772 valid 050 1.845920e-01 -216.317052
2019-12-04 16:29:55,831 validation loss; R2: 1.853912e-01 -208.845873
2019-12-04 16:29:55,853 epoch 9 lr 1.000000e-03
2019-12-04 16:29:56,133 train 000 1.576200e-01 -312.862795
2019-12-04 16:30:06,003 train 050 1.593840e-01 -239.981331
2019-12-04 16:30:15,870 train 100 1.600090e-01 -237.918423
2019-12-04 16:30:25,739 train 150 1.580315e-01 -239.295178
2019-12-04 16:30:35,610 train 200 1.587971e-01 -241.871273
2019-12-04 16:30:45,482 train 250 1.592040e-01 -240.457052
2019-12-04 16:30:55,352 train 300 1.590130e-01 -241.210197
2019-12-04 16:31:05,221 train 350 1.589430e-01 -243.439502
2019-12-04 16:31:15,085 train 400 1.587045e-01 -244.339445
2019-12-04 16:31:24,948 train 450 1.582567e-01 -244.282269
2019-12-04 16:31:34,809 train 500 1.586883e-01 -242.577400
2019-12-04 16:31:44,681 train 550 1.575857e-01 -243.131447
2019-12-04 16:31:54,544 train 600 1.577216e-01 -244.781508
2019-12-04 16:32:04,411 train 650 1.580173e-01 -246.238881
2019-12-04 16:32:14,291 train 700 1.582286e-01 -246.881447
2019-12-04 16:32:24,168 train 750 1.580749e-01 -246.729231
2019-12-04 16:32:34,165 train 800 1.582098e-01 -247.425911
2019-12-04 16:32:44,247 train 850 1.586075e-01 -247.462943
2019-12-04 16:32:52,258 training loss; R2: 1.584949e-01 -246.998692
2019-12-04 16:32:52,363 valid 000 1.778578e-01 -185.947959
2019-12-04 16:32:54,512 valid 050 1.818042e-01 -176.569335
2019-12-04 16:32:56,573 validation loss; R2: 1.796904e-01 -177.999439
2019-12-04 16:32:56,585 epoch 10 lr 1.000000e-03
2019-12-04 16:32:56,852 train 000 1.082356e-01 -132.881452
2019-12-04 16:33:06,908 train 050 1.540343e-01 -258.990942
2019-12-04 16:33:16,956 train 100 1.552838e-01 -255.895355
2019-12-04 16:33:27,017 train 150 1.560779e-01 -258.153229
2019-12-04 16:33:37,086 train 200 1.555247e-01 -258.506958
2019-12-04 16:33:47,142 train 250 1.548623e-01 -257.475204
2019-12-04 16:33:57,198 train 300 1.554275e-01 -258.615316
2019-12-04 16:34:07,257 train 350 1.557248e-01 -257.251764
2019-12-04 16:34:17,316 train 400 1.544951e-01 -256.113829
2019-12-04 16:34:27,370 train 450 1.554217e-01 -256.959268
2019-12-04 16:34:37,430 train 500 1.557759e-01 -255.528868
2019-12-04 16:34:47,484 train 550 1.564577e-01 -256.104720
2019-12-04 16:34:57,534 train 600 1.569001e-01 -254.758567
2019-12-04 16:35:07,593 train 650 1.574822e-01 -251.900199
2019-12-04 16:35:17,650 train 700 1.578121e-01 -251.422288
2019-12-04 16:35:27,705 train 750 1.577080e-01 -251.578936
2019-12-04 16:35:37,761 train 800 1.574789e-01 -252.204750
2019-12-04 16:35:47,810 train 850 1.579006e-01 -251.671767
2019-12-04 16:35:55,813 training loss; R2: 1.578787e-01 -250.477203
2019-12-04 16:35:55,925 valid 000 2.070418e-01 -383.771372
2019-12-04 16:35:58,074 valid 050 1.702158e-01 -225.141001
2019-12-04 16:36:00,132 validation loss; R2: 1.733676e-01 -230.127614
2019-12-04 16:36:00,144 epoch 11 lr 1.000000e-03
2019-12-04 16:36:00,406 train 000 1.544781e-01 -153.217562
2019-12-04 16:36:10,271 train 050 1.619051e-01 -256.790539
2019-12-04 16:36:20,133 train 100 1.583073e-01 -244.796199
2019-12-04 16:36:29,995 train 150 1.584044e-01 -251.077337
2019-12-04 16:36:39,858 train 200 1.569190e-01 -254.064505
2019-12-04 16:36:49,726 train 250 1.564093e-01 -253.334461
2019-12-04 16:36:59,590 train 300 1.560073e-01 -254.829308
2019-12-04 16:37:09,473 train 350 1.567946e-01 -253.040768
2019-12-04 16:37:19,351 train 400 1.567667e-01 -251.916697
2019-12-04 16:37:29,216 train 450 1.570375e-01 -251.409807
2019-12-04 16:37:39,108 train 500 1.567248e-01 -251.324134
2019-12-04 16:37:48,978 train 550 1.568014e-01 -251.421707
2019-12-04 16:37:58,844 train 600 1.572179e-01 -250.586171
2019-12-04 16:38:08,716 train 650 1.569267e-01 -251.436057
2019-12-04 16:38:18,586 train 700 1.568921e-01 -251.572185
2019-12-04 16:38:28,452 train 750 1.570287e-01 -249.470797
2019-12-04 16:38:38,315 train 800 1.571051e-01 -250.920457
2019-12-04 16:38:48,176 train 850 1.572104e-01 -250.288076
2019-12-04 16:38:56,020 training loss; R2: 1.573130e-01 -250.412098
2019-12-04 16:38:56,133 valid 000 1.810601e-01 -218.376043
2019-12-04 16:38:58,277 valid 050 1.752300e-01 -223.290009
2019-12-04 16:39:00,335 validation loss; R2: 1.734455e-01 -234.871979
2019-12-04 16:39:00,347 epoch 12 lr 1.000000e-03
2019-12-04 16:39:00,609 train 000 1.279632e-01 -182.976877
2019-12-04 16:39:10,466 train 050 1.541242e-01 -239.941436
2019-12-04 16:39:20,320 train 100 1.533805e-01 -246.046713
2019-12-04 16:39:30,164 train 150 1.551336e-01 -250.261514
2019-12-04 16:39:40,008 train 200 1.560456e-01 -247.344541
2019-12-04 16:39:49,854 train 250 1.570084e-01 -248.412987
2019-12-04 16:39:59,699 train 300 1.572910e-01 -249.561404
2019-12-04 16:40:09,547 train 350 1.576065e-01 -249.327360
2019-12-04 16:40:19,391 train 400 1.578209e-01 -248.342129
2019-12-04 16:40:29,234 train 450 1.581095e-01 -247.255432
2019-12-04 16:40:39,080 train 500 1.578482e-01 -247.690311
2019-12-04 16:40:48,932 train 550 1.571762e-01 -250.330579
2019-12-04 16:40:58,789 train 600 1.572270e-01 -251.331113
2019-12-04 16:41:08,632 train 650 1.568791e-01 -250.544561
2019-12-04 16:41:18,479 train 700 1.572720e-01 -250.693691
2019-12-04 16:41:28,325 train 750 1.569104e-01 -251.174848
2019-12-04 16:41:38,170 train 800 1.567010e-01 -251.451551
2019-12-04 16:41:48,016 train 850 1.568074e-01 -251.851053
2019-12-04 16:41:55,854 training loss; R2: 1.568002e-01 -252.703711
2019-12-04 16:41:55,959 valid 000 1.725527e-01 -279.145197
2019-12-04 16:41:58,104 valid 050 1.698293e-01 -191.985200
2019-12-04 16:42:00,161 validation loss; R2: 1.721570e-01 -189.361122
2019-12-04 16:42:00,173 epoch 13 lr 1.000000e-03
2019-12-04 16:42:00,435 train 000 1.955264e-01 -299.199916
2019-12-04 16:42:10,298 train 050 1.566382e-01 -236.719602
2019-12-04 16:42:20,158 train 100 1.559072e-01 -252.395608
2019-12-04 16:42:30,012 train 150 1.551455e-01 -256.250328
2019-12-04 16:42:39,863 train 200 1.553591e-01 -251.523986
2019-12-04 16:42:49,718 train 250 1.555166e-01 -252.947373
2019-12-04 16:42:59,653 train 300 1.553458e-01 -255.760523
2019-12-04 16:43:09,688 train 350 1.564080e-01 -256.956966
2019-12-04 16:43:19,547 train 400 1.556782e-01 -255.978717
2019-12-04 16:43:29,406 train 450 1.551965e-01 -256.152780
2019-12-04 16:43:39,264 train 500 1.556687e-01 -256.625468
2019-12-04 16:43:49,134 train 550 1.561433e-01 -256.070826
2019-12-04 16:43:58,994 train 600 1.564752e-01 -254.519148
2019-12-04 16:44:08,856 train 650 1.566568e-01 -253.465233
2019-12-04 16:44:18,723 train 700 1.564161e-01 -254.438538
2019-12-04 16:44:28,589 train 750 1.559681e-01 -253.907087
2019-12-04 16:44:38,471 train 800 1.560871e-01 -254.659066
2019-12-04 16:44:48,332 train 850 1.562236e-01 -253.463464
2019-12-04 16:44:56,175 training loss; R2: 1.564100e-01 -252.747644
2019-12-04 16:44:56,289 valid 000 1.367923e-01 -130.051539
2019-12-04 16:44:58,435 valid 050 1.709930e-01 -195.879092
2019-12-04 16:45:00,492 validation loss; R2: 1.717711e-01 -212.029354
2019-12-04 16:45:00,504 epoch 14 lr 1.000000e-03
2019-12-04 16:45:00,763 train 000 1.696186e-01 -263.747687
2019-12-04 16:45:10,624 train 050 1.532798e-01 -260.160120
2019-12-04 16:45:20,481 train 100 1.538371e-01 -257.917032
2019-12-04 16:45:30,433 train 150 1.548089e-01 -259.395889
2019-12-04 16:45:40,473 train 200 1.542381e-01 -257.878353
2019-12-04 16:45:50,508 train 250 1.554367e-01 -257.062344
2019-12-04 16:46:00,543 train 300 1.553285e-01 -257.805715
2019-12-04 16:46:10,580 train 350 1.559091e-01 -256.551817
2019-12-04 16:46:20,618 train 400 1.559719e-01 -257.554356
2019-12-04 16:46:30,655 train 450 1.554742e-01 -256.819431
2019-12-04 16:46:40,689 train 500 1.556783e-01 -255.359092
2019-12-04 16:46:50,727 train 550 1.558465e-01 -255.720328
2019-12-04 16:47:00,762 train 600 1.556256e-01 -257.141860
2019-12-04 16:47:10,801 train 650 1.553189e-01 -255.816782
2019-12-04 16:47:20,838 train 700 1.560369e-01 -255.787215
2019-12-04 16:47:30,870 train 750 1.558895e-01 -256.232272
2019-12-04 16:47:40,903 train 800 1.557785e-01 -255.396699
2019-12-04 16:47:50,939 train 850 1.557710e-01 -253.559531
2019-12-04 16:47:58,920 training loss; R2: 1.556895e-01 -253.432239
2019-12-04 16:47:59,028 valid 000 1.707900e-01 -145.871134
2019-12-04 16:48:01,177 valid 050 1.744685e-01 -212.145249
2019-12-04 16:48:03,238 validation loss; R2: 1.705623e-01 -209.209111
2019-12-04 16:48:03,250 epoch 15 lr 1.000000e-03
2019-12-04 16:48:03,516 train 000 1.706838e-01 -392.525685
2019-12-04 16:48:13,575 train 050 1.548679e-01 -260.528438
2019-12-04 16:48:23,604 train 100 1.528055e-01 -259.856381
2019-12-04 16:48:33,627 train 150 1.540062e-01 -251.651293
2019-12-04 16:48:43,491 train 200 1.547409e-01 -249.409438
2019-12-04 16:48:53,347 train 250 1.545044e-01 -250.945352
2019-12-04 16:49:03,198 train 300 1.537645e-01 -251.941124
2019-12-04 16:49:13,050 train 350 1.544335e-01 -252.520548
2019-12-04 16:49:22,909 train 400 1.551493e-01 -253.967269
2019-12-04 16:49:32,759 train 450 1.550824e-01 -256.122079
2019-12-04 16:49:42,620 train 500 1.549772e-01 -255.698082
2019-12-04 16:49:52,483 train 550 1.545582e-01 -255.437749
2019-12-04 16:50:02,333 train 600 1.545197e-01 -256.051647
2019-12-04 16:50:12,187 train 650 1.545036e-01 -257.269367
2019-12-04 16:50:22,038 train 700 1.548695e-01 -257.689353
2019-12-04 16:50:31,892 train 750 1.548050e-01 -257.339059
2019-12-04 16:50:41,746 train 800 1.549418e-01 -256.916346
2019-12-04 16:50:51,601 train 850 1.549469e-01 -257.030642
2019-12-04 16:50:59,435 training loss; R2: 1.550238e-01 -257.640437
2019-12-04 16:50:59,543 valid 000 1.539418e-01 -257.787537
2019-12-04 16:51:01,688 valid 050 1.686592e-01 -228.799791
2019-12-04 16:51:03,746 validation loss; R2: 1.693837e-01 -229.836346
